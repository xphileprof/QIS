{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import make_scorer #CHANGE (updated to be consistent with scikit_learn .24)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import precision_score,accuracy_score, f1_score, recall_score, hamming_loss\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import backend as K\n",
    "\n",
    "#%matplotlib inline\n",
    "#import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "\n",
    "print (pd.__version__)\n",
    "\n",
    "######### DEFINITION OF GLOBAL VARIABLES #########\n",
    "RUN_CONFIGURATION_LOOP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "#sys.path.append('/')\n",
    "import circuits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are super long functions to be hard coded because i dont have time to properly fix them, sorry bout it\n",
    "#[(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 1.5, -0.5), (0, 1.5, 1.5)]\n",
    "def graph_with_errs_d3(df):\n",
    "    x_data = []\n",
    "    z_data = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        x_data.append([])\n",
    "        z_data.append([])\n",
    "        \n",
    "        if df.loc[i].at[\"X0\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 0.5))\n",
    "        if df.loc[i].at[\"Z1\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 0.5))\n",
    "        if df.loc[i].at[\"X2\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 1.5))\n",
    "        if df.loc[i].at[\"Z3\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 2.5))\n",
    "        if df.loc[i].at[\"Z4\"] == -1:\n",
    "            z_data[i].append((0, 1.5, -0.5))\n",
    "        if df.loc[i].at[\"X5\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 0.5))\n",
    "        if df.loc[i].at[\"X6\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 1.5))\n",
    "        if df.loc[i].at[\"Z7\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 1.5))\n",
    "        x_data[i] = str(x_data[i])\n",
    "        z_data[i] = str(z_data[i])\n",
    "    #graph_df = pd.DataFrame(df[\"Labels\"], x_data, z_data, columns=[\"Labels\", \"XSyn\", \"ZSyn\"])\n",
    "    graph_df = pd.DataFrame({\"XSyn\":x_data, \"ZSyn\":z_data})\n",
    "    return graph_df\n",
    "        \n",
    "\n",
    "def graph_with_errs_d5(df):\n",
    "    x_data = []\n",
    "    z_data = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        x_data.append([])\n",
    "        z_data.append([])\n",
    "        if df.loc[i].at[\"X0\"] == -1:\n",
    "             x_data[i].append((0, -0.5, 0.5))\n",
    "        if df.loc[i].at[\"Z1\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 0.5))\n",
    "        if df.loc[i].at[\"X2\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 1.5))\n",
    "        if df.loc[i].at[\"X3\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 2.5))\n",
    "        if df.loc[i].at[\"Z4\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 2.5))\n",
    "        if df.loc[i].at[\"X5\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 3.5))\n",
    "        if df.loc[i].at[\"Z6\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 4.5))\n",
    "        if df.loc[i].at[\"Z7\"] == -1:\n",
    "            z_data[i].append((0, 1.5, -0.5))\n",
    "        if df.loc[i].at[\"X8\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 0.5))\n",
    "        if df.loc[i].at[\"Z9\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 1.5))\n",
    "        if df.loc[i].at[\"X10\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 2.5))\n",
    "        if df.loc[i].at[\"Z11\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 3.5))\n",
    "        if df.loc[i].at[\"Z12\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 0.5))\n",
    "        if df.loc[i].at[\"X13\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 1.5))\n",
    "        if df.loc[i].at[\"Z14\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 2.5))\n",
    "        if df.loc[i].at[\"X15\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 3.5))\n",
    "        if df.loc[i].at[\"Z16\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 4.5))\n",
    "        if df.loc[i].at[\"Z17\"] == -1:\n",
    "            z_data[i].append((0, 3.5, -0.5))\n",
    "        if df.loc[i].at[\"X18\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 0.5))\n",
    "        if df.loc[i].at[\"X19\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 1.5))\n",
    "        if df.loc[i].at[\"Z20\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 1.5))\n",
    "        if df.loc[i].at[\"X21\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 2.5))\n",
    "        if df.loc[i].at[\"X22\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 3.5))\n",
    "        if df.loc[i].at[\"Z23\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 3.5))\n",
    "        x_data[i] = str(x_data[i])\n",
    "        z_data[i] = str(z_data[i])\n",
    "            \n",
    "    graph_df = pd.DataFrame({\"XSyn\":x_data, \"ZSyn\":z_data})\n",
    "    return graph_df\n",
    "    \n",
    "def graph_with_errs_d7(df):\n",
    "    x_data = []\n",
    "    z_data = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        x_data.append([])\n",
    "        z_data.append([])\n",
    "        \n",
    "        if df.loc[i].at[\"X0\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 0.5))\n",
    "        if df.loc[i].at[\"Z1\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 0.5))\n",
    "        if df.loc[i].at[\"X2\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 1.5))\n",
    "        if df.loc[i].at[\"X3\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 2.5))\n",
    "        if df.loc[i].at[\"Z4\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 2.5))\n",
    "        if df.loc[i].at[\"X5\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 3.5))\n",
    "        if df.loc[i].at[\"X6\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 4.5))\n",
    "        if df.loc[i].at[\"Z7\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 4.5))\n",
    "        if df.loc[i].at[\"X8\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 5.5))\n",
    "        if df.loc[i].at[\"Z9\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 6.5))\n",
    "        if df.loc[i].at[\"Z10\"] == -1:\n",
    "            z_data[i].append((0, 1.5, -0.5))\n",
    "        if df.loc[i].at[\"X11\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 0.5))\n",
    "        if df.loc[i].at[\"Z12\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 1.5))\n",
    "        if df.loc[i].at[\"X13\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 2.5))\n",
    "        if df.loc[i].at[\"Z14\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 3.5))\n",
    "        if df.loc[i].at[\"X15\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 4.5))\n",
    "        if df.loc[i].at[\"Z16\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 5.5))\n",
    "        if df.loc[i].at[\"Z17\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 0.5))\n",
    "        if df.loc[i].at[\"X18\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 1.5))\n",
    "        if df.loc[i].at[\"Z19\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 2.5))\n",
    "        if df.loc[i].at[\"X20\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 3.5))\n",
    "        if df.loc[i].at[\"Z21\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 4.5))\n",
    "        if df.loc[i].at[\"X22\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 5.5))\n",
    "        if df.loc[i].at[\"Z23\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 6.5))\n",
    "        if df.loc[i].at[\"Z24\"] == -1:\n",
    "            z_data[i].append((0, 3.5, -0.5))\n",
    "        if df.loc[i].at[\"X25\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 0.5))\n",
    "        if df.loc[i].at[\"Z26\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 1.5))\n",
    "        if df.loc[i].at[\"X27\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 2.5))\n",
    "        if df.loc[i].at[\"Z28\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 3.5))\n",
    "        if df.loc[i].at[\"X29\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 4.5))\n",
    "        if df.loc[i].at[\"Z30\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 5.5))\n",
    "        if df.loc[i].at[\"Z31\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 0.5))\n",
    "        if df.loc[i].at[\"X32\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 1.5))\n",
    "        if df.loc[i].at[\"Z33\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 2.5))\n",
    "        if df.loc[i].at[\"X34\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 3.5))\n",
    "        if df.loc[i].at[\"Z35\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 4.5))\n",
    "        if df.loc[i].at[\"X36\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 5.5))\n",
    "        if df.loc[i].at[\"Z37\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 6.5))\n",
    "        if df.loc[i].at[\"Z38\"] == -1:\n",
    "            z_data[i].append((0, 5.5, -0.5))\n",
    "        if df.loc[i].at[\"X39\"] == -1:\n",
    "            x_data[i].append((0, 5.5, 0.5))\n",
    "        if df.loc[i].at[\"X40\"] == -1:\n",
    "            x_data[i].append((0, 6.5, 1.5))\n",
    "        if df.loc[i].at[\"Z41\"] == -1:\n",
    "            z_data[i].append((0, 5.5, 1.5))\n",
    "        if df.loc[i].at[\"X42\"] == -1:\n",
    "            x_data[i].append((0, 5.5, 2.5))\n",
    "        if df.loc[i].at[\"X43\"] == -1:\n",
    "            x_data[i].append((0, 6.5, 3.5))\n",
    "        if df.loc[i].at[\"Z44\"] == -1:\n",
    "            z_data[i].append((0, 5.5, 3.5))\n",
    "        if df.loc[i].at[\"X45\"] == -1:\n",
    "            x_data[i].append((0, 5.5, 4.5))\n",
    "        if df.loc[i].at[\"X46\"] == -1:\n",
    "            x_data[i].append((0, 6.5, 5.5))\n",
    "        if df.loc[i].at[\"Z47\"] == -1: \n",
    "            z_data[i].append((0, 5.5, 5.5))\n",
    "        x_data[i] = str(x_data[i])\n",
    "        z_data[i] = str(z_data[i])\n",
    "    graph_df = pd.DataFrame({\"XSyn\":x_data, \"ZSyn\":z_data})\n",
    "    return graph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions needed to work with the GraphDecoder/MWPM module\n",
    "import time\n",
    "\n",
    "def add_measurement_errs(curr_syn, prob_err, x_syn, depth):\n",
    "    #x_syn is True if it is x syndrome, False if it is Z syndrome\n",
    "    total_time = 0\n",
    "    new_syn = []\n",
    "    if x_syn:\n",
    "        for i in curr_syn:\n",
    "            rand = random.random()\n",
    "            if rand > prob_err:\n",
    "                new_syn.append(i)\n",
    "        return (new_syn + return_xmeasurement_errs(depth, prob_err))\n",
    "    else:\n",
    "        for i in curr_syn:\n",
    "            rand = random.random()\n",
    "            if rand > prob_err:\n",
    "                new_syn.append(i)\n",
    "        return (new_syn + return_zmeasurement_errs(depth, prob_err))\n",
    "    \n",
    "def do_new_decoding(data, depth, prob_err):\n",
    "    decoder = circuits.GraphDecoder(depth,1)\n",
    "    G = decoder.S['Z']\n",
    "    #decoder.graph_2D(G,'distance')\n",
    "    df = pd.DataFrame()\n",
    "    syn = []\n",
    "    total_time = 0\n",
    "    \n",
    "    for row in data:\n",
    "        x_input = []\n",
    "        z_input = []\n",
    "        x_type = True\n",
    "        for col in row:\n",
    "            if not col == \"[]\":\n",
    "                col = eval(col)\n",
    "                for c in col:\n",
    "                    if x_type:\n",
    "                        x_input.append(c)\n",
    "                    else:\n",
    "                        z_input.append(c)\n",
    "            x_type = not x_type  \n",
    "            \n",
    "        if prob_err > 0:\n",
    "            syndromes_x = add_measurement_errs(x_input, prob_err, True, depth)\n",
    "            syndromes_z = add_measurement_errs(z_input, prob_err, False, depth)\n",
    "        else:\n",
    "            syndromes_x = x_input\n",
    "            syndromes_z = z_input\n",
    "\n",
    "        start = time.time_ns()\n",
    "        error_graph_x, paths_x = decoder.make_error_graph(syndromes_x,'X')\n",
    "        matching_graph_x = decoder.matching_graph(error_graph_x,'X')\n",
    "        matches_x = decoder.matching(matching_graph_x,'X')\n",
    "        flips_x = decoder.calculate_qubit_flips(matches_x, paths_x,'X')\n",
    "        syn_x = (translate_errors(flips_x))\n",
    "\n",
    "        error_graph_z, paths_z = decoder.make_error_graph(syndromes_z,'Z')\n",
    "        matching_graph_z = decoder.matching_graph(error_graph_z,'Z')\n",
    "        matches_z = decoder.matching(matching_graph_z,'Z')\n",
    "        flips_z = decoder.calculate_qubit_flips(matches_z, paths_z,'Z')\n",
    "        syn_z = translate_errors(flips_z)\n",
    "        df = df.append(pd.Series([syn_x, syn_z]), ignore_index=True)\n",
    "        end = time.time_ns()\n",
    "        total_time += (end - start)/ (10 ** 9)\n",
    "    return (df, total_time) \n",
    "\n",
    "import random\n",
    "def return_xmeasurement_errs(depth, prob):\n",
    "    \n",
    "    new_errs = []\n",
    "    \n",
    "    if depth == 3:\n",
    "        errs = [(0, -0.5, 0.5), (0, 0.5, 1.5), (0, 1.5, 0.5), (0, 2.5, 1.5)]\n",
    "    elif depth == 5:\n",
    "        errs = [(0, -0.5, 0.5), (0, 0.5, 1.5), (0, -0.5, 2.5), (0, 0.5, 3.5), (0, 1.5, 0.5), (0, 1.5, 2.5),\n",
    "                        (0, 2.5, 1.5), (0, 2.5, 3.5), (0, 3.5, 0.5), (0, 4.5, 1.5), (0, 3.5, 2.5), (0, 4.5, 3.5)]\n",
    "    else:\n",
    "        errs = [(0, -0.5, 0.5), (0, 0.5, 1.5), (0, -0.5, 2.5), (0, 0.5, 3.5), (0, -0.5, 4.5), (0, 0.5, 5.5),\n",
    "                        (0, 1.5, 0.5), (0, 1.5, 2.5), (0, 1.5, 4.5), (0, 2.5, 1.5), (0, 2.5, 3.5), (0, 2.5, 5.5),\n",
    "                        (0, 3.5, 0.5),  (0, 3.5, 2.5), (0, 3.5, 4.5), (0, 4.5, 1.5), (0, 4.5, 3.5), (0, 4.5, 5.5),\n",
    "                       (0, 5.5, 0.5), (0, 6.5, 1.5), (0, 5.5, 2.5), (0, 6.5, 3.5), (0, 5.5, 4.5), (0, 6.5, 5.5)]\n",
    "    for e in errs:\n",
    "        rand = random.random()\n",
    "        if rand <= prob:\n",
    "            new_errs.append(e)\n",
    "            \n",
    "    return new_errs\n",
    "            \n",
    "\n",
    "def return_zmeasurement_errs(depth, prob):\n",
    "    \n",
    "    new_errs = []\n",
    "    \n",
    "    if depth == 3:\n",
    "        errs = [(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 1.5, -0.5), (0, 1.5, 1.5)]\n",
    "    elif depth == 5:\n",
    "        errs = [(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 0.5, 4.5), (0, 1.5, -0.5), (0, 1.5, 1.5), (0, 1.5, 3.5),\n",
    "                        (0, 2.5, 0.5), (0, 2.5, 2.5), (0, 2.5, 4.5), (0, 3.5, -0.5), (0, 3.5, 1.5), (0, 3.5, 3.5)]\n",
    "    else:\n",
    "        errs = [(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 0.5, 4.5), (0, 0.5, 6.5), (0, 1.5, -0.5), (0, 1.5, 1.5),\n",
    "                        (0, 1.5, 3.5), (0, 1.5, 5.5), (0, 2.5, 0.5), (0, 2.5, 2.5), (0, 2.5, 4.5), (0, 2.5, 6.5),\n",
    "                        (0, 3.5, -0.5),  (0, 3.5, 1.5), (0, 3.5, 3.5), (0, 3.5, 5.5), (0, 4.5, 0.5), (0, 4.5, 2.5),\n",
    "                       (0, 4.5, 4.5), (0, 4.5, 6.5), (0, 5.5, -0.5), (0, 5.5, 1.5), (0, 5.5, 3.5), (0, 5.5, 5.5)]\n",
    "        \n",
    "    for e in errs:\n",
    "        rand = random.random()\n",
    "        if rand <= prob:\n",
    "            new_errs.append(e)\n",
    "            \n",
    "    return new_errs\n",
    "\n",
    "def translate_errors (phys_errs):\n",
    "    flipX = np.array([(0, 1),(1, 0)])\n",
    "    flipZ = np.array([(1, 0), (0, -1)])\n",
    "    errs = []\n",
    "    str2 = \"\"\n",
    "    for qubit, flip in phys_errs.items():\n",
    "        row = int(qubit[1])\n",
    "        col = int(qubit[2])\n",
    "        if str(flip) == \"X\":\n",
    "            str1 = \"X\"\n",
    "        elif str(flip) == \"Z\":\n",
    "            str1 = \"Z\"\n",
    "        else:\n",
    "            str1 = \"X\"\n",
    "            str2 = \"Z\"\n",
    "        str1 += str(row) + str(col)\n",
    "        errs.append(str1)\n",
    "        if str2 != \"\":\n",
    "            str2 += str(row) +str(col)\n",
    "            errs.append(str2)\n",
    "            str2 = \"\"\n",
    "    return errs   \n",
    "\n",
    "def translate_to_graph(df_graph, labels, mlb):\n",
    "#go through labels given\n",
    "    indices = []\n",
    "    labels = mlb.inverse_transform(labels)\n",
    "    \n",
    "    for row in labels:\n",
    "        label_str = str(row)\n",
    "        for index, r in df_graph.iterrows():\n",
    "            if label_str == \"('',)\":\n",
    "                if str(r[\"Labels\"]) == \"[' ']\":\n",
    "                    indices.append([index])\n",
    "                    break\n",
    "            if set(row) == set(r[\"Labels\"]):\n",
    "                indices.append([index])\n",
    "                break\n",
    "\n",
    "    df_syns = df_graph.drop(['Labels'], axis=1)\n",
    "    return_df = pd.DataFrame()\n",
    "    for i in indices:\n",
    "        return_df = return_df.append(df_syns.loc[i])\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function needed for preprocessing. CSV file reads in a string, needs to be a list for labels \n",
    "#for preprocessing csv files\n",
    "def create_list_from_string(err_list):\n",
    "    newstring = err_list.replace(\"'\", \"\")\n",
    "    new_err_list = newstring.strip('][').split(', ')\n",
    "    return sorted(set(new_err_list))\n",
    "\n",
    "\n",
    "def create_string_from_list(err_list):\n",
    "    return_string = \"[\"\n",
    "    if err_list[0] == \"''\":\n",
    "        return \"[' ']\"\n",
    "    else:\n",
    "        for index, i in enumerate(err_list):\n",
    "            return_string = return_string +  \"'\" + i + \"'\"\n",
    "            if index < (len(err_list)-1):\n",
    "                return_string += \", \"\n",
    "    return return_string + \"]\"\n",
    "        \n",
    "\n",
    "#take in two 2d arrays of predicted values, true values, and threshold to determine labels. \n",
    "#calculates the partial accuracy of the predicted values, averaged out for all obersvations\n",
    "def partial_accuracy(y_pred, y_true):\n",
    "    total = 0\n",
    "    rows = y_pred.shape[0]\n",
    "    cols = y_pred.shape[1]\n",
    "    for i in range(0, rows):\n",
    "        row_correct = 0\n",
    "        for j in range(0, cols):\n",
    "            if y_pred[i,j] == y_true[i,j]:\n",
    "                row_correct += 1\n",
    "        total += row_correct/cols\n",
    "    return total/rows\n",
    "\n",
    "def partial_accuracy_and_contingency(y_pred, y_true, mlb):\n",
    "    total = 0\n",
    "    a= np.zeros(shape=y_true.shape)\n",
    "    rows = y_pred.shape[0]\n",
    "    cols = y_pred.shape[1]\n",
    "    df = pd.DataFrame(a, columns = mlb.classes_)\n",
    "    for i in range(0, rows):\n",
    "        row_correct = 0\n",
    "        for j, label in enumerate(mlb.classes_):\n",
    "            if y_pred[i,j] == y_true[i,j]:\n",
    "                row_correct += 1\n",
    "                df.at[i, label] = 1\n",
    "            else:\n",
    "                df.at[i, label] = 0\n",
    "\n",
    "        total += row_correct/cols\n",
    "\n",
    "    return (total/rows, df)\n",
    "\n",
    "def contingency_table_and_t (clf1, clf2):\n",
    "    a = 0 #clf1 pos, clf2 pos\n",
    "    b = 0 #clf1 pos, clf2 neg\n",
    "    c = 0 #clf1 neg, clf2 pos\n",
    "    d = 0 #clf1 neg, clf2 neg\n",
    "    \n",
    "    for index, value in clf1.items():\n",
    "        if value == 1 and clf2[index] == 1:\n",
    "            a+=1\n",
    "        elif value == 1 and clf2[index] == 0: #classifier 1 right, classifier 2 wrong\n",
    "            b+=1\n",
    "        elif value == 0 and clf2[index] == 1: #classifier 1 wrong, classifier 2 right\n",
    "            c+=1\n",
    "        else:\n",
    "            d+=1\n",
    "    print(\"[\"+str(a)+\", \"+str(b)+\"]\")\n",
    "    print(\"[\"+str(c)+\", \"+str(d)+\"]\")\n",
    "    if b == 0 and c ==0:\n",
    "        print(\"both b and c are zero\")\n",
    "        t=0\n",
    "    else:\n",
    "        t = (((b-c)-1)**2)/(b+c)\n",
    "    return ([[a,b],[c,d]], t)\n",
    "\n",
    "def add_noise(val, noise_level):\n",
    "    rand = random.uniform(0, 1)\n",
    "    if rand <= noise_level:\n",
    "        if val == -1:\n",
    "            val = 1\n",
    "        elif val == 1:\n",
    "            val = -1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#x_d7= trainData_d7.dropna()\n",
    "#######################################################################################################\n",
    "\n",
    "##trainData_d7 = pd.read_csv(\"depth7_all_combos.csv\")\n",
    "##trainData_d7 = trainData_d7.applymap(lambda x: add_noise(x,.01))\n",
    "\n",
    "#These four lines remove duplicates\n",
    "##trainData_d7['Labels'] = trainData_d7['Labels'].map(lambda x: create_list_from_string(x))\n",
    "##trainData_d7['Labels'] = trainData_d7['Labels'].astype(str)\n",
    "##trainData_d7 = trainData_d7.drop_duplicates('Labels', keep='first', ignore_index=True)\n",
    "##trainData_d7['Labels'] = trainData_d7['Labels'].map(lambda x: create_list_from_string(x))\n",
    "\n",
    "##testData_d7_MWPM = graph_with_errs_d7(trainData_d7)\n",
    "\n",
    "#transforms the data to encoding for ML\n",
    "##mlb_d7 = MultiLabelBinarizer()\n",
    "##mlb_d7.fit(trainData_d7['Labels'])\n",
    "##df = pd.DataFrame(mlb_d7.transform(trainData_d7['Labels']))\n",
    "##df['Labels']= df.values.tolist()\n",
    "##trainData_d7 = trainData_d7.drop(['Labels'], axis=1)\n",
    "##trainData_d7 = pd.concat([df[\"Labels\"],testData_d7_MWPM, trainData_d7], axis=1, ignore_index=True)\n",
    "##trainData_d7.columns = [\"Labels\",\"XSyn\", \"ZSyn\",\"X0\", \"Z1\", \"X2\", \"X3\", \"Z4\", \"X5\", \"X6\", \"Z7\", \"X8\", \"Z9\", \"Z10\", \"X11\", \"Z12\", \"X13\", \"Z14\", \"X15\", \"Z16\", \"Z17\", \"X18\", \"Z19\",\"X20\", \"Z21\", \"X22\", \"Z23\", \"Z24\", \"X25\", \"Z26\", \"X27\", \"Z28\", \"X29\", \"Z30\", \"Z31\", \"X32\", \"Z33\", \"X34\", \"Z35\", \"X36\", \"Z37\", \"Z38\", \"X39\", \"X40\", \"Z41\", \"X42\", \"X43\", \"Z44\", \"X45\", \"X46\", \"Z47\"]\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "##trainData_d5 = pd.read_csv(\"depth5_all_combos.csv\") # RM FOR D7 TESTS\n",
    "##trainData_d5 = trainData_d5.applymap(lambda x: add_noise(x,.01)) #was .05  # RM FOR D7 TESTS\n",
    "#These four lines remove duplicates\n",
    "##trainData_d5['Labels'] = trainData_d5['Labels'].map(lambda x: create_list_from_string(x)) # RM FOR D7 TESTS\n",
    "##trainData_d5['Labels'] = trainData_d5['Labels'].astype(str) # RM FOR D7 TESTS\n",
    "##trainData_d5 = trainData_d5.drop_duplicates('Labels', keep='first', ignore_index=True) # RM FOR D7 TESTS\n",
    "##trainData_d5['Labels'] = trainData_d5['Labels'].map(lambda x: create_list_from_string(x)) # RM FOR D7 TESTS\n",
    "\n",
    "\n",
    "##testData_d5_MWPM = graph_with_errs_d5(trainData_d5) # RM FOR D7 TESTS\n",
    "\n",
    "\n",
    "#transforms the data to encoding for ML\n",
    "##mlb = MultiLabelBinarizer() # RM FOR D7 TESTS\n",
    "##mlb.fit(trainData_d5['Labels']) # RM FOR D7 TESTS\n",
    "##df = pd.DataFrame(mlb.transform(trainData_d5['Labels'])) # RM FOR D7 TESTS\n",
    "##df['Labels']= df.values.tolist() # RM FOR D7 TESTS\n",
    "##trainData_d5 = trainData_d5.drop(['Labels'], axis=1) # RM FOR D7 TESTS\n",
    "##trainData_d5 = pd.concat([df[\"Labels\"], testData_d5_MWPM, trainData_d5], axis=1, ignore_index=True) # RM FOR D7 TESTS\n",
    "##trainData_d5.columns = [\"Labels\",\"XSyn\", \"ZSyn\",\"X0\",\"Z1\",\"X2\",\"X3\",\"Z4\",\"X5\",\"Z6\",\"Z7\",\"X8\",\"Z9\",\"X10\",\"Z11\",\"Z12\",\"X13\",\"Z14\",\"X15\",\"Z16\",\"Z17\",\"X18\",\"X19\",\"Z20\",\"X21\",\"X22\",\"Z23\"] # RM FOR D7 TESTS\n",
    "#########################################################################################\n",
    "\n",
    "#Has no duplicates, small enough to check manually\n",
    "# Change the CSV file to whichever dataset I'm using\n",
    "trainData_d3 = pd.read_csv(\"v2samples.csv\") # RM FOR D7 TESTS\n",
    "\n",
    "trainData_d3[\"Labels\"] = trainData_d3['Labels'].map(lambda x: create_list_from_string(x)) # RM FOR D7 TESTS\n",
    "trainData_d3 = trainData_d3.applymap(lambda x: add_noise(x,.01)) # RM FOR D7 TESTS\n",
    "\n",
    "testData_d3_MWPM = graph_with_errs_d3(trainData_d3) # RM FOR D7 TESTS\n",
    "\n",
    "mlb_d3 = MultiLabelBinarizer() # RM FOR D7 TESTS\n",
    "mlb_d3.fit(trainData_d3[\"Labels\"]) # RM FOR D7 TESTS\n",
    "df = pd.DataFrame(mlb_d3.transform(trainData_d3['Labels'])) # RM FOR D7 TESTS\n",
    "df['Labels']= df.values.tolist() # RM FOR D7 TESTS\n",
    "trainData_d3 = trainData_d3.drop(['Labels'], axis=1) # RM FOR D7 TESTS\n",
    "trainData_d3 = pd.concat([df['Labels'], testData_d3_MWPM, trainData_d3], axis=1, ignore_index=True) # RM FOR D7 TESTS\n",
    "trainData_d3.columns = [\"Labels\",\"XSyn\", \"ZSyn\", \"X0\", \"Z1\", \"X2\", \"Z3\", \"Z4\", \"X5\", \"X6\", \"Z7\"] # RM FOR D7 TESTS\n",
    "#########################################################################################\n",
    "y_d3 = trainData_d3[\"Labels\"] # RM FOR D7 TESTS\n",
    "x_d3 = trainData_d3.drop([\"Labels\"], axis=1) # RM FOR D7 TESTS\n",
    "\n",
    "##y_d5 = trainData_d5[\"Labels\"]  # RM FOR D7 TESTS\n",
    "##x_d5 = trainData_d5.drop([\"Labels\"], axis=1)  # RM FOR D7 TESTS\n",
    "\n",
    "##y_d7 = trainData_d7[\"Labels\"]\n",
    "##x_d7 = trainData_d7.drop([\"Labels\"], axis=1)\n",
    "\n",
    "\n",
    "x_d3 = x_d3.replace([-1], 0) # RM FOR D7 TESTS\n",
    "##x_d5 = x_d5.replace([-1], 0) # RM FOR D7 TESTS\n",
    "##x_d7 = x_d7.replace([-1], 0)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brett: Not sure why this was here. It's just a duplicate. Consider removing.\n",
    "##y_d7 = trainData_d7[\"Labels\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for creating lookup tables here:\n",
    "from collections import defaultdict\n",
    "from math import log2\n",
    "\n",
    "def generateAllBinaryStrings(n, arr, i, lookup):  \n",
    "    if i == n: \n",
    "        lookup.setBitStringArray(arr, n)  \n",
    "        return\n",
    "      \n",
    "    # First assign \"0\" at ith position  \n",
    "    # and try for all other permutations  \n",
    "    # for remaining positions  \n",
    "    arr[i] = 0\n",
    "    generateAllBinaryStrings(n, arr, i + 1, lookup)  \n",
    "  \n",
    "    # And then assign \"1\" at ith position  , \n",
    "    # and try for all other permutations  \n",
    "    # for remaining positions  \n",
    "    arr[i] = 1\n",
    "    generateAllBinaryStrings(n, arr, i + 1, lookup)\n",
    "\n",
    "class lookup_decoder:\n",
    "    \n",
    "    def __init__(self, depth):\n",
    "        #self.lookupTable = defaultdict()\n",
    "        self.lookupTable = {}\n",
    "        self.distributions = {}\n",
    "        self.depth = depth\n",
    "        #generating all possible syndrome observations\n",
    "        #arr = [None] * (depth**2 - 1)\n",
    "        #generateAllBinaryStrings((depth**2 - 1), arr, 0, self)\n",
    "        \n",
    "    def setBitStringArray(self, arr, n): \n",
    "        new_str = \"\"\n",
    "        for i in range(0, n):  \n",
    "            new_str += str(arr[i])\n",
    "        self.lookupTable.update({new_str:defaultdict()})  \n",
    "        \n",
    "    def update_table (self, syndrome, phys_errs):\n",
    "        #all the keys are made in the init, so simply update the physical error combinations for the given syndrome\n",
    "        if syndrome not in self.lookupTable:\n",
    "            self.lookupTable[syndrome] = {}\n",
    "            self.lookupTable[syndrome][phys_errs] = 1\n",
    "            return\n",
    "        \n",
    "        if phys_errs not in self.lookupTable[syndrome]:\n",
    "            self.lookupTable[syndrome].update({phys_errs: 1})\n",
    "        else:\n",
    "            self.lookupTable[syndrome][phys_errs] += 1\n",
    "     \n",
    "    def get_probable_error(self, syndrome):\n",
    "        return_key = []\n",
    "\n",
    "        if syndrome not in self.lookupTable.keys():\n",
    "            for i in range(2* int(self.depth**2) + 1):\n",
    "                return_key.append(0)\n",
    "            return return_key\n",
    "        \n",
    "        key, value = max(self.lookupTable[syndrome].items(), key=lambda x:x[1])\n",
    "        \n",
    "        for character in key:\n",
    "            if character == '0' or character == '1':\n",
    "                return_key.append(int(character))\n",
    "                \n",
    "        return return_key\n",
    "        \n",
    "    def make_distribution_graph(self, syn):\n",
    "        \n",
    "        plt.bar(list(self.lookupTable[syn].keys()), self.lookupTable[syn].values(), color='g')\n",
    "        plt.show()\n",
    "        \n",
    "    def syndrome_count_graph(self):\n",
    "        graph_dict = {}\n",
    "        for syn in self.lookupTable:\n",
    "            graph_dict.update({syn:sum(self.lookupTable[syn].values())})\n",
    "        plt.ylim((0,4))\n",
    "        plt.bar(graph_dict.keys(), graph_dict.values())\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def length_of_lookup(self):\n",
    "        print(len(self.lookupTable))\n",
    "        \n",
    "            \n",
    "    def get_entropies(self):\n",
    "        entropies = {}\n",
    "        for syn in self.lookupTable:\n",
    "            total = sum(self.lookupTable[syn].values())\n",
    "            h = 0\n",
    "            for key in self.lookupTable[syn]:\n",
    "                p = self.lookupTable[syn][key]/total\n",
    "                h += p+log2(p)\n",
    "            entropies[syn] = -h\n",
    "        print(entropies)\n",
    "            \n",
    "    def get_syndromes(self):\n",
    "        return self.lookupTable.keys()\n",
    "                     \n",
    "    def print_lookup(self):\n",
    "        for syn in self.lookupTable:\n",
    "            print(self.lookupTable[syn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_plut(table, data_x, data_y):\n",
    "    i = 0\n",
    "    for index, x in enumerate(data_x):\n",
    "        syn = \"\".join([str(i) for i in x])\n",
    "        syn = syn.replace(\".0\",\"\")\n",
    "        labels = np.array2string(np.array(data_y[i]), precision=1, separator='',suppress_small=True).replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "        table.update_table(syn, labels)\n",
    "        i+=1\n",
    "    return table\n",
    "\n",
    "\n",
    "def test_plut(table, test_set):\n",
    "    predictions_lookup = []\n",
    "    for index, x in enumerate(test_set):\n",
    "        syn_x = \"\".join([str(i) for i in x])\n",
    "        syn_x = syn_x.replace(\".0\",\"\")\n",
    "        predictions_lookup.append(table.get_probable_error(syn_x))\n",
    "    return np.array(predictions_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_FFNN_model_DepthThree(depth):\n",
    "    model = Sequential()\n",
    "    layers = 2\n",
    "    #input layer\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    \n",
    "    #hidden layers go here\n",
    "    for i in range(layers):\n",
    "        model.add(Dense(80, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(19 , activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=tf.keras.optimizers.SGD(learning_rate=0.05),\n",
    "                  metrics=['accuracy']) #CHANGE  (added tf., changed lr to learning_rate)\n",
    "    return model\n",
    "\n",
    "#make any needed changes here\n",
    "def compile_FFNN_model_DepthFive(depth):\n",
    "    model = Sequential()\n",
    "    layers = 4\n",
    "    \n",
    "    #input layer\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    \n",
    "    #hidden layers go here\n",
    "    for i in range(layers):\n",
    "        model.add(Dense(240, activation='relu'))\n",
    "    \n",
    "    #model.add(Dense((2*depth**2) , activation='sigmoid'))\n",
    "    model.add(Dense(51, activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=tf.keras.optimizers.SGD(learning_rate=0.05),\n",
    "                  metrics=['accuracy']) #CHANGE (added tf.)\n",
    "    return model\n",
    "\n",
    "\n",
    "#make any needed changes here\n",
    "def compile_FFNN_model_DepthSeven(depth):\n",
    "    model = Sequential()\n",
    "    layers = 4\n",
    "    \n",
    "    #input layer\n",
    "    model.add(Dense(48, activation='relu'))\n",
    "    \n",
    "    #hidden layers go here\n",
    "    for i in range(layers):\n",
    "        model.add(Dense(400, activation='relu'))\n",
    "    \n",
    "    #model.add(Dense((2*depth**2) , activation='sigmoid'))\n",
    "    model.add(Dense(99, activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=tf.keras.optimizers.SGD(learning_rate=0.05),\n",
    "                  metrics=['accuracy']) #CHANGE  (added tf.)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:99: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_train = np.asarray(inputs_train).astype(np.int) #CHANGE (added)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:100: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  targets[train] = np.asarray(targets[train]).astype(np.int) #CHANGE (added)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6550 - accuracy: 0.0437 - val_loss: 0.6947 - val_accuracy: 0.0290\n",
      "Epoch 2/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6520 - accuracy: 0.0291 - val_loss: 0.7063 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6515 - accuracy: 0.0309 - val_loss: 0.7056 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6514 - accuracy: 0.0311 - val_loss: 0.7073 - val_accuracy: 0.3128\n",
      "Epoch 5/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6513 - accuracy: 0.0237 - val_loss: 0.7080 - val_accuracy: 0.0436\n",
      "Epoch 6/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6513 - accuracy: 0.0291 - val_loss: 0.7095 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6513 - accuracy: 0.0269 - val_loss: 0.7072 - val_accuracy: 0.0102\n",
      "Epoch 8/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6513 - accuracy: 0.0267 - val_loss: 0.7070 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0260 - val_loss: 0.7078 - val_accuracy: 0.0064\n",
      "Epoch 10/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0293 - val_loss: 0.7066 - val_accuracy: 0.0865\n",
      "Epoch 11/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0268 - val_loss: 0.7067 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0412 - val_loss: 0.7113 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6512 - accuracy: 0.0293 - val_loss: 0.7092 - val_accuracy: 0.0055\n",
      "Epoch 14/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0304 - val_loss: 0.7069 - val_accuracy: 0.3128\n",
      "Epoch 15/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0282 - val_loss: 0.7056 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0320 - val_loss: 0.7084 - val_accuracy: 0.0176\n",
      "Epoch 17/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0330 - val_loss: 0.7112 - val_accuracy: 0.0401\n",
      "Epoch 18/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0268 - val_loss: 0.7085 - val_accuracy: 0.1086\n",
      "Epoch 19/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0287 - val_loss: 0.7099 - val_accuracy: 0.3128\n",
      "Epoch 20/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0270 - val_loss: 0.7100 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0271 - val_loss: 0.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0293 - val_loss: 0.7081 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0282 - val_loss: 0.7101 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0327 - val_loss: 0.7100 - val_accuracy: 0.0094\n",
      "Epoch 25/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0298 - val_loss: 0.7079 - val_accuracy: 0.0304\n",
      "Epoch 26/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0339 - val_loss: 0.7062 - val_accuracy: 0.0094\n",
      "Epoch 27/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0339 - val_loss: 0.7085 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0336 - val_loss: 0.7100 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0348 - val_loss: 0.7110 - val_accuracy: 0.0850\n",
      "Epoch 30/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0319 - val_loss: 0.7099 - val_accuracy: 0.0127\n",
      "Epoch 31/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0436 - val_loss: 0.7064 - val_accuracy: 0.0125\n",
      "Epoch 32/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0286 - val_loss: 0.7089 - val_accuracy: 0.0122\n",
      "Epoch 33/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0286 - val_loss: 0.7118 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0210 - val_loss: 0.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0211 - val_loss: 0.7075 - val_accuracy: 0.0401\n",
      "Epoch 36/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0388 - val_loss: 0.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0300 - val_loss: 0.7095 - val_accuracy: 0.0371\n",
      "Epoch 38/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0178 - val_loss: 0.7068 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0232 - val_loss: 0.7058 - val_accuracy: 0.0266\n",
      "Epoch 40/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0208 - val_loss: 0.7110 - val_accuracy: 0.0749\n",
      "Epoch 41/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0251 - val_loss: 0.7096 - val_accuracy: 2.3842e-04\n",
      "Epoch 42/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0321 - val_loss: 0.7102 - val_accuracy: 0.0175\n",
      "Epoch 43/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0228 - val_loss: 0.7089 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0354 - val_loss: 0.7094 - val_accuracy: 0.0194\n",
      "Epoch 45/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0351 - val_loss: 0.7093 - val_accuracy: 0.0061\n",
      "Epoch 46/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0304 - val_loss: 0.7088 - val_accuracy: 0.0224\n",
      "Epoch 47/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0375 - val_loss: 0.7096 - val_accuracy: 0.0030\n",
      "Epoch 48/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0248 - val_loss: 0.7077 - val_accuracy: 0.1395\n",
      "Epoch 49/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0303 - val_loss: 0.7102 - val_accuracy: 0.0061\n",
      "Epoch 50/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0309 - val_loss: 0.7074 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0368 - val_loss: 0.7098 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0301 - val_loss: 0.7099 - val_accuracy: 0.0092\n",
      "Epoch 53/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0405 - val_loss: 0.7084 - val_accuracy: 0.0010\n",
      "Epoch 54/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0343 - val_loss: 0.7087 - val_accuracy: 0.0192\n",
      "Epoch 55/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0252 - val_loss: 0.7095 - val_accuracy: 2.3842e-04\n",
      "Epoch 56/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0213 - val_loss: 0.7094 - val_accuracy: 0.0976\n",
      "Epoch 57/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0177 - val_loss: 0.7070 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0378 - val_loss: 0.7097 - val_accuracy: 0.0498\n",
      "Epoch 59/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0314 - val_loss: 0.7076 - val_accuracy: 0.0129\n",
      "Epoch 60/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0285 - val_loss: 0.7088 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0323 - val_loss: 0.7086 - val_accuracy: 0.0083\n",
      "Epoch 62/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0245 - val_loss: 0.7079 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0277 - val_loss: 0.7088 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0232 - val_loss: 0.7095 - val_accuracy: 0.0043\n",
      "Epoch 65/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0311 - val_loss: 0.7090 - val_accuracy: 0.2681\n",
      "Epoch 66/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0364 - val_loss: 0.7085 - val_accuracy: 0.0102\n",
      "Epoch 67/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0215 - val_loss: 0.7112 - val_accuracy: 0.2934\n",
      "Epoch 68/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0397 - val_loss: 0.7091 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0242 - val_loss: 0.7101 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0258 - val_loss: 0.7092 - val_accuracy: 0.0627\n",
      "Epoch 71/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0267 - val_loss: 0.7105 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0295 - val_loss: 0.7107 - val_accuracy: 0.0077\n",
      "Epoch 73/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0321 - val_loss: 0.7106 - val_accuracy: 0.0159\n",
      "Epoch 74/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0291 - val_loss: 0.7097 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0225 - val_loss: 0.7078 - val_accuracy: 0.1411\n",
      "Epoch 76/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0297 - val_loss: 0.7104 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0249 - val_loss: 0.7109 - val_accuracy: 0.0443\n",
      "Epoch 78/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0291 - val_loss: 0.7085 - val_accuracy: 0.0838\n",
      "Epoch 79/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0395 - val_loss: 0.7122 - val_accuracy: 0.0764\n",
      "Epoch 80/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0414 - val_loss: 0.7133 - val_accuracy: 0.0344\n",
      "Epoch 81/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0319 - val_loss: 0.7099 - val_accuracy: 0.0388\n",
      "Epoch 82/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0260 - val_loss: 0.7091 - val_accuracy: 0.0086\n",
      "Epoch 83/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0314 - val_loss: 0.7099 - val_accuracy: 0.0026\n",
      "Epoch 84/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0304 - val_loss: 0.7099 - val_accuracy: 0.0073\n",
      "Epoch 85/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0340 - val_loss: 0.7086 - val_accuracy: 0.0012\n",
      "Epoch 86/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0285 - val_loss: 0.7088 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0296 - val_loss: 0.7103 - val_accuracy: 0.0029\n",
      "Epoch 88/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0264 - val_loss: 0.7087 - val_accuracy: 0.1136\n",
      "Epoch 89/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0224 - val_loss: 0.7088 - val_accuracy: 0.0174\n",
      "Epoch 90/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0301 - val_loss: 0.7081 - val_accuracy: 0.0067\n",
      "Epoch 91/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0305 - val_loss: 0.7098 - val_accuracy: 0.0153\n",
      "Epoch 92/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0225 - val_loss: 0.7082 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0230 - val_loss: 0.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0252 - val_loss: 0.7079 - val_accuracy: 0.0235\n",
      "Epoch 95/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0298 - val_loss: 0.7103 - val_accuracy: 2.1458e-04\n",
      "Epoch 96/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0321 - val_loss: 0.7093 - val_accuracy: 0.0350\n",
      "Epoch 97/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0265 - val_loss: 0.7065 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0317 - val_loss: 0.7099 - val_accuracy: 0.0094\n",
      "Epoch 99/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0241 - val_loss: 0.7081 - val_accuracy: 0.0153\n",
      "Epoch 100/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0297 - val_loss: 0.7088 - val_accuracy: 0.0628\n",
      "Epoch 101/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0225 - val_loss: 0.7105 - val_accuracy: 0.0183\n",
      "Epoch 102/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0281 - val_loss: 0.7085 - val_accuracy: 0.0255\n",
      "Epoch 103/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0403 - val_loss: 0.7067 - val_accuracy: 0.0495\n",
      "Epoch 104/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0340 - val_loss: 0.7080 - val_accuracy: 0.0377\n",
      "Epoch 105/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0259 - val_loss: 0.7093 - val_accuracy: 0.0627\n",
      "Epoch 106/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0307 - val_loss: 0.7095 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0190 - val_loss: 0.7087 - val_accuracy: 0.0024\n",
      "Epoch 108/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0243 - val_loss: 0.7095 - val_accuracy: 0.2554\n",
      "Epoch 109/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0260 - val_loss: 0.7080 - val_accuracy: 0.0027\n",
      "Epoch 110/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0212 - val_loss: 0.7092 - val_accuracy: 0.0091\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0255 - val_loss: 0.7101 - val_accuracy: 0.0031\n",
      "Epoch 112/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0184 - val_loss: 0.7093 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0384 - val_loss: 0.7099 - val_accuracy: 0.2502\n",
      "Epoch 114/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0239 - val_loss: 0.7079 - val_accuracy: 0.0290\n",
      "Epoch 115/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0334 - val_loss: 0.7087 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0270 - val_loss: 0.7113 - val_accuracy: 0.0403\n",
      "Epoch 117/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0256 - val_loss: 0.7093 - val_accuracy: 0.0232\n",
      "Epoch 118/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0451 - val_loss: 0.7102 - val_accuracy: 0.0621\n",
      "Epoch 119/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0403 - val_loss: 0.7075 - val_accuracy: 0.0051\n",
      "Epoch 120/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0248 - val_loss: 0.7108 - val_accuracy: 0.1029\n",
      "Epoch 121/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0369 - val_loss: 0.7091 - val_accuracy: 0.0051\n",
      "Epoch 122/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0257 - val_loss: 0.7080 - val_accuracy: 0.0511\n",
      "Epoch 123/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0285 - val_loss: 0.7105 - val_accuracy: 3.0994e-04\n",
      "Epoch 124/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0342 - val_loss: 0.7097 - val_accuracy: 0.0024\n",
      "Epoch 125/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0294 - val_loss: 0.7093 - val_accuracy: 0.0037\n",
      "Epoch 126/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0421 - val_loss: 0.7092 - val_accuracy: 0.0823\n",
      "Epoch 127/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0302 - val_loss: 0.7094 - val_accuracy: 0.0307\n",
      "Epoch 128/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0313 - val_loss: 0.7096 - val_accuracy: 0.1694\n",
      "Epoch 129/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0225 - val_loss: 0.7093 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0272 - val_loss: 0.7083 - val_accuracy: 0.0174\n",
      "Epoch 131/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0318 - val_loss: 0.7111 - val_accuracy: 0.1082\n",
      "Epoch 132/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0363 - val_loss: 0.7091 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0266 - val_loss: 0.7088 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0250 - val_loss: 0.7082 - val_accuracy: 0.0172\n",
      "Epoch 135/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0441 - val_loss: 0.7104 - val_accuracy: 0.0021\n",
      "Epoch 136/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0342 - val_loss: 0.7101 - val_accuracy: 0.0188\n",
      "Epoch 137/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0304 - val_loss: 0.7077 - val_accuracy: 0.0173\n",
      "Epoch 138/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0262 - val_loss: 0.7098 - val_accuracy: 0.0238\n",
      "Epoch 139/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0283 - val_loss: 0.7113 - val_accuracy: 0.0629\n",
      "Epoch 140/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0341 - val_loss: 0.7086 - val_accuracy: 0.0746\n",
      "Epoch 141/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0317 - val_loss: 0.7090 - val_accuracy: 0.0521\n",
      "Epoch 142/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0270 - val_loss: 0.7088 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0273 - val_loss: 0.7097 - val_accuracy: 0.0497\n",
      "Epoch 144/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0281 - val_loss: 0.7108 - val_accuracy: 0.0049\n",
      "Epoch 145/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0267 - val_loss: 0.7093 - val_accuracy: 0.0477\n",
      "Epoch 146/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0233 - val_loss: 0.7085 - val_accuracy: 0.0198\n",
      "Epoch 147/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0274 - val_loss: 0.7087 - val_accuracy: 0.0205\n",
      "Epoch 148/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0283 - val_loss: 0.7075 - val_accuracy: 0.0134\n",
      "Epoch 149/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0233 - val_loss: 0.7090 - val_accuracy: 0.0241\n",
      "Epoch 150/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0203 - val_loss: 0.7100 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0256 - val_loss: 0.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0226 - val_loss: 0.7091 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0326 - val_loss: 0.7083 - val_accuracy: 0.0645\n",
      "Epoch 154/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0233 - val_loss: 0.7111 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0284 - val_loss: 0.7094 - val_accuracy: 0.0225\n",
      "Epoch 156/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0355 - val_loss: 0.7101 - val_accuracy: 0.0113\n",
      "Epoch 157/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0226 - val_loss: 0.7086 - val_accuracy: 0.0724\n",
      "Epoch 158/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0282 - val_loss: 0.7092 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0414 - val_loss: 0.7104 - val_accuracy: 0.0059\n",
      "Epoch 160/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0333 - val_loss: 0.7086 - val_accuracy: 0.0067\n",
      "Epoch 161/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0365 - val_loss: 0.7077 - val_accuracy: 0.0661\n",
      "Epoch 162/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0259 - val_loss: 0.7070 - val_accuracy: 0.0757\n",
      "Epoch 163/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0281 - val_loss: 0.7095 - val_accuracy: 0.0498\n",
      "Epoch 164/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0261 - val_loss: 0.7102 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0221 - val_loss: 0.7077 - val_accuracy: 0.0539\n",
      "Epoch 166/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0290 - val_loss: 0.7082 - val_accuracy: 0.0021\n",
      "Epoch 167/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0253 - val_loss: 0.7075 - val_accuracy: 0.0020\n",
      "Epoch 168/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0280 - val_loss: 0.7096 - val_accuracy: 0.0048\n",
      "Epoch 169/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0245 - val_loss: 0.7088 - val_accuracy: 0.0229\n",
      "Epoch 170/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0387 - val_loss: 0.7062 - val_accuracy: 0.0111\n",
      "Epoch 171/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0355 - val_loss: 0.7089 - val_accuracy: 0.0063\n",
      "Epoch 172/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0216 - val_loss: 0.7083 - val_accuracy: 0.0495\n",
      "Epoch 173/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0363 - val_loss: 0.7086 - val_accuracy: 8.8215e-04\n",
      "Epoch 174/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0242 - val_loss: 0.7093 - val_accuracy: 2.8610e-04\n",
      "Epoch 175/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0342 - val_loss: 0.7097 - val_accuracy: 0.0077\n",
      "Epoch 176/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0260 - val_loss: 0.7105 - val_accuracy: 0.0522\n",
      "Epoch 177/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0273 - val_loss: 0.7120 - val_accuracy: 7.1526e-04\n",
      "Epoch 178/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0260 - val_loss: 0.7064 - val_accuracy: 0.0624\n",
      "Epoch 179/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0238 - val_loss: 0.7068 - val_accuracy: 0.0369\n",
      "Epoch 180/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0415 - val_loss: 0.7101 - val_accuracy: 0.0096\n",
      "Epoch 181/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0297 - val_loss: 0.7101 - val_accuracy: 0.0049\n",
      "Epoch 182/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0326 - val_loss: 0.7094 - val_accuracy: 0.0075\n",
      "Epoch 183/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0297 - val_loss: 0.7114 - val_accuracy: 0.1140\n",
      "Epoch 184/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0305 - val_loss: 0.7094 - val_accuracy: 0.0147\n",
      "Epoch 185/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0275 - val_loss: 0.7093 - val_accuracy: 0.1486\n",
      "Epoch 186/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0299 - val_loss: 0.7091 - val_accuracy: 0.1576\n",
      "Epoch 187/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0284 - val_loss: 0.7095 - val_accuracy: 0.0239\n",
      "Epoch 188/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0365 - val_loss: 0.7091 - val_accuracy: 0.0219\n",
      "Epoch 189/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0323 - val_loss: 0.7108 - val_accuracy: 0.0948\n",
      "Epoch 190/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0289 - val_loss: 0.7091 - val_accuracy: 0.0619\n",
      "Epoch 191/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0276 - val_loss: 0.7083 - val_accuracy: 0.0018\n",
      "Epoch 192/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0312 - val_loss: 0.7091 - val_accuracy: 0.0337\n",
      "Epoch 193/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0264 - val_loss: 0.7092 - val_accuracy: 0.0801\n",
      "Epoch 194/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0271 - val_loss: 0.7067 - val_accuracy: 0.0200\n",
      "Epoch 195/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0224 - val_loss: 0.7095 - val_accuracy: 0.0023\n",
      "Epoch 196/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0401 - val_loss: 0.7095 - val_accuracy: 0.1566\n",
      "Epoch 197/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0291 - val_loss: 0.7094 - val_accuracy: 0.2839\n",
      "Epoch 198/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0437 - val_loss: 0.7087 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0233 - val_loss: 0.7098 - val_accuracy: 0.0483\n",
      "Epoch 200/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0357 - val_loss: 0.7094 - val_accuracy: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:109: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_test = np.asarray(inputs_test).astype(np.int) #CHANGE (added)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  targets[test] = np.asarray(targets[test]).astype(np.int) #CHANGE (added)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:136: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "  tprs.append(interp(mean_fpr, fpr, tpr))\n",
      "C:\\Users\\User\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:806: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:99: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_train = np.asarray(inputs_train).astype(np.int) #CHANGE (added)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:100: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  targets[train] = np.asarray(targets[train]).astype(np.int) #CHANGE (added)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5243/5243 [==============================] - 24s 4ms/step - loss: 0.6549 - accuracy: 0.0841 - val_loss: 0.6957 - val_accuracy: 0.0028\n",
      "Epoch 2/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6523 - accuracy: 0.0431 - val_loss: 0.7084 - val_accuracy: 0.0149\n",
      "Epoch 3/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6517 - accuracy: 0.0380 - val_loss: 0.7091 - val_accuracy: 0.2974\n",
      "Epoch 4/200\n",
      "5243/5243 [==============================] - 20s 4ms/step - loss: 0.6514 - accuracy: 0.0294 - val_loss: 0.7077 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "5243/5243 [==============================] - 20s 4ms/step - loss: 0.6513 - accuracy: 0.0307 - val_loss: 0.7061 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "5243/5243 [==============================] - 23s 4ms/step - loss: 0.6513 - accuracy: 0.0303 - val_loss: 0.7112 - val_accuracy: 0.0349\n",
      "Epoch 7/200\n",
      "5243/5243 [==============================] - 22s 4ms/step - loss: 0.6513 - accuracy: 0.0307 - val_loss: 0.7119 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6512 - accuracy: 0.0267 - val_loss: 0.7084 - val_accuracy: 0.0019\n",
      "Epoch 9/200\n",
      "5243/5243 [==============================] - 20s 4ms/step - loss: 0.6512 - accuracy: 0.0304 - val_loss: 0.7078 - val_accuracy: 0.2099\n",
      "Epoch 10/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6512 - accuracy: 0.0301 - val_loss: 0.7083 - val_accuracy: 0.0188\n",
      "Epoch 11/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0377 - val_loss: 0.7114 - val_accuracy: 0.0388\n",
      "Epoch 12/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0310 - val_loss: 0.7074 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0232 - val_loss: 0.7098 - val_accuracy: 0.2382\n",
      "Epoch 14/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0247 - val_loss: 0.7085 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0237 - val_loss: 0.7118 - val_accuracy: 0.0182\n",
      "Epoch 16/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0272 - val_loss: 0.7101 - val_accuracy: 0.0188\n",
      "Epoch 17/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0379 - val_loss: 0.7118 - val_accuracy: 0.0208\n",
      "Epoch 18/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0373 - val_loss: 0.7076 - val_accuracy: 0.1170\n",
      "Epoch 19/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0358 - val_loss: 0.7103 - val_accuracy: 0.3054\n",
      "Epoch 20/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0317 - val_loss: 0.7101 - val_accuracy: 0.0094\n",
      "Epoch 21/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0250 - val_loss: 0.7100 - val_accuracy: 0.0489\n",
      "Epoch 22/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0371 - val_loss: 0.7116 - val_accuracy: 0.0793\n",
      "Epoch 23/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0278 - val_loss: 0.7085 - val_accuracy: 0.0384\n",
      "Epoch 24/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0243 - val_loss: 0.7090 - val_accuracy: 0.0054\n",
      "Epoch 25/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0265 - val_loss: 0.7120 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0285 - val_loss: 0.7111 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0346 - val_loss: 0.7082 - val_accuracy: 0.1563\n",
      "Epoch 28/200\n",
      "5243/5243 [==============================] - 18s 4ms/step - loss: 0.6511 - accuracy: 0.0229 - val_loss: 0.7120 - val_accuracy: 0.0609\n",
      "Epoch 29/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0212 - val_loss: 0.7118 - val_accuracy: 0.2055\n",
      "Epoch 30/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0292 - val_loss: 0.7081 - val_accuracy: 0.0642\n",
      "Epoch 31/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0216 - val_loss: 0.7096 - val_accuracy: 0.0182\n",
      "Epoch 32/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0232 - val_loss: 0.7121 - val_accuracy: 0.0317\n",
      "Epoch 33/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0345 - val_loss: 0.7101 - val_accuracy: 0.0201\n",
      "Epoch 34/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0227 - val_loss: 0.7069 - val_accuracy: 0.0773\n",
      "Epoch 35/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0276 - val_loss: 0.7111 - val_accuracy: 0.0546\n",
      "Epoch 36/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0294 - val_loss: 0.7115 - val_accuracy: 0.0384\n",
      "Epoch 37/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0306 - val_loss: 0.7105 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0317 - val_loss: 0.7077 - val_accuracy: 0.0337\n",
      "Epoch 39/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0293 - val_loss: 0.7075 - val_accuracy: 0.0043\n",
      "Epoch 40/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0374 - val_loss: 0.7104 - val_accuracy: 0.0060\n",
      "Epoch 41/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0221 - val_loss: 0.7083 - val_accuracy: 0.0705\n",
      "Epoch 42/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0228 - val_loss: 0.7115 - val_accuracy: 0.0119\n",
      "Epoch 43/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0295 - val_loss: 0.7113 - val_accuracy: 0.0300\n",
      "Epoch 44/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0325 - val_loss: 0.7095 - val_accuracy: 0.0400\n",
      "Epoch 45/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0228 - val_loss: 0.7123 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0318 - val_loss: 0.7072 - val_accuracy: 0.0505\n",
      "Epoch 47/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0238 - val_loss: 0.7086 - val_accuracy: 0.0940\n",
      "Epoch 48/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0343 - val_loss: 0.7096 - val_accuracy: 0.0060\n",
      "Epoch 49/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0267 - val_loss: 0.7089 - val_accuracy: 0.2857\n",
      "Epoch 50/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0295 - val_loss: 0.7080 - val_accuracy: 0.0140\n",
      "Epoch 51/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0286 - val_loss: 0.7113 - val_accuracy: 0.0206\n",
      "Epoch 52/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0346 - val_loss: 0.7081 - val_accuracy: 0.0038\n",
      "Epoch 53/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0299 - val_loss: 0.7118 - val_accuracy: 0.0187\n",
      "Epoch 54/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0238 - val_loss: 0.7101 - val_accuracy: 0.0877\n",
      "Epoch 55/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0401 - val_loss: 0.7079 - val_accuracy: 0.0028\n",
      "Epoch 56/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0226 - val_loss: 0.7082 - val_accuracy: 0.0089\n",
      "Epoch 57/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0322 - val_loss: 0.7090 - val_accuracy: 0.1489\n",
      "Epoch 58/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0347 - val_loss: 0.7107 - val_accuracy: 0.0028\n",
      "Epoch 59/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0254 - val_loss: 0.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0214 - val_loss: 0.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0266 - val_loss: 0.7109 - val_accuracy: 0.0617\n",
      "Epoch 62/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0313 - val_loss: 0.7095 - val_accuracy: 0.0062\n",
      "Epoch 63/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0269 - val_loss: 0.7063 - val_accuracy: 0.0241\n",
      "Epoch 64/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0261 - val_loss: 0.7106 - val_accuracy: 0.0739\n",
      "Epoch 65/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0298 - val_loss: 0.7088 - val_accuracy: 0.0126\n",
      "Epoch 66/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0243 - val_loss: 0.7111 - val_accuracy: 0.0176\n",
      "Epoch 67/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0252 - val_loss: 0.7102 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0239 - val_loss: 0.7101 - val_accuracy: 0.0321\n",
      "Epoch 69/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0286 - val_loss: 0.7109 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0259 - val_loss: 0.7086 - val_accuracy: 0.0172\n",
      "Epoch 71/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0371 - val_loss: 0.7085 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0283 - val_loss: 0.7104 - val_accuracy: 0.0054\n",
      "Epoch 73/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0266 - val_loss: 0.7068 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0270 - val_loss: 0.7072 - val_accuracy: 0.2691\n",
      "Epoch 75/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0380 - val_loss: 0.7085 - val_accuracy: 0.0495\n",
      "Epoch 76/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0227 - val_loss: 0.7092 - val_accuracy: 0.0132\n",
      "Epoch 77/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0305 - val_loss: 0.7086 - val_accuracy: 0.0266\n",
      "Epoch 78/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0282 - val_loss: 0.7103 - val_accuracy: 0.0349\n",
      "Epoch 79/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0372 - val_loss: 0.7083 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0345 - val_loss: 0.7080 - val_accuracy: 0.0400\n",
      "Epoch 81/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0287 - val_loss: 0.7083 - val_accuracy: 0.0937\n",
      "Epoch 82/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0367 - val_loss: 0.7090 - val_accuracy: 0.0443\n",
      "Epoch 83/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0320 - val_loss: 0.7098 - val_accuracy: 0.0370\n",
      "Epoch 84/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0290 - val_loss: 0.7105 - val_accuracy: 0.0014\n",
      "Epoch 85/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0240 - val_loss: 0.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0190 - val_loss: 0.7077 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0374 - val_loss: 0.7091 - val_accuracy: 0.0028\n",
      "Epoch 88/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0229 - val_loss: 0.7081 - val_accuracy: 0.0514\n",
      "Epoch 89/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0318 - val_loss: 0.7089 - val_accuracy: 0.0050\n",
      "Epoch 90/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0292 - val_loss: 0.7097 - val_accuracy: 0.0146\n",
      "Epoch 91/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0244 - val_loss: 0.7081 - val_accuracy: 0.0497\n",
      "Epoch 92/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0269 - val_loss: 0.7108 - val_accuracy: 0.0299\n",
      "Epoch 93/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0303 - val_loss: 0.7109 - val_accuracy: 0.0155\n",
      "Epoch 94/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0333 - val_loss: 0.7083 - val_accuracy: 0.0081\n",
      "Epoch 95/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0265 - val_loss: 0.7115 - val_accuracy: 0.1076\n",
      "Epoch 96/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0281 - val_loss: 0.7121 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0312 - val_loss: 0.7068 - val_accuracy: 0.0196\n",
      "Epoch 98/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0244 - val_loss: 0.7109 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0262 - val_loss: 0.7084 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0257 - val_loss: 0.7096 - val_accuracy: 4.7684e-04\n",
      "Epoch 101/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0285 - val_loss: 0.7091 - val_accuracy: 0.0051\n",
      "Epoch 102/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0253 - val_loss: 0.7089 - val_accuracy: 0.0379\n",
      "Epoch 103/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0302 - val_loss: 0.7101 - val_accuracy: 0.1041\n",
      "Epoch 104/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0225 - val_loss: 0.7087 - val_accuracy: 0.0206\n",
      "Epoch 105/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0232 - val_loss: 0.7096 - val_accuracy: 0.0063\n",
      "Epoch 106/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0328 - val_loss: 0.7093 - val_accuracy: 0.0320\n",
      "Epoch 107/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0422 - val_loss: 0.7100 - val_accuracy: 9.5368e-04\n",
      "Epoch 108/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0288 - val_loss: 0.7105 - val_accuracy: 0.0211\n",
      "Epoch 109/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0240 - val_loss: 0.7086 - val_accuracy: 0.0411\n",
      "Epoch 110/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0353 - val_loss: 0.7091 - val_accuracy: 0.0602\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0180 - val_loss: 0.7073 - val_accuracy: 0.0167\n",
      "Epoch 112/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0271 - val_loss: 0.7115 - val_accuracy: 7.1526e-04\n",
      "Epoch 113/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0260 - val_loss: 0.7079 - val_accuracy: 0.1458\n",
      "Epoch 114/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0231 - val_loss: 0.7094 - val_accuracy: 0.0011\n",
      "Epoch 115/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0239 - val_loss: 0.7101 - val_accuracy: 0.0320\n",
      "Epoch 116/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0296 - val_loss: 0.7116 - val_accuracy: 0.0353\n",
      "Epoch 117/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0314 - val_loss: 0.7092 - val_accuracy: 0.0428\n",
      "Epoch 118/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0222 - val_loss: 0.7115 - val_accuracy: 0.0323\n",
      "Epoch 119/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0450 - val_loss: 0.7118 - val_accuracy: 0.0024\n",
      "Epoch 120/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0227 - val_loss: 0.7088 - val_accuracy: 0.0244\n",
      "Epoch 121/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0179 - val_loss: 0.7096 - val_accuracy: 0.0183\n",
      "Epoch 122/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0273 - val_loss: 0.7096 - val_accuracy: 0.0332\n",
      "Epoch 123/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0285 - val_loss: 0.7074 - val_accuracy: 0.0217\n",
      "Epoch 124/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0239 - val_loss: 0.7077 - val_accuracy: 0.1676\n",
      "Epoch 125/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0302 - val_loss: 0.7116 - val_accuracy: 0.0039\n",
      "Epoch 126/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0273 - val_loss: 0.7089 - val_accuracy: 0.0209\n",
      "Epoch 127/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0332 - val_loss: 0.7072 - val_accuracy: 0.1033\n",
      "Epoch 128/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0235 - val_loss: 0.7093 - val_accuracy: 0.1392\n",
      "Epoch 129/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0287 - val_loss: 0.7083 - val_accuracy: 0.0148\n",
      "Epoch 130/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0278 - val_loss: 0.7085 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0344 - val_loss: 0.7094 - val_accuracy: 0.0541\n",
      "Epoch 132/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0326 - val_loss: 0.7104 - val_accuracy: 0.2831\n",
      "Epoch 133/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0343 - val_loss: 0.7088 - val_accuracy: 0.0066\n",
      "Epoch 134/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0334 - val_loss: 0.7107 - val_accuracy: 0.0479\n",
      "Epoch 135/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0291 - val_loss: 0.7089 - val_accuracy: 0.0044\n",
      "Epoch 136/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0369 - val_loss: 0.7098 - val_accuracy: 0.0240\n",
      "Epoch 137/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0212 - val_loss: 0.7113 - val_accuracy: 0.1065\n",
      "Epoch 138/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0330 - val_loss: 0.7097 - val_accuracy: 0.0033\n",
      "Epoch 139/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0256 - val_loss: 0.7111 - val_accuracy: 0.0473\n",
      "Epoch 140/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0254 - val_loss: 0.7096 - val_accuracy: 3.0994e-04\n",
      "Epoch 141/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0198 - val_loss: 0.7110 - val_accuracy: 0.0410\n",
      "Epoch 142/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0277 - val_loss: 0.7081 - val_accuracy: 0.0408\n",
      "Epoch 143/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0262 - val_loss: 0.7085 - val_accuracy: 0.0170\n",
      "Epoch 144/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0223 - val_loss: 0.7085 - val_accuracy: 0.0302\n",
      "Epoch 145/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0285 - val_loss: 0.7095 - val_accuracy: 0.0077\n",
      "Epoch 146/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0293 - val_loss: 0.7101 - val_accuracy: 0.0626\n",
      "Epoch 147/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0304 - val_loss: 0.7098 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0245 - val_loss: 0.7098 - val_accuracy: 0.0270\n",
      "Epoch 149/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0201 - val_loss: 0.7100 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0222 - val_loss: 0.7086 - val_accuracy: 0.0036\n",
      "Epoch 151/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0235 - val_loss: 0.7078 - val_accuracy: 0.1536\n",
      "Epoch 152/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0202 - val_loss: 0.7084 - val_accuracy: 6.6757e-04\n",
      "Epoch 153/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0294 - val_loss: 0.7087 - val_accuracy: 0.1323\n",
      "Epoch 154/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0335 - val_loss: 0.7106 - val_accuracy: 0.0028\n",
      "Epoch 155/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0265 - val_loss: 0.7087 - val_accuracy: 0.0219\n",
      "Epoch 156/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0280 - val_loss: 0.7103 - val_accuracy: 0.0099\n",
      "Epoch 157/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0275 - val_loss: 0.7082 - val_accuracy: 0.0812\n",
      "Epoch 158/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0306 - val_loss: 0.7093 - val_accuracy: 0.0116\n",
      "Epoch 159/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0214 - val_loss: 0.7105 - val_accuracy: 0.0016\n",
      "Epoch 160/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0274 - val_loss: 0.7076 - val_accuracy: 0.1021\n",
      "Epoch 161/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0182 - val_loss: 0.7078 - val_accuracy: 0.0141\n",
      "Epoch 162/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0293 - val_loss: 0.7088 - val_accuracy: 0.0052\n",
      "Epoch 163/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0201 - val_loss: 0.7089 - val_accuracy: 0.0935\n",
      "Epoch 164/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0253 - val_loss: 0.7101 - val_accuracy: 0.0366\n",
      "Epoch 165/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0288 - val_loss: 0.7099 - val_accuracy: 0.2005\n",
      "Epoch 166/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0403 - val_loss: 0.7095 - val_accuracy: 0.0519\n",
      "Epoch 167/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6511 - accuracy: 0.0276 - val_loss: 0.7082 - val_accuracy: 0.0442\n",
      "Epoch 168/200\n",
      "5243/5243 [==============================] - 13s 3ms/step - loss: 0.6510 - accuracy: 0.0219 - val_loss: 0.7094 - val_accuracy: 0.0753\n",
      "Epoch 169/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0222 - val_loss: 0.7121 - val_accuracy: 0.0089\n",
      "Epoch 170/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0282 - val_loss: 0.7101 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0297 - val_loss: 0.7099 - val_accuracy: 0.0282\n",
      "Epoch 172/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0264 - val_loss: 0.7100 - val_accuracy: 0.0933\n",
      "Epoch 173/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0254 - val_loss: 0.7093 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0238 - val_loss: 0.7112 - val_accuracy: 0.1539\n",
      "Epoch 175/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0341 - val_loss: 0.7102 - val_accuracy: 0.0128\n",
      "Epoch 176/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0272 - val_loss: 0.7088 - val_accuracy: 0.0093\n",
      "Epoch 177/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0184 - val_loss: 0.7091 - val_accuracy: 0.0219\n",
      "Epoch 178/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6510 - accuracy: 0.0231 - val_loss: 0.7083 - val_accuracy: 0.0371\n",
      "Epoch 179/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0242 - val_loss: 0.7098 - val_accuracy: 0.0805\n",
      "Epoch 180/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0288 - val_loss: 0.7091 - val_accuracy: 0.0575\n",
      "Epoch 181/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0286 - val_loss: 0.7085 - val_accuracy: 2.6226e-04\n",
      "Epoch 182/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0178 - val_loss: 0.7081 - val_accuracy: 0.1319\n",
      "Epoch 183/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0367 - val_loss: 0.7091 - val_accuracy: 0.0024\n",
      "Epoch 184/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0309 - val_loss: 0.7092 - val_accuracy: 0.0039\n",
      "Epoch 185/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0248 - val_loss: 0.7088 - val_accuracy: 0.0175\n",
      "Epoch 186/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0257 - val_loss: 0.7096 - val_accuracy: 0.0116\n",
      "Epoch 187/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0270 - val_loss: 0.7089 - val_accuracy: 0.0722\n",
      "Epoch 188/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0293 - val_loss: 0.7102 - val_accuracy: 0.0077\n",
      "Epoch 189/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0315 - val_loss: 0.7100 - val_accuracy: 0.0327\n",
      "Epoch 190/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0307 - val_loss: 0.7124 - val_accuracy: 0.0062\n",
      "Epoch 191/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0251 - val_loss: 0.7095 - val_accuracy: 0.0023\n",
      "Epoch 192/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0307 - val_loss: 0.7102 - val_accuracy: 0.0408\n",
      "Epoch 193/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0355 - val_loss: 0.7108 - val_accuracy: 0.0057\n",
      "Epoch 194/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0370 - val_loss: 0.7097 - val_accuracy: 0.1364\n",
      "Epoch 195/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6510 - accuracy: 0.0374 - val_loss: 0.7108 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6510 - accuracy: 0.0223 - val_loss: 0.7070 - val_accuracy: 0.0626\n",
      "Epoch 197/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6510 - accuracy: 0.0230 - val_loss: 0.7092 - val_accuracy: 0.0024\n",
      "Epoch 198/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6510 - accuracy: 0.0287 - val_loss: 0.7110 - val_accuracy: 0.0593\n",
      "Epoch 199/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0298 - val_loss: 0.7076 - val_accuracy: 0.0244\n",
      "Epoch 200/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0240 - val_loss: 0.7104 - val_accuracy: 0.0230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:109: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_test = np.asarray(inputs_test).astype(np.int) #CHANGE (added)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  targets[test] = np.asarray(targets[test]).astype(np.int) #CHANGE (added)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:136: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "  tprs.append(interp(mean_fpr, fpr, tpr))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:99: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_train = np.asarray(inputs_train).astype(np.int) #CHANGE (added)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:100: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  targets[train] = np.asarray(targets[train]).astype(np.int) #CHANGE (added)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6550 - accuracy: 0.0295 - val_loss: 0.7008 - val_accuracy: 0.1407\n",
      "Epoch 2/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6517 - accuracy: 0.0350 - val_loss: 0.7108 - val_accuracy: 0.0760\n",
      "Epoch 3/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6515 - accuracy: 0.0304 - val_loss: 0.7093 - val_accuracy: 0.0962\n",
      "Epoch 4/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6514 - accuracy: 0.0310 - val_loss: 0.7083 - val_accuracy: 0.1265\n",
      "Epoch 5/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6514 - accuracy: 0.0310 - val_loss: 0.7073 - val_accuracy: 0.0598\n",
      "Epoch 6/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6514 - accuracy: 0.0275 - val_loss: 0.7042 - val_accuracy: 0.0022\n",
      "Epoch 7/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6513 - accuracy: 0.0291 - val_loss: 0.7091 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6513 - accuracy: 0.0219 - val_loss: 0.7100 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6513 - accuracy: 0.0254 - val_loss: 0.7084 - val_accuracy: 0.0017\n",
      "Epoch 10/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6513 - accuracy: 0.0291 - val_loss: 0.7136 - val_accuracy: 0.0778\n",
      "Epoch 11/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6513 - accuracy: 0.0195 - val_loss: 0.7089 - val_accuracy: 0.0268\n",
      "Epoch 12/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6513 - accuracy: 0.0281 - val_loss: 0.7113 - val_accuracy: 0.0264\n",
      "Epoch 13/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6513 - accuracy: 0.0321 - val_loss: 0.7082 - val_accuracy: 0.0276\n",
      "Epoch 14/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6513 - accuracy: 0.0303 - val_loss: 0.7091 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0311 - val_loss: 0.7057 - val_accuracy: 0.1031\n",
      "Epoch 16/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0330 - val_loss: 0.7095 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0269 - val_loss: 0.7095 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0326 - val_loss: 0.7091 - val_accuracy: 0.2727\n",
      "Epoch 19/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0272 - val_loss: 0.7106 - val_accuracy: 0.0345\n",
      "Epoch 20/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0307 - val_loss: 0.7075 - val_accuracy: 0.0089\n",
      "Epoch 21/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0187 - val_loss: 0.7093 - val_accuracy: 0.0012\n",
      "Epoch 22/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0320 - val_loss: 0.7098 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0322 - val_loss: 0.7093 - val_accuracy: 0.0139\n",
      "Epoch 24/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0242 - val_loss: 0.7100 - val_accuracy: 2.6226e-04\n",
      "Epoch 25/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0237 - val_loss: 0.7102 - val_accuracy: 0.0257\n",
      "Epoch 26/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0256 - val_loss: 0.7110 - val_accuracy: 0.3065\n",
      "Epoch 27/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0410 - val_loss: 0.7085 - val_accuracy: 0.0193\n",
      "Epoch 28/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0291 - val_loss: 0.7076 - val_accuracy: 0.2261\n",
      "Epoch 29/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0182 - val_loss: 0.7085 - val_accuracy: 0.0023\n",
      "Epoch 30/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0289 - val_loss: 0.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0366 - val_loss: 0.7090 - val_accuracy: 0.0011\n",
      "Epoch 32/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0204 - val_loss: 0.7088 - val_accuracy: 0.0013\n",
      "Epoch 33/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0280 - val_loss: 0.7106 - val_accuracy: 4.5300e-04\n",
      "Epoch 34/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0227 - val_loss: 0.7096 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0343 - val_loss: 0.7082 - val_accuracy: 0.0025\n",
      "Epoch 36/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0305 - val_loss: 0.7083 - val_accuracy: 0.0098\n",
      "Epoch 37/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0302 - val_loss: 0.7106 - val_accuracy: 0.1258\n",
      "Epoch 38/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0311 - val_loss: 0.7091 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0301 - val_loss: 0.7085 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6512 - accuracy: 0.0358 - val_loss: 0.7092 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0297 - val_loss: 0.7054 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0280 - val_loss: 0.7112 - val_accuracy: 0.1253\n",
      "Epoch 43/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0387 - val_loss: 0.7064 - val_accuracy: 2.3842e-05\n",
      "Epoch 44/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0257 - val_loss: 0.7094 - val_accuracy: 0.0616\n",
      "Epoch 45/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0269 - val_loss: 0.7089 - val_accuracy: 0.0431\n",
      "Epoch 46/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0280 - val_loss: 0.7090 - val_accuracy: 0.2335\n",
      "Epoch 47/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0323 - val_loss: 0.7090 - val_accuracy: 0.0047\n",
      "Epoch 48/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0282 - val_loss: 0.7085 - val_accuracy: 0.0176\n",
      "Epoch 49/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0215 - val_loss: 0.7112 - val_accuracy: 0.0731\n",
      "Epoch 50/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0315 - val_loss: 0.7070 - val_accuracy: 0.0049\n",
      "Epoch 51/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0219 - val_loss: 0.7105 - val_accuracy: 0.0187\n",
      "Epoch 52/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6512 - accuracy: 0.0245 - val_loss: 0.7089 - val_accuracy: 0.0025\n",
      "Epoch 53/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0328 - val_loss: 0.7105 - val_accuracy: 0.0268\n",
      "Epoch 54/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6512 - accuracy: 0.0329 - val_loss: 0.7089 - val_accuracy: 0.0440\n",
      "Epoch 55/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6512 - accuracy: 0.0252 - val_loss: 0.7095 - val_accuracy: 0.0030\n",
      "Epoch 56/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0273 - val_loss: 0.7095 - val_accuracy: 4.7684e-05\n",
      "Epoch 57/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0273 - val_loss: 0.7102 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0207 - val_loss: 0.7071 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0235 - val_loss: 0.7099 - val_accuracy: 0.0316\n",
      "Epoch 60/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0273 - val_loss: 0.7085 - val_accuracy: 0.0216\n",
      "Epoch 61/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6512 - accuracy: 0.0318 - val_loss: 0.7078 - val_accuracy: 0.0198\n",
      "Epoch 62/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0259 - val_loss: 0.7096 - val_accuracy: 0.0540\n",
      "Epoch 63/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6512 - accuracy: 0.0332 - val_loss: 0.7072 - val_accuracy: 0.0060\n",
      "Epoch 64/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0248 - val_loss: 0.7077 - val_accuracy: 0.0012\n",
      "Epoch 65/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0338 - val_loss: 0.7072 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6512 - accuracy: 0.0288 - val_loss: 0.7083 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6512 - accuracy: 0.0264 - val_loss: 0.7084 - val_accuracy: 0.0087\n",
      "Epoch 68/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6512 - accuracy: 0.0224 - val_loss: 0.7075 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "5243/5243 [==============================] - 19s 4ms/step - loss: 0.6512 - accuracy: 0.0194 - val_loss: 0.7099 - val_accuracy: 7.1526e-05\n",
      "Epoch 70/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0305 - val_loss: 0.7084 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6512 - accuracy: 0.0282 - val_loss: 0.7092 - val_accuracy: 0.0198\n",
      "Epoch 72/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0321 - val_loss: 0.7068 - val_accuracy: 0.0617\n",
      "Epoch 73/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0347 - val_loss: 0.7085 - val_accuracy: 3.5763e-04\n",
      "Epoch 74/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6512 - accuracy: 0.0304 - val_loss: 0.7085 - val_accuracy: 0.1549\n",
      "Epoch 75/200\n",
      "5243/5243 [==============================] - 23s 4ms/step - loss: 0.6512 - accuracy: 0.0258 - val_loss: 0.7091 - val_accuracy: 0.0662\n",
      "Epoch 76/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6512 - accuracy: 0.0282 - val_loss: 0.7085 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6512 - accuracy: 0.0334 - val_loss: 0.7077 - val_accuracy: 0.0356\n",
      "Epoch 78/200\n",
      "5243/5243 [==============================] - 18s 4ms/step - loss: 0.6512 - accuracy: 0.0218 - val_loss: 0.7091 - val_accuracy: 0.0049\n",
      "Epoch 79/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6512 - accuracy: 0.0195 - val_loss: 0.7074 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6512 - accuracy: 0.0298 - val_loss: 0.7091 - val_accuracy: 0.0015\n",
      "Epoch 81/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6512 - accuracy: 0.0249 - val_loss: 0.7080 - val_accuracy: 0.0184\n",
      "Epoch 82/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6512 - accuracy: 0.0306 - val_loss: 0.7100 - val_accuracy: 0.0073\n",
      "Epoch 83/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6512 - accuracy: 0.0276 - val_loss: 0.7084 - val_accuracy: 0.3066\n",
      "Epoch 84/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6512 - accuracy: 0.0310 - val_loss: 0.7067 - val_accuracy: 0.0362\n",
      "Epoch 85/200\n",
      "5243/5243 [==============================] - 21s 4ms/step - loss: 0.6511 - accuracy: 0.0260 - val_loss: 0.7090 - val_accuracy: 0.0027\n",
      "Epoch 86/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6512 - accuracy: 0.0279 - val_loss: 0.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6512 - accuracy: 0.0198 - val_loss: 0.7083 - val_accuracy: 0.0092\n",
      "Epoch 88/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6512 - accuracy: 0.0311 - val_loss: 0.7072 - val_accuracy: 0.1409\n",
      "Epoch 89/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6512 - accuracy: 0.0338 - val_loss: 0.7082 - val_accuracy: 0.1855\n",
      "Epoch 90/200\n",
      "5243/5243 [==============================] - 18s 4ms/step - loss: 0.6511 - accuracy: 0.0241 - val_loss: 0.7070 - val_accuracy: 0.0196\n",
      "Epoch 91/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6512 - accuracy: 0.0262 - val_loss: 0.7099 - val_accuracy: 0.0046\n",
      "Epoch 92/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0257 - val_loss: 0.7095 - val_accuracy: 0.0303\n",
      "Epoch 93/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6512 - accuracy: 0.0312 - val_loss: 0.7077 - val_accuracy: 0.0324\n",
      "Epoch 94/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6512 - accuracy: 0.0240 - val_loss: 0.7102 - val_accuracy: 0.0237\n",
      "Epoch 95/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0254 - val_loss: 0.7092 - val_accuracy: 0.0515\n",
      "Epoch 96/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0356 - val_loss: 0.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0286 - val_loss: 0.7102 - val_accuracy: 0.1863\n",
      "Epoch 98/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0301 - val_loss: 0.7098 - val_accuracy: 0.0282\n",
      "Epoch 99/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0333 - val_loss: 0.7092 - val_accuracy: 0.0390\n",
      "Epoch 100/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0225 - val_loss: 0.7079 - val_accuracy: 0.0055\n",
      "Epoch 101/200\n",
      "5243/5243 [==============================] - 19s 4ms/step - loss: 0.6511 - accuracy: 0.0288 - val_loss: 0.7092 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "5243/5243 [==============================] - 19s 4ms/step - loss: 0.6512 - accuracy: 0.0262 - val_loss: 0.7103 - val_accuracy: 0.0048\n",
      "Epoch 103/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0363 - val_loss: 0.7096 - val_accuracy: 0.1457\n",
      "Epoch 104/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0222 - val_loss: 0.7084 - val_accuracy: 0.0619\n",
      "Epoch 105/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0349 - val_loss: 0.7099 - val_accuracy: 0.0562\n",
      "Epoch 106/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0225 - val_loss: 0.7094 - val_accuracy: 0.0012\n",
      "Epoch 107/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0238 - val_loss: 0.7078 - val_accuracy: 0.0628\n",
      "Epoch 108/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0195 - val_loss: 0.7092 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0328 - val_loss: 0.7092 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "5243/5243 [==============================] - 18s 4ms/step - loss: 0.6511 - accuracy: 0.0301 - val_loss: 0.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0361 - val_loss: 0.7100 - val_accuracy: 0.0155\n",
      "Epoch 112/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0234 - val_loss: 0.7091 - val_accuracy: 9.5368e-05\n",
      "Epoch 113/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0237 - val_loss: 0.7096 - val_accuracy: 0.0368\n",
      "Epoch 114/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0295 - val_loss: 0.7091 - val_accuracy: 0.0887\n",
      "Epoch 115/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0272 - val_loss: 0.7075 - val_accuracy: 0.0386\n",
      "Epoch 116/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0286 - val_loss: 0.7072 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0291 - val_loss: 0.7087 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0387 - val_loss: 0.7070 - val_accuracy: 0.0145\n",
      "Epoch 119/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0314 - val_loss: 0.7085 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0288 - val_loss: 0.7081 - val_accuracy: 0.0977\n",
      "Epoch 121/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0238 - val_loss: 0.7088 - val_accuracy: 0.1230\n",
      "Epoch 122/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0258 - val_loss: 0.7079 - val_accuracy: 9.5368e-05\n",
      "Epoch 123/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0302 - val_loss: 0.7076 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0256 - val_loss: 0.7078 - val_accuracy: 0.0104\n",
      "Epoch 125/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0242 - val_loss: 0.7098 - val_accuracy: 0.0131\n",
      "Epoch 126/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0217 - val_loss: 0.7099 - val_accuracy: 0.0109\n",
      "Epoch 127/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0329 - val_loss: 0.7093 - val_accuracy: 0.0205\n",
      "Epoch 128/200\n",
      "5243/5243 [==============================] - 19s 4ms/step - loss: 0.6511 - accuracy: 0.0174 - val_loss: 0.7078 - val_accuracy: 0.0054\n",
      "Epoch 129/200\n",
      "5243/5243 [==============================] - 19s 4ms/step - loss: 0.6511 - accuracy: 0.0257 - val_loss: 0.7080 - val_accuracy: 0.0583\n",
      "Epoch 130/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0302 - val_loss: 0.7082 - val_accuracy: 0.0299\n",
      "Epoch 131/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0227 - val_loss: 0.7097 - val_accuracy: 0.0121\n",
      "Epoch 132/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0255 - val_loss: 0.7098 - val_accuracy: 0.1382\n",
      "Epoch 133/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0416 - val_loss: 0.7090 - val_accuracy: 0.1486\n",
      "Epoch 134/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0344 - val_loss: 0.7077 - val_accuracy: 0.0161\n",
      "Epoch 135/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0202 - val_loss: 0.7095 - val_accuracy: 0.0472\n",
      "Epoch 136/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0450 - val_loss: 0.7102 - val_accuracy: 0.0068\n",
      "Epoch 137/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0329 - val_loss: 0.7080 - val_accuracy: 0.0844\n",
      "Epoch 138/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0183 - val_loss: 0.7095 - val_accuracy: 0.0507\n",
      "Epoch 139/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0247 - val_loss: 0.7092 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0193 - val_loss: 0.7098 - val_accuracy: 0.0664\n",
      "Epoch 141/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0358 - val_loss: 0.7098 - val_accuracy: 0.0736\n",
      "Epoch 142/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0310 - val_loss: 0.7088 - val_accuracy: 0.0024\n",
      "Epoch 143/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0201 - val_loss: 0.7106 - val_accuracy: 0.0052\n",
      "Epoch 144/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0362 - val_loss: 0.7083 - val_accuracy: 0.0520\n",
      "Epoch 145/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0273 - val_loss: 0.7087 - val_accuracy: 0.0283\n",
      "Epoch 146/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0209 - val_loss: 0.7096 - val_accuracy: 0.0098\n",
      "Epoch 147/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0216 - val_loss: 0.7092 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0304 - val_loss: 0.7086 - val_accuracy: 0.0296\n",
      "Epoch 149/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0425 - val_loss: 0.7104 - val_accuracy: 6.9141e-04\n",
      "Epoch 150/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0369 - val_loss: 0.7099 - val_accuracy: 0.0273\n",
      "Epoch 151/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0296 - val_loss: 0.7080 - val_accuracy: 0.2295\n",
      "Epoch 152/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0386 - val_loss: 0.7094 - val_accuracy: 0.0087\n",
      "Epoch 153/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0351 - val_loss: 0.7080 - val_accuracy: 2.3842e-05\n",
      "Epoch 154/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0388 - val_loss: 0.7095 - val_accuracy: 0.0112\n",
      "Epoch 155/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0232 - val_loss: 0.7089 - val_accuracy: 0.0647\n",
      "Epoch 156/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0237 - val_loss: 0.7083 - val_accuracy: 0.0109\n",
      "Epoch 157/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0401 - val_loss: 0.7086 - val_accuracy: 0.0218\n",
      "Epoch 158/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0256 - val_loss: 0.7081 - val_accuracy: 0.0041\n",
      "Epoch 159/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0311 - val_loss: 0.7085 - val_accuracy: 0.0029\n",
      "Epoch 160/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0291 - val_loss: 0.7078 - val_accuracy: 0.0131\n",
      "Epoch 161/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0372 - val_loss: 0.7063 - val_accuracy: 0.0037\n",
      "Epoch 162/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0329 - val_loss: 0.7078 - val_accuracy: 0.2676\n",
      "Epoch 163/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0263 - val_loss: 0.7099 - val_accuracy: 0.0049\n",
      "Epoch 164/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0404 - val_loss: 0.7108 - val_accuracy: 0.0219\n",
      "Epoch 165/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0216 - val_loss: 0.7095 - val_accuracy: 0.0268\n",
      "Epoch 166/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0227 - val_loss: 0.7108 - val_accuracy: 0.0178\n",
      "Epoch 167/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0195 - val_loss: 0.7092 - val_accuracy: 4.0531e-04\n",
      "Epoch 168/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0364 - val_loss: 0.7091 - val_accuracy: 0.0125\n",
      "Epoch 169/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0294 - val_loss: 0.7103 - val_accuracy: 0.0028\n",
      "Epoch 170/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0370 - val_loss: 0.7103 - val_accuracy: 0.1455\n",
      "Epoch 171/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0238 - val_loss: 0.7096 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0228 - val_loss: 0.7099 - val_accuracy: 0.0319\n",
      "Epoch 173/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0184 - val_loss: 0.7099 - val_accuracy: 0.1032\n",
      "Epoch 174/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0310 - val_loss: 0.7090 - val_accuracy: 0.0207\n",
      "Epoch 175/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0265 - val_loss: 0.7084 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0334 - val_loss: 0.7093 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0244 - val_loss: 0.7097 - val_accuracy: 0.0298\n",
      "Epoch 178/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0425 - val_loss: 0.7073 - val_accuracy: 0.0049\n",
      "Epoch 179/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0224 - val_loss: 0.7087 - val_accuracy: 0.0027\n",
      "Epoch 180/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0258 - val_loss: 0.7080 - val_accuracy: 0.1749\n",
      "Epoch 181/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0284 - val_loss: 0.7081 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0280 - val_loss: 0.7072 - val_accuracy: 0.0068\n",
      "Epoch 183/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0319 - val_loss: 0.7103 - val_accuracy: 0.0415\n",
      "Epoch 184/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0250 - val_loss: 0.7093 - val_accuracy: 0.0422\n",
      "Epoch 185/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0246 - val_loss: 0.7093 - val_accuracy: 0.0038\n",
      "Epoch 186/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0366 - val_loss: 0.7102 - val_accuracy: 0.0052\n",
      "Epoch 187/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0221 - val_loss: 0.7097 - val_accuracy: 0.1168\n",
      "Epoch 188/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0262 - val_loss: 0.7096 - val_accuracy: 0.0053\n",
      "Epoch 189/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0333 - val_loss: 0.7090 - val_accuracy: 0.0073\n",
      "Epoch 190/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0280 - val_loss: 0.7085 - val_accuracy: 0.0125\n",
      "Epoch 191/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0380 - val_loss: 0.7082 - val_accuracy: 0.0065\n",
      "Epoch 192/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0314 - val_loss: 0.7091 - val_accuracy: 0.1023\n",
      "Epoch 193/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0319 - val_loss: 0.7100 - val_accuracy: 0.0623\n",
      "Epoch 194/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0262 - val_loss: 0.7090 - val_accuracy: 0.0293\n",
      "Epoch 195/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0303 - val_loss: 0.7096 - val_accuracy: 0.0072\n",
      "Epoch 196/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0267 - val_loss: 0.7096 - val_accuracy: 0.0428\n",
      "Epoch 197/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0327 - val_loss: 0.7076 - val_accuracy: 4.2915e-04\n",
      "Epoch 198/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0185 - val_loss: 0.7079 - val_accuracy: 0.0189\n",
      "Epoch 199/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0316 - val_loss: 0.7085 - val_accuracy: 0.2770\n",
      "Epoch 200/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0364 - val_loss: 0.7085 - val_accuracy: 0.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:109: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_test = np.asarray(inputs_test).astype(np.int) #CHANGE (added)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  targets[test] = np.asarray(targets[test]).astype(np.int) #CHANGE (added)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:136: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "  tprs.append(interp(mean_fpr, fpr, tpr))\n",
      "C:\\Users\\User\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:806: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:99: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_train = np.asarray(inputs_train).astype(np.int) #CHANGE (added)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:100: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  targets[train] = np.asarray(targets[train]).astype(np.int) #CHANGE (added)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6549 - accuracy: 0.0302 - val_loss: 0.7048 - val_accuracy: 0.0044\n",
      "Epoch 2/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6514 - accuracy: 0.0283 - val_loss: 0.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6513 - accuracy: 0.0234 - val_loss: 0.7080 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6513 - accuracy: 0.0320 - val_loss: 0.7103 - val_accuracy: 0.0026\n",
      "Epoch 5/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0254 - val_loss: 0.7092 - val_accuracy: 0.0202\n",
      "Epoch 6/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0331 - val_loss: 0.7096 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0269 - val_loss: 0.7061 - val_accuracy: 0.0022\n",
      "Epoch 8/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0313 - val_loss: 0.7106 - val_accuracy: 0.0167\n",
      "Epoch 9/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0292 - val_loss: 0.7093 - val_accuracy: 0.0388\n",
      "Epoch 10/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0279 - val_loss: 0.7113 - val_accuracy: 2.1458e-04\n",
      "Epoch 11/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0311 - val_loss: 0.7088 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0263 - val_loss: 0.7072 - val_accuracy: 0.0348\n",
      "Epoch 13/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0292 - val_loss: 0.7083 - val_accuracy: 0.0196\n",
      "Epoch 14/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0380 - val_loss: 0.7100 - val_accuracy: 0.0042\n",
      "Epoch 15/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0264 - val_loss: 0.7100 - val_accuracy: 0.2466\n",
      "Epoch 16/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0311 - val_loss: 0.7091 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0276 - val_loss: 0.7106 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0278 - val_loss: 0.7088 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0239 - val_loss: 0.7114 - val_accuracy: 0.0180\n",
      "Epoch 20/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0260 - val_loss: 0.7105 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0193 - val_loss: 0.7092 - val_accuracy: 0.0014\n",
      "Epoch 22/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0275 - val_loss: 0.7082 - val_accuracy: 0.2497\n",
      "Epoch 23/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0287 - val_loss: 0.7109 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0295 - val_loss: 0.7109 - val_accuracy: 0.3032\n",
      "Epoch 25/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0245 - val_loss: 0.7077 - val_accuracy: 0.0031\n",
      "Epoch 26/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0369 - val_loss: 0.7094 - val_accuracy: 0.1551\n",
      "Epoch 27/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0262 - val_loss: 0.7073 - val_accuracy: 3.5763e-04\n",
      "Epoch 28/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0335 - val_loss: 0.7089 - val_accuracy: 0.0113\n",
      "Epoch 29/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0301 - val_loss: 0.7097 - val_accuracy: 0.2264\n",
      "Epoch 30/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0309 - val_loss: 0.7101 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0251 - val_loss: 0.7106 - val_accuracy: 0.0192\n",
      "Epoch 32/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0277 - val_loss: 0.7111 - val_accuracy: 0.0071\n",
      "Epoch 33/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0357 - val_loss: 0.7086 - val_accuracy: 3.5763e-04\n",
      "Epoch 34/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0257 - val_loss: 0.7105 - val_accuracy: 0.0189\n",
      "Epoch 35/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0212 - val_loss: 0.7105 - val_accuracy: 0.1366\n",
      "Epoch 36/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0302 - val_loss: 0.7094 - val_accuracy: 0.0708\n",
      "Epoch 37/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0257 - val_loss: 0.7109 - val_accuracy: 0.0507\n",
      "Epoch 38/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0348 - val_loss: 0.7095 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0255 - val_loss: 0.7084 - val_accuracy: 0.0152\n",
      "Epoch 40/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0345 - val_loss: 0.7082 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0232 - val_loss: 0.7094 - val_accuracy: 0.1117\n",
      "Epoch 42/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0276 - val_loss: 0.7076 - val_accuracy: 0.0892\n",
      "Epoch 43/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0362 - val_loss: 0.7077 - val_accuracy: 0.0781\n",
      "Epoch 44/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0330 - val_loss: 0.7081 - val_accuracy: 0.0173\n",
      "Epoch 45/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0262 - val_loss: 0.7118 - val_accuracy: 0.0357\n",
      "Epoch 46/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0323 - val_loss: 0.7083 - val_accuracy: 0.1158\n",
      "Epoch 47/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0249 - val_loss: 0.7106 - val_accuracy: 0.1551\n",
      "Epoch 48/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0340 - val_loss: 0.7099 - val_accuracy: 0.0192\n",
      "Epoch 49/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0282 - val_loss: 0.7099 - val_accuracy: 0.0296\n",
      "Epoch 50/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0375 - val_loss: 0.7087 - val_accuracy: 0.0058\n",
      "Epoch 51/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0281 - val_loss: 0.7096 - val_accuracy: 0.0467\n",
      "Epoch 52/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0210 - val_loss: 0.7098 - val_accuracy: 0.0485\n",
      "Epoch 53/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0242 - val_loss: 0.7083 - val_accuracy: 0.0736\n",
      "Epoch 54/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0302 - val_loss: 0.7088 - val_accuracy: 4.7684e-05\n",
      "Epoch 55/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0312 - val_loss: 0.7099 - val_accuracy: 0.0068\n",
      "Epoch 56/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0341 - val_loss: 0.7071 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0230 - val_loss: 0.7072 - val_accuracy: 0.1342\n",
      "Epoch 58/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0299 - val_loss: 0.7104 - val_accuracy: 0.1117\n",
      "Epoch 59/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0314 - val_loss: 0.7099 - val_accuracy: 0.0036\n",
      "Epoch 60/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0294 - val_loss: 0.7071 - val_accuracy: 0.0045\n",
      "Epoch 61/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0302 - val_loss: 0.7105 - val_accuracy: 0.0176\n",
      "Epoch 62/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0298 - val_loss: 0.7094 - val_accuracy: 0.0021\n",
      "Epoch 63/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0216 - val_loss: 0.7072 - val_accuracy: 0.1101\n",
      "Epoch 64/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0279 - val_loss: 0.7095 - val_accuracy: 0.0149\n",
      "Epoch 65/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0253 - val_loss: 0.7065 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0276 - val_loss: 0.7099 - val_accuracy: 0.0130\n",
      "Epoch 67/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0261 - val_loss: 0.7102 - val_accuracy: 0.0093\n",
      "Epoch 68/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0232 - val_loss: 0.7106 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0320 - val_loss: 0.7094 - val_accuracy: 0.0187\n",
      "Epoch 70/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0238 - val_loss: 0.7077 - val_accuracy: 0.0407\n",
      "Epoch 71/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0296 - val_loss: 0.7089 - val_accuracy: 0.0067\n",
      "Epoch 72/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0269 - val_loss: 0.7095 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0341 - val_loss: 0.7094 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0275 - val_loss: 0.7100 - val_accuracy: 0.0179\n",
      "Epoch 75/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0279 - val_loss: 0.7097 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0235 - val_loss: 0.7111 - val_accuracy: 0.0585\n",
      "Epoch 77/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0390 - val_loss: 0.7123 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0244 - val_loss: 0.7122 - val_accuracy: 0.0050\n",
      "Epoch 79/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0267 - val_loss: 0.7092 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0326 - val_loss: 0.7089 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0380 - val_loss: 0.7097 - val_accuracy: 0.0306\n",
      "Epoch 82/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0216 - val_loss: 0.7086 - val_accuracy: 0.1875\n",
      "Epoch 83/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0282 - val_loss: 0.7087 - val_accuracy: 3.5763e-04\n",
      "Epoch 84/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0269 - val_loss: 0.7079 - val_accuracy: 0.0053\n",
      "Epoch 85/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0289 - val_loss: 0.7093 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0266 - val_loss: 0.7111 - val_accuracy: 0.0512\n",
      "Epoch 87/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0266 - val_loss: 0.7102 - val_accuracy: 0.0248\n",
      "Epoch 88/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0266 - val_loss: 0.7101 - val_accuracy: 0.0114\n",
      "Epoch 89/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0290 - val_loss: 0.7069 - val_accuracy: 0.0145\n",
      "Epoch 90/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0319 - val_loss: 0.7099 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0348 - val_loss: 0.7087 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0319 - val_loss: 0.7103 - val_accuracy: 0.0453\n",
      "Epoch 93/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0292 - val_loss: 0.7092 - val_accuracy: 0.0268\n",
      "Epoch 94/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0295 - val_loss: 0.7089 - val_accuracy: 0.1283\n",
      "Epoch 95/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0305 - val_loss: 0.7103 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0238 - val_loss: 0.7111 - val_accuracy: 0.0180\n",
      "Epoch 97/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0278 - val_loss: 0.7119 - val_accuracy: 0.0962\n",
      "Epoch 98/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0318 - val_loss: 0.7094 - val_accuracy: 0.0187\n",
      "Epoch 99/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0333 - val_loss: 0.7088 - val_accuracy: 0.0319\n",
      "Epoch 100/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0325 - val_loss: 0.7089 - val_accuracy: 0.0255\n",
      "Epoch 101/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0244 - val_loss: 0.7084 - val_accuracy: 0.0062\n",
      "Epoch 102/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0303 - val_loss: 0.7090 - val_accuracy: 0.0649\n",
      "Epoch 103/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0259 - val_loss: 0.7090 - val_accuracy: 0.1051\n",
      "Epoch 104/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0341 - val_loss: 0.7100 - val_accuracy: 0.0315\n",
      "Epoch 105/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0263 - val_loss: 0.7106 - val_accuracy: 0.2296\n",
      "Epoch 106/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0287 - val_loss: 0.7084 - val_accuracy: 0.0101\n",
      "Epoch 107/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6510 - accuracy: 0.0244 - val_loss: 0.7093 - val_accuracy: 0.0149\n",
      "Epoch 108/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0275 - val_loss: 0.7096 - val_accuracy: 0.0630\n",
      "Epoch 109/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0246 - val_loss: 0.7086 - val_accuracy: 0.0638\n",
      "Epoch 110/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0222 - val_loss: 0.7111 - val_accuracy: 0.0391\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0274 - val_loss: 0.7111 - val_accuracy: 0.1056\n",
      "Epoch 112/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0191 - val_loss: 0.7075 - val_accuracy: 0.0477\n",
      "Epoch 113/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0302 - val_loss: 0.7110 - val_accuracy: 0.0483\n",
      "Epoch 114/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0268 - val_loss: 0.7108 - val_accuracy: 0.0107\n",
      "Epoch 115/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0300 - val_loss: 0.7104 - val_accuracy: 0.0432\n",
      "Epoch 116/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6510 - accuracy: 0.0272 - val_loss: 0.7091 - val_accuracy: 0.0803\n",
      "Epoch 117/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0283 - val_loss: 0.7084 - val_accuracy: 0.0654\n",
      "Epoch 118/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0273 - val_loss: 0.7070 - val_accuracy: 0.0915\n",
      "Epoch 119/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0296 - val_loss: 0.7111 - val_accuracy: 0.0541\n",
      "Epoch 120/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0320 - val_loss: 0.7093 - val_accuracy: 0.0440\n",
      "Epoch 121/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0240 - val_loss: 0.7103 - val_accuracy: 0.0255\n",
      "Epoch 122/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0263 - val_loss: 0.7105 - val_accuracy: 0.0846\n",
      "Epoch 123/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0318 - val_loss: 0.7084 - val_accuracy: 0.0086\n",
      "Epoch 124/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0237 - val_loss: 0.7101 - val_accuracy: 0.0721\n",
      "Epoch 125/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0282 - val_loss: 0.7100 - val_accuracy: 0.0733\n",
      "Epoch 126/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0289 - val_loss: 0.7100 - val_accuracy: 0.0078\n",
      "Epoch 127/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0258 - val_loss: 0.7096 - val_accuracy: 0.0161\n",
      "Epoch 128/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0288 - val_loss: 0.7112 - val_accuracy: 0.0393\n",
      "Epoch 129/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0355 - val_loss: 0.7115 - val_accuracy: 0.0205\n",
      "Epoch 130/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0247 - val_loss: 0.7092 - val_accuracy: 0.0171\n",
      "Epoch 131/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0344 - val_loss: 0.7107 - val_accuracy: 0.0134\n",
      "Epoch 132/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0287 - val_loss: 0.7113 - val_accuracy: 0.0013\n",
      "Epoch 133/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0313 - val_loss: 0.7107 - val_accuracy: 0.0649\n",
      "Epoch 134/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0320 - val_loss: 0.7107 - val_accuracy: 0.0192\n",
      "Epoch 135/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0284 - val_loss: 0.7098 - val_accuracy: 0.0047\n",
      "Epoch 136/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0242 - val_loss: 0.7096 - val_accuracy: 0.0113\n",
      "Epoch 137/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6510 - accuracy: 0.0227 - val_loss: 0.7103 - val_accuracy: 0.0304\n",
      "Epoch 138/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0327 - val_loss: 0.7078 - val_accuracy: 0.0050\n",
      "Epoch 139/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0216 - val_loss: 0.7100 - val_accuracy: 0.0451\n",
      "Epoch 140/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0323 - val_loss: 0.7098 - val_accuracy: 0.0038\n",
      "Epoch 141/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0236 - val_loss: 0.7107 - val_accuracy: 0.0149\n",
      "Epoch 142/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0332 - val_loss: 0.7099 - val_accuracy: 0.0842\n",
      "Epoch 143/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0275 - val_loss: 0.7113 - val_accuracy: 0.0216\n",
      "Epoch 144/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0253 - val_loss: 0.7098 - val_accuracy: 0.0218\n",
      "Epoch 145/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0365 - val_loss: 0.7084 - val_accuracy: 0.0133\n",
      "Epoch 146/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0278 - val_loss: 0.7068 - val_accuracy: 0.0438\n",
      "Epoch 147/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0326 - val_loss: 0.7103 - val_accuracy: 0.0127\n",
      "Epoch 148/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0297 - val_loss: 0.7092 - val_accuracy: 0.1607\n",
      "Epoch 149/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0235 - val_loss: 0.7093 - val_accuracy: 0.0186\n",
      "Epoch 150/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0293 - val_loss: 0.7117 - val_accuracy: 0.0305\n",
      "Epoch 151/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0299 - val_loss: 0.7087 - val_accuracy: 0.0225\n",
      "Epoch 152/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0272 - val_loss: 0.7123 - val_accuracy: 0.0164\n",
      "Epoch 153/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0250 - val_loss: 0.7097 - val_accuracy: 0.0659\n",
      "Epoch 154/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0294 - val_loss: 0.7108 - val_accuracy: 0.0383\n",
      "Epoch 155/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0216 - val_loss: 0.7115 - val_accuracy: 0.0087\n",
      "Epoch 156/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0332 - val_loss: 0.7087 - val_accuracy: 0.0766\n",
      "Epoch 157/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0360 - val_loss: 0.7084 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0293 - val_loss: 0.7120 - val_accuracy: 0.0047\n",
      "Epoch 159/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0308 - val_loss: 0.7093 - val_accuracy: 0.0018\n",
      "Epoch 160/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0258 - val_loss: 0.7098 - val_accuracy: 0.0650\n",
      "Epoch 161/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0231 - val_loss: 0.7103 - val_accuracy: 0.0149\n",
      "Epoch 162/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0291 - val_loss: 0.7097 - val_accuracy: 0.1471\n",
      "Epoch 163/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0306 - val_loss: 0.7112 - val_accuracy: 0.0033\n",
      "Epoch 164/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0331 - val_loss: 0.7094 - val_accuracy: 0.0334\n",
      "Epoch 165/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0262 - val_loss: 0.7084 - val_accuracy: 0.0212\n",
      "Epoch 166/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0348 - val_loss: 0.7082 - val_accuracy: 0.0127\n",
      "Epoch 167/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0254 - val_loss: 0.7101 - val_accuracy: 0.0583\n",
      "Epoch 168/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0259 - val_loss: 0.7098 - val_accuracy: 0.0152\n",
      "Epoch 169/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0330 - val_loss: 0.7119 - val_accuracy: 0.0121\n",
      "Epoch 170/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0302 - val_loss: 0.7099 - val_accuracy: 0.0773\n",
      "Epoch 171/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0272 - val_loss: 0.7105 - val_accuracy: 0.0248\n",
      "Epoch 172/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6510 - accuracy: 0.0327 - val_loss: 0.7115 - val_accuracy: 0.0023\n",
      "Epoch 173/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6510 - accuracy: 0.0364 - val_loss: 0.7097 - val_accuracy: 0.0490\n",
      "Epoch 174/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0304 - val_loss: 0.7095 - val_accuracy: 0.1141\n",
      "Epoch 175/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0280 - val_loss: 0.7090 - val_accuracy: 0.0562\n",
      "Epoch 176/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0290 - val_loss: 0.7117 - val_accuracy: 0.0043\n",
      "Epoch 177/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6510 - accuracy: 0.0294 - val_loss: 0.7098 - val_accuracy: 0.0338\n",
      "Epoch 178/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6510 - accuracy: 0.0327 - val_loss: 0.7102 - val_accuracy: 0.0420\n",
      "Epoch 179/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0336 - val_loss: 0.7098 - val_accuracy: 0.0116\n",
      "Epoch 180/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0272 - val_loss: 0.7091 - val_accuracy: 0.0175\n",
      "Epoch 181/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0273 - val_loss: 0.7117 - val_accuracy: 0.0596\n",
      "Epoch 182/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0331 - val_loss: 0.7111 - val_accuracy: 0.0438\n",
      "Epoch 183/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0248 - val_loss: 0.7104 - val_accuracy: 0.0095\n",
      "Epoch 184/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0269 - val_loss: 0.7077 - val_accuracy: 0.0418\n",
      "Epoch 185/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0338 - val_loss: 0.7103 - val_accuracy: 0.0342\n",
      "Epoch 186/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0266 - val_loss: 0.7114 - val_accuracy: 0.0534\n",
      "Epoch 187/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0358 - val_loss: 0.7110 - val_accuracy: 0.0210\n",
      "Epoch 188/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0287 - val_loss: 0.7098 - val_accuracy: 6.4373e-04\n",
      "Epoch 189/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0232 - val_loss: 0.7097 - val_accuracy: 0.0132\n",
      "Epoch 190/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0284 - val_loss: 0.7103 - val_accuracy: 0.0817\n",
      "Epoch 191/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0263 - val_loss: 0.7081 - val_accuracy: 0.0106\n",
      "Epoch 192/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0303 - val_loss: 0.7084 - val_accuracy: 0.0311\n",
      "Epoch 193/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0321 - val_loss: 0.7097 - val_accuracy: 0.0269\n",
      "Epoch 194/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6510 - accuracy: 0.0262 - val_loss: 0.7107 - val_accuracy: 0.0352\n",
      "Epoch 195/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0300 - val_loss: 0.7122 - val_accuracy: 0.0477\n",
      "Epoch 196/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6510 - accuracy: 0.0280 - val_loss: 0.7110 - val_accuracy: 0.0714\n",
      "Epoch 197/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0387 - val_loss: 0.7102 - val_accuracy: 0.0334\n",
      "Epoch 198/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6510 - accuracy: 0.0276 - val_loss: 0.7092 - val_accuracy: 0.0155\n",
      "Epoch 199/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0292 - val_loss: 0.7093 - val_accuracy: 0.0012\n",
      "Epoch 200/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0264 - val_loss: 0.7109 - val_accuracy: 0.0676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:109: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_test = np.asarray(inputs_test).astype(np.int) #CHANGE (added)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  targets[test] = np.asarray(targets[test]).astype(np.int) #CHANGE (added)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:136: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "  tprs.append(interp(mean_fpr, fpr, tpr))\n",
      "C:\\Users\\User\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:806: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:99: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_train = np.asarray(inputs_train).astype(np.int) #CHANGE (added)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:100: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  targets[train] = np.asarray(targets[train]).astype(np.int) #CHANGE (added)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5243/5243 [==============================] - 20s 4ms/step - loss: 0.6550 - accuracy: 0.0368 - val_loss: 0.7037 - val_accuracy: 0.1199\n",
      "Epoch 2/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6514 - accuracy: 0.0349 - val_loss: 0.7098 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6513 - accuracy: 0.0319 - val_loss: 0.7099 - val_accuracy: 0.0091\n",
      "Epoch 4/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6513 - accuracy: 0.0384 - val_loss: 0.7082 - val_accuracy: 0.0150\n",
      "Epoch 5/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6513 - accuracy: 0.0287 - val_loss: 0.7078 - val_accuracy: 0.0049\n",
      "Epoch 6/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6513 - accuracy: 0.0313 - val_loss: 0.7087 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0293 - val_loss: 0.7099 - val_accuracy: 0.0568\n",
      "Epoch 8/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0330 - val_loss: 0.7089 - val_accuracy: 0.0068\n",
      "Epoch 9/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0358 - val_loss: 0.7104 - val_accuracy: 0.0779\n",
      "Epoch 10/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0310 - val_loss: 0.7119 - val_accuracy: 0.0252\n",
      "Epoch 11/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0314 - val_loss: 0.7081 - val_accuracy: 0.3040\n",
      "Epoch 12/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0381 - val_loss: 0.7101 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0317 - val_loss: 0.7106 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0377 - val_loss: 0.7101 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6512 - accuracy: 0.0339 - val_loss: 0.7098 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0337 - val_loss: 0.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0291 - val_loss: 0.7087 - val_accuracy: 0.2991\n",
      "Epoch 18/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0298 - val_loss: 0.7104 - val_accuracy: 0.2058\n",
      "Epoch 19/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0402 - val_loss: 0.7106 - val_accuracy: 6.6756e-04\n",
      "Epoch 20/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0294 - val_loss: 0.7088 - val_accuracy: 0.1644\n",
      "Epoch 21/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6512 - accuracy: 0.0383 - val_loss: 0.7074 - val_accuracy: 0.0557\n",
      "Epoch 22/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0356 - val_loss: 0.7081 - val_accuracy: 0.0386\n",
      "Epoch 23/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0523 - val_loss: 0.7085 - val_accuracy: 2.8610e-04\n",
      "Epoch 24/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0257 - val_loss: 0.7073 - val_accuracy: 0.2904\n",
      "Epoch 25/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0372 - val_loss: 0.7080 - val_accuracy: 0.0050\n",
      "Epoch 26/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0364 - val_loss: 0.7108 - val_accuracy: 0.0014\n",
      "Epoch 27/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0351 - val_loss: 0.7101 - val_accuracy: 0.0659\n",
      "Epoch 28/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0430 - val_loss: 0.7105 - val_accuracy: 0.0746\n",
      "Epoch 29/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0331 - val_loss: 0.7096 - val_accuracy: 0.1536\n",
      "Epoch 30/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0365 - val_loss: 0.7078 - val_accuracy: 0.0631\n",
      "Epoch 31/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0262 - val_loss: 0.7078 - val_accuracy: 0.0097\n",
      "Epoch 32/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0521 - val_loss: 0.7112 - val_accuracy: 0.0137\n",
      "Epoch 33/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0279 - val_loss: 0.7102 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0374 - val_loss: 0.7087 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0336 - val_loss: 0.7092 - val_accuracy: 0.0478\n",
      "Epoch 36/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0339 - val_loss: 0.7093 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0340 - val_loss: 0.7094 - val_accuracy: 0.0025\n",
      "Epoch 38/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0398 - val_loss: 0.7103 - val_accuracy: 0.0779\n",
      "Epoch 39/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0419 - val_loss: 0.7074 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0419 - val_loss: 0.7082 - val_accuracy: 0.0512\n",
      "Epoch 41/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0226 - val_loss: 0.7096 - val_accuracy: 2.8610e-04\n",
      "Epoch 42/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0441 - val_loss: 0.7091 - val_accuracy: 0.0133\n",
      "Epoch 43/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0374 - val_loss: 0.7096 - val_accuracy: 0.0191\n",
      "Epoch 44/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0308 - val_loss: 0.7077 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0543 - val_loss: 0.7112 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0313 - val_loss: 0.7108 - val_accuracy: 0.1872\n",
      "Epoch 47/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0444 - val_loss: 0.7124 - val_accuracy: 0.1019\n",
      "Epoch 48/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0314 - val_loss: 0.7102 - val_accuracy: 0.0746\n",
      "Epoch 49/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0389 - val_loss: 0.7112 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0332 - val_loss: 0.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0354 - val_loss: 0.7085 - val_accuracy: 0.0227\n",
      "Epoch 52/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0430 - val_loss: 0.7082 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0251 - val_loss: 0.7080 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0312 - val_loss: 0.7112 - val_accuracy: 9.2981e-04\n",
      "Epoch 55/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0406 - val_loss: 0.7096 - val_accuracy: 0.0184\n",
      "Epoch 56/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0497 - val_loss: 0.7102 - val_accuracy: 0.0569\n",
      "Epoch 57/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0244 - val_loss: 0.7092 - val_accuracy: 0.0090\n",
      "Epoch 58/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0362 - val_loss: 0.7104 - val_accuracy: 0.0062\n",
      "Epoch 59/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0365 - val_loss: 0.7106 - val_accuracy: 0.0047\n",
      "Epoch 60/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0342 - val_loss: 0.7103 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0297 - val_loss: 0.7090 - val_accuracy: 0.0524\n",
      "Epoch 62/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0426 - val_loss: 0.7107 - val_accuracy: 0.0188\n",
      "Epoch 63/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0303 - val_loss: 0.7083 - val_accuracy: 0.0358\n",
      "Epoch 64/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0495 - val_loss: 0.7107 - val_accuracy: 0.0058\n",
      "Epoch 65/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0325 - val_loss: 0.7075 - val_accuracy: 0.0227\n",
      "Epoch 66/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0406 - val_loss: 0.7094 - val_accuracy: 0.0682\n",
      "Epoch 67/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0445 - val_loss: 0.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0300 - val_loss: 0.7088 - val_accuracy: 0.0152\n",
      "Epoch 69/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0421 - val_loss: 0.7097 - val_accuracy: 0.0342\n",
      "Epoch 70/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0359 - val_loss: 0.7095 - val_accuracy: 0.0448\n",
      "Epoch 71/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0417 - val_loss: 0.7089 - val_accuracy: 0.0317\n",
      "Epoch 72/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0326 - val_loss: 0.7087 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0297 - val_loss: 0.7104 - val_accuracy: 0.0014\n",
      "Epoch 74/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0327 - val_loss: 0.7088 - val_accuracy: 9.2981e-04\n",
      "Epoch 75/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0405 - val_loss: 0.7087 - val_accuracy: 0.2993\n",
      "Epoch 76/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0481 - val_loss: 0.7093 - val_accuracy: 0.0172\n",
      "Epoch 77/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0294 - val_loss: 0.7089 - val_accuracy: 0.0126\n",
      "Epoch 78/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0287 - val_loss: 0.7077 - val_accuracy: 0.0195\n",
      "Epoch 79/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0316 - val_loss: 0.7092 - val_accuracy: 0.0734\n",
      "Epoch 80/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0341 - val_loss: 0.7094 - val_accuracy: 0.0436\n",
      "Epoch 81/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0341 - val_loss: 0.7094 - val_accuracy: 0.0017\n",
      "Epoch 82/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0357 - val_loss: 0.7073 - val_accuracy: 0.0779\n",
      "Epoch 83/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0312 - val_loss: 0.7073 - val_accuracy: 0.0101\n",
      "Epoch 84/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0329 - val_loss: 0.7088 - val_accuracy: 0.0406\n",
      "Epoch 85/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0401 - val_loss: 0.7081 - val_accuracy: 0.0038\n",
      "Epoch 86/200\n",
      "5243/5243 [==============================] - 19s 4ms/step - loss: 0.6511 - accuracy: 0.0303 - val_loss: 0.7093 - val_accuracy: 0.0463\n",
      "Epoch 87/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0400 - val_loss: 0.7116 - val_accuracy: 0.0075\n",
      "Epoch 88/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0371 - val_loss: 0.7096 - val_accuracy: 0.0026\n",
      "Epoch 89/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0449 - val_loss: 0.7082 - val_accuracy: 0.0586\n",
      "Epoch 90/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0416 - val_loss: 0.7111 - val_accuracy: 0.0367\n",
      "Epoch 91/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0434 - val_loss: 0.7087 - val_accuracy: 0.0261\n",
      "Epoch 92/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0331 - val_loss: 0.7077 - val_accuracy: 2.6225e-04\n",
      "Epoch 93/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0432 - val_loss: 0.7087 - val_accuracy: 0.0059\n",
      "Epoch 94/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0293 - val_loss: 0.7093 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0395 - val_loss: 0.7100 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0538 - val_loss: 0.7079 - val_accuracy: 0.0074\n",
      "Epoch 97/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0333 - val_loss: 0.7097 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0339 - val_loss: 0.7074 - val_accuracy: 0.0168\n",
      "Epoch 99/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0331 - val_loss: 0.7072 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0299 - val_loss: 0.7088 - val_accuracy: 0.0335\n",
      "Epoch 101/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0295 - val_loss: 0.7092 - val_accuracy: 0.0582\n",
      "Epoch 102/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0262 - val_loss: 0.7079 - val_accuracy: 0.0413\n",
      "Epoch 103/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0466 - val_loss: 0.7107 - val_accuracy: 0.2608\n",
      "Epoch 104/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0349 - val_loss: 0.7105 - val_accuracy: 0.2657\n",
      "Epoch 105/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0339 - val_loss: 0.7102 - val_accuracy: 0.0109\n",
      "Epoch 106/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0421 - val_loss: 0.7091 - val_accuracy: 0.1692\n",
      "Epoch 107/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0260 - val_loss: 0.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0448 - val_loss: 0.7088 - val_accuracy: 0.0264\n",
      "Epoch 109/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0461 - val_loss: 0.7096 - val_accuracy: 9.2981e-04\n",
      "Epoch 110/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0391 - val_loss: 0.7079 - val_accuracy: 0.0166\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0306 - val_loss: 0.7109 - val_accuracy: 0.0979\n",
      "Epoch 112/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0413 - val_loss: 0.7087 - val_accuracy: 0.1990\n",
      "Epoch 113/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0447 - val_loss: 0.7094 - val_accuracy: 0.0080\n",
      "Epoch 114/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0290 - val_loss: 0.7083 - val_accuracy: 0.0755\n",
      "Epoch 115/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0315 - val_loss: 0.7091 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0447 - val_loss: 0.7107 - val_accuracy: 0.0379\n",
      "Epoch 117/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0359 - val_loss: 0.7097 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0519 - val_loss: 0.7076 - val_accuracy: 0.0027\n",
      "Epoch 119/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0411 - val_loss: 0.7095 - val_accuracy: 0.0192\n",
      "Epoch 120/200\n",
      "5243/5243 [==============================] - 19s 4ms/step - loss: 0.6511 - accuracy: 0.0420 - val_loss: 0.7097 - val_accuracy: 0.0176\n",
      "Epoch 121/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6511 - accuracy: 0.0419 - val_loss: 0.7094 - val_accuracy: 0.0066\n",
      "Epoch 122/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0361 - val_loss: 0.7098 - val_accuracy: 0.0340\n",
      "Epoch 123/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0355 - val_loss: 0.7107 - val_accuracy: 0.0283\n",
      "Epoch 124/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0352 - val_loss: 0.7093 - val_accuracy: 0.0047\n",
      "Epoch 125/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0380 - val_loss: 0.7089 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0401 - val_loss: 0.7092 - val_accuracy: 0.0367\n",
      "Epoch 127/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0478 - val_loss: 0.7097 - val_accuracy: 0.0103\n",
      "Epoch 128/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0364 - val_loss: 0.7086 - val_accuracy: 0.0100\n",
      "Epoch 129/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0348 - val_loss: 0.7071 - val_accuracy: 0.0061\n",
      "Epoch 130/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0407 - val_loss: 0.7104 - val_accuracy: 0.0481\n",
      "Epoch 131/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0372 - val_loss: 0.7094 - val_accuracy: 0.0386\n",
      "Epoch 132/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0373 - val_loss: 0.7102 - val_accuracy: 0.0103\n",
      "Epoch 133/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0382 - val_loss: 0.7091 - val_accuracy: 0.0046\n",
      "Epoch 134/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0338 - val_loss: 0.7103 - val_accuracy: 0.0469\n",
      "Epoch 135/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0331 - val_loss: 0.7084 - val_accuracy: 0.2999\n",
      "Epoch 136/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0400 - val_loss: 0.7096 - val_accuracy: 0.2770\n",
      "Epoch 137/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0512 - val_loss: 0.7111 - val_accuracy: 0.0015\n",
      "Epoch 138/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0237 - val_loss: 0.7090 - val_accuracy: 0.0174\n",
      "Epoch 139/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0374 - val_loss: 0.7082 - val_accuracy: 0.0311\n",
      "Epoch 140/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0306 - val_loss: 0.7075 - val_accuracy: 0.0137\n",
      "Epoch 141/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0308 - val_loss: 0.7081 - val_accuracy: 0.0069\n",
      "Epoch 142/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0404 - val_loss: 0.7098 - val_accuracy: 0.0101\n",
      "Epoch 143/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0410 - val_loss: 0.7107 - val_accuracy: 0.0375\n",
      "Epoch 144/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0449 - val_loss: 0.7105 - val_accuracy: 0.0026\n",
      "Epoch 145/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0421 - val_loss: 0.7116 - val_accuracy: 0.0099\n",
      "Epoch 146/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0424 - val_loss: 0.7108 - val_accuracy: 0.1418\n",
      "Epoch 147/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0337 - val_loss: 0.7091 - val_accuracy: 0.1001\n",
      "Epoch 148/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0369 - val_loss: 0.7099 - val_accuracy: 0.0363\n",
      "Epoch 149/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0258 - val_loss: 0.7107 - val_accuracy: 0.0198\n",
      "Epoch 150/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0360 - val_loss: 0.7103 - val_accuracy: 0.0307\n",
      "Epoch 151/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0249 - val_loss: 0.7087 - val_accuracy: 0.1550\n",
      "Epoch 152/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0383 - val_loss: 0.7081 - val_accuracy: 0.0064\n",
      "Epoch 153/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0294 - val_loss: 0.7096 - val_accuracy: 0.0013\n",
      "Epoch 154/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0496 - val_loss: 0.7070 - val_accuracy: 0.1105\n",
      "Epoch 155/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0312 - val_loss: 0.7082 - val_accuracy: 0.0053\n",
      "Epoch 156/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0459 - val_loss: 0.7101 - val_accuracy: 0.0081\n",
      "Epoch 157/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0254 - val_loss: 0.7098 - val_accuracy: 0.0419\n",
      "Epoch 158/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0339 - val_loss: 0.7095 - val_accuracy: 0.0610\n",
      "Epoch 159/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0326 - val_loss: 0.7082 - val_accuracy: 0.0378\n",
      "Epoch 160/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0401 - val_loss: 0.7099 - val_accuracy: 0.0142\n",
      "Epoch 161/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0324 - val_loss: 0.7105 - val_accuracy: 0.0543\n",
      "Epoch 162/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0410 - val_loss: 0.7081 - val_accuracy: 0.0823\n",
      "Epoch 163/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0357 - val_loss: 0.7090 - val_accuracy: 0.2958\n",
      "Epoch 164/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0416 - val_loss: 0.7097 - val_accuracy: 0.0073\n",
      "Epoch 165/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0339 - val_loss: 0.7085 - val_accuracy: 0.0984\n",
      "Epoch 166/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0431 - val_loss: 0.7090 - val_accuracy: 0.0135\n",
      "Epoch 167/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0303 - val_loss: 0.7099 - val_accuracy: 0.0017\n",
      "Epoch 168/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0274 - val_loss: 0.7095 - val_accuracy: 0.0307\n",
      "Epoch 169/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0388 - val_loss: 0.7094 - val_accuracy: 0.0423\n",
      "Epoch 170/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0440 - val_loss: 0.7104 - val_accuracy: 0.1688 0s - loss: 0.6511 - accu\n",
      "Epoch 171/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0390 - val_loss: 0.7084 - val_accuracy: 0.0498\n",
      "Epoch 172/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0313 - val_loss: 0.7096 - val_accuracy: 0.0083\n",
      "Epoch 173/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0433 - val_loss: 0.7096 - val_accuracy: 0.0098\n",
      "Epoch 174/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0289 - val_loss: 0.7096 - val_accuracy: 0.1743\n",
      "Epoch 175/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0377 - val_loss: 0.7113 - val_accuracy: 0.0335\n",
      "Epoch 176/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0271 - val_loss: 0.7084 - val_accuracy: 0.0082\n",
      "Epoch 177/200\n",
      "5243/5243 [==============================] - 15s 3ms/step - loss: 0.6511 - accuracy: 0.0338 - val_loss: 0.7093 - val_accuracy: 0.0739\n",
      "Epoch 178/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0404 - val_loss: 0.7093 - val_accuracy: 0.0282\n",
      "Epoch 179/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0323 - val_loss: 0.7085 - val_accuracy: 0.0135\n",
      "Epoch 180/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0394 - val_loss: 0.7097 - val_accuracy: 0.0182\n",
      "Epoch 181/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0336 - val_loss: 0.7089 - val_accuracy: 0.0872\n",
      "Epoch 182/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0466 - val_loss: 0.7089 - val_accuracy: 0.1396\n",
      "Epoch 183/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6510 - accuracy: 0.0474 - val_loss: 0.7099 - val_accuracy: 0.0487\n",
      "Epoch 184/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0384 - val_loss: 0.7096 - val_accuracy: 0.0124\n",
      "Epoch 185/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0366 - val_loss: 0.7072 - val_accuracy: 0.0448\n",
      "Epoch 186/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0374 - val_loss: 0.7094 - val_accuracy: 0.0804\n",
      "Epoch 187/200\n",
      "5243/5243 [==============================] - 14s 3ms/step - loss: 0.6511 - accuracy: 0.0419 - val_loss: 0.7089 - val_accuracy: 0.0948\n",
      "Epoch 188/200\n",
      "5243/5243 [==============================] - 17s 3ms/step - loss: 0.6510 - accuracy: 0.0286 - val_loss: 0.7087 - val_accuracy: 0.1444\n",
      "Epoch 189/200\n",
      "5243/5243 [==============================] - 16s 3ms/step - loss: 0.6511 - accuracy: 0.0395 - val_loss: 0.7098 - val_accuracy: 0.0612\n",
      "Epoch 190/200\n",
      "5243/5243 [==============================] - 20s 4ms/step - loss: 0.6511 - accuracy: 0.0392 - val_loss: 0.7103 - val_accuracy: 0.0674\n",
      "Epoch 191/200\n",
      "5243/5243 [==============================] - 21s 4ms/step - loss: 0.6511 - accuracy: 0.0358 - val_loss: 0.7097 - val_accuracy: 2.8610e-04\n",
      "Epoch 192/200\n",
      "5243/5243 [==============================] - 22s 4ms/step - loss: 0.6510 - accuracy: 0.0340 - val_loss: 0.7069 - val_accuracy: 0.0177\n",
      "Epoch 193/200\n",
      "5243/5243 [==============================] - 20s 4ms/step - loss: 0.6510 - accuracy: 0.0382 - val_loss: 0.7080 - val_accuracy: 0.0135\n",
      "Epoch 194/200\n",
      "5243/5243 [==============================] - 19s 4ms/step - loss: 0.6511 - accuracy: 0.0355 - val_loss: 0.7083 - val_accuracy: 2.3841e-05\n",
      "Epoch 195/200\n",
      "5243/5243 [==============================] - 19s 4ms/step - loss: 0.6511 - accuracy: 0.0315 - val_loss: 0.7107 - val_accuracy: 0.0252\n",
      "Epoch 196/200\n",
      "5243/5243 [==============================] - 19s 4ms/step - loss: 0.6511 - accuracy: 0.0407 - val_loss: 0.7100 - val_accuracy: 0.0691\n",
      "Epoch 197/200\n",
      "5243/5243 [==============================] - 22s 4ms/step - loss: 0.6510 - accuracy: 0.0484 - val_loss: 0.7113 - val_accuracy: 0.0571\n",
      "Epoch 198/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6511 - accuracy: 0.0402 - val_loss: 0.7082 - val_accuracy: 0.0051\n",
      "Epoch 199/200\n",
      "5243/5243 [==============================] - 19s 4ms/step - loss: 0.6511 - accuracy: 0.0364 - val_loss: 0.7099 - val_accuracy: 0.0212\n",
      "Epoch 200/200\n",
      "5243/5243 [==============================] - 18s 3ms/step - loss: 0.6510 - accuracy: 0.0309 - val_loss: 0.7095 - val_accuracy: 0.1688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:109: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  inputs_test = np.asarray(inputs_test).astype(np.int) #CHANGE (added)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:110: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  targets[test] = np.asarray(targets[test]).astype(np.int) #CHANGE (added)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_12236/3963942960.py:136: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "  tprs.append(interp(mean_fpr, fpr, tpr))\n",
      "C:\\Users\\User\\anaconda3\\envs\\research\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:806: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52428, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[52053, 375]\n",
      "[0, 0]\n",
      "[6475, 19627]\n",
      "[19894, 6432]\n",
      "[3502, 22600]\n",
      "[22751, 3575]\n",
      "[6650, 19419]\n",
      "[19704, 6655]\n",
      "[5871, 20198]\n",
      "[20317, 6042]\n",
      "[3218, 22822]\n",
      "[23167, 3221]\n",
      "[14023, 12017]\n",
      "[12213, 14175]\n",
      "[1660, 24523]\n",
      "[24560, 1685]\n",
      "[1616, 24567]\n",
      "[24599, 1646]\n",
      "[6549, 19663]\n",
      "[19744, 6472]\n",
      "[13492, 12720]\n",
      "[12700, 13516]\n",
      "[0, 26268]\n",
      "[26160, 0]\n",
      "[9809, 16459]\n",
      "[16377, 9783]\n",
      "[0, 26416]\n",
      "[26012, 0]\n",
      "[0, 26416]\n",
      "[26012, 0]\n",
      "[8219, 18044]\n",
      "[18000, 8165]\n",
      "[6041, 20222]\n",
      "[20054, 6111]\n",
      "[5004, 21200]\n",
      "[21263, 4961]\n",
      "[14519, 11685]\n",
      "[11564, 14660]\n",
      "[3171, 23003]\n",
      "[23022, 3232]\n",
      "[4512, 21662]\n",
      "[21790, 4464]\n",
      "[0, 26257]\n",
      "[26171, 0]\n",
      "[13068, 13189]\n",
      "[13167, 13004]\n",
      "[4954, 21222]\n",
      "[21275, 4977]\n",
      "[11948, 14228]\n",
      "[14239, 12013]\n",
      "[6578, 19653]\n",
      "[19582, 6615]\n",
      "[0, 26231]\n",
      "[26197, 0]\n",
      "[6416, 19727]\n",
      "[19655, 6630]\n",
      "[6884, 19259]\n",
      "[19413, 6872]\n",
      "[8143, 17984]\n",
      "[18095, 8206]\n",
      "[13737, 12390]\n",
      "[12432, 13869]\n",
      "[6428, 19724]\n",
      "[19719, 6557]\n",
      "[0, 26152]\n",
      "[26276, 0]\n",
      "[1696, 24395]\n",
      "[24662, 1675]\n",
      "[4905, 21186]\n",
      "[21406, 4931]\n",
      "[0, 26256]\n",
      "[26172, 0]\n",
      "[7346, 18910]\n",
      "[18839, 7333]\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds of MWPM:\n",
      "> Accuracy: 0.5262623845513525 (+- 0.0006335964088936181)\n",
      "> F1: 0.24215354995714589(+- 0.0006407235333689676)\n",
      "> Time: 519.2995027599807 (+- 25.727411133490953)\n",
      "#####################################################################################\n",
      "Average scores for all folds of PLUT:\n",
      "> Accuracy: 0.5260330990789654 (+- 0.00045925927807386667)\n",
      "> F1: 0.35838060019774376(+- 0.0029164155267952414)\n",
      "> Time: 13.468020419999998 (+- 0.7244816770880941)\n",
      "#####################################################################################\n",
      "Average scores for all folds of NN:\n",
      "> Accuracy: 0.12057649723841171 (+- 0.20343808220558635)\n",
      "> F1: 0.6666662374097092(+- 0.0006664746981962531)\n",
      "> Time: 2.00965434 (+- 0.14492919602725468)\n",
      "#####################################################################################\n",
      "> AUC for class : 0.30241474021515224 (+- 0.0)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 373.00266666666664\n",
      "> AUC for class X00: 0.49504727036083684 (+- 0.0009164612941536299)\n",
      "X^2 for MWPM and NN: 1.81736292097872\n",
      "X^2 for PLUT and NN: 0.5094485237370731\n",
      "> AUC for class X01: 0.4886385745595532 (+- 0.0012763379388712073)\n",
      "X^2 for MWPM and NN: 2.090739462720139\n",
      "X^2 for PLUT and NN: 0.35542391706775267\n",
      "> AUC for class X02: 0.4898746942756227 (+- 0.001385012649520854)\n",
      "X^2 for MWPM and NN: 2.6031442301419903\n",
      "X^2 for PLUT and NN: 1.6016921172100702\n",
      "> AUC for class X10: 0.4951189881808614 (+- 0.0017563444482340941)\n",
      "X^2 for MWPM and NN: 0.02941955463194996\n",
      "X^2 for PLUT and NN: 0.022149452873937273\n",
      "> AUC for class X11: 0.4922318907271769 (+- 0.0020570137321310163)\n",
      "X^2 for MWPM and NN: 0.17062958357652194\n",
      "X^2 for PLUT and NN: 0.014201416207710465\n",
      "> AUC for class X12: 0.48974874405117347 (+- 0.0015572685315332164)\n",
      "X^2 for MWPM and NN: 0.21837567711909667\n",
      "X^2 for PLUT and NN: 0.19981118284809354\n",
      "> AUC for class X20: 0.49515794601501006 (+- 0.001746115040578369)\n",
      "X^2 for MWPM and NN: 3.0977531090257115\n",
      "X^2 for PLUT and NN: 3.0977531090257115\n",
      "> AUC for class X21: 0.4919664496389121 (+- 0.00132464843263521)\n",
      "X^2 for MWPM and NN: 0.051298413050715794\n",
      "X^2 for PLUT and NN: 0.6924471149071407\n",
      "> AUC for class X22: 0.49237903921528553 (+- 0.0020817298938364923)\n",
      "X^2 for MWPM and NN: 0.09646044791936509\n",
      "X^2 for PLUT and NN: 0.6193814787732805\n",
      "> AUC for class Z00: 0.4941392367825396 (+- 0.0008545344994024252)\n",
      "X^2 for MWPM and NN: 0.008690928843020097\n",
      "X^2 for PLUT and NN: 0.38297431648715824\n",
      "> AUC for class Z01: 0.489933899034056 (+- 0.001343055379127514)\n",
      "X^2 for MWPM and NN: 0.13780804150453957\n",
      "X^2 for PLUT and NN: 0.016732432842616482\n",
      "> AUC for class Z02: 0.48887091311193964 (+- 0.0016338623413224066)\n",
      "X^2 for MWPM and NN: 0.06861660823116926\n",
      "X^2 for PLUT and NN: 0.005058488776478028\n",
      "> AUC for class Z10: 0.4947005042570618 (+- 0.0011526162823385193)\n",
      "X^2 for MWPM and NN: 0.12488849241748438\n",
      "X^2 for PLUT and NN: 0.020771343556878003\n",
      "> AUC for class Z11: 0.48842609130116543 (+- 0.0018887556010888287)\n",
      "X^2 for MWPM and NN: 0.12800264080036564\n",
      "X^2 for PLUT and NN: 0.6212505171700455\n",
      "> AUC for class Z12: 0.49048289141927526 (+- 0.0011863774526971059)\n",
      "X^2 for MWPM and NN: 0.3476814767593337\n",
      "X^2 for PLUT and NN: 0.07449037144468616\n",
      "> AUC for class Z20: 0.4956480955866624 (+- 0.0026258547304262607)\n",
      "X^2 for MWPM and NN: 0.0004056486575564739\n",
      "X^2 for PLUT and NN: 0.298027771419852\n",
      "> AUC for class Z21: 0.4907653298525375 (+- 0.0024072958571594656)\n",
      "X^2 for MWPM and NN: 1.4640927900197729\n",
      "X^2 for PLUT and NN: 1.1467176934635612\n",
      "> AUC for class Z22: 0.4888107906467897 (+- 0.0015845402082897782)\n",
      "X^2 for MWPM and NN: 0.13139925230792707\n",
      "X^2 for PLUT and NN: 0.12980476304008054\n",
      "###################################################################################\n",
      "TOTAL F1 NN: [0.6665508032724343, 0.6666577185949173, 0.6660022984313841, 0.6679135130862413, 0.6662068536635696]\n",
      "TOTAL F1 PLUT: [0.3622404197913215, 0.3554179177469899, 0.3614727106935768, 0.35556942651895, 0.35720252623788096]\n",
      "TOTAL F1 MWPM: [0.24221146526276569, 0.2412198443079927, 0.24294329393871678, 0.24272101344195, 0.24167213283430436]\n",
      "TOTAL ACC NN: [0.0020408553536981344, 0.017471246421337128, 0.00457761948928237, 0.05296687036752701, 0.5258258945602139]\n",
      "TOTAL ACC PLUT: [0.5266089177243064, 0.5263208087930308, 0.5262063683116077, 0.5253239719680851, 0.5257054285977975]\n",
      "TOTAL ACC MWPM: [0.5263428937981909, 0.5256301504490474, 0.5272935528850217, 0.5255628915696139, 0.5264824340548893]\n",
      "TOTAL TIME NN: [1.8344147, 2.008454, 2.0794701, 1.884426, 2.2415069]\n",
      "TOTAL TIME PLUT: [12.5508465, 14.3865441, 14.0291713, 12.7038721, 13.6696681]\n",
      "TOTAL TIME MWPM: [485.05673499998164, 533.2347135999871, 560.7087749999918, 510.3875701999709, 507.1097199999724]\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# D3 TESTING\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "inputs = x_d3.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = y_d3.copy()\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "n_classes = 19\n",
    "\n",
    "acc_per_fold = []\n",
    "f1_per_fold = []\n",
    "time_per_fold = []\n",
    "\n",
    "\n",
    "acc_per_fold_plut = []\n",
    "f1_per_fold_plut = []\n",
    "time_per_fold_plut = []\n",
    "\n",
    "acc_per_fold_mwpm = []\n",
    "f1_per_fold_mwpm = []\n",
    "time_per_fold_mwpm = []\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "aucs_classes = {}\n",
    "for i in mlb_d3.classes_:\n",
    "    aucs_classes[i] = []\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#for i in range(5):\n",
    "    \n",
    "    # K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for i, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "    i_train = inputs[train].copy()\n",
    "    i_test = inputs[test].copy()\n",
    "    x_test_d3 = i_test[:,:2]\n",
    "    inputs_train = i_train[:,3:]\n",
    "    inputs_test = i_test[:,3:]\n",
    "    ####################################################################################################\n",
    "    #test MWPM decoder for this fold\n",
    "    #labels = targets[train], features = inputs[train]\n",
    "    #x_test_d3 = translate_to_graph(testData_d3_MWPM, targets[test], mlb_d3)\n",
    "    decoding_d3, time_mwpm = do_new_decoding(x_test_d3, 3, .03)\n",
    "    decoding_d3['combine'] = decoding_d3[[0, 1]].values.tolist()\n",
    "    decoding_d3['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "    decoding_d3 = np.array(decoding_d3[0])\n",
    "\n",
    "    time_per_fold_mwpm.append(time_mwpm)\n",
    "\n",
    "    pred_mwpm = mlb_d3.transform(decoding_d3)\n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_mwpm)\n",
    "    else:\n",
    "        acc, contingency_mwpm = partial_accuracy_and_contingency(targets[test], pred_mwpm, mlb_d3)\n",
    "        \n",
    "    acc_per_fold_mwpm.append(acc)\n",
    "    f1_per_fold_mwpm.append(f1_score(targets[test], pred_mwpm, average='micro'))\n",
    "\n",
    "\n",
    "    #####################################################################################################\n",
    "    #test the plut decoder for this fold\n",
    "\n",
    "    lookup_d3 = lookup_decoder(3)\n",
    "\n",
    "    lookup_d3 = train_plut(lookup_d3, inputs_train, targets[train])\n",
    "\n",
    "    start = time.time_ns()\n",
    "    pred_plut_d3 = test_plut(lookup_d3, inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_plut_d3)\n",
    "    else:\n",
    "        acc, contingency_plut = partial_accuracy_and_contingency(targets[test], pred_plut_d3, mlb_d3)\n",
    "\n",
    "    acc_per_fold_plut.append(acc)\n",
    "    f1_per_fold_plut.append(f1_score(targets[test], pred_plut_d3, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #Test the NN decoder for this fold\n",
    "\n",
    "    model = compile_FFNN_model_DepthThree(3)\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    \n",
    "    inputs_train = np.asarray(inputs_train).astype(np.int) #CHANGE (added)\n",
    "    targets[train] = np.asarray(targets[train]).astype(np.int) #CHANGE (added)\n",
    "    \n",
    "    history = model.fit(\n",
    "        inputs_train, targets[train],\n",
    "        validation_split=.2,\n",
    "        epochs=200,\n",
    "        verbose=1)\n",
    "\n",
    "   # Generate generalization metrics\n",
    "    inputs_test = np.asarray(inputs_test).astype(np.int) #CHANGE (added)\n",
    "    targets[test] = np.asarray(targets[test]).astype(np.int) #CHANGE (added)\n",
    "    \n",
    "    scores = model.evaluate(inputs_test, targets[test], verbose=0)\n",
    "\n",
    "    #get the time to predicting test\n",
    "    start = time.time_ns()\n",
    "    predictions_d3 = model.predict(inputs_test) #change here\n",
    "    end = time.time_ns()\n",
    "    time_per_fold.append((end - start)/ (10 ** 9))\n",
    "\n",
    "    #threshold based on previous tests with train_test_split in hyperparameter tuning\n",
    "    pred=predictions_d3.copy() #change here\n",
    "    pred[pred>=.1]=1 \n",
    "    pred[pred<.1]=0\n",
    "    \n",
    "    if fold_no <5:\n",
    "        acc = scores[1]\n",
    "    else:\n",
    "        acc, contingency_nn = partial_accuracy_and_contingency(targets[test], pred, mlb_d3)\n",
    "\n",
    "    acc_per_fold.append(acc)\n",
    "    f1_per_fold.append(f1_score(targets[test], pred, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #comput ROC AUC for classes and the mircoaverage\n",
    "    fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d3.ravel())\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    #get the AUCs of each class, used to get average AUC of each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d3[:, i]) #change here\n",
    "        aucs_classes[mlb_d3.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "        \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "        \n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb_d3.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "    \n",
    "############print mean and stdev of AUC of each class#####################      \n",
    "    \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print(\"#####################################################################################\")\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print(\"#####################################################################################\")\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "print(\"#####################################################################################\")\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 3 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_train_d3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12236/211353708.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fit model on training data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m history = model.fit(\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train_d3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_train_d3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train_d3' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "model = compile_FFNN_model_DepthThree(3)\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x=x_train_d3.values,\n",
    "    y=Y_train_d3,\n",
    "    validation_split=.25,\n",
    "    epochs=200\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss (MSE)')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAowAAAJ7CAYAAABppMB3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAACNo0lEQVR4nO3dd5xcdb3/8dcnm957Iz0h9J7QhdBEEVAE9AoWbFwFVH7Xht6rl6tXAQvqBcSLDRt6BRXpSMnShYQaCIEE0ntPdlM22f3+/vickzk7O3N2Zktmdvb9fDz2cXbmlPnOnJlzPufzLcdCCIiIiIiI5NOl1AUQERERkfKmgFFEREREUilgFBEREZFUChhFREREJJUCRhERERFJpYBRRERERFIpYBTpoMzsEjMLOf62m9kqM3vNzP5oZv9mZmNLXd62lni/l7TjaxxlZleZ2R1mNsfMVpvZLjPbbGYvmNn3zWxyK1/j6qz9970C1uliZsuy1pvQmnK0Rnvui8Tns6iF698al6+NiybSqShgFKk8PYERwIHAvwA/BBaa2V/MbHRJS9YMM5tRDgFQwteAa4DzgYOB4UBXoD9wBPAl4DUz+9c2fM2LzKy5Y/OpwD5t+JoiIqkUMIpUhrOAftHfQGAC8A7gKmAeUAW8H5hjZseVpogd0jrg98ClwInAZGAYcBgeLK4CegA/M7N3tcHrbcEDwVObWe6jieVFRNqdAkaRyrA9hFAT/W0OISwOITwZQrgOzzT+G1APDAbuNLMxJS1tBxFC+EwI4SMhhJ+HEJ4KIbwdQlgXQnglhPBD4HigNlr8qjZ4yTui6UfyLWBmffDgH+D2NnhNEZFmKWAUqXDB/YhMQDMcuLp0JaocIYSFwKPRw6PaYJO/i6bvN7PeeZZ5P9AHWAg81QavKSLSLAWMIp3HD4E3o/8/YmbD8i1oZqeZ2W1mttjMdkSdPGZFHUD65FlnQqL94Qwz62Nm/xl1vqk1sw1m9pCZnZ1n/QDMTDy1MLtDT9qbM7OPmdmTZrbRzLaZ2ctm9hUz657+sbTarmi6sw229RiwGOhLJouYLc4+/g4oqCOHmR1iZr8ws7eiTlFbzOwlM/uOmQ0tYP2DzewPZrYy+j4sMrObzWx8Ia8fbWOQmf2HmT1rZuvNbGfUceeP5dxMwsyGmdl3o+/Tlujze8vMfm5mBzWz7ngz+1HUYarGzOrMbEX02d9iZuflWe94M/u9mb0dvd626Lf4jJlda2bT2+fdiqQIIehPf/rrgH/AJXjAEIAZBa7z1cQ65+eY3xO4LbFMrr+3gH1zrDshscx5wJyUbfwgx/pprxn8cJVz+U/iVbP51nsQ6NJO+2AosCF6nftauI2rk+8P+E5c7hzLjsabFgRg36zvwIQ82/9SYp1cfxuAk1LKdz5Ql7Lu9MTjS/Js4xRgfTP791vNfD6LWvj53prr+1PguqcAm1LKvBu4Ms+6JwM1zbznmjz7q7nfwj3t8X3Wn/7S/pRhFOlcnk78nyur8zvgQ3iA8ANgGjAEGAt8DFgKTALuzpdpjFwPTAX+Ew9shgFnALOi+V80s09mrdMP77wTO4hMR574L5ev4wHqdcAheDvNw4G/RfPfCXwqpaxFMbOuZjbOzD6MVwkPwrOL32yjl4irpU8zs1FZ8y7Ga4b+GUKYX0BZLwK+H63zKnAu3oN+PHA5sBEv/71mNinH+gfiFxDd8A4+H8OD1n3wYLUO+L9mynAkcD++X17Ee+6Pjx5PwwM6gG+YWZvtp9Yys32Bu4EBeGB8GV7uEcB7gbl4Z7IfmdmFWet2AX6LNx14C++kNAV/z6OBk/DvyxtZ600Fro0ePgK8K3rNQcBE4D3A/+DBt8jeVeqIVX/601/L/mhZhnFEYp0/ZM17f/R8A3BunvXHAGui5b6UNW8CjbMgF+VYvzfwUjR/LdAja/6MxPoTmnkvyde6OMf8LniAEvAAq7Wf9zpyZ3teBU5oxXavjreVeG5W9NwXs5Z9JXr+shzfgQlZy/YAVkfzXgf653jtI4Ad0TJ/zTH/nmheDTA1x/z9gW2JMlySY5mXo3nPAN3zfAbfjZZZA/TK8/ksauHne2v251vgendG620HDs0xfyAe8AVgZfK94Rcu8WdyWBGv+blondX5Piv96a9Uf8owinQumxL/D86a94Vo+ucQwl25Vg4hLANujB5enPI6z4YQbsux/jZ8bEPw6txzmitwAZ4JIfwhx2s14FkegCPMrGsbvFa2FcCP8cC0LcXl3tNb2swOxwOROuBPBWzjHLyDE8BXQwhNhuAJIbwI/G/08Nxku1YzGwG8O3p4YwjhzRzrzwNuylcAMzsFODR6+PEQQl2eRb+N9zYfhmeES8rMhpP5bt4cQngle5kQwiYyHclGAsm2ucnv2vIiXjpeb23KZyVSEgoYRToXS/wf9jzpPXLjKuqZZtY33x+eUQM4NKVDyd/yPA/wDzwrBXBCC95DtvtT5sVVft3xar3WGI9Xiw/CB/H+MtAL+DnwRI7q49b4E94+7jAzOyR6Lh578b4QwoYCtnFiNN0G3JeyXDw0TxU+TFDsODLniLT9+deUeadH0yXAspTvVBU+Xih4NXWpHU/mvacNXXQPnoEEH/c09kbi+d9EVc2FiC88Doo6twwpcD2RdqeAUaRzGZD4f2Pi/0l4OzWAnwFbU/7+Ei3XhaZZyti8PM8TQqgH4vZ344soez4rUuZtS/yfb5iagoQQaoOPc7kphPBaCOEHwNH453gkmbaHrRZCWAs8ED38qJlV4W1LKeJ14s/2zRDC7pTlXsuxDngTg1je/YlXd+ezXzQdR/p3aiuZYYny9t7fi5Kfw9x8C4UQdpHju5yVST8LeMPM5kU9qz+S7+IihFCNV4WDd1BbbWb/NLMfmNm5zbQbFmlXChhFOpdkpmNl4v8B2QsWqGee52uaWS+en68jSzHqC1zOml+kOCGEBXgnBPBOKvulLV+kuFr6Irzzw0i888U9Ba4ff7bN7YutOdYBH9onlraNtHkt+V7l+07tTcnPodDPr9F3OYTwE7wz1j/xbP5+eOer3+LZ1rvzZB4/gGev38Yzr8cAXwT+DqwxsxvMrH9xb0ek9RQwinQuySrHZI/p5EnxrBCCFfi3KM/r9M3zfPb8ralLdQzPJv4/NO9Sxbsb2Iz3qo2D0j8X0bYt/mwL3RfJdaDxdyJtG2nz4m08V8R36pJmyrs3JD+HFn+XQwh3hhCOwzubvQ8feWAufu49G/inZd0zPYSwK4TwgxDCZHyEgY8Cv8B7qfcGrgAeaac2uSJ5KWAU6STMzIBPRA/rgMcTsxfhvaPB75fcWvunlKMKPxGCD1Ld0SVP3CHvUkUKIewg034uHvKmmGrvRdF0ajPBRXLw6UV5/s+7P4EDUua9HU0nRd+/jmJR4v8D8y0Ufa5xlnBRvuVCCGtDCH8PIXw5hHAQ3rygAW8Pe2XKegtCCL8LIXwaH9oqvnCYRuNONiLtTgGjSOfx/8ic3H4TQlgXzwghbAaeix5+sA1eK+cdLCJnkGlPmH1ru12J/6vaoBx7w0mJ/99q423/NvH/ghDC03mXbOrJaNobr9LO54JoWo8PfRN7hsxFRNr+zHdHGvAOTuA94k9NWa7cJN/7+SnLvQfv+ASZz7tZIYQ/kek8lhZwJ9fZTeNbeha0nkhbUcAoUuHMfR4f2Bq8auu/ciz6w2h6opn9WzPbrDKzKSmLHBMNGp29Xm8yAxOvw6tdk5IDEo9OK0N7i24Jl69TT7zMEcBno4cL8TEm29KTeGBwAH7nkGLcg49rCHCdmTVpL2pmh5Ep/9+jzjYAhBBWk+mBfkWu9nZmtj8+oHU+/yATGN0cDdWTl/ntJXukLbM3hBDWkPluXmZmB2cvY2YDaPybuicxb5+o93dOZtaLzPd7feL5faNBv/NJZv81eLfsVQoYRSpDr8QwJQOiO5GcYGZfxnvB/gSvOl0PvC+E0GRsuBDCHWTG9/uhmf3NzM4ys9FmNjC6L+67zOw6vKrxypTyLAJ+bWbfMLPJZjbEzE7H7xV9WLTMVSGE7PsvLwDi8QKvMrOpZtYzurvK3m6zdRB+P+ufmdl7o/cxyMyGm9lxZnYtniHtg2ejPhdCaLMqafCRpkMI86K/tN7gudbdiWeVwatVnzSzs6NAeKyZfQa/m0gPvK3hV3Js5it484U+QHXcwzf6+xhQjQ8ynbf8+N1htuPNEF42sy+Z35s6/iwPN7NPmdnd+P5vi45QOZnZsQX8xcMvfRkfG7IXPtTUpdHnNszMzsGD+biT0xey2paegXds+YWZvd/MpkTvd6yZvQd4CM+6Avwxsd6/A2+Z2TVmdka0/MDou/dxMkMY1dL0YkukfZV65HD96U9/Lfuj8V0+mvvbDdwBjGpmm93xYXUK2eb1WetOSMw7D88s5Vv3hyll+G6+9bKWy3t3kcQyMxLLTSjy852RUv7k3wbgwlbsx6tzvb8WfAdyvj9afy/pC8h/L+mNFHYv6eOBZQV+Twfl+XwWtfDzvbWI30nAL6jidVt0L2kK/21e04KybkuWUX/621t/6mUlUnl24lm69fht2Z4Dbg8hLG1uxeBZks+Y2S3ApXj7vDF4lmUL3kbvn3j128Mpm9oIHIuPJXc+PkZdHTAb+EkIIW1omP/A747xYTwz1o92GBKnAM/i914+BR/EejSZO6esxwPiB4HfhhDKtnowhPADM/sHfiefU4BReKDzNr4ffxQS7VlzrH+Hmc3D79l9Cj725iq8uvmaEMLbzfVnCSE8HVVpfwL/TA+NtrM72tareLbz9hDCxla83TYVQpgZlftKvL3iJDxTvwLPlv84hPBqjlX/jN/68jT8u7MP/t1pwO/H/jTwvyGEf2at91X8d3Uafj/0Ufi93Lfj2deH8bvuLGmzNylSIAshlLoMIlIBouFBFkYPTwk+CLGIiFQAtWEUERERkVQKGEVEREQklQJGEREREUmlgFFEREREUilgFBEREZFU6iXdjoYOHRomTJjQ7q9TW1tLnz592v11pPxo33du2v+dl/Z959Ze+//5559fF0IYlmuexmFsRxMmTGD27Nnt/jrV1dXMmDGj3V9Hyo/2feem/d95ad93bu21/81scb55qpIWERERkVQKGEVEREQklQJGEREREUmlgFFEREREUilgFBEREZFUChhFREREJJUCRhERERFJpYBRRERERFIpYBQRERGRVAoYRURERCSVAkYRERERSaWAUURERERSKWAUERERkVQKGEVEREQklQJGEREREUmlgFFEREREUilgFBEREZFUChhFREREJJUCRhERERFJpYBRRERERFIpYBQRERGRVAoYRURERCSVAkapLLt2wG3/AqteLXVJREREKoYCRqksGxfCm/fDG/eVuiQiIiIVQwGjVJbatT5d+0ZpyyEiIlJBFDBKZYkDxnVvlrYcIiIiFUQBo1SW2nU+XTcfGhpKWxYREZEKoYBRKkucYdy9HbYsK21ZREREKoQCRqksccAIsFbV0iIiIm1BAaNUltp10HeE/692jNJRzP07zFPPfhEpXwoYpbLUrIFh+0GvwQoYpeN47Pvwj/8odSlEpFR2boUnfwT1u0tdkrwUMEplqV0LfYbB0KmFB4zLZsMNR8GOzYW/zoaFsOSfLSujSLZt62DDW7BlRalLIiKlMO8+ePhqWPZcqUuSlwJGaWzN6/Di70tdiparXQd9hsPQfYsLGNcv8CCwUNXXwO0fb1kZRZJCyLS9XfRUacsiIqWxaYlPNy7OPX/rati2Ye+VJwcFjNLY7F/B3V/wk1ipvPkP+OH+nqIvxq7tULcV+gz1aunatYX9wLatazwtxOZlULMKGuqLK+PetHOr3ypRytuOTdAQVUMteqKkRRGREtm0uPE02wNXwS9O33vlyUEBozS2bYOfvHZuKV0Z3rgXtq6EDW8Xt148BmNcJQ0+HmNztq2PpkVcvW1ZAaGh5Fd8qX5/ATzw1VKXQppTG33/unSFRU+WtiwiUhrNZhhXQb9Re688OShglMa2RwFQKQOhZc/7dPPy4taLq/UaBYwF3CIwDjRrC8wwhuABLUDtmuLKuDete0NDC3UE8fd20oy2a8e4Ywu8/KfS1hSIlLuNi2D3zlKXwm1e6tM4cMy2dSX0G7n3ypODAkZpbPvGaFqigHFnDax5zf/fUmzAmMgwDhwHVT0Ka8cYB8eFVklv3wi7o6remjINGOt3eTlrVpe6JJ3PnDvg12cVfqehOGA88H0+bYt2jHP+DH/7V1j9Wuu3JVKJdu2Anx7v7dFLraEBNsUBY44MYwhRhlEBo5STOHiKA8e9bcWLXtULmSuuQu3JMA6FLlUwZEphGbY9bRjXF/Y6cXYRyjdgjD+Lci1fJXvzQVj8FKyeU9jy8fdv0gzoOaBt2jHGHbhWFVgGkc5m7euwqxbm/KX0mfiaVdCwC3oP9URJ/a7G83ds9ruXqUq6MTO7yMyeMLPNZlZjZrPN7HIzK7isZjbBzEKBfydlrTvWzD5rZr80s1fMbHe03Jfa/t2WoThQ3FaigHHZLJ/2HtK6KmmAYVPbp0p6SyJgLNcq6ThQrNsKdbWlLUulqVkDPz4U3pqZe/7aeT5d+Hhh24u/d31HwPgT2qYd48ZFPlXAKG1h01Jv4lAu1bdtYdWrPt28BJa/UNqyxNXQE070hEl2smTrKp8qw5hhZjcBfwCmAU8ADwFTgRuBO4oIGmuA36T8RVEJW4Hns9Y9H/gp8AngEKCqhW+n46nflenskqySDsF7IO8Ny2Z7ZnD4gd4TuRi1a6FrL+jexx8P2dd/iLvr8q/T0FB8u82OlGGE1ldL764r/RV4OVn8tFcb3fflppmAhoZMR6u3Hytse7VrPbPYtbufMNqiHWNcrbXqldZtZ29oqIe/fErjmpaz+77sTRxunOZNLgptblHOVr/q54uq7vDaX0tblrg6euI7fJrd8SU+5yhgdGZ2PnAZsAo4NIRwdgjhPGBf4HXgPOBzhWwrhLAuhHBJvj8gTiX9KYSQnX5ZCPwE+ChwIPC7Vr+5jmL7psz/yeDplT/7MDetDRpf+iPc8QlvkJ9LCJ5h3GcaDBjTsjaMfYeBmT8ePMmv1vINUwA+pElcBV5oG8b4x9tneOPArJwkA9nWBLW7dsCPD4FZv2h9mcrBq3/Jn7luqC8sq73iRZ+unw+zf9143ualXnXUY4AHlmkXK7HatV4VBTD2mMav0VIbo4zFqjm5g/3FTxeeAW1va16HObfDU/9T6pJILhsXwZsPwAHn+vf6L5+EZ29u+9dpaIC7Pg/Ls3M4Oax4KZNFb6lVr8LIg2HyqX5rzlJeFMfnqAnvaPw4Fl/0q0p6j69F06+GEPaMhRJCWA18Nnp4VTFV07mY2T7AmdHDX2bPDyH8PYRwZQjhdyGE14EKuJQqULLdYjLDuOY1D6xaExzt2gEPfcNP2L97X+42kpuXehXvmGnQfx/PshQzzmF8l5fYkMk+Xf9W/nXidos9BhRRJb3CT/ADxpRxhjEZMLYiw/j2TG9fU45Vm8/81P8KtX2jX7A8f2vTeXW18KeL4CeHNj+c04oXYdRhMPEkqP5u4+9y3MnqiIu9fdSKAqq6atdlvrcDx/u02Ox60vaNsHMzDJrov9tc23r4v+CBr7f8NdpS/BkteKi4uy1J+5h3L8y8JhNAzfoFWBd417Xwr4/D8IO8nW5bWzMXXvhN8zeOqKuF35wLD/1ny18rBG9jPOJgOOg8P/cUEqi2l01L/BgwZIoPr5Uvw9h3xN4vW0JZBIxmNgY4CqgDbs+eH0J4DFgOjASObeXLXYK/79dCCM+2cluVJRkkJjOMcVCUr8p27RvNX+3Nud0DuuM/78HHb85pur24/eKY6R6MhfpM241CZAeMg6OAcUNKwBgHicOm+om2kAB160roPwr6Di/fgLEmWSXdijK+fne0jQKCzrs+54HI3vLSH+D5Xze/XCyuKs7OJG9d7b2a33zAxyBdknJYCMGzG6OPhDO/61n5x76fmb82ajM77ZOAFVYtXbvOO2qBT6t6FN/hKyk+2Rxwtk9zBftbV/pvthyaGix/3gOS+jq/PZqUzrYNcOdn4bFr4ZmboG4bvPA7/y4N2Ae6dIHxx3vToba+5/HS6HcXnwfyeeXPfkGUVnPUnM3L/OJk5MGw37ujaum/tWxbu3bA3z7b+E5hu3fCbf/imfxCbFriI3t0qfJzX/Z727oKevSHHn1bVsY2UhYBI3BENH0thJCv3nNW1rItdUk0bZJd7PTiAK5Lt8bBYxws5Btq52//Cn+/Iv92Q/CDz4hD4IxvwYf+6MN9PHdL4+WWzfY2JSMO8h8NFJdpqV2bOfEC9B7sbcMKyTAO3Q8IhfUO37IC+o324LRcOr2smtO4SUHtGhgwzk/ELc0w1u+GN6ITeLLdZj5v3A9vPdKy12qJrSv9IF3oiSvO/mVfqPzpQz7vX/4I3fumZxo2vO0nq9FHwMhD4NAPelYkrnpe94Z32Bo6xecXUu2bvNAx8+9+azKM8clmv/cA1jRgDMG/E3Vby2Pg+eUveLZ2wLjStyVrqSd+6E03nr2l/DuGbF4O//fh3Pv+8R/4HaLGHQ8PfRPu/7JnqY/+18wy44717HmhowAUKg4YV7+Wv6NeCPDcz/3/7OYjW1cXnmBYHXV4GXGInyMmnwav3dn4Aqp+NyxtJniNt/XybfB0oknFvHvhzfthVoFhxualMGCs/z9wfNOxGMtgDEYon4BxYjRNu2SIP8GJKcukMrOTgSl4JrPztE0sVBwsDZ6YO8OYL5javDy64tyVe/5bj/oQBsdd7ifEKad7VcDirPHmls3yE3FVt0zAuKXAE2d8P95khtHMs4xpVYzbEhlGKGxonWSGsXZdSRuAd9+5Hm6/BH52IlRfm5lRs8YPMH2GtTxgXPyU7/M+w5s/EO/Y7J//plZkxoqxu873VcMu7+VYiD0BY2IfhwArX4Hpn4L9z/LvX1rAGLctHB1dtx5wNtTVZLIia9+MLj6ASSfDsuc8S5NPQ71fiCUvdNICxo2L4e3q/NuLlwEYfoA3y8ju+LJjc2Yc0da2A2utXds9QNjnKDjofX6sKIcgtlhv3O+jJ9z/ZfifI2H13FKXKL8XfuM1B0uzMukb3vaL+CM+DBf9n58HXvy9V0GPPz6z3Lioki8tE98SS5+FXoO8TXm+NryLn/YmUoMm+EVxMjj/27/6XyHiHtIjDvTpvqf7uSaZ2X/tr/DL0zO1BvnEbe3n3JH5rcfV6gseyn9ejMVjMA4c548Hjc9RJV36MRihfALGOM+aNv5HTTTt14rX+UQ0vSuEUMSNgzuJOIM4ZEruDGOuA3lDvQddu7fnb+f2zE3QdyQcfH7muXHHNQ4yd9bAypdh7HR/3H8fnxaaaYnvx5sMGME7vhRSJR2f5Jtrx7i7zgOjfqO9PUmob7tBzle9WngVYQgw+9cc/dzlXo3Xc2BmOBfwMvYd3rpq83n3eMb30A/4NtIyeXEWd/uGvTOMTzIIzpVB3rEZbpkBi5/JPBdXSScvfHZu8aCz73B/vM9R/j3Odw/uFS96lfHwA/zxhHeAVXlbzxA8wxhffEyc4dWsS1N6/27f6CfI5Pd2wNj83/snfgB/vCj9e7JpsWdNeg30LGf27zL52W1alH877WH3Tm+6EF/ErXzFf0P7HAUHv99/w3EziI6ifrf/do/+NHzkTv/tvXxbqUuVWwjwapTFzQ5KHv4vv1g/5d+hZ3/44O/9OHzSlzIdCcEvaAaMhSXP0MTunb7/im3qsHW1X7wc9XF/nK9aetbP/bt97OXReomaj7VvNK4WTrN6jrfx7RGFE8P292nyVrJxFnJlMyMNxCMa7NzinWc2L/MLn5GH+nEoOzDPVrsG6ndmAsaB4/255IXm1pUl7/AC0LXUBdhbzKw/cEH08Fft+DqXApcCjBgxgurq6vZ6qT1qampa9DqDNrxEzx1rWDn6nQBMfPslxloVK2q6MHLrWp6srsYa6jmpdh0GLJz7Aou3NX6dbnWbOCHqZTx/5m0sH9O4B3TfrQuY9tYjvD3xYpY8mWnPMaxmAAft2sbz9/6arf2nMmTdsxxSX8dLNUPZFL2XE6t6s2rusyzYlee9hcCgjS+xaeCh9NyxkmOAuUvWsmZnZvkJW6sYv2kZjz/6EKFLtyabmLzgZUZ36ckL81cyHXh11mOsW5T/irDHjjUcB8xbuYX6ql0cBMyaeQ+1fSfkXacQAza9xhEvfZ1XD/oq64Ydn7pst7pN7PfGjQxdP4uN/Q7i7QM+x4RFf6D/itd5Nvrsjt+4nHVVY+lR143uK+bzfLHfj9DAcS/9hS0DD2Xjut1MJfD0w3+nrseQnIsPX/0Y0bU6zz30F7b1Gddofpf6nRzw+o9YMu58tvbft7iy5NBvyxscFf0//9kHWL688b4dtuYJDlrxIksfuom3pngW4uglL9Eb2LlxBc9En0evbf69eX3JWlbXVTN0U08ObtjF8/f/hq3992vyuofPraZL7/G88EQmO35EvynYi39nzu6DOWH7RhZsqmJZdTVd6ndzonVlWfXveHtp7mvz3rVLOBp4bfEa1m73Mo3fVM+EratyfmcPe/slBu2q5el//JW6HkNy/vYPeetFuncdwvPV1Yzb1pdJmxbz5EP3sLubX5cP3PgKh0fLvv38TJas8306evm99Nv6Fm/s//l8H3urDdg0lyNe+i0rVyznjf0/zz7L7mZf4OnFO6nrvomje41ix5O/5JWt49utDG2td+0Sjt69ndc39WD1UuPI3mOpn/sYL3evbtfXbclxv+/Wt5m23oOipa8+yVs7PFDqtW0lx8y9k0XjP8ii5+cB0cXnETfBOoOs1zmgx0QGLnicZ2bObBRMjl5+L1Pn38Lso35ITb8pBZdr6NpnOBh4oXYk+/caTe1L9/Pa7satz7rvXM+xc+9i+T7nsGH5Ng4DXnzsXjYPPIgu9XWctHUF9V2680RWmXI5euEsavuM57XofXXfuZHjgfn/vJ/ly3wkvYPnPcNQYPHs+1m4YVjebU1665/s06U7O3sMpW7m/7DxpSeYSGDWmE9y1Oovsvzhn/PWlPwX2/03z+NI4JWlm9mwrZrhq2s5EHjuoTv8OBoCJ21ewbKNdbyd2A8tPe+3RrkEjHH2sE/KMnEWcmsLX+NfgN7AMqAduni5EMItwC0A06ZNCzNmzGivl9qjurqaFr3ObT+DZbPY76Lv+uOtd8L6wYyZehgsv4cZJx7vGaPH/Wpx4siBTMx+nVWvQhQH7ttzA/sm54cAt34feg9l0gevYVLPAZl5W/eHud/jqKE74fgZcNdfoUd/Dj/3s36VCzB3AmP6wph87+2V2+Gxq73zweQj4Dk4cNpJHDg5sfyg1bD4/zj5kHEwrGkAwIbboGY40096F8yGgyeOhGl5Xg+8GuafsP+0GdCtF8z9PtMPGA+TU9YpxEy/Wj941yswI6X36u46uOEozxK961pe274fM045FR5ZAE8+zYx3nAAYVG9h9NTDvbnAW48W//1Y9jw8tp5h7/guw3r0g/k/4/iDJ8I+R+ZevvqfPvgVcPTUUbBv1ustnQVPPMOwuqXwmSe8fWlrvL4Vos61+w6i8fcO4K+e4RnLKsbOmOGZj8dWA0aP+lpmnHyyn1SWPgfPwQFHvYMD9p0BW6bCa9dy1AjgmKxtNjTA04vgsA81/jzD++Dx73PCWD+cTjnuLKZMieYvOZZxO+czLt/nv/AJmAUHTTvJq7ABXlwGi/7IyYdP8WrBpJf9guz4/UfB+ONz//Zf/TKMPcifn78LFv6OE/cdBBNO8PmvrIGX/d9Jg4xJ8fq//C6seo5RH/uVZyfbw+yF8BKMWvcUo47+Baz/PfQbzfFnvt/n7/4gvZ/+H2accIz/vlrqkW95tunCIjpFtdTLf4JZcMCp/8IBw/eHrSfCa3dmvmPtpEXH/YerPSPedwRj+zT4bwM8K/gcTDjzs0wYfUTaFlzv+XDf48w4fKJXD8f+cBMA08b0hCNylO21Oz0De/SnGz//4ENQ1YMj33MJ1L9A77dnNv38nr4RQj1jz/smYxvq4ZX/5IhJw+DQGZ4ZfAKqGuqYcezhXrWdT10tVK+k9zGXZD6/EOCF/o2PJXO+CMD4HjWMT/uc1/0WasfQ+4iP0PuR/2LgrjUw8SSmn30JbLyLsZtezXzOucxZBy/Coe84G4bvD0t7w+vXc/S+I2DqDK/Ze2w34w48mnHHZbbT4vN+K5RLlfSiaJp2WTk2a9lixdXRt4YQD7zXyW1d4dXJcep7+wb/ocU/tux7Eeeqkk6OD5XdQHjevbD4STjl616NkNRvpFcJLH7Gf6zzH4LJp2SCRYiG1slTNdfQ4A3NAZ78caaRcJ/hjZdrbmidbeu9k0IcwNQ204Zxa1T90G9U5rXaYizGuHpnwUPp1eKrX/U2e+f+Dxz7We/UAtGYk/X+OWxbDwSv5uw73Ks3im1n+eb9fmKZemam7UxaO8b1C6Bbb/8/u8E2ZNoZblkGf/tM69t9xmUZMNZfO6mhHub/w/9f+bIHixsW+ucz4iCv/tkVfefjz7p3lDntP9r37bLZTV9z/QJvr5h9Qp18qlcrx2NVDk1cmEw51auE8zULyL47EeTv8NVQn3kuWfW25Fm483KfH0LU4zI6lI48xKfJaun4sxu6X6ZasqEhatcVmq9Cy2XXDu9l2lxV5No3fNiQ3Tu8ndfyFxpfhIw42D/L7OrSYqx/y48Jc//uTV3a28qXvenG0ChzPvJQbyKT63dQSiH4sGaTZsCoQxv3xI1/Q0MKzArmase4a4dfAIGPrZnLsz/zttbZ35Olz/r3oGsPH1atZnXT7//Cx718Qyb77xQyyyS/L821t149FwjeQzpm5tuOsq/srsv8xvK9l9iWFX6uOvwiP2ZuWwdHfMTnTX2Xf7brFuRfP/6eDEx0ekm+pzK5ywuUT8AYt3A9yMzyXVZOz1q2YGZ2IHAMEIC9cMnZQcS3uIt/dNs3Qq/BiYBxg7ctAQ9McrXVi094+7/Hg4J4m7vrfNzFYfvDkR/L/frjj/dAadUrHojt+87G89Ma/79xn3ekmfYJD4ieuN6fz9WGEfJ3fKld52Mqdu3hwxY01+klfn/9R2favbV2aJ36Xd5mZ8I7vA1X2vAOcYeMccc1fj7ORG1cmOm53Xe4t7Ns2J3e+3vbhqadH1bN8Yxsr0GZtjNpPaXXv+XDIXXplntImHg/nvofMP/Bxj0KwQdzX/RU0/Vi9bsaD3lUs9q/k2OPaXoxsGyWv9+D3u9tCFfNyXR4iU908X6OOz0lO53sc1Tuji/ZHV6Sy3fv5+0Yu/XJBHzgwSTkv41gHLBmt2GEpt/9LSt8X4Lv59icP8NLv/cTas1qD8birE/fEb7tZMBYs9oDnJGHZPb7xoXe8xWadkYrxAu/9c5Xzd2tZe08f91xx8M/b/b2xcmAsbnfayGqr/GLg1APy3ME/m1t5cv+nrpENwUbdbhPc91lp2atjwPakgum7ZvghwdkgrJiLX/Bg5OD3+9BycbFmcBt3QJvZx636WvO8AP9eJlsx7j4SW/L3qVr4/bUSRve9t9cMhGxa7sPVTX2aH88ZppPk+0Y63f593JidCffHn09CRF3OEn+Hpob0SHu3T3i4MbPD52aacO4cZF/f4bt7+e1fDebAC9D/9Ee0O33bi/X/tGQVlOjIZ/ffCD/+puW+AVrfIeyvsP99xkH9Hvu8lL6NoxlETCGEJbiFUzdgQuz50e9m8fgd4HJ0dK2WZ+MpjNDCK04ElWQ3XWZwCLO/mzb6AFCnG3btiHzwx40MXfQEc+PfyDLnvPpc7f4weGd34GqPC0fxh3rQegzXo3BlDMazx+wj5/Ys+8wE4JnFwdNgHd/HyaenLlndJwpivUe7B1C4o4vi5+Gv/5rJvjYtiGzTu8hzd/tZesK7/TQa5AfGKq6t35onZWveMZr+if9IPbyn/Ivu/wFD3DjBtKxQVHAuGFhJoDtMzwR1Kb0lL79Eh8IN2nN3EzHjj7DAct/5R6CB21D9/V9lqun9KalPjj6O74E+50Fj32v8X59+Gq49aymd06J3Xo2/OM/Mo+3rvRgaNh+HqAmt/Xmg37SmnGVP176XOb7Ed9JJc6W78kwZgWMG97KLLN9k1fRz7vbs6hDpzYuW1W3zC29hu7buBpt5GH+vXrr0dzva9s6wBpX0WdnT2LJjFUywxhnQF75v0xWIs5SmPlJLw6YIepxOcJ/P5uX+ck4Dih7DkwP3PNZ8LBPm7sP9tp5Xp6jP5XJ1u9zVGZ+8sKnJVa/5r1Vp30CiJocNKc1Y1E2NPjvd9ShmedGHOiZppUvN13+hVvh7i+0bPigdW/6Z5bsRBWCD7KdNrD+piWeMX/uf/2Cbv+zvSdu3dbMMX39gsKzi+DB8ZjpjbPR8x+Grj39950rK1dXmzkOJcu74iXveDY2upgbcbBvJ5nlX/GSZ/fjgBGg/5hMh5NktnRryrEuBJjzF7+Iyj6GDp3iwV9dbeb3cuD7fJovy9jQ4EmE+Dd77g3wqUehe1TbMmi8B9fNBYzJspj54/hiThnGnK6JpteZ2Z5vrpkNx+/tDHBtsjrZzK4ws3lm9tt8GzWzbsCHo4caezFWkzj5xyf47Rv8xNVrcOZx/AMftn+eKuk1fjU0/gQPpJY+59VOj/63Zwz3PT1/GcZFnTte+bNnbfpljWK/J9OSNd7W2zP97hAnXOnB6ClRm79eg3MHp0MmZ7JQD18Nr/wpUwWzLTFocu8hzfeS3hINqWPmf33aYPDuJVEj0HHHeY/k5bPzV2GseMFPsNlto/qN9P2wYWEm6xtnGCF/wLj8BVj4mB9w48G+d271g9jwqBtLVVffVr4r923rfWzCIVOiHr65MoxLvcrFzIew2VWbGR6mocGbL1gV3Ptv8EbWwXV3nWcbktmrrav9veVqcvDmg/5ZDtvPy7NslmcO+o/JfKf2ZBjXexAYH+AhE8Asm+U9R783EX5xqrfzGn9C7u9YnEnMbifbpQtMOsUDxlyBSe1a/83F2Snwtnt9hjX9HOOAccC4TAYuBA/uAebe5Vl38BNVLHukgJrVnk0aNMGzKJuX+QncquDwi2HlS8VV5e7eCYuirNfiRMDY0OBNTeJs2vZN/h0atj/sf07muxln5CBzIdbSDOOj3/HM16nf8O9vcxnPWb+A70/JfWyb/zDcfILfRzmfjQs98Bp1WOa5br38e5Crd20cKD38X5me+Etnwe/e3/wYsPH+T1441K7zQbbv+X9Nv18N9f78jw+BX5zmFxT7vcvbp8YZ6DgoWb8g81sq1LjjPJBa/Zo/nv8Pvxf66CM88Mq+a0/yIicZMMYBcJxhrOrm20hmGBc+5tP41nngF6d7qqQXZUbWSMswvvqXTDOp7GPokKhJwfoFiYDxvT5d81ru7dWu9WA3fu3egz3wTNr3nZ6oyDXywsZF/nsbOL7x86MO9XXqd5fNfaShjALGEMIdwM343VzmmNndZvZXYD5+T+c7gRuzVhsK7AdkXSo0cjYwHNgENHtZZ2ajzOyf8R/wnmjW55LPm1np88OtsSXxo4pPTNuzMozbN3ow1GOAB0m5qqRr1kQp9O7+I1/0JNzxST8Bn3tDehmGTI6q4gLse2bT+fGPMLsd4zM3eXr+8Iv88bhjPTuZ3UEgFo/FuOz5zBXxihe97eaubZkMY5+huaukFz7uAQ1EwxuMzszLN2xN3J6sEIuf8Qxhv5FwyIWAeTVjth1bPBhPZmRiZv7+NyYzjMMSAWP03Ot3+z29Y8mq4TgjsiaqTooDRvCy5Qs64+B78GS/Ms6VYdy8LFNVO+Ed/p2ad48/XvGCX8Cc9X1v/3XHxz2jENvwlgc269/KfKbxuGRxViQuw6YlfnCf+i5/PGaaZyrWvenZv3hfxyfnuElC0ugjAIPbPw5PXg+HfcgH9b7sWR90Ppc9AeP+uefVrskM05GUPXZoLFdzjDhQmPiOPRm47nUb/b0ccI4H4f/8mS+TzFgMmeLf6/g9JzOM4BcLq1/1IGfKqV7t3dzdNpKWPuu/o8GTvE1bPIj53DvhDxd4ZhYyJ+Fh+/vx4pSv+2eb7GBjFgW4LQgY174Bb9wLx3/Oj2Fjj/b3ke/uTTu2eIC5bV3j29Ft2wB//BD84Xy/0Jj9q/zZ9ZUv+TQZMIJ/j3NlGFe96gH/5iXenm/dfLjtQh/wvrmq5jiLlgwY44Bv2SxYkBg0f/dO/x3N/pUPun3Rn+GTD8N5/+vz97STW+Tfi23risswAkz7uH93//JpP2ZseMuPw/FxIz6O7ClrFDBal8YB46KnPFhLNgsZM80/2/giduHjnnlMLtN/n0SV9OJMNXm+fbWzxmspRh2Wu5lU3AZ13Xz/6zfKa1m698s/rmb8+v1H554P/nqhvnGWH/zz+dW7/Pt54v9rPO+Ac/18u/gpfz89B7auE1gbKZuAESCEcBlwMV49fTJ+z+cFwBXA+SGEAu7b1kTc2eW2EEKewdUa6YG3d4z/4m/ouKzne7SgLOUj/qJjfoLftcMP+r0GZTKMcZV03+H+3PZNTdve1K7JVHuOne4/8tVz4L0/bf6KyCzTpmzqO5vO39P4P5FhrKv1g8fB53u7w9gHfgsfznM9MGSyn3yf+rH/+Lv19oAxDg4bVUlnBYwNDXDnZX5nhIWPRw2cE9cKcaeS7HV+cnimqj1NQ4O3A4oHxu0/2qtdXs3xXla+BITcASN40LlhYdRGrae3R4qztjWrPNi678tw52f8BLlhoXcMiMc+i09+8dV0XCUNnpHKd+UeZ/eGTPYM3taVmaAhtmlpJrvXtbvv7zfu9yvoefd4FfLB74eLb/cMQ3w3B8i0h9q5OZM9rYkCxvj2j3HAGN/jdk/AON1Pzqte9arkPc0tEm0Y+2Q1Y+jZ36/wq7r59+p9P/VBvYfv37hTVtKQyXDR7VFVaJY97RhzVEvXrs8TMObI1G5a7CexYfv7SX77JvrURsHDtE/6Omtf94uE5MllTxY2CsL2ZBgTQcOqOX5CHnuMn9CLacf41qO+/076srdhi+8N/Up00TP/IZ/G+zHOwh51CZz3s6bba2nAGLenO+R8n4471sfGy9ee7p83+0l50ET/vsWB5YP/7mU+/b/83skNu3Pffxw8KOzSDYYd0Pj5UYf5dzRZPVpX6+/riIv9AvmJH8Lv3++Z3aruzbe3zJVhjIOw7v1g5nf8N759kwfqc//uTYLO+p63pRs7PdNOLt73mxZnfr9xwFSoPkP9t7HmNfjjB/25fc/w3wlkst2xeJ+OPyETMO6u8+/apBmNlz3yY74/HrvWz01Ln21cHQ2NmyxtWuzvqd/IxrVnSY9/349NZ/2gcUY/NngSYJkMY9y8ZPgBmSx+trhKPC1g3BNAJz6PdQu8CU5ogI/fD6MPb7zOlNP9PDX372Vzlxcos4ARIIRwWwjhhBBC/xBCnxDCUSGEm3L1bA4hXB1CsBDCjJTtnRMtc3mBr78oWr65v0Utf5dlID75jzjIT0xx9rD3YD+oVHWPqqTX+Amo1yAgeO+/pJq1md7Ccfuwoy/1qo9CHP5hv4XZqBxDOeRqy7XoKe/IEJ+EY9175x8KZPBkL/vrd8GRH/GD+YoXm3Z4iAPGZGZw2XP++VT18MzplhWNGx/3Gdb4vs3ggyFvXpLJSqZZP98/52Qnlqln+vPZGaa4I0a+YS+SGcY+w/1g172vH3hq1vjJbetKn3f3F+Dvl/vJ6uSv+me0J2B83TtvJKtJ+o1sfOV+1+c9ewF+gO3S1ZcfOBYIiQsSvGpq5+ZML0DwTlLb1vuJYN69XpXVa5AH4GOmN87OJO+0sG6+t7mrXRs10u/rGd/1b3nw/eLvPFsRVwuNifrKNezyAbV7DvTHyTaM2RlGgIvvgM+/mKmSKsTUd+b+DvYf5SeNZAYoln07y1g8eHfyuxi3dUq08+tTG2WdRhwcZadpWr0VZ442vOVZ9Z1b/EKi/z6+35a/4Ptr5CF+kTHqsMb3wK3f7QHV9/eFZ35KEwse8d9+HKQvetI/3wUPAebzQ/CMStdeTcuXbfAkf6/ZFx3NWTbbv0Nxe964ijNXtfS2DfD0Dd6e74xv+e/1jfu9FuLl2/yuVCde6cHPlDP8u56rPCtf8TaLXbs3fj5u05js+BL3zh1xMLzz2x5A1q6Di//sn/2yHB2tkuLM/aalmQv3OMN42jc9UJ/1C/jVmV5r8b6fwfFX5N5Wj36eBNi4uPge0kn7nuHH+42L/HMfMtkzqN16N80wbljorzn+hGjEgVrPjO7a1jRgHLqvX1DM/rXvj907mgaMcQ3Umrl+jBk0oelxKla7zi/gD7so873I1q2X/77WvenHmbit8ogDvdo9V43RnoBxn/yf0ZDJflGRDDpf+ZMH9h+/P3O3maTuvf2znXeP/zYVMEpJbVnhWaiRh/gBKK6u6jXYA41egxtnGJPV1EnxfPATxvt+Bmd8u/By7Pcu+NBt3tYrW9ceHqwmG8C/9aiXO3mrqubEPS8xP7iNPsIP9HE1bbJKeveOxncqefUv/nofu8vb9tXvbHw12Xd41I4lcT0TV18sn920ww74gaL6Wj9BxCfm5PuZeLJP336s8XrLX/CDYnZGbM/7nOjlXzUH+kZZK7Oo2nx11PDa4JMPepZq8VN+L+T+ozxI2FMlPddPlMl90m+Uv8/6XV7+F37r7UF3bPFAZNAEb9u3p91pIjsWB77J3sNTTvcg/Mkf+QE67jQF3qZt7euZNj9r52WG7Fm/ILPf4oPokMn+/Kt3+Hs4KdHmbOShfrAGPwFUdfWgMc4w1q7LHbAlv/NtYfKpHkj97ET4zTkenEDUhjFXwDjGT6TJ39umxR5sJTo49ald4uv3HQaH/Ys/PygrIBs0wbOG6xdksi99R3qWZeC4zP3C42FGxp/gwVddrbeL/NmJcN+XvDyPf7/x76NmrQdFk0/1z2v4Qf4+X/ubZ+amf9I7aqydF3V4mZr7t540eJJnXnK1hU2zPKt976CJfnGUq+PLUz/2ThSn/od30hgw1jOO93/FjzknfSmz7NGX+u/n9bsabyME/75lV0dDZjij5IVP3Dt35MGeZf3Ab+Bjd3uZ9znKL2LzVZ9DJrPYsCuzHzcu8t/mtI/7d+O+L3nA9JG/weEfyr8t8O/JpihgtKrmA/l8zvgWjDnaM6fg+3fY/k2zchsX+jFq5CFA8AvTt6v9uznhxKbbnXGVB3H3f9WXyT7mx0FafAwdOD5/Tcjb1f65Tf9U+nsZuq9vb+fmTMA4/CBPlGxd6fNuOCqTld2y3I8vuX7Dsapuvr+TGcblz/tFZFq70QPO9e/dipfKooc0KGDsvLas8MBnwFg/oMcn4XhInd6DM20Y+45IdIRJnMDqd/uJNw4Yq7r5Qapbz7Yr58ST/NZ3cSP8tx7xA0cx7TmGRAHjfmf5AWv0EV51Fle79U5kGCGTeayPhriZeqZflZ4dDd2zJwAl9+0B4wNlfV3utmAv/t6H/vjFqfDAVX5SS25z+IGeuYw7hcTiE2I+cSCx9vXG41H2HeEHnjfu94zb4Enepunwi+Hkr/gyow6LxnDc4AHv8Kwqtjg4q1kdvafgV/WzfuEHzzg7EWcRk+0Y4/8HJNrV9ejnWYUFUXXlfmdl5o06zIONuGp87Rt+Qqnq4ZnX7F6DQ6Z40PnIt33dONMG/l2MT+jxCaD3YN9fIfi+zu5Z3x6mf8p/G/3HwIZF3u5r01I/EeVrwwiZoKl+tzfNGDgu0/Zww9ueYYz31bD9vC3UYVmBQtcevr31b2WqSOOmCgPHZ6r5R0RBzvgT/MLox4fAnz/iFyEf/D18+C/+ub3wu8y2346GC4oz/hNO9KzxS7f5OI9x26wFD/t+zNXGM1tLhtbZWePf++TvwwzGHdP01ozbN8Gzt3gHs+EH+EXE9E95Z4jls+G0/2w8vMyU0zPV1knr3vTPY+ShNNFzgK+TDBhXvept7OLA7IBzMkPI7DPN26Dmqz4Pwb8LcfVmHDxuXBRdrHWDd13r++5TD2d67aeJh9ZZv8CDx+wsaaG69YJPPdT4Qm34AU3fy4a3/TOJL0xWzfHOLKOPzJ2Z7zvcOzbW1/kxO3ss3/g3EgeMcZX01tVNs4ELH/d207mC+6Qh+2YCzriKPs4Azv8H/N9H/POKm77E59HmLoKS1doNDR4w5rsJQmzqmX7MIyjDKCUWd94YONav5uOebnFWpddgzwzVbfWTSxxIJnsTblsHhEzA2B6mf9qv9ub82U+w696EyacVt41eg+C9N8G7vuuP4yrduIowfs9x4BhnnxY94SfTgy/wx4dfBJfPatxBJz7ZJzu+rH416mxiuYcoebvaT4rvud6bBBzx4cY99rp08Szj29WNO3lsWZYeMCY7/fRNBCF9h3sQuPKlTFOBAft4+6M4GxW3oVnwiO/X4Qc13vaesRhXexWfVfnJ6ZmbPBCJ2xL2H+Pvu1GGMfo/WSUNcECUVRx9pJcnFh/UV77sgdK6+X6iHDzJ2/7U5AgYd2zyasUzvt304D1phmcj4g5AcdODuloPhnJlGNva4In+HbzoT/DRO/0keOdnfV7OKuk4YIyys1uW+4XJwHFeDd9neJRhXNq4c9LpV8OUHL+PIVM8E5zMMEJivMaRme/M+OP9ez1sf/jA7+CK2R7cjDvWm048fUPmHvALHvHPM+7pPOFEz0Qunw2HXujvY9j+fuG1ZVnuuy01+axaEDCufMmPY/tMa/z82GM8qEq2JXztr37BeMxnMs8d+VGvLh99ZNOAu0sXvzPJ0n82/j0/+t/edOOAc3KXKZm1Bz8ujDg4991f4sAx1/if4MeX3TsymbjsgBG8ne3H7yu8LeKg8f7bXPtmpodwWxm2v19cxueL3XX+XR48yQPVHv090Fs2u2l1dNJxl3vZ4uFtkuKanj0B4wQ/TtXvbFoTtvBxv9NRviHeYskeznsyjNHv694v+u+2z/BMsiEetLs5ww/wz3rHFv9e79icfiwHv2iJf8vKMEpJxZ034irEuK1NnEnsPSjTdqzviNxV0snx/trL2KO9CuO5X3h2EXKfEJtzxIczB9bBk6Oeb6964BO3a4szTfHdXl79iy+37xmZ7WRXqcXBcrLjy+q5nskbdWjTzgO7d/pzU0736rpPPwqn/2fT8k6a4duMqzGWRx0JRqdclQ4Y523SoGmGMc6aTn137nXjLMnLt/m0SYYxCra2rvQM0qhDfeiSbev85BtXrXTt7oFcsmH+5qXeJjb7ezL13V7df9B5jZ8fOM73ycqXvRqrYZefgIZO8av7OAPQNxEwgg9fEd9eL+nkr8Jnn86cqOPmFvFnklad1B6GTPYqz3gomnxtGCETMO65G0SUpR08CRY+RlXDjqb7KpfBk7MyjFkBY1yFCp7t+fICDz4OPLfxSfbEf/PA76U/QPV1/huZckbmNzH+hMyycaZ3yumZQKiQDGOfYd72tpiAMd5+dtYmHtsv/qzBRwkYdkDjtsC9B8Ml93omNVe26MiP+mf1t894hnLxM15FfeKV+bM/447zKt+Vr3hWafVrje8ukjR4kn/nc91hCDL7P/58Ny2mS32dH8cHTcy9TnMGjvcAaM3clrVfTJPd0WPTEg/oB0/03+GIg6M7A9Xn/s3GuveGK2bBCZ9vOq9bLz9m79jkn13PAYnjVKId46YlfhzJbgOZSxwkduuTGQ2j92AP2Brq4fxfZobJaWjIDNrdnPjzWDsv8V1tJmCETBtqZRilZELwk27/0ZkTUHwlHGcSew32QACiXtLR88mq1z13FMkaP7EtmXmWcc1rfruvfqMLO+mk6dIlk1HrPSRzgojbBm5b71fEr9/lnTPSqr/jICju+LJru2dyhh8I40+MGnUnOufna+SdLZ4fV0svfMyD2+QAwdmSbQiT+yQOrAaOyx9c9B7sJ5D49ZJZK8hc4W5e6ie1scfC+OP8PULjtjgDxjYOGDctjTpYZB1u+g6Dz7/kWYQks6hj0kuNe9YOmeIH/s3LvE1TnN0dF3W4OPOa3O+ta/fGVV69h/iFT3xhsDcyjNlO+ELmJJ2rSrrPUA+ms3vG7gkYJ2Yyt9n7KpchU7yzy+pX/aIivjDMFTCm2fcMP9nf/QWo/q4HlGd+N1HuIX7xMe74zLaTF3iF/HbjIaKKDRgHjm+6L0cf7gHV4z/IZKuXPRfdxi0r0zfmqMaZ7qQe/eD9v/AA4d5/gwe/7sei4/J0KgE47IPe9vbZ//WOcHU1Te8uEjNrfIehbRu8t3acoYtvrjB0qh9zNi2hx841QGh8L+di7GnrGoofg7E52T2l43bocfZ45CF+Idi1l7d/TJN2P+44WIs/g1x3pVr4uE8LCRjjTOvQKY2PVyd9Gd57o3dsG3+8nwfXvp6pkm7OngB6ru/jbn0Ku9A78H1+YT7l9OaX3QsUMHZG29b7lWW/0Zl0+ro3/QQVD2CcbPDfd0TUfsQaV0nHGca+OU54bemQC/31Ny70tlJpB5BCJQPG2J4q6XU+/t6OzY3bw+XSf5QHL/GBce0bfiU94iCvAtm9o3E101szPfDL1cg7aeBYzwq9Xe3Vfs/dAodckBkWI5+4Wjq7Sho8o5f22Y06zMvee0jTZgZ9hvn7nP8Pv5AYF/WIP/0/fb1k26CB45p2esmujo71H5V7iIvRh/vBNR5+Y+hUP5g37PZODH2GZTJfvQbBRf/XdMDcfHoP9t9AqTKM4O0Kz73Bq/5zBVFmjcdi3LQEsExVdTKrNLyAICwOCBY/5b/n+GQYVxEXku2Iy3XGf/nyF/8FLvhV005YF/0ZPpho5zjueA8MqnoUHtxkD62T3Rmkdp23WY1rPJY9n6nWTarq5j2S174Oz//a21ZalbdfLNbY6XDK1zyruuIF/+4nB3zP1muQV2/P+XPm1pD5Mozgn+maud5U4r4vwzM3Zm4Tmrzf8MBxsGkJvbZHWbSWBowDE+u1dYax/z5e7RxnGON9GX9v93SwOq51bd77x7+HKPhNtrWOLXzcf+OFXFj1G+nlTt4PHrw26IgP+/8Toizv6/dEnSALqJIeMNaz5qujgHH04bmPe9m69fTaiOaO+3uJAsbOaM9QAKP8C9l3hAcKcRYRGv/fd4R/uXsN3PtV0uAH5cOjH+uUU9OXLVRctZvMSPTo5z3eXvyDd0o57EPNV3/36OfB39y7PHMbtwUdcVA0VI41rpZ+e6afGLIbcOcyaYb3OP3LJz2oOPtHza8TX8En90mcldr/PU2XT4qD6OEHNg0su1T59yC+Wo+r+sYe7WPVJb8vA8d6B4245/jmpZnMZ6FGHeYXNXP/7uv26Jtpm7VsVuuqaHoP9ixvHIzl63Xe3sYfD5c9nb839oAxXgUfggcM/Udnxh6NLgx29Bha2Hcp2S4wmX0efgB85snmvxtJU073phT57uLUf1Tj31W3nr7s6CMKO0nG5d242APF52+FH+7f+E4h1dfCEz/wO5k01753/7N9sPiZ34WX/+jlb+n358R/8yr48SfCIQUEncd8xr/HM7/jF1xpQcuYaX4cfuRb3uMfMrda3LTEs8I9+iUCxigoanHAOBaIfudtHTDGtQQLHvbM7oaFnlWLL0TjjHY8IkRLxRnhZFtcyGQYQ/DRJiaeVFiiwczHXo1vK5rLwPEeJMY3Vygkwxj3HF/5sjf/aq7DS5lSwNgZZY8dFZ/MeyVOXPH/1iWThes1qHGVdM0aPwj06Nu+5QWvwjvmM5mx3lorbr+UPFmb+Ylu7eserJ3zP4UdZA58n/feXfO6Zwi69vQTXu/BXgUVH/S3b/ShMyafUlgZJ83wnpOhwdtWFXKVGV/BJzOEk2b4CT6trRBksoT5qkr6jfQM38BxjQcvzzZgbGboj911fkIvOmA83Kdr52WyYPFJrb4uc2Joifi7vW6+T0uRYSzEfu/xKuTnb42G1En0Mo8CwNo+BQ6FMnB8pn1rdrA08pC2ydqnOe9/fbzBQg2e5N+hxU/DA1/35i+P/rfP27rah3XqN9ozcPd/1Z/PFzCaebX59o0eSMR3iGqJLlU+uPzH7mq+Zyx4m+fJp3lGe8iU9OYtcfmf/Zl//w96vx874guGeP9Hd1PqtX2lV3m3tNNh1x5ehdutd2FBT7GOvcw75bzyf36hErdfBH9/597ombvWiM9hcc/z7r29N3TchnHdfD8OFVIdHZt8SnoVvZlf7MXjVxaSYQTvbb30n378KjSjX2YUMHZGW6OAMW7vEVdzJYOn+P8+wzJZgbizQKx2TftXR8f6jYB3X9d2qflBE/yEk311PmiiDy/ygd8VPszEAed4YD33Ts8wDtsv85lNOMGrUFe/5rf+Cg3Nt1+MTZrh1XkX/LrwNkaHXAin/Hum1zJk2kc1Z/SRXh2Tb4zLOEiLs4v5xAfvNXOjAbxD/irpfAZN9A5HkKmyTd7nvLUZRoB1b3hnnOQQKuVk+qf8O/Dg1z1wTAaM0YVBbZ9xudfNVtU1kYVpxzbH+XTvU1gmNBZnRP/ySf/+Hn6xZ91WvAjP3ODB5Mfu9t/H3Du9mjnX8DaxUYf6WIV9R8J+eTp+Fcqs8EwpwLFRb/h87RdjfYb6b6equ98BZ/Ipfoxd92bTgLFhF/23vB6NsdmKYH/I5MwdTdrafu/2i9DHv+cX1MlRHMz8Jgqt/e0NyKqShsaDd8f3oG7uYrlYyc5dhQbbyexyBw0Ym+ljLhVpy0oPcOITR3wyT3YMiE/MyavX3oMbDx9Ts7o0J5+2YAaXzmx6wLr4z14tXUy7mr7D/QDy2p3eYy857M+RH4U5d8AtM/wk2L1v5u4jzenZHz5xf+HlAA+s47EVi9V7sPeOrcoTKMdBWtx+MZ/xx/mJufpab7ANjQftLkSXLtEdR55sPBTL0H29l3arAsYoY75uvmcX2zu71lJduvhA+Dcf59mxZMDYZwi896csX92dAkNGz3CtX1A2PS5TxQFjzWp4zw/9QuiN++G+r/jF18EXeJvV9/8v3HyiBwxp7QnBbwl3xrca31J0b5h8mg+Qf9D7m1/2zOj2fsMPyJRz4ePecWzfd/rj6IKs39a3YXQra1zO+oHXGrQHM5jxNfhjNKB8cnD+tjLpFL+YSF7E9huRCRhfv8tHj2hpT/J84oDRqgrP8MY1N32GFV/jUiaUYaxkIXgD23ULGt9xZMsKD/TiTgPxgMq9cmQYk1V/Taqk1+bu4dlR9BvZNGPZo1/LGmEf+F7PWNWsbnyrpxEHweXP+tX22nnRANTdWlfu9tS1R/4AKs5IN5dh7N4HTvuGtzV86if+XEsOkHEVebJTSNyLsTVBT/w937y0dO0XC9V/lHeOgcyQH7EjLmZnzyJ+f3HWuSNc5PWNOh+MPwGO+oRnJ0/+ivdw3lUL7/g3X27gOK8eft9Pm99ml6rSZJO7dIH331LY7VIPOMd7noMHOf338Xa8u7c3zjACRkPL2y/Ghu+f3hGntaa+K9P8J3lzgrbSd5jv+2SzqH6jPGBc9rwH20d/qu0vCofu6+e+fnk67eUSZxiTdyPqYJRhrGTzH4LbEr18D/mAH7i2rmg8EGicYUxWSe/JMI5o/Ny2RKeX2jXF3aKvkh1wjvdsJHiQmNRnqDekfvuxxtUyHc1B5/mJq5Dehodd5MOJxGNnFtrOJ2n/s2DR440/z7hqvjVtGHP1jC9nB5wDlz3b+o4J8R2POkKGsUsXHwdywNhMW8Fpn/A7C408tHE727izVqUx8wvMV/7PH+8JGBMXX22dOWtrZnDKf8AfLkhvMtCW+o30dotP/NDHZ5z2ibZ/DTPPGu/YVPg6fYf7SBWHXND25dlLFDBWssVPevXquf/jdyh46fd+d40tK5uOmwdNe0l36da4fUbvwX7nl/guD8nbAnZ2/UZ6r+glTze9S0qsrdvR7G3DpvqdRArRpQu86xq49T1+0dGSrO2EE70Hb1I8DmVrshXJ73kpxmBsiUKGzmnOuOM8U1dIwF8OsseG7NrDvw9dOtFpa8I7mgaM3Xp5dqt2beszjHvDvqd7U5e99VvrO9I7lrxxL5x8Vftllc/8TvHrXPSnti/HXtSJfnmd0NJZXq13+EWeXVz5Mtx/lQ/gm7zX6JApPrxBPAgzeHX1Jfc0rgbbM3j3xsy4aB25SrqtnfAFv/pXEO0mnOjti3bvaH7ZQk0+DS5/rrBbzOXTtbtXd+7c0jEyjG1lxEFw1ZLmlytnxdxDvhIkx2tNNusYOK7jBIywdy/M4gx6tz5wzL/uvdftBBQwVqr6Xd6jcNrH/XFVVzj7evhldJu7ZJV0t57eDijbuKy2asmAMW4T2RHaQ+0t+72rsHZKnUkhbcuKYda6YDHWa5AHjOXehlE6t0ETfHDqXbXeCS42cBxh+QvYwIK7PHUe8blt+ifyj3EqLaJOL5Vq1Rxvb5a8+8HYo+HIj/n/LRl3K/7xbdvgV7egbJp0THE7xs6UYZSOx8xvMTg564YFU9/NmuEntu4uKZVqzDQ47Zvwji+WuiQVRxnGSrVslk+z79MZt0ErdCzApOT9pF+/x9s4lnuja5Fc9owzqoBRytxp32z63GEf5PWNI1D9Tg5V3RQsthMFjJVq6XOems8e/673YO8E0xJxz+k3H4SXb4MTrtx7A3eLtKX4u6wMo4hIQVQlXamWzfIBottyvKc4K/PCbzwYPenLbbdtkb0prpJWhlFEpCAKGCtRzRq/9+zYo5tfthjd+2aGtDjj23vnHtIi7aGPAkYRkWKoSroSLX3Op9ntF1vLzDvL9B/ToQcfFeHwD/v3ODkmo4iI5KWAsRIte847pMS3VmtLH/6bZ2c66K2NRAC/5d7hHyp1KUREOgwFjJVo2WwPFttjyIWhrbw9mYiIiHQ4asNYiTYubnyHFhEREZFWUMBYibZv1Aj3IiIi0mYUMFaa3Tv9NlK9Bpa6JCIiIlIhFDBWmu0bfdpLGUYRERFpGwoYK822DT7VcCEiIiLSRhQwVpo9GUYFjCIiItI2FDBWmjhgVKcXERERaSMKGCvNdlVJi4iISNtSwFhp1OlFRERE2pgCxkqzbYPfFrB7n1KXRERERCqEAsZKEw/arXs9i4iISBtRwFhptm9Q+0URERFpUwoYK832TQoYRUREpE0pYKw02zaow4uIiIi0KQWMlWb7RmUYRUREpE0pYKw02zdCbwWMIiIi0nYUMFaSXdth93ZlGEVERKRNKWCsJBq0W0RERNqBAsZKsk23BRQREZG2p4CxkuzJMCpgFBERkbajgLGSbI8yjL1VJS0iIiJtRwFjJVGGUURERNqBAsZKsqcNozKMIiIi0nYUMFaS7Ruhqgd061XqkoiIiEgFUcBYSbZv9PaLZqUuiYiIiFQQBYyVRLcFFBERkXaggLGSKGAUERGRdqCAsZJs26CAUURERNqcAsZKogyjiIiItAMFjJUiBB+4W4N2i4iISBtTwFgpdm2D+jplGEVERKTNKWCsFBq0W0RERNqJAsZKodsCioiISDtRwFgptscZRgWMIiIi0rYUMFaKOMOoTi8iIiLSxhQwVortm3zac2ApSyEiIiIVSAFjpdi51ac9+pa2HCIiIlJxFDBWiroan3ZXwCgiIiJtSwFjpdhZA916Q5eqUpdEREREKowCxkpRtxV69Ct1KURERKQClV3AaGYXmdkTZrbZzGrMbLaZXW5mBZfVzCaYWSjw76Q823iXmf3DzDaY2TYze9XM/t3MerTdu21DO2tUHS0iIiLtomupC5BkZjcBlwE7gEeAXcBpwI3AaWZ2QQihoYBN1QC/SZl/IDAd2Ao8n6McXwGuA+qBamAjcDLw38DZZnZaCGFbgW9r76irUYcXERERaRdlEzCa2fl4sLgKOCmEMD96fgQwEzgP+Bzwk+a2FUJYB1yS8lr3Rf/+KYRQmzVvGnAtsA04NYTwbPR8X+Be4CTgO8D/K+Lttb+dNdBdVdIiIiLS9sqpSvpr0fSrcbAIEEJYDXw2enhVMVXTuZjZPsCZ0cNf5ljkKsCA6+JgMSpHDfBxoAG4zMwGtqYcba5uqzKMIiIi0i7KImA0szHAUUAdcHv2/BDCY8ByYCRwbCtf7hL8fb+WDAijcnQH3h09/EOOcrwNPAN0B85qZTnaltowioiISDspi4AROCKavhZC2J5nmVlZy7bUJdE0V3ZxP6A3sCGE8FY7l6NtqQ2jiIiItJNyCRgnRtPFKcssyVq2aGZ2MjAFz2T+LqUcS3LMa7NytAtlGEVERKSdlEvAGEc6tSnLRLcyoTU9Oz4RTe+KOsaUqhxtyhrqYfd2jcMoIiIi7aJsekm3NzPrD1wQPfxVO77OpcClACNGjKC6urq9XmqPHVs89l2wdDXL9sLrSfmoqanZK98xKU/a/52X9n3nVor9Xy4BY5y165OyTJz929rC1/gXvH3iMuDB9ipHCOEW4BaAadOmhRkzZhRd0GI984D3E5py4GFMOar9X0/KR3V1NXvjOyblSfu/89K+79xKsf/LpUp6UTQdn7LM2KxlixVXR9+aMvh3vO1x7ViONldVH/UTUhtGERERaQflEjC+GE0PMrNeeZaZnrVswczsQOAYIAC/Tll0HrAdGGxmk/Msc3RLy9Fe9gSMasMoIiIi7aAsAsYQwlLgBXx8wwuz50e9m8fgd4F5pgUv8cloOjMaSzFfOeqA+6OHF+coxyTgOLyX9b0tKEe76LpbGUYRERFpP2URMEauiabXmdmU+EkzGw78NHp4bbI62cyuMLN5ZvbbfBs1s27Ah6OHucZezHYtnon8qpnF2cT41oC/wj+zn4YQNhWwrb0ik2FUwCgiIiJtr2wCxhDCHcDN+N1c5pjZ3Wb2V2A+cCBwJ3Bj1mpD8cG209ocng0MBzYBfy2gHLPw2wP2Bp42s3+Y2Z+Bt4CTgWeBfy/4je0FasMoIiIi7alcekkDEEK4zMyeBC7Hg7MqvF3hr4CbUzqrpIk7u9wWQthRYDm+Z2avAF/E2072BN4G/gf4QQhhZwvK0W7UhlFERETaU1kFjAAhhNuA2wpc9mrg6maWOaeF5XgAeKAl6+5tasMoIiIi7alsqqSl5arqt4N1gW75OpiLiIiItJwCxgpQVb8duvcDs1IXRURERCqQAsYKUFW/XT2kRUREpN0oYKwAXXdvV/tFERERaTcKGCuAMowiIiLSnhQwVgBvw6iAUURERNqHAsYKUFW/Q2MwioiISLtRwFgB1IZRRERE2pMCxgqgNowiIiLSnhQwVgC1YRQREZH2pICxo9u9ky5htzKMIiIi0m4UMHZ0O2t82l2dXkRERKR9KGDs6Oq2+lQZRhEREWknChg7uj0ZRgWMIiIi0j4UMHZ0dVHAqHEYRUREpJ0oYOzodipgFBERkfalgLGji9swqkpaRERE2okCxo5uT4ZRAaOIiIi0DwWMHV2dOr2IiIhI+1LA2NGpDaOIiIi0MwWMHV3dVhqsG1R1K3VJREREpEIpYOzodtawu2uvUpdCREREKpgCxo6urob6KgWMIiIi0n4UMHZ0OxUwioiISPtSwNjR1W1VwCgiIiLtSgFjR6c2jCIiItLOFDB2dGrDKCIiIu1MAWNHpzaMIiIi0s4UMHZ0yjCKiIhIO1PA2NF9+K8s3+c9pS6FiIiIVDAFjB3d2Ols7z2q1KUQERGRCqaAUURERERSKWAUERERkVQKGEVEREQklQJGEREREUmlgFFEREREUilgFBEREZFUChhFREREJJUCRhERERFJpYBRRERERFIpYBQRERGRVAoYRURERCSVAkYRERERSaWAUURERERSKWAUERERkVQKGEVEREQklQJGEREREUmlgFFEREREUilgFBEREZFUChhFREREJJUCRhERERFJpYBRRERERFIpYBQRERGRVAoYRURERCSVAkYRERERSaWAUURERERSKWAUERERkVQKGEVEREQklQJGEREREUmlgFFEREREUilgFBEREZFUChhFREREJJUCRhERERFJVXYBo5ldZGZPmNlmM6sxs9lmdrmZtaisZlZlZp8xs8fNbL2Z7TCzpWZ2t5mdk2edsWZ2o5m9ZWY7zWydmT1oZu9p3bsTERER6Xi6lroASWZ2E3AZsAN4BNgFnAbcCJxmZheEEBqK2N4Q4H5gOrABeAaoBcYCpwOrgbuz1pkOPAAMBhYD9wIjgVOBd5rZt0II/9mKtykiIiLSoZRNwGhm5+PB4irgpBDC/Oj5EcBM4Dzgc8BPCtxeF+AuPFj8CXBVCGFHYn4/YELWOj2Bv+DB4g3Av4UQdkfzjseDx2+a2ZMhhIda/GZFREREOpByqpL+WjT9ahwsAoQQVgOfjR5eVUTV9KeB44F7QghXJoPFaLtbQwhzstY5D88+vgV8MQ4Wo+WfBr4TPfxmgWUQERER6fDKImA0szHAUUAdcHv2/BDCY8ByvGr42AI3e0U0vb6IokyPpo+FEHblmP+PaHqCmY0sYrsiIiIiHVa5VEkfEU1fCyFsz7PMLGCfaNmn0zZmZqOAg4F64Bkzmwp8EBiDt2V8DHgwhBCyVu0bTdfl2XT8vAFHAvellUNERESkEpRLwDgxmi5OWWZJ1rJpDomm6/Hq7O/R+L1eBTxtZueFENYkno//n5Rnu5MT/xdSDhEREZEOryyqpMlk9mpTlqmJpv0K2N7gxPR6vJr7QKA/3tv5dbx9Y3b196PR9D1RNXm2zyb+719AOUREREQ6vHLJMLa1OBDuCjwZQrgoMW+mmb0TeBM4ycxOCSHMBAghPGpmjwMnAQ+Z2RXAc8AI4AvAh/ChfroBOYf3MbNLgUsBRowYQXV1dVu/tyZqamr2yutI+dG+79y0/zsv7fvOrRT7v1wCxjh72CdlmTgLubWA7SWX+Xn2zBDCMjO7F7gAOAUftid2IfBX4ATg4axVfwycCEzD20I2EUK4BbgFYNq0aWHGjBkFFLd1qqur2RuvI+VH+75z0/7vvLTvO7dS7P9yCRgXRdPxKcuMzVo2zcI8/+daplFv5xDCGjN7Bz6w96nAEHyA77+HEGab2Ypo0ewheUREREQqUrkEjC9G04PMrFeentLTs5ZN8wbeHrIPHvDlMjSa1mTPiHpPPxT97WFmk4FReGeaFwooh4iIiEiHVxadXkIIS/EArDteJdyImZ2MD4mzCr+9X3Pb2wXcEz08Lcf2uuHtFAFmF1HUL0XTW0IIdUWsJyIiItJhlUXAGLkmml5nZlPiJ81sOPDT6OG1yXtJm9kVZjbPzH6bZ3sNwKVmdmZinSrgOnyInOXA35IrmdkhZtYn67muZvbvwL8CC8jc8UVERESk4pVLlTQhhDvM7GZ86Jo5ZvYw3iP5NHwImzuBG7NWGwrsh2ces7f3spldid9H+n4zew5Yhg/8PQnYDFyYo/r7i8CFZvYCHlD2wu8uMxyYD7wzhJA2/I+IiIhIRSk6YDQzA6bgQ80MBDbiA14vyHHnlKKEEC4zsyeBy4GTgSpgHvAr4OZkdrHA7d1gZnPwquRj8buzrMR7MV8TQliUY7U78UD0MLzd5A68TeT3gJuy70ktIiIiUukKChjNrBdwEfBe4B3kHrR6i5k9gQdcf0y5xV+qEMJtwG0FLns1cHUzy1QD1UW8/p34exARERERmgkYzWwg8HXgU8AA/B7KAc/SbQC24MHjEHx4mrOB9wA/MLOf41m8Te1UdhERERHZC/J2ejGzy/E2e1/Cq2WvB94NDAkhjAkhHBpCODGa7oMHjWfhg1vvAL4MzDezy9r5PYiIiIhIO0rrJX0DPrj1ucCYEMKXQwgP5ssYhhA2hRAeCCF8ER9k+334INs3tGmJRURERGSvSquSfn/Unq9oIYR64C7gLjN7X0u2ISIiIiLlIW+GsaXBYnttR0RERERKo5wG7hYRERGRMtTmAaOZjTGzQ9t6uyIiIiJSGmm9pOvN7Jd55v3VzK7Is+q3gRfbonAiIiIiUnppnV4s+svlfcCmti6MiIiIiJQftWEUERERkVQKGEVEREQklQJGEREREUmlgFFEREREUilgFBEREZFUChhFREREJFVzAePHovEYG/0BIWXeR9u/2CIiIiKyt6SNwwj5x2FsTmjheiIiIiJSZtICxol7rRQiIiIiUrbyBowhhMV7syAiIiIiUp7U6UVEREREUjXXhjGVmY0G3g0MA5YB94UQNrRFwURERESkPOQNGM3sQOAS4MUQwh9zzP8EcBPQPfH0FjP7WAjhrrYuqIiIiIiURlqV9PnAF4Fd2TPMbBrwv0APYDvwPLASGAD80czGt31RRURERKQU0gLGE/Bg8J4c864CqoA3gKkhhKOBcXgQ2Qu4rI3LKSIiIiIlkhYwTsGro3cknzSzbsBZ+FiLXwshrAAIITQAXwVqgNPap7giIiIisrelBYzDgCU5nj8C6AnsAB5IzgghbAFmAZPbqoAiIiIiUlppAWMPvHo525HR9OXs7GNkFdCntQUTERERkfKQFjCuxaulsx2PV0fPyrNeb0BD64iIiIhUiLSA8VngIDM7KX7CzPoD50QPH8mz3gF4llFEREREKkBawHgLYMBdZvZtM/s8UI0PnbMCuD97hWg4nanAnLYvqoiIiIiUQtq9pP9hZv8DfB74evS0AfXAZSGEJuMzAp+Ipg+3aSlFREREpGRSbw0YQrjSzB4GPggMx3tN3xJCyNd+cQzwd+AfbVpKERERESmZZu8lHUK4h9yDd+da9pOtLpGIiIiIlJW0NowiIiIiIgoYRURERCRd3ippM/tVK7YbVD0tIiIiUhnS2jBegg/QbS3YbgAUMIqIiIhUgGY7vQDP4T2f69q5LCIiIiJShtICxqfx2wAejd8i8I/Ar0MIL+yNgomIiIhIecjb6SWEcCJ+15ZrgW3A5cAsM3vJzK40s2F7qYwiIiIiUkKpvaRDCAtCCF8HxgPvBv6MB5HXA8vM7G9mdq6ZVbV/UUVERESkFAoaVie4B0MIHwJG4dnGl4D3An8DVpjZd9qtlCIiIiJSMkWPwxhC2BxCuDmEcAxwEHAvMAz4dFsXTkRERERKr5Be0k2YWX/gQ8DHgenR05vaqEwiIiIiUkYKDhjNzIB34uMzvhfoAdTj95m+Fbi77YsnIiIiIqXWbMBoZlPxIPEjwGh8IO/X8CDxdyGENe1YPhEREREpsbRbA16KB4rH4EHiRuBm4NYQwuy9UjoRERERKbm0DOPP8Fv8zcaziXcCOwHMbHBzGw4hbGh98URERESk1Appwzgt+ruxiO2GArctIiIiImWuuaDOWrjdlq4nIiIiImUmb8AYQih6jEYRERERqTwKCkVEREQklQJGEREREUmVN2A0s25t8QJttR0RERERKY20DOObZvbR6A4vRTN3CfBmi0omIiIiImUhLWCsAX4NzDezfzezcYVs0MzGm9k3gPnAr4AtrS+miIiIiJRK2rA6hwGXAVcD3wa+ZWYLgGeA14H1eDDYHxgCHAgcB0zGh9VZD1yBDwAuIiIiIh1U2rA6DcCNZvZr/BaBlwEHAPviA3Nni6uuXwF+Cvw+hLCtTUsrIiIiIntds3djCSHUAjcBN5nZFGAGcDgwHBgAbALWAC8AM0MIi9qnqCIiIiJSCkXdvi+EsABY0E5lEREREZEypHEYRURERCSVAkYRERERSaWAUURERERSlV3AaGYXmdkTZrbZzGrMbLaZXW5mLSqrmVWZ2WfM7HEzW29mO8xsqZndbWbn5FlnjJndYGZvmNn2aJ35ZvYzM5vUuncoIiIi0rEU1emlvZnZTfjwPTuAR4BdwGnAjcBpZnZBNNxPodsbAtwPTAc24GNI1gJjgdOB1cDdWescATwKDASWAQ9Gs6YB/wpcbGZnhhCebtm7FBEREelYyiZgNLPz8WBxFXBSCGF+9PwIYCZwHvA54CcFbq8LcBceLP4EuCqEsCMxvx8wIceqN+HB4s+By0MIu6Llu+GDkH8CuBkf2FxERESk4pVTlfTXoulX42ARIISwGvhs9PCqIqqmPw0cD9wTQrgyGSxG290aQpiTfM7MeuJ3qwH4zzhYjJbfBfxH9PBQM+tdYDlEREREOrSyCBjNbAxwFFAH3J49P4TwGLAcGAkcW+Bmr4im1xdRlHpgdwHL1QLbi9iuiIiISIfVJgGjmfU1s6PMbHgLN3FENH0thJAvEJuVtWxaeUYBB+MB4DNmNtXMvmFm/2tm15jZu8zMsteLsoiPRA//K6qGjrfZDb+nNsAvQwi5bo8oIiIiUnEKbsNoZqcAFwI/DyG8mHj+ErzdX0+gwcyuCyH8R+6t5DUxmi5OWWZJ1rJpDomm6/Hq7O/R+L1eBTxtZueFENZkrXsZ8ABepf1uM5sdPT8dGAT8GPhKAWUQERERqQjFZBg/hXf4WBQ/YWYTgVuAXniVMcDXzOy0IsvRN5rWpixTE037FbC9wYnp9Xg194FAf+BU4HW8fWOu6u+3o3n3A2OA90V/+wBzgSeSbRtFREREKl0xvaSPBl4OIWxMPPeRaBtfDSF838ymAf/Es3SP5NjG3hIHwl2BJ0MIFyXmzTSzdwJvAieZ2SkhhJnxTDM7HvgrsAV4LxAPn3MC8EPgL2b2nyGEb+V6YTO7FLgUYMSIEVRXV7fdu8qjpqZmr7yOlB/t+85N+7/z0r7v3Eqx/4sJGIcBr2Q9dyo+ZuKNACGE2Wb2NMUPORNnD/ukLBNnIbcWsL3kMj/PnhlCWGZm9wIXAKfgw/ZgZgOBO6NyHB9lG2N/N7PX8M/gG2b2x2Rv7sS2b8GzrkybNi3MmDGjgOK2TnV1NXvjdaT8aN93btr/nZf2fedWiv1fTJV0b3wgbWDPOIfTgOeyOqosBUYVWY5F0XR8yjJjs5ZNszDP/7mWGZl47j14YPzPrGARgBDCAuBZPNCeUUA5RERERDq8YgLGNcCUxONj8SDyqazlelD8kDNxJ5qDzKxXnmWmZy2b5g0y7SGH5FlmaDStSTw3LppuTtn2pmg6OGUZERERkYpRTMD4DHCEmX3AzPoD/w4E4KGs5Q4AVhRTiBDCUuAFoDveE7sRMzsZ74CyKipHc9vbBdwTPWzSAScaIuek6OHsxKy43Eclh9TJWu+o6GG+zKWIiIhIRSkmYPw+Pqj1H4GNwLuBF0MI1fEC0QDcB9A4CCvUNdH0OjPbk8mMxnb8afTw2uS9pM3sCjObZ2a/zbO9BuBSMzszsU4VcB0wGe/Z/bfEOvcD2/BM44/MrEdivR7A/+BV4xvJ3GNaREREpKIV3OklhPCcmZ2N38JvOPAcmdv5xT6IV+dmZx0L2f4dZnYzPm7iHDN7GG8zeRo+HM6dRJ1rEoYC++GZx+ztvWxmV+L3kb7fzJ4DluEDf0+Kynlhsv1lCGGNmV0G/BK4HDjPzF6IZh+Ft83cCXwihJBWbS0iIiJSMYrpJU0I4SFSgsEQwg/xoWdaJIRwmZk9iQdrJwNVwDzgV8DNyexigdu7wczmAF/C21weCazEezFfE0JYlGOd30TrXAm8AzgjmrUcDySvDyHMLf7diYiIiHRMRQWMe0MI4TbgtgKXvRq4upllqoHqIsvwAvDRYtYRERERqVQFt2E0s+5mNtzMemY939fM/tvM7jazG8xsbL5tiIiIiEjHU0yG8RvA14ETiXoqR2MxPo4P1G3RcueZ2WEhhPVtWVARERERKY1iekmfBiwPISSHtTkPOBx4Fb/X9N+A0cBn2qqAIiIiIlJaxQSME/ABsZPei4/F+OEQwq/wMRRX4oGkiIiIiFSAYgLGwcDqrOeOBxaHEOYARL2YnyVzxxQRERER6eCKCRh3AQPiB9GA2pOAJ7OW2wb0bX3RRERERKQcFBMwvgmckOglfT5eHZ0dMI7C7zstIiIiIhWgmIDxdmAg8LiZXY/fXq8OvwMLsOe2e0cCC9quiCIiIiJSSsUMq/Mj/K4npwDTgHrgyhBCMpv4Trza+vE2K6GIiIiIlFQx95LeaWan4+MwjgBeCCG8nbXYDuD/AXe1XRFFREREpJSKvZd0AJ5ImT8TmNnaQomIiIhI+WjxvaTNzIAh0cMN0ZA6IiIiIlJhiun0AoCZnWFmDwI1+LiMq4GtZvaAmZ3R1gUUERERkdIqKmA0s/8CHsA7v/TCh9UJ0f/vBB4ws6vbuIwiIiIiUkIFB4xm9i7gG8B2fEid/fBAsVf0/3X4oN3fMLMz276oIiIiIlIKxWQYP4cPpXNWCOFrIYT5IYRd0d/8EMLXgPfgGcfPtUdhRURERGTvKyZgPBp4KoSQd4zFaN4TwDGtLZiIiIiIlIdiAsZ+wLICllsRLSsiIiIiFaCYgHENcGgByx0MrG1ZcURERESk3BQTMFYDB5nZF/ItYGafAw4BHm1luURERESkTBQzcPe1wIXA9Wb2fuC3wEK8k8sk4KP4bQN34D2mRURERKQCFHMv6blm9kHgd8A78OAwyYCtwEdCCHPbrogiIiIiUkrF3kv6LjObClwKnATsE81aDjwG/DyEsLptiygiIiIipVT0vaSjgPDb+eab2QigRwhhSWsKJiIiIiLloeh7SRfgTuDtdtiuiIiIiJRAewSM4O0ZRURERKQCtFfAKCIiIiIVQgGjiIiIiKRSwCgiIiIiqRQwioiIiEgqBYwiIiIikirvOIxmdlILt9m/heuJiIiISBlKG7i7Gr9PdLGsheuJiIiISBlKCxiXoMBPREREpNPLGzCGECbsxXKIiIiISJlSpxcRERERSaWAUURERERSKWAUERERkVQKGEVEREQklQJGEREREUmlgFFEREREUilgFBEREZFUChhFREREJJUCRhERERFJpYBRRERERFIpYBQRERGRVAoYRURERCSVAkYRERERSaWAUURERERSKWAUERERkVQKGEVEREQklQJGEREREUmlgFFEREREUilgFBEREZFUChhFREREJJUCRhERERFJpYBRRERERFIpYBQRERGRVAoYRURERCSVAkYRERERSaWAUURERERSKWAUERERkVQKGEVEREQkVdkFjGZ2kZk9YWabzazGzGab2eVm1qKymlmVmX3GzB43s/VmtsPMlprZ3WZ2TtayM8wsFPg3rm3esYiIiEh561rqAiSZ2U3AZcAO4BFgF3AacCNwmpldEEJoKGJ7Q4D7genABuAZoBYYC5wOrAbuTqyyCvhNyiaPBg4A3gKWFloOERERkY6sbAJGMzsfDxZXASeFEOZHz48AZgLnAZ8DflLg9roAd+HB4k+Aq0IIOxLz+wETkuuEEOYBl6Rsc270769CCKGQcoiIiIh0dOVUJf21aPrVOFgECCGsBj4bPbyqiKrpTwPHA/eEEK5MBovRdreGEOYUWjgzOw7PLtYDtxa6noiIiEhHVxYBo5mNAY4C6oDbs+eHEB4DlgMjgWML3OwV0fT6tigj8Ilo+kAIYUUbbVNERESk7JVLlfQR0fS1EML2PMvMAvaJln06bWNmNgo4GM8GPmNmU4EPAmPwtoyPAQ8WWq1sZr2j9QF+Wcg6IiIiIpWiXALGidF0ccoyS7KWTXNINF2PV2d/j8bv9SrgaTM7L4SwpoDtXQj0A9YA9xSwvIiIiEjFKIsqaaBvNK1NWaYmmvYrYHuDE9Pr8WruA4H+wKnA63j7xibV33nE1dG/DSHsKnAdERERkYpQLhnGthYHwl2BJ0MIFyXmzTSzdwJvAieZ2SkhhJn5NmRmU4CTooe/au6FzexS4FKAESNGUF1d3YLiF6empmavvI6UH+37zk37v/PSvu/cSrH/yyVgjLOHfVKWibOQWwvYXnKZn2fPDCEsM7N7gQuAU/Bhe/KJs4vPhBBeb+6FQwi3ALcATJs2LcyYMaOA4rZOdXU1e+N1pPxo33du2v+dl/Z951aK/V8uVdKLoun4lGXGZi2bZmGe/3MtMzLfRsysCvho9FCdXURERKRTKpeA8cVoepCZ9cqzzPSsZdO8QaY95JA8ywyNpjV55gOciffMrgH+r4DXFREREak4ZREwhhCWAi8A3fEeyY2Y2cn4kDir8Nv7Nbe9XWR6M5+WY3vdyLRLnJ2yqU9G0z+HENICSxEREZGKVRYBY+SaaHpd1NEEADMbDvw0enht8l7SZnaFmc0zs9/m2V4DcKmZnZlYpwq4DpiMDwb+t1yFMbOhwDnRQ1VHi4iISKdVLp1eCCHcYWY34+MmzjGzh4FdeIawP3AncGPWakOB/fDMY/b2XjazK/H7SN9vZs8By/CBvycBm4ELUwYK/wjQDZgXQkgdKFxERESkkpVThpEQwmXAxXj19Ml4G8IF+G3+zg8h1Be5vRvwcRfvA6YA5+JB8i3A4SGEtOrtj0fTZofSEREREalkZZNhjIUQbgNuK3DZq4Grm1mmGqhuQTkOLXYdERERkUpUVhlGERERESk/ChhFREREJJUCRhERERFJpYBRRERERFIpYBQRERGRVAoYRURERCSVAkYRERERSaWAUURERERSKWAUERERkVQKGEVEREQklQJGEREREUmlgFFEREREUilgFBEREZFUChhFREREJJUCRhERERFJpYBRRERERFIpYBQRERGRVAoYRURERCSVAkYRERERSaWAUURERERSKWAUERERkVQKGEVEREQklQJGEREREUmlgFFEREREUilgFBEREZFUChhFREREJJUCRhERERFJpYBRRERERFIpYBQRERGRVAoYRURERCSVAkYRERERSaWAUURERERSKWAUERERkVQKGEVEREQklQJGEREREUmlgFFEREREUilgFBEREZFUChhFREREJJUCRhERERFJpYBRRERERFIpYBQRERGRVAoYRURERCSVAkYRERERSaWAUURERERSKWAUERERkVQKGEVEREQklQJGEREREUmlgFFEREREUilgFBEREZFUChhFREREJJUCRhERERFJpYBRRERERFIpYBQRERGRVAoYRURERCSVAkYRERERSaWAUURERERSKWAUERERkVQKGEVEREQklQJGEREREUmlgFFEREREUilgFBEREZFUChhFREREJJUCRhERERFJVXYBo5ldZGZPmNlmM6sxs9lmdrmZtaisZlZlZp8xs8fNbL2Z7TCzpWZ2t5mdk7JeLzP7ipnNMrNNZrbNzBaa2e1mdkLL36GIiIhIx9K11AVIMrObgMuAHcAjwC7gNOBG4DQzuyCE0FDE9oYA9wPTgQ3AM0AtMBY4HVgN3J1jvYnAP4ApwEpgJrAbGA+8D3gZeKol71FERESkoymbgNHMzseDxVXASSGE+dHzI/CA7Tzgc8BPCtxeF+AuPFj8CXBVCGFHYn4/YEKO9foADwGTgKuAH4QQ6hPzhwBDin+HIiIiIh1TOVVJfy2afjUOFgFCCKuBz0YPryqiavrTwPHAPSGEK5PBYrTdrSGEOTnW+w9gMnBTCOG6ZLAYrbc+hPBmgWUQERER6fDKImA0szHAUUAdcHv2/BDCY8ByYCRwbIGbvSKaXl9EObrjgWZR64mIiIhUsnKpkj4imr4WQtieZ5lZwD7Rsk+nbczMRgEHA/XAM2Y2FfggMAZvy/gY8GAIIWStehRe3bw8hLDQzI7Eq8KH4+0d/xFCeLLYNyciIiLSkZVLwDgxmi5OWWZJ1rJpDomm6/Hq7O/R+L1eBTxtZueFENbkWG+5mf0A+GLWdr9hZncCHw4h1BZQDhEREZEOryyqpIG+0TQtCKuJpv0K2N7gxPR6vJr7QKA/cCrwOt6+Mbv6O17vCDxY/DHeU3oQ8F68Wvx9wE8LKIOIiIhIRSiXDGNbiwPhrsCTIYSLEvNmmtk7gTeBk8zslBDCzKz1ugG/DyH8v8R6d5nZCuA54CNm9q0QwlvZL2xmlwKXAowYMYLq6uo2e1P51NTU7JXXkfKjfd+5af93Xtr3nVsp9n+5BIxx9rBPyjJxFnJrAdtLLvPz7JkhhGVmdi9wAXAKPmxPIevNNrPngWnAyUCTgDGEcAtwC8C0adPCjBkzCihu61RXV7M3XkfKj/Z956b933lp33dupdj/5VIlvSiajk9ZZmzWsmkW5vk/1zIj22A9ERERkYpVLgHji9H0IDPrlWeZ6VnLpnmDTHvIfINsD42mNYnnktsuZj0RERGRilUWAWMIYSnwAtAduDB7vpmdjA+Jswq/vV9z29sF3BM9PC3H9roBJ0UPZyfWWw48m7LeIODI7PVEREREKllZBIyRa6LpdWY2JX7SzIaT6ZV8bfJe0mZ2hZnNM7Pf5tleA3CpmZ2ZWKcKuA6/m8ty4G9Z630nmn7dzKYl1usJ3AwMAJ6ngMBVREREpBKUS6cXQgh3mNnN+LiJc8zsYWAXnunrD9wJ3Ji12lBgPzzzmL29l83sSvw+0veb2XPAMnzInEnAZuDC7IHCQwh3m9kP8WF1njazf+LjOR4NjMaDzA/lGPRbREREpCKVU4aREMJlwMV49fTJwJnAAvw2f+dn39e5gO3dgI+7eB8+nuK5eJB8C3B4CCFnljCE8CXgfOBJfDDvs4Bt+JiORyTvdS0iIiJS6comwxgLIdwG3FbgslcDVzezTDVQ3YJy/BX4a7HriYiIiFSassowioiIiEj5UcAoIiIiIqkUMIqIiIhIKgWMIiIiIpJKAaOIiIiIpFLA2MFt3r6Lbbs0JKSIiIi0HwWMHdzx1zzC3xfUlboYIiIiUsEUMHZw/Xp2Y9vuUpdCREREKpkCxg6ub8+ubN+tKmkRERFpPwoYO7h+ChhFRESknSlg7OD69ezGdlVJi4iISDtSwNjB9evRlW3KMIqIiEg7UsDYwfXr2ZUdyjCKiIhIO1LA2MH166kMo4iIiLQvBYwdXL+e3airh131DaUuioiIiFQoBYwdXN8eXQGo3al6aREREWkfChg7uH49PWDcqoaMIiIi0k4UMHZw/Xp2A2DLjl0lLomIiIhUKgWMHZwyjCIiItLeFDB2cHHAWKOAUURERNqJAsYOLq6S3rpTVdIiIiLSPhQwdnBxL2lVSYuIiEh7UcDYwakNo4iIiLQ3BYwdXM9uVXQ1BYwiIiLSfhQwVoBe3WCrhtURERGRdqKAsQL06mrKMIqIiEi7UcBYAXp1NWp0a0ARERFpJwoYK0DvrqqSFhERkfajgLEC9FSVtIiIiLQjBYwVoLcCRhEREWlHChgrQC9VSYuIiEg7UsBYAeJOLyGEUhdFREREKpACxgrQqxs0BKitqy91UURERKQCKWCsAL27GgA1ascoIiIi7UABYwXoGQWMascoIiIi7UEBYwXo3dWnW5RhFBERkXaggLEC9FKGUURERNqRAsYKsKcNo24PKCIiIu1AAWMF6BlVSWvwbhEREWkPChgrQO9uqpIWERGR9qOAsQL0qAIzDasjIiIi7UMBYwXoYkbf7l3VS1pERETahQLGCtGvZ1e1YRQREZF2oYCxQvTr2U1tGEVERKRdKGCsEH17dtWwOiIiItIuFDBWCFVJi4iISHtRwFghVCUtIiIi7UUBY4XopyppERERaScKGCtEvx4aVkdERETahwLGCtGvZ1fqdjewc3d9qYsiIiIiFUYBY4Xo17MbAFu2K8soIiIibUsBY4XYb2Q/AGa+sabEJREREZFKo4CxQhwzcTBTR/Tl1qcWEUIodXFERESkgihgrBBmxiXHT2Tuyi3MXryx1MURERGRCqKAsYK874jR9O/ZlVufWlTqooiIiEgFUcBYQXp378q/HD2OB15bxYpN20tdHBEREakQChgrzEeOHU8IgRseXaC2jCIiItImFDBWmLGDe/Ox4yfwx+eWcNVf5rC7vqHURRIREZEOrmupCyBt75tnH0jfHl254dEFrN66g6+cuT8HjOqHmZW6aCIiItIBKWCsQGbGF9+5HyP69+S/7n6Ns954gknD+nDSvsOYOLQP4wb3pn+vbvTpUUWf7l3p06MrfXpU0b2qi4JKERERaUIBYwX78LHjOeuQUTzw6irufnkFf569lG11+W8d2LWL0bt7FX16dKVXtyp6dquiZ7cu9Opetedxr25VdK3qQheDqi5GFzPMoMqMqiqjaxejqkuXaOp/XbsYZoYBXcwD2i4GXaJ5XczoWuXrVVnj9apy/HXt4kFtCBCAEAINASDsec7w1zGDLtHrGf4Y2FNuSzzv6wCJx3uWS6xr0XuIl0+uT/SYPduKno/K0/hxPD8RpFv2vPR1d9YHttfVkyvOz95+odtMzhMREQEFjBVvcJ/uXHTMOC46ZhwhBNbW7GTphu1s3bGLbXX11Ozczbadu6mtq6d25+49z+3YVc+OXQ3s2FXP9l31bKzdtef/3Q2BhoZAQxSoNTQE6kPY8/zuBnW22aseeqDdX6JVwW+eZZrbZu5tFB/8kvV6uaSFx+nr5Z+Ztl58IdIlukCKLzii6x7iX1AIIboogkDmd2X4RdD27dvp83z1nguk3GUsrnwtfU+5l89fpi5dMu+DrAvK+GItJC4C48+iWMVe+hRzsVT8totYtpmtb9q8nZ/Oe6bFhSlm8WLL3aVL5rvtF+z+7Y73ZUNovF+bvp4ltpe/LE3nNV0vTgIU+z7K0agBPfnWew8u2esrYOxEzIzh/XoyvF/Pdn2dOOO3u6GBhgbY1dDgB4foILEn0AyB+obM3+6Gxo/rQ6C+oYHd9fH/0XL1IXo/2dm+TCYxkHkNAtQ3hEYnnT3lIXMyzj6Axc83NGSdsJos3/jxnpVJnvgzn02u5xs/1/gAumddQtZjePutt5g4aXJiG42XSe6T7HVzbTvXMnnfS47y5CszTV43vTwFvZdmypNvu03ln5m2Xuq8ZrYZnzT9wgvqExvbkx2PH1vj55LfxVWrdjJ0eP+8byFfOfKVvSXvKe+28m0nURvQEL2PhpDZr3Ew0RACRpcmNQHtqZiBJYoNX4vadgHLVkW1PO1elmKXDw001EfH3BAfuzM1OJlaG/ZcKCT3a67fb66Z2fPyHTtyHZ86qi4lDnjLLmA0s4uAzwKHAlXAPODXwM0hhKK7/JpZFfBp4CLgIKAPsBZ4CbglhHB31vK3Ah9L2eQbIYT9iy1HZ2Jm0cGsCoBeVJW4RJWrOixlxozJzS8oFam6upoZM44sdTGkBHzfH1vqYkgnUlYBo5ndBFwG7AAeAXYBpwE3AqeZ2QXFBI1mNgS4H5gObACeAWqBscDpwGrg7jyrPwUsyPH8ykJfX0RERKQSlE3AaGbn48HiKuCkEML86PkRwEzgPOBzwE8K3F4X4C48WPwJcFUIYUdifj9gQsomfhFCuLXoNyIiIiJSYcpp4O6vRdOvxsEiQAhhNV5FDXBVFAgW4tPA8cA9IYQrk8FitN2tIYQ5rS20iIiISKUri4DRzMYARwF1wO3Z80MIjwHLgZFAoY02roim17dFGUVEREQ6q3Kpkj4imr4WQtieZ5lZwD7Rsk+nbczMRgEHA/XAM2Y2FfggMAZvy/gY8GBIv9nyKWZ2KNAXb+v4JPBQSzreiIiIiHRk5RIwToymi1OWWZK1bJpDoul6vDr7ezR+r1cBT5vZeSGENXm28dEcz801s39RVbaIiIh0JmVRJY1n8cB7MOdTE037FbC9wYnp9Xg194FAf+BU4HW8fWOT6m98uJ3PR8v3BUYDZwMvR889bGb7FFAGERERkYpQLhnGthYHwl2BJ0MIFyXmzTSzdwJvAieZ2SkhhJnxzBDCj7O2VQvca2YP4VXZx+IddK4gBzO7FLgUYMSIEVRXV7f+3TSjpqZmr7yOlB/t+85N+7/z0r7v3Eqx/8slYIyzh31SlomzkFsL2F5ymZ9nzwwhLDOze4ELgFPwYXtShRDqzOwa4O/AWSnL3QLcAjBt2rQwY8aMAorbOj6Aa/u/jpQf7fvOTfu/89K+79xKsf/LpUp6UTQdn7LM2Kxl0yzM83+uZUYWsL3YvGiqKmkRERHpNMolYHwxmh5kZr3yLDM9a9k0b5BpDzkkzzJDo2lNnvm5xNsqZh0RERGRDq0sAsYQwlLgBaA7cGH2fDM7GR8SZxV+e7/mtrcLuCd6eFqO7XUDTooezi6iqB+IprOKWEdERESkQyuLgDFyTTS9zsymxE+a2XDgp9HDa5PjIJrZFWY2z8x+m2d7DcClZnZmYp0q4DpgMj4Y+N8S8w43s7OjZUg839XMvoj3ngb4UUvfpIiIiEhHUy6dXggh3GFmN+PjJs4xs4eBXXiGsD9wJ3Bj1mpDgf3wzGP29l42syvx+0jfb2bPAcvwgb8nAZuBC7MGCp+AB5AbzOwFYA1eDX0IPrxOA/CVEMKDbfCWRURERDqEsgkYAUIIl5nZk8DlwMlAFd7R5FfAzcXeZSWEcIOZzQG+hA+HcySwEu/FfE0IYVHWKi/jAebR+JiL7wACHmj+GrgphPB8y96diIiISMdUVgEjQAjhNuC2Ape9Gri6mWWqgeoCt7cQuLKQZUVEREQ6i3JqwygiIiIiZUgBo4iIiIikUsAoIiIiIqkUMIqIiIhIKgWMIiIiIpJKAaOIiIiIpFLAKCIiIiKpLIRQ6jJULDNbCyzeCy81FFi3F15Hyo/2feem/d95ad93bu21/8eHEIblmqGAsQKY2ewQwrRSl0P2Pu37zk37v/PSvu/cSrH/VSUtIiIiIqkUMIqIiIhIKgWMleGWUhdASkb7vnPT/u+8tO87t72+/9WGUURERERSKcMoIiIiIqkUMHZQZnaRmT1hZpvNrMbMZpvZ5WamfdrBmdmtZhZS/ublWa9L9B2YHX0nNkffkQ/t7fcg+ZnZfmb2BTP7vZnNM7OGaL9eUMC6Lfrdm9m7zOwfZrbBzLaZ2atm9u9m1qPt3pkUoiX7v6XHhGhdHRfKgJl1M7PTzOyH0b7YYmZ1ZrbczO4wsxnNrF/y337XYleQ0jOzm4DLgB3AI8Au4DTgRuA0M7sghNBQwiJK23gKWJDj+ZXZT5hZFfBX4FxgC/APoAf+vbjNzI4NIXyhHcsqhfssUPS+aOnv3sy+AlwH1APVwEbgZOC/gbPN7LQQwraWvRVpgRbt/0jBxwTQcaHMnAw8FP2/CngcqAUOBM4Hzjezb4cQvpm9Ytn89kMI+utAf9EXK+AHiH0Tz48A5kbzvlDqcuqvVfv41mg/XlLEOl+M1nkNGJF4ft/o4BSA95b6vekvAHwK+B7wAWBydCAPwAUp67Todw9MAxrwE9Mxief7Ao9F6/2o1J9JZ/pr4f4v+pgQrafjQpn8AacCdwDvyDHvg8DuaH+ckjWvbH77Jf8Q9Vf0l252tKM/mmPeyYkvVpdSl1V/Ld7HRZ0cgCpgdbTOSTnmfyya91yp35v+cu6/QgKGFv3uoxNUAL6ZY71JeOZhJzCw1J9DZ/1rr4BRx4WO9Qf8Itofv8x6vmx++2rv1oGY2RjgKKAOuD17fgjhMWA5MBI4du+WTkroOGA4sCyE8HiO+bfjVRjTzWyfvVoyabWW/u7NrDvw7ujhH3Ks9zbwDNAdOKvNCy6lpuNCx/JiNB0TP1Fuv30FjB3LEdH0tRDC9jzLzMpaVjquU8zsejO7xcy+bWZn5mngHO/rWTnmEbyNymvRw8PboZzSvlr6u98P6A1sCCG8VcR6Ur4KPSaAjgsdzb7RNNketax+++r00rFMjKaLU5ZZkrWsdFwfzfHcXDP7lxDCnMRzhX4vDkffi46opb/7iVnzCl1PylehxwTQcaHDMLORwCXRw78kZpXVb18Zxo6lbzStTVmmJpr2a+eySPt5Cfg83nuuLzAaOBt4OXru4awqJH0vKltL96++F5XjJYo7JoD2f4dgZl2B3wMDgEdCCHcnZpfVb18ZRpEyE0L4cdZTtcC9ZvYQ3rvtWOBrwBV7uWgiUgI6JlS0n+FD5CwFPlzisqRShrFjia8I+qQsE19ZbG3nssheFkKoA66JHiYbKut7Udlaun/1vahwKccE0P4ve2b2E+CT+BBHp4UQVmUtUla/fQWMHcuiaDo+ZZmxWctKZYnv6JCsfloUTfW9qEyLommx+zf+f1yR60nHkuuYADoulDUz+yHezGAtHizOz7HYomhaFr99BYwdS9zt/iAz65VnmelZy0plGRJNaxLPvRBNp5ODmfUGDo4e6nvR8bT0dz8P2A4MNrPJedY7Osd60rHkOiaAjgtly8y+B/wbsB44PYQwN8+iZfXbV8DYgYQQluIHge7AhdnzzexkfAynVfgYS1J5PhBNk0NlPINfpY4xs5NyrHMh0A2YFUJY3s7lkzbW0t99VF15f/Tw4hzrTcLH6qsD7m3zgsvekuuYADoulCUzuxb4Mn6bvjNCCK/kW7bsfvulHt1cf0WPBn8BmZHdpySeH46PqaVbA3bgP3yIi7OBqqznu+K3+aqP9vGZWfO/ROYWYMMTz+8bfVd0C7Ay/aOwO3206HePZx/i24MdnXi+b+J1f1Tqz6Az/zW3/1t6TIiW0XGhjP7wezgHPFg8qsB1yua3b9EGpAMxs5/iN7DfATxM5kbk/YE78QNPfckKKC1mZu8D/gZswK8s1+BVTofgQ2k0AFeFEL6ftV5VtN45wBb8BvXdgNOBnsANIYTP7513IWnM7Ejgp4mnDsSHtpiP73cAQgjHZq3Xot+9mX0FuA4PLB4FNuG3FBsOPAucGnwQZ9kLit3/LT0mROvquFAmzOxc4O/Rw9lkBk3PNi+EcG3WumXx21fA2EGZ2UXA5fhBowpvs/Ar4OYQQkMpyyYtZ2YTgS/g7UvG4yeGACwDngBuCiE8n2fdLsBlwMeB/fGDxCvAT0MIt7V/6aUQZjYDmNncciEEy7Fui373ZvYuPBs1DQ8U3gZuA34QQthZ9JuQFit2/7fmmBCtr+NCGTCzS4BfF7DoYyGEGTnWL/lvXwGjiIiIiKRSpxcRERERSaWAUURERERSKWAUERERkVQKGEVEREQklQJGEREREUmlgFFEREREUilgFBEREZFUChhFRFKY2SIzCwX8zSh1WQthZldH5b261GURkY6ja6kLICLSQTwIrEqZnzZPRKRDU8AoIlKYa0MI1aUuhIhIKahKWkRERERSKWAUEWlDZjYhaiO4yMy6mtlVZva6me0ws9Vm9hszG5ey/kFm9lszW2pmO81snZndZ2bvbuZ1zzSzv5rZCjOrM7NVZvaUmX3VzHrlWWeEmf2vmS2LXmuhmV1rZj1zLFtlZp8xs6fNbHP0GqvN7AUz+6GZDSv+0xKRjkIBo4hI+/k/4L+AJcCdwE7go8AsM9sve2EzOxd4HvgIsBn4CzAXOBO4z8y+nWMdM7ObgQeA84Dl0XovA2OBa4EROco2Nnqts4FngGpgOPBV4M85lv8lcDNwOPAscEf0GgOAfwMmp34SItKhqQ2jiEj7GA/0Ao4IIcwFMLPueOD1YeB3wNHxwmY2MnquB/DFEML1iXkzgHuB/zCzJ0MIDyZe5wvAZ4DVwPtCCP9MrGfAKcDGHOX7BPAL4PIQQl20/AHAc8A5ZnZCCOGp6PnxwMeApcD0EMLq5IbM7HBgRRGfjYh0MMowiogUZmbKkDqb8qzz7ThYBIgCs88BW4DpZnZCYtlPA/2Bp5LBYrReNXBD9PBL8fNm1hX49+jhJclgMVovhBAeDSFszlG2pcDn42AxWv51PGgFOC2x7PBo+kJ2sBit91IIYU2O1xCRCqEMo4hIYdKG1dmW5/nfZz8RQthkZncDFwMzgKeiWSdH09/k2dav8OriE82sKoRQD0wDhgLLQggPNPsOGns0hLA9x/PzounorOe2Au8xs68DfwghLC7y9USkA1PAKCJSmGKH1dkUQtiUZ96iaDom8dw+0XRhyjoNQE9gCLAGr/YGeKOIcsWW5Hl+SzTd0/ElhLDVzD6BB63fAb5jZsvxto/3An8KIexoQRlEpINQlbSISHkJ7bRstoZiFg4h3AGMAy7BA8ca4ALg18A8MxvbirKISJlTwCgi0j4GmtmAPPMmRNPliefi/yelrNMF2AFsiJ6Ls4RNely3hxDCphDCb0IInwwh7A9MAWbimc7r9kYZRKQ0FDCKiLSfi7OfiILIs6OH1YlZj0XTj+bZ1sej6ZMhhN3R/88D64AxZnZm64pavBDCW3gVNcBhe/v1RWTvUcAoItJ+vhkNVQOAmXUDfoKPXfh8COHJxLI/xzuWnGhmn09uxMxOwntXA/wwfj6EsAu4Jnr4azM7Oms9M7NTUjKdBTGzI8zsg3kGAD8nmqoTjEgFU6cXEZHCXGVml6TMvy2E8I/E4yV4BvAlM3sUH4j7eHzA7HVkZRJDCKvM7CP4YN8/MbNPAa/ivZXfgV/g/3eO3tA/Ag4APgX808xmAwuAwcCB0etNjF6/pcYDfwK2mdkL+JA83YEj8Cr0rcA3W7F9ESlzChhFRArTXJXvS0AyYAzAB4Cr8Du3jMd7IP8e+EYIYVH2BkIIfzezafjwOafinUq2Rtu9IYRwX451AvBpM/s7PoD30fjdWNbjgeMN5B8OqFD/BL6GD/2zP3AUUIcHjj+MyqYMo0gFMz/WiIhIWzCzCfjQOItDCBNKWxoRkbahNowiIiIikkoBo4iIiIikUsAoIiIiIqnUhlFEREREUinDKCIiIiKpFDCKiIiISCoFjCIiIiKSSgGjiIiIiKRSwCgiIiIiqRQwioiIiEiq/w+J91rE0sWUwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Make a quick epoch vs. loss plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Depth 3 Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Make a quick epoch vs. accuracy plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Depth 3 Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12236/349347309.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions_d3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_d3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Time: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "start = time.time()\n",
    "predictions_d3 = model.predict(x_test_d3.values)\n",
    "end = time.time()\n",
    "print(\"Time: \" + str(end - start))\n",
    "# predict\n",
    "\n",
    "thresholds=[0.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "for val in thresholds:\n",
    "    pred=predictions_d3.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "\n",
    "    precision = precision_score(Y_test_d3, pred, average='micro')\n",
    "    recall = recall_score(Y_test_d3, pred, average='micro')\n",
    "    f1 = f1_score(Y_test_d3, pred, average='micro')\n",
    "   \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "    print(\"Accuracy = \",accuracy_score(Y_test_d3, pred))\n",
    "    print(\"Partial Accuracy = \",partial_accuracy(Y_test_d3, pred))\n",
    "    print(\"\\n\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D5 TESTING\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "inputs = x_d5.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = np.array(y_d5)\n",
    "#targets = np.stack(targets)\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "\n",
    "n_classes = 51\n",
    "\n",
    "acc_per_fold = []\n",
    "f1_per_fold = []\n",
    "time_per_fold = []\n",
    "\n",
    "acc_per_fold_plut = []\n",
    "f1_per_fold_plut = []\n",
    "time_per_fold_plut = []\n",
    "\n",
    "acc_per_fold_mwpm = []\n",
    "f1_per_fold_mwpm = []\n",
    "time_per_fold_mwpm = []\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "aucs_classes = {}\n",
    "for i in mlb.classes_:\n",
    "    aucs_classes[i] = []\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for i, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "    i_train = inputs[train].copy()\n",
    "    i_test = inputs[test].copy()\n",
    "    x_test_d5 = i_test[:,:2]\n",
    "    inputs_train = i_train[:,3:]\n",
    "    inputs_test = i_test[:,3:]\n",
    "    \n",
    "    ####################################################################################################\n",
    "    #test MWPM decoder for this fold\n",
    "    #labels = targets[train], features = inputs[train]\n",
    "    #x_test_d5 = translate_to_graph(testData_d5_MWPM, targets[test], mlb)\n",
    "    decoding_d5, time_mwpm = do_new_decoding(x_test_d5, 5, 0)\n",
    "    decoding_d5['combine'] = decoding_d5[[0, 1]].values.tolist()\n",
    "    decoding_d5['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "    decoding_d5 = np.array(decoding_d5[0])\n",
    "                                              \n",
    "    time_per_fold_mwpm.append(time_mwpm)\n",
    "                                              \n",
    "    pred_mwpm = mlb.transform(decoding_d5)\n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_mwpm)\n",
    "    else:\n",
    "        acc, contingency_mwpm = partial_accuracy_and_contingency(targets[test], pred_mwpm, mlb)\n",
    "        \n",
    "    acc_per_fold_mwpm.append(acc)\n",
    "    f1_per_fold_mwpm.append(f1_score(targets[test], pred_mwpm, average='micro'))\n",
    "    \n",
    "    #####################################################################################################\n",
    "    #test the plut decoder for this fold\n",
    "    \n",
    "    lookup_d5 = lookup_decoder(5)\n",
    "    \n",
    "    lookup_d5 = train_plut(lookup_d5, inputs_train, targets[train])\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    pred_plut_d5 = test_plut(lookup_d5, inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_plut_d5)\n",
    "    else:\n",
    "        acc, contingency_plut = partial_accuracy_and_contingency(targets[test], pred_plut_d5, mlb)\n",
    "        \n",
    "    acc_per_fold_plut.append(acc)\n",
    "    f1_per_fold_plut.append(f1_score(targets[test], pred_plut_d5, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #Test the NN decoder for this fold\n",
    "    \n",
    "    model_d5 = compile_FFNN_model_DepthFive(5)\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    \n",
    "    inputs_train = np.asarray(inputs_train).astype(np.int) #CHANGE (added)\n",
    "    targets[train] = np.asarray(targets[train]).astype(np.int) #CHANGE (added)\n",
    "    \n",
    "    history = model_d5.fit(\n",
    "    inputs_train,\n",
    "    targets[train],\n",
    "    validation_split=.25,\n",
    "    epochs = 800\n",
    ")\n",
    "   # Generate generalization metrics\n",
    "\n",
    "    inputs_test = np.asarray(inputs_test).astype(np.int) #CHANGE (added)\n",
    "    targets[test] = np.asarray(targets[test]).astype(np.int) #CHANGE (added)\n",
    "    scores = model_d5.evaluate(inputs_test, targets[test], verbose=0)\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    predictions_d5 = model_d5.predict(inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    #threshold based on previous tests with train_test_split in hyperparameter tuning\n",
    "    pred=predictions_d5.copy() #change here\n",
    "    pred[pred>=.4]=1 \n",
    "    pred[pred<.4]=0\n",
    "    \n",
    "    if fold_no < 5:\n",
    "        acc = scores[1]\n",
    "    else:\n",
    "        acc, contingency_nn = partial_accuracy_and_contingency(targets[test], pred, mlb)\n",
    "\n",
    "    acc_per_fold.append(acc)\n",
    "    f1_per_fold.append(f1_score(targets[test], pred, average='micro'))\n",
    "\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d5.ravel())\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    \n",
    "    #get the AUCs of each class, used to get average AUC of each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d5[:, i]) \n",
    "        aucs_classes[mlb.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "        \n",
    "        \n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print(\"##############################################################################\")\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print(\"##############################################################################\")\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "print(\"##############################################################################\")\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "    \n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 5 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D7 TESTING\n",
    "\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "inputs = x_d7.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = np.array(y_d7)\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "n_classes = 99\n",
    "\n",
    "acc_per_fold = []\n",
    "f1_per_fold = []\n",
    "time_per_fold = []\n",
    "\n",
    "acc_per_fold_plut = []\n",
    "f1_per_fold_plut = []\n",
    "time_per_fold_plut = []\n",
    "\n",
    "acc_per_fold_mwpm = []\n",
    "f1_per_fold_mwpm = []\n",
    "time_per_fold_mwpm = []\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "aucs_classes = {}\n",
    "for i in mlb_d7.classes_:\n",
    "    aucs_classes[i] = []\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for i, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "    i_train = inputs[train].copy()\n",
    "    i_test = inputs[test].copy()\n",
    "    t_test = targets[test].copy()\n",
    "    x_test_d7 = i_test[:,:2]\n",
    "    inputs_train = i_train[:,3:]\n",
    "    inputs_test = i_test[:,3:]\n",
    "    indices = np.random.choice(inputs[test].shape[0], 20000, replace=False)\n",
    "    x_test_d7 = x_test_d7[indices]\n",
    "    inputs_test_2 = inputs_test[indices]\n",
    "    targets_test_2 = targets[test][indices]\n",
    "    ####################################################################################################\n",
    "    #test MWPM decoder for this fold\n",
    "    #labels = targets[train], features = inputs[train]\n",
    "   # x_test_d7 = translate_to_graph(testData_d7_MWPM, targs, mlb_d7)\n",
    "    decoding_d7, time_mwpm = do_new_decoding(x_test_d7, 7, 0)\n",
    "    decoding_d7['combine'] = decoding_d7[[0, 1]].values.tolist()\n",
    "    decoding_d7['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "    decoding_d7 = np.array(decoding_d7[0])\n",
    "                                              \n",
    "    time_per_fold_mwpm.append(time_mwpm)\n",
    "                                              \n",
    "    pred_mwpm = mlb_d7.transform(decoding_d7)\n",
    "\n",
    "    if fold_no < 3:\n",
    "        acc = partial_accuracy(targets_test_2, pred_mwpm)\n",
    "    else:\n",
    "        acc, contingency_mwpm = partial_accuracy_and_contingency(targets_test_2, pred_mwpm, mlb_d7)\n",
    "        \n",
    "    acc_per_fold_mwpm.append(acc)\n",
    "    f1_per_fold_mwpm.append(f1_score(targets_test_2, pred_mwpm, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #test the plut decoder for this fold\n",
    "    \n",
    "    lookup_d7 = lookup_decoder(7)\n",
    "    \n",
    "    lookup_d7 = train_plut(lookup_d7, inputs_train, targets[train])\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    pred_plut_d7 = test_plut(lookup_d7, inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    if fold_no < 3:\n",
    "        acc = partial_accuracy(targets[test], pred_plut_d7)\n",
    "        f1 = f1_score(targets[test], pred_plut_d7, average='micro')\n",
    "    else:\n",
    "        pred_plut_d7 = test_plut(lookup_d7, inputs_test_2)\n",
    "        f1 = f1_score(targets_test_2, pred_plut_d7, average='micro')\n",
    "        acc, contingency_plut = partial_accuracy_and_contingency(targets_test_2, pred_plut_d7, mlb_d7)\n",
    "        \n",
    "    acc_per_fold_plut.append(acc)\n",
    "    f1_per_fold_plut.append(f1)\n",
    "    \n",
    "    #####################################################################################################\n",
    "    #Test the NN decoder for this fold\n",
    "    \n",
    "    model_d7 = compile_FFNN_model_DepthSeven(7)\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    \n",
    "    inputs_train = np.asarray(inputs_train).astype(np.int) #CHANGE (added)\n",
    "    targets[train] = np.asarray(targets[train]).astype(np.int) #CHANGE (added)\n",
    "    \n",
    "    history = model_d7.fit(\n",
    "        x=inputs_train ,\n",
    "        y=targets[train],\n",
    "        validation_split=.25,\n",
    "        epochs= 150)\n",
    "    \n",
    "   # Generate generalization metrics\n",
    "    \n",
    "    inputs_test = np.asarray(inputs_test).astype(np.int) #CHANGE (added)\n",
    "    targets[test] = np.asarray(targets[test]).astype(np.int) #CHANGE (added)\n",
    "    \n",
    "    scores = model_d7.evaluate(inputs_test, targets[test], verbose=0)\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    predictions_d7 = model_d7.predict(inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    #threshold based on previous tests with train_test_split in hyperparameter tuning\n",
    "    pred=predictions_d7.copy() #change here\n",
    "    pred[pred>=.5]=1 \n",
    "    pred[pred<.5]=0\n",
    "     \n",
    "    if fold_no < 3:\n",
    "        acc = scores[1]\n",
    "        f1 = f1_score(targets[test], pred, average='micro')\n",
    "    else:\n",
    "        inputs_test_2 = np.asarray(inputs_test_2).astype(np.int) #CHANGE (added)\n",
    "        pred = model_d7.predict(inputs_test_2)\n",
    "        pred[pred>=.5]=1 \n",
    "        pred[pred<.5]=0\n",
    "        acc, contingency_nn = partial_accuracy_and_contingency(targets_test_2, pred, mlb_d7)\n",
    "        f1 = f1_score(targets_test_2, pred, average='micro')\n",
    " \n",
    "    acc_per_fold.append(acc)\n",
    "    f1_per_fold.append(f1)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d7.ravel())\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    \n",
    "    #get the AUCs of each class, used to get average AUC of each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d7[:, i]) \n",
    "        aucs_classes[mlb_d7.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "\n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "print(\"Train complete\")\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "print(len(mlb_d7.classes_))\n",
    "\n",
    "for class_ in mlb_d7.classes_:\n",
    "    print(\"interating\")\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 7 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test MWPM decoder for this fold\n",
    "#labels = targets[train], features = inputs[train]\n",
    "# x_test_d7 = translate_to_graph(testData_d7_MWPM, targs, mlb_d7)\n",
    "\"\"\"\n",
    "decoding_d7, time_mwpm = do_new_decoding(x_test_d7, 7, 0)\n",
    "decoding_d7['combine'] = decoding_d7[[0, 1]].values.tolist()\n",
    "decoding_d7['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "decoding_d7 = np.array(decoding_d7[0])\n",
    "\n",
    "time_per_fold_mwpm.append(time_mwpm)\n",
    "\n",
    "pred_mwpm = mlb_d7.transform(decoding_d7)\n",
    "\n",
    "if fold_no < 3:\n",
    "    acc = partial_accuracy(targets_test_2, pred_mwpm)\n",
    "else:\n",
    "    acc, contingency_mwpm = partial_accuracy_and_contingency(targets_test_2, pred_mwpm, mlb_d7)\"\"\"\n",
    "\n",
    "#acc_per_fold_mwpm.append(acc)\n",
    "#f1_per_fold_mwpm.append(f1_score(targets_test_2, pred_mwpm, average='micro'))\n",
    "\n",
    "#####################################################################################################\n",
    "#test the plut decoder for this fold\n",
    "\n",
    "#lookup_d7 = lookup_decoder(7)\n",
    "\n",
    "#lookup_d7 = train_plut(lookup_d7, inputs_train, targets[train])\n",
    "\n",
    "#start = time.time_ns()\n",
    "#pred_plut_d7 = test_plut(lookup_d7, inputs_test)\n",
    "#end = time.time_ns() \n",
    "#time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "\n",
    "pred_plut_d7 = test_plut(lookup_d7, inputs_test_2)\n",
    "#f1 = f1_score(targets_test_2, pred_plut_d7, average='micro')\n",
    "acc, contingency_plut = partial_accuracy_and_contingency(targets_test_2, pred_plut_d7, mlb_d7)\n",
    "\n",
    "#acc_per_fold_plut.append(acc)\n",
    "#f1_per_fold_plut.append(f1)\n",
    "\n",
    "#####################################################################################################\n",
    "#Test the NN decoder for this fold\n",
    "\"\"\"\n",
    "model_d7 = compile_FFNN_model_DepthSeven(7)\n",
    "\n",
    "# Generate a print\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "# Fit data to model\n",
    "history = model_d7.fit(\n",
    "    x=inputs_train ,\n",
    "    y=targets[train],\n",
    "    validation_split=.25,\n",
    "    epochs= 150)\"\"\"\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d7.ravel())\n",
    "tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "tprs[-1][0] = 0.0\n",
    "roc_auc = auc(fpr, tpr)\n",
    "aucs.append(roc_auc)\n",
    "plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "#get the AUCs of each class, used to get average AUC of each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d7[:, i]) \n",
    "    aucs_classes[mlb_d7.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "\n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb_d7.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 7 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test MWPM decoder for this fold\n",
    "#labels = targets[train], features = inputs[train]\n",
    "# x_test_d7 = translate_to_graph(testData_d7_MWPM, targs, mlb_d7)\n",
    "\"\"\"\n",
    "decoding_d7, time_mwpm = do_new_decoding(x_test_d7, 7, 0)\n",
    "decoding_d7['combine'] = decoding_d7[[0, 1]].values.tolist()\n",
    "decoding_d7['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "decoding_d7 = np.array(decoding_d7[0])\n",
    "\n",
    "time_per_fold_mwpm.append(time_mwpm)\n",
    "\n",
    "pred_mwpm = mlb_d7.transform(decoding_d7)\n",
    "\n",
    "if fold_no < 3:\n",
    "    acc = partial_accuracy(targets_test_2, pred_mwpm)\n",
    "else:\n",
    "    acc, contingency_mwpm = partial_accuracy_and_contingency(targets_test_2, pred_mwpm, mlb_d7)\"\"\"\n",
    "\n",
    "#acc_per_fold_mwpm.append(acc)\n",
    "#f1_per_fold_mwpm.append(f1_score(targets_test_2, pred_mwpm, average='micro'))\n",
    "\n",
    "#####################################################################################################\n",
    "#test the plut decoder for this fold\n",
    "\n",
    "#lookup_d7 = lookup_decoder(7)\n",
    "\n",
    "#lookup_d7 = train_plut(lookup_d7, inputs_train, targets[train])\n",
    "\n",
    "#start = time.time_ns()\n",
    "#pred_plut_d7 = test_plut(lookup_d7, inputs_test)\n",
    "#end = time.time_ns() \n",
    "#time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "\n",
    "if fold_no < 3:\n",
    "    acc = partial_accuracy(targets[test], pred_plut_d7)\n",
    "    f1 = f1_score(targets[test], pred_plut_d7, average='micro')\n",
    "else:\n",
    "    pred_plut_d7 = test_plut(lookup_d7, inputs_test_2)\n",
    "    #f1 = f1_score(targets_test_2, pred_plut_d7, average='micro')\n",
    "    acc, contingency_plut = partial_accuracy_and_contingency(targets_test_2, pred_plut_d7, mlb_d7)\n",
    "\n",
    "#acc_per_fold_plut.append(acc)\n",
    "#f1_per_fold_plut.append(f1)\n",
    "\n",
    "#####################################################################################################\n",
    "#Test the NN decoder for this fold\n",
    "\"\"\"\n",
    "model_d7 = compile_FFNN_model_DepthSeven(7)\n",
    "\n",
    "# Generate a print\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "# Fit data to model\n",
    "history = model_d7.fit(\n",
    "    x=inputs_train ,\n",
    "    y=targets[train],\n",
    "    validation_split=.25,\n",
    "    epochs= 150)\"\"\"\n",
    "\n",
    "pred = model_d7.predict(inputs_test_2)\n",
    "pred[pred>=.5]=1 \n",
    "pred[pred<.5]=0\n",
    "acc, contingency_nn = partial_accuracy_and_contingency(targets_test_2, pred, mlb_d7)\n",
    "f1 = f1_score(targets_test_2, pred, average='micro')\n",
    "\n",
    "#acc_per_fold.append(acc)\n",
    "f1_per_fold.append(f1)\n",
    "\n",
    "# Increase fold number\n",
    "fold_no = fold_no + 1\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d7.ravel())\n",
    "tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "tprs[-1][0] = 0.0\n",
    "roc_auc = auc(fpr, tpr)\n",
    "aucs.append(roc_auc)\n",
    "plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "#get the AUCs of each class, used to get average AUC of each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d7[:, i]) \n",
    "    aucs_classes[mlb_d7.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "\n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb_d7.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 7 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model_d5 = compile_FFNN_model_DepthFive(5)\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "history = model_d5.fit(\n",
    "    x=x_train_d5.values,\n",
    "    y=Y_train_d5,\n",
    "    validation_split=.25,\n",
    "    epochs = 500\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Make a quick epoch vs. loss plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Depth 5 Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Make a quick epoch vs. accuracy plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Depth 5 Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# predict\n",
    "from sklearn.metrics import precision_score,accuracy_score, f1_score, recall_score, hamming_loss\n",
    "\n",
    "start = time.time()\n",
    "predictions_d5 = model_d5.predict(x_test_d5.values)\n",
    "end = time.time()\n",
    "print(\"Time: \" + str(end - start))\n",
    "\n",
    "pred=predictions_d5.copy()\n",
    "\n",
    "thresholds=[0.1, 0.2, 0.3, .4, .5, .6, .7, .8, .9]\n",
    "for val in thresholds:\n",
    "    pred=predictions_d5.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "    \n",
    "  \n",
    "    precision = precision_score(Y_test_d5, pred, average='micro')\n",
    "    recall = recall_score(Y_test_d5, pred, average='micro')\n",
    "    f1 = f1_score(Y_test_d5, pred, average='micro')\n",
    "   \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "    print(\"Accuracy = \",accuracy_score(Y_test_d5, pred))\n",
    "    print(\"Accuracy = \",partial_accuracy(Y_test_d5, pred))\n",
    "    print(\"\\n\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pred=predictions_d5.copy()\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "#look at confusion matrix to see what got misclassified    \n",
    "pred[pred>=.5]=1\n",
    "pred[pred<.5]=0\n",
    "multilabel_confusion_matrix(Y_test_d5, pred)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#look at classifcation report to see what got mislabeled\n",
    "print(classification_report(Y_test_d5, pred))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d7 = compile_FFNN_model_DepthSeven(7)\n",
    "print(\"Fit model on training data\")\n",
    "history = model_d7.fit(\n",
    "    x=x_d7.values,#x=x_train_d7.values,\n",
    "    y=y_d7,#y=Y_train_d7,\n",
    "    validation_split=.25,\n",
    "    epochs= 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a quick epoch vs. loss plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Depth 7 Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a quick epoch vs. accuracy plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Depth 7 Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\n",
    "# predict\n",
    "from sklearn.metrics import precision_score,accuracy_score, f1_score, recall_score, hamming_loss\n",
    "\n",
    "start = time.time()\n",
    "predictions_d7 = model_d7.predict(x_test_d7.values)\n",
    "end = time.time()\n",
    "print(\"Time: \" + str(end - start))\n",
    "\n",
    "pred=predictions_d7.copy()\n",
    "\n",
    "\n",
    "thresholds=[0.1, 0.2, 0.3, .4, .5, .6, .7, .8, .9]\n",
    "for val in thresholds:\n",
    "    pred=predictions_d7.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "    \n",
    "  \n",
    "    precision = precision_score(Y_test_d7, pred, average='micro')\n",
    "    recall = recall_score(Y_test_d7, pred, average='micro')\n",
    "    f1 = f1_score(Y_test_d7, pred, average='micro')\n",
    "   \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "    print(\"Accuracy = \",accuracy_score(Y_test_d7, pred))\n",
    "    print(\"Accuracy = \",partial_accuracy(Y_test_d7, pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "predictions_d7 = model_d7.predict(x_test_d7.values)\n",
    "pred=predictions_d7.copy()\n",
    "\n",
    "n_classes = 99\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test_d7[:, i], pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test_d7.ravel(), pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x_train_d3.to_csv(\"x_train_d3_01.csv\")\n",
    "x_test_d3.to_csv(\"x_test_d3_01.csv\")\n",
    "pd.DataFrame(Y_train_d3).to_csv(\"Y_train_d3_01.csv\")\n",
    "pd.DataFrame(Y_test_d3).to_csv(\"Y_test_d3_01.csv\")\n",
    "\n",
    "x_train_d5.to_csv(\"x_train_d5_01.csv\")\n",
    "x_test_d5.to_csv(\"x_test_d5_01.csv\")\n",
    "pd.DataFrame(Y_train_d5).to_csv(\"Y_train_d5_01.csv\")\n",
    "pd.DataFrame(Y_test_d5).to_csv(\"Y_test_d5_01.csv\")\n",
    "\n",
    "x_train_d7.to_csv(\"x_train_d7_01.csv\")\n",
    "x_test_d7.to_csv(\"x_test_d7_01.csv\")\n",
    "pd.DataFrame(Y_train_d7).to_csv(\"Y_train_d7_01.csv\")\n",
    "pd.DataFrame(Y_test_d7).to_csv(\"Y_test_d7_01.csv\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model_d7.save(\"model_d7_01.h5\")\n",
    "model_d5.save(\"model_d5_01.h5\")\n",
    "model.save(\"model_d3_01.h5\")\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
