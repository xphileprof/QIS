{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import make_scorer #CHANGE (updated to be consistent with scikit_learn .24)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import precision_score,accuracy_score, f1_score, recall_score, hamming_loss\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import backend as K\n",
    "\n",
    "#%matplotlib inline\n",
    "#import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "\n",
    "print (pd.__version__)\n",
    "\n",
    "######### DEFINITION OF GLOBAL VARIABLES #########\n",
    "RUN_CONFIGURATION_LOOP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "#sys.path.append('/')\n",
    "import circuits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are super long functions to be hard coded because i dont have time to properly fix them, sorry bout it\n",
    "#[(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 1.5, -0.5), (0, 1.5, 1.5)]\n",
    "def graph_with_errs_d3(df):\n",
    "    x_data = []\n",
    "    z_data = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        x_data.append([])\n",
    "        z_data.append([])\n",
    "        \n",
    "        if df.loc[i].at[\"X0\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 0.5))\n",
    "        if df.loc[i].at[\"Z1\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 0.5))\n",
    "        if df.loc[i].at[\"X2\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 1.5))\n",
    "        if df.loc[i].at[\"Z3\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 2.5))\n",
    "        if df.loc[i].at[\"Z4\"] == -1:\n",
    "            z_data[i].append((0, 1.5, -0.5))\n",
    "        if df.loc[i].at[\"X5\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 0.5))\n",
    "        if df.loc[i].at[\"X6\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 1.5))\n",
    "        if df.loc[i].at[\"Z7\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 1.5))\n",
    "        x_data[i] = str(x_data[i])\n",
    "        z_data[i] = str(z_data[i])\n",
    "    #graph_df = pd.DataFrame(df[\"Labels\"], x_data, z_data, columns=[\"Labels\", \"XSyn\", \"ZSyn\"])\n",
    "    graph_df = pd.DataFrame({\"XSyn\":x_data, \"ZSyn\":z_data})\n",
    "    return graph_df\n",
    "        \n",
    "\n",
    "def graph_with_errs_d5(df):\n",
    "    x_data = []\n",
    "    z_data = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        x_data.append([])\n",
    "        z_data.append([])\n",
    "        if df.loc[i].at[\"X0\"] == -1:\n",
    "             x_data[i].append((0, -0.5, 0.5))\n",
    "        if df.loc[i].at[\"Z1\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 0.5))\n",
    "        if df.loc[i].at[\"X2\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 1.5))\n",
    "        if df.loc[i].at[\"X3\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 2.5))\n",
    "        if df.loc[i].at[\"Z4\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 2.5))\n",
    "        if df.loc[i].at[\"X5\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 3.5))\n",
    "        if df.loc[i].at[\"Z6\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 4.5))\n",
    "        if df.loc[i].at[\"Z7\"] == -1:\n",
    "            z_data[i].append((0, 1.5, -0.5))\n",
    "        if df.loc[i].at[\"X8\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 0.5))\n",
    "        if df.loc[i].at[\"Z9\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 1.5))\n",
    "        if df.loc[i].at[\"X10\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 2.5))\n",
    "        if df.loc[i].at[\"Z11\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 3.5))\n",
    "        if df.loc[i].at[\"Z12\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 0.5))\n",
    "        if df.loc[i].at[\"X13\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 1.5))\n",
    "        if df.loc[i].at[\"Z14\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 2.5))\n",
    "        if df.loc[i].at[\"X15\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 3.5))\n",
    "        if df.loc[i].at[\"Z16\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 4.5))\n",
    "        if df.loc[i].at[\"Z17\"] == -1:\n",
    "            z_data[i].append((0, 3.5, -0.5))\n",
    "        if df.loc[i].at[\"X18\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 0.5))\n",
    "        if df.loc[i].at[\"X19\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 1.5))\n",
    "        if df.loc[i].at[\"Z20\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 1.5))\n",
    "        if df.loc[i].at[\"X21\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 2.5))\n",
    "        if df.loc[i].at[\"X22\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 3.5))\n",
    "        if df.loc[i].at[\"Z23\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 3.5))\n",
    "        x_data[i] = str(x_data[i])\n",
    "        z_data[i] = str(z_data[i])\n",
    "            \n",
    "    graph_df = pd.DataFrame({\"XSyn\":x_data, \"ZSyn\":z_data})\n",
    "    return graph_df\n",
    "    \n",
    "def graph_with_errs_d7(df):\n",
    "    x_data = []\n",
    "    z_data = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        x_data.append([])\n",
    "        z_data.append([])\n",
    "        \n",
    "        if df.loc[i].at[\"X0\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 0.5))\n",
    "        if df.loc[i].at[\"Z1\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 0.5))\n",
    "        if df.loc[i].at[\"X2\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 1.5))\n",
    "        if df.loc[i].at[\"X3\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 2.5))\n",
    "        if df.loc[i].at[\"Z4\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 2.5))\n",
    "        if df.loc[i].at[\"X5\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 3.5))\n",
    "        if df.loc[i].at[\"X6\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 4.5))\n",
    "        if df.loc[i].at[\"Z7\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 4.5))\n",
    "        if df.loc[i].at[\"X8\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 5.5))\n",
    "        if df.loc[i].at[\"Z9\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 6.5))\n",
    "        if df.loc[i].at[\"Z10\"] == -1:\n",
    "            z_data[i].append((0, 1.5, -0.5))\n",
    "        if df.loc[i].at[\"X11\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 0.5))\n",
    "        if df.loc[i].at[\"Z12\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 1.5))\n",
    "        if df.loc[i].at[\"X13\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 2.5))\n",
    "        if df.loc[i].at[\"Z14\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 3.5))\n",
    "        if df.loc[i].at[\"X15\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 4.5))\n",
    "        if df.loc[i].at[\"Z16\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 5.5))\n",
    "        if df.loc[i].at[\"Z17\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 0.5))\n",
    "        if df.loc[i].at[\"X18\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 1.5))\n",
    "        if df.loc[i].at[\"Z19\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 2.5))\n",
    "        if df.loc[i].at[\"X20\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 3.5))\n",
    "        if df.loc[i].at[\"Z21\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 4.5))\n",
    "        if df.loc[i].at[\"X22\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 5.5))\n",
    "        if df.loc[i].at[\"Z23\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 6.5))\n",
    "        if df.loc[i].at[\"Z24\"] == -1:\n",
    "            z_data[i].append((0, 3.5, -0.5))\n",
    "        if df.loc[i].at[\"X25\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 0.5))\n",
    "        if df.loc[i].at[\"Z26\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 1.5))\n",
    "        if df.loc[i].at[\"X27\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 2.5))\n",
    "        if df.loc[i].at[\"Z28\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 3.5))\n",
    "        if df.loc[i].at[\"X29\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 4.5))\n",
    "        if df.loc[i].at[\"Z30\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 5.5))\n",
    "        if df.loc[i].at[\"Z31\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 0.5))\n",
    "        if df.loc[i].at[\"X32\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 1.5))\n",
    "        if df.loc[i].at[\"Z33\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 2.5))\n",
    "        if df.loc[i].at[\"X34\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 3.5))\n",
    "        if df.loc[i].at[\"Z35\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 4.5))\n",
    "        if df.loc[i].at[\"X36\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 5.5))\n",
    "        if df.loc[i].at[\"Z37\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 6.5))\n",
    "        if df.loc[i].at[\"Z38\"] == -1:\n",
    "            z_data[i].append((0, 5.5, -0.5))\n",
    "        if df.loc[i].at[\"X39\"] == -1:\n",
    "            x_data[i].append((0, 5.5, 0.5))\n",
    "        if df.loc[i].at[\"X40\"] == -1:\n",
    "            x_data[i].append((0, 6.5, 1.5))\n",
    "        if df.loc[i].at[\"Z41\"] == -1:\n",
    "            z_data[i].append((0, 5.5, 1.5))\n",
    "        if df.loc[i].at[\"X42\"] == -1:\n",
    "            x_data[i].append((0, 5.5, 2.5))\n",
    "        if df.loc[i].at[\"X43\"] == -1:\n",
    "            x_data[i].append((0, 6.5, 3.5))\n",
    "        if df.loc[i].at[\"Z44\"] == -1:\n",
    "            z_data[i].append((0, 5.5, 3.5))\n",
    "        if df.loc[i].at[\"X45\"] == -1:\n",
    "            x_data[i].append((0, 5.5, 4.5))\n",
    "        if df.loc[i].at[\"X46\"] == -1:\n",
    "            x_data[i].append((0, 6.5, 5.5))\n",
    "        if df.loc[i].at[\"Z47\"] == -1: \n",
    "            z_data[i].append((0, 5.5, 5.5))\n",
    "        x_data[i] = str(x_data[i])\n",
    "        z_data[i] = str(z_data[i])\n",
    "    graph_df = pd.DataFrame({\"XSyn\":x_data, \"ZSyn\":z_data})\n",
    "    return graph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions needed to work with the GraphDecoder/MWPM module\n",
    "import time\n",
    "\n",
    "def add_measurement_errs(curr_syn, prob_err, x_syn, depth):\n",
    "    #x_syn is True if it is x syndrome, False if it is Z syndrome\n",
    "    total_time = 0\n",
    "    new_syn = []\n",
    "    if x_syn:\n",
    "        for i in curr_syn:\n",
    "            rand = random.random()\n",
    "            if rand > prob_err:\n",
    "                new_syn.append(i)\n",
    "        return (new_syn + return_xmeasurement_errs(depth, prob_err))\n",
    "    else:\n",
    "        for i in curr_syn:\n",
    "            rand = random.random()\n",
    "            if rand > prob_err:\n",
    "                new_syn.append(i)\n",
    "        return (new_syn + return_zmeasurement_errs(depth, prob_err))\n",
    "    \n",
    "def do_new_decoding(data, depth, prob_err):\n",
    "    decoder = circuits.GraphDecoder(depth,1)\n",
    "    G = decoder.S['Z']\n",
    "    #decoder.graph_2D(G,'distance')\n",
    "    df = pd.DataFrame()\n",
    "    syn = []\n",
    "    total_time = 0\n",
    "    \n",
    "    for row in data:\n",
    "        x_input = []\n",
    "        z_input = []\n",
    "        x_type = True\n",
    "        for col in row:\n",
    "            if not col == \"[]\":\n",
    "                col = eval(col)\n",
    "                for c in col:\n",
    "                    if x_type:\n",
    "                        x_input.append(c)\n",
    "                    else:\n",
    "                        z_input.append(c)\n",
    "            x_type = not x_type  \n",
    "            \n",
    "        if prob_err > 0:\n",
    "            syndromes_x = add_measurement_errs(x_input, prob_err, True, depth)\n",
    "            syndromes_z = add_measurement_errs(z_input, prob_err, False, depth)\n",
    "        else:\n",
    "            syndromes_x = x_input\n",
    "            syndromes_z = z_input\n",
    "\n",
    "        start = time.time_ns()\n",
    "        error_graph_x, paths_x = decoder.make_error_graph(syndromes_x,'X')\n",
    "        matching_graph_x = decoder.matching_graph(error_graph_x,'X')\n",
    "        matches_x = decoder.matching(matching_graph_x,'X')\n",
    "        flips_x = decoder.calculate_qubit_flips(matches_x, paths_x,'X')\n",
    "        syn_x = (translate_errors(flips_x))\n",
    "\n",
    "        error_graph_z, paths_z = decoder.make_error_graph(syndromes_z,'Z')\n",
    "        matching_graph_z = decoder.matching_graph(error_graph_z,'Z')\n",
    "        matches_z = decoder.matching(matching_graph_z,'Z')\n",
    "        flips_z = decoder.calculate_qubit_flips(matches_z, paths_z,'Z')\n",
    "        syn_z = translate_errors(flips_z)\n",
    "        df = df.append(pd.Series([syn_x, syn_z]), ignore_index=True)\n",
    "        end = time.time_ns()\n",
    "        total_time += (end - start)/ (10 ** 9)\n",
    "    return (df, total_time) \n",
    "\n",
    "import random\n",
    "def return_xmeasurement_errs(depth, prob):\n",
    "    \n",
    "    new_errs = []\n",
    "    \n",
    "    if depth == 3:\n",
    "        errs = [(0, -0.5, 0.5), (0, 0.5, 1.5), (0, 1.5, 0.5), (0, 2.5, 1.5)]\n",
    "    elif depth == 5:\n",
    "        errs = [(0, -0.5, 0.5), (0, 0.5, 1.5), (0, -0.5, 2.5), (0, 0.5, 3.5), (0, 1.5, 0.5), (0, 1.5, 2.5),\n",
    "                        (0, 2.5, 1.5), (0, 2.5, 3.5), (0, 3.5, 0.5), (0, 4.5, 1.5), (0, 3.5, 2.5), (0, 4.5, 3.5)]\n",
    "    else:\n",
    "        errs = [(0, -0.5, 0.5), (0, 0.5, 1.5), (0, -0.5, 2.5), (0, 0.5, 3.5), (0, -0.5, 4.5), (0, 0.5, 5.5),\n",
    "                        (0, 1.5, 0.5), (0, 1.5, 2.5), (0, 1.5, 4.5), (0, 2.5, 1.5), (0, 2.5, 3.5), (0, 2.5, 5.5),\n",
    "                        (0, 3.5, 0.5),  (0, 3.5, 2.5), (0, 3.5, 4.5), (0, 4.5, 1.5), (0, 4.5, 3.5), (0, 4.5, 5.5),\n",
    "                       (0, 5.5, 0.5), (0, 6.5, 1.5), (0, 5.5, 2.5), (0, 6.5, 3.5), (0, 5.5, 4.5), (0, 6.5, 5.5)]\n",
    "    for e in errs:\n",
    "        rand = random.random()\n",
    "        if rand <= prob:\n",
    "            new_errs.append(e)\n",
    "            \n",
    "    return new_errs\n",
    "            \n",
    "\n",
    "def return_zmeasurement_errs(depth, prob):\n",
    "    \n",
    "    new_errs = []\n",
    "    \n",
    "    if depth == 3:\n",
    "        errs = [(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 1.5, -0.5), (0, 1.5, 1.5)]\n",
    "    elif depth == 5:\n",
    "        errs = [(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 0.5, 4.5), (0, 1.5, -0.5), (0, 1.5, 1.5), (0, 1.5, 3.5),\n",
    "                        (0, 2.5, 0.5), (0, 2.5, 2.5), (0, 2.5, 4.5), (0, 3.5, -0.5), (0, 3.5, 1.5), (0, 3.5, 3.5)]\n",
    "    else:\n",
    "        errs = [(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 0.5, 4.5), (0, 0.5, 6.5), (0, 1.5, -0.5), (0, 1.5, 1.5),\n",
    "                        (0, 1.5, 3.5), (0, 1.5, 5.5), (0, 2.5, 0.5), (0, 2.5, 2.5), (0, 2.5, 4.5), (0, 2.5, 6.5),\n",
    "                        (0, 3.5, -0.5),  (0, 3.5, 1.5), (0, 3.5, 3.5), (0, 3.5, 5.5), (0, 4.5, 0.5), (0, 4.5, 2.5),\n",
    "                       (0, 4.5, 4.5), (0, 4.5, 6.5), (0, 5.5, -0.5), (0, 5.5, 1.5), (0, 5.5, 3.5), (0, 5.5, 5.5)]\n",
    "        \n",
    "    for e in errs:\n",
    "        rand = random.random()\n",
    "        if rand <= prob:\n",
    "            new_errs.append(e)\n",
    "            \n",
    "    return new_errs\n",
    "\n",
    "def translate_errors (phys_errs):\n",
    "    flipX = np.array([(0, 1),(1, 0)])\n",
    "    flipZ = np.array([(1, 0), (0, -1)])\n",
    "    errs = []\n",
    "    str2 = \"\"\n",
    "    for qubit, flip in phys_errs.items():\n",
    "        row = int(qubit[1])\n",
    "        col = int(qubit[2])\n",
    "        if str(flip) == \"X\":\n",
    "            str1 = \"X\"\n",
    "        elif str(flip) == \"Z\":\n",
    "            str1 = \"Z\"\n",
    "        else:\n",
    "            str1 = \"X\"\n",
    "            str2 = \"Z\"\n",
    "        str1 += str(row) + str(col)\n",
    "        errs.append(str1)\n",
    "        if str2 != \"\":\n",
    "            str2 += str(row) +str(col)\n",
    "            errs.append(str2)\n",
    "            str2 = \"\"\n",
    "    return errs   \n",
    "\n",
    "def translate_to_graph(df_graph, labels, mlb):\n",
    "#go through labels given\n",
    "    indices = []\n",
    "    labels = mlb.inverse_transform(labels)\n",
    "    \n",
    "    for row in labels:\n",
    "        label_str = str(row)\n",
    "        for index, r in df_graph.iterrows():\n",
    "            if label_str == \"('',)\":\n",
    "                if str(r[\"Labels\"]) == \"[' ']\":\n",
    "                    indices.append([index])\n",
    "                    break\n",
    "            if set(row) == set(r[\"Labels\"]):\n",
    "                indices.append([index])\n",
    "                break\n",
    "\n",
    "    df_syns = df_graph.drop(['Labels'], axis=1)\n",
    "    return_df = pd.DataFrame()\n",
    "    for i in indices:\n",
    "        return_df = return_df.append(df_syns.loc[i])\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function needed for preprocessing. CSV file reads in a string, needs to be a list for labels \n",
    "#for preprocessing csv files\n",
    "def create_list_from_string(err_list):\n",
    "    newstring = err_list.replace(\"'\", \"\")\n",
    "    new_err_list = newstring.strip('][').split(', ')\n",
    "    return sorted(set(new_err_list))\n",
    "\n",
    "\n",
    "def create_string_from_list(err_list):\n",
    "    return_string = \"[\"\n",
    "    if err_list[0] == \"''\":\n",
    "        return \"[' ']\"\n",
    "    else:\n",
    "        for index, i in enumerate(err_list):\n",
    "            return_string = return_string +  \"'\" + i + \"'\"\n",
    "            if index < (len(err_list)-1):\n",
    "                return_string += \", \"\n",
    "    return return_string + \"]\"\n",
    "        \n",
    "\n",
    "#take in two 2d arrays of predicted values, true values, and threshold to determine labels. \n",
    "#calculates the partial accuracy of the predicted values, averaged out for all obersvations\n",
    "def partial_accuracy(y_pred, y_true):\n",
    "    total = 0\n",
    "    rows = y_pred.shape[0]\n",
    "    cols = y_pred.shape[1]\n",
    "    for i in range(0, rows):\n",
    "        row_correct = 0\n",
    "        for j in range(0, cols):\n",
    "            if y_pred[i,j] == y_true[i,j]:\n",
    "                row_correct += 1\n",
    "        total += row_correct/cols\n",
    "    return total/rows\n",
    "\n",
    "def partial_accuracy_and_contingency(y_pred, y_true, mlb):\n",
    "    total = 0\n",
    "    a= np.zeros(shape=y_true.shape)\n",
    "    rows = y_pred.shape[0]\n",
    "    cols = y_pred.shape[1]\n",
    "    df = pd.DataFrame(a, columns = mlb.classes_)\n",
    "    for i in range(0, rows):\n",
    "        row_correct = 0\n",
    "        for j, label in enumerate(mlb.classes_):\n",
    "            if y_pred[i,j] == y_true[i,j]:\n",
    "                row_correct += 1\n",
    "                df.at[i, label] = 1\n",
    "            else:\n",
    "                df.at[i, label] = 0\n",
    "\n",
    "        total += row_correct/cols\n",
    "\n",
    "    return (total/rows, df)\n",
    "\n",
    "def contingency_table_and_t (clf1, clf2):\n",
    "    a = 0 #clf1 pos, clf2 pos\n",
    "    b = 0 #clf1 pos, clf2 neg\n",
    "    c = 0 #clf1 neg, clf2 pos\n",
    "    d = 0 #clf1 neg, clf2 neg\n",
    "    \n",
    "    for index, value in clf1.items():\n",
    "        if value == 1 and clf2[index] == 1:\n",
    "            a+=1\n",
    "        elif value == 1 and clf2[index] == 0: #classifier 1 right, classifier 2 wrong\n",
    "            b+=1\n",
    "        elif value == 0 and clf2[index] == 1: #classifier 1 wrong, classifier 2 right\n",
    "            c+=1\n",
    "        else:\n",
    "            d+=1\n",
    "    print(\"[\"+str(a)+\", \"+str(b)+\"]\")\n",
    "    print(\"[\"+str(c)+\", \"+str(d)+\"]\")\n",
    "    if b == 0 and c ==0:\n",
    "        print(\"both b and c are zero\")\n",
    "        t=0\n",
    "    else:\n",
    "        t = (((b-c)-1)**2)/(b+c)\n",
    "    return ([[a,b],[c,d]], t)\n",
    "\n",
    "def add_noise(val, noise_level):\n",
    "    rand = random.uniform(0, 1)\n",
    "    if rand <= noise_level:\n",
    "        if val == -1:\n",
    "            val = 1\n",
    "        elif val == 1:\n",
    "            val = -1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#x_d7= trainData_d7.dropna()\n",
    "#######################################################################################################\n",
    "\n",
    "##trainData_d7 = pd.read_csv(\"depth7_all_combos.csv\")\n",
    "##trainData_d7 = trainData_d7.applymap(lambda x: add_noise(x,.01))\n",
    "\n",
    "#These four lines remove duplicates\n",
    "##trainData_d7['Labels'] = trainData_d7['Labels'].map(lambda x: create_list_from_string(x))\n",
    "##trainData_d7['Labels'] = trainData_d7['Labels'].astype(str)\n",
    "##trainData_d7 = trainData_d7.drop_duplicates('Labels', keep='first', ignore_index=True)\n",
    "##trainData_d7['Labels'] = trainData_d7['Labels'].map(lambda x: create_list_from_string(x))\n",
    "\n",
    "##testData_d7_MWPM = graph_with_errs_d7(trainData_d7)\n",
    "\n",
    "#transforms the data to encoding for ML\n",
    "##mlb_d7 = MultiLabelBinarizer()\n",
    "##mlb_d7.fit(trainData_d7['Labels'])\n",
    "##df = pd.DataFrame(mlb_d7.transform(trainData_d7['Labels']))\n",
    "##df['Labels']= df.values.tolist()\n",
    "##trainData_d7 = trainData_d7.drop(['Labels'], axis=1)\n",
    "##trainData_d7 = pd.concat([df[\"Labels\"],testData_d7_MWPM, trainData_d7], axis=1, ignore_index=True)\n",
    "##trainData_d7.columns = [\"Labels\",\"XSyn\", \"ZSyn\",\"X0\", \"Z1\", \"X2\", \"X3\", \"Z4\", \"X5\", \"X6\", \"Z7\", \"X8\", \"Z9\", \"Z10\", \"X11\", \"Z12\", \"X13\", \"Z14\", \"X15\", \"Z16\", \"Z17\", \"X18\", \"Z19\",\"X20\", \"Z21\", \"X22\", \"Z23\", \"Z24\", \"X25\", \"Z26\", \"X27\", \"Z28\", \"X29\", \"Z30\", \"Z31\", \"X32\", \"Z33\", \"X34\", \"Z35\", \"X36\", \"Z37\", \"Z38\", \"X39\", \"X40\", \"Z41\", \"X42\", \"X43\", \"Z44\", \"X45\", \"X46\", \"Z47\"]\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "##trainData_d5 = pd.read_csv(\"depth5_all_combos.csv\") # RM FOR D7 TESTS\n",
    "##trainData_d5 = trainData_d5.applymap(lambda x: add_noise(x,.01)) #was .05  # RM FOR D7 TESTS\n",
    "#These four lines remove duplicates\n",
    "##trainData_d5['Labels'] = trainData_d5['Labels'].map(lambda x: create_list_from_string(x)) # RM FOR D7 TESTS\n",
    "##trainData_d5['Labels'] = trainData_d5['Labels'].astype(str) # RM FOR D7 TESTS\n",
    "##trainData_d5 = trainData_d5.drop_duplicates('Labels', keep='first', ignore_index=True) # RM FOR D7 TESTS\n",
    "##trainData_d5['Labels'] = trainData_d5['Labels'].map(lambda x: create_list_from_string(x)) # RM FOR D7 TESTS\n",
    "\n",
    "\n",
    "##testData_d5_MWPM = graph_with_errs_d5(trainData_d5) # RM FOR D7 TESTS\n",
    "\n",
    "\n",
    "#transforms the data to encoding for ML\n",
    "##mlb = MultiLabelBinarizer() # RM FOR D7 TESTS\n",
    "##mlb.fit(trainData_d5['Labels']) # RM FOR D7 TESTS\n",
    "##df = pd.DataFrame(mlb.transform(trainData_d5['Labels'])) # RM FOR D7 TESTS\n",
    "##df['Labels']= df.values.tolist() # RM FOR D7 TESTS\n",
    "##trainData_d5 = trainData_d5.drop(['Labels'], axis=1) # RM FOR D7 TESTS\n",
    "##trainData_d5 = pd.concat([df[\"Labels\"], testData_d5_MWPM, trainData_d5], axis=1, ignore_index=True) # RM FOR D7 TESTS\n",
    "##trainData_d5.columns = [\"Labels\",\"XSyn\", \"ZSyn\",\"X0\",\"Z1\",\"X2\",\"X3\",\"Z4\",\"X5\",\"Z6\",\"Z7\",\"X8\",\"Z9\",\"X10\",\"Z11\",\"Z12\",\"X13\",\"Z14\",\"X15\",\"Z16\",\"Z17\",\"X18\",\"X19\",\"Z20\",\"X21\",\"X22\",\"Z23\"] # RM FOR D7 TESTS\n",
    "#########################################################################################\n",
    "\n",
    "#Has no duplicates, small enough to check manually\n",
    "# Change the CSV file to whichever dataset I'm using\n",
    "trainData_d3 = pd.read_csv(\"v2samples-10000.csv\") # RM FOR D7 TESTS\n",
    "\n",
    "trainData_d3[\"Labels\"] = trainData_d3['Labels'].map(lambda x: create_list_from_string(x)) # RM FOR D7 TESTS\n",
    "trainData_d3 = trainData_d3.applymap(lambda x: add_noise(x,.01)) # RM FOR D7 TESTS\n",
    "\n",
    "testData_d3_MWPM = graph_with_errs_d3(trainData_d3) # RM FOR D7 TESTS\n",
    "\n",
    "mlb_d3 = MultiLabelBinarizer() # RM FOR D7 TESTS\n",
    "mlb_d3.fit(trainData_d3[\"Labels\"]) # RM FOR D7 TESTS\n",
    "df = pd.DataFrame(mlb_d3.transform(trainData_d3['Labels'])) # RM FOR D7 TESTS\n",
    "df['Labels']= df.values.tolist() # RM FOR D7 TESTS\n",
    "trainData_d3 = trainData_d3.drop(['Labels'], axis=1) # RM FOR D7 TESTS\n",
    "trainData_d3 = pd.concat([df['Labels'], testData_d3_MWPM, trainData_d3], axis=1, ignore_index=True) # RM FOR D7 TESTS\n",
    "trainData_d3.columns = [\"Labels\",\"XSyn\", \"ZSyn\", \"X0\", \"Z1\", \"X2\", \"Z3\", \"Z4\", \"X5\", \"X6\", \"Z7\"] # RM FOR D7 TESTS\n",
    "#########################################################################################\n",
    "y_d3 = trainData_d3[\"Labels\"] # RM FOR D7 TESTS\n",
    "x_d3 = trainData_d3.drop([\"Labels\"], axis=1) # RM FOR D7 TESTS\n",
    "\n",
    "##y_d5 = trainData_d5[\"Labels\"]  # RM FOR D7 TESTS\n",
    "##x_d5 = trainData_d5.drop([\"Labels\"], axis=1)  # RM FOR D7 TESTS\n",
    "\n",
    "##y_d7 = trainData_d7[\"Labels\"]\n",
    "##x_d7 = trainData_d7.drop([\"Labels\"], axis=1)\n",
    "\n",
    "\n",
    "x_d3 = x_d3.replace([-1], 0) # RM FOR D7 TESTS\n",
    "##x_d5 = x_d5.replace([-1], 0) # RM FOR D7 TESTS\n",
    "##x_d7 = x_d7.replace([-1], 0)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brett: Not sure why this was here. It's just a duplicate. Consider removing.\n",
    "##y_d7 = trainData_d7[\"Labels\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for creating lookup tables here:\n",
    "from collections import defaultdict\n",
    "from math import log2\n",
    "\n",
    "def generateAllBinaryStrings(n, arr, i, lookup):  \n",
    "    if i == n: \n",
    "        lookup.setBitStringArray(arr, n)  \n",
    "        return\n",
    "      \n",
    "    # First assign \"0\" at ith position  \n",
    "    # and try for all other permutations  \n",
    "    # for remaining positions  \n",
    "    arr[i] = 0\n",
    "    generateAllBinaryStrings(n, arr, i + 1, lookup)  \n",
    "  \n",
    "    # And then assign \"1\" at ith position  , \n",
    "    # and try for all other permutations  \n",
    "    # for remaining positions  \n",
    "    arr[i] = 1\n",
    "    generateAllBinaryStrings(n, arr, i + 1, lookup)\n",
    "\n",
    "class lookup_decoder:\n",
    "    \n",
    "    def __init__(self, depth):\n",
    "        #self.lookupTable = defaultdict()\n",
    "        self.lookupTable = {}\n",
    "        self.distributions = {}\n",
    "        self.depth = depth\n",
    "        #generating all possible syndrome observations\n",
    "        #arr = [None] * (depth**2 - 1)\n",
    "        #generateAllBinaryStrings((depth**2 - 1), arr, 0, self)\n",
    "        \n",
    "    def setBitStringArray(self, arr, n): \n",
    "        new_str = \"\"\n",
    "        for i in range(0, n):  \n",
    "            new_str += str(arr[i])\n",
    "        self.lookupTable.update({new_str:defaultdict()})  \n",
    "        \n",
    "    def update_table (self, syndrome, phys_errs):\n",
    "        #all the keys are made in the init, so simply update the physical error combinations for the given syndrome\n",
    "        if syndrome not in self.lookupTable:\n",
    "            self.lookupTable[syndrome] = {}\n",
    "            self.lookupTable[syndrome][phys_errs] = 1\n",
    "            return\n",
    "        \n",
    "        if phys_errs not in self.lookupTable[syndrome]:\n",
    "            self.lookupTable[syndrome].update({phys_errs: 1})\n",
    "        else:\n",
    "            self.lookupTable[syndrome][phys_errs] += 1\n",
    "     \n",
    "    def get_probable_error(self, syndrome):\n",
    "        return_key = []\n",
    "\n",
    "        if syndrome not in self.lookupTable.keys():\n",
    "            for i in range(2* int(self.depth**2) + 1):\n",
    "                return_key.append(0)\n",
    "            return return_key\n",
    "        \n",
    "        key, value = max(self.lookupTable[syndrome].items(), key=lambda x:x[1])\n",
    "        \n",
    "        for character in key:\n",
    "            if character == '0' or character == '1':\n",
    "                return_key.append(int(character))\n",
    "                \n",
    "        return return_key\n",
    "        \n",
    "    def make_distribution_graph(self, syn):\n",
    "        \n",
    "        plt.bar(list(self.lookupTable[syn].keys()), self.lookupTable[syn].values(), color='g')\n",
    "        plt.show()\n",
    "        \n",
    "    def syndrome_count_graph(self):\n",
    "        graph_dict = {}\n",
    "        for syn in self.lookupTable:\n",
    "            graph_dict.update({syn:sum(self.lookupTable[syn].values())})\n",
    "        plt.ylim((0,4))\n",
    "        plt.bar(graph_dict.keys(), graph_dict.values())\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def length_of_lookup(self):\n",
    "        print(len(self.lookupTable))\n",
    "        \n",
    "            \n",
    "    def get_entropies(self):\n",
    "        entropies = {}\n",
    "        for syn in self.lookupTable:\n",
    "            total = sum(self.lookupTable[syn].values())\n",
    "            h = 0\n",
    "            for key in self.lookupTable[syn]:\n",
    "                p = self.lookupTable[syn][key]/total\n",
    "                h += p+log2(p)\n",
    "            entropies[syn] = -h\n",
    "        print(entropies)\n",
    "            \n",
    "    def get_syndromes(self):\n",
    "        return self.lookupTable.keys()\n",
    "                     \n",
    "    def print_lookup(self):\n",
    "        for syn in self.lookupTable:\n",
    "            print(self.lookupTable[syn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_plut(table, data_x, data_y):\n",
    "    i = 0\n",
    "    for index, x in enumerate(data_x):\n",
    "        syn = \"\".join([str(i) for i in x])\n",
    "        syn = syn.replace(\".0\",\"\")\n",
    "        labels = np.array2string(np.array(data_y[i]), precision=1, separator='',suppress_small=True).replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "        table.update_table(syn, labels)\n",
    "        i+=1\n",
    "    return table\n",
    "\n",
    "\n",
    "def test_plut(table, test_set):\n",
    "    predictions_lookup = []\n",
    "    for index, x in enumerate(test_set):\n",
    "        syn_x = \"\".join([str(i) for i in x])\n",
    "        syn_x = syn_x.replace(\".0\",\"\")\n",
    "        predictions_lookup.append(table.get_probable_error(syn_x))\n",
    "    return np.array(predictions_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_FFNN_model_DepthThree(depth):\n",
    "    model = Sequential()\n",
    "    layers = 4\n",
    "    #input layer\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    \n",
    "    #hidden layers go here\n",
    "    for i in range(layers):\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(19 , activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=tf.keras.optimizers.SGD(learning_rate=0.05),\n",
    "                  metrics=['accuracy']) #CHANGE  (added tf., changed lr to learning_rate)\n",
    "    return model\n",
    "\n",
    "#make any needed changes here\n",
    "def compile_FFNN_model_DepthFive(depth):\n",
    "    model = Sequential()\n",
    "    layers = 4\n",
    "    \n",
    "    #input layer\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    \n",
    "    #hidden layers go here\n",
    "    for i in range(layers):\n",
    "        model.add(Dense(240, activation='relu'))\n",
    "    \n",
    "    #model.add(Dense((2*depth**2) , activation='sigmoid'))\n",
    "    model.add(Dense(51, activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=tf.keras.optimizers.SGD(learning_rate=0.05),\n",
    "                  metrics=['accuracy']) #CHANGE (added tf.)\n",
    "    return model\n",
    "\n",
    "\n",
    "#make any needed changes here\n",
    "def compile_FFNN_model_DepthSeven(depth):\n",
    "    model = Sequential()\n",
    "    layers = 4\n",
    "    \n",
    "    #input layer\n",
    "    model.add(Dense(48, activation='relu'))\n",
    "    \n",
    "    #hidden layers go here\n",
    "    for i in range(layers):\n",
    "        model.add(Dense(400, activation='relu'))\n",
    "    \n",
    "    #model.add(Dense((2*depth**2) , activation='sigmoid'))\n",
    "    model.add(Dense(99, activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=tf.keras.optimizers.SGD(learning_rate=0.05),\n",
    "                  metrics=['accuracy']) #CHANGE  (added tf.)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\research\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\research\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\research\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Labels'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13328/96145152.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m#test MWPM decoder for this fold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m#labels = targets[train], features = inputs[train]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mx_test_d3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranslate_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestData_d3_MWPM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlb_d3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mdecoding_d3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_mwpm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_new_decoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_d3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.03\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mdecoding_d3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'combine'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoding_d3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13328/2415224786.py\u001b[0m in \u001b[0;36mtranslate_to_graph\u001b[1;34m(df_graph, labels, mlb)\u001b[0m\n\u001b[0;32m    145\u001b[0m                     \u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Labels\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m                 \u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\research\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\research\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\research\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Labels'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# D3 TESTING\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "inputs = x_d3.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = y_d3.copy()\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "n_classes = 19\n",
    "\n",
    "acc_per_fold = []\n",
    "f1_per_fold = []\n",
    "time_per_fold = []\n",
    "\n",
    "\n",
    "acc_per_fold_plut = []\n",
    "f1_per_fold_plut = []\n",
    "time_per_fold_plut = []\n",
    "\n",
    "acc_per_fold_mwpm = []\n",
    "f1_per_fold_mwpm = []\n",
    "time_per_fold_mwpm = []\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "aucs_classes = {}\n",
    "for i in mlb_d3.classes_:\n",
    "    aucs_classes[i] = []\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#for i in range(5):\n",
    "    \n",
    "    # K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for i, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "    i_train = inputs[train].copy()\n",
    "    i_test = inputs[test].copy()\n",
    "    x_test_d3 = i_test[:,:2]\n",
    "    inputs_train = i_train[:,3:]\n",
    "    inputs_test = i_test[:,3:]\n",
    "    ####################################################################################################\n",
    "    #test MWPM decoder for this fold\n",
    "    #labels = targets[train], features = inputs[train]\n",
    "    #x_test_d3 = translate_to_graph(testData_d3_MWPM, targets[test], mlb_d3)\n",
    "    decoding_d3, time_mwpm = do_new_decoding(x_test_d3, 3, .03)\n",
    "    decoding_d3['combine'] = decoding_d3[[0, 1]].values.tolist()\n",
    "    decoding_d3['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "    decoding_d3 = np.array(decoding_d3[0])\n",
    "\n",
    "    time_per_fold_mwpm.append(time_mwpm)\n",
    "\n",
    "    pred_mwpm = mlb_d3.transform(decoding_d3)\n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_mwpm)\n",
    "    else:\n",
    "        acc, contingency_mwpm = partial_accuracy_and_contingency(targets[test], pred_mwpm, mlb_d3)\n",
    "        \n",
    "    acc_per_fold_mwpm.append(acc)\n",
    "    f1_per_fold_mwpm.append(f1_score(targets[test], pred_mwpm, average='micro'))\n",
    "\n",
    "\n",
    "    #####################################################################################################\n",
    "    #test the plut decoder for this fold\n",
    "\n",
    "    lookup_d3 = lookup_decoder(3)\n",
    "\n",
    "    lookup_d3 = train_plut(lookup_d3, inputs_train, targets[train])\n",
    "\n",
    "    start = time.time_ns()\n",
    "    pred_plut_d3 = test_plut(lookup_d3, inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_plut_d3)\n",
    "    else:\n",
    "        acc, contingency_plut = partial_accuracy_and_contingency(targets[test], pred_plut_d3, mlb_d3)\n",
    "\n",
    "    acc_per_fold_plut.append(acc)\n",
    "    f1_per_fold_plut.append(f1_score(targets[test], pred_plut_d3, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #Test the NN decoder for this fold\n",
    "\n",
    "    model = compile_FFNN_model_DepthThree(3)\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    \n",
    "    inputs_train = np.asarray(inputs_train).astype(np.int) #CHANGE (added)\n",
    "    targets[train] = np.asarray(targets[train]).astype(np.int) #CHANGE (added)\n",
    "    \n",
    "    history = model.fit(\n",
    "        inputs_train, targets[train],\n",
    "        validation_split=.2,\n",
    "        epochs=200,\n",
    "        verbose=1)\n",
    "\n",
    "   # Generate generalization metrics\n",
    "    inputs_test = np.asarray(inputs_test).astype(np.int) #CHANGE (added)\n",
    "    targets[test] = np.asarray(targets[test]).astype(np.int) #CHANGE (added)\n",
    "    \n",
    "    scores = model.evaluate(inputs_test, targets[test], verbose=0)\n",
    "\n",
    "    #get the time to predicting test\n",
    "    start = time.time_ns()\n",
    "    predictions_d3 = model.predict(inputs_test) #change here\n",
    "    end = time.time_ns()\n",
    "    time_per_fold.append((end - start)/ (10 ** 9))\n",
    "\n",
    "    #threshold based on previous tests with train_test_split in hyperparameter tuning\n",
    "    pred=predictions_d3.copy() #change here\n",
    "    pred[pred>=.1]=1 \n",
    "    pred[pred<.1]=0\n",
    "    \n",
    "    if fold_no <5:\n",
    "        acc = scores[1]\n",
    "    else:\n",
    "        acc, contingency_nn = partial_accuracy_and_contingency(targets[test], pred, mlb_d3)\n",
    "\n",
    "    acc_per_fold.append(acc)\n",
    "    f1_per_fold.append(f1_score(targets[test], pred, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #comput ROC AUC for classes and the mircoaverage\n",
    "    fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d3.ravel())\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    #get the AUCs of each class, used to get average AUC of each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d3[:, i]) #change here\n",
    "        aucs_classes[mlb_d3.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "        \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "        \n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb_d3.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "    \n",
    "############print mean and stdev of AUC of each class#####################      \n",
    "    \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print(\"#####################################################################################\")\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print(\"#####################################################################################\")\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "print(\"#####################################################################################\")\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 3 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_train_d3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4540/211353708.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fit model on training data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m history = model.fit(\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train_d3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_train_d3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train_d3' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "model = compile_FFNN_model_DepthThree(3)\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x=x_train_d3.values,\n",
    "    y=Y_train_d3,\n",
    "    validation_split=.25,\n",
    "    epochs=200\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss (MSE)')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Make a quick epoch vs. loss plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Depth 3 Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Make a quick epoch vs. accuracy plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Depth 3 Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4540/349347309.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions_d3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_d3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Time: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "predictions_d3 = model.predict(x_test_d3.values)\n",
    "end = time.time()\n",
    "print(\"Time: \" + str(end - start))\n",
    "# predict\n",
    "\n",
    "thresholds=[0.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "for val in thresholds:\n",
    "    pred=predictions_d3.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "\n",
    "    precision = precision_score(Y_test_d3, pred, average='micro')\n",
    "    recall = recall_score(Y_test_d3, pred, average='micro')\n",
    "    f1 = f1_score(Y_test_d3, pred, average='micro')\n",
    "   \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "    print(\"Accuracy = \",accuracy_score(Y_test_d3, pred))\n",
    "    print(\"Partial Accuracy = \",partial_accuracy(Y_test_d3, pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D5 TESTING\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "inputs = x_d5.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = np.array(y_d5)\n",
    "#targets = np.stack(targets)\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "\n",
    "n_classes = 51\n",
    "\n",
    "acc_per_fold = []\n",
    "f1_per_fold = []\n",
    "time_per_fold = []\n",
    "\n",
    "acc_per_fold_plut = []\n",
    "f1_per_fold_plut = []\n",
    "time_per_fold_plut = []\n",
    "\n",
    "acc_per_fold_mwpm = []\n",
    "f1_per_fold_mwpm = []\n",
    "time_per_fold_mwpm = []\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "aucs_classes = {}\n",
    "for i in mlb.classes_:\n",
    "    aucs_classes[i] = []\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for i, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "    i_train = inputs[train].copy()\n",
    "    i_test = inputs[test].copy()\n",
    "    x_test_d5 = i_test[:,:2]\n",
    "    inputs_train = i_train[:,3:]\n",
    "    inputs_test = i_test[:,3:]\n",
    "    \n",
    "    ####################################################################################################\n",
    "    #test MWPM decoder for this fold\n",
    "    #labels = targets[train], features = inputs[train]\n",
    "    #x_test_d5 = translate_to_graph(testData_d5_MWPM, targets[test], mlb)\n",
    "    decoding_d5, time_mwpm = do_new_decoding(x_test_d5, 5, 0)\n",
    "    decoding_d5['combine'] = decoding_d5[[0, 1]].values.tolist()\n",
    "    decoding_d5['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "    decoding_d5 = np.array(decoding_d5[0])\n",
    "                                              \n",
    "    time_per_fold_mwpm.append(time_mwpm)\n",
    "                                              \n",
    "    pred_mwpm = mlb.transform(decoding_d5)\n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_mwpm)\n",
    "    else:\n",
    "        acc, contingency_mwpm = partial_accuracy_and_contingency(targets[test], pred_mwpm, mlb)\n",
    "        \n",
    "    acc_per_fold_mwpm.append(acc)\n",
    "    f1_per_fold_mwpm.append(f1_score(targets[test], pred_mwpm, average='micro'))\n",
    "    \n",
    "    #####################################################################################################\n",
    "    #test the plut decoder for this fold\n",
    "    \n",
    "    lookup_d5 = lookup_decoder(5)\n",
    "    \n",
    "    lookup_d5 = train_plut(lookup_d5, inputs_train, targets[train])\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    pred_plut_d5 = test_plut(lookup_d5, inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_plut_d5)\n",
    "    else:\n",
    "        acc, contingency_plut = partial_accuracy_and_contingency(targets[test], pred_plut_d5, mlb)\n",
    "        \n",
    "    acc_per_fold_plut.append(acc)\n",
    "    f1_per_fold_plut.append(f1_score(targets[test], pred_plut_d5, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #Test the NN decoder for this fold\n",
    "    \n",
    "    model_d5 = compile_FFNN_model_DepthFive(5)\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    \n",
    "    inputs_train = np.asarray(inputs_train).astype(np.int) #CHANGE (added)\n",
    "    targets[train] = np.asarray(targets[train]).astype(np.int) #CHANGE (added)\n",
    "    \n",
    "    history = model_d5.fit(\n",
    "    inputs_train,\n",
    "    targets[train],\n",
    "    validation_split=.25,\n",
    "    epochs = 800\n",
    ")\n",
    "   # Generate generalization metrics\n",
    "\n",
    "    inputs_test = np.asarray(inputs_test).astype(np.int) #CHANGE (added)\n",
    "    targets[test] = np.asarray(targets[test]).astype(np.int) #CHANGE (added)\n",
    "    scores = model_d5.evaluate(inputs_test, targets[test], verbose=0)\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    predictions_d5 = model_d5.predict(inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    #threshold based on previous tests with train_test_split in hyperparameter tuning\n",
    "    pred=predictions_d5.copy() #change here\n",
    "    pred[pred>=.4]=1 \n",
    "    pred[pred<.4]=0\n",
    "    \n",
    "    if fold_no < 5:\n",
    "        acc = scores[1]\n",
    "    else:\n",
    "        acc, contingency_nn = partial_accuracy_and_contingency(targets[test], pred, mlb)\n",
    "\n",
    "    acc_per_fold.append(acc)\n",
    "    f1_per_fold.append(f1_score(targets[test], pred, average='micro'))\n",
    "\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d5.ravel())\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    \n",
    "    #get the AUCs of each class, used to get average AUC of each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d5[:, i]) \n",
    "        aucs_classes[mlb.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "        \n",
    "        \n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print(\"##############################################################################\")\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print(\"##############################################################################\")\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "print(\"##############################################################################\")\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "    \n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 5 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D7 TESTING\n",
    "\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "inputs = x_d7.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = np.array(y_d7)\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "n_classes = 99\n",
    "\n",
    "acc_per_fold = []\n",
    "f1_per_fold = []\n",
    "time_per_fold = []\n",
    "\n",
    "acc_per_fold_plut = []\n",
    "f1_per_fold_plut = []\n",
    "time_per_fold_plut = []\n",
    "\n",
    "acc_per_fold_mwpm = []\n",
    "f1_per_fold_mwpm = []\n",
    "time_per_fold_mwpm = []\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "aucs_classes = {}\n",
    "for i in mlb_d7.classes_:\n",
    "    aucs_classes[i] = []\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for i, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "    i_train = inputs[train].copy()\n",
    "    i_test = inputs[test].copy()\n",
    "    t_test = targets[test].copy()\n",
    "    x_test_d7 = i_test[:,:2]\n",
    "    inputs_train = i_train[:,3:]\n",
    "    inputs_test = i_test[:,3:]\n",
    "    indices = np.random.choice(inputs[test].shape[0], 20000, replace=False)\n",
    "    x_test_d7 = x_test_d7[indices]\n",
    "    inputs_test_2 = inputs_test[indices]\n",
    "    targets_test_2 = targets[test][indices]\n",
    "    ####################################################################################################\n",
    "    #test MWPM decoder for this fold\n",
    "    #labels = targets[train], features = inputs[train]\n",
    "   # x_test_d7 = translate_to_graph(testData_d7_MWPM, targs, mlb_d7)\n",
    "    decoding_d7, time_mwpm = do_new_decoding(x_test_d7, 7, 0)\n",
    "    decoding_d7['combine'] = decoding_d7[[0, 1]].values.tolist()\n",
    "    decoding_d7['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "    decoding_d7 = np.array(decoding_d7[0])\n",
    "                                              \n",
    "    time_per_fold_mwpm.append(time_mwpm)\n",
    "                                              \n",
    "    pred_mwpm = mlb_d7.transform(decoding_d7)\n",
    "\n",
    "    if fold_no < 3:\n",
    "        acc = partial_accuracy(targets_test_2, pred_mwpm)\n",
    "    else:\n",
    "        acc, contingency_mwpm = partial_accuracy_and_contingency(targets_test_2, pred_mwpm, mlb_d7)\n",
    "        \n",
    "    acc_per_fold_mwpm.append(acc)\n",
    "    f1_per_fold_mwpm.append(f1_score(targets_test_2, pred_mwpm, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #test the plut decoder for this fold\n",
    "    \n",
    "    lookup_d7 = lookup_decoder(7)\n",
    "    \n",
    "    lookup_d7 = train_plut(lookup_d7, inputs_train, targets[train])\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    pred_plut_d7 = test_plut(lookup_d7, inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    if fold_no < 3:\n",
    "        acc = partial_accuracy(targets[test], pred_plut_d7)\n",
    "        f1 = f1_score(targets[test], pred_plut_d7, average='micro')\n",
    "    else:\n",
    "        pred_plut_d7 = test_plut(lookup_d7, inputs_test_2)\n",
    "        f1 = f1_score(targets_test_2, pred_plut_d7, average='micro')\n",
    "        acc, contingency_plut = partial_accuracy_and_contingency(targets_test_2, pred_plut_d7, mlb_d7)\n",
    "        \n",
    "    acc_per_fold_plut.append(acc)\n",
    "    f1_per_fold_plut.append(f1)\n",
    "    \n",
    "    #####################################################################################################\n",
    "    #Test the NN decoder for this fold\n",
    "    \n",
    "    model_d7 = compile_FFNN_model_DepthSeven(7)\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    \n",
    "    inputs_train = np.asarray(inputs_train).astype(np.int) #CHANGE (added)\n",
    "    targets[train] = np.asarray(targets[train]).astype(np.int) #CHANGE (added)\n",
    "    \n",
    "    history = model_d7.fit(\n",
    "        x=inputs_train ,\n",
    "        y=targets[train],\n",
    "        validation_split=.25,\n",
    "        epochs= 150)\n",
    "    \n",
    "   # Generate generalization metrics\n",
    "    \n",
    "    inputs_test = np.asarray(inputs_test).astype(np.int) #CHANGE (added)\n",
    "    targets[test] = np.asarray(targets[test]).astype(np.int) #CHANGE (added)\n",
    "    \n",
    "    scores = model_d7.evaluate(inputs_test, targets[test], verbose=0)\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    predictions_d7 = model_d7.predict(inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    #threshold based on previous tests with train_test_split in hyperparameter tuning\n",
    "    pred=predictions_d7.copy() #change here\n",
    "    pred[pred>=.5]=1 \n",
    "    pred[pred<.5]=0\n",
    "     \n",
    "    if fold_no < 3:\n",
    "        acc = scores[1]\n",
    "        f1 = f1_score(targets[test], pred, average='micro')\n",
    "    else:\n",
    "        inputs_test_2 = np.asarray(inputs_test_2).astype(np.int) #CHANGE (added)\n",
    "        pred = model_d7.predict(inputs_test_2)\n",
    "        pred[pred>=.5]=1 \n",
    "        pred[pred<.5]=0\n",
    "        acc, contingency_nn = partial_accuracy_and_contingency(targets_test_2, pred, mlb_d7)\n",
    "        f1 = f1_score(targets_test_2, pred, average='micro')\n",
    " \n",
    "    acc_per_fold.append(acc)\n",
    "    f1_per_fold.append(f1)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d7.ravel())\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    \n",
    "    #get the AUCs of each class, used to get average AUC of each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d7[:, i]) \n",
    "        aucs_classes[mlb_d7.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "\n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "print(\"Train complete\")\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "print(len(mlb_d7.classes_))\n",
    "\n",
    "for class_ in mlb_d7.classes_:\n",
    "    print(\"interating\")\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 7 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test MWPM decoder for this fold\n",
    "#labels = targets[train], features = inputs[train]\n",
    "# x_test_d7 = translate_to_graph(testData_d7_MWPM, targs, mlb_d7)\n",
    "\"\"\"\n",
    "decoding_d7, time_mwpm = do_new_decoding(x_test_d7, 7, 0)\n",
    "decoding_d7['combine'] = decoding_d7[[0, 1]].values.tolist()\n",
    "decoding_d7['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "decoding_d7 = np.array(decoding_d7[0])\n",
    "\n",
    "time_per_fold_mwpm.append(time_mwpm)\n",
    "\n",
    "pred_mwpm = mlb_d7.transform(decoding_d7)\n",
    "\n",
    "if fold_no < 3:\n",
    "    acc = partial_accuracy(targets_test_2, pred_mwpm)\n",
    "else:\n",
    "    acc, contingency_mwpm = partial_accuracy_and_contingency(targets_test_2, pred_mwpm, mlb_d7)\"\"\"\n",
    "\n",
    "#acc_per_fold_mwpm.append(acc)\n",
    "#f1_per_fold_mwpm.append(f1_score(targets_test_2, pred_mwpm, average='micro'))\n",
    "\n",
    "#####################################################################################################\n",
    "#test the plut decoder for this fold\n",
    "\n",
    "#lookup_d7 = lookup_decoder(7)\n",
    "\n",
    "#lookup_d7 = train_plut(lookup_d7, inputs_train, targets[train])\n",
    "\n",
    "#start = time.time_ns()\n",
    "#pred_plut_d7 = test_plut(lookup_d7, inputs_test)\n",
    "#end = time.time_ns() \n",
    "#time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "\n",
    "pred_plut_d7 = test_plut(lookup_d7, inputs_test_2)\n",
    "#f1 = f1_score(targets_test_2, pred_plut_d7, average='micro')\n",
    "acc, contingency_plut = partial_accuracy_and_contingency(targets_test_2, pred_plut_d7, mlb_d7)\n",
    "\n",
    "#acc_per_fold_plut.append(acc)\n",
    "#f1_per_fold_plut.append(f1)\n",
    "\n",
    "#####################################################################################################\n",
    "#Test the NN decoder for this fold\n",
    "\"\"\"\n",
    "model_d7 = compile_FFNN_model_DepthSeven(7)\n",
    "\n",
    "# Generate a print\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "# Fit data to model\n",
    "history = model_d7.fit(\n",
    "    x=inputs_train ,\n",
    "    y=targets[train],\n",
    "    validation_split=.25,\n",
    "    epochs= 150)\"\"\"\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d7.ravel())\n",
    "tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "tprs[-1][0] = 0.0\n",
    "roc_auc = auc(fpr, tpr)\n",
    "aucs.append(roc_auc)\n",
    "plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "#get the AUCs of each class, used to get average AUC of each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d7[:, i]) \n",
    "    aucs_classes[mlb_d7.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "\n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb_d7.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 7 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test MWPM decoder for this fold\n",
    "#labels = targets[train], features = inputs[train]\n",
    "# x_test_d7 = translate_to_graph(testData_d7_MWPM, targs, mlb_d7)\n",
    "\"\"\"\n",
    "decoding_d7, time_mwpm = do_new_decoding(x_test_d7, 7, 0)\n",
    "decoding_d7['combine'] = decoding_d7[[0, 1]].values.tolist()\n",
    "decoding_d7['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "decoding_d7 = np.array(decoding_d7[0])\n",
    "\n",
    "time_per_fold_mwpm.append(time_mwpm)\n",
    "\n",
    "pred_mwpm = mlb_d7.transform(decoding_d7)\n",
    "\n",
    "if fold_no < 3:\n",
    "    acc = partial_accuracy(targets_test_2, pred_mwpm)\n",
    "else:\n",
    "    acc, contingency_mwpm = partial_accuracy_and_contingency(targets_test_2, pred_mwpm, mlb_d7)\"\"\"\n",
    "\n",
    "#acc_per_fold_mwpm.append(acc)\n",
    "#f1_per_fold_mwpm.append(f1_score(targets_test_2, pred_mwpm, average='micro'))\n",
    "\n",
    "#####################################################################################################\n",
    "#test the plut decoder for this fold\n",
    "\n",
    "#lookup_d7 = lookup_decoder(7)\n",
    "\n",
    "#lookup_d7 = train_plut(lookup_d7, inputs_train, targets[train])\n",
    "\n",
    "#start = time.time_ns()\n",
    "#pred_plut_d7 = test_plut(lookup_d7, inputs_test)\n",
    "#end = time.time_ns() \n",
    "#time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "\n",
    "if fold_no < 3:\n",
    "    acc = partial_accuracy(targets[test], pred_plut_d7)\n",
    "    f1 = f1_score(targets[test], pred_plut_d7, average='micro')\n",
    "else:\n",
    "    pred_plut_d7 = test_plut(lookup_d7, inputs_test_2)\n",
    "    #f1 = f1_score(targets_test_2, pred_plut_d7, average='micro')\n",
    "    acc, contingency_plut = partial_accuracy_and_contingency(targets_test_2, pred_plut_d7, mlb_d7)\n",
    "\n",
    "#acc_per_fold_plut.append(acc)\n",
    "#f1_per_fold_plut.append(f1)\n",
    "\n",
    "#####################################################################################################\n",
    "#Test the NN decoder for this fold\n",
    "\"\"\"\n",
    "model_d7 = compile_FFNN_model_DepthSeven(7)\n",
    "\n",
    "# Generate a print\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "# Fit data to model\n",
    "history = model_d7.fit(\n",
    "    x=inputs_train ,\n",
    "    y=targets[train],\n",
    "    validation_split=.25,\n",
    "    epochs= 150)\"\"\"\n",
    "\n",
    "pred = model_d7.predict(inputs_test_2)\n",
    "pred[pred>=.5]=1 \n",
    "pred[pred<.5]=0\n",
    "acc, contingency_nn = partial_accuracy_and_contingency(targets_test_2, pred, mlb_d7)\n",
    "f1 = f1_score(targets_test_2, pred, average='micro')\n",
    "\n",
    "#acc_per_fold.append(acc)\n",
    "f1_per_fold.append(f1)\n",
    "\n",
    "# Increase fold number\n",
    "fold_no = fold_no + 1\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d7.ravel())\n",
    "tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "tprs[-1][0] = 0.0\n",
    "roc_auc = auc(fpr, tpr)\n",
    "aucs.append(roc_auc)\n",
    "plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "#get the AUCs of each class, used to get average AUC of each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d7[:, i]) \n",
    "    aucs_classes[mlb_d7.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "\n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb_d7.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 7 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model_d5 = compile_FFNN_model_DepthFive(5)\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "history = model_d5.fit(\n",
    "    x=x_train_d5.values,\n",
    "    y=Y_train_d5,\n",
    "    validation_split=.25,\n",
    "    epochs = 500\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Make a quick epoch vs. loss plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Depth 5 Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Make a quick epoch vs. accuracy plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Depth 5 Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# predict\n",
    "from sklearn.metrics import precision_score,accuracy_score, f1_score, recall_score, hamming_loss\n",
    "\n",
    "start = time.time()\n",
    "predictions_d5 = model_d5.predict(x_test_d5.values)\n",
    "end = time.time()\n",
    "print(\"Time: \" + str(end - start))\n",
    "\n",
    "pred=predictions_d5.copy()\n",
    "\n",
    "thresholds=[0.1, 0.2, 0.3, .4, .5, .6, .7, .8, .9]\n",
    "for val in thresholds:\n",
    "    pred=predictions_d5.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "    \n",
    "  \n",
    "    precision = precision_score(Y_test_d5, pred, average='micro')\n",
    "    recall = recall_score(Y_test_d5, pred, average='micro')\n",
    "    f1 = f1_score(Y_test_d5, pred, average='micro')\n",
    "   \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "    print(\"Accuracy = \",accuracy_score(Y_test_d5, pred))\n",
    "    print(\"Accuracy = \",partial_accuracy(Y_test_d5, pred))\n",
    "    print(\"\\n\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pred=predictions_d5.copy()\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "#look at confusion matrix to see what got misclassified    \n",
    "pred[pred>=.5]=1\n",
    "pred[pred<.5]=0\n",
    "multilabel_confusion_matrix(Y_test_d5, pred)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#look at classifcation report to see what got mislabeled\n",
    "print(classification_report(Y_test_d5, pred))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d7 = compile_FFNN_model_DepthSeven(7)\n",
    "print(\"Fit model on training data\")\n",
    "history = model_d7.fit(\n",
    "    x=x_d7.values,#x=x_train_d7.values,\n",
    "    y=y_d7,#y=Y_train_d7,\n",
    "    validation_split=.25,\n",
    "    epochs= 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a quick epoch vs. loss plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Depth 7 Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a quick epoch vs. accuracy plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Depth 7 Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\n",
    "# predict\n",
    "from sklearn.metrics import precision_score,accuracy_score, f1_score, recall_score, hamming_loss\n",
    "\n",
    "start = time.time()\n",
    "predictions_d7 = model_d7.predict(x_test_d7.values)\n",
    "end = time.time()\n",
    "print(\"Time: \" + str(end - start))\n",
    "\n",
    "pred=predictions_d7.copy()\n",
    "\n",
    "\n",
    "thresholds=[0.1, 0.2, 0.3, .4, .5, .6, .7, .8, .9]\n",
    "for val in thresholds:\n",
    "    pred=predictions_d7.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "    \n",
    "  \n",
    "    precision = precision_score(Y_test_d7, pred, average='micro')\n",
    "    recall = recall_score(Y_test_d7, pred, average='micro')\n",
    "    f1 = f1_score(Y_test_d7, pred, average='micro')\n",
    "   \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "    print(\"Accuracy = \",accuracy_score(Y_test_d7, pred))\n",
    "    print(\"Accuracy = \",partial_accuracy(Y_test_d7, pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "predictions_d7 = model_d7.predict(x_test_d7.values)\n",
    "pred=predictions_d7.copy()\n",
    "\n",
    "n_classes = 99\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test_d7[:, i], pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test_d7.ravel(), pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_4540/2859714260.py:9: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "  mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'micro'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4540/2859714260.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Plot all ROC curves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n\u001b[0m\u001b[0;32m     21\u001b[0m          \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'micro-average ROC curve (area = {0:0.2f})'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"micro\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'micro'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x_train_d3.to_csv(\"x_train_d3_01.csv\")\n",
    "x_test_d3.to_csv(\"x_test_d3_01.csv\")\n",
    "pd.DataFrame(Y_train_d3).to_csv(\"Y_train_d3_01.csv\")\n",
    "pd.DataFrame(Y_test_d3).to_csv(\"Y_test_d3_01.csv\")\n",
    "\n",
    "x_train_d5.to_csv(\"x_train_d5_01.csv\")\n",
    "x_test_d5.to_csv(\"x_test_d5_01.csv\")\n",
    "pd.DataFrame(Y_train_d5).to_csv(\"Y_train_d5_01.csv\")\n",
    "pd.DataFrame(Y_test_d5).to_csv(\"Y_test_d5_01.csv\")\n",
    "\n",
    "x_train_d7.to_csv(\"x_train_d7_01.csv\")\n",
    "x_test_d7.to_csv(\"x_test_d7_01.csv\")\n",
    "pd.DataFrame(Y_train_d7).to_csv(\"Y_train_d7_01.csv\")\n",
    "pd.DataFrame(Y_test_d7).to_csv(\"Y_test_d7_01.csv\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_d7.save(\"model_d7_01.h5\")\n",
    "#model_d5.save(\"model_d5_01.h5\")\n",
    "model.save(\"model_d3_01.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
