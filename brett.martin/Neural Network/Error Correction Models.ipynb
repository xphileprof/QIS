{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import circuits\n",
    "\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import precision_score,accuracy_score, f1_score, recall_score, hamming_loss\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import backend as K\n",
    "\n",
    "from collections import defaultdict\n",
    "from math import log2\n",
    "\n",
    "print (pd.__version__)\n",
    "RUN_CONFIGURATION_LOOP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_with_errs_d3(df):\n",
    "    x_data = []\n",
    "    z_data = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        x_data.append([])\n",
    "        z_data.append([])\n",
    "        if df.loc[i].at[\"X0\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 0.5))\n",
    "        if df.loc[i].at[\"Z1\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 0.5))\n",
    "        if df.loc[i].at[\"X2\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 1.5))\n",
    "        if df.loc[i].at[\"Z3\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 2.5))\n",
    "        if df.loc[i].at[\"Z4\"] == -1:\n",
    "            z_data[i].append((0, 1.5, -0.5))\n",
    "        if df.loc[i].at[\"X5\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 0.5))\n",
    "        if df.loc[i].at[\"X6\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 1.5))\n",
    "        if df.loc[i].at[\"Z7\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 1.5))\n",
    "        x_data[i] = str(x_data[i])\n",
    "        z_data[i] = str(z_data[i])\n",
    "        \n",
    "    graph_df = pd.DataFrame({\"XSyn\":x_data, \"ZSyn\":z_data})\n",
    "    return graph_df\n",
    "        \n",
    "\n",
    "def graph_with_errs_d5(df):\n",
    "    x_data = []\n",
    "    z_data = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        x_data.append([])\n",
    "        z_data.append([])\n",
    "        if df.loc[i].at[\"X0\"] == -1:\n",
    "             x_data[i].append((0, -0.5, 0.5))\n",
    "        if df.loc[i].at[\"Z1\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 0.5))\n",
    "        if df.loc[i].at[\"X2\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 1.5))\n",
    "        if df.loc[i].at[\"X3\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 2.5))\n",
    "        if df.loc[i].at[\"Z4\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 2.5))\n",
    "        if df.loc[i].at[\"X5\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 3.5))\n",
    "        if df.loc[i].at[\"Z6\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 4.5))\n",
    "        if df.loc[i].at[\"Z7\"] == -1:\n",
    "            z_data[i].append((0, 1.5, -0.5))\n",
    "        if df.loc[i].at[\"X8\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 0.5))\n",
    "        if df.loc[i].at[\"Z9\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 1.5))\n",
    "        if df.loc[i].at[\"X10\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 2.5))\n",
    "        if df.loc[i].at[\"Z11\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 3.5))\n",
    "        if df.loc[i].at[\"Z12\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 0.5))\n",
    "        if df.loc[i].at[\"X13\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 1.5))\n",
    "        if df.loc[i].at[\"Z14\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 2.5))\n",
    "        if df.loc[i].at[\"X15\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 3.5))\n",
    "        if df.loc[i].at[\"Z16\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 4.5))\n",
    "        if df.loc[i].at[\"Z17\"] == -1:\n",
    "            z_data[i].append((0, 3.5, -0.5))\n",
    "        if df.loc[i].at[\"X18\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 0.5))\n",
    "        if df.loc[i].at[\"X19\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 1.5))\n",
    "        if df.loc[i].at[\"Z20\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 1.5))\n",
    "        if df.loc[i].at[\"X21\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 2.5))\n",
    "        if df.loc[i].at[\"X22\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 3.5))\n",
    "        if df.loc[i].at[\"Z23\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 3.5))\n",
    "        x_data[i] = str(x_data[i])\n",
    "        z_data[i] = str(z_data[i])\n",
    "            \n",
    "    graph_df = pd.DataFrame({\"XSyn\":x_data, \"ZSyn\":z_data})\n",
    "    return graph_df\n",
    "\n",
    "\n",
    "def graph_with_errs_d7(df):\n",
    "    x_data = []\n",
    "    z_data = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        x_data.append([])\n",
    "        z_data.append([])\n",
    "        if df.loc[i].at[\"X0\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 0.5))\n",
    "        if df.loc[i].at[\"Z1\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 0.5))\n",
    "        if df.loc[i].at[\"X2\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 1.5))\n",
    "        if df.loc[i].at[\"X3\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 2.5))\n",
    "        if df.loc[i].at[\"Z4\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 2.5))\n",
    "        if df.loc[i].at[\"X5\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 3.5))\n",
    "        if df.loc[i].at[\"X6\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 4.5))\n",
    "        if df.loc[i].at[\"Z7\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 4.5))\n",
    "        if df.loc[i].at[\"X8\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 5.5))\n",
    "        if df.loc[i].at[\"Z9\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 6.5))\n",
    "        if df.loc[i].at[\"Z10\"] == -1:\n",
    "            z_data[i].append((0, 1.5, -0.5))\n",
    "        if df.loc[i].at[\"X11\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 0.5))\n",
    "        if df.loc[i].at[\"Z12\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 1.5))\n",
    "        if df.loc[i].at[\"X13\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 2.5))\n",
    "        if df.loc[i].at[\"Z14\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 3.5))\n",
    "        if df.loc[i].at[\"X15\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 4.5))\n",
    "        if df.loc[i].at[\"Z16\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 5.5))\n",
    "        if df.loc[i].at[\"Z17\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 0.5))\n",
    "        if df.loc[i].at[\"X18\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 1.5))\n",
    "        if df.loc[i].at[\"Z19\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 2.5))\n",
    "        if df.loc[i].at[\"X20\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 3.5))\n",
    "        if df.loc[i].at[\"Z21\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 4.5))\n",
    "        if df.loc[i].at[\"X22\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 5.5))\n",
    "        if df.loc[i].at[\"Z23\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 6.5))\n",
    "        if df.loc[i].at[\"Z24\"] == -1:\n",
    "            z_data[i].append((0, 3.5, -0.5))\n",
    "        if df.loc[i].at[\"X25\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 0.5))\n",
    "        if df.loc[i].at[\"Z26\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 1.5))\n",
    "        if df.loc[i].at[\"X27\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 2.5))\n",
    "        if df.loc[i].at[\"Z28\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 3.5))\n",
    "        if df.loc[i].at[\"X29\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 4.5))\n",
    "        if df.loc[i].at[\"Z30\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 5.5))\n",
    "        if df.loc[i].at[\"Z31\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 0.5))\n",
    "        if df.loc[i].at[\"X32\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 1.5))\n",
    "        if df.loc[i].at[\"Z33\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 2.5))\n",
    "        if df.loc[i].at[\"X34\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 3.5))\n",
    "        if df.loc[i].at[\"Z35\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 4.5))\n",
    "        if df.loc[i].at[\"X36\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 5.5))\n",
    "        if df.loc[i].at[\"Z37\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 6.5))\n",
    "        if df.loc[i].at[\"Z38\"] == -1:\n",
    "            z_data[i].append((0, 5.5, -0.5))\n",
    "        if df.loc[i].at[\"X39\"] == -1:\n",
    "            x_data[i].append((0, 5.5, 0.5))\n",
    "        if df.loc[i].at[\"X40\"] == -1:\n",
    "            x_data[i].append((0, 6.5, 1.5))\n",
    "        if df.loc[i].at[\"Z41\"] == -1:\n",
    "            z_data[i].append((0, 5.5, 1.5))\n",
    "        if df.loc[i].at[\"X42\"] == -1:\n",
    "            x_data[i].append((0, 5.5, 2.5))\n",
    "        if df.loc[i].at[\"X43\"] == -1:\n",
    "            x_data[i].append((0, 6.5, 3.5))\n",
    "        if df.loc[i].at[\"Z44\"] == -1:\n",
    "            z_data[i].append((0, 5.5, 3.5))\n",
    "        if df.loc[i].at[\"X45\"] == -1:\n",
    "            x_data[i].append((0, 5.5, 4.5))\n",
    "        if df.loc[i].at[\"X46\"] == -1:\n",
    "            x_data[i].append((0, 6.5, 5.5))\n",
    "        if df.loc[i].at[\"Z47\"] == -1: \n",
    "            z_data[i].append((0, 5.5, 5.5))\n",
    "        x_data[i] = str(x_data[i])\n",
    "        z_data[i] = str(z_data[i])\n",
    "        \n",
    "    graph_df = pd.DataFrame({\"XSyn\":x_data, \"ZSyn\":z_data})\n",
    "    return graph_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MWPM functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_measurement_errs(curr_syn, prob_err, x_syn, depth):\n",
    "    #x_syn is True if it is x syndrome, False if it is Z syndrome\n",
    "    total_time = 0\n",
    "    new_syn = []\n",
    "    if x_syn:\n",
    "        for i in curr_syn:\n",
    "            rand = random.random()\n",
    "            if rand > prob_err:\n",
    "                new_syn.append(i)\n",
    "        return (new_syn + return_xmeasurement_errs(depth, prob_err))\n",
    "    else:\n",
    "        for i in curr_syn:\n",
    "            rand = random.random()\n",
    "            if rand > prob_err:\n",
    "                new_syn.append(i)\n",
    "        return (new_syn + return_zmeasurement_errs(depth, prob_err))\n",
    "\n",
    "\n",
    "def do_new_decoding(data, depth, prob_err):\n",
    "    decoder = circuits.GraphDecoder(depth,1)\n",
    "    G = decoder.S['Z']\n",
    "    df = pd.DataFrame()\n",
    "    syn = []\n",
    "    total_time = 0\n",
    "    \n",
    "    for row in data:\n",
    "        x_input = []\n",
    "        z_input = []\n",
    "        x_type = True\n",
    "        for col in row:\n",
    "            if not col == \"[]\":\n",
    "                col = eval(col)\n",
    "                for c in col:\n",
    "                    if x_type:\n",
    "                        x_input.append(c)\n",
    "                    else:\n",
    "                        z_input.append(c)\n",
    "            x_type = not x_type  \n",
    "            \n",
    "        if prob_err > 0:\n",
    "            syndromes_x = add_measurement_errs(x_input, prob_err, True, depth)\n",
    "            syndromes_z = add_measurement_errs(z_input, prob_err, False, depth)\n",
    "        else:\n",
    "            syndromes_x = x_input\n",
    "            syndromes_z = z_input\n",
    "\n",
    "        start = time.time_ns()\n",
    "        error_graph_x, paths_x = decoder.make_error_graph(syndromes_x,'X')\n",
    "        matching_graph_x = decoder.matching_graph(error_graph_x,'X')\n",
    "        matches_x = decoder.matching(matching_graph_x,'X')\n",
    "        flips_x = decoder.calculate_qubit_flips(matches_x, paths_x,'X')\n",
    "        syn_x = (translate_errors(flips_x))\n",
    "\n",
    "        error_graph_z, paths_z = decoder.make_error_graph(syndromes_z,'Z')\n",
    "        matching_graph_z = decoder.matching_graph(error_graph_z,'Z')\n",
    "        matches_z = decoder.matching(matching_graph_z,'Z')\n",
    "        flips_z = decoder.calculate_qubit_flips(matches_z, paths_z,'Z')\n",
    "        syn_z = translate_errors(flips_z)\n",
    "        df = df.append(pd.Series([syn_x, syn_z]), ignore_index=True)\n",
    "        end = time.time_ns()\n",
    "        total_time += (end - start)/ (10 ** 9)\n",
    "    return (df, total_time) \n",
    "\n",
    "\n",
    "def return_xmeasurement_errs(depth, prob):\n",
    "    \n",
    "    new_errs = []\n",
    "    \n",
    "    if depth == 3:\n",
    "        errs = [(0, -0.5, 0.5), (0, 0.5, 1.5), (0, 1.5, 0.5), (0, 2.5, 1.5)]\n",
    "    elif depth == 5:\n",
    "        errs = [(0, -0.5, 0.5), (0, 0.5, 1.5), (0, -0.5, 2.5), (0, 0.5, 3.5), (0, 1.5, 0.5), (0, 1.5, 2.5),\n",
    "                        (0, 2.5, 1.5), (0, 2.5, 3.5), (0, 3.5, 0.5), (0, 4.5, 1.5), (0, 3.5, 2.5), (0, 4.5, 3.5)]\n",
    "    else:\n",
    "        errs = [(0, -0.5, 0.5), (0, 0.5, 1.5), (0, -0.5, 2.5), (0, 0.5, 3.5), (0, -0.5, 4.5), (0, 0.5, 5.5),\n",
    "                        (0, 1.5, 0.5), (0, 1.5, 2.5), (0, 1.5, 4.5), (0, 2.5, 1.5), (0, 2.5, 3.5), (0, 2.5, 5.5),\n",
    "                        (0, 3.5, 0.5),  (0, 3.5, 2.5), (0, 3.5, 4.5), (0, 4.5, 1.5), (0, 4.5, 3.5), (0, 4.5, 5.5),\n",
    "                       (0, 5.5, 0.5), (0, 6.5, 1.5), (0, 5.5, 2.5), (0, 6.5, 3.5), (0, 5.5, 4.5), (0, 6.5, 5.5)]\n",
    "    for e in errs:\n",
    "        rand = random.random()\n",
    "        if rand <= prob:\n",
    "            new_errs.append(e)\n",
    "            \n",
    "    return new_errs\n",
    "            \n",
    "\n",
    "def return_zmeasurement_errs(depth, prob):\n",
    "    \n",
    "    new_errs = []\n",
    "    \n",
    "    if depth == 3:\n",
    "        errs = [(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 1.5, -0.5), (0, 1.5, 1.5)]\n",
    "    elif depth == 5:\n",
    "        errs = [(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 0.5, 4.5), (0, 1.5, -0.5), (0, 1.5, 1.5), (0, 1.5, 3.5),\n",
    "                        (0, 2.5, 0.5), (0, 2.5, 2.5), (0, 2.5, 4.5), (0, 3.5, -0.5), (0, 3.5, 1.5), (0, 3.5, 3.5)]\n",
    "    else:\n",
    "        errs = [(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 0.5, 4.5), (0, 0.5, 6.5), (0, 1.5, -0.5), (0, 1.5, 1.5),\n",
    "                        (0, 1.5, 3.5), (0, 1.5, 5.5), (0, 2.5, 0.5), (0, 2.5, 2.5), (0, 2.5, 4.5), (0, 2.5, 6.5),\n",
    "                        (0, 3.5, -0.5),  (0, 3.5, 1.5), (0, 3.5, 3.5), (0, 3.5, 5.5), (0, 4.5, 0.5), (0, 4.5, 2.5),\n",
    "                       (0, 4.5, 4.5), (0, 4.5, 6.5), (0, 5.5, -0.5), (0, 5.5, 1.5), (0, 5.5, 3.5), (0, 5.5, 5.5)]\n",
    "        \n",
    "    for e in errs:\n",
    "        rand = random.random()\n",
    "        if rand <= prob:\n",
    "            new_errs.append(e)\n",
    "            \n",
    "    return new_errs\n",
    "\n",
    "\n",
    "def translate_errors (phys_errs):\n",
    "    flipX = np.array([(0, 1),(1, 0)])\n",
    "    flipZ = np.array([(1, 0), (0, -1)])\n",
    "    errs = []\n",
    "    str2 = \"\"\n",
    "    for qubit, flip in phys_errs.items():\n",
    "        row = int(qubit[1])\n",
    "        col = int(qubit[2])\n",
    "        if str(flip) == \"X\":\n",
    "            str1 = \"X\"\n",
    "        elif str(flip) == \"Z\":\n",
    "            str1 = \"Z\"\n",
    "        else:\n",
    "            str1 = \"X\"\n",
    "            str2 = \"Z\"\n",
    "        str1 += str(row) + str(col)\n",
    "        errs.append(str1)\n",
    "        if str2 != \"\":\n",
    "            str2 += str(row) +str(col)\n",
    "            errs.append(str2)\n",
    "            str2 = \"\"\n",
    "    return errs   \n",
    "\n",
    "\n",
    "def translate_to_graph(df_graph, labels, mlb):\n",
    "#go through labels given\n",
    "    indices = []\n",
    "    labels = mlb.inverse_transform(labels)\n",
    "    \n",
    "    for row in labels:\n",
    "        label_str = str(row)\n",
    "        for index, r in df_graph.iterrows():\n",
    "            if label_str == \"('',)\":\n",
    "                if str(r[\"Labels\"]) == \"[' ']\":\n",
    "                    indices.append([index])\n",
    "                    break\n",
    "            if set(row) == set(r[\"Labels\"]):\n",
    "                indices.append([index])\n",
    "                break\n",
    "\n",
    "    df_syns = df_graph.drop(['Labels'], axis=1)\n",
    "    return_df = pd.DataFrame()\n",
    "    for i in indices:\n",
    "        return_df = return_df.append(df_syns.loc[i])\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list_from_string(err_list):\n",
    "    newstring = err_list.replace(\"'\", \"\")\n",
    "    new_err_list = newstring.strip('][').split(', ')\n",
    "    return sorted(set(new_err_list))\n",
    "\n",
    "\n",
    "def create_string_from_list(err_list):\n",
    "    return_string = \"[\"\n",
    "    if err_list[0] == \"''\":\n",
    "        return \"[' ']\"\n",
    "    else:\n",
    "        for index, i in enumerate(err_list):\n",
    "            return_string = return_string +  \"'\" + i + \"'\"\n",
    "            if index < (len(err_list)-1):\n",
    "                return_string += \", \"\n",
    "    return return_string + \"]\"\n",
    "        \n",
    "\n",
    "#take in two 2d arrays of predicted values, true values, and threshold to determine labels. \n",
    "#calculates the partial accuracy of the predicted values, averaged out for all obersvations\n",
    "def partial_accuracy(y_pred, y_true):\n",
    "    total = 0\n",
    "    rows = y_pred.shape[0]\n",
    "    cols = y_pred.shape[1]\n",
    "    for i in range(0, rows):\n",
    "        row_correct = 0\n",
    "        for j in range(0, cols):\n",
    "            if y_pred[i,j] == y_true[i,j]:\n",
    "                row_correct += 1\n",
    "        total += row_correct/cols\n",
    "    return total/rows\n",
    "\n",
    "\n",
    "def partial_accuracy_and_contingency(y_pred, y_true, mlb):\n",
    "    total = 0\n",
    "    a= np.zeros(shape=y_true.shape)\n",
    "    rows = y_pred.shape[0]\n",
    "    cols = y_pred.shape[1]\n",
    "    df = pd.DataFrame(a, columns = mlb.classes_)\n",
    "    for i in range(0, rows):\n",
    "        row_correct = 0\n",
    "        for j, label in enumerate(mlb.classes_):\n",
    "            if y_pred[i,j] == y_true[i,j]:\n",
    "                row_correct += 1\n",
    "                df.at[i, label] = 1\n",
    "            else:\n",
    "                df.at[i, label] = 0\n",
    "\n",
    "        total += row_correct/cols\n",
    "\n",
    "    return (total/rows, df)\n",
    "\n",
    "\n",
    "def contingency_table_and_t (clf1, clf2):\n",
    "    a = 0 #clf1 pos, clf2 pos\n",
    "    b = 0 #clf1 pos, clf2 neg\n",
    "    c = 0 #clf1 neg, clf2 pos\n",
    "    d = 0 #clf1 neg, clf2 neg\n",
    "    \n",
    "    for index, value in clf1.items():\n",
    "        if value == 1 and clf2[index] == 1:\n",
    "            a+=1\n",
    "        elif value == 1 and clf2[index] == 0: #classifier 1 right, classifier 2 wrong\n",
    "            b+=1\n",
    "        elif value == 0 and clf2[index] == 1: #classifier 1 wrong, classifier 2 right\n",
    "            c+=1\n",
    "        else:\n",
    "            d+=1\n",
    "    print(\"[\"+str(a)+\", \"+str(b)+\"]\")\n",
    "    print(\"[\"+str(c)+\", \"+str(d)+\"]\")\n",
    "    if b == 0 and c ==0:\n",
    "        print(\"both b and c are zero\")\n",
    "        t=0\n",
    "    else:\n",
    "        t = (((b-c)-1)**2)/(b+c)\n",
    "    return ([[a,b],[c,d]], t)\n",
    "\n",
    "\n",
    "def add_noise(val, noise_level):\n",
    "    rand = random.uniform(0, 1)\n",
    "    if rand <= noise_level:\n",
    "        if val == -1:\n",
    "            val = 1\n",
    "        elif val == 1:\n",
    "            val = -1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup table functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAllBinaryStrings(n, arr, i, lookup):  \n",
    "    if i == n: \n",
    "        lookup.setBitStringArray(arr, n)  \n",
    "        return\n",
    "      \n",
    "    # First assign \"0\" at ith position  \n",
    "    # and try for all other permutations  \n",
    "    # for remaining positions  \n",
    "    arr[i] = 0\n",
    "    generateAllBinaryStrings(n, arr, i + 1, lookup)  \n",
    "  \n",
    "    # And then assign \"1\" at ith position  , \n",
    "    # and try for all other permutations  \n",
    "    # for remaining positions  \n",
    "    arr[i] = 1\n",
    "    generateAllBinaryStrings(n, arr, i + 1, lookup)\n",
    "\n",
    "\n",
    "class lookup_decoder:\n",
    "    \n",
    "    def __init__(self, depth):\n",
    "        #self.lookupTable = defaultdict()\n",
    "        self.lookupTable = {}\n",
    "        self.distributions = {}\n",
    "        self.depth = depth\n",
    "        #generating all possible syndrome observations\n",
    "        #arr = [None] * (depth**2 - 1)\n",
    "        #generateAllBinaryStrings((depth**2 - 1), arr, 0, self)\n",
    "        \n",
    "    def setBitStringArray(self, arr, n): \n",
    "        new_str = \"\"\n",
    "        for i in range(0, n):  \n",
    "            new_str += str(arr[i])\n",
    "        self.lookupTable.update({new_str:defaultdict()})  \n",
    "        \n",
    "    def update_table (self, syndrome, phys_errs):\n",
    "        #all the keys are made in the init, so simply update the physical error combinations for the given syndrome\n",
    "        if syndrome not in self.lookupTable:\n",
    "            self.lookupTable[syndrome] = {}\n",
    "            self.lookupTable[syndrome][phys_errs] = 1\n",
    "            return\n",
    "        \n",
    "        if phys_errs not in self.lookupTable[syndrome]:\n",
    "            self.lookupTable[syndrome].update({phys_errs: 1})\n",
    "        else:\n",
    "            self.lookupTable[syndrome][phys_errs] += 1\n",
    "     \n",
    "    def get_probable_error(self, syndrome):\n",
    "        return_key = []\n",
    "\n",
    "        if syndrome not in self.lookupTable.keys():\n",
    "            for i in range(2* int(self.depth**2) + 1):\n",
    "                return_key.append(0)\n",
    "            return return_key\n",
    "        \n",
    "        key, value = max(self.lookupTable[syndrome].items(), key=lambda x:x[1])\n",
    "        \n",
    "        for character in key:\n",
    "            if character == '0' or character == '1':\n",
    "                return_key.append(int(character))\n",
    "                \n",
    "        return return_key\n",
    "        \n",
    "    def make_distribution_graph(self, syn):\n",
    "        \n",
    "        plt.bar(list(self.lookupTable[syn].keys()), self.lookupTable[syn].values(), color='g')\n",
    "        plt.show()\n",
    "        \n",
    "    def syndrome_count_graph(self):\n",
    "        graph_dict = {}\n",
    "        for syn in self.lookupTable:\n",
    "            graph_dict.update({syn:sum(self.lookupTable[syn].values())})\n",
    "        plt.ylim((0,4))\n",
    "        plt.bar(graph_dict.keys(), graph_dict.values())\n",
    "        plt.show()\n",
    "    \n",
    "    def length_of_lookup(self):\n",
    "        print(len(self.lookupTable))\n",
    "            \n",
    "    def get_entropies(self):\n",
    "        entropies = {}\n",
    "        for syn in self.lookupTable:\n",
    "            total = sum(self.lookupTable[syn].values())\n",
    "            h = 0\n",
    "            for key in self.lookupTable[syn]:\n",
    "                p = self.lookupTable[syn][key]/total\n",
    "                h += p+log2(p)\n",
    "            entropies[syn] = -h\n",
    "        print(entropies)\n",
    "            \n",
    "    def get_syndromes(self):\n",
    "        return self.lookupTable.keys()\n",
    "                     \n",
    "    def print_lookup(self):\n",
    "        for syn in self.lookupTable:\n",
    "            print(self.lookupTable[syn])\n",
    "            \n",
    "\n",
    "def train_plut(table, data_x, data_y):\n",
    "    i = 0\n",
    "    for index, x in enumerate(data_x):\n",
    "        syn = \"\".join([str(i) for i in x])\n",
    "        syn = syn.replace(\".0\",\"\")\n",
    "        labels = np.array2string(np.array(data_y[i]), precision=1, separator='',suppress_small=True).replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "        table.update_table(syn, labels)\n",
    "        i+=1\n",
    "    return table\n",
    "\n",
    "\n",
    "def test_plut(table, test_set):\n",
    "    predictions_lookup = []\n",
    "    for index, x in enumerate(test_set):\n",
    "        syn_x = \"\".join([str(i) for i in x])\n",
    "        syn_x = syn_x.replace(\".0\",\"\")\n",
    "        predictions_lookup.append(table.get_probable_error(syn_x))\n",
    "    return np.array(predictions_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model compilation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_FFNN_model_DepthThree(depth):\n",
    "    model = Sequential()\n",
    "    layers = 4\n",
    "    \n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    \n",
    "    for i in range(layers):\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(18 , activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(lr=0.05),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_FFNN_cv_model_DepthThree(depth):\n",
    "    model = Sequential()\n",
    "    layers = 4\n",
    "\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    \n",
    "    for i in range(layers):\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(19 , activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(lr=0.05),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_FFNN_cv_model_DepthFive(depth):\n",
    "    model = Sequential()\n",
    "    layers = 4\n",
    "    \n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    \n",
    "    for i in range(layers):\n",
    "        model.add(Dense(240, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(51, activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(learning_rate=0.05),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_FFNN_cv_model_DepthSeven(depth):\n",
    "    model = Sequential()\n",
    "    layers = 4\n",
    "    \n",
    "    model.add(Dense(48, activation='relu'))\n",
    "    \n",
    "    for i in range(layers):\n",
    "        model.add(Dense(400, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(99, activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(learning_rate=0.05),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D3 Training, Testing, and Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data sets from CSV\n",
    "\n",
    "#### Data sets for D3:\n",
    "* Original:\n",
    "    - \"depth3_all_combos.csv\"\n",
    "* Exhaustive:\n",
    "    - \"ex-samples-d3.csv\"\n",
    "* Randomly-sampled, with replacement (version 2):\n",
    "    - \"v2samples-d3-1000.csv\"\n",
    "    - \"v2samples-d3-10000.csv\"\n",
    "* Randomly-sampled, without replacement (version 3):\n",
    "    - \"v3samples-d3-1000.csv\"\n",
    "    - \"v3samples-d3-10000.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData_d3 = pd.read_csv(\"SAMPLES/v2samples-d3-10000.csv\")\n",
    "\n",
    "trainData_d3[\"Labels\"] = trainData_d3['Labels'].map(lambda x: create_list_from_string(x))\n",
    "trainData_d3 = trainData_d3.applymap(lambda x: add_noise(x,.01))\n",
    "\n",
    "testData_d3_MWPM = graph_with_errs_d3(trainData_d3)\n",
    "\n",
    "mlb_d3 = MultiLabelBinarizer()\n",
    "mlb_d3.fit(trainData_d3[\"Labels\"])\n",
    "df = pd.DataFrame(mlb_d3.transform(trainData_d3['Labels']))\n",
    "df['Labels']= df.values.tolist()\n",
    "trainData_d3 = trainData_d3.drop(['Labels'], axis=1)\n",
    "trainData_d3 = pd.concat([df['Labels'], testData_d3_MWPM, trainData_d3], axis=1, ignore_index=True)\n",
    "trainData_d3.columns = [\"Labels\",\"XSyn\", \"ZSyn\", \"X0\", \"Z1\", \"X2\", \"Z3\", \"Z4\", \"X5\", \"X6\", \"Z7\"]\n",
    "\n",
    "y_d3 = trainData_d3[\"Labels\"]\n",
    "x_d3 = trainData_d3.drop([\"Labels\"], axis=1)\n",
    "\n",
    "x_d3 = x_d3.replace([-1], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Train on 5625 samples, validate on 1875 samples\n",
      "Epoch 1/200\n",
      "5625/5625 [==============================] - 0s 55us/step - loss: 0.5735 - accuracy: 0.8068 - val_loss: 0.3146 - val_accuracy: 0.9179\n",
      "Epoch 2/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.2920 - accuracy: 0.9159 - val_loss: 0.2825 - val_accuracy: 0.9179\n",
      "Epoch 3/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.2863 - accuracy: 0.9159 - val_loss: 0.2813 - val_accuracy: 0.9179\n",
      "Epoch 4/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.2856 - accuracy: 0.9159 - val_loss: 0.2808 - val_accuracy: 0.9179\n",
      "Epoch 5/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.2852 - accuracy: 0.9159 - val_loss: 0.2804 - val_accuracy: 0.9179\n",
      "Epoch 6/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.2848 - accuracy: 0.9159 - val_loss: 0.2800 - val_accuracy: 0.9179\n",
      "Epoch 7/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.2845 - accuracy: 0.9159 - val_loss: 0.2798 - val_accuracy: 0.9179\n",
      "Epoch 8/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.2841 - accuracy: 0.9159 - val_loss: 0.2793 - val_accuracy: 0.9179\n",
      "Epoch 9/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2837 - accuracy: 0.9159 - val_loss: 0.2789 - val_accuracy: 0.9179\n",
      "Epoch 10/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2834 - accuracy: 0.9159 - val_loss: 0.2785 - val_accuracy: 0.9179\n",
      "Epoch 11/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2829 - accuracy: 0.9159 - val_loss: 0.2782 - val_accuracy: 0.9179\n",
      "Epoch 12/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.2825 - accuracy: 0.9159 - val_loss: 0.2776 - val_accuracy: 0.9179\n",
      "Epoch 13/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.2819 - accuracy: 0.9159 - val_loss: 0.2771 - val_accuracy: 0.9179\n",
      "Epoch 14/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.2813 - accuracy: 0.9159 - val_loss: 0.2764 - val_accuracy: 0.9179\n",
      "Epoch 15/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2804 - accuracy: 0.9159 - val_loss: 0.2753 - val_accuracy: 0.9179\n",
      "Epoch 16/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.2793 - accuracy: 0.9159 - val_loss: 0.2740 - val_accuracy: 0.9179\n",
      "Epoch 17/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.2779 - accuracy: 0.9159 - val_loss: 0.2723 - val_accuracy: 0.9179\n",
      "Epoch 18/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2760 - accuracy: 0.9159 - val_loss: 0.2701 - val_accuracy: 0.9179\n",
      "Epoch 19/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2735 - accuracy: 0.9159 - val_loss: 0.2671 - val_accuracy: 0.9179\n",
      "Epoch 20/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2703 - accuracy: 0.9159 - val_loss: 0.2635 - val_accuracy: 0.9179\n",
      "Epoch 21/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2666 - accuracy: 0.9159 - val_loss: 0.2593 - val_accuracy: 0.9179\n",
      "Epoch 22/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2628 - accuracy: 0.9159 - val_loss: 0.2553 - val_accuracy: 0.9179\n",
      "Epoch 23/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.2591 - accuracy: 0.9159 - val_loss: 0.2517 - val_accuracy: 0.9179\n",
      "Epoch 24/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.2556 - accuracy: 0.9158 - val_loss: 0.2481 - val_accuracy: 0.9179\n",
      "Epoch 25/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.2524 - accuracy: 0.9159 - val_loss: 0.2446 - val_accuracy: 0.9177\n",
      "Epoch 26/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.2490 - accuracy: 0.9159 - val_loss: 0.2413 - val_accuracy: 0.9179\n",
      "Epoch 27/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.2458 - accuracy: 0.9157 - val_loss: 0.2378 - val_accuracy: 0.9177\n",
      "Epoch 28/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.2426 - accuracy: 0.9159 - val_loss: 0.2345 - val_accuracy: 0.9177\n",
      "Epoch 29/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.2397 - accuracy: 0.9175 - val_loss: 0.2320 - val_accuracy: 0.9215\n",
      "Epoch 30/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.2372 - accuracy: 0.9192 - val_loss: 0.2293 - val_accuracy: 0.9216\n",
      "Epoch 31/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.2349 - accuracy: 0.9194 - val_loss: 0.2274 - val_accuracy: 0.9215\n",
      "Epoch 32/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.2326 - accuracy: 0.9199 - val_loss: 0.2247 - val_accuracy: 0.9230\n",
      "Epoch 33/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.2305 - accuracy: 0.9203 - val_loss: 0.2226 - val_accuracy: 0.9213\n",
      "Epoch 34/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.2284 - accuracy: 0.9201 - val_loss: 0.2207 - val_accuracy: 0.9225\n",
      "Epoch 35/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2261 - accuracy: 0.9205 - val_loss: 0.2178 - val_accuracy: 0.9229\n",
      "Epoch 36/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2236 - accuracy: 0.9209 - val_loss: 0.2154 - val_accuracy: 0.9229\n",
      "Epoch 37/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.2213 - accuracy: 0.9210 - val_loss: 0.2130 - val_accuracy: 0.9225\n",
      "Epoch 38/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.2190 - accuracy: 0.9212 - val_loss: 0.2108 - val_accuracy: 0.9228\n",
      "Epoch 39/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.2168 - accuracy: 0.9219 - val_loss: 0.2088 - val_accuracy: 0.9246\n",
      "Epoch 40/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.2152 - accuracy: 0.9227 - val_loss: 0.2071 - val_accuracy: 0.9246\n",
      "Epoch 41/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.2138 - accuracy: 0.9232 - val_loss: 0.2059 - val_accuracy: 0.9251\n",
      "Epoch 42/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2125 - accuracy: 0.9235 - val_loss: 0.2046 - val_accuracy: 0.9261\n",
      "Epoch 43/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.2113 - accuracy: 0.9236 - val_loss: 0.2033 - val_accuracy: 0.9260\n",
      "Epoch 44/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.2104 - accuracy: 0.9243 - val_loss: 0.2023 - val_accuracy: 0.9263\n",
      "Epoch 45/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2095 - accuracy: 0.9241 - val_loss: 0.2011 - val_accuracy: 0.9260\n",
      "Epoch 46/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.2086 - accuracy: 0.9244 - val_loss: 0.2005 - val_accuracy: 0.9260\n",
      "Epoch 47/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2077 - accuracy: 0.9248 - val_loss: 0.1998 - val_accuracy: 0.9259\n",
      "Epoch 48/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2069 - accuracy: 0.9253 - val_loss: 0.1985 - val_accuracy: 0.9282\n",
      "Epoch 49/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2060 - accuracy: 0.9255 - val_loss: 0.1978 - val_accuracy: 0.9282\n",
      "Epoch 50/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.2051 - accuracy: 0.9263 - val_loss: 0.1970 - val_accuracy: 0.9283\n",
      "Epoch 51/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.2041 - accuracy: 0.9265 - val_loss: 0.1957 - val_accuracy: 0.9287\n",
      "Epoch 52/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2030 - accuracy: 0.9267 - val_loss: 0.1941 - val_accuracy: 0.9287\n",
      "Epoch 53/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2018 - accuracy: 0.9269 - val_loss: 0.1931 - val_accuracy: 0.9291\n",
      "Epoch 54/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.2006 - accuracy: 0.9274 - val_loss: 0.1928 - val_accuracy: 0.9288\n",
      "Epoch 55/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1994 - accuracy: 0.9273 - val_loss: 0.1913 - val_accuracy: 0.9289\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1981 - accuracy: 0.9274 - val_loss: 0.1893 - val_accuracy: 0.9303\n",
      "Epoch 57/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1965 - accuracy: 0.9278 - val_loss: 0.1885 - val_accuracy: 0.9289\n",
      "Epoch 58/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1950 - accuracy: 0.9278 - val_loss: 0.1865 - val_accuracy: 0.9310\n",
      "Epoch 59/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1935 - accuracy: 0.9287 - val_loss: 0.1847 - val_accuracy: 0.9308\n",
      "Epoch 60/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1921 - accuracy: 0.9291 - val_loss: 0.1830 - val_accuracy: 0.9329\n",
      "Epoch 61/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1906 - accuracy: 0.9295 - val_loss: 0.1833 - val_accuracy: 0.9309\n",
      "Epoch 62/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1893 - accuracy: 0.9303 - val_loss: 0.1812 - val_accuracy: 0.9331\n",
      "Epoch 63/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1880 - accuracy: 0.9308 - val_loss: 0.1795 - val_accuracy: 0.9335\n",
      "Epoch 64/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1867 - accuracy: 0.9309 - val_loss: 0.1789 - val_accuracy: 0.9333\n",
      "Epoch 65/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1857 - accuracy: 0.9312 - val_loss: 0.1769 - val_accuracy: 0.9352\n",
      "Epoch 66/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1847 - accuracy: 0.9314 - val_loss: 0.1759 - val_accuracy: 0.9339\n",
      "Epoch 67/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1836 - accuracy: 0.9320 - val_loss: 0.1754 - val_accuracy: 0.9343\n",
      "Epoch 68/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1829 - accuracy: 0.9321 - val_loss: 0.1739 - val_accuracy: 0.9347\n",
      "Epoch 69/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1821 - accuracy: 0.9327 - val_loss: 0.1743 - val_accuracy: 0.9356\n",
      "Epoch 70/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1811 - accuracy: 0.9329 - val_loss: 0.1727 - val_accuracy: 0.9365\n",
      "Epoch 71/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1804 - accuracy: 0.9333 - val_loss: 0.1726 - val_accuracy: 0.9377\n",
      "Epoch 72/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1798 - accuracy: 0.9341 - val_loss: 0.1722 - val_accuracy: 0.9377\n",
      "Epoch 73/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1790 - accuracy: 0.9342 - val_loss: 0.1711 - val_accuracy: 0.9373\n",
      "Epoch 74/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1782 - accuracy: 0.9342 - val_loss: 0.1700 - val_accuracy: 0.9383\n",
      "Epoch 75/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1777 - accuracy: 0.9346 - val_loss: 0.1694 - val_accuracy: 0.9386\n",
      "Epoch 76/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1771 - accuracy: 0.9351 - val_loss: 0.1697 - val_accuracy: 0.9381\n",
      "Epoch 77/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1765 - accuracy: 0.9354 - val_loss: 0.1684 - val_accuracy: 0.9383\n",
      "Epoch 78/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1759 - accuracy: 0.9351 - val_loss: 0.1678 - val_accuracy: 0.9387\n",
      "Epoch 79/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1756 - accuracy: 0.9356 - val_loss: 0.1671 - val_accuracy: 0.9389\n",
      "Epoch 80/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1750 - accuracy: 0.9357 - val_loss: 0.1668 - val_accuracy: 0.9388\n",
      "Epoch 81/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1746 - accuracy: 0.9357 - val_loss: 0.1667 - val_accuracy: 0.9388\n",
      "Epoch 82/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1742 - accuracy: 0.9355 - val_loss: 0.1663 - val_accuracy: 0.9393\n",
      "Epoch 83/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1739 - accuracy: 0.9358 - val_loss: 0.1658 - val_accuracy: 0.9388\n",
      "Epoch 84/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1735 - accuracy: 0.9359 - val_loss: 0.1657 - val_accuracy: 0.9391\n",
      "Epoch 85/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1731 - accuracy: 0.9362 - val_loss: 0.1649 - val_accuracy: 0.9397\n",
      "Epoch 86/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1727 - accuracy: 0.9363 - val_loss: 0.1644 - val_accuracy: 0.9397\n",
      "Epoch 87/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1725 - accuracy: 0.9365 - val_loss: 0.1649 - val_accuracy: 0.9394\n",
      "Epoch 88/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1722 - accuracy: 0.9364 - val_loss: 0.1640 - val_accuracy: 0.9396\n",
      "Epoch 89/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1719 - accuracy: 0.9367 - val_loss: 0.1641 - val_accuracy: 0.9401\n",
      "Epoch 90/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1717 - accuracy: 0.9366 - val_loss: 0.1644 - val_accuracy: 0.9397\n",
      "Epoch 91/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1713 - accuracy: 0.9369 - val_loss: 0.1631 - val_accuracy: 0.9402\n",
      "Epoch 92/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1711 - accuracy: 0.9368 - val_loss: 0.1636 - val_accuracy: 0.9397\n",
      "Epoch 93/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.1709 - accuracy: 0.9367 - val_loss: 0.1634 - val_accuracy: 0.9398\n",
      "Epoch 94/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1705 - accuracy: 0.9369 - val_loss: 0.1623 - val_accuracy: 0.9399\n",
      "Epoch 95/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1702 - accuracy: 0.9370 - val_loss: 0.1631 - val_accuracy: 0.9405\n",
      "Epoch 96/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1701 - accuracy: 0.9368 - val_loss: 0.1625 - val_accuracy: 0.9399\n",
      "Epoch 97/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1698 - accuracy: 0.9371 - val_loss: 0.1621 - val_accuracy: 0.9400\n",
      "Epoch 98/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1695 - accuracy: 0.9370 - val_loss: 0.1613 - val_accuracy: 0.9396\n",
      "Epoch 99/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1693 - accuracy: 0.9370 - val_loss: 0.1613 - val_accuracy: 0.9401\n",
      "Epoch 100/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1692 - accuracy: 0.9369 - val_loss: 0.1613 - val_accuracy: 0.9404\n",
      "Epoch 101/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1690 - accuracy: 0.9370 - val_loss: 0.1612 - val_accuracy: 0.9409\n",
      "Epoch 102/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1689 - accuracy: 0.9369 - val_loss: 0.1622 - val_accuracy: 0.9412\n",
      "Epoch 103/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1685 - accuracy: 0.9369 - val_loss: 0.1605 - val_accuracy: 0.9401\n",
      "Epoch 104/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1682 - accuracy: 0.9371 - val_loss: 0.1604 - val_accuracy: 0.9411\n",
      "Epoch 105/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1681 - accuracy: 0.9372 - val_loss: 0.1612 - val_accuracy: 0.9399\n",
      "Epoch 106/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1680 - accuracy: 0.9371 - val_loss: 0.1609 - val_accuracy: 0.9394\n",
      "Epoch 107/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1677 - accuracy: 0.9373 - val_loss: 0.1602 - val_accuracy: 0.9398\n",
      "Epoch 108/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1676 - accuracy: 0.9373 - val_loss: 0.1600 - val_accuracy: 0.9398\n",
      "Epoch 109/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1673 - accuracy: 0.9373 - val_loss: 0.1608 - val_accuracy: 0.9398\n",
      "Epoch 110/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1671 - accuracy: 0.9376 - val_loss: 0.1593 - val_accuracy: 0.9405\n",
      "Epoch 111/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1669 - accuracy: 0.9376 - val_loss: 0.1594 - val_accuracy: 0.9406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1668 - accuracy: 0.9375 - val_loss: 0.1599 - val_accuracy: 0.9400\n",
      "Epoch 113/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1665 - accuracy: 0.9376 - val_loss: 0.1600 - val_accuracy: 0.9399\n",
      "Epoch 114/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1665 - accuracy: 0.9378 - val_loss: 0.1587 - val_accuracy: 0.9409\n",
      "Epoch 115/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1664 - accuracy: 0.9374 - val_loss: 0.1594 - val_accuracy: 0.9398\n",
      "Epoch 116/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1662 - accuracy: 0.9373 - val_loss: 0.1584 - val_accuracy: 0.9401\n",
      "Epoch 117/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1660 - accuracy: 0.9376 - val_loss: 0.1584 - val_accuracy: 0.9401\n",
      "Epoch 118/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1658 - accuracy: 0.9376 - val_loss: 0.1590 - val_accuracy: 0.9407\n",
      "Epoch 119/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1658 - accuracy: 0.9375 - val_loss: 0.1590 - val_accuracy: 0.9415\n",
      "Epoch 120/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1655 - accuracy: 0.9376 - val_loss: 0.1580 - val_accuracy: 0.9408\n",
      "Epoch 121/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1654 - accuracy: 0.9374 - val_loss: 0.1575 - val_accuracy: 0.9407\n",
      "Epoch 122/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1652 - accuracy: 0.9377 - val_loss: 0.1581 - val_accuracy: 0.9392\n",
      "Epoch 123/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1651 - accuracy: 0.9379 - val_loss: 0.1582 - val_accuracy: 0.9388\n",
      "Epoch 124/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1649 - accuracy: 0.9376 - val_loss: 0.1579 - val_accuracy: 0.9408\n",
      "Epoch 125/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1648 - accuracy: 0.9374 - val_loss: 0.1569 - val_accuracy: 0.9410\n",
      "Epoch 126/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1645 - accuracy: 0.9373 - val_loss: 0.1573 - val_accuracy: 0.9410\n",
      "Epoch 127/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1644 - accuracy: 0.9377 - val_loss: 0.1571 - val_accuracy: 0.9403\n",
      "Epoch 128/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1643 - accuracy: 0.9375 - val_loss: 0.1566 - val_accuracy: 0.9407\n",
      "Epoch 129/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1642 - accuracy: 0.9380 - val_loss: 0.1567 - val_accuracy: 0.9407\n",
      "Epoch 130/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1640 - accuracy: 0.9381 - val_loss: 0.1564 - val_accuracy: 0.9399\n",
      "Epoch 131/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1638 - accuracy: 0.9377 - val_loss: 0.1560 - val_accuracy: 0.9409\n",
      "Epoch 132/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.1637 - accuracy: 0.9379 - val_loss: 0.1567 - val_accuracy: 0.9400\n",
      "Epoch 133/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1636 - accuracy: 0.9376 - val_loss: 0.1560 - val_accuracy: 0.9412\n",
      "Epoch 134/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1634 - accuracy: 0.9377 - val_loss: 0.1561 - val_accuracy: 0.9396\n",
      "Epoch 135/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1634 - accuracy: 0.9377 - val_loss: 0.1555 - val_accuracy: 0.9403\n",
      "Epoch 136/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1630 - accuracy: 0.9379 - val_loss: 0.1555 - val_accuracy: 0.9407\n",
      "Epoch 137/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.1629 - accuracy: 0.9377 - val_loss: 0.1551 - val_accuracy: 0.9408\n",
      "Epoch 138/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.1628 - accuracy: 0.9377 - val_loss: 0.1554 - val_accuracy: 0.9407\n",
      "Epoch 139/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1627 - accuracy: 0.9379 - val_loss: 0.1545 - val_accuracy: 0.9416\n",
      "Epoch 140/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.1625 - accuracy: 0.9380 - val_loss: 0.1551 - val_accuracy: 0.9413\n",
      "Epoch 141/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1624 - accuracy: 0.9379 - val_loss: 0.1549 - val_accuracy: 0.9409\n",
      "Epoch 142/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1623 - accuracy: 0.9379 - val_loss: 0.1548 - val_accuracy: 0.9409\n",
      "Epoch 143/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1622 - accuracy: 0.9381 - val_loss: 0.1548 - val_accuracy: 0.9398\n",
      "Epoch 144/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1621 - accuracy: 0.9378 - val_loss: 0.1547 - val_accuracy: 0.9418\n",
      "Epoch 145/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1619 - accuracy: 0.9378 - val_loss: 0.1542 - val_accuracy: 0.9412\n",
      "Epoch 146/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1617 - accuracy: 0.9377 - val_loss: 0.1547 - val_accuracy: 0.9408\n",
      "Epoch 147/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1616 - accuracy: 0.9381 - val_loss: 0.1544 - val_accuracy: 0.9402\n",
      "Epoch 148/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1615 - accuracy: 0.9383 - val_loss: 0.1546 - val_accuracy: 0.9412\n",
      "Epoch 149/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.1614 - accuracy: 0.9382 - val_loss: 0.1560 - val_accuracy: 0.9388\n",
      "Epoch 150/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1612 - accuracy: 0.9379 - val_loss: 0.1542 - val_accuracy: 0.9411\n",
      "Epoch 151/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1612 - accuracy: 0.9379 - val_loss: 0.1547 - val_accuracy: 0.9394\n",
      "Epoch 152/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.1610 - accuracy: 0.9379 - val_loss: 0.1551 - val_accuracy: 0.9406\n",
      "Epoch 153/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1610 - accuracy: 0.9381 - val_loss: 0.1545 - val_accuracy: 0.9408\n",
      "Epoch 154/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1608 - accuracy: 0.9383 - val_loss: 0.1530 - val_accuracy: 0.9415\n",
      "Epoch 155/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1606 - accuracy: 0.9380 - val_loss: 0.1560 - val_accuracy: 0.9407\n",
      "Epoch 156/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.1605 - accuracy: 0.9383 - val_loss: 0.1531 - val_accuracy: 0.9418\n",
      "Epoch 157/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.1604 - accuracy: 0.9384 - val_loss: 0.1528 - val_accuracy: 0.9410\n",
      "Epoch 158/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.1602 - accuracy: 0.9383 - val_loss: 0.1527 - val_accuracy: 0.9408\n",
      "Epoch 159/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1601 - accuracy: 0.9379 - val_loss: 0.1530 - val_accuracy: 0.9413\n",
      "Epoch 160/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1600 - accuracy: 0.9380 - val_loss: 0.1529 - val_accuracy: 0.9418\n",
      "Epoch 161/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1598 - accuracy: 0.9385 - val_loss: 0.1523 - val_accuracy: 0.9416\n",
      "Epoch 162/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1597 - accuracy: 0.9380 - val_loss: 0.1518 - val_accuracy: 0.9414\n",
      "Epoch 163/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1596 - accuracy: 0.9386 - val_loss: 0.1522 - val_accuracy: 0.9401\n",
      "Epoch 164/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1595 - accuracy: 0.9384 - val_loss: 0.1523 - val_accuracy: 0.9411\n",
      "Epoch 165/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1594 - accuracy: 0.9384 - val_loss: 0.1525 - val_accuracy: 0.9410\n",
      "Epoch 166/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1592 - accuracy: 0.9385 - val_loss: 0.1530 - val_accuracy: 0.9403\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1590 - accuracy: 0.9384 - val_loss: 0.1536 - val_accuracy: 0.9416\n",
      "Epoch 168/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1590 - accuracy: 0.9383 - val_loss: 0.1517 - val_accuracy: 0.9417\n",
      "Epoch 169/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.1590 - accuracy: 0.9384 - val_loss: 0.1515 - val_accuracy: 0.9409\n",
      "Epoch 170/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.1587 - accuracy: 0.9384 - val_loss: 0.1523 - val_accuracy: 0.9407\n",
      "Epoch 171/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.1587 - accuracy: 0.9382 - val_loss: 0.1515 - val_accuracy: 0.9414\n",
      "Epoch 172/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1585 - accuracy: 0.9382 - val_loss: 0.1513 - val_accuracy: 0.9416\n",
      "Epoch 173/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.1584 - accuracy: 0.9383 - val_loss: 0.1519 - val_accuracy: 0.9415\n",
      "Epoch 174/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1585 - accuracy: 0.9385 - val_loss: 0.1508 - val_accuracy: 0.9415\n",
      "Epoch 175/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1583 - accuracy: 0.9385 - val_loss: 0.1514 - val_accuracy: 0.9418\n",
      "Epoch 176/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.1582 - accuracy: 0.9385 - val_loss: 0.1512 - val_accuracy: 0.9415\n",
      "Epoch 177/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.1581 - accuracy: 0.9385 - val_loss: 0.1514 - val_accuracy: 0.9414\n",
      "Epoch 178/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1579 - accuracy: 0.9384 - val_loss: 0.1506 - val_accuracy: 0.9421\n",
      "Epoch 179/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1578 - accuracy: 0.9384 - val_loss: 0.1507 - val_accuracy: 0.9417\n",
      "Epoch 180/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1577 - accuracy: 0.9384 - val_loss: 0.1518 - val_accuracy: 0.9420\n",
      "Epoch 181/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1575 - accuracy: 0.9387 - val_loss: 0.1507 - val_accuracy: 0.9426\n",
      "Epoch 182/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1574 - accuracy: 0.9386 - val_loss: 0.1506 - val_accuracy: 0.9423\n",
      "Epoch 183/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1573 - accuracy: 0.9387 - val_loss: 0.1501 - val_accuracy: 0.9416\n",
      "Epoch 184/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1572 - accuracy: 0.9387 - val_loss: 0.1509 - val_accuracy: 0.9419\n",
      "Epoch 185/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1572 - accuracy: 0.9388 - val_loss: 0.1531 - val_accuracy: 0.9400\n",
      "Epoch 186/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1570 - accuracy: 0.9389 - val_loss: 0.1504 - val_accuracy: 0.9415\n",
      "Epoch 187/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1569 - accuracy: 0.9386 - val_loss: 0.1506 - val_accuracy: 0.9422\n",
      "Epoch 188/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1568 - accuracy: 0.9384 - val_loss: 0.1502 - val_accuracy: 0.9426\n",
      "Epoch 189/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.1566 - accuracy: 0.9386 - val_loss: 0.1500 - val_accuracy: 0.9420\n",
      "Epoch 190/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1567 - accuracy: 0.9384 - val_loss: 0.1495 - val_accuracy: 0.9427\n",
      "Epoch 191/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1565 - accuracy: 0.9389 - val_loss: 0.1509 - val_accuracy: 0.9405\n",
      "Epoch 192/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1566 - accuracy: 0.9385 - val_loss: 0.1493 - val_accuracy: 0.9420\n",
      "Epoch 193/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1564 - accuracy: 0.9390 - val_loss: 0.1499 - val_accuracy: 0.9425\n",
      "Epoch 194/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1563 - accuracy: 0.9385 - val_loss: 0.1507 - val_accuracy: 0.9423\n",
      "Epoch 195/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1564 - accuracy: 0.9388 - val_loss: 0.1492 - val_accuracy: 0.9431\n",
      "Epoch 196/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1561 - accuracy: 0.9388 - val_loss: 0.1501 - val_accuracy: 0.9432\n",
      "Epoch 197/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1560 - accuracy: 0.9387 - val_loss: 0.1492 - val_accuracy: 0.9427\n",
      "Epoch 198/200\n",
      "5625/5625 [==============================] - 0s 32us/step - loss: 0.1559 - accuracy: 0.9388 - val_loss: 0.1487 - val_accuracy: 0.9432\n",
      "Epoch 199/200\n",
      "5625/5625 [==============================] - 0s 31us/step - loss: 0.1559 - accuracy: 0.9387 - val_loss: 0.1489 - val_accuracy: 0.9428\n",
      "Epoch 200/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.1558 - accuracy: 0.9388 - val_loss: 0.1489 - val_accuracy: 0.9427\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_187 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 18)                594       \n",
      "=================================================================\n",
      "Total params: 4,122\n",
      "Trainable params: 4,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = x_d3.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = y_d3.copy()\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "train_input_d3 = inputs[:,2:]\n",
    "train_output_d3 = targets[:,1:]\n",
    "\n",
    "x_train_d3, x_test_d3, Y_train_d3, Y_test_d3 = train_test_split(train_input_d3, train_output_d3, train_size=0.75, shuffle=True)\n",
    "\n",
    "model = compile_FFNN_model_DepthThree(3)\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x=x_train_d3,\n",
    "    y=Y_train_d3,\n",
    "    validation_split=.25,\n",
    "    epochs=200\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate confusion matrix and F1 scores on test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.62      0.71       209\n",
      "           1       0.87      0.78      0.82       194\n",
      "           2       0.53      0.49      0.51       201\n",
      "           3       0.40      0.46      0.43       177\n",
      "           4       0.79      0.68      0.73       179\n",
      "           5       0.36      0.07      0.11       151\n",
      "           6       0.00      0.00      0.00       164\n",
      "           7       0.65      0.83      0.73       138\n",
      "           8       0.73      0.71      0.72       131\n",
      "           9       0.39      0.65      0.49       125\n",
      "          10       0.00      0.00      0.00       119\n",
      "          11       0.45      0.74      0.56       103\n",
      "          12       0.44      0.81      0.57       115\n",
      "          13       0.66      0.75      0.70       124\n",
      "          14       0.53      0.87      0.66       107\n",
      "          15       0.56      0.98      0.71        93\n",
      "          16       0.34      0.96      0.50        81\n",
      "          17       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           0.56      2501\n",
      "   macro avg       0.47      0.58      0.50      2501\n",
      "weighted avg       0.51      0.56      0.51      2501\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predictions_d3 = model.predict(x_test_d3)\n",
    "\n",
    "y_pred = np.argmax(predictions_d3, axis=1)\n",
    "y_test = np.argmax(Y_test_d3, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['X00', 'X01', 'X02', 'X10', 'X11', 'X12', 'X20',\n",
    " 'X21', 'X22','Z00', 'Z01', 'Z02', 'Z10', 'Z11', 'Z12', \n",
    " 'Z20', 'Z21', 'Z22'])\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "disp.plot(ax=ax, values_format=\"d\", cmap='gray')\n",
    "disp.im_.colorbar.remove()\n",
    "print( classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Epoch vs. Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss (MSE)')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Depth 3 Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Epoch vs. Accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Depth 3 Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_d3_v3_1k.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Train on 640 samples, validate on 160 samples\n",
      "Epoch 1/200\n",
      "640/640 [==============================] - 0s 205us/step - loss: 0.6785 - accuracy: 0.6663 - val_loss: 0.6698 - val_accuracy: 0.7099\n",
      "Epoch 2/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.6605 - accuracy: 0.7426 - val_loss: 0.6523 - val_accuracy: 0.7467\n",
      "Epoch 3/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.6408 - accuracy: 0.7656 - val_loss: 0.6322 - val_accuracy: 0.7638\n",
      "Epoch 4/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.6175 - accuracy: 0.7839 - val_loss: 0.6080 - val_accuracy: 0.7908\n",
      "Epoch 5/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.5884 - accuracy: 0.8033 - val_loss: 0.5776 - val_accuracy: 0.7984\n",
      "Epoch 6/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.5522 - accuracy: 0.8090 - val_loss: 0.5417 - val_accuracy: 0.7984\n",
      "Epoch 7/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.5124 - accuracy: 0.8090 - val_loss: 0.5074 - val_accuracy: 0.8010\n",
      "Epoch 8/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4785 - accuracy: 0.8307 - val_loss: 0.4838 - val_accuracy: 0.8339\n",
      "Epoch 9/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4571 - accuracy: 0.8441 - val_loss: 0.4712 - val_accuracy: 0.8339\n",
      "Epoch 10/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4458 - accuracy: 0.8441 - val_loss: 0.4646 - val_accuracy: 0.8339\n",
      "Epoch 11/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.4397 - accuracy: 0.8441 - val_loss: 0.4604 - val_accuracy: 0.8339\n",
      "Epoch 12/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4360 - accuracy: 0.8441 - val_loss: 0.4573 - val_accuracy: 0.8339\n",
      "Epoch 13/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4335 - accuracy: 0.8441 - val_loss: 0.4552 - val_accuracy: 0.8339\n",
      "Epoch 14/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4318 - accuracy: 0.8441 - val_loss: 0.4535 - val_accuracy: 0.8339\n",
      "Epoch 15/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.4305 - accuracy: 0.8441 - val_loss: 0.4522 - val_accuracy: 0.8339\n",
      "Epoch 16/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4296 - accuracy: 0.8441 - val_loss: 0.4511 - val_accuracy: 0.8339\n",
      "Epoch 17/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4288 - accuracy: 0.8441 - val_loss: 0.4503 - val_accuracy: 0.8339\n",
      "Epoch 18/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4282 - accuracy: 0.8441 - val_loss: 0.4495 - val_accuracy: 0.8339\n",
      "Epoch 19/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4277 - accuracy: 0.8441 - val_loss: 0.4490 - val_accuracy: 0.8339\n",
      "Epoch 20/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.4273 - accuracy: 0.8441 - val_loss: 0.4486 - val_accuracy: 0.8339\n",
      "Epoch 21/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4270 - accuracy: 0.8441 - val_loss: 0.4481 - val_accuracy: 0.8339\n",
      "Epoch 22/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4267 - accuracy: 0.8441 - val_loss: 0.4477 - val_accuracy: 0.8339\n",
      "Epoch 23/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4265 - accuracy: 0.8441 - val_loss: 0.4473 - val_accuracy: 0.8339\n",
      "Epoch 24/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4262 - accuracy: 0.8441 - val_loss: 0.4471 - val_accuracy: 0.8339\n",
      "Epoch 25/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4260 - accuracy: 0.8441 - val_loss: 0.4468 - val_accuracy: 0.8339\n",
      "Epoch 26/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4258 - accuracy: 0.8441 - val_loss: 0.4465 - val_accuracy: 0.8339\n",
      "Epoch 27/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4256 - accuracy: 0.8441 - val_loss: 0.4462 - val_accuracy: 0.8339\n",
      "Epoch 28/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4254 - accuracy: 0.8441 - val_loss: 0.4459 - val_accuracy: 0.8339\n",
      "Epoch 29/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4253 - accuracy: 0.8441 - val_loss: 0.4458 - val_accuracy: 0.8339\n",
      "Epoch 30/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4251 - accuracy: 0.8441 - val_loss: 0.4455 - val_accuracy: 0.8339\n",
      "Epoch 31/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4250 - accuracy: 0.8441 - val_loss: 0.4453 - val_accuracy: 0.8339\n",
      "Epoch 32/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4249 - accuracy: 0.8441 - val_loss: 0.4452 - val_accuracy: 0.8339\n",
      "Epoch 33/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4247 - accuracy: 0.8441 - val_loss: 0.4450 - val_accuracy: 0.8339\n",
      "Epoch 34/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4246 - accuracy: 0.8441 - val_loss: 0.4449 - val_accuracy: 0.8339\n",
      "Epoch 35/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4244 - accuracy: 0.8441 - val_loss: 0.4447 - val_accuracy: 0.8339\n",
      "Epoch 36/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4243 - accuracy: 0.8441 - val_loss: 0.4445 - val_accuracy: 0.8339\n",
      "Epoch 37/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4242 - accuracy: 0.8441 - val_loss: 0.4444 - val_accuracy: 0.8339\n",
      "Epoch 38/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4241 - accuracy: 0.8441 - val_loss: 0.4442 - val_accuracy: 0.8339\n",
      "Epoch 39/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4239 - accuracy: 0.8441 - val_loss: 0.4441 - val_accuracy: 0.8339\n",
      "Epoch 40/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4238 - accuracy: 0.8441 - val_loss: 0.4440 - val_accuracy: 0.8339\n",
      "Epoch 41/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4237 - accuracy: 0.8441 - val_loss: 0.4439 - val_accuracy: 0.8339\n",
      "Epoch 42/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4235 - accuracy: 0.8441 - val_loss: 0.4437 - val_accuracy: 0.8339\n",
      "Epoch 43/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4234 - accuracy: 0.8441 - val_loss: 0.4435 - val_accuracy: 0.8339\n",
      "Epoch 44/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4233 - accuracy: 0.8441 - val_loss: 0.4434 - val_accuracy: 0.8339\n",
      "Epoch 45/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4232 - accuracy: 0.8441 - val_loss: 0.4431 - val_accuracy: 0.8339\n",
      "Epoch 46/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4230 - accuracy: 0.8441 - val_loss: 0.4430 - val_accuracy: 0.8339\n",
      "Epoch 47/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4229 - accuracy: 0.8441 - val_loss: 0.4428 - val_accuracy: 0.8339\n",
      "Epoch 48/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4227 - accuracy: 0.8441 - val_loss: 0.4427 - val_accuracy: 0.8339\n",
      "Epoch 49/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4226 - accuracy: 0.8441 - val_loss: 0.4426 - val_accuracy: 0.8339\n",
      "Epoch 50/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4225 - accuracy: 0.8441 - val_loss: 0.4426 - val_accuracy: 0.8339\n",
      "Epoch 51/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4224 - accuracy: 0.8441 - val_loss: 0.4424 - val_accuracy: 0.8339\n",
      "Epoch 52/200\n",
      "640/640 [==============================] - 0s 39us/step - loss: 0.4222 - accuracy: 0.8441 - val_loss: 0.4422 - val_accuracy: 0.8339\n",
      "Epoch 53/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4221 - accuracy: 0.8441 - val_loss: 0.4421 - val_accuracy: 0.8339\n",
      "Epoch 54/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4220 - accuracy: 0.8441 - val_loss: 0.4420 - val_accuracy: 0.8339\n",
      "Epoch 55/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4219 - accuracy: 0.8441 - val_loss: 0.4418 - val_accuracy: 0.8339\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 36us/step - loss: 0.4218 - accuracy: 0.8441 - val_loss: 0.4418 - val_accuracy: 0.8339\n",
      "Epoch 57/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4217 - accuracy: 0.8441 - val_loss: 0.4417 - val_accuracy: 0.8339\n",
      "Epoch 58/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4216 - accuracy: 0.8441 - val_loss: 0.4416 - val_accuracy: 0.8339\n",
      "Epoch 59/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4215 - accuracy: 0.8441 - val_loss: 0.4414 - val_accuracy: 0.8339\n",
      "Epoch 60/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4213 - accuracy: 0.8441 - val_loss: 0.4413 - val_accuracy: 0.8339\n",
      "Epoch 61/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4212 - accuracy: 0.8441 - val_loss: 0.4411 - val_accuracy: 0.8339\n",
      "Epoch 62/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4211 - accuracy: 0.8441 - val_loss: 0.4410 - val_accuracy: 0.8339\n",
      "Epoch 63/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4210 - accuracy: 0.8441 - val_loss: 0.4409 - val_accuracy: 0.8339\n",
      "Epoch 64/200\n",
      "640/640 [==============================] - 0s 42us/step - loss: 0.4209 - accuracy: 0.8441 - val_loss: 0.4408 - val_accuracy: 0.8339\n",
      "Epoch 65/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4208 - accuracy: 0.8441 - val_loss: 0.4407 - val_accuracy: 0.8339\n",
      "Epoch 66/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4207 - accuracy: 0.8441 - val_loss: 0.4405 - val_accuracy: 0.8339\n",
      "Epoch 67/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4206 - accuracy: 0.8441 - val_loss: 0.4405 - val_accuracy: 0.8339\n",
      "Epoch 68/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4205 - accuracy: 0.8441 - val_loss: 0.4403 - val_accuracy: 0.8339\n",
      "Epoch 69/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4204 - accuracy: 0.8441 - val_loss: 0.4401 - val_accuracy: 0.8339\n",
      "Epoch 70/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4203 - accuracy: 0.8441 - val_loss: 0.4400 - val_accuracy: 0.8339\n",
      "Epoch 71/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4201 - accuracy: 0.8441 - val_loss: 0.4399 - val_accuracy: 0.8339\n",
      "Epoch 72/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4200 - accuracy: 0.8441 - val_loss: 0.4398 - val_accuracy: 0.8339\n",
      "Epoch 73/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4199 - accuracy: 0.8441 - val_loss: 0.4397 - val_accuracy: 0.8339\n",
      "Epoch 74/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4198 - accuracy: 0.8441 - val_loss: 0.4395 - val_accuracy: 0.8339\n",
      "Epoch 75/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.4197 - accuracy: 0.8441 - val_loss: 0.4394 - val_accuracy: 0.8339\n",
      "Epoch 76/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.4195 - accuracy: 0.8441 - val_loss: 0.4394 - val_accuracy: 0.8339\n",
      "Epoch 77/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4194 - accuracy: 0.8441 - val_loss: 0.4393 - val_accuracy: 0.8339\n",
      "Epoch 78/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4193 - accuracy: 0.8441 - val_loss: 0.4391 - val_accuracy: 0.8339\n",
      "Epoch 79/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4192 - accuracy: 0.8441 - val_loss: 0.4389 - val_accuracy: 0.8339\n",
      "Epoch 80/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4190 - accuracy: 0.8441 - val_loss: 0.4387 - val_accuracy: 0.8339\n",
      "Epoch 81/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4189 - accuracy: 0.8441 - val_loss: 0.4386 - val_accuracy: 0.8339\n",
      "Epoch 82/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4187 - accuracy: 0.8441 - val_loss: 0.4385 - val_accuracy: 0.8339\n",
      "Epoch 83/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4187 - accuracy: 0.8441 - val_loss: 0.4383 - val_accuracy: 0.8339\n",
      "Epoch 84/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4185 - accuracy: 0.8441 - val_loss: 0.4382 - val_accuracy: 0.8339\n",
      "Epoch 85/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4183 - accuracy: 0.8441 - val_loss: 0.4381 - val_accuracy: 0.8339\n",
      "Epoch 86/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.4182 - accuracy: 0.8441 - val_loss: 0.4380 - val_accuracy: 0.8339\n",
      "Epoch 87/200\n",
      "640/640 [==============================] - 0s 35us/step - loss: 0.4181 - accuracy: 0.8441 - val_loss: 0.4378 - val_accuracy: 0.8339\n",
      "Epoch 88/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4179 - accuracy: 0.8441 - val_loss: 0.4375 - val_accuracy: 0.8339\n",
      "Epoch 89/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4177 - accuracy: 0.8441 - val_loss: 0.4374 - val_accuracy: 0.8339\n",
      "Epoch 90/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4175 - accuracy: 0.8441 - val_loss: 0.4373 - val_accuracy: 0.8339\n",
      "Epoch 91/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4174 - accuracy: 0.8441 - val_loss: 0.4372 - val_accuracy: 0.8339\n",
      "Epoch 92/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4172 - accuracy: 0.8441 - val_loss: 0.4369 - val_accuracy: 0.8339\n",
      "Epoch 93/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4170 - accuracy: 0.8441 - val_loss: 0.4368 - val_accuracy: 0.8339\n",
      "Epoch 94/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4168 - accuracy: 0.8441 - val_loss: 0.4365 - val_accuracy: 0.8339\n",
      "Epoch 95/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4166 - accuracy: 0.8441 - val_loss: 0.4364 - val_accuracy: 0.8339\n",
      "Epoch 96/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4165 - accuracy: 0.8441 - val_loss: 0.4361 - val_accuracy: 0.8339\n",
      "Epoch 97/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4163 - accuracy: 0.8441 - val_loss: 0.4359 - val_accuracy: 0.8339\n",
      "Epoch 98/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4161 - accuracy: 0.8441 - val_loss: 0.4358 - val_accuracy: 0.8339\n",
      "Epoch 99/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4159 - accuracy: 0.8441 - val_loss: 0.4355 - val_accuracy: 0.8339\n",
      "Epoch 100/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4156 - accuracy: 0.8441 - val_loss: 0.4353 - val_accuracy: 0.8339\n",
      "Epoch 101/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4155 - accuracy: 0.8441 - val_loss: 0.4350 - val_accuracy: 0.8339\n",
      "Epoch 102/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4152 - accuracy: 0.8441 - val_loss: 0.4350 - val_accuracy: 0.8339\n",
      "Epoch 103/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.4151 - accuracy: 0.8441 - val_loss: 0.4346 - val_accuracy: 0.8339\n",
      "Epoch 104/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4148 - accuracy: 0.8441 - val_loss: 0.4342 - val_accuracy: 0.8339\n",
      "Epoch 105/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4146 - accuracy: 0.8441 - val_loss: 0.4341 - val_accuracy: 0.8339\n",
      "Epoch 106/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4144 - accuracy: 0.8441 - val_loss: 0.4339 - val_accuracy: 0.8339\n",
      "Epoch 107/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4141 - accuracy: 0.8441 - val_loss: 0.4336 - val_accuracy: 0.8339\n",
      "Epoch 108/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4139 - accuracy: 0.8441 - val_loss: 0.4334 - val_accuracy: 0.8339\n",
      "Epoch 109/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4137 - accuracy: 0.8441 - val_loss: 0.4332 - val_accuracy: 0.8339\n",
      "Epoch 110/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4134 - accuracy: 0.8441 - val_loss: 0.4329 - val_accuracy: 0.8339\n",
      "Epoch 111/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4131 - accuracy: 0.8441 - val_loss: 0.4328 - val_accuracy: 0.8339\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 33us/step - loss: 0.4129 - accuracy: 0.8441 - val_loss: 0.4324 - val_accuracy: 0.8339\n",
      "Epoch 113/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4126 - accuracy: 0.8441 - val_loss: 0.4322 - val_accuracy: 0.8339\n",
      "Epoch 114/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4123 - accuracy: 0.8441 - val_loss: 0.4320 - val_accuracy: 0.8339\n",
      "Epoch 115/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4121 - accuracy: 0.8441 - val_loss: 0.4315 - val_accuracy: 0.8339\n",
      "Epoch 116/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4118 - accuracy: 0.8441 - val_loss: 0.4312 - val_accuracy: 0.8339\n",
      "Epoch 117/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4115 - accuracy: 0.8441 - val_loss: 0.4310 - val_accuracy: 0.8339\n",
      "Epoch 118/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4111 - accuracy: 0.8441 - val_loss: 0.4306 - val_accuracy: 0.8339\n",
      "Epoch 119/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4109 - accuracy: 0.8441 - val_loss: 0.4305 - val_accuracy: 0.8339\n",
      "Epoch 120/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4106 - accuracy: 0.8441 - val_loss: 0.4302 - val_accuracy: 0.8339\n",
      "Epoch 121/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4103 - accuracy: 0.8441 - val_loss: 0.4298 - val_accuracy: 0.8339\n",
      "Epoch 122/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4099 - accuracy: 0.8441 - val_loss: 0.4295 - val_accuracy: 0.8339\n",
      "Epoch 123/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4096 - accuracy: 0.8441 - val_loss: 0.4291 - val_accuracy: 0.8339\n",
      "Epoch 124/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4092 - accuracy: 0.8441 - val_loss: 0.4288 - val_accuracy: 0.8339\n",
      "Epoch 125/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4088 - accuracy: 0.8441 - val_loss: 0.4285 - val_accuracy: 0.8339\n",
      "Epoch 126/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4085 - accuracy: 0.8441 - val_loss: 0.4279 - val_accuracy: 0.8339\n",
      "Epoch 127/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4081 - accuracy: 0.8441 - val_loss: 0.4277 - val_accuracy: 0.8339\n",
      "Epoch 128/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4077 - accuracy: 0.8441 - val_loss: 0.4274 - val_accuracy: 0.8339\n",
      "Epoch 129/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.4073 - accuracy: 0.8441 - val_loss: 0.4270 - val_accuracy: 0.8339\n",
      "Epoch 130/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4069 - accuracy: 0.8441 - val_loss: 0.4266 - val_accuracy: 0.8339\n",
      "Epoch 131/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4065 - accuracy: 0.8441 - val_loss: 0.4264 - val_accuracy: 0.8339\n",
      "Epoch 132/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4060 - accuracy: 0.8441 - val_loss: 0.4257 - val_accuracy: 0.8339\n",
      "Epoch 133/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4055 - accuracy: 0.8441 - val_loss: 0.4252 - val_accuracy: 0.8339\n",
      "Epoch 134/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4051 - accuracy: 0.8441 - val_loss: 0.4249 - val_accuracy: 0.8339\n",
      "Epoch 135/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4046 - accuracy: 0.8441 - val_loss: 0.4245 - val_accuracy: 0.8339\n",
      "Epoch 136/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4041 - accuracy: 0.8441 - val_loss: 0.4240 - val_accuracy: 0.8339\n",
      "Epoch 137/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.4036 - accuracy: 0.8441 - val_loss: 0.4236 - val_accuracy: 0.8339\n",
      "Epoch 138/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4031 - accuracy: 0.8441 - val_loss: 0.4233 - val_accuracy: 0.8339\n",
      "Epoch 139/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4026 - accuracy: 0.8441 - val_loss: 0.4226 - val_accuracy: 0.8339\n",
      "Epoch 140/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4021 - accuracy: 0.8441 - val_loss: 0.4224 - val_accuracy: 0.8339\n",
      "Epoch 141/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4016 - accuracy: 0.8441 - val_loss: 0.4217 - val_accuracy: 0.8339\n",
      "Epoch 142/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4011 - accuracy: 0.8442 - val_loss: 0.4213 - val_accuracy: 0.8339\n",
      "Epoch 143/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4006 - accuracy: 0.8442 - val_loss: 0.4210 - val_accuracy: 0.8339\n",
      "Epoch 144/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4000 - accuracy: 0.8442 - val_loss: 0.4204 - val_accuracy: 0.8339\n",
      "Epoch 145/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3995 - accuracy: 0.8443 - val_loss: 0.4201 - val_accuracy: 0.8339\n",
      "Epoch 146/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3990 - accuracy: 0.8443 - val_loss: 0.4197 - val_accuracy: 0.8339\n",
      "Epoch 147/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.3985 - accuracy: 0.8443 - val_loss: 0.4191 - val_accuracy: 0.8339\n",
      "Epoch 148/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3979 - accuracy: 0.8443 - val_loss: 0.4186 - val_accuracy: 0.8339\n",
      "Epoch 149/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3974 - accuracy: 0.8445 - val_loss: 0.4181 - val_accuracy: 0.8342\n",
      "Epoch 150/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3969 - accuracy: 0.8447 - val_loss: 0.4180 - val_accuracy: 0.8339\n",
      "Epoch 151/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3964 - accuracy: 0.8449 - val_loss: 0.4175 - val_accuracy: 0.8339\n",
      "Epoch 152/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3958 - accuracy: 0.8448 - val_loss: 0.4171 - val_accuracy: 0.8339\n",
      "Epoch 153/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3953 - accuracy: 0.8449 - val_loss: 0.4168 - val_accuracy: 0.8339\n",
      "Epoch 154/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.3949 - accuracy: 0.8449 - val_loss: 0.4161 - val_accuracy: 0.8339\n",
      "Epoch 155/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3943 - accuracy: 0.8449 - val_loss: 0.4157 - val_accuracy: 0.8339\n",
      "Epoch 156/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3938 - accuracy: 0.8449 - val_loss: 0.4154 - val_accuracy: 0.8339\n",
      "Epoch 157/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3934 - accuracy: 0.8449 - val_loss: 0.4146 - val_accuracy: 0.8339\n",
      "Epoch 158/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3928 - accuracy: 0.8449 - val_loss: 0.4147 - val_accuracy: 0.8339\n",
      "Epoch 159/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3924 - accuracy: 0.8449 - val_loss: 0.4141 - val_accuracy: 0.8342\n",
      "Epoch 160/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3919 - accuracy: 0.8449 - val_loss: 0.4137 - val_accuracy: 0.8345\n",
      "Epoch 161/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3914 - accuracy: 0.8450 - val_loss: 0.4135 - val_accuracy: 0.8352\n",
      "Epoch 162/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3910 - accuracy: 0.8455 - val_loss: 0.4130 - val_accuracy: 0.8355\n",
      "Epoch 163/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3905 - accuracy: 0.8457 - val_loss: 0.4125 - val_accuracy: 0.8349\n",
      "Epoch 164/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3901 - accuracy: 0.8456 - val_loss: 0.4120 - val_accuracy: 0.8349\n",
      "Epoch 165/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3897 - accuracy: 0.8453 - val_loss: 0.4120 - val_accuracy: 0.8359\n",
      "Epoch 166/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3893 - accuracy: 0.8459 - val_loss: 0.4117 - val_accuracy: 0.8359\n",
      "Epoch 167/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3889 - accuracy: 0.8463 - val_loss: 0.4113 - val_accuracy: 0.8355\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 34us/step - loss: 0.3885 - accuracy: 0.8456 - val_loss: 0.4109 - val_accuracy: 0.8349\n",
      "Epoch 169/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3881 - accuracy: 0.8453 - val_loss: 0.4109 - val_accuracy: 0.8349\n",
      "Epoch 170/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3878 - accuracy: 0.8459 - val_loss: 0.4104 - val_accuracy: 0.8352\n",
      "Epoch 171/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3874 - accuracy: 0.8458 - val_loss: 0.4100 - val_accuracy: 0.8352\n",
      "Epoch 172/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3871 - accuracy: 0.8459 - val_loss: 0.4097 - val_accuracy: 0.8352\n",
      "Epoch 173/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3867 - accuracy: 0.8462 - val_loss: 0.4095 - val_accuracy: 0.8355\n",
      "Epoch 174/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3864 - accuracy: 0.8459 - val_loss: 0.4095 - val_accuracy: 0.8352\n",
      "Epoch 175/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3860 - accuracy: 0.8456 - val_loss: 0.4091 - val_accuracy: 0.8349\n",
      "Epoch 176/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3857 - accuracy: 0.8458 - val_loss: 0.4090 - val_accuracy: 0.8352\n",
      "Epoch 177/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3855 - accuracy: 0.8461 - val_loss: 0.4087 - val_accuracy: 0.8345\n",
      "Epoch 178/200\n",
      "640/640 [==============================] - 0s 35us/step - loss: 0.3852 - accuracy: 0.8461 - val_loss: 0.4087 - val_accuracy: 0.8349\n",
      "Epoch 179/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3849 - accuracy: 0.8458 - val_loss: 0.4082 - val_accuracy: 0.8342\n",
      "Epoch 180/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3845 - accuracy: 0.8464 - val_loss: 0.4079 - val_accuracy: 0.8336\n",
      "Epoch 181/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3842 - accuracy: 0.8465 - val_loss: 0.4079 - val_accuracy: 0.8339\n",
      "Epoch 182/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3840 - accuracy: 0.8467 - val_loss: 0.4076 - val_accuracy: 0.8339\n",
      "Epoch 183/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3837 - accuracy: 0.8469 - val_loss: 0.4079 - val_accuracy: 0.8339\n",
      "Epoch 184/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3835 - accuracy: 0.8470 - val_loss: 0.4076 - val_accuracy: 0.8329\n",
      "Epoch 185/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3832 - accuracy: 0.8472 - val_loss: 0.4070 - val_accuracy: 0.8329\n",
      "Epoch 186/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3829 - accuracy: 0.8475 - val_loss: 0.4067 - val_accuracy: 0.8326\n",
      "Epoch 187/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3827 - accuracy: 0.8475 - val_loss: 0.4067 - val_accuracy: 0.8326\n",
      "Epoch 188/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3825 - accuracy: 0.8468 - val_loss: 0.4065 - val_accuracy: 0.8326\n",
      "Epoch 189/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3822 - accuracy: 0.8475 - val_loss: 0.4068 - val_accuracy: 0.8329\n",
      "Epoch 190/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.3820 - accuracy: 0.8473 - val_loss: 0.4067 - val_accuracy: 0.8339\n",
      "Epoch 191/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.3818 - accuracy: 0.8479 - val_loss: 0.4065 - val_accuracy: 0.8339\n",
      "Epoch 192/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3816 - accuracy: 0.8474 - val_loss: 0.4068 - val_accuracy: 0.8345\n",
      "Epoch 193/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3814 - accuracy: 0.8471 - val_loss: 0.4060 - val_accuracy: 0.8349\n",
      "Epoch 194/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3813 - accuracy: 0.8478 - val_loss: 0.4060 - val_accuracy: 0.8352\n",
      "Epoch 195/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.3810 - accuracy: 0.8472 - val_loss: 0.4060 - val_accuracy: 0.8345\n",
      "Epoch 196/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3808 - accuracy: 0.8476 - val_loss: 0.4054 - val_accuracy: 0.8345\n",
      "Epoch 197/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3805 - accuracy: 0.8473 - val_loss: 0.4062 - val_accuracy: 0.8349\n",
      "Epoch 198/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3805 - accuracy: 0.8466 - val_loss: 0.4057 - val_accuracy: 0.8355\n",
      "Epoch 199/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3803 - accuracy: 0.8469 - val_loss: 0.4054 - val_accuracy: 0.8355\n",
      "Epoch 200/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3801 - accuracy: 0.8467 - val_loss: 0.4051 - val_accuracy: 0.8355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:127: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Train on 640 samples, validate on 161 samples\n",
      "Epoch 1/200\n",
      "640/640 [==============================] - 0s 202us/step - loss: 0.6865 - accuracy: 0.5959 - val_loss: 0.6789 - val_accuracy: 0.6535\n",
      "Epoch 2/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.6685 - accuracy: 0.7105 - val_loss: 0.6627 - val_accuracy: 0.7274\n",
      "Epoch 3/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.6511 - accuracy: 0.7517 - val_loss: 0.6458 - val_accuracy: 0.7414\n",
      "Epoch 4/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.6321 - accuracy: 0.7549 - val_loss: 0.6269 - val_accuracy: 0.7483\n",
      "Epoch 5/200\n",
      "640/640 [==============================] - 0s 39us/step - loss: 0.6100 - accuracy: 0.7663 - val_loss: 0.6042 - val_accuracy: 0.7587\n",
      "Epoch 6/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.5832 - accuracy: 0.7804 - val_loss: 0.5766 - val_accuracy: 0.7702\n",
      "Epoch 7/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.5508 - accuracy: 0.7983 - val_loss: 0.5442 - val_accuracy: 0.8068\n",
      "Epoch 8/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.5145 - accuracy: 0.8328 - val_loss: 0.5111 - val_accuracy: 0.8336\n",
      "Epoch 9/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4809 - accuracy: 0.8435 - val_loss: 0.4849 - val_accuracy: 0.8339\n",
      "Epoch 10/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4575 - accuracy: 0.8435 - val_loss: 0.4693 - val_accuracy: 0.8339\n",
      "Epoch 11/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4446 - accuracy: 0.8435 - val_loss: 0.4614 - val_accuracy: 0.8339\n",
      "Epoch 12/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4382 - accuracy: 0.8435 - val_loss: 0.4572 - val_accuracy: 0.8339\n",
      "Epoch 13/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4348 - accuracy: 0.8435 - val_loss: 0.4546 - val_accuracy: 0.8339\n",
      "Epoch 14/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4327 - accuracy: 0.8435 - val_loss: 0.4527 - val_accuracy: 0.8339\n",
      "Epoch 15/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4313 - accuracy: 0.8435 - val_loss: 0.4515 - val_accuracy: 0.8339\n",
      "Epoch 16/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4302 - accuracy: 0.8435 - val_loss: 0.4505 - val_accuracy: 0.8339\n",
      "Epoch 17/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4294 - accuracy: 0.8435 - val_loss: 0.4496 - val_accuracy: 0.8339\n",
      "Epoch 18/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4288 - accuracy: 0.8435 - val_loss: 0.4491 - val_accuracy: 0.8339\n",
      "Epoch 19/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4283 - accuracy: 0.8435 - val_loss: 0.4487 - val_accuracy: 0.8339\n",
      "Epoch 20/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4279 - accuracy: 0.8435 - val_loss: 0.4483 - val_accuracy: 0.8339\n",
      "Epoch 21/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4275 - accuracy: 0.8435 - val_loss: 0.4480 - val_accuracy: 0.8339\n",
      "Epoch 22/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4272 - accuracy: 0.8435 - val_loss: 0.4478 - val_accuracy: 0.8339\n",
      "Epoch 23/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4270 - accuracy: 0.8435 - val_loss: 0.4475 - val_accuracy: 0.8339\n",
      "Epoch 24/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4267 - accuracy: 0.8435 - val_loss: 0.4472 - val_accuracy: 0.8339\n",
      "Epoch 25/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4265 - accuracy: 0.8435 - val_loss: 0.4470 - val_accuracy: 0.8339\n",
      "Epoch 26/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4263 - accuracy: 0.8435 - val_loss: 0.4469 - val_accuracy: 0.8339\n",
      "Epoch 27/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4261 - accuracy: 0.8435 - val_loss: 0.4467 - val_accuracy: 0.8339\n",
      "Epoch 28/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4259 - accuracy: 0.8435 - val_loss: 0.4465 - val_accuracy: 0.8339\n",
      "Epoch 29/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4257 - accuracy: 0.8435 - val_loss: 0.4464 - val_accuracy: 0.8339\n",
      "Epoch 30/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4256 - accuracy: 0.8435 - val_loss: 0.4462 - val_accuracy: 0.8339\n",
      "Epoch 31/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4254 - accuracy: 0.8435 - val_loss: 0.4461 - val_accuracy: 0.8339\n",
      "Epoch 32/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4253 - accuracy: 0.8435 - val_loss: 0.4460 - val_accuracy: 0.8339\n",
      "Epoch 33/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4251 - accuracy: 0.8435 - val_loss: 0.4458 - val_accuracy: 0.8339\n",
      "Epoch 34/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4250 - accuracy: 0.8435 - val_loss: 0.4458 - val_accuracy: 0.8339\n",
      "Epoch 35/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4249 - accuracy: 0.8435 - val_loss: 0.4455 - val_accuracy: 0.8339\n",
      "Epoch 36/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4248 - accuracy: 0.8435 - val_loss: 0.4454 - val_accuracy: 0.8339\n",
      "Epoch 37/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4246 - accuracy: 0.8435 - val_loss: 0.4453 - val_accuracy: 0.8339\n",
      "Epoch 38/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4245 - accuracy: 0.8435 - val_loss: 0.4452 - val_accuracy: 0.8339\n",
      "Epoch 39/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4244 - accuracy: 0.8435 - val_loss: 0.4451 - val_accuracy: 0.8339\n",
      "Epoch 40/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4243 - accuracy: 0.8435 - val_loss: 0.4450 - val_accuracy: 0.8339\n",
      "Epoch 41/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4242 - accuracy: 0.8435 - val_loss: 0.4449 - val_accuracy: 0.8339\n",
      "Epoch 42/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4241 - accuracy: 0.8435 - val_loss: 0.4448 - val_accuracy: 0.8339\n",
      "Epoch 43/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4240 - accuracy: 0.8435 - val_loss: 0.4447 - val_accuracy: 0.8339\n",
      "Epoch 44/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4239 - accuracy: 0.8435 - val_loss: 0.4446 - val_accuracy: 0.8339\n",
      "Epoch 45/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4238 - accuracy: 0.8435 - val_loss: 0.4444 - val_accuracy: 0.8339\n",
      "Epoch 46/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4237 - accuracy: 0.8435 - val_loss: 0.4443 - val_accuracy: 0.8339\n",
      "Epoch 47/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4236 - accuracy: 0.8435 - val_loss: 0.4442 - val_accuracy: 0.8339\n",
      "Epoch 48/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4235 - accuracy: 0.8435 - val_loss: 0.4442 - val_accuracy: 0.8339\n",
      "Epoch 49/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4234 - accuracy: 0.8435 - val_loss: 0.4441 - val_accuracy: 0.8339\n",
      "Epoch 50/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4233 - accuracy: 0.8435 - val_loss: 0.4440 - val_accuracy: 0.8339\n",
      "Epoch 51/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4232 - accuracy: 0.8435 - val_loss: 0.4439 - val_accuracy: 0.8339\n",
      "Epoch 52/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4231 - accuracy: 0.8435 - val_loss: 0.4438 - val_accuracy: 0.8339\n",
      "Epoch 53/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4230 - accuracy: 0.8435 - val_loss: 0.4438 - val_accuracy: 0.8339\n",
      "Epoch 54/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4230 - accuracy: 0.8435 - val_loss: 0.4437 - val_accuracy: 0.8339\n",
      "Epoch 55/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4229 - accuracy: 0.8435 - val_loss: 0.4436 - val_accuracy: 0.8339\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 34us/step - loss: 0.4228 - accuracy: 0.8435 - val_loss: 0.4435 - val_accuracy: 0.8339\n",
      "Epoch 57/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4227 - accuracy: 0.8435 - val_loss: 0.4435 - val_accuracy: 0.8339\n",
      "Epoch 58/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4226 - accuracy: 0.8435 - val_loss: 0.4434 - val_accuracy: 0.8339\n",
      "Epoch 59/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4226 - accuracy: 0.8435 - val_loss: 0.4434 - val_accuracy: 0.8339\n",
      "Epoch 60/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4225 - accuracy: 0.8435 - val_loss: 0.4433 - val_accuracy: 0.8339\n",
      "Epoch 61/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4224 - accuracy: 0.8435 - val_loss: 0.4432 - val_accuracy: 0.8339\n",
      "Epoch 62/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4223 - accuracy: 0.8435 - val_loss: 0.4432 - val_accuracy: 0.8339\n",
      "Epoch 63/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4222 - accuracy: 0.8435 - val_loss: 0.4430 - val_accuracy: 0.8339\n",
      "Epoch 64/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4221 - accuracy: 0.8435 - val_loss: 0.4429 - val_accuracy: 0.8339\n",
      "Epoch 65/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4220 - accuracy: 0.8435 - val_loss: 0.4430 - val_accuracy: 0.8339\n",
      "Epoch 66/200\n",
      "640/640 [==============================] - 0s 48us/step - loss: 0.4219 - accuracy: 0.8435 - val_loss: 0.4429 - val_accuracy: 0.8339\n",
      "Epoch 67/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4218 - accuracy: 0.8435 - val_loss: 0.4428 - val_accuracy: 0.8339\n",
      "Epoch 68/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4218 - accuracy: 0.8435 - val_loss: 0.4426 - val_accuracy: 0.8339\n",
      "Epoch 69/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4217 - accuracy: 0.8435 - val_loss: 0.4426 - val_accuracy: 0.8339\n",
      "Epoch 70/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4216 - accuracy: 0.8435 - val_loss: 0.4425 - val_accuracy: 0.8339\n",
      "Epoch 71/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4215 - accuracy: 0.8435 - val_loss: 0.4424 - val_accuracy: 0.8339\n",
      "Epoch 72/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4214 - accuracy: 0.8435 - val_loss: 0.4424 - val_accuracy: 0.8339\n",
      "Epoch 73/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4213 - accuracy: 0.8435 - val_loss: 0.4423 - val_accuracy: 0.8339\n",
      "Epoch 74/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4212 - accuracy: 0.8435 - val_loss: 0.4422 - val_accuracy: 0.8339\n",
      "Epoch 75/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4211 - accuracy: 0.8435 - val_loss: 0.4421 - val_accuracy: 0.8339\n",
      "Epoch 76/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4211 - accuracy: 0.8435 - val_loss: 0.4420 - val_accuracy: 0.8339\n",
      "Epoch 77/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4209 - accuracy: 0.8435 - val_loss: 0.4420 - val_accuracy: 0.8339\n",
      "Epoch 78/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4208 - accuracy: 0.8435 - val_loss: 0.4418 - val_accuracy: 0.8339\n",
      "Epoch 79/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4207 - accuracy: 0.8435 - val_loss: 0.4417 - val_accuracy: 0.8339\n",
      "Epoch 80/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4206 - accuracy: 0.8435 - val_loss: 0.4417 - val_accuracy: 0.8339\n",
      "Epoch 81/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4205 - accuracy: 0.8435 - val_loss: 0.4415 - val_accuracy: 0.8339\n",
      "Epoch 82/200\n",
      "640/640 [==============================] - 0s 39us/step - loss: 0.4204 - accuracy: 0.8435 - val_loss: 0.4415 - val_accuracy: 0.8339\n",
      "Epoch 83/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4203 - accuracy: 0.8435 - val_loss: 0.4414 - val_accuracy: 0.8339\n",
      "Epoch 84/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4202 - accuracy: 0.8435 - val_loss: 0.4414 - val_accuracy: 0.8339\n",
      "Epoch 85/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4201 - accuracy: 0.8435 - val_loss: 0.4412 - val_accuracy: 0.8339\n",
      "Epoch 86/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4200 - accuracy: 0.8435 - val_loss: 0.4410 - val_accuracy: 0.8339\n",
      "Epoch 87/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4198 - accuracy: 0.8435 - val_loss: 0.4409 - val_accuracy: 0.8339\n",
      "Epoch 88/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4197 - accuracy: 0.8435 - val_loss: 0.4408 - val_accuracy: 0.8339\n",
      "Epoch 89/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4196 - accuracy: 0.8435 - val_loss: 0.4408 - val_accuracy: 0.8339\n",
      "Epoch 90/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4195 - accuracy: 0.8435 - val_loss: 0.4407 - val_accuracy: 0.8339\n",
      "Epoch 91/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4194 - accuracy: 0.8435 - val_loss: 0.4406 - val_accuracy: 0.8339\n",
      "Epoch 92/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4192 - accuracy: 0.8435 - val_loss: 0.4405 - val_accuracy: 0.8339\n",
      "Epoch 93/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4191 - accuracy: 0.8435 - val_loss: 0.4404 - val_accuracy: 0.8339\n",
      "Epoch 94/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4190 - accuracy: 0.8435 - val_loss: 0.4403 - val_accuracy: 0.8339\n",
      "Epoch 95/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.4189 - accuracy: 0.8435 - val_loss: 0.4402 - val_accuracy: 0.8339\n",
      "Epoch 96/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4187 - accuracy: 0.8435 - val_loss: 0.4400 - val_accuracy: 0.8339\n",
      "Epoch 97/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4186 - accuracy: 0.8435 - val_loss: 0.4401 - val_accuracy: 0.8339\n",
      "Epoch 98/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4184 - accuracy: 0.8435 - val_loss: 0.4399 - val_accuracy: 0.8339\n",
      "Epoch 99/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4183 - accuracy: 0.8435 - val_loss: 0.4398 - val_accuracy: 0.8339\n",
      "Epoch 100/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4181 - accuracy: 0.8435 - val_loss: 0.4397 - val_accuracy: 0.8339\n",
      "Epoch 101/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4180 - accuracy: 0.8435 - val_loss: 0.4396 - val_accuracy: 0.8339\n",
      "Epoch 102/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4178 - accuracy: 0.8435 - val_loss: 0.4395 - val_accuracy: 0.8339\n",
      "Epoch 103/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4177 - accuracy: 0.8435 - val_loss: 0.4392 - val_accuracy: 0.8339\n",
      "Epoch 104/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4175 - accuracy: 0.8435 - val_loss: 0.4391 - val_accuracy: 0.8339\n",
      "Epoch 105/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4174 - accuracy: 0.8435 - val_loss: 0.4391 - val_accuracy: 0.8339\n",
      "Epoch 106/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4172 - accuracy: 0.8435 - val_loss: 0.4389 - val_accuracy: 0.8339\n",
      "Epoch 107/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4170 - accuracy: 0.8435 - val_loss: 0.4389 - val_accuracy: 0.8339\n",
      "Epoch 108/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4168 - accuracy: 0.8435 - val_loss: 0.4388 - val_accuracy: 0.8339\n",
      "Epoch 109/200\n",
      "640/640 [==============================] - 0s 39us/step - loss: 0.4167 - accuracy: 0.8435 - val_loss: 0.4386 - val_accuracy: 0.8339\n",
      "Epoch 110/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4165 - accuracy: 0.8435 - val_loss: 0.4384 - val_accuracy: 0.8339\n",
      "Epoch 111/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4163 - accuracy: 0.8435 - val_loss: 0.4383 - val_accuracy: 0.8339\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 36us/step - loss: 0.4161 - accuracy: 0.8435 - val_loss: 0.4382 - val_accuracy: 0.8339\n",
      "Epoch 113/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4159 - accuracy: 0.8435 - val_loss: 0.4379 - val_accuracy: 0.8339\n",
      "Epoch 114/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4157 - accuracy: 0.8435 - val_loss: 0.4378 - val_accuracy: 0.8339\n",
      "Epoch 115/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4155 - accuracy: 0.8435 - val_loss: 0.4377 - val_accuracy: 0.8339\n",
      "Epoch 116/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4154 - accuracy: 0.8435 - val_loss: 0.4375 - val_accuracy: 0.8339\n",
      "Epoch 117/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4152 - accuracy: 0.8435 - val_loss: 0.4375 - val_accuracy: 0.8339\n",
      "Epoch 118/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4149 - accuracy: 0.8435 - val_loss: 0.4373 - val_accuracy: 0.8339\n",
      "Epoch 119/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4147 - accuracy: 0.8435 - val_loss: 0.4372 - val_accuracy: 0.8339\n",
      "Epoch 120/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4145 - accuracy: 0.8435 - val_loss: 0.4369 - val_accuracy: 0.8339\n",
      "Epoch 121/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4143 - accuracy: 0.8435 - val_loss: 0.4368 - val_accuracy: 0.8339\n",
      "Epoch 122/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4141 - accuracy: 0.8435 - val_loss: 0.4366 - val_accuracy: 0.8339\n",
      "Epoch 123/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4139 - accuracy: 0.8435 - val_loss: 0.4366 - val_accuracy: 0.8339\n",
      "Epoch 124/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4136 - accuracy: 0.8435 - val_loss: 0.4364 - val_accuracy: 0.8339\n",
      "Epoch 125/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4134 - accuracy: 0.8435 - val_loss: 0.4361 - val_accuracy: 0.8339\n",
      "Epoch 126/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4132 - accuracy: 0.8435 - val_loss: 0.4361 - val_accuracy: 0.8339\n",
      "Epoch 127/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4130 - accuracy: 0.8435 - val_loss: 0.4361 - val_accuracy: 0.8339\n",
      "Epoch 128/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4127 - accuracy: 0.8435 - val_loss: 0.4359 - val_accuracy: 0.8339\n",
      "Epoch 129/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4125 - accuracy: 0.8435 - val_loss: 0.4356 - val_accuracy: 0.8339\n",
      "Epoch 130/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4123 - accuracy: 0.8435 - val_loss: 0.4354 - val_accuracy: 0.8339\n",
      "Epoch 131/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4120 - accuracy: 0.8435 - val_loss: 0.4352 - val_accuracy: 0.8339\n",
      "Epoch 132/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4119 - accuracy: 0.8435 - val_loss: 0.4352 - val_accuracy: 0.8339\n",
      "Epoch 133/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4116 - accuracy: 0.8435 - val_loss: 0.4351 - val_accuracy: 0.8339\n",
      "Epoch 134/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4114 - accuracy: 0.8435 - val_loss: 0.4349 - val_accuracy: 0.8339\n",
      "Epoch 135/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4112 - accuracy: 0.8435 - val_loss: 0.4348 - val_accuracy: 0.8339\n",
      "Epoch 136/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4110 - accuracy: 0.8435 - val_loss: 0.4346 - val_accuracy: 0.8339\n",
      "Epoch 137/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4107 - accuracy: 0.8435 - val_loss: 0.4343 - val_accuracy: 0.8339\n",
      "Epoch 138/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4104 - accuracy: 0.8435 - val_loss: 0.4343 - val_accuracy: 0.8339\n",
      "Epoch 139/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4102 - accuracy: 0.8435 - val_loss: 0.4340 - val_accuracy: 0.8339\n",
      "Epoch 140/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4100 - accuracy: 0.8435 - val_loss: 0.4339 - val_accuracy: 0.8339\n",
      "Epoch 141/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4097 - accuracy: 0.8435 - val_loss: 0.4336 - val_accuracy: 0.8339\n",
      "Epoch 142/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4094 - accuracy: 0.8435 - val_loss: 0.4335 - val_accuracy: 0.8339\n",
      "Epoch 143/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4092 - accuracy: 0.8435 - val_loss: 0.4333 - val_accuracy: 0.8339\n",
      "Epoch 144/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4090 - accuracy: 0.8435 - val_loss: 0.4332 - val_accuracy: 0.8339\n",
      "Epoch 145/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4087 - accuracy: 0.8435 - val_loss: 0.4332 - val_accuracy: 0.8339\n",
      "Epoch 146/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4085 - accuracy: 0.8435 - val_loss: 0.4329 - val_accuracy: 0.8339\n",
      "Epoch 147/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4082 - accuracy: 0.8435 - val_loss: 0.4326 - val_accuracy: 0.8339\n",
      "Epoch 148/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4080 - accuracy: 0.8435 - val_loss: 0.4324 - val_accuracy: 0.8339\n",
      "Epoch 149/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4077 - accuracy: 0.8435 - val_loss: 0.4322 - val_accuracy: 0.8339\n",
      "Epoch 150/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4075 - accuracy: 0.8435 - val_loss: 0.4321 - val_accuracy: 0.8339\n",
      "Epoch 151/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4072 - accuracy: 0.8435 - val_loss: 0.4319 - val_accuracy: 0.8339\n",
      "Epoch 152/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4069 - accuracy: 0.8435 - val_loss: 0.4315 - val_accuracy: 0.8339\n",
      "Epoch 153/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4066 - accuracy: 0.8435 - val_loss: 0.4315 - val_accuracy: 0.8339\n",
      "Epoch 154/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4063 - accuracy: 0.8435 - val_loss: 0.4314 - val_accuracy: 0.8339\n",
      "Epoch 155/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4061 - accuracy: 0.8435 - val_loss: 0.4313 - val_accuracy: 0.8339\n",
      "Epoch 156/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4058 - accuracy: 0.8435 - val_loss: 0.4312 - val_accuracy: 0.8339\n",
      "Epoch 157/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4056 - accuracy: 0.8435 - val_loss: 0.4310 - val_accuracy: 0.8339\n",
      "Epoch 158/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4052 - accuracy: 0.8435 - val_loss: 0.4304 - val_accuracy: 0.8339\n",
      "Epoch 159/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.4051 - accuracy: 0.8435 - val_loss: 0.4306 - val_accuracy: 0.8339\n",
      "Epoch 160/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4047 - accuracy: 0.8435 - val_loss: 0.4304 - val_accuracy: 0.8339\n",
      "Epoch 161/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4044 - accuracy: 0.8435 - val_loss: 0.4302 - val_accuracy: 0.8339\n",
      "Epoch 162/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4042 - accuracy: 0.8435 - val_loss: 0.4300 - val_accuracy: 0.8339\n",
      "Epoch 163/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4039 - accuracy: 0.8435 - val_loss: 0.4298 - val_accuracy: 0.8339\n",
      "Epoch 164/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4036 - accuracy: 0.8435 - val_loss: 0.4296 - val_accuracy: 0.8339\n",
      "Epoch 165/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4033 - accuracy: 0.8435 - val_loss: 0.4295 - val_accuracy: 0.8339\n",
      "Epoch 166/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4030 - accuracy: 0.8435 - val_loss: 0.4293 - val_accuracy: 0.8339\n",
      "Epoch 167/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4027 - accuracy: 0.8435 - val_loss: 0.4291 - val_accuracy: 0.8339\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 33us/step - loss: 0.4025 - accuracy: 0.8435 - val_loss: 0.4288 - val_accuracy: 0.8339\n",
      "Epoch 169/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4022 - accuracy: 0.8435 - val_loss: 0.4285 - val_accuracy: 0.8339\n",
      "Epoch 170/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4019 - accuracy: 0.8435 - val_loss: 0.4283 - val_accuracy: 0.8339\n",
      "Epoch 171/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4016 - accuracy: 0.8435 - val_loss: 0.4280 - val_accuracy: 0.8339\n",
      "Epoch 172/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4014 - accuracy: 0.8435 - val_loss: 0.4279 - val_accuracy: 0.8339\n",
      "Epoch 173/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4010 - accuracy: 0.8435 - val_loss: 0.4279 - val_accuracy: 0.8339\n",
      "Epoch 174/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4008 - accuracy: 0.8437 - val_loss: 0.4278 - val_accuracy: 0.8339\n",
      "Epoch 175/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4005 - accuracy: 0.8436 - val_loss: 0.4273 - val_accuracy: 0.8343\n",
      "Epoch 176/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4002 - accuracy: 0.8437 - val_loss: 0.4271 - val_accuracy: 0.8343\n",
      "Epoch 177/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3999 - accuracy: 0.8438 - val_loss: 0.4270 - val_accuracy: 0.8343\n",
      "Epoch 178/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.3996 - accuracy: 0.8437 - val_loss: 0.4268 - val_accuracy: 0.8343\n",
      "Epoch 179/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.3993 - accuracy: 0.8437 - val_loss: 0.4265 - val_accuracy: 0.8343\n",
      "Epoch 180/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3990 - accuracy: 0.8436 - val_loss: 0.4263 - val_accuracy: 0.8343\n",
      "Epoch 181/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3987 - accuracy: 0.8437 - val_loss: 0.4260 - val_accuracy: 0.8343\n",
      "Epoch 182/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3984 - accuracy: 0.8438 - val_loss: 0.4257 - val_accuracy: 0.8343\n",
      "Epoch 183/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3980 - accuracy: 0.8437 - val_loss: 0.4254 - val_accuracy: 0.8343\n",
      "Epoch 184/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3978 - accuracy: 0.8438 - val_loss: 0.4255 - val_accuracy: 0.8343\n",
      "Epoch 185/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3975 - accuracy: 0.8436 - val_loss: 0.4250 - val_accuracy: 0.8343\n",
      "Epoch 186/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3972 - accuracy: 0.8439 - val_loss: 0.4250 - val_accuracy: 0.8343\n",
      "Epoch 187/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.3968 - accuracy: 0.8438 - val_loss: 0.4247 - val_accuracy: 0.8343\n",
      "Epoch 188/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3966 - accuracy: 0.8436 - val_loss: 0.4244 - val_accuracy: 0.8343\n",
      "Epoch 189/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3963 - accuracy: 0.8437 - val_loss: 0.4244 - val_accuracy: 0.8343\n",
      "Epoch 190/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3960 - accuracy: 0.8441 - val_loss: 0.4240 - val_accuracy: 0.8343\n",
      "Epoch 191/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3958 - accuracy: 0.8438 - val_loss: 0.4239 - val_accuracy: 0.8343\n",
      "Epoch 192/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3955 - accuracy: 0.8438 - val_loss: 0.4238 - val_accuracy: 0.8343\n",
      "Epoch 193/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3951 - accuracy: 0.8439 - val_loss: 0.4233 - val_accuracy: 0.8343\n",
      "Epoch 194/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.3948 - accuracy: 0.8440 - val_loss: 0.4235 - val_accuracy: 0.8343\n",
      "Epoch 195/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3945 - accuracy: 0.8439 - val_loss: 0.4228 - val_accuracy: 0.8346\n",
      "Epoch 196/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3942 - accuracy: 0.8439 - val_loss: 0.4228 - val_accuracy: 0.8346\n",
      "Epoch 197/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3940 - accuracy: 0.8439 - val_loss: 0.4228 - val_accuracy: 0.8346\n",
      "Epoch 198/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3938 - accuracy: 0.8440 - val_loss: 0.4223 - val_accuracy: 0.8346\n",
      "Epoch 199/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3934 - accuracy: 0.8439 - val_loss: 0.4223 - val_accuracy: 0.8343\n",
      "Epoch 200/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3933 - accuracy: 0.8438 - val_loss: 0.4219 - val_accuracy: 0.8343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:127: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Train on 640 samples, validate on 161 samples\n",
      "Epoch 1/200\n",
      "640/640 [==============================] - 0s 200us/step - loss: 0.6864 - accuracy: 0.6466 - val_loss: 0.6812 - val_accuracy: 0.7306\n",
      "Epoch 2/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.6757 - accuracy: 0.7516 - val_loss: 0.6709 - val_accuracy: 0.7656\n",
      "Epoch 3/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.6652 - accuracy: 0.7785 - val_loss: 0.6606 - val_accuracy: 0.7846\n",
      "Epoch 4/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.6545 - accuracy: 0.7901 - val_loss: 0.6500 - val_accuracy: 0.7891\n",
      "Epoch 5/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.6434 - accuracy: 0.7963 - val_loss: 0.6390 - val_accuracy: 0.7947\n",
      "Epoch 6/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.6316 - accuracy: 0.8007 - val_loss: 0.6272 - val_accuracy: 0.7957\n",
      "Epoch 7/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.6189 - accuracy: 0.8034 - val_loss: 0.6145 - val_accuracy: 0.7980\n",
      "Epoch 8/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.6051 - accuracy: 0.8067 - val_loss: 0.6006 - val_accuracy: 0.8012\n",
      "Epoch 9/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.5898 - accuracy: 0.8082 - val_loss: 0.5851 - val_accuracy: 0.8025\n",
      "Epoch 10/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.5725 - accuracy: 0.8087 - val_loss: 0.5678 - val_accuracy: 0.8032\n",
      "Epoch 11/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.5532 - accuracy: 0.8141 - val_loss: 0.5487 - val_accuracy: 0.8107\n",
      "Epoch 12/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.5321 - accuracy: 0.8238 - val_loss: 0.5283 - val_accuracy: 0.8205\n",
      "Epoch 13/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.5100 - accuracy: 0.8364 - val_loss: 0.5077 - val_accuracy: 0.8330\n",
      "Epoch 14/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4883 - accuracy: 0.8436 - val_loss: 0.4888 - val_accuracy: 0.8343\n",
      "Epoch 15/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4692 - accuracy: 0.8437 - val_loss: 0.4735 - val_accuracy: 0.8343\n",
      "Epoch 16/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4544 - accuracy: 0.8438 - val_loss: 0.4627 - val_accuracy: 0.8343\n",
      "Epoch 17/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4444 - accuracy: 0.8438 - val_loss: 0.4561 - val_accuracy: 0.8343\n",
      "Epoch 18/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4383 - accuracy: 0.8438 - val_loss: 0.4522 - val_accuracy: 0.8343\n",
      "Epoch 19/200\n",
      "640/640 [==============================] - 0s 35us/step - loss: 0.4347 - accuracy: 0.8438 - val_loss: 0.4499 - val_accuracy: 0.8343\n",
      "Epoch 20/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4324 - accuracy: 0.8438 - val_loss: 0.4483 - val_accuracy: 0.8343\n",
      "Epoch 21/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4309 - accuracy: 0.8438 - val_loss: 0.4472 - val_accuracy: 0.8343\n",
      "Epoch 22/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4297 - accuracy: 0.8438 - val_loss: 0.4462 - val_accuracy: 0.8343\n",
      "Epoch 23/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4289 - accuracy: 0.8438 - val_loss: 0.4455 - val_accuracy: 0.8343\n",
      "Epoch 24/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4282 - accuracy: 0.8438 - val_loss: 0.4449 - val_accuracy: 0.8343\n",
      "Epoch 25/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4277 - accuracy: 0.8438 - val_loss: 0.4444 - val_accuracy: 0.8343\n",
      "Epoch 26/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4272 - accuracy: 0.8438 - val_loss: 0.4440 - val_accuracy: 0.8343\n",
      "Epoch 27/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4268 - accuracy: 0.8438 - val_loss: 0.4437 - val_accuracy: 0.8343\n",
      "Epoch 28/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4265 - accuracy: 0.8438 - val_loss: 0.4434 - val_accuracy: 0.8343\n",
      "Epoch 29/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4263 - accuracy: 0.8438 - val_loss: 0.4431 - val_accuracy: 0.8343\n",
      "Epoch 30/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4261 - accuracy: 0.8438 - val_loss: 0.4429 - val_accuracy: 0.8343\n",
      "Epoch 31/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4258 - accuracy: 0.8438 - val_loss: 0.4427 - val_accuracy: 0.8343\n",
      "Epoch 32/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4256 - accuracy: 0.8438 - val_loss: 0.4425 - val_accuracy: 0.8343\n",
      "Epoch 33/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4255 - accuracy: 0.8437 - val_loss: 0.4423 - val_accuracy: 0.8343\n",
      "Epoch 34/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4254 - accuracy: 0.8438 - val_loss: 0.4422 - val_accuracy: 0.8343\n",
      "Epoch 35/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4252 - accuracy: 0.8438 - val_loss: 0.4420 - val_accuracy: 0.8343\n",
      "Epoch 36/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4251 - accuracy: 0.8438 - val_loss: 0.4419 - val_accuracy: 0.8343\n",
      "Epoch 37/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4249 - accuracy: 0.8437 - val_loss: 0.4418 - val_accuracy: 0.8343\n",
      "Epoch 38/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4248 - accuracy: 0.8438 - val_loss: 0.4417 - val_accuracy: 0.8343\n",
      "Epoch 39/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4247 - accuracy: 0.8438 - val_loss: 0.4416 - val_accuracy: 0.8343\n",
      "Epoch 40/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4246 - accuracy: 0.8438 - val_loss: 0.4415 - val_accuracy: 0.8343\n",
      "Epoch 41/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4245 - accuracy: 0.8438 - val_loss: 0.4414 - val_accuracy: 0.8343\n",
      "Epoch 42/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4244 - accuracy: 0.8438 - val_loss: 0.4413 - val_accuracy: 0.8343\n",
      "Epoch 43/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4243 - accuracy: 0.8438 - val_loss: 0.4411 - val_accuracy: 0.8343\n",
      "Epoch 44/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4242 - accuracy: 0.8438 - val_loss: 0.4410 - val_accuracy: 0.8343\n",
      "Epoch 45/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4241 - accuracy: 0.8437 - val_loss: 0.4410 - val_accuracy: 0.8343\n",
      "Epoch 46/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4240 - accuracy: 0.8438 - val_loss: 0.4409 - val_accuracy: 0.8343\n",
      "Epoch 47/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4239 - accuracy: 0.8438 - val_loss: 0.4408 - val_accuracy: 0.8343\n",
      "Epoch 48/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4238 - accuracy: 0.8437 - val_loss: 0.4407 - val_accuracy: 0.8343\n",
      "Epoch 49/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4237 - accuracy: 0.8438 - val_loss: 0.4406 - val_accuracy: 0.8343\n",
      "Epoch 50/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4236 - accuracy: 0.8438 - val_loss: 0.4405 - val_accuracy: 0.8343\n",
      "Epoch 51/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4235 - accuracy: 0.8438 - val_loss: 0.4404 - val_accuracy: 0.8343\n",
      "Epoch 52/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4234 - accuracy: 0.8438 - val_loss: 0.4404 - val_accuracy: 0.8343\n",
      "Epoch 53/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4233 - accuracy: 0.8438 - val_loss: 0.4403 - val_accuracy: 0.8343\n",
      "Epoch 54/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4233 - accuracy: 0.8438 - val_loss: 0.4402 - val_accuracy: 0.8343\n",
      "Epoch 55/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4231 - accuracy: 0.8438 - val_loss: 0.4401 - val_accuracy: 0.8343\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 33us/step - loss: 0.4230 - accuracy: 0.8438 - val_loss: 0.4401 - val_accuracy: 0.8343\n",
      "Epoch 57/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4230 - accuracy: 0.8438 - val_loss: 0.4400 - val_accuracy: 0.8343\n",
      "Epoch 58/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4229 - accuracy: 0.8438 - val_loss: 0.4399 - val_accuracy: 0.8343\n",
      "Epoch 59/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4228 - accuracy: 0.8438 - val_loss: 0.4398 - val_accuracy: 0.8343\n",
      "Epoch 60/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4227 - accuracy: 0.8438 - val_loss: 0.4398 - val_accuracy: 0.8343\n",
      "Epoch 61/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4226 - accuracy: 0.8438 - val_loss: 0.4397 - val_accuracy: 0.8343\n",
      "Epoch 62/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4225 - accuracy: 0.8438 - val_loss: 0.4396 - val_accuracy: 0.8343\n",
      "Epoch 63/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4224 - accuracy: 0.8438 - val_loss: 0.4395 - val_accuracy: 0.8343\n",
      "Epoch 64/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4223 - accuracy: 0.8438 - val_loss: 0.4394 - val_accuracy: 0.8343\n",
      "Epoch 65/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4223 - accuracy: 0.8438 - val_loss: 0.4393 - val_accuracy: 0.8343\n",
      "Epoch 66/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4222 - accuracy: 0.8437 - val_loss: 0.4393 - val_accuracy: 0.8343\n",
      "Epoch 67/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4221 - accuracy: 0.8438 - val_loss: 0.4392 - val_accuracy: 0.8343\n",
      "Epoch 68/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4220 - accuracy: 0.8438 - val_loss: 0.4391 - val_accuracy: 0.8343\n",
      "Epoch 69/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4219 - accuracy: 0.8438 - val_loss: 0.4390 - val_accuracy: 0.8343\n",
      "Epoch 70/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4218 - accuracy: 0.8438 - val_loss: 0.4389 - val_accuracy: 0.8343\n",
      "Epoch 71/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4217 - accuracy: 0.8438 - val_loss: 0.4389 - val_accuracy: 0.8343\n",
      "Epoch 72/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4216 - accuracy: 0.8438 - val_loss: 0.4388 - val_accuracy: 0.8343\n",
      "Epoch 73/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4215 - accuracy: 0.8438 - val_loss: 0.4387 - val_accuracy: 0.8343\n",
      "Epoch 74/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4214 - accuracy: 0.8438 - val_loss: 0.4386 - val_accuracy: 0.8343\n",
      "Epoch 75/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4213 - accuracy: 0.8438 - val_loss: 0.4385 - val_accuracy: 0.8343\n",
      "Epoch 76/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4212 - accuracy: 0.8438 - val_loss: 0.4384 - val_accuracy: 0.8343\n",
      "Epoch 77/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4211 - accuracy: 0.8438 - val_loss: 0.4383 - val_accuracy: 0.8343\n",
      "Epoch 78/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4210 - accuracy: 0.8438 - val_loss: 0.4383 - val_accuracy: 0.8343\n",
      "Epoch 79/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4209 - accuracy: 0.8438 - val_loss: 0.4382 - val_accuracy: 0.8343\n",
      "Epoch 80/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4208 - accuracy: 0.8438 - val_loss: 0.4381 - val_accuracy: 0.8343\n",
      "Epoch 81/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4207 - accuracy: 0.8438 - val_loss: 0.4380 - val_accuracy: 0.8343\n",
      "Epoch 82/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4206 - accuracy: 0.8438 - val_loss: 0.4379 - val_accuracy: 0.8343\n",
      "Epoch 83/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4204 - accuracy: 0.8438 - val_loss: 0.4378 - val_accuracy: 0.8343\n",
      "Epoch 84/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4203 - accuracy: 0.8438 - val_loss: 0.4377 - val_accuracy: 0.8343\n",
      "Epoch 85/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4202 - accuracy: 0.8437 - val_loss: 0.4376 - val_accuracy: 0.8343\n",
      "Epoch 86/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4201 - accuracy: 0.8438 - val_loss: 0.4375 - val_accuracy: 0.8343\n",
      "Epoch 87/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.8438 - val_loss: 0.4374 - val_accuracy: 0.8343\n",
      "Epoch 88/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4198 - accuracy: 0.8438 - val_loss: 0.4373 - val_accuracy: 0.8343\n",
      "Epoch 89/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4197 - accuracy: 0.8438 - val_loss: 0.4372 - val_accuracy: 0.8343\n",
      "Epoch 90/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4195 - accuracy: 0.8438 - val_loss: 0.4371 - val_accuracy: 0.8343\n",
      "Epoch 91/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4194 - accuracy: 0.8438 - val_loss: 0.4369 - val_accuracy: 0.8343\n",
      "Epoch 92/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4193 - accuracy: 0.8438 - val_loss: 0.4368 - val_accuracy: 0.8343\n",
      "Epoch 93/200\n",
      "640/640 [==============================] - 0s 45us/step - loss: 0.4191 - accuracy: 0.8438 - val_loss: 0.4367 - val_accuracy: 0.8343\n",
      "Epoch 94/200\n",
      "640/640 [==============================] - 0s 41us/step - loss: 0.4190 - accuracy: 0.8438 - val_loss: 0.4366 - val_accuracy: 0.8343\n",
      "Epoch 95/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4188 - accuracy: 0.8438 - val_loss: 0.4364 - val_accuracy: 0.8343\n",
      "Epoch 96/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4187 - accuracy: 0.8438 - val_loss: 0.4364 - val_accuracy: 0.8343\n",
      "Epoch 97/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4185 - accuracy: 0.8437 - val_loss: 0.4362 - val_accuracy: 0.8343\n",
      "Epoch 98/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4184 - accuracy: 0.8438 - val_loss: 0.4361 - val_accuracy: 0.8343\n",
      "Epoch 99/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4182 - accuracy: 0.8438 - val_loss: 0.4360 - val_accuracy: 0.8343\n",
      "Epoch 100/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4180 - accuracy: 0.8438 - val_loss: 0.4359 - val_accuracy: 0.8343\n",
      "Epoch 101/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4179 - accuracy: 0.8438 - val_loss: 0.4358 - val_accuracy: 0.8343\n",
      "Epoch 102/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4177 - accuracy: 0.8438 - val_loss: 0.4356 - val_accuracy: 0.8343\n",
      "Epoch 103/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4175 - accuracy: 0.8438 - val_loss: 0.4355 - val_accuracy: 0.8343\n",
      "Epoch 104/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4174 - accuracy: 0.8438 - val_loss: 0.4353 - val_accuracy: 0.8343\n",
      "Epoch 105/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4171 - accuracy: 0.8438 - val_loss: 0.4352 - val_accuracy: 0.8343\n",
      "Epoch 106/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4170 - accuracy: 0.8438 - val_loss: 0.4351 - val_accuracy: 0.8343\n",
      "Epoch 107/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4168 - accuracy: 0.8438 - val_loss: 0.4349 - val_accuracy: 0.8343\n",
      "Epoch 108/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4166 - accuracy: 0.8438 - val_loss: 0.4348 - val_accuracy: 0.8343\n",
      "Epoch 109/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4164 - accuracy: 0.8438 - val_loss: 0.4347 - val_accuracy: 0.8343\n",
      "Epoch 110/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4163 - accuracy: 0.8438 - val_loss: 0.4345 - val_accuracy: 0.8343\n",
      "Epoch 111/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4160 - accuracy: 0.8438 - val_loss: 0.4344 - val_accuracy: 0.8343\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 34us/step - loss: 0.4159 - accuracy: 0.8438 - val_loss: 0.4342 - val_accuracy: 0.8343\n",
      "Epoch 113/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4157 - accuracy: 0.8438 - val_loss: 0.4341 - val_accuracy: 0.8343\n",
      "Epoch 114/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4155 - accuracy: 0.8438 - val_loss: 0.4339 - val_accuracy: 0.8343\n",
      "Epoch 115/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4153 - accuracy: 0.8438 - val_loss: 0.4338 - val_accuracy: 0.8343\n",
      "Epoch 116/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4151 - accuracy: 0.8438 - val_loss: 0.4336 - val_accuracy: 0.8343\n",
      "Epoch 117/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4149 - accuracy: 0.8437 - val_loss: 0.4334 - val_accuracy: 0.8343\n",
      "Epoch 118/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4147 - accuracy: 0.8438 - val_loss: 0.4333 - val_accuracy: 0.8343\n",
      "Epoch 119/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4145 - accuracy: 0.8438 - val_loss: 0.4331 - val_accuracy: 0.8343\n",
      "Epoch 120/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4143 - accuracy: 0.8437 - val_loss: 0.4329 - val_accuracy: 0.8343\n",
      "Epoch 121/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4140 - accuracy: 0.8438 - val_loss: 0.4328 - val_accuracy: 0.8343\n",
      "Epoch 122/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4138 - accuracy: 0.8438 - val_loss: 0.4326 - val_accuracy: 0.8343\n",
      "Epoch 123/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4136 - accuracy: 0.8438 - val_loss: 0.4324 - val_accuracy: 0.8343\n",
      "Epoch 124/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4134 - accuracy: 0.8438 - val_loss: 0.4323 - val_accuracy: 0.8349\n",
      "Epoch 125/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4132 - accuracy: 0.8438 - val_loss: 0.4322 - val_accuracy: 0.8349\n",
      "Epoch 126/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4130 - accuracy: 0.8440 - val_loss: 0.4320 - val_accuracy: 0.8349\n",
      "Epoch 127/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4128 - accuracy: 0.8439 - val_loss: 0.4318 - val_accuracy: 0.8349\n",
      "Epoch 128/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4126 - accuracy: 0.8438 - val_loss: 0.4316 - val_accuracy: 0.8352\n",
      "Epoch 129/200\n",
      "640/640 [==============================] - 0s 39us/step - loss: 0.4124 - accuracy: 0.8439 - val_loss: 0.4315 - val_accuracy: 0.8352\n",
      "Epoch 130/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4122 - accuracy: 0.8439 - val_loss: 0.4313 - val_accuracy: 0.8352\n",
      "Epoch 131/200\n",
      "640/640 [==============================] - 0s 41us/step - loss: 0.4120 - accuracy: 0.8439 - val_loss: 0.4311 - val_accuracy: 0.8352\n",
      "Epoch 132/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4118 - accuracy: 0.8439 - val_loss: 0.4310 - val_accuracy: 0.8352\n",
      "Epoch 133/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4115 - accuracy: 0.8439 - val_loss: 0.4308 - val_accuracy: 0.8352\n",
      "Epoch 134/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4114 - accuracy: 0.8439 - val_loss: 0.4306 - val_accuracy: 0.8352\n",
      "Epoch 135/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4111 - accuracy: 0.8439 - val_loss: 0.4305 - val_accuracy: 0.8356\n",
      "Epoch 136/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4110 - accuracy: 0.8441 - val_loss: 0.4303 - val_accuracy: 0.8356\n",
      "Epoch 137/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4107 - accuracy: 0.8444 - val_loss: 0.4301 - val_accuracy: 0.8356\n",
      "Epoch 138/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4105 - accuracy: 0.8441 - val_loss: 0.4300 - val_accuracy: 0.8359\n",
      "Epoch 139/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4104 - accuracy: 0.8447 - val_loss: 0.4298 - val_accuracy: 0.8359\n",
      "Epoch 140/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4101 - accuracy: 0.8447 - val_loss: 0.4296 - val_accuracy: 0.8359\n",
      "Epoch 141/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4100 - accuracy: 0.8447 - val_loss: 0.4295 - val_accuracy: 0.8359\n",
      "Epoch 142/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4098 - accuracy: 0.8447 - val_loss: 0.4293 - val_accuracy: 0.8359\n",
      "Epoch 143/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4096 - accuracy: 0.8447 - val_loss: 0.4291 - val_accuracy: 0.8359\n",
      "Epoch 144/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4094 - accuracy: 0.8447 - val_loss: 0.4290 - val_accuracy: 0.8359\n",
      "Epoch 145/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4092 - accuracy: 0.8447 - val_loss: 0.4289 - val_accuracy: 0.8359\n",
      "Epoch 146/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4091 - accuracy: 0.8447 - val_loss: 0.4288 - val_accuracy: 0.8359\n",
      "Epoch 147/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4089 - accuracy: 0.8448 - val_loss: 0.4286 - val_accuracy: 0.8359\n",
      "Epoch 148/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4087 - accuracy: 0.8447 - val_loss: 0.4284 - val_accuracy: 0.8359\n",
      "Epoch 149/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4085 - accuracy: 0.8447 - val_loss: 0.4283 - val_accuracy: 0.8359\n",
      "Epoch 150/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4084 - accuracy: 0.8447 - val_loss: 0.4281 - val_accuracy: 0.8359\n",
      "Epoch 151/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4082 - accuracy: 0.8449 - val_loss: 0.4281 - val_accuracy: 0.8359\n",
      "Epoch 152/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4080 - accuracy: 0.8447 - val_loss: 0.4279 - val_accuracy: 0.8359\n",
      "Epoch 153/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4079 - accuracy: 0.8447 - val_loss: 0.4277 - val_accuracy: 0.8359\n",
      "Epoch 154/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4077 - accuracy: 0.8447 - val_loss: 0.4277 - val_accuracy: 0.8346\n",
      "Epoch 155/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4075 - accuracy: 0.8447 - val_loss: 0.4276 - val_accuracy: 0.8346\n",
      "Epoch 156/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4074 - accuracy: 0.8446 - val_loss: 0.4274 - val_accuracy: 0.8346\n",
      "Epoch 157/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4072 - accuracy: 0.8447 - val_loss: 0.4273 - val_accuracy: 0.8346\n",
      "Epoch 158/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4071 - accuracy: 0.8448 - val_loss: 0.4271 - val_accuracy: 0.8346\n",
      "Epoch 159/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4069 - accuracy: 0.8449 - val_loss: 0.4270 - val_accuracy: 0.8346\n",
      "Epoch 160/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4068 - accuracy: 0.8450 - val_loss: 0.4269 - val_accuracy: 0.8346\n",
      "Epoch 161/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4066 - accuracy: 0.8446 - val_loss: 0.4268 - val_accuracy: 0.8346\n",
      "Epoch 162/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4065 - accuracy: 0.8449 - val_loss: 0.4267 - val_accuracy: 0.8339\n",
      "Epoch 163/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4063 - accuracy: 0.8448 - val_loss: 0.4264 - val_accuracy: 0.8339\n",
      "Epoch 164/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4061 - accuracy: 0.8447 - val_loss: 0.4263 - val_accuracy: 0.8343\n",
      "Epoch 165/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4060 - accuracy: 0.8447 - val_loss: 0.4262 - val_accuracy: 0.8343\n",
      "Epoch 166/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4058 - accuracy: 0.8447 - val_loss: 0.4260 - val_accuracy: 0.8343\n",
      "Epoch 167/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4057 - accuracy: 0.8445 - val_loss: 0.4260 - val_accuracy: 0.8346\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 34us/step - loss: 0.4056 - accuracy: 0.8448 - val_loss: 0.4259 - val_accuracy: 0.8346\n",
      "Epoch 169/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4054 - accuracy: 0.8449 - val_loss: 0.4257 - val_accuracy: 0.8343\n",
      "Epoch 170/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4052 - accuracy: 0.8447 - val_loss: 0.4256 - val_accuracy: 0.8343\n",
      "Epoch 171/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4051 - accuracy: 0.8447 - val_loss: 0.4255 - val_accuracy: 0.8346\n",
      "Epoch 172/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4049 - accuracy: 0.8448 - val_loss: 0.4253 - val_accuracy: 0.8346\n",
      "Epoch 173/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4048 - accuracy: 0.8449 - val_loss: 0.4252 - val_accuracy: 0.8343\n",
      "Epoch 174/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4046 - accuracy: 0.8450 - val_loss: 0.4251 - val_accuracy: 0.8343\n",
      "Epoch 175/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4045 - accuracy: 0.8449 - val_loss: 0.4249 - val_accuracy: 0.8339\n",
      "Epoch 176/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4043 - accuracy: 0.8451 - val_loss: 0.4248 - val_accuracy: 0.8339\n",
      "Epoch 177/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4041 - accuracy: 0.8448 - val_loss: 0.4247 - val_accuracy: 0.8343\n",
      "Epoch 178/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4040 - accuracy: 0.8451 - val_loss: 0.4246 - val_accuracy: 0.8343\n",
      "Epoch 179/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4038 - accuracy: 0.8450 - val_loss: 0.4244 - val_accuracy: 0.8343\n",
      "Epoch 180/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4037 - accuracy: 0.8451 - val_loss: 0.4243 - val_accuracy: 0.8343\n",
      "Epoch 181/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4035 - accuracy: 0.8451 - val_loss: 0.4241 - val_accuracy: 0.8339\n",
      "Epoch 182/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4034 - accuracy: 0.8450 - val_loss: 0.4240 - val_accuracy: 0.8343\n",
      "Epoch 183/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4032 - accuracy: 0.8453 - val_loss: 0.4239 - val_accuracy: 0.8339\n",
      "Epoch 184/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4030 - accuracy: 0.8451 - val_loss: 0.4237 - val_accuracy: 0.8343\n",
      "Epoch 185/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4029 - accuracy: 0.8450 - val_loss: 0.4236 - val_accuracy: 0.8339\n",
      "Epoch 186/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4027 - accuracy: 0.8449 - val_loss: 0.4235 - val_accuracy: 0.8339\n",
      "Epoch 187/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4025 - accuracy: 0.8452 - val_loss: 0.4233 - val_accuracy: 0.8339\n",
      "Epoch 188/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4024 - accuracy: 0.8451 - val_loss: 0.4232 - val_accuracy: 0.8339\n",
      "Epoch 189/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4022 - accuracy: 0.8449 - val_loss: 0.4230 - val_accuracy: 0.8339\n",
      "Epoch 190/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4020 - accuracy: 0.8451 - val_loss: 0.4229 - val_accuracy: 0.8339\n",
      "Epoch 191/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4018 - accuracy: 0.8450 - val_loss: 0.4227 - val_accuracy: 0.8336\n",
      "Epoch 192/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4017 - accuracy: 0.8448 - val_loss: 0.4227 - val_accuracy: 0.8336\n",
      "Epoch 193/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4015 - accuracy: 0.8451 - val_loss: 0.4225 - val_accuracy: 0.8336\n",
      "Epoch 194/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4013 - accuracy: 0.8447 - val_loss: 0.4223 - val_accuracy: 0.8336\n",
      "Epoch 195/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4011 - accuracy: 0.8453 - val_loss: 0.4222 - val_accuracy: 0.8336\n",
      "Epoch 196/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4009 - accuracy: 0.8451 - val_loss: 0.4220 - val_accuracy: 0.8336\n",
      "Epoch 197/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4007 - accuracy: 0.8450 - val_loss: 0.4219 - val_accuracy: 0.8336\n",
      "Epoch 198/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4006 - accuracy: 0.8448 - val_loss: 0.4217 - val_accuracy: 0.8336\n",
      "Epoch 199/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4003 - accuracy: 0.8451 - val_loss: 0.4216 - val_accuracy: 0.8336\n",
      "Epoch 200/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4002 - accuracy: 0.8448 - val_loss: 0.4214 - val_accuracy: 0.8336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:127: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Train on 640 samples, validate on 161 samples\n",
      "Epoch 1/200\n",
      "640/640 [==============================] - 0s 231us/step - loss: 0.6852 - accuracy: 0.6414 - val_loss: 0.6778 - val_accuracy: 0.7306\n",
      "Epoch 2/200\n",
      "640/640 [==============================] - 0s 42us/step - loss: 0.6703 - accuracy: 0.7755 - val_loss: 0.6631 - val_accuracy: 0.8130\n",
      "Epoch 3/200\n",
      "640/640 [==============================] - 0s 39us/step - loss: 0.6544 - accuracy: 0.8310 - val_loss: 0.6467 - val_accuracy: 0.8316\n",
      "Epoch 4/200\n",
      "640/640 [==============================] - 0s 39us/step - loss: 0.6361 - accuracy: 0.8446 - val_loss: 0.6272 - val_accuracy: 0.8330\n",
      "Epoch 5/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.6135 - accuracy: 0.8450 - val_loss: 0.6026 - val_accuracy: 0.8330\n",
      "Epoch 6/200\n",
      "640/640 [==============================] - 0s 39us/step - loss: 0.5843 - accuracy: 0.8451 - val_loss: 0.5704 - val_accuracy: 0.8330\n",
      "Epoch 7/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.5461 - accuracy: 0.8451 - val_loss: 0.5303 - val_accuracy: 0.8330\n",
      "Epoch 8/200\n",
      "640/640 [==============================] - 0s 41us/step - loss: 0.5016 - accuracy: 0.8451 - val_loss: 0.4908 - val_accuracy: 0.8330\n",
      "Epoch 9/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4639 - accuracy: 0.8451 - val_loss: 0.4668 - val_accuracy: 0.8330\n",
      "Epoch 10/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4437 - accuracy: 0.8451 - val_loss: 0.4583 - val_accuracy: 0.8330\n",
      "Epoch 11/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4357 - accuracy: 0.8451 - val_loss: 0.4555 - val_accuracy: 0.8330\n",
      "Epoch 12/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4325 - accuracy: 0.8451 - val_loss: 0.4539 - val_accuracy: 0.8330\n",
      "Epoch 13/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4305 - accuracy: 0.8451 - val_loss: 0.4526 - val_accuracy: 0.8330\n",
      "Epoch 14/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4293 - accuracy: 0.8451 - val_loss: 0.4516 - val_accuracy: 0.8330\n",
      "Epoch 15/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4284 - accuracy: 0.8451 - val_loss: 0.4509 - val_accuracy: 0.8330\n",
      "Epoch 16/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4277 - accuracy: 0.8451 - val_loss: 0.4502 - val_accuracy: 0.8330\n",
      "Epoch 17/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4271 - accuracy: 0.8451 - val_loss: 0.4496 - val_accuracy: 0.8330\n",
      "Epoch 18/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4267 - accuracy: 0.8451 - val_loss: 0.4491 - val_accuracy: 0.8330\n",
      "Epoch 19/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4263 - accuracy: 0.8451 - val_loss: 0.4487 - val_accuracy: 0.8330\n",
      "Epoch 20/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4259 - accuracy: 0.8451 - val_loss: 0.4484 - val_accuracy: 0.8330\n",
      "Epoch 21/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4256 - accuracy: 0.8451 - val_loss: 0.4481 - val_accuracy: 0.8330\n",
      "Epoch 22/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4254 - accuracy: 0.8451 - val_loss: 0.4478 - val_accuracy: 0.8330\n",
      "Epoch 23/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4252 - accuracy: 0.8451 - val_loss: 0.4476 - val_accuracy: 0.8330\n",
      "Epoch 24/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4249 - accuracy: 0.8451 - val_loss: 0.4472 - val_accuracy: 0.8330\n",
      "Epoch 25/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4247 - accuracy: 0.8451 - val_loss: 0.4471 - val_accuracy: 0.8330\n",
      "Epoch 26/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4245 - accuracy: 0.8451 - val_loss: 0.4468 - val_accuracy: 0.8330\n",
      "Epoch 27/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4243 - accuracy: 0.8451 - val_loss: 0.4466 - val_accuracy: 0.8330\n",
      "Epoch 28/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4241 - accuracy: 0.8451 - val_loss: 0.4464 - val_accuracy: 0.8330\n",
      "Epoch 29/200\n",
      "640/640 [==============================] - 0s 31us/step - loss: 0.4239 - accuracy: 0.8451 - val_loss: 0.4462 - val_accuracy: 0.8330\n",
      "Epoch 30/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4238 - accuracy: 0.8451 - val_loss: 0.4462 - val_accuracy: 0.8330\n",
      "Epoch 31/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4236 - accuracy: 0.8451 - val_loss: 0.4460 - val_accuracy: 0.8330\n",
      "Epoch 32/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4235 - accuracy: 0.8451 - val_loss: 0.4459 - val_accuracy: 0.8330\n",
      "Epoch 33/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4234 - accuracy: 0.8451 - val_loss: 0.4457 - val_accuracy: 0.8330\n",
      "Epoch 34/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4233 - accuracy: 0.8451 - val_loss: 0.4456 - val_accuracy: 0.8330\n",
      "Epoch 35/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4231 - accuracy: 0.8451 - val_loss: 0.4454 - val_accuracy: 0.8330\n",
      "Epoch 36/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4230 - accuracy: 0.8451 - val_loss: 0.4453 - val_accuracy: 0.8330\n",
      "Epoch 37/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4229 - accuracy: 0.8451 - val_loss: 0.4452 - val_accuracy: 0.8330\n",
      "Epoch 38/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4227 - accuracy: 0.8451 - val_loss: 0.4450 - val_accuracy: 0.8330\n",
      "Epoch 39/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4227 - accuracy: 0.8451 - val_loss: 0.4449 - val_accuracy: 0.8330\n",
      "Epoch 40/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4226 - accuracy: 0.8451 - val_loss: 0.4448 - val_accuracy: 0.8330\n",
      "Epoch 41/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4224 - accuracy: 0.8451 - val_loss: 0.4446 - val_accuracy: 0.8330\n",
      "Epoch 42/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4223 - accuracy: 0.8451 - val_loss: 0.4445 - val_accuracy: 0.8330\n",
      "Epoch 43/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4222 - accuracy: 0.8451 - val_loss: 0.4444 - val_accuracy: 0.8330\n",
      "Epoch 44/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4222 - accuracy: 0.8451 - val_loss: 0.4444 - val_accuracy: 0.8330\n",
      "Epoch 45/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4220 - accuracy: 0.8451 - val_loss: 0.4443 - val_accuracy: 0.8330\n",
      "Epoch 46/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4220 - accuracy: 0.8451 - val_loss: 0.4441 - val_accuracy: 0.8330\n",
      "Epoch 47/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4219 - accuracy: 0.8451 - val_loss: 0.4440 - val_accuracy: 0.8330\n",
      "Epoch 48/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4218 - accuracy: 0.8451 - val_loss: 0.4441 - val_accuracy: 0.8330\n",
      "Epoch 49/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4217 - accuracy: 0.8451 - val_loss: 0.4439 - val_accuracy: 0.8330\n",
      "Epoch 50/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4216 - accuracy: 0.8451 - val_loss: 0.4439 - val_accuracy: 0.8330\n",
      "Epoch 51/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4215 - accuracy: 0.8451 - val_loss: 0.4436 - val_accuracy: 0.8330\n",
      "Epoch 52/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4214 - accuracy: 0.8451 - val_loss: 0.4436 - val_accuracy: 0.8330\n",
      "Epoch 53/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4214 - accuracy: 0.8451 - val_loss: 0.4435 - val_accuracy: 0.8330\n",
      "Epoch 54/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4213 - accuracy: 0.8451 - val_loss: 0.4435 - val_accuracy: 0.8330\n",
      "Epoch 55/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4213 - accuracy: 0.8451 - val_loss: 0.4434 - val_accuracy: 0.8330\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 34us/step - loss: 0.4211 - accuracy: 0.8451 - val_loss: 0.4433 - val_accuracy: 0.8330\n",
      "Epoch 57/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4211 - accuracy: 0.8451 - val_loss: 0.4432 - val_accuracy: 0.8330\n",
      "Epoch 58/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4210 - accuracy: 0.8451 - val_loss: 0.4432 - val_accuracy: 0.8330\n",
      "Epoch 59/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4209 - accuracy: 0.8451 - val_loss: 0.4431 - val_accuracy: 0.8330\n",
      "Epoch 60/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4208 - accuracy: 0.8451 - val_loss: 0.4430 - val_accuracy: 0.8330\n",
      "Epoch 61/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4208 - accuracy: 0.8451 - val_loss: 0.4429 - val_accuracy: 0.8330\n",
      "Epoch 62/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4207 - accuracy: 0.8451 - val_loss: 0.4428 - val_accuracy: 0.8330\n",
      "Epoch 63/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4206 - accuracy: 0.8451 - val_loss: 0.4427 - val_accuracy: 0.8330\n",
      "Epoch 64/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4206 - accuracy: 0.8451 - val_loss: 0.4426 - val_accuracy: 0.8330\n",
      "Epoch 65/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4205 - accuracy: 0.8451 - val_loss: 0.4425 - val_accuracy: 0.8330\n",
      "Epoch 66/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4204 - accuracy: 0.8451 - val_loss: 0.4424 - val_accuracy: 0.8330\n",
      "Epoch 67/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4203 - accuracy: 0.8451 - val_loss: 0.4423 - val_accuracy: 0.8330\n",
      "Epoch 68/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4203 - accuracy: 0.8451 - val_loss: 0.4422 - val_accuracy: 0.8330\n",
      "Epoch 69/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4202 - accuracy: 0.8451 - val_loss: 0.4421 - val_accuracy: 0.8330\n",
      "Epoch 70/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4201 - accuracy: 0.8451 - val_loss: 0.4422 - val_accuracy: 0.8330\n",
      "Epoch 71/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.8451 - val_loss: 0.4420 - val_accuracy: 0.8330\n",
      "Epoch 72/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4200 - accuracy: 0.8451 - val_loss: 0.4419 - val_accuracy: 0.8330\n",
      "Epoch 73/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.8451 - val_loss: 0.4417 - val_accuracy: 0.8330\n",
      "Epoch 74/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4198 - accuracy: 0.8451 - val_loss: 0.4418 - val_accuracy: 0.8330\n",
      "Epoch 75/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4197 - accuracy: 0.8451 - val_loss: 0.4417 - val_accuracy: 0.8330\n",
      "Epoch 76/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4197 - accuracy: 0.8451 - val_loss: 0.4416 - val_accuracy: 0.8330\n",
      "Epoch 77/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4195 - accuracy: 0.8451 - val_loss: 0.4414 - val_accuracy: 0.8330\n",
      "Epoch 78/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4195 - accuracy: 0.8451 - val_loss: 0.4413 - val_accuracy: 0.8330\n",
      "Epoch 79/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4194 - accuracy: 0.8451 - val_loss: 0.4412 - val_accuracy: 0.8330\n",
      "Epoch 80/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4192 - accuracy: 0.8451 - val_loss: 0.4411 - val_accuracy: 0.8330\n",
      "Epoch 81/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4192 - accuracy: 0.8451 - val_loss: 0.4411 - val_accuracy: 0.8330\n",
      "Epoch 82/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4191 - accuracy: 0.8451 - val_loss: 0.4409 - val_accuracy: 0.8330\n",
      "Epoch 83/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4190 - accuracy: 0.8451 - val_loss: 0.4408 - val_accuracy: 0.8330\n",
      "Epoch 84/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4189 - accuracy: 0.8451 - val_loss: 0.4408 - val_accuracy: 0.8330\n",
      "Epoch 85/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4189 - accuracy: 0.8451 - val_loss: 0.4406 - val_accuracy: 0.8330\n",
      "Epoch 86/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4188 - accuracy: 0.8451 - val_loss: 0.4406 - val_accuracy: 0.8330\n",
      "Epoch 87/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4187 - accuracy: 0.8451 - val_loss: 0.4405 - val_accuracy: 0.8330\n",
      "Epoch 88/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4186 - accuracy: 0.8451 - val_loss: 0.4404 - val_accuracy: 0.8330\n",
      "Epoch 89/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4185 - accuracy: 0.8451 - val_loss: 0.4403 - val_accuracy: 0.8330\n",
      "Epoch 90/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4184 - accuracy: 0.8451 - val_loss: 0.4403 - val_accuracy: 0.8330\n",
      "Epoch 91/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4183 - accuracy: 0.8451 - val_loss: 0.4400 - val_accuracy: 0.8330\n",
      "Epoch 92/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4182 - accuracy: 0.8451 - val_loss: 0.4399 - val_accuracy: 0.8330\n",
      "Epoch 93/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4181 - accuracy: 0.8451 - val_loss: 0.4399 - val_accuracy: 0.8330\n",
      "Epoch 94/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4180 - accuracy: 0.8451 - val_loss: 0.4398 - val_accuracy: 0.8330\n",
      "Epoch 95/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4179 - accuracy: 0.8451 - val_loss: 0.4396 - val_accuracy: 0.8330\n",
      "Epoch 96/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4178 - accuracy: 0.8451 - val_loss: 0.4395 - val_accuracy: 0.8330\n",
      "Epoch 97/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4177 - accuracy: 0.8451 - val_loss: 0.4394 - val_accuracy: 0.8330\n",
      "Epoch 98/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4175 - accuracy: 0.8451 - val_loss: 0.4393 - val_accuracy: 0.8330\n",
      "Epoch 99/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4174 - accuracy: 0.8451 - val_loss: 0.4392 - val_accuracy: 0.8330\n",
      "Epoch 100/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4173 - accuracy: 0.8451 - val_loss: 0.4390 - val_accuracy: 0.8330\n",
      "Epoch 101/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4172 - accuracy: 0.8451 - val_loss: 0.4389 - val_accuracy: 0.8330\n",
      "Epoch 102/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4171 - accuracy: 0.8451 - val_loss: 0.4387 - val_accuracy: 0.8330\n",
      "Epoch 103/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4169 - accuracy: 0.8451 - val_loss: 0.4386 - val_accuracy: 0.8330\n",
      "Epoch 104/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4168 - accuracy: 0.8451 - val_loss: 0.4385 - val_accuracy: 0.8330\n",
      "Epoch 105/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4167 - accuracy: 0.8451 - val_loss: 0.4383 - val_accuracy: 0.8330\n",
      "Epoch 106/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4165 - accuracy: 0.8451 - val_loss: 0.4382 - val_accuracy: 0.8330\n",
      "Epoch 107/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4163 - accuracy: 0.8451 - val_loss: 0.4380 - val_accuracy: 0.8330\n",
      "Epoch 108/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4163 - accuracy: 0.8451 - val_loss: 0.4380 - val_accuracy: 0.8330\n",
      "Epoch 109/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4161 - accuracy: 0.8451 - val_loss: 0.4377 - val_accuracy: 0.8330\n",
      "Epoch 110/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4159 - accuracy: 0.8451 - val_loss: 0.4376 - val_accuracy: 0.8330\n",
      "Epoch 111/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4158 - accuracy: 0.8451 - val_loss: 0.4374 - val_accuracy: 0.8330\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 36us/step - loss: 0.4157 - accuracy: 0.8451 - val_loss: 0.4373 - val_accuracy: 0.8330\n",
      "Epoch 113/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4155 - accuracy: 0.8451 - val_loss: 0.4371 - val_accuracy: 0.8330\n",
      "Epoch 114/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4154 - accuracy: 0.8451 - val_loss: 0.4369 - val_accuracy: 0.8330\n",
      "Epoch 115/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4152 - accuracy: 0.8451 - val_loss: 0.4367 - val_accuracy: 0.8330\n",
      "Epoch 116/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4150 - accuracy: 0.8451 - val_loss: 0.4366 - val_accuracy: 0.8330\n",
      "Epoch 117/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4148 - accuracy: 0.8451 - val_loss: 0.4364 - val_accuracy: 0.8330\n",
      "Epoch 118/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4147 - accuracy: 0.8451 - val_loss: 0.4363 - val_accuracy: 0.8330\n",
      "Epoch 119/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4145 - accuracy: 0.8451 - val_loss: 0.4361 - val_accuracy: 0.8330\n",
      "Epoch 120/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4142 - accuracy: 0.8451 - val_loss: 0.4358 - val_accuracy: 0.8330\n",
      "Epoch 121/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4140 - accuracy: 0.8451 - val_loss: 0.4356 - val_accuracy: 0.8330\n",
      "Epoch 122/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4138 - accuracy: 0.8451 - val_loss: 0.4354 - val_accuracy: 0.8330\n",
      "Epoch 123/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4135 - accuracy: 0.8451 - val_loss: 0.4351 - val_accuracy: 0.8330\n",
      "Epoch 124/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4133 - accuracy: 0.8451 - val_loss: 0.4349 - val_accuracy: 0.8330\n",
      "Epoch 125/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4131 - accuracy: 0.8451 - val_loss: 0.4346 - val_accuracy: 0.8330\n",
      "Epoch 126/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4128 - accuracy: 0.8451 - val_loss: 0.4345 - val_accuracy: 0.8330\n",
      "Epoch 127/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4126 - accuracy: 0.8451 - val_loss: 0.4342 - val_accuracy: 0.8330\n",
      "Epoch 128/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4124 - accuracy: 0.8451 - val_loss: 0.4340 - val_accuracy: 0.8330\n",
      "Epoch 129/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4121 - accuracy: 0.8451 - val_loss: 0.4338 - val_accuracy: 0.8330\n",
      "Epoch 130/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4119 - accuracy: 0.8451 - val_loss: 0.4335 - val_accuracy: 0.8330\n",
      "Epoch 131/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4117 - accuracy: 0.8451 - val_loss: 0.4333 - val_accuracy: 0.8330\n",
      "Epoch 132/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4114 - accuracy: 0.8451 - val_loss: 0.4331 - val_accuracy: 0.8330\n",
      "Epoch 133/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4111 - accuracy: 0.8451 - val_loss: 0.4328 - val_accuracy: 0.8330\n",
      "Epoch 134/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4109 - accuracy: 0.8451 - val_loss: 0.4326 - val_accuracy: 0.8330\n",
      "Epoch 135/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4107 - accuracy: 0.8451 - val_loss: 0.4325 - val_accuracy: 0.8330\n",
      "Epoch 136/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4104 - accuracy: 0.8451 - val_loss: 0.4322 - val_accuracy: 0.8330\n",
      "Epoch 137/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4102 - accuracy: 0.8451 - val_loss: 0.4319 - val_accuracy: 0.8330\n",
      "Epoch 138/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4100 - accuracy: 0.8451 - val_loss: 0.4317 - val_accuracy: 0.8330\n",
      "Epoch 139/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4097 - accuracy: 0.8451 - val_loss: 0.4316 - val_accuracy: 0.8330\n",
      "Epoch 140/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4094 - accuracy: 0.8451 - val_loss: 0.4312 - val_accuracy: 0.8330\n",
      "Epoch 141/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4092 - accuracy: 0.8451 - val_loss: 0.4309 - val_accuracy: 0.8330\n",
      "Epoch 142/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4089 - accuracy: 0.8451 - val_loss: 0.4306 - val_accuracy: 0.8330\n",
      "Epoch 143/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4086 - accuracy: 0.8451 - val_loss: 0.4304 - val_accuracy: 0.8330\n",
      "Epoch 144/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4084 - accuracy: 0.8451 - val_loss: 0.4301 - val_accuracy: 0.8330\n",
      "Epoch 145/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4082 - accuracy: 0.8451 - val_loss: 0.4299 - val_accuracy: 0.8330\n",
      "Epoch 146/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4078 - accuracy: 0.8451 - val_loss: 0.4297 - val_accuracy: 0.8330\n",
      "Epoch 147/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4076 - accuracy: 0.8451 - val_loss: 0.4294 - val_accuracy: 0.8330\n",
      "Epoch 148/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4074 - accuracy: 0.8451 - val_loss: 0.4292 - val_accuracy: 0.8330\n",
      "Epoch 149/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4072 - accuracy: 0.8451 - val_loss: 0.4291 - val_accuracy: 0.8330\n",
      "Epoch 150/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4069 - accuracy: 0.8451 - val_loss: 0.4289 - val_accuracy: 0.8330\n",
      "Epoch 151/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4066 - accuracy: 0.8451 - val_loss: 0.4286 - val_accuracy: 0.8330\n",
      "Epoch 152/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4063 - accuracy: 0.8451 - val_loss: 0.4284 - val_accuracy: 0.8330\n",
      "Epoch 153/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4061 - accuracy: 0.8451 - val_loss: 0.4281 - val_accuracy: 0.8330\n",
      "Epoch 154/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4059 - accuracy: 0.8451 - val_loss: 0.4278 - val_accuracy: 0.8330\n",
      "Epoch 155/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4056 - accuracy: 0.8451 - val_loss: 0.4277 - val_accuracy: 0.8330\n",
      "Epoch 156/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4055 - accuracy: 0.8451 - val_loss: 0.4275 - val_accuracy: 0.8330\n",
      "Epoch 157/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4052 - accuracy: 0.8451 - val_loss: 0.4272 - val_accuracy: 0.8330\n",
      "Epoch 158/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4049 - accuracy: 0.8451 - val_loss: 0.4270 - val_accuracy: 0.8330\n",
      "Epoch 159/200\n",
      "640/640 [==============================] - 0s 39us/step - loss: 0.4047 - accuracy: 0.8451 - val_loss: 0.4268 - val_accuracy: 0.8330\n",
      "Epoch 160/200\n",
      "640/640 [==============================] - 0s 39us/step - loss: 0.4045 - accuracy: 0.8451 - val_loss: 0.4266 - val_accuracy: 0.8330\n",
      "Epoch 161/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4043 - accuracy: 0.8451 - val_loss: 0.4264 - val_accuracy: 0.8330\n",
      "Epoch 162/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4041 - accuracy: 0.8451 - val_loss: 0.4262 - val_accuracy: 0.8330\n",
      "Epoch 163/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4039 - accuracy: 0.8451 - val_loss: 0.4261 - val_accuracy: 0.8330\n",
      "Epoch 164/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4036 - accuracy: 0.8451 - val_loss: 0.4259 - val_accuracy: 0.8330\n",
      "Epoch 165/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4034 - accuracy: 0.8451 - val_loss: 0.4257 - val_accuracy: 0.8330\n",
      "Epoch 166/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4032 - accuracy: 0.8451 - val_loss: 0.4254 - val_accuracy: 0.8336\n",
      "Epoch 167/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4030 - accuracy: 0.8456 - val_loss: 0.4253 - val_accuracy: 0.8336\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 34us/step - loss: 0.4028 - accuracy: 0.8453 - val_loss: 0.4251 - val_accuracy: 0.8343\n",
      "Epoch 169/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4027 - accuracy: 0.8456 - val_loss: 0.4248 - val_accuracy: 0.8343\n",
      "Epoch 170/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4024 - accuracy: 0.8452 - val_loss: 0.4247 - val_accuracy: 0.8343\n",
      "Epoch 171/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4022 - accuracy: 0.8455 - val_loss: 0.4245 - val_accuracy: 0.8343\n",
      "Epoch 172/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4020 - accuracy: 0.8455 - val_loss: 0.4244 - val_accuracy: 0.8343\n",
      "Epoch 173/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4018 - accuracy: 0.8454 - val_loss: 0.4242 - val_accuracy: 0.8333\n",
      "Epoch 174/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4015 - accuracy: 0.8454 - val_loss: 0.4239 - val_accuracy: 0.8333\n",
      "Epoch 175/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4013 - accuracy: 0.8451 - val_loss: 0.4237 - val_accuracy: 0.8333\n",
      "Epoch 176/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4010 - accuracy: 0.8451 - val_loss: 0.4235 - val_accuracy: 0.8333\n",
      "Epoch 177/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4008 - accuracy: 0.8456 - val_loss: 0.4233 - val_accuracy: 0.8336\n",
      "Epoch 178/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4006 - accuracy: 0.8453 - val_loss: 0.4231 - val_accuracy: 0.8333\n",
      "Epoch 179/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4003 - accuracy: 0.8454 - val_loss: 0.4231 - val_accuracy: 0.8336\n",
      "Epoch 180/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4001 - accuracy: 0.8454 - val_loss: 0.4229 - val_accuracy: 0.8333\n",
      "Epoch 181/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3999 - accuracy: 0.8453 - val_loss: 0.4227 - val_accuracy: 0.8333\n",
      "Epoch 182/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3998 - accuracy: 0.8454 - val_loss: 0.4225 - val_accuracy: 0.8336\n",
      "Epoch 183/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3995 - accuracy: 0.8453 - val_loss: 0.4222 - val_accuracy: 0.8336\n",
      "Epoch 184/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3994 - accuracy: 0.8462 - val_loss: 0.4222 - val_accuracy: 0.8336\n",
      "Epoch 185/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3992 - accuracy: 0.8455 - val_loss: 0.4220 - val_accuracy: 0.8349\n",
      "Epoch 186/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3989 - accuracy: 0.8456 - val_loss: 0.4219 - val_accuracy: 0.8336\n",
      "Epoch 187/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3987 - accuracy: 0.8457 - val_loss: 0.4217 - val_accuracy: 0.8349\n",
      "Epoch 188/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3985 - accuracy: 0.8459 - val_loss: 0.4216 - val_accuracy: 0.8349\n",
      "Epoch 189/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3983 - accuracy: 0.8460 - val_loss: 0.4212 - val_accuracy: 0.8346\n",
      "Epoch 190/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3981 - accuracy: 0.8461 - val_loss: 0.4209 - val_accuracy: 0.8349\n",
      "Epoch 191/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3979 - accuracy: 0.8459 - val_loss: 0.4208 - val_accuracy: 0.8352\n",
      "Epoch 192/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3976 - accuracy: 0.8460 - val_loss: 0.4207 - val_accuracy: 0.8349\n",
      "Epoch 193/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3975 - accuracy: 0.8461 - val_loss: 0.4205 - val_accuracy: 0.8349\n",
      "Epoch 194/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3972 - accuracy: 0.8458 - val_loss: 0.4204 - val_accuracy: 0.8346\n",
      "Epoch 195/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3970 - accuracy: 0.8462 - val_loss: 0.4201 - val_accuracy: 0.8339\n",
      "Epoch 196/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3968 - accuracy: 0.8462 - val_loss: 0.4199 - val_accuracy: 0.8349\n",
      "Epoch 197/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3965 - accuracy: 0.8457 - val_loss: 0.4197 - val_accuracy: 0.8349\n",
      "Epoch 198/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3962 - accuracy: 0.8459 - val_loss: 0.4195 - val_accuracy: 0.8343\n",
      "Epoch 199/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3961 - accuracy: 0.8457 - val_loss: 0.4192 - val_accuracy: 0.8349\n",
      "Epoch 200/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3958 - accuracy: 0.8456 - val_loss: 0.4192 - val_accuracy: 0.8349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:127: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Train on 640 samples, validate on 161 samples\n",
      "Epoch 1/200\n",
      "640/640 [==============================] - 0s 211us/step - loss: 0.6831 - accuracy: 0.6104 - val_loss: 0.6757 - val_accuracy: 0.6806\n",
      "Epoch 2/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.6677 - accuracy: 0.7025 - val_loss: 0.6607 - val_accuracy: 0.7195\n",
      "Epoch 3/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.6514 - accuracy: 0.7354 - val_loss: 0.6441 - val_accuracy: 0.7434\n",
      "Epoch 4/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.6325 - accuracy: 0.7604 - val_loss: 0.6239 - val_accuracy: 0.7636\n",
      "Epoch 5/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.6086 - accuracy: 0.7850 - val_loss: 0.5979 - val_accuracy: 0.7872\n",
      "Epoch 6/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.5772 - accuracy: 0.8183 - val_loss: 0.5642 - val_accuracy: 0.8231\n",
      "Epoch 7/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.5376 - accuracy: 0.8429 - val_loss: 0.5245 - val_accuracy: 0.8349\n",
      "Epoch 8/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4951 - accuracy: 0.8450 - val_loss: 0.4885 - val_accuracy: 0.8349\n",
      "Epoch 9/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4615 - accuracy: 0.8450 - val_loss: 0.4668 - val_accuracy: 0.8349\n",
      "Epoch 10/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4433 - accuracy: 0.8450 - val_loss: 0.4576 - val_accuracy: 0.8349\n",
      "Epoch 11/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4353 - accuracy: 0.8450 - val_loss: 0.4535 - val_accuracy: 0.8349\n",
      "Epoch 12/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4314 - accuracy: 0.8450 - val_loss: 0.4513 - val_accuracy: 0.8349\n",
      "Epoch 13/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4292 - accuracy: 0.8450 - val_loss: 0.4496 - val_accuracy: 0.8349\n",
      "Epoch 14/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4278 - accuracy: 0.8450 - val_loss: 0.4484 - val_accuracy: 0.8349\n",
      "Epoch 15/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4267 - accuracy: 0.8450 - val_loss: 0.4474 - val_accuracy: 0.8349\n",
      "Epoch 16/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4260 - accuracy: 0.8450 - val_loss: 0.4467 - val_accuracy: 0.8349\n",
      "Epoch 17/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4254 - accuracy: 0.8450 - val_loss: 0.4462 - val_accuracy: 0.8349\n",
      "Epoch 18/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4250 - accuracy: 0.8450 - val_loss: 0.4458 - val_accuracy: 0.8349\n",
      "Epoch 19/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4247 - accuracy: 0.8450 - val_loss: 0.4455 - val_accuracy: 0.8349\n",
      "Epoch 20/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4244 - accuracy: 0.8450 - val_loss: 0.4453 - val_accuracy: 0.8349\n",
      "Epoch 21/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4242 - accuracy: 0.8450 - val_loss: 0.4451 - val_accuracy: 0.8349\n",
      "Epoch 22/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4240 - accuracy: 0.8450 - val_loss: 0.4447 - val_accuracy: 0.8349\n",
      "Epoch 23/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4239 - accuracy: 0.8450 - val_loss: 0.4446 - val_accuracy: 0.8349\n",
      "Epoch 24/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4237 - accuracy: 0.8450 - val_loss: 0.4445 - val_accuracy: 0.8349\n",
      "Epoch 25/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4236 - accuracy: 0.8450 - val_loss: 0.4443 - val_accuracy: 0.8349\n",
      "Epoch 26/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4235 - accuracy: 0.8450 - val_loss: 0.4441 - val_accuracy: 0.8349\n",
      "Epoch 27/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4234 - accuracy: 0.8450 - val_loss: 0.4441 - val_accuracy: 0.8349\n",
      "Epoch 28/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4233 - accuracy: 0.8450 - val_loss: 0.4439 - val_accuracy: 0.8349\n",
      "Epoch 29/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4232 - accuracy: 0.8450 - val_loss: 0.4439 - val_accuracy: 0.8349\n",
      "Epoch 30/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4231 - accuracy: 0.8450 - val_loss: 0.4438 - val_accuracy: 0.8349\n",
      "Epoch 31/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4230 - accuracy: 0.8450 - val_loss: 0.4436 - val_accuracy: 0.8349\n",
      "Epoch 32/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4229 - accuracy: 0.8450 - val_loss: 0.4436 - val_accuracy: 0.8349\n",
      "Epoch 33/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4228 - accuracy: 0.8450 - val_loss: 0.4434 - val_accuracy: 0.8349\n",
      "Epoch 34/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4227 - accuracy: 0.8450 - val_loss: 0.4432 - val_accuracy: 0.8349\n",
      "Epoch 35/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4226 - accuracy: 0.8450 - val_loss: 0.4431 - val_accuracy: 0.8349\n",
      "Epoch 36/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4226 - accuracy: 0.8450 - val_loss: 0.4430 - val_accuracy: 0.8349\n",
      "Epoch 37/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4225 - accuracy: 0.8450 - val_loss: 0.4429 - val_accuracy: 0.8349\n",
      "Epoch 38/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4224 - accuracy: 0.8450 - val_loss: 0.4429 - val_accuracy: 0.8349\n",
      "Epoch 39/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4223 - accuracy: 0.8450 - val_loss: 0.4427 - val_accuracy: 0.8349\n",
      "Epoch 40/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4223 - accuracy: 0.8450 - val_loss: 0.4426 - val_accuracy: 0.8349\n",
      "Epoch 41/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4222 - accuracy: 0.8450 - val_loss: 0.4426 - val_accuracy: 0.8349\n",
      "Epoch 42/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4221 - accuracy: 0.8450 - val_loss: 0.4424 - val_accuracy: 0.8349\n",
      "Epoch 43/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4220 - accuracy: 0.8450 - val_loss: 0.4423 - val_accuracy: 0.8349\n",
      "Epoch 44/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4219 - accuracy: 0.8450 - val_loss: 0.4423 - val_accuracy: 0.8349\n",
      "Epoch 45/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4219 - accuracy: 0.8450 - val_loss: 0.4422 - val_accuracy: 0.8349\n",
      "Epoch 46/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4219 - accuracy: 0.8450 - val_loss: 0.4421 - val_accuracy: 0.8349\n",
      "Epoch 47/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4218 - accuracy: 0.8450 - val_loss: 0.4421 - val_accuracy: 0.8349\n",
      "Epoch 48/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4217 - accuracy: 0.8450 - val_loss: 0.4420 - val_accuracy: 0.8349\n",
      "Epoch 49/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4217 - accuracy: 0.8450 - val_loss: 0.4419 - val_accuracy: 0.8349\n",
      "Epoch 50/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4216 - accuracy: 0.8450 - val_loss: 0.4418 - val_accuracy: 0.8349\n",
      "Epoch 51/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4215 - accuracy: 0.8450 - val_loss: 0.4417 - val_accuracy: 0.8349\n",
      "Epoch 52/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4214 - accuracy: 0.8450 - val_loss: 0.4416 - val_accuracy: 0.8349\n",
      "Epoch 53/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4214 - accuracy: 0.8450 - val_loss: 0.4416 - val_accuracy: 0.8349\n",
      "Epoch 54/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4213 - accuracy: 0.8450 - val_loss: 0.4416 - val_accuracy: 0.8349\n",
      "Epoch 55/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4213 - accuracy: 0.8450 - val_loss: 0.4416 - val_accuracy: 0.8349\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 36us/step - loss: 0.4212 - accuracy: 0.8450 - val_loss: 0.4414 - val_accuracy: 0.8349\n",
      "Epoch 57/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4211 - accuracy: 0.8450 - val_loss: 0.4414 - val_accuracy: 0.8349\n",
      "Epoch 58/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4211 - accuracy: 0.8450 - val_loss: 0.4413 - val_accuracy: 0.8349\n",
      "Epoch 59/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4210 - accuracy: 0.8450 - val_loss: 0.4413 - val_accuracy: 0.8349\n",
      "Epoch 60/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4209 - accuracy: 0.8450 - val_loss: 0.4412 - val_accuracy: 0.8349\n",
      "Epoch 61/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4209 - accuracy: 0.8450 - val_loss: 0.4411 - val_accuracy: 0.8349\n",
      "Epoch 62/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4208 - accuracy: 0.8450 - val_loss: 0.4410 - val_accuracy: 0.8349\n",
      "Epoch 63/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4207 - accuracy: 0.8450 - val_loss: 0.4409 - val_accuracy: 0.8349\n",
      "Epoch 64/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4207 - accuracy: 0.8450 - val_loss: 0.4408 - val_accuracy: 0.8349\n",
      "Epoch 65/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4206 - accuracy: 0.8450 - val_loss: 0.4407 - val_accuracy: 0.8349\n",
      "Epoch 66/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4206 - accuracy: 0.8450 - val_loss: 0.4406 - val_accuracy: 0.8349\n",
      "Epoch 67/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4205 - accuracy: 0.8450 - val_loss: 0.4406 - val_accuracy: 0.8349\n",
      "Epoch 68/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4204 - accuracy: 0.8450 - val_loss: 0.4405 - val_accuracy: 0.8349\n",
      "Epoch 69/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4204 - accuracy: 0.8450 - val_loss: 0.4404 - val_accuracy: 0.8349\n",
      "Epoch 70/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4203 - accuracy: 0.8450 - val_loss: 0.4404 - val_accuracy: 0.8349\n",
      "Epoch 71/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4202 - accuracy: 0.8450 - val_loss: 0.4402 - val_accuracy: 0.8349\n",
      "Epoch 72/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4201 - accuracy: 0.8450 - val_loss: 0.4402 - val_accuracy: 0.8349\n",
      "Epoch 73/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4201 - accuracy: 0.8450 - val_loss: 0.4401 - val_accuracy: 0.8349\n",
      "Epoch 74/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4200 - accuracy: 0.8450 - val_loss: 0.4400 - val_accuracy: 0.8349\n",
      "Epoch 75/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4199 - accuracy: 0.8450 - val_loss: 0.4400 - val_accuracy: 0.8349\n",
      "Epoch 76/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4199 - accuracy: 0.8450 - val_loss: 0.4399 - val_accuracy: 0.8349\n",
      "Epoch 77/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4198 - accuracy: 0.8450 - val_loss: 0.4398 - val_accuracy: 0.8349\n",
      "Epoch 78/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4197 - accuracy: 0.8450 - val_loss: 0.4397 - val_accuracy: 0.8349\n",
      "Epoch 79/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4196 - accuracy: 0.8450 - val_loss: 0.4397 - val_accuracy: 0.8349\n",
      "Epoch 80/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4196 - accuracy: 0.8450 - val_loss: 0.4395 - val_accuracy: 0.8349\n",
      "Epoch 81/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4195 - accuracy: 0.8450 - val_loss: 0.4394 - val_accuracy: 0.8349\n",
      "Epoch 82/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4194 - accuracy: 0.8450 - val_loss: 0.4393 - val_accuracy: 0.8349\n",
      "Epoch 83/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4193 - accuracy: 0.8450 - val_loss: 0.4393 - val_accuracy: 0.8349\n",
      "Epoch 84/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4192 - accuracy: 0.8450 - val_loss: 0.4392 - val_accuracy: 0.8349\n",
      "Epoch 85/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4192 - accuracy: 0.8450 - val_loss: 0.4390 - val_accuracy: 0.8349\n",
      "Epoch 86/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4191 - accuracy: 0.8450 - val_loss: 0.4390 - val_accuracy: 0.8349\n",
      "Epoch 87/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4190 - accuracy: 0.8450 - val_loss: 0.4389 - val_accuracy: 0.8349\n",
      "Epoch 88/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4189 - accuracy: 0.8450 - val_loss: 0.4388 - val_accuracy: 0.8349\n",
      "Epoch 89/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4188 - accuracy: 0.8450 - val_loss: 0.4387 - val_accuracy: 0.8349\n",
      "Epoch 90/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4187 - accuracy: 0.8450 - val_loss: 0.4386 - val_accuracy: 0.8349\n",
      "Epoch 91/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4186 - accuracy: 0.8450 - val_loss: 0.4385 - val_accuracy: 0.8349\n",
      "Epoch 92/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4185 - accuracy: 0.8450 - val_loss: 0.4384 - val_accuracy: 0.8349\n",
      "Epoch 93/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4184 - accuracy: 0.8450 - val_loss: 0.4383 - val_accuracy: 0.8349\n",
      "Epoch 94/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4184 - accuracy: 0.8450 - val_loss: 0.4381 - val_accuracy: 0.8349\n",
      "Epoch 95/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4182 - accuracy: 0.8450 - val_loss: 0.4380 - val_accuracy: 0.8349\n",
      "Epoch 96/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4181 - accuracy: 0.8450 - val_loss: 0.4379 - val_accuracy: 0.8349\n",
      "Epoch 97/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4180 - accuracy: 0.8450 - val_loss: 0.4377 - val_accuracy: 0.8349\n",
      "Epoch 98/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4179 - accuracy: 0.8450 - val_loss: 0.4377 - val_accuracy: 0.8349\n",
      "Epoch 99/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4178 - accuracy: 0.8450 - val_loss: 0.4375 - val_accuracy: 0.8349\n",
      "Epoch 100/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4177 - accuracy: 0.8450 - val_loss: 0.4374 - val_accuracy: 0.8349\n",
      "Epoch 101/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4175 - accuracy: 0.8450 - val_loss: 0.4372 - val_accuracy: 0.8349\n",
      "Epoch 102/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4174 - accuracy: 0.8450 - val_loss: 0.4371 - val_accuracy: 0.8349\n",
      "Epoch 103/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4173 - accuracy: 0.8450 - val_loss: 0.4370 - val_accuracy: 0.8349\n",
      "Epoch 104/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4172 - accuracy: 0.8450 - val_loss: 0.4368 - val_accuracy: 0.8349\n",
      "Epoch 105/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4170 - accuracy: 0.8450 - val_loss: 0.4367 - val_accuracy: 0.8349\n",
      "Epoch 106/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4169 - accuracy: 0.8450 - val_loss: 0.4366 - val_accuracy: 0.8349\n",
      "Epoch 107/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4168 - accuracy: 0.8450 - val_loss: 0.4365 - val_accuracy: 0.8349\n",
      "Epoch 108/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4166 - accuracy: 0.8450 - val_loss: 0.4363 - val_accuracy: 0.8349\n",
      "Epoch 109/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4165 - accuracy: 0.8450 - val_loss: 0.4361 - val_accuracy: 0.8349\n",
      "Epoch 110/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4163 - accuracy: 0.8450 - val_loss: 0.4359 - val_accuracy: 0.8349\n",
      "Epoch 111/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4161 - accuracy: 0.8450 - val_loss: 0.4358 - val_accuracy: 0.8349\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 33us/step - loss: 0.4160 - accuracy: 0.8450 - val_loss: 0.4356 - val_accuracy: 0.8349\n",
      "Epoch 113/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4158 - accuracy: 0.8450 - val_loss: 0.4355 - val_accuracy: 0.8349\n",
      "Epoch 114/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4157 - accuracy: 0.8450 - val_loss: 0.4352 - val_accuracy: 0.8349\n",
      "Epoch 115/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4155 - accuracy: 0.8450 - val_loss: 0.4350 - val_accuracy: 0.8349\n",
      "Epoch 116/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4153 - accuracy: 0.8450 - val_loss: 0.4348 - val_accuracy: 0.8349\n",
      "Epoch 117/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4151 - accuracy: 0.8450 - val_loss: 0.4346 - val_accuracy: 0.8349\n",
      "Epoch 118/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4149 - accuracy: 0.8450 - val_loss: 0.4345 - val_accuracy: 0.8349\n",
      "Epoch 119/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4148 - accuracy: 0.8450 - val_loss: 0.4343 - val_accuracy: 0.8349\n",
      "Epoch 120/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4145 - accuracy: 0.8450 - val_loss: 0.4340 - val_accuracy: 0.8349\n",
      "Epoch 121/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4143 - accuracy: 0.8450 - val_loss: 0.4339 - val_accuracy: 0.8349\n",
      "Epoch 122/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4142 - accuracy: 0.8450 - val_loss: 0.4337 - val_accuracy: 0.8349\n",
      "Epoch 123/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4140 - accuracy: 0.8450 - val_loss: 0.4333 - val_accuracy: 0.8349\n",
      "Epoch 124/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4137 - accuracy: 0.8450 - val_loss: 0.4331 - val_accuracy: 0.8349\n",
      "Epoch 125/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4135 - accuracy: 0.8450 - val_loss: 0.4329 - val_accuracy: 0.8349\n",
      "Epoch 126/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4132 - accuracy: 0.8450 - val_loss: 0.4327 - val_accuracy: 0.8349\n",
      "Epoch 127/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4130 - accuracy: 0.8450 - val_loss: 0.4325 - val_accuracy: 0.8349\n",
      "Epoch 128/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4128 - accuracy: 0.8450 - val_loss: 0.4322 - val_accuracy: 0.8349\n",
      "Epoch 129/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4125 - accuracy: 0.8450 - val_loss: 0.4319 - val_accuracy: 0.8349\n",
      "Epoch 130/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4123 - accuracy: 0.8450 - val_loss: 0.4317 - val_accuracy: 0.8349\n",
      "Epoch 131/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4121 - accuracy: 0.8450 - val_loss: 0.4314 - val_accuracy: 0.8349\n",
      "Epoch 132/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4118 - accuracy: 0.8450 - val_loss: 0.4312 - val_accuracy: 0.8349\n",
      "Epoch 133/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4115 - accuracy: 0.8450 - val_loss: 0.4309 - val_accuracy: 0.8349\n",
      "Epoch 134/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4113 - accuracy: 0.8450 - val_loss: 0.4306 - val_accuracy: 0.8349\n",
      "Epoch 135/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4111 - accuracy: 0.8450 - val_loss: 0.4304 - val_accuracy: 0.8349\n",
      "Epoch 136/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4108 - accuracy: 0.8450 - val_loss: 0.4302 - val_accuracy: 0.8349\n",
      "Epoch 137/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4105 - accuracy: 0.8450 - val_loss: 0.4299 - val_accuracy: 0.8349\n",
      "Epoch 138/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4103 - accuracy: 0.8450 - val_loss: 0.4296 - val_accuracy: 0.8349\n",
      "Epoch 139/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4100 - accuracy: 0.8450 - val_loss: 0.4292 - val_accuracy: 0.8349\n",
      "Epoch 140/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4097 - accuracy: 0.8450 - val_loss: 0.4290 - val_accuracy: 0.8349\n",
      "Epoch 141/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4095 - accuracy: 0.8450 - val_loss: 0.4287 - val_accuracy: 0.8349\n",
      "Epoch 142/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4092 - accuracy: 0.8450 - val_loss: 0.4285 - val_accuracy: 0.8349\n",
      "Epoch 143/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4089 - accuracy: 0.8450 - val_loss: 0.4282 - val_accuracy: 0.8349\n",
      "Epoch 144/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4086 - accuracy: 0.8450 - val_loss: 0.4278 - val_accuracy: 0.8349\n",
      "Epoch 145/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4084 - accuracy: 0.8450 - val_loss: 0.4277 - val_accuracy: 0.8349\n",
      "Epoch 146/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4081 - accuracy: 0.8450 - val_loss: 0.4274 - val_accuracy: 0.8349\n",
      "Epoch 147/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4078 - accuracy: 0.8450 - val_loss: 0.4271 - val_accuracy: 0.8349\n",
      "Epoch 148/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4076 - accuracy: 0.8450 - val_loss: 0.4268 - val_accuracy: 0.8349\n",
      "Epoch 149/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4073 - accuracy: 0.8450 - val_loss: 0.4266 - val_accuracy: 0.8349\n",
      "Epoch 150/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4070 - accuracy: 0.8450 - val_loss: 0.4263 - val_accuracy: 0.8349\n",
      "Epoch 151/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4067 - accuracy: 0.8450 - val_loss: 0.4259 - val_accuracy: 0.8349\n",
      "Epoch 152/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4065 - accuracy: 0.8450 - val_loss: 0.4258 - val_accuracy: 0.8349\n",
      "Epoch 153/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4062 - accuracy: 0.8450 - val_loss: 0.4255 - val_accuracy: 0.8349\n",
      "Epoch 154/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4060 - accuracy: 0.8450 - val_loss: 0.4252 - val_accuracy: 0.8349\n",
      "Epoch 155/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4057 - accuracy: 0.8450 - val_loss: 0.4250 - val_accuracy: 0.8349\n",
      "Epoch 156/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4055 - accuracy: 0.8450 - val_loss: 0.4246 - val_accuracy: 0.8349\n",
      "Epoch 157/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4052 - accuracy: 0.8450 - val_loss: 0.4244 - val_accuracy: 0.8349\n",
      "Epoch 158/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4050 - accuracy: 0.8450 - val_loss: 0.4243 - val_accuracy: 0.8349\n",
      "Epoch 159/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4048 - accuracy: 0.8450 - val_loss: 0.4240 - val_accuracy: 0.8349\n",
      "Epoch 160/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4046 - accuracy: 0.8450 - val_loss: 0.4238 - val_accuracy: 0.8349\n",
      "Epoch 161/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4043 - accuracy: 0.8450 - val_loss: 0.4236 - val_accuracy: 0.8349\n",
      "Epoch 162/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4041 - accuracy: 0.8450 - val_loss: 0.4234 - val_accuracy: 0.8349\n",
      "Epoch 163/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4039 - accuracy: 0.8450 - val_loss: 0.4232 - val_accuracy: 0.8349\n",
      "Epoch 164/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4037 - accuracy: 0.8450 - val_loss: 0.4230 - val_accuracy: 0.8349\n",
      "Epoch 165/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4035 - accuracy: 0.8450 - val_loss: 0.4228 - val_accuracy: 0.8349\n",
      "Epoch 166/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4033 - accuracy: 0.8450 - val_loss: 0.4226 - val_accuracy: 0.8349\n",
      "Epoch 167/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4031 - accuracy: 0.8450 - val_loss: 0.4225 - val_accuracy: 0.8349\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 33us/step - loss: 0.4029 - accuracy: 0.8450 - val_loss: 0.4223 - val_accuracy: 0.8349\n",
      "Epoch 169/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4028 - accuracy: 0.8450 - val_loss: 0.4221 - val_accuracy: 0.8349\n",
      "Epoch 170/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4026 - accuracy: 0.8450 - val_loss: 0.4220 - val_accuracy: 0.8349\n",
      "Epoch 171/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4024 - accuracy: 0.8450 - val_loss: 0.4218 - val_accuracy: 0.8349\n",
      "Epoch 172/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4023 - accuracy: 0.8451 - val_loss: 0.4216 - val_accuracy: 0.8349\n",
      "Epoch 173/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4021 - accuracy: 0.8451 - val_loss: 0.4214 - val_accuracy: 0.8349\n",
      "Epoch 174/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4020 - accuracy: 0.8451 - val_loss: 0.4213 - val_accuracy: 0.8346\n",
      "Epoch 175/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4018 - accuracy: 0.8450 - val_loss: 0.4213 - val_accuracy: 0.8346\n",
      "Epoch 176/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4017 - accuracy: 0.8451 - val_loss: 0.4210 - val_accuracy: 0.8346\n",
      "Epoch 177/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4015 - accuracy: 0.8450 - val_loss: 0.4208 - val_accuracy: 0.8346\n",
      "Epoch 178/200\n",
      "640/640 [==============================] - 0s 39us/step - loss: 0.4014 - accuracy: 0.8452 - val_loss: 0.4207 - val_accuracy: 0.8346\n",
      "Epoch 179/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4012 - accuracy: 0.8456 - val_loss: 0.4206 - val_accuracy: 0.8346\n",
      "Epoch 180/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4011 - accuracy: 0.8454 - val_loss: 0.4204 - val_accuracy: 0.8346\n",
      "Epoch 181/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4009 - accuracy: 0.8456 - val_loss: 0.4204 - val_accuracy: 0.8349\n",
      "Epoch 182/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.4008 - accuracy: 0.8461 - val_loss: 0.4202 - val_accuracy: 0.8349\n",
      "Epoch 183/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4006 - accuracy: 0.8455 - val_loss: 0.4201 - val_accuracy: 0.8356\n",
      "Epoch 184/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.4006 - accuracy: 0.8454 - val_loss: 0.4200 - val_accuracy: 0.8356\n",
      "Epoch 185/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4004 - accuracy: 0.8457 - val_loss: 0.4198 - val_accuracy: 0.8356\n",
      "Epoch 186/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.4003 - accuracy: 0.8456 - val_loss: 0.4198 - val_accuracy: 0.8349\n",
      "Epoch 187/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4002 - accuracy: 0.8455 - val_loss: 0.4196 - val_accuracy: 0.8356\n",
      "Epoch 188/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.4000 - accuracy: 0.8455 - val_loss: 0.4195 - val_accuracy: 0.8352\n",
      "Epoch 189/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3999 - accuracy: 0.8456 - val_loss: 0.4195 - val_accuracy: 0.8349\n",
      "Epoch 190/200\n",
      "640/640 [==============================] - 0s 38us/step - loss: 0.3998 - accuracy: 0.8455 - val_loss: 0.4195 - val_accuracy: 0.8356\n",
      "Epoch 191/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3997 - accuracy: 0.8456 - val_loss: 0.4193 - val_accuracy: 0.8356\n",
      "Epoch 192/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3996 - accuracy: 0.8455 - val_loss: 0.4191 - val_accuracy: 0.8356\n",
      "Epoch 193/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3994 - accuracy: 0.8452 - val_loss: 0.4190 - val_accuracy: 0.8356\n",
      "Epoch 194/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3993 - accuracy: 0.8453 - val_loss: 0.4191 - val_accuracy: 0.8356\n",
      "Epoch 195/200\n",
      "640/640 [==============================] - 0s 36us/step - loss: 0.3992 - accuracy: 0.8451 - val_loss: 0.4189 - val_accuracy: 0.8343\n",
      "Epoch 196/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3991 - accuracy: 0.8453 - val_loss: 0.4188 - val_accuracy: 0.8359\n",
      "Epoch 197/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3990 - accuracy: 0.8450 - val_loss: 0.4188 - val_accuracy: 0.8346\n",
      "Epoch 198/200\n",
      "640/640 [==============================] - 0s 33us/step - loss: 0.3989 - accuracy: 0.8451 - val_loss: 0.4186 - val_accuracy: 0.8356\n",
      "Epoch 199/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3988 - accuracy: 0.8448 - val_loss: 0.4184 - val_accuracy: 0.8359\n",
      "Epoch 200/200\n",
      "640/640 [==============================] - 0s 34us/step - loss: 0.3986 - accuracy: 0.8449 - val_loss: 0.4185 - val_accuracy: 0.8359\n",
      "[200, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[194, 6]\n",
      "[0, 0]\n",
      "[15, 21]\n",
      "[154, 10]\n",
      "[2, 34]\n",
      "[160, 4]\n",
      "[15, 12]\n",
      "[153, 20]\n",
      "[2, 25]\n",
      "[144, 29]\n",
      "[14, 19]\n",
      "[149, 18]\n",
      "[3, 30]\n",
      "[153, 14]\n",
      "[24, 28]\n",
      "[134, 14]\n",
      "[23, 29]\n",
      "[129, 19]\n",
      "[32, 22]\n",
      "[112, 34]\n",
      "[24, 30]\n",
      "[125, 21]\n",
      "[0, 37]\n",
      "[163, 0]\n",
      "[5, 32]\n",
      "[143, 20]\n",
      "[0, 41]\n",
      "[159, 0]\n",
      "[8, 33]\n",
      "[143, 16]\n",
      "[101, 15]\n",
      "[69, 15]\n",
      "[88, 28]\n",
      "[70, 14]\n",
      "[63, 19]\n",
      "[104, 14]\n",
      "[62, 20]\n",
      "[96, 22]\n",
      "[59, 14]\n",
      "[109, 18]\n",
      "[52, 21]\n",
      "[113, 14]\n",
      "[0, 30]\n",
      "[170, 0]\n",
      "[4, 26]\n",
      "[157, 13]\n",
      "[14, 17]\n",
      "[160, 9]\n",
      "[17, 14]\n",
      "[158, 11]\n",
      "[150, 8]\n",
      "[30, 12]\n",
      "[145, 13]\n",
      "[27, 15]\n",
      "[13, 12]\n",
      "[153, 22]\n",
      "[10, 15]\n",
      "[156, 19]\n",
      "[28, 10]\n",
      "[145, 17]\n",
      "[21, 17]\n",
      "[153, 9]\n",
      "[141, 11]\n",
      "[38, 10]\n",
      "[140, 12]\n",
      "[31, 17]\n",
      "[7, 26]\n",
      "[144, 23]\n",
      "[4, 29]\n",
      "[147, 20]\n",
      "[0, 36]\n",
      "[164, 0]\n",
      "[6, 30]\n",
      "[146, 18]\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds of MWPM:\n",
      "> Accuracy: 0.8355739722440412 (+- 0.006746833207407369)\n",
      "> F1: 0.39882250196225133(+- 0.027277443838911584)\n",
      "> Time: 1.7011342799999993 (+- 0.02857638894229981)\n",
      "#####################################################################################\n",
      "Average scores for all folds of PLUT:\n",
      "> Accuracy: 0.8061914113642301 (+- 0.0063600180114422354)\n",
      "> F1: 0.2942922609068757(+- 0.01364674463853834)\n",
      "> Time: 0.00240284 (+- 0.0004880885067280319)\n",
      "#####################################################################################\n",
      "Average scores for all folds of NN:\n",
      "> Accuracy: 0.7409471545219423 (+- 0.20547634248878438)\n",
      "> F1: 0.3171180867915862(+- 0.011106507563251884)\n",
      "> Time: 0.04180944 (+- 0.0004004200624344389)\n",
      "#####################################################################################\n",
      "> AUC for class : 0.025000000000000022 (+- 0.0)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 4.166666666666667\n",
      "> AUC for class X00: 0.4379223641792057 (+- 0.03869218604304361)\n",
      "X^2 for MWPM and NN: 102.60571428571428\n",
      "X^2 for PLUT and NN: 83.13917525773196\n",
      "> AUC for class X01: 0.5327670744455194 (+- 0.022517500584258072)\n",
      "X^2 for MWPM and NN: 122.2060606060606\n",
      "X^2 for PLUT and NN: 85.20710059171597\n",
      "> AUC for class X02: 0.502699075511383 (+- 0.08120253948671843)\n",
      "X^2 for MWPM and NN: 102.14880952380952\n",
      "X^2 for PLUT and NN: 84.02185792349727\n",
      "> AUC for class X10: 0.5601678922233149 (+- 0.031198078801189254)\n",
      "X^2 for MWPM and NN: 70.67283950617283\n",
      "X^2 for PLUT and NN: 64.5632911392405\n",
      "> AUC for class X11: 0.5807262211873045 (+- 0.07509678676977241)\n",
      "X^2 for MWPM and NN: 61.798507462686565\n",
      "X^2 for PLUT and NN: 59.458064516129035\n",
      "> AUC for class X12: 0.49936829037717023 (+- 0.04835059002199696)\n",
      "X^2 for MWPM and NN: 80.645\n",
      "X^2 for PLUT and NN: 71.68\n",
      "> AUC for class X20: 0.5849279572173822 (+- 0.06776525652106075)\n",
      "X^2 for MWPM and NN: 70.805\n",
      "X^2 for PLUT and NN: 70.00568181818181\n",
      "> AUC for class X21: 0.8123696848092641 (+- 0.06318095563981917)\n",
      "X^2 for MWPM and NN: 36.01190476190476\n",
      "X^2 for PLUT and NN: 18.867346938775512\n",
      "> AUC for class X22: 0.7651352299862137 (+- 0.08667314837146463)\n",
      "X^2 for MWPM and NN: 60.13008130081301\n",
      "X^2 for PLUT and NN: 51.11206896551724\n",
      "> AUC for class Z00: 0.5536381144127482 (+- 0.06978010729112284)\n",
      "X^2 for MWPM and NN: 74.92682926829268\n",
      "X^2 for PLUT and NN: 64.54477611940298\n",
      "> AUC for class Z01: 0.5865524407554426 (+- 0.058030693576473856)\n",
      "X^2 for MWPM and NN: 99.405\n",
      "X^2 for PLUT and NN: 95.21311475409836\n",
      "> AUC for class Z02: 0.7623535159258734 (+- 0.09772655018826823)\n",
      "X^2 for MWPM and NN: 117.15254237288136\n",
      "X^2 for PLUT and NN: 122.23837209302326\n",
      "> AUC for class Z10: 0.8111854306977824 (+- 0.07739619349432676)\n",
      "X^2 for MWPM and NN: 13.921052631578947\n",
      "X^2 for PLUT and NN: 5.625\n",
      "> AUC for class Z11: 0.5897899317437449 (+- 0.040616505112904176)\n",
      "X^2 for MWPM and NN: 122.2060606060606\n",
      "X^2 for PLUT and NN: 117.91812865497076\n",
      "> AUC for class Z12: 0.80116459008831 (+- 0.0585746907171942)\n",
      "X^2 for MWPM and NN: 119.32903225806452\n",
      "X^2 for PLUT and NN: 110.40588235294118\n",
      "> AUC for class Z20: 0.8015543382225221 (+- 0.0784555926502464)\n",
      "X^2 for MWPM and NN: 16.0\n",
      "X^2 for PLUT and NN: 9.30232558139535\n",
      "> AUC for class Z21: 0.5516561453030684 (+- 0.055279786617981844)\n",
      "X^2 for MWPM and NN: 83.3\n",
      "X^2 for PLUT and NN: 80.46022727272727\n",
      "> AUC for class Z22: 0.4874381492018463 (+- 0.09839640280859063)\n",
      "X^2 for MWPM and NN: 83.205\n",
      "X^2 for PLUT and NN: 77.7784090909091\n",
      "###################################################################################\n",
      "TOTAL F1 NN: [0.3378212974296205, 0.31545741324921134, 0.3122110416100082, 0.3045092838196287, 0.3155913978494624]\n",
      "TOTAL F1 PLUT: [0.29643888354186715, 0.3090551181102362, 0.26904985888993416, 0.3027436140018921, 0.2941738299904489]\n",
      "TOTAL F1 MWPM: [0.4384615384615385, 0.36328125000000006, 0.3748792270531401, 0.4011406844106464, 0.41634980988593157]\n",
      "TOTAL ACC NN: [0.8423671722412109, 0.8450000286102295, 0.8447368741035461, 0.8426316976547241, 0.33000000000000035]\n",
      "TOTAL ACC PLUT: [0.8085886357685241, 0.8152631578947351, 0.7955263157894727, 0.8060526315789458, 0.805526315789472]\n",
      "TOTAL ACC MWPM: [0.8470803875360027, 0.8284210526315771, 0.8297368421052613, 0.8342105263157876, 0.8384210526315771]\n",
      "TOTAL TIME NN: [0.0420093, 0.0410086, 0.04201, 0.0420097, 0.0420096]\n",
      "TOTAL TIME PLUT: [0.0020123, 0.0030007, 0.0020004, 0.0020003, 0.0030005]\n",
      "TOTAL TIME MWPM: [1.6471104999999995, 1.7093962, 1.7293916999999992, 1.7013853999999993, 1.718387599999999]\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:127: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "inputs = x_d3.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = y_d3.copy()\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "n_classes = 19\n",
    "\n",
    "acc_per_fold = []\n",
    "f1_per_fold = []\n",
    "time_per_fold = []\n",
    "\n",
    "\n",
    "acc_per_fold_plut = []\n",
    "f1_per_fold_plut = []\n",
    "time_per_fold_plut = []\n",
    "\n",
    "acc_per_fold_mwpm = []\n",
    "f1_per_fold_mwpm = []\n",
    "time_per_fold_mwpm = []\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "aucs_classes = {}\n",
    "for i in mlb_d3.classes_:\n",
    "    aucs_classes[i] = []\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for i, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "    \n",
    "    i_train = inputs[train].copy()\n",
    "    i_test = inputs[test].copy()\n",
    "    x_test_d3 = i_test[:,:2]\n",
    "    inputs_train = i_train[:,3:]\n",
    "    inputs_test = i_test[:,3:]\n",
    "    \n",
    "    ####################################################################################################\n",
    "    #test MWPM decoder for this fold\n",
    "    \n",
    "    decoding_d3, time_mwpm = do_new_decoding(x_test_d3, 3, .03)\n",
    "    decoding_d3['combine'] = decoding_d3[[0, 1]].values.tolist()\n",
    "    decoding_d3['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "    decoding_d3 = np.array(decoding_d3[0])\n",
    "\n",
    "    time_per_fold_mwpm.append(time_mwpm)\n",
    "\n",
    "    pred_mwpm = mlb_d3.transform(decoding_d3)\n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_mwpm)\n",
    "    else:\n",
    "        acc, contingency_mwpm = partial_accuracy_and_contingency(targets[test], pred_mwpm, mlb_d3)\n",
    "        \n",
    "    acc_per_fold_mwpm.append(acc)\n",
    "    f1_per_fold_mwpm.append(f1_score(targets[test], pred_mwpm, average='micro'))\n",
    "\n",
    "\n",
    "    #####################################################################################################\n",
    "    #test the plut decoder for this fold\n",
    "\n",
    "    lookup_d3 = lookup_decoder(3)\n",
    "\n",
    "    lookup_d3 = train_plut(lookup_d3, inputs_train, targets[train])\n",
    "\n",
    "    start = time.time_ns()\n",
    "    pred_plut_d3 = test_plut(lookup_d3, inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_plut_d3)\n",
    "    else:\n",
    "        acc, contingency_plut = partial_accuracy_and_contingency(targets[test], pred_plut_d3, mlb_d3)\n",
    "\n",
    "    acc_per_fold_plut.append(acc)\n",
    "    f1_per_fold_plut.append(f1_score(targets[test], pred_plut_d3, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #Test the NN decoder for this fold\n",
    "\n",
    "    model = compile_FFNN_cv_model_DepthThree(3)\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "\n",
    "    history = model.fit(\n",
    "        inputs_train, targets[train],\n",
    "        validation_split=.2,\n",
    "        epochs=200,\n",
    "        verbose=1)\n",
    "\n",
    "   # Generate generalization metrics\n",
    "    scores = model.evaluate(inputs_test, targets[test], verbose=0)\n",
    "\n",
    "    #get the time to predicting test\n",
    "    start = time.time_ns()\n",
    "    predictions_d3 = model.predict(inputs_test) #change here\n",
    "    end = time.time_ns()\n",
    "    time_per_fold.append((end - start)/ (10 ** 9))\n",
    "\n",
    "    #threshold based on previous tests with train_test_split in hyperparameter tuning\n",
    "    pred=predictions_d3.copy() #change here\n",
    "    pred[pred>=.1]=1 \n",
    "    pred[pred<.1]=0\n",
    "    \n",
    "    if fold_no <5:\n",
    "        acc = scores[1]\n",
    "    else:\n",
    "        acc, contingency_nn = partial_accuracy_and_contingency(targets[test], pred, mlb_d3)\n",
    "\n",
    "    acc_per_fold.append(acc)\n",
    "    f1_per_fold.append(f1_score(targets[test], pred, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #comput ROC AUC for classes and the mircoaverage\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d3.ravel())\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    #get the AUCs of each class, used to get average AUC of each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d3[:, i]) #change here\n",
    "        aucs_classes[mlb_d3.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "        \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "        \n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb_d3.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "    \n",
    "############print mean and stdev of AUC of each class#####################      \n",
    "    \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print(\"#####################################################################################\")\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print(\"#####################################################################################\")\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "print(\"#####################################################################################\")\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 3 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D5 Training, Testing, and Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data sets from CSV\n",
    "\n",
    "#### Data sets for D5:\n",
    "* Original:\n",
    "    - \"depth5_all_combos.csv\"\n",
    "* Randomly-sampled, with replacement (version 2):\n",
    "    - \"v2samples-d5-1000.csv\"\n",
    "    - \"v2samples-d5-10000.csv\"\n",
    "* Randomly-sampled, without replacement (version 3):\n",
    "    - \"v3samples-d5-1000.csv\"\n",
    "    - \"v3samples-d5-10000.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData_d5 = pd.read_csv(\"SAMPLES/v2samples-d5-1000.csv\")\n",
    "\n",
    "trainData_d5 = trainData_d5.applymap(lambda x: add_noise(x,.01)) #was .05\n",
    "\n",
    "#These four lines remove duplicates\n",
    "trainData_d5['Labels'] = trainData_d5['Labels'].map(lambda x: create_list_from_string(x))\n",
    "trainData_d5['Labels'] = trainData_d5['Labels'].astype(str)\n",
    "trainData_d5 = trainData_d5.drop_duplicates('Labels', keep='first', ignore_index=True)\n",
    "trainData_d5['Labels'] = trainData_d5['Labels'].map(lambda x: create_list_from_string(x))\n",
    "\n",
    "testData_d5_MWPM = graph_with_errs_d5(trainData_d5)\n",
    "\n",
    "#transforms the data to encoding for ML\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(trainData_d5['Labels'])\n",
    "df = pd.DataFrame(mlb.transform(trainData_d5['Labels']))\n",
    "df['Labels']= df.values.tolist()\n",
    "trainData_d5 = trainData_d5.drop(['Labels'], axis=1)\n",
    "trainData_d5 = pd.concat([df[\"Labels\"], testData_d5_MWPM, trainData_d5], axis=1, ignore_index=True)\n",
    "trainData_d5.columns = [\"Labels\",\"XSyn\", \"ZSyn\",\"X0\",\"Z1\",\"X2\",\"X3\",\"Z4\",\"X5\",\"Z6\",\"Z7\",\"X8\",\"Z9\",\"X10\",\"Z11\",\"Z12\",\"X13\",\"Z14\",\"X15\",\"Z16\",\"Z17\",\"X18\",\"X19\",\"Z20\",\"X21\",\"X22\",\"Z23\"]\n",
    "\n",
    "y_d5 = trainData_d5[\"Labels\"] \n",
    "x_d5 = trainData_d5.drop([\"Labels\"], axis=1) \n",
    "\n",
    "x_d5 = x_d5.replace([-1], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Train on 450 samples, validate on 150 samples\n",
      "Epoch 1/500\n",
      "450/450 [==============================] - 0s 369us/step - loss: 0.6579 - accuracy: 0.7133 - val_loss: 0.6355 - val_accuracy: 0.8267\n",
      "Epoch 2/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.6139 - accuracy: 0.8566 - val_loss: 0.5748 - val_accuracy: 0.8871\n",
      "Epoch 3/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.5333 - accuracy: 0.9061 - val_loss: 0.4591 - val_accuracy: 0.9226\n",
      "Epoch 4/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.3956 - accuracy: 0.9323 - val_loss: 0.3074 - val_accuracy: 0.9404\n",
      "Epoch 5/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2748 - accuracy: 0.9395 - val_loss: 0.2389 - val_accuracy: 0.9404\n",
      "Epoch 6/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2366 - accuracy: 0.9395 - val_loss: 0.2260 - val_accuracy: 0.9404\n",
      "Epoch 7/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2292 - accuracy: 0.9395 - val_loss: 0.2242 - val_accuracy: 0.9404\n",
      "Epoch 8/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2272 - accuracy: 0.9395 - val_loss: 0.2241 - val_accuracy: 0.9404\n",
      "Epoch 9/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2263 - accuracy: 0.9395 - val_loss: 0.2240 - val_accuracy: 0.9404\n",
      "Epoch 10/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2256 - accuracy: 0.9395 - val_loss: 0.2240 - val_accuracy: 0.9404\n",
      "Epoch 11/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2252 - accuracy: 0.9395 - val_loss: 0.2240 - val_accuracy: 0.9404\n",
      "Epoch 12/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2249 - accuracy: 0.9395 - val_loss: 0.2242 - val_accuracy: 0.9404\n",
      "Epoch 13/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2248 - accuracy: 0.9395 - val_loss: 0.2243 - val_accuracy: 0.9404\n",
      "Epoch 14/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2248 - accuracy: 0.9395 - val_loss: 0.2244 - val_accuracy: 0.9404\n",
      "Epoch 15/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2245 - accuracy: 0.9395 - val_loss: 0.2246 - val_accuracy: 0.9404\n",
      "Epoch 16/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2243 - accuracy: 0.9395 - val_loss: 0.2246 - val_accuracy: 0.9404\n",
      "Epoch 17/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2242 - accuracy: 0.9395 - val_loss: 0.2246 - val_accuracy: 0.9404\n",
      "Epoch 18/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2241 - accuracy: 0.9395 - val_loss: 0.2249 - val_accuracy: 0.9404\n",
      "Epoch 19/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2242 - accuracy: 0.9395 - val_loss: 0.2246 - val_accuracy: 0.9404\n",
      "Epoch 20/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2240 - accuracy: 0.9395 - val_loss: 0.2243 - val_accuracy: 0.9404\n",
      "Epoch 21/500\n",
      "450/450 [==============================] - 0s 102us/step - loss: 0.2240 - accuracy: 0.9395 - val_loss: 0.2244 - val_accuracy: 0.9404\n",
      "Epoch 22/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2239 - accuracy: 0.9395 - val_loss: 0.2241 - val_accuracy: 0.9404\n",
      "Epoch 23/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2239 - accuracy: 0.9395 - val_loss: 0.2243 - val_accuracy: 0.9404\n",
      "Epoch 24/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2239 - accuracy: 0.9395 - val_loss: 0.2245 - val_accuracy: 0.9404\n",
      "Epoch 25/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2238 - accuracy: 0.9395 - val_loss: 0.2243 - val_accuracy: 0.9404\n",
      "Epoch 26/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2238 - accuracy: 0.9395 - val_loss: 0.2245 - val_accuracy: 0.9404\n",
      "Epoch 27/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2237 - accuracy: 0.9395 - val_loss: 0.2248 - val_accuracy: 0.9404\n",
      "Epoch 28/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2238 - accuracy: 0.9395 - val_loss: 0.2246 - val_accuracy: 0.9404\n",
      "Epoch 29/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2237 - accuracy: 0.9395 - val_loss: 0.2243 - val_accuracy: 0.9404\n",
      "Epoch 30/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2237 - accuracy: 0.9395 - val_loss: 0.2243 - val_accuracy: 0.9404\n",
      "Epoch 31/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2237 - accuracy: 0.9395 - val_loss: 0.2242 - val_accuracy: 0.9404\n",
      "Epoch 32/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2238 - accuracy: 0.9395 - val_loss: 0.2242 - val_accuracy: 0.9404\n",
      "Epoch 33/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2238 - accuracy: 0.9395 - val_loss: 0.2243 - val_accuracy: 0.9404\n",
      "Epoch 34/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2237 - accuracy: 0.9395 - val_loss: 0.2242 - val_accuracy: 0.9404\n",
      "Epoch 35/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2236 - accuracy: 0.9395 - val_loss: 0.2245 - val_accuracy: 0.9404\n",
      "Epoch 36/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2237 - accuracy: 0.9395 - val_loss: 0.2242 - val_accuracy: 0.9404\n",
      "Epoch 37/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2237 - accuracy: 0.9395 - val_loss: 0.2244 - val_accuracy: 0.9404\n",
      "Epoch 38/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2236 - accuracy: 0.9395 - val_loss: 0.2245 - val_accuracy: 0.9404\n",
      "Epoch 39/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2236 - accuracy: 0.9395 - val_loss: 0.2244 - val_accuracy: 0.9404\n",
      "Epoch 40/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2236 - accuracy: 0.9395 - val_loss: 0.2247 - val_accuracy: 0.9404\n",
      "Epoch 41/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2236 - accuracy: 0.9395 - val_loss: 0.2245 - val_accuracy: 0.9404\n",
      "Epoch 42/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2236 - accuracy: 0.9395 - val_loss: 0.2242 - val_accuracy: 0.9404\n",
      "Epoch 43/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2236 - accuracy: 0.9395 - val_loss: 0.2239 - val_accuracy: 0.9404\n",
      "Epoch 44/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2236 - accuracy: 0.9395 - val_loss: 0.2234 - val_accuracy: 0.9404\n",
      "Epoch 45/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2235 - accuracy: 0.9395 - val_loss: 0.2235 - val_accuracy: 0.9404\n",
      "Epoch 46/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2235 - accuracy: 0.9395 - val_loss: 0.2239 - val_accuracy: 0.9404\n",
      "Epoch 47/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2236 - accuracy: 0.9395 - val_loss: 0.2240 - val_accuracy: 0.9404\n",
      "Epoch 48/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2235 - accuracy: 0.9395 - val_loss: 0.2244 - val_accuracy: 0.9404\n",
      "Epoch 49/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2235 - accuracy: 0.9395 - val_loss: 0.2244 - val_accuracy: 0.9404\n",
      "Epoch 50/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2234 - accuracy: 0.9395 - val_loss: 0.2243 - val_accuracy: 0.9404\n",
      "Epoch 51/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2235 - accuracy: 0.9395 - val_loss: 0.2245 - val_accuracy: 0.9404\n",
      "Epoch 52/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2234 - accuracy: 0.9395 - val_loss: 0.2245 - val_accuracy: 0.9404\n",
      "Epoch 53/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2234 - accuracy: 0.9395 - val_loss: 0.2242 - val_accuracy: 0.9404\n",
      "Epoch 54/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2234 - accuracy: 0.9395 - val_loss: 0.2239 - val_accuracy: 0.9404\n",
      "Epoch 55/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2234 - accuracy: 0.9395 - val_loss: 0.2241 - val_accuracy: 0.9404\n",
      "Epoch 56/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2234 - accuracy: 0.9395 - val_loss: 0.2241 - val_accuracy: 0.9404\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 91us/step - loss: 0.2234 - accuracy: 0.9395 - val_loss: 0.2239 - val_accuracy: 0.9404\n",
      "Epoch 58/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2233 - accuracy: 0.9395 - val_loss: 0.2241 - val_accuracy: 0.9404\n",
      "Epoch 59/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2233 - accuracy: 0.9395 - val_loss: 0.2242 - val_accuracy: 0.9404\n",
      "Epoch 60/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2232 - accuracy: 0.9395 - val_loss: 0.2244 - val_accuracy: 0.9404\n",
      "Epoch 61/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2232 - accuracy: 0.9395 - val_loss: 0.2246 - val_accuracy: 0.9404\n",
      "Epoch 62/500\n",
      "450/450 [==============================] - 0s 95us/step - loss: 0.2232 - accuracy: 0.9395 - val_loss: 0.2242 - val_accuracy: 0.9404\n",
      "Epoch 63/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2232 - accuracy: 0.9395 - val_loss: 0.2244 - val_accuracy: 0.9404\n",
      "Epoch 64/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2232 - accuracy: 0.9395 - val_loss: 0.2238 - val_accuracy: 0.9404\n",
      "Epoch 65/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2231 - accuracy: 0.9395 - val_loss: 0.2237 - val_accuracy: 0.9404\n",
      "Epoch 66/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2231 - accuracy: 0.9395 - val_loss: 0.2242 - val_accuracy: 0.9404\n",
      "Epoch 67/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2232 - accuracy: 0.9395 - val_loss: 0.2241 - val_accuracy: 0.9404\n",
      "Epoch 68/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2232 - accuracy: 0.9395 - val_loss: 0.2241 - val_accuracy: 0.9404\n",
      "Epoch 69/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2231 - accuracy: 0.9395 - val_loss: 0.2236 - val_accuracy: 0.9404\n",
      "Epoch 70/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2231 - accuracy: 0.9395 - val_loss: 0.2238 - val_accuracy: 0.9404\n",
      "Epoch 71/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2231 - accuracy: 0.9395 - val_loss: 0.2236 - val_accuracy: 0.9404\n",
      "Epoch 72/500\n",
      "450/450 [==============================] - 0s 88us/step - loss: 0.2231 - accuracy: 0.9395 - val_loss: 0.2237 - val_accuracy: 0.9404\n",
      "Epoch 73/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2231 - accuracy: 0.9395 - val_loss: 0.2238 - val_accuracy: 0.9404\n",
      "Epoch 74/500\n",
      "450/450 [==============================] - 0s 99us/step - loss: 0.2230 - accuracy: 0.9395 - val_loss: 0.2240 - val_accuracy: 0.9404\n",
      "Epoch 75/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2230 - accuracy: 0.9395 - val_loss: 0.2242 - val_accuracy: 0.9404\n",
      "Epoch 76/500\n",
      "450/450 [==============================] - 0s 99us/step - loss: 0.2231 - accuracy: 0.9395 - val_loss: 0.2240 - val_accuracy: 0.9404\n",
      "Epoch 77/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2230 - accuracy: 0.9395 - val_loss: 0.2241 - val_accuracy: 0.9404\n",
      "Epoch 78/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2230 - accuracy: 0.9395 - val_loss: 0.2240 - val_accuracy: 0.9404\n",
      "Epoch 79/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2230 - accuracy: 0.9395 - val_loss: 0.2239 - val_accuracy: 0.9404\n",
      "Epoch 80/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2229 - accuracy: 0.9395 - val_loss: 0.2239 - val_accuracy: 0.9404\n",
      "Epoch 81/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2229 - accuracy: 0.9395 - val_loss: 0.2239 - val_accuracy: 0.9404\n",
      "Epoch 82/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2229 - accuracy: 0.9395 - val_loss: 0.2239 - val_accuracy: 0.9404\n",
      "Epoch 83/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2229 - accuracy: 0.9395 - val_loss: 0.2238 - val_accuracy: 0.9404\n",
      "Epoch 84/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2228 - accuracy: 0.9395 - val_loss: 0.2239 - val_accuracy: 0.9404\n",
      "Epoch 85/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2228 - accuracy: 0.9395 - val_loss: 0.2242 - val_accuracy: 0.9404\n",
      "Epoch 86/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2228 - accuracy: 0.9395 - val_loss: 0.2243 - val_accuracy: 0.9404\n",
      "Epoch 87/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2228 - accuracy: 0.9395 - val_loss: 0.2244 - val_accuracy: 0.9404\n",
      "Epoch 88/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2228 - accuracy: 0.9395 - val_loss: 0.2243 - val_accuracy: 0.9404\n",
      "Epoch 89/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2228 - accuracy: 0.9395 - val_loss: 0.2240 - val_accuracy: 0.9404\n",
      "Epoch 90/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2228 - accuracy: 0.9395 - val_loss: 0.2242 - val_accuracy: 0.9404\n",
      "Epoch 91/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2228 - accuracy: 0.9395 - val_loss: 0.2238 - val_accuracy: 0.9404\n",
      "Epoch 92/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2227 - accuracy: 0.9395 - val_loss: 0.2239 - val_accuracy: 0.9404\n",
      "Epoch 93/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2227 - accuracy: 0.9395 - val_loss: 0.2236 - val_accuracy: 0.9404\n",
      "Epoch 94/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2227 - accuracy: 0.9395 - val_loss: 0.2237 - val_accuracy: 0.9404\n",
      "Epoch 95/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2227 - accuracy: 0.9395 - val_loss: 0.2240 - val_accuracy: 0.9404\n",
      "Epoch 96/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2227 - accuracy: 0.9395 - val_loss: 0.2236 - val_accuracy: 0.9404\n",
      "Epoch 97/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2226 - accuracy: 0.9395 - val_loss: 0.2237 - val_accuracy: 0.9404\n",
      "Epoch 98/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2226 - accuracy: 0.9395 - val_loss: 0.2237 - val_accuracy: 0.9404\n",
      "Epoch 99/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2226 - accuracy: 0.9395 - val_loss: 0.2235 - val_accuracy: 0.9404\n",
      "Epoch 100/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2226 - accuracy: 0.9395 - val_loss: 0.2233 - val_accuracy: 0.9404\n",
      "Epoch 101/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2226 - accuracy: 0.9395 - val_loss: 0.2234 - val_accuracy: 0.9404\n",
      "Epoch 102/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2225 - accuracy: 0.9395 - val_loss: 0.2235 - val_accuracy: 0.9404\n",
      "Epoch 103/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2225 - accuracy: 0.9395 - val_loss: 0.2236 - val_accuracy: 0.9404\n",
      "Epoch 104/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2225 - accuracy: 0.9395 - val_loss: 0.2230 - val_accuracy: 0.9404\n",
      "Epoch 105/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2225 - accuracy: 0.9395 - val_loss: 0.2232 - val_accuracy: 0.9404\n",
      "Epoch 106/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2226 - accuracy: 0.9395 - val_loss: 0.2230 - val_accuracy: 0.9404\n",
      "Epoch 107/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2225 - accuracy: 0.9395 - val_loss: 0.2235 - val_accuracy: 0.9404\n",
      "Epoch 108/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2225 - accuracy: 0.9395 - val_loss: 0.2237 - val_accuracy: 0.9404\n",
      "Epoch 109/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2224 - accuracy: 0.9395 - val_loss: 0.2236 - val_accuracy: 0.9404\n",
      "Epoch 110/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2224 - accuracy: 0.9395 - val_loss: 0.2238 - val_accuracy: 0.9404\n",
      "Epoch 111/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2224 - accuracy: 0.9395 - val_loss: 0.2235 - val_accuracy: 0.9404\n",
      "Epoch 112/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2224 - accuracy: 0.9395 - val_loss: 0.2237 - val_accuracy: 0.9404\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 91us/step - loss: 0.2225 - accuracy: 0.9395 - val_loss: 0.2236 - val_accuracy: 0.9404\n",
      "Epoch 114/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2224 - accuracy: 0.9395 - val_loss: 0.2229 - val_accuracy: 0.9404\n",
      "Epoch 115/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2224 - accuracy: 0.9395 - val_loss: 0.2233 - val_accuracy: 0.9404\n",
      "Epoch 116/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2223 - accuracy: 0.9395 - val_loss: 0.2228 - val_accuracy: 0.9404\n",
      "Epoch 117/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2223 - accuracy: 0.9395 - val_loss: 0.2230 - val_accuracy: 0.9404\n",
      "Epoch 118/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2223 - accuracy: 0.9395 - val_loss: 0.2233 - val_accuracy: 0.9404\n",
      "Epoch 119/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2224 - accuracy: 0.9395 - val_loss: 0.2235 - val_accuracy: 0.9404\n",
      "Epoch 120/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2224 - accuracy: 0.9395 - val_loss: 0.2235 - val_accuracy: 0.9404\n",
      "Epoch 121/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2223 - accuracy: 0.9395 - val_loss: 0.2236 - val_accuracy: 0.9404\n",
      "Epoch 122/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2223 - accuracy: 0.9395 - val_loss: 0.2235 - val_accuracy: 0.9404\n",
      "Epoch 123/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2222 - accuracy: 0.9395 - val_loss: 0.2234 - val_accuracy: 0.9404\n",
      "Epoch 124/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2222 - accuracy: 0.9395 - val_loss: 0.2235 - val_accuracy: 0.9404\n",
      "Epoch 125/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2222 - accuracy: 0.9395 - val_loss: 0.2235 - val_accuracy: 0.9404\n",
      "Epoch 126/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2222 - accuracy: 0.9395 - val_loss: 0.2235 - val_accuracy: 0.9404\n",
      "Epoch 127/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2221 - accuracy: 0.9395 - val_loss: 0.2232 - val_accuracy: 0.9404\n",
      "Epoch 128/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2221 - accuracy: 0.9395 - val_loss: 0.2228 - val_accuracy: 0.9404\n",
      "Epoch 129/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2221 - accuracy: 0.9395 - val_loss: 0.2228 - val_accuracy: 0.9404\n",
      "Epoch 130/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2221 - accuracy: 0.9395 - val_loss: 0.2233 - val_accuracy: 0.9404\n",
      "Epoch 131/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2220 - accuracy: 0.9395 - val_loss: 0.2230 - val_accuracy: 0.9404\n",
      "Epoch 132/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2220 - accuracy: 0.9395 - val_loss: 0.2233 - val_accuracy: 0.9404\n",
      "Epoch 133/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2220 - accuracy: 0.9395 - val_loss: 0.2234 - val_accuracy: 0.9404\n",
      "Epoch 134/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2221 - accuracy: 0.9395 - val_loss: 0.2228 - val_accuracy: 0.9404\n",
      "Epoch 135/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2220 - accuracy: 0.9395 - val_loss: 0.2231 - val_accuracy: 0.9404\n",
      "Epoch 136/500\n",
      "450/450 [==============================] - 0s 92us/step - loss: 0.2220 - accuracy: 0.9395 - val_loss: 0.2234 - val_accuracy: 0.9404\n",
      "Epoch 137/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2220 - accuracy: 0.9395 - val_loss: 0.2236 - val_accuracy: 0.9404\n",
      "Epoch 138/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2220 - accuracy: 0.9395 - val_loss: 0.2234 - val_accuracy: 0.9404\n",
      "Epoch 139/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2220 - accuracy: 0.9395 - val_loss: 0.2238 - val_accuracy: 0.9404\n",
      "Epoch 140/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2220 - accuracy: 0.9395 - val_loss: 0.2236 - val_accuracy: 0.9404\n",
      "Epoch 141/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2219 - accuracy: 0.9395 - val_loss: 0.2237 - val_accuracy: 0.9404\n",
      "Epoch 142/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2219 - accuracy: 0.9395 - val_loss: 0.2235 - val_accuracy: 0.9404\n",
      "Epoch 143/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2218 - accuracy: 0.9395 - val_loss: 0.2235 - val_accuracy: 0.9404\n",
      "Epoch 144/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2219 - accuracy: 0.9395 - val_loss: 0.2230 - val_accuracy: 0.9404\n",
      "Epoch 145/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2219 - accuracy: 0.9395 - val_loss: 0.2230 - val_accuracy: 0.9404\n",
      "Epoch 146/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2219 - accuracy: 0.9395 - val_loss: 0.2231 - val_accuracy: 0.9404\n",
      "Epoch 147/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2218 - accuracy: 0.9395 - val_loss: 0.2230 - val_accuracy: 0.9404\n",
      "Epoch 148/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2217 - accuracy: 0.9395 - val_loss: 0.2232 - val_accuracy: 0.9404\n",
      "Epoch 149/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2216 - accuracy: 0.9395 - val_loss: 0.2231 - val_accuracy: 0.9404\n",
      "Epoch 150/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2217 - accuracy: 0.9395 - val_loss: 0.2232 - val_accuracy: 0.9404\n",
      "Epoch 151/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2217 - accuracy: 0.9395 - val_loss: 0.2231 - val_accuracy: 0.9404\n",
      "Epoch 152/500\n",
      "450/450 [==============================] - 0s 90us/step - loss: 0.2217 - accuracy: 0.9395 - val_loss: 0.2229 - val_accuracy: 0.9404\n",
      "Epoch 153/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2217 - accuracy: 0.9395 - val_loss: 0.2229 - val_accuracy: 0.9404\n",
      "Epoch 154/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2216 - accuracy: 0.9395 - val_loss: 0.2226 - val_accuracy: 0.9404\n",
      "Epoch 155/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2216 - accuracy: 0.9395 - val_loss: 0.2222 - val_accuracy: 0.9404\n",
      "Epoch 156/500\n",
      "450/450 [==============================] - 0s 95us/step - loss: 0.2215 - accuracy: 0.9395 - val_loss: 0.2227 - val_accuracy: 0.9404\n",
      "Epoch 157/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2215 - accuracy: 0.9395 - val_loss: 0.2226 - val_accuracy: 0.9404\n",
      "Epoch 158/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2215 - accuracy: 0.9395 - val_loss: 0.2225 - val_accuracy: 0.9404\n",
      "Epoch 159/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2215 - accuracy: 0.9395 - val_loss: 0.2226 - val_accuracy: 0.9404\n",
      "Epoch 160/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2217 - accuracy: 0.9395 - val_loss: 0.2228 - val_accuracy: 0.9404\n",
      "Epoch 161/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2215 - accuracy: 0.9395 - val_loss: 0.2226 - val_accuracy: 0.9404\n",
      "Epoch 162/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2215 - accuracy: 0.9395 - val_loss: 0.2227 - val_accuracy: 0.9404\n",
      "Epoch 163/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2214 - accuracy: 0.9395 - val_loss: 0.2221 - val_accuracy: 0.9404\n",
      "Epoch 164/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2214 - accuracy: 0.9395 - val_loss: 0.2223 - val_accuracy: 0.9404\n",
      "Epoch 165/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2214 - accuracy: 0.9395 - val_loss: 0.2226 - val_accuracy: 0.9404\n",
      "Epoch 166/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2214 - accuracy: 0.9395 - val_loss: 0.2227 - val_accuracy: 0.9404\n",
      "Epoch 167/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2213 - accuracy: 0.9395 - val_loss: 0.2227 - val_accuracy: 0.9404\n",
      "Epoch 168/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2213 - accuracy: 0.9395 - val_loss: 0.2227 - val_accuracy: 0.9404\n",
      "Epoch 169/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 93us/step - loss: 0.2213 - accuracy: 0.9395 - val_loss: 0.2223 - val_accuracy: 0.9404\n",
      "Epoch 170/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2212 - accuracy: 0.9395 - val_loss: 0.2225 - val_accuracy: 0.9404\n",
      "Epoch 171/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2213 - accuracy: 0.9395 - val_loss: 0.2226 - val_accuracy: 0.9404\n",
      "Epoch 172/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2212 - accuracy: 0.9395 - val_loss: 0.2227 - val_accuracy: 0.9404\n",
      "Epoch 173/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2212 - accuracy: 0.9395 - val_loss: 0.2223 - val_accuracy: 0.9404\n",
      "Epoch 174/500\n",
      "450/450 [==============================] - 0s 100us/step - loss: 0.2211 - accuracy: 0.9395 - val_loss: 0.2224 - val_accuracy: 0.9404\n",
      "Epoch 175/500\n",
      "450/450 [==============================] - 0s 100us/step - loss: 0.2211 - accuracy: 0.9395 - val_loss: 0.2223 - val_accuracy: 0.9404\n",
      "Epoch 176/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2211 - accuracy: 0.9395 - val_loss: 0.2226 - val_accuracy: 0.9404\n",
      "Epoch 177/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2211 - accuracy: 0.9395 - val_loss: 0.2223 - val_accuracy: 0.9404\n",
      "Epoch 178/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2211 - accuracy: 0.9395 - val_loss: 0.2221 - val_accuracy: 0.9404\n",
      "Epoch 179/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2210 - accuracy: 0.9395 - val_loss: 0.2223 - val_accuracy: 0.9404\n",
      "Epoch 180/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2210 - accuracy: 0.9395 - val_loss: 0.2221 - val_accuracy: 0.9404\n",
      "Epoch 181/500\n",
      "450/450 [==============================] - 0s 102us/step - loss: 0.2210 - accuracy: 0.9395 - val_loss: 0.2221 - val_accuracy: 0.9404\n",
      "Epoch 182/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2210 - accuracy: 0.9395 - val_loss: 0.2220 - val_accuracy: 0.9404\n",
      "Epoch 183/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2209 - accuracy: 0.9395 - val_loss: 0.2222 - val_accuracy: 0.9404\n",
      "Epoch 184/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2209 - accuracy: 0.9395 - val_loss: 0.2219 - val_accuracy: 0.9404\n",
      "Epoch 185/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2209 - accuracy: 0.9395 - val_loss: 0.2220 - val_accuracy: 0.9404\n",
      "Epoch 186/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2209 - accuracy: 0.9395 - val_loss: 0.2218 - val_accuracy: 0.9404\n",
      "Epoch 187/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2208 - accuracy: 0.9395 - val_loss: 0.2218 - val_accuracy: 0.9404\n",
      "Epoch 188/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2208 - accuracy: 0.9395 - val_loss: 0.2218 - val_accuracy: 0.9404\n",
      "Epoch 189/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2208 - accuracy: 0.9395 - val_loss: 0.2218 - val_accuracy: 0.9404\n",
      "Epoch 190/500\n",
      "450/450 [==============================] - 0s 100us/step - loss: 0.2208 - accuracy: 0.9395 - val_loss: 0.2217 - val_accuracy: 0.9404\n",
      "Epoch 191/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2207 - accuracy: 0.9395 - val_loss: 0.2217 - val_accuracy: 0.9404\n",
      "Epoch 192/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2207 - accuracy: 0.9395 - val_loss: 0.2217 - val_accuracy: 0.9404\n",
      "Epoch 193/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2207 - accuracy: 0.9395 - val_loss: 0.2218 - val_accuracy: 0.9404\n",
      "Epoch 194/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2207 - accuracy: 0.9395 - val_loss: 0.2218 - val_accuracy: 0.9404\n",
      "Epoch 195/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2206 - accuracy: 0.9395 - val_loss: 0.2219 - val_accuracy: 0.9404\n",
      "Epoch 196/500\n",
      "450/450 [==============================] - 0s 94us/step - loss: 0.2206 - accuracy: 0.9395 - val_loss: 0.2220 - val_accuracy: 0.9404\n",
      "Epoch 197/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2206 - accuracy: 0.9395 - val_loss: 0.2220 - val_accuracy: 0.9404\n",
      "Epoch 198/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2206 - accuracy: 0.9395 - val_loss: 0.2219 - val_accuracy: 0.9404\n",
      "Epoch 199/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2206 - accuracy: 0.9395 - val_loss: 0.2215 - val_accuracy: 0.9404\n",
      "Epoch 200/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2205 - accuracy: 0.9395 - val_loss: 0.2219 - val_accuracy: 0.9404\n",
      "Epoch 201/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2204 - accuracy: 0.9395 - val_loss: 0.2217 - val_accuracy: 0.9404\n",
      "Epoch 202/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2204 - accuracy: 0.9395 - val_loss: 0.2212 - val_accuracy: 0.9404\n",
      "Epoch 203/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2204 - accuracy: 0.9395 - val_loss: 0.2212 - val_accuracy: 0.9404\n",
      "Epoch 204/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2204 - accuracy: 0.9395 - val_loss: 0.2217 - val_accuracy: 0.9404\n",
      "Epoch 205/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2204 - accuracy: 0.9395 - val_loss: 0.2215 - val_accuracy: 0.9404\n",
      "Epoch 206/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2203 - accuracy: 0.9395 - val_loss: 0.2216 - val_accuracy: 0.9404\n",
      "Epoch 207/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2202 - accuracy: 0.9395 - val_loss: 0.2217 - val_accuracy: 0.9404\n",
      "Epoch 208/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2203 - accuracy: 0.9395 - val_loss: 0.2214 - val_accuracy: 0.9404\n",
      "Epoch 209/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2202 - accuracy: 0.9395 - val_loss: 0.2212 - val_accuracy: 0.9404\n",
      "Epoch 210/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2202 - accuracy: 0.9395 - val_loss: 0.2216 - val_accuracy: 0.9404\n",
      "Epoch 211/500\n",
      "450/450 [==============================] - 0s 97us/step - loss: 0.2203 - accuracy: 0.9395 - val_loss: 0.2214 - val_accuracy: 0.9404\n",
      "Epoch 212/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2203 - accuracy: 0.9395 - val_loss: 0.2214 - val_accuracy: 0.9404\n",
      "Epoch 213/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2202 - accuracy: 0.9395 - val_loss: 0.2216 - val_accuracy: 0.9404\n",
      "Epoch 214/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2201 - accuracy: 0.9395 - val_loss: 0.2215 - val_accuracy: 0.9404\n",
      "Epoch 215/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2201 - accuracy: 0.9395 - val_loss: 0.2215 - val_accuracy: 0.9404\n",
      "Epoch 216/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2200 - accuracy: 0.9395 - val_loss: 0.2216 - val_accuracy: 0.9404\n",
      "Epoch 217/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2201 - accuracy: 0.9395 - val_loss: 0.2217 - val_accuracy: 0.9404\n",
      "Epoch 218/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2199 - accuracy: 0.9395 - val_loss: 0.2211 - val_accuracy: 0.9404\n",
      "Epoch 219/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2199 - accuracy: 0.9395 - val_loss: 0.2210 - val_accuracy: 0.9404\n",
      "Epoch 220/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2199 - accuracy: 0.9395 - val_loss: 0.2209 - val_accuracy: 0.9404\n",
      "Epoch 221/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2199 - accuracy: 0.9395 - val_loss: 0.2210 - val_accuracy: 0.9404\n",
      "Epoch 222/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2198 - accuracy: 0.9395 - val_loss: 0.2210 - val_accuracy: 0.9404\n",
      "Epoch 223/500\n",
      "450/450 [==============================] - 0s 92us/step - loss: 0.2197 - accuracy: 0.9395 - val_loss: 0.2210 - val_accuracy: 0.9404\n",
      "Epoch 224/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2197 - accuracy: 0.9395 - val_loss: 0.2205 - val_accuracy: 0.9404\n",
      "Epoch 225/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 96us/step - loss: 0.2197 - accuracy: 0.9395 - val_loss: 0.2203 - val_accuracy: 0.9404\n",
      "Epoch 226/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2196 - accuracy: 0.9395 - val_loss: 0.2203 - val_accuracy: 0.9404\n",
      "Epoch 227/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2196 - accuracy: 0.9395 - val_loss: 0.2205 - val_accuracy: 0.9404\n",
      "Epoch 228/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2195 - accuracy: 0.9395 - val_loss: 0.2205 - val_accuracy: 0.9404\n",
      "Epoch 229/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2195 - accuracy: 0.9395 - val_loss: 0.2208 - val_accuracy: 0.9404\n",
      "Epoch 230/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2195 - accuracy: 0.9395 - val_loss: 0.2204 - val_accuracy: 0.9404\n",
      "Epoch 231/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2195 - accuracy: 0.9395 - val_loss: 0.2208 - val_accuracy: 0.9404\n",
      "Epoch 232/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2195 - accuracy: 0.9395 - val_loss: 0.2209 - val_accuracy: 0.9404\n",
      "Epoch 233/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2194 - accuracy: 0.9395 - val_loss: 0.2208 - val_accuracy: 0.9404\n",
      "Epoch 234/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2193 - accuracy: 0.9395 - val_loss: 0.2209 - val_accuracy: 0.9404\n",
      "Epoch 235/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2193 - accuracy: 0.9395 - val_loss: 0.2210 - val_accuracy: 0.9404\n",
      "Epoch 236/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2193 - accuracy: 0.9395 - val_loss: 0.2207 - val_accuracy: 0.9404\n",
      "Epoch 237/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2192 - accuracy: 0.9395 - val_loss: 0.2209 - val_accuracy: 0.9404\n",
      "Epoch 238/500\n",
      "450/450 [==============================] - 0s 92us/step - loss: 0.2192 - accuracy: 0.9395 - val_loss: 0.2206 - val_accuracy: 0.9404\n",
      "Epoch 239/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2192 - accuracy: 0.9395 - val_loss: 0.2203 - val_accuracy: 0.9404\n",
      "Epoch 240/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2191 - accuracy: 0.9395 - val_loss: 0.2208 - val_accuracy: 0.9404\n",
      "Epoch 241/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2191 - accuracy: 0.9395 - val_loss: 0.2206 - val_accuracy: 0.9404\n",
      "Epoch 242/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2191 - accuracy: 0.9395 - val_loss: 0.2202 - val_accuracy: 0.9404\n",
      "Epoch 243/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2191 - accuracy: 0.9395 - val_loss: 0.2205 - val_accuracy: 0.9404\n",
      "Epoch 244/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2190 - accuracy: 0.9395 - val_loss: 0.2208 - val_accuracy: 0.9404\n",
      "Epoch 245/500\n",
      "450/450 [==============================] - 0s 113us/step - loss: 0.2190 - accuracy: 0.9395 - val_loss: 0.2207 - val_accuracy: 0.9404\n",
      "Epoch 246/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2190 - accuracy: 0.9395 - val_loss: 0.2205 - val_accuracy: 0.9404\n",
      "Epoch 247/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2189 - accuracy: 0.9395 - val_loss: 0.2207 - val_accuracy: 0.9404\n",
      "Epoch 248/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2188 - accuracy: 0.9395 - val_loss: 0.2207 - val_accuracy: 0.9404\n",
      "Epoch 249/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2188 - accuracy: 0.9395 - val_loss: 0.2206 - val_accuracy: 0.9404\n",
      "Epoch 250/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2188 - accuracy: 0.9395 - val_loss: 0.2203 - val_accuracy: 0.9404\n",
      "Epoch 251/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2187 - accuracy: 0.9395 - val_loss: 0.2202 - val_accuracy: 0.9404\n",
      "Epoch 252/500\n",
      "450/450 [==============================] - 0s 95us/step - loss: 0.2186 - accuracy: 0.9395 - val_loss: 0.2200 - val_accuracy: 0.9404\n",
      "Epoch 253/500\n",
      "450/450 [==============================] - 0s 92us/step - loss: 0.2186 - accuracy: 0.9395 - val_loss: 0.2197 - val_accuracy: 0.9404\n",
      "Epoch 254/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2186 - accuracy: 0.9395 - val_loss: 0.2198 - val_accuracy: 0.9404\n",
      "Epoch 255/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2186 - accuracy: 0.9395 - val_loss: 0.2198 - val_accuracy: 0.9404\n",
      "Epoch 256/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2186 - accuracy: 0.9395 - val_loss: 0.2194 - val_accuracy: 0.9404\n",
      "Epoch 257/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2185 - accuracy: 0.9395 - val_loss: 0.2199 - val_accuracy: 0.9404\n",
      "Epoch 258/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2185 - accuracy: 0.9395 - val_loss: 0.2194 - val_accuracy: 0.9404\n",
      "Epoch 259/500\n",
      "450/450 [==============================] - 0s 92us/step - loss: 0.2183 - accuracy: 0.9395 - val_loss: 0.2194 - val_accuracy: 0.9404\n",
      "Epoch 260/500\n",
      "450/450 [==============================] - 0s 100us/step - loss: 0.2183 - accuracy: 0.9395 - val_loss: 0.2196 - val_accuracy: 0.9404\n",
      "Epoch 261/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2182 - accuracy: 0.9395 - val_loss: 0.2196 - val_accuracy: 0.9404\n",
      "Epoch 262/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2182 - accuracy: 0.9395 - val_loss: 0.2200 - val_accuracy: 0.9404\n",
      "Epoch 263/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2181 - accuracy: 0.9395 - val_loss: 0.2200 - val_accuracy: 0.9404\n",
      "Epoch 264/500\n",
      "450/450 [==============================] - 0s 92us/step - loss: 0.2183 - accuracy: 0.9395 - val_loss: 0.2198 - val_accuracy: 0.9404\n",
      "Epoch 265/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2181 - accuracy: 0.9395 - val_loss: 0.2199 - val_accuracy: 0.9404\n",
      "Epoch 266/500\n",
      "450/450 [==============================] - 0s 101us/step - loss: 0.2180 - accuracy: 0.9395 - val_loss: 0.2198 - val_accuracy: 0.9404\n",
      "Epoch 267/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2180 - accuracy: 0.9395 - val_loss: 0.2193 - val_accuracy: 0.9404\n",
      "Epoch 268/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2179 - accuracy: 0.9395 - val_loss: 0.2193 - val_accuracy: 0.9404\n",
      "Epoch 269/500\n",
      "450/450 [==============================] - 0s 97us/step - loss: 0.2179 - accuracy: 0.9395 - val_loss: 0.2195 - val_accuracy: 0.9404\n",
      "Epoch 270/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2178 - accuracy: 0.9395 - val_loss: 0.2192 - val_accuracy: 0.9404\n",
      "Epoch 271/500\n",
      "450/450 [==============================] - 0s 92us/step - loss: 0.2177 - accuracy: 0.9395 - val_loss: 0.2194 - val_accuracy: 0.9404\n",
      "Epoch 272/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2177 - accuracy: 0.9395 - val_loss: 0.2194 - val_accuracy: 0.9404\n",
      "Epoch 273/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2177 - accuracy: 0.9395 - val_loss: 0.2194 - val_accuracy: 0.9404\n",
      "Epoch 274/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2176 - accuracy: 0.9395 - val_loss: 0.2193 - val_accuracy: 0.9404\n",
      "Epoch 275/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2175 - accuracy: 0.9395 - val_loss: 0.2190 - val_accuracy: 0.9404\n",
      "Epoch 276/500\n",
      "450/450 [==============================] - 0s 95us/step - loss: 0.2174 - accuracy: 0.9395 - val_loss: 0.2194 - val_accuracy: 0.9404\n",
      "Epoch 277/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2174 - accuracy: 0.9395 - val_loss: 0.2195 - val_accuracy: 0.9404\n",
      "Epoch 278/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2174 - accuracy: 0.9395 - val_loss: 0.2194 - val_accuracy: 0.9404\n",
      "Epoch 279/500\n",
      "450/450 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.93 - 0s 91us/step - loss: 0.2173 - accuracy: 0.9395 - val_loss: 0.2197 - val_accuracy: 0.9404\n",
      "Epoch 280/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2173 - accuracy: 0.9395 - val_loss: 0.2195 - val_accuracy: 0.9404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2172 - accuracy: 0.9395 - val_loss: 0.2193 - val_accuracy: 0.9404\n",
      "Epoch 282/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2172 - accuracy: 0.9395 - val_loss: 0.2190 - val_accuracy: 0.9404\n",
      "Epoch 283/500\n",
      "450/450 [==============================] - 0s 97us/step - loss: 0.2171 - accuracy: 0.9395 - val_loss: 0.2195 - val_accuracy: 0.9404\n",
      "Epoch 284/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2170 - accuracy: 0.9395 - val_loss: 0.2187 - val_accuracy: 0.9404\n",
      "Epoch 285/500\n",
      "450/450 [==============================] - 0s 99us/step - loss: 0.2169 - accuracy: 0.9395 - val_loss: 0.2190 - val_accuracy: 0.9404\n",
      "Epoch 286/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2170 - accuracy: 0.9395 - val_loss: 0.2185 - val_accuracy: 0.9404\n",
      "Epoch 287/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2168 - accuracy: 0.9395 - val_loss: 0.2184 - val_accuracy: 0.9404\n",
      "Epoch 288/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2168 - accuracy: 0.9395 - val_loss: 0.2185 - val_accuracy: 0.9404\n",
      "Epoch 289/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2168 - accuracy: 0.9395 - val_loss: 0.2185 - val_accuracy: 0.9404\n",
      "Epoch 290/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2167 - accuracy: 0.9395 - val_loss: 0.2182 - val_accuracy: 0.9404\n",
      "Epoch 291/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2166 - accuracy: 0.9395 - val_loss: 0.2183 - val_accuracy: 0.9404\n",
      "Epoch 292/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2165 - accuracy: 0.9395 - val_loss: 0.2185 - val_accuracy: 0.9404\n",
      "Epoch 293/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2165 - accuracy: 0.9395 - val_loss: 0.2182 - val_accuracy: 0.9404\n",
      "Epoch 294/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2164 - accuracy: 0.9395 - val_loss: 0.2178 - val_accuracy: 0.9404\n",
      "Epoch 295/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2164 - accuracy: 0.9395 - val_loss: 0.2181 - val_accuracy: 0.9404\n",
      "Epoch 296/500\n",
      "450/450 [==============================] - 0s 97us/step - loss: 0.2163 - accuracy: 0.9395 - val_loss: 0.2180 - val_accuracy: 0.9404\n",
      "Epoch 297/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2162 - accuracy: 0.9395 - val_loss: 0.2176 - val_accuracy: 0.9404\n",
      "Epoch 298/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2162 - accuracy: 0.9395 - val_loss: 0.2177 - val_accuracy: 0.9404\n",
      "Epoch 299/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2161 - accuracy: 0.9395 - val_loss: 0.2175 - val_accuracy: 0.9404\n",
      "Epoch 300/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2162 - accuracy: 0.9395 - val_loss: 0.2178 - val_accuracy: 0.9404\n",
      "Epoch 301/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2161 - accuracy: 0.9395 - val_loss: 0.2180 - val_accuracy: 0.9404\n",
      "Epoch 302/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2159 - accuracy: 0.9395 - val_loss: 0.2178 - val_accuracy: 0.9404\n",
      "Epoch 303/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2159 - accuracy: 0.9395 - val_loss: 0.2181 - val_accuracy: 0.9404\n",
      "Epoch 304/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2159 - accuracy: 0.9395 - val_loss: 0.2182 - val_accuracy: 0.9404\n",
      "Epoch 305/500\n",
      "450/450 [==============================] - 0s 92us/step - loss: 0.2158 - accuracy: 0.9395 - val_loss: 0.2179 - val_accuracy: 0.9404\n",
      "Epoch 306/500\n",
      "450/450 [==============================] - 0s 100us/step - loss: 0.2157 - accuracy: 0.9395 - val_loss: 0.2177 - val_accuracy: 0.9404\n",
      "Epoch 307/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2156 - accuracy: 0.9395 - val_loss: 0.2173 - val_accuracy: 0.9404\n",
      "Epoch 308/500\n",
      "450/450 [==============================] - 0s 95us/step - loss: 0.2155 - accuracy: 0.9395 - val_loss: 0.2176 - val_accuracy: 0.9404\n",
      "Epoch 309/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2155 - accuracy: 0.9395 - val_loss: 0.2174 - val_accuracy: 0.9404\n",
      "Epoch 310/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2154 - accuracy: 0.9395 - val_loss: 0.2175 - val_accuracy: 0.9404\n",
      "Epoch 311/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2153 - accuracy: 0.9395 - val_loss: 0.2177 - val_accuracy: 0.9404\n",
      "Epoch 312/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2153 - accuracy: 0.9395 - val_loss: 0.2179 - val_accuracy: 0.9404\n",
      "Epoch 313/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2152 - accuracy: 0.9395 - val_loss: 0.2176 - val_accuracy: 0.9404\n",
      "Epoch 314/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2151 - accuracy: 0.9395 - val_loss: 0.2176 - val_accuracy: 0.9404\n",
      "Epoch 315/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2150 - accuracy: 0.9395 - val_loss: 0.2175 - val_accuracy: 0.9404\n",
      "Epoch 316/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2149 - accuracy: 0.9395 - val_loss: 0.2169 - val_accuracy: 0.9404\n",
      "Epoch 317/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2149 - accuracy: 0.9395 - val_loss: 0.2173 - val_accuracy: 0.9404\n",
      "Epoch 318/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2149 - accuracy: 0.9395 - val_loss: 0.2172 - val_accuracy: 0.9404\n",
      "Epoch 319/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2148 - accuracy: 0.9395 - val_loss: 0.2170 - val_accuracy: 0.9404\n",
      "Epoch 320/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2147 - accuracy: 0.9395 - val_loss: 0.2164 - val_accuracy: 0.9404\n",
      "Epoch 321/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2147 - accuracy: 0.9395 - val_loss: 0.2169 - val_accuracy: 0.9404\n",
      "Epoch 322/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2146 - accuracy: 0.9395 - val_loss: 0.2170 - val_accuracy: 0.9404\n",
      "Epoch 323/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2145 - accuracy: 0.9395 - val_loss: 0.2173 - val_accuracy: 0.9404\n",
      "Epoch 324/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2144 - accuracy: 0.9395 - val_loss: 0.2170 - val_accuracy: 0.9404\n",
      "Epoch 325/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2143 - accuracy: 0.9395 - val_loss: 0.2167 - val_accuracy: 0.9404\n",
      "Epoch 326/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2142 - accuracy: 0.9395 - val_loss: 0.2166 - val_accuracy: 0.9404\n",
      "Epoch 327/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2142 - accuracy: 0.9395 - val_loss: 0.2167 - val_accuracy: 0.9404\n",
      "Epoch 328/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2142 - accuracy: 0.9395 - val_loss: 0.2170 - val_accuracy: 0.9404\n",
      "Epoch 329/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2141 - accuracy: 0.9395 - val_loss: 0.2170 - val_accuracy: 0.9404\n",
      "Epoch 330/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2141 - accuracy: 0.9395 - val_loss: 0.2165 - val_accuracy: 0.9404\n",
      "Epoch 331/500\n",
      "450/450 [==============================] - 0s 90us/step - loss: 0.2139 - accuracy: 0.9395 - val_loss: 0.2166 - val_accuracy: 0.9404\n",
      "Epoch 332/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2139 - accuracy: 0.9395 - val_loss: 0.2165 - val_accuracy: 0.9404\n",
      "Epoch 333/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2138 - accuracy: 0.9395 - val_loss: 0.2168 - val_accuracy: 0.9404\n",
      "Epoch 334/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2138 - accuracy: 0.9395 - val_loss: 0.2168 - val_accuracy: 0.9404\n",
      "Epoch 335/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2137 - accuracy: 0.9395 - val_loss: 0.2167 - val_accuracy: 0.9404\n",
      "Epoch 336/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2136 - accuracy: 0.9395 - val_loss: 0.2161 - val_accuracy: 0.9404\n",
      "Epoch 337/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 91us/step - loss: 0.2135 - accuracy: 0.9395 - val_loss: 0.2163 - val_accuracy: 0.9404\n",
      "Epoch 338/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2135 - accuracy: 0.9395 - val_loss: 0.2161 - val_accuracy: 0.9404\n",
      "Epoch 339/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2133 - accuracy: 0.9395 - val_loss: 0.2157 - val_accuracy: 0.9404\n",
      "Epoch 340/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2133 - accuracy: 0.9395 - val_loss: 0.2154 - val_accuracy: 0.9404\n",
      "Epoch 341/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2132 - accuracy: 0.9395 - val_loss: 0.2157 - val_accuracy: 0.9404\n",
      "Epoch 342/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2133 - accuracy: 0.9395 - val_loss: 0.2156 - val_accuracy: 0.9404\n",
      "Epoch 343/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2131 - accuracy: 0.9395 - val_loss: 0.2155 - val_accuracy: 0.9404\n",
      "Epoch 344/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2130 - accuracy: 0.9395 - val_loss: 0.2155 - val_accuracy: 0.9404\n",
      "Epoch 345/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2129 - accuracy: 0.9395 - val_loss: 0.2158 - val_accuracy: 0.9404\n",
      "Epoch 346/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2129 - accuracy: 0.9395 - val_loss: 0.2160 - val_accuracy: 0.9404\n",
      "Epoch 347/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2128 - accuracy: 0.9395 - val_loss: 0.2157 - val_accuracy: 0.9404\n",
      "Epoch 348/500\n",
      "450/450 [==============================] - 0s 92us/step - loss: 0.2127 - accuracy: 0.9395 - val_loss: 0.2154 - val_accuracy: 0.9404\n",
      "Epoch 349/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2126 - accuracy: 0.9395 - val_loss: 0.2158 - val_accuracy: 0.9404\n",
      "Epoch 350/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2126 - accuracy: 0.9395 - val_loss: 0.2156 - val_accuracy: 0.9404\n",
      "Epoch 351/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2125 - accuracy: 0.9395 - val_loss: 0.2161 - val_accuracy: 0.9404\n",
      "Epoch 352/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2126 - accuracy: 0.9395 - val_loss: 0.2157 - val_accuracy: 0.9404\n",
      "Epoch 353/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2124 - accuracy: 0.9395 - val_loss: 0.2157 - val_accuracy: 0.9404\n",
      "Epoch 354/500\n",
      "450/450 [==============================] - 0s 92us/step - loss: 0.2123 - accuracy: 0.9395 - val_loss: 0.2156 - val_accuracy: 0.9404\n",
      "Epoch 355/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2122 - accuracy: 0.9395 - val_loss: 0.2153 - val_accuracy: 0.9404\n",
      "Epoch 356/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2121 - accuracy: 0.9395 - val_loss: 0.2153 - val_accuracy: 0.9404\n",
      "Epoch 357/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2120 - accuracy: 0.9395 - val_loss: 0.2154 - val_accuracy: 0.9404\n",
      "Epoch 358/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2119 - accuracy: 0.9395 - val_loss: 0.2151 - val_accuracy: 0.9404\n",
      "Epoch 359/500\n",
      "450/450 [==============================] - 0s 84us/step - loss: 0.2119 - accuracy: 0.9395 - val_loss: 0.2151 - val_accuracy: 0.9404\n",
      "Epoch 360/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2118 - accuracy: 0.9395 - val_loss: 0.2149 - val_accuracy: 0.9404\n",
      "Epoch 361/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2117 - accuracy: 0.9395 - val_loss: 0.2146 - val_accuracy: 0.9404\n",
      "Epoch 362/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2116 - accuracy: 0.9395 - val_loss: 0.2146 - val_accuracy: 0.9404\n",
      "Epoch 363/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2115 - accuracy: 0.9395 - val_loss: 0.2148 - val_accuracy: 0.9404\n",
      "Epoch 364/500\n",
      "450/450 [==============================] - 0s 100us/step - loss: 0.2114 - accuracy: 0.9395 - val_loss: 0.2147 - val_accuracy: 0.9404\n",
      "Epoch 365/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2113 - accuracy: 0.9395 - val_loss: 0.2151 - val_accuracy: 0.9404\n",
      "Epoch 366/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2114 - accuracy: 0.9395 - val_loss: 0.2146 - val_accuracy: 0.9404\n",
      "Epoch 367/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2112 - accuracy: 0.9395 - val_loss: 0.2146 - val_accuracy: 0.9404\n",
      "Epoch 368/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2112 - accuracy: 0.9395 - val_loss: 0.2147 - val_accuracy: 0.9404\n",
      "Epoch 369/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2110 - accuracy: 0.9395 - val_loss: 0.2147 - val_accuracy: 0.9404\n",
      "Epoch 370/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2111 - accuracy: 0.9395 - val_loss: 0.2149 - val_accuracy: 0.9404\n",
      "Epoch 371/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2110 - accuracy: 0.9395 - val_loss: 0.2149 - val_accuracy: 0.9404\n",
      "Epoch 372/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2110 - accuracy: 0.9395 - val_loss: 0.2150 - val_accuracy: 0.9404\n",
      "Epoch 373/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2108 - accuracy: 0.9395 - val_loss: 0.2145 - val_accuracy: 0.9404\n",
      "Epoch 374/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2108 - accuracy: 0.9395 - val_loss: 0.2142 - val_accuracy: 0.9404\n",
      "Epoch 375/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2107 - accuracy: 0.9395 - val_loss: 0.2138 - val_accuracy: 0.9404\n",
      "Epoch 376/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2106 - accuracy: 0.9395 - val_loss: 0.2140 - val_accuracy: 0.9404\n",
      "Epoch 377/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2106 - accuracy: 0.9395 - val_loss: 0.2138 - val_accuracy: 0.9404\n",
      "Epoch 378/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2104 - accuracy: 0.9395 - val_loss: 0.2135 - val_accuracy: 0.9404\n",
      "Epoch 379/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2103 - accuracy: 0.9395 - val_loss: 0.2137 - val_accuracy: 0.9404\n",
      "Epoch 380/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2102 - accuracy: 0.9395 - val_loss: 0.2139 - val_accuracy: 0.9404\n",
      "Epoch 381/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2103 - accuracy: 0.9395 - val_loss: 0.2136 - val_accuracy: 0.9404\n",
      "Epoch 382/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2102 - accuracy: 0.9395 - val_loss: 0.2136 - val_accuracy: 0.9404\n",
      "Epoch 383/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2102 - accuracy: 0.9395 - val_loss: 0.2132 - val_accuracy: 0.9404\n",
      "Epoch 384/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2100 - accuracy: 0.9395 - val_loss: 0.2133 - val_accuracy: 0.9404\n",
      "Epoch 385/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2099 - accuracy: 0.9395 - val_loss: 0.2130 - val_accuracy: 0.9404\n",
      "Epoch 386/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2098 - accuracy: 0.9395 - val_loss: 0.2129 - val_accuracy: 0.9404\n",
      "Epoch 387/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2098 - accuracy: 0.9395 - val_loss: 0.2130 - val_accuracy: 0.9404\n",
      "Epoch 388/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2096 - accuracy: 0.9395 - val_loss: 0.2127 - val_accuracy: 0.9404\n",
      "Epoch 389/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2096 - accuracy: 0.9395 - val_loss: 0.2134 - val_accuracy: 0.9404\n",
      "Epoch 390/500\n",
      "450/450 [==============================] - 0s 90us/step - loss: 0.2096 - accuracy: 0.9395 - val_loss: 0.2132 - val_accuracy: 0.9404\n",
      "Epoch 391/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2096 - accuracy: 0.9395 - val_loss: 0.2136 - val_accuracy: 0.9404\n",
      "Epoch 392/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2095 - accuracy: 0.9395 - val_loss: 0.2132 - val_accuracy: 0.9404\n",
      "Epoch 393/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 87us/step - loss: 0.2093 - accuracy: 0.9395 - val_loss: 0.2127 - val_accuracy: 0.9404\n",
      "Epoch 394/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2092 - accuracy: 0.9395 - val_loss: 0.2130 - val_accuracy: 0.9404\n",
      "Epoch 395/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2092 - accuracy: 0.9396 - val_loss: 0.2134 - val_accuracy: 0.9404\n",
      "Epoch 396/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2091 - accuracy: 0.9395 - val_loss: 0.2137 - val_accuracy: 0.9404\n",
      "Epoch 397/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2091 - accuracy: 0.9395 - val_loss: 0.2135 - val_accuracy: 0.9404\n",
      "Epoch 398/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2090 - accuracy: 0.9395 - val_loss: 0.2132 - val_accuracy: 0.9404\n",
      "Epoch 399/500\n",
      "450/450 [==============================] - 0s 90us/step - loss: 0.2088 - accuracy: 0.9396 - val_loss: 0.2132 - val_accuracy: 0.9404\n",
      "Epoch 400/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2087 - accuracy: 0.9396 - val_loss: 0.2127 - val_accuracy: 0.9404\n",
      "Epoch 401/500\n",
      "450/450 [==============================] - 0s 92us/step - loss: 0.2087 - accuracy: 0.9396 - val_loss: 0.2129 - val_accuracy: 0.9404\n",
      "Epoch 402/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2087 - accuracy: 0.9396 - val_loss: 0.2134 - val_accuracy: 0.9404\n",
      "Epoch 403/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2087 - accuracy: 0.9395 - val_loss: 0.2126 - val_accuracy: 0.9404\n",
      "Epoch 404/500\n",
      "450/450 [==============================] - 0s 84us/step - loss: 0.2085 - accuracy: 0.9396 - val_loss: 0.2124 - val_accuracy: 0.9404\n",
      "Epoch 405/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2084 - accuracy: 0.9396 - val_loss: 0.2122 - val_accuracy: 0.9404\n",
      "Epoch 406/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2083 - accuracy: 0.9396 - val_loss: 0.2119 - val_accuracy: 0.9404\n",
      "Epoch 407/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2081 - accuracy: 0.9396 - val_loss: 0.2121 - val_accuracy: 0.9404\n",
      "Epoch 408/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2081 - accuracy: 0.9396 - val_loss: 0.2120 - val_accuracy: 0.9404\n",
      "Epoch 409/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2081 - accuracy: 0.9396 - val_loss: 0.2123 - val_accuracy: 0.9404\n",
      "Epoch 410/500\n",
      "450/450 [==============================] - 0s 90us/step - loss: 0.2081 - accuracy: 0.9396 - val_loss: 0.2117 - val_accuracy: 0.9404\n",
      "Epoch 411/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2079 - accuracy: 0.9396 - val_loss: 0.2117 - val_accuracy: 0.9404\n",
      "Epoch 412/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2078 - accuracy: 0.9396 - val_loss: 0.2118 - val_accuracy: 0.9404\n",
      "Epoch 413/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2077 - accuracy: 0.9396 - val_loss: 0.2120 - val_accuracy: 0.9404\n",
      "Epoch 414/500\n",
      "450/450 [==============================] - 0s 97us/step - loss: 0.2076 - accuracy: 0.9397 - val_loss: 0.2112 - val_accuracy: 0.9404\n",
      "Epoch 415/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2075 - accuracy: 0.9396 - val_loss: 0.2110 - val_accuracy: 0.9404\n",
      "Epoch 416/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2075 - accuracy: 0.9396 - val_loss: 0.2115 - val_accuracy: 0.9404\n",
      "Epoch 417/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2074 - accuracy: 0.9396 - val_loss: 0.2119 - val_accuracy: 0.9404\n",
      "Epoch 418/500\n",
      "450/450 [==============================] - 0s 86us/step - loss: 0.2074 - accuracy: 0.9396 - val_loss: 0.2114 - val_accuracy: 0.9403\n",
      "Epoch 419/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2072 - accuracy: 0.9396 - val_loss: 0.2116 - val_accuracy: 0.9404\n",
      "Epoch 420/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2070 - accuracy: 0.9397 - val_loss: 0.2114 - val_accuracy: 0.9404\n",
      "Epoch 421/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2071 - accuracy: 0.9397 - val_loss: 0.2111 - val_accuracy: 0.9404\n",
      "Epoch 422/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2069 - accuracy: 0.9397 - val_loss: 0.2104 - val_accuracy: 0.9404\n",
      "Epoch 423/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2068 - accuracy: 0.9397 - val_loss: 0.2109 - val_accuracy: 0.9403\n",
      "Epoch 424/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2069 - accuracy: 0.9397 - val_loss: 0.2110 - val_accuracy: 0.9404\n",
      "Epoch 425/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2067 - accuracy: 0.9397 - val_loss: 0.2111 - val_accuracy: 0.9404\n",
      "Epoch 426/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2066 - accuracy: 0.9397 - val_loss: 0.2110 - val_accuracy: 0.9403\n",
      "Epoch 427/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2065 - accuracy: 0.9397 - val_loss: 0.2110 - val_accuracy: 0.9404\n",
      "Epoch 428/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2064 - accuracy: 0.9397 - val_loss: 0.2108 - val_accuracy: 0.9404\n",
      "Epoch 429/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2063 - accuracy: 0.9397 - val_loss: 0.2106 - val_accuracy: 0.9404\n",
      "Epoch 430/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2063 - accuracy: 0.9397 - val_loss: 0.2106 - val_accuracy: 0.9404\n",
      "Epoch 431/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2062 - accuracy: 0.9397 - val_loss: 0.2105 - val_accuracy: 0.9404\n",
      "Epoch 432/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2061 - accuracy: 0.9397 - val_loss: 0.2105 - val_accuracy: 0.9403\n",
      "Epoch 433/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2059 - accuracy: 0.9396 - val_loss: 0.2106 - val_accuracy: 0.9404\n",
      "Epoch 434/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2058 - accuracy: 0.9397 - val_loss: 0.2108 - val_accuracy: 0.9404\n",
      "Epoch 435/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2057 - accuracy: 0.9397 - val_loss: 0.2104 - val_accuracy: 0.9404\n",
      "Epoch 436/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2056 - accuracy: 0.9397 - val_loss: 0.2107 - val_accuracy: 0.9404\n",
      "Epoch 437/500\n",
      "450/450 [==============================] - 0s 92us/step - loss: 0.2055 - accuracy: 0.9397 - val_loss: 0.2104 - val_accuracy: 0.9404\n",
      "Epoch 438/500\n",
      "450/450 [==============================] - 0s 92us/step - loss: 0.2055 - accuracy: 0.9397 - val_loss: 0.2110 - val_accuracy: 0.9404\n",
      "Epoch 439/500\n",
      "450/450 [==============================] - 0s 97us/step - loss: 0.2055 - accuracy: 0.9397 - val_loss: 0.2104 - val_accuracy: 0.9403\n",
      "Epoch 440/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2054 - accuracy: 0.9396 - val_loss: 0.2103 - val_accuracy: 0.9403\n",
      "Epoch 441/500\n",
      "450/450 [==============================] - 0s 90us/step - loss: 0.2052 - accuracy: 0.9396 - val_loss: 0.2108 - val_accuracy: 0.9404\n",
      "Epoch 442/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2052 - accuracy: 0.9397 - val_loss: 0.2106 - val_accuracy: 0.9404\n",
      "Epoch 443/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2050 - accuracy: 0.9397 - val_loss: 0.2108 - val_accuracy: 0.9404\n",
      "Epoch 444/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2050 - accuracy: 0.9397 - val_loss: 0.2105 - val_accuracy: 0.9404\n",
      "Epoch 445/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2048 - accuracy: 0.9397 - val_loss: 0.2099 - val_accuracy: 0.9404\n",
      "Epoch 446/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2047 - accuracy: 0.9397 - val_loss: 0.2095 - val_accuracy: 0.9404\n",
      "Epoch 447/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2045 - accuracy: 0.9397 - val_loss: 0.2099 - val_accuracy: 0.9404\n",
      "Epoch 448/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2045 - accuracy: 0.9397 - val_loss: 0.2097 - val_accuracy: 0.9404\n",
      "Epoch 449/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 0s 91us/step - loss: 0.2044 - accuracy: 0.9397 - val_loss: 0.2101 - val_accuracy: 0.9404\n",
      "Epoch 450/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2043 - accuracy: 0.9397 - val_loss: 0.2101 - val_accuracy: 0.9404\n",
      "Epoch 451/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2042 - accuracy: 0.9397 - val_loss: 0.2093 - val_accuracy: 0.9404\n",
      "Epoch 452/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2040 - accuracy: 0.9397 - val_loss: 0.2095 - val_accuracy: 0.9404\n",
      "Epoch 453/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2040 - accuracy: 0.9397 - val_loss: 0.2095 - val_accuracy: 0.9404\n",
      "Epoch 454/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2038 - accuracy: 0.9397 - val_loss: 0.2092 - val_accuracy: 0.9404\n",
      "Epoch 455/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.2038 - accuracy: 0.9396 - val_loss: 0.2091 - val_accuracy: 0.9404\n",
      "Epoch 456/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2036 - accuracy: 0.9396 - val_loss: 0.2092 - val_accuracy: 0.9403\n",
      "Epoch 457/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2036 - accuracy: 0.9396 - val_loss: 0.2089 - val_accuracy: 0.9404\n",
      "Epoch 458/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2033 - accuracy: 0.9396 - val_loss: 0.2094 - val_accuracy: 0.9404\n",
      "Epoch 459/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2034 - accuracy: 0.9397 - val_loss: 0.2092 - val_accuracy: 0.9404\n",
      "Epoch 460/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2031 - accuracy: 0.9397 - val_loss: 0.2088 - val_accuracy: 0.9404\n",
      "Epoch 461/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2030 - accuracy: 0.9396 - val_loss: 0.2088 - val_accuracy: 0.9404\n",
      "Epoch 462/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2029 - accuracy: 0.9397 - val_loss: 0.2091 - val_accuracy: 0.9403\n",
      "Epoch 463/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2029 - accuracy: 0.9397 - val_loss: 0.2090 - val_accuracy: 0.9404\n",
      "Epoch 464/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2026 - accuracy: 0.9396 - val_loss: 0.2084 - val_accuracy: 0.9404\n",
      "Epoch 465/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2025 - accuracy: 0.9397 - val_loss: 0.2087 - val_accuracy: 0.9404\n",
      "Epoch 466/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2025 - accuracy: 0.9396 - val_loss: 0.2086 - val_accuracy: 0.9404\n",
      "Epoch 467/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2024 - accuracy: 0.9396 - val_loss: 0.2084 - val_accuracy: 0.9404\n",
      "Epoch 468/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2023 - accuracy: 0.9396 - val_loss: 0.2079 - val_accuracy: 0.9404\n",
      "Epoch 469/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2021 - accuracy: 0.9396 - val_loss: 0.2078 - val_accuracy: 0.9404\n",
      "Epoch 470/500\n",
      "450/450 [==============================] - 0s 98us/step - loss: 0.2020 - accuracy: 0.9396 - val_loss: 0.2075 - val_accuracy: 0.9404\n",
      "Epoch 471/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2019 - accuracy: 0.9397 - val_loss: 0.2077 - val_accuracy: 0.9404\n",
      "Epoch 472/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2018 - accuracy: 0.9396 - val_loss: 0.2079 - val_accuracy: 0.9404\n",
      "Epoch 473/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2017 - accuracy: 0.9396 - val_loss: 0.2082 - val_accuracy: 0.9404\n",
      "Epoch 474/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2016 - accuracy: 0.9396 - val_loss: 0.2081 - val_accuracy: 0.9404\n",
      "Epoch 475/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2015 - accuracy: 0.9397 - val_loss: 0.2080 - val_accuracy: 0.9404\n",
      "Epoch 476/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2014 - accuracy: 0.9396 - val_loss: 0.2075 - val_accuracy: 0.9404\n",
      "Epoch 477/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2013 - accuracy: 0.9396 - val_loss: 0.2075 - val_accuracy: 0.9403\n",
      "Epoch 478/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2012 - accuracy: 0.9396 - val_loss: 0.2075 - val_accuracy: 0.9403\n",
      "Epoch 479/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.2011 - accuracy: 0.9396 - val_loss: 0.2073 - val_accuracy: 0.9403\n",
      "Epoch 480/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.2009 - accuracy: 0.9396 - val_loss: 0.2074 - val_accuracy: 0.9403\n",
      "Epoch 481/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2008 - accuracy: 0.9397 - val_loss: 0.2075 - val_accuracy: 0.9404\n",
      "Epoch 482/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2006 - accuracy: 0.9397 - val_loss: 0.2076 - val_accuracy: 0.9404\n",
      "Epoch 483/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2007 - accuracy: 0.9396 - val_loss: 0.2074 - val_accuracy: 0.9405\n",
      "Epoch 484/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.2005 - accuracy: 0.9396 - val_loss: 0.2072 - val_accuracy: 0.9404\n",
      "Epoch 485/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2003 - accuracy: 0.9396 - val_loss: 0.2067 - val_accuracy: 0.9404\n",
      "Epoch 486/500\n",
      "450/450 [==============================] - 0s 107us/step - loss: 0.2001 - accuracy: 0.9396 - val_loss: 0.2071 - val_accuracy: 0.9404\n",
      "Epoch 487/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.2002 - accuracy: 0.9396 - val_loss: 0.2065 - val_accuracy: 0.9404\n",
      "Epoch 488/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.1999 - accuracy: 0.9397 - val_loss: 0.2060 - val_accuracy: 0.9405\n",
      "Epoch 489/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.1999 - accuracy: 0.9396 - val_loss: 0.2063 - val_accuracy: 0.9404\n",
      "Epoch 490/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.1998 - accuracy: 0.9396 - val_loss: 0.2065 - val_accuracy: 0.9403\n",
      "Epoch 491/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.1997 - accuracy: 0.9395 - val_loss: 0.2064 - val_accuracy: 0.9404\n",
      "Epoch 492/500\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.1995 - accuracy: 0.9396 - val_loss: 0.2072 - val_accuracy: 0.9404\n",
      "Epoch 493/500\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.1994 - accuracy: 0.9396 - val_loss: 0.2069 - val_accuracy: 0.9403\n",
      "Epoch 494/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.1992 - accuracy: 0.9396 - val_loss: 0.2066 - val_accuracy: 0.9403\n",
      "Epoch 495/500\n",
      "450/450 [==============================] - 0s 96us/step - loss: 0.1991 - accuracy: 0.9396 - val_loss: 0.2064 - val_accuracy: 0.9403\n",
      "Epoch 496/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.1990 - accuracy: 0.9397 - val_loss: 0.2062 - val_accuracy: 0.9403\n",
      "Epoch 497/500\n",
      "450/450 [==============================] - 0s 87us/step - loss: 0.1988 - accuracy: 0.9396 - val_loss: 0.2062 - val_accuracy: 0.9403\n",
      "Epoch 498/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.1987 - accuracy: 0.9396 - val_loss: 0.2060 - val_accuracy: 0.9403\n",
      "Epoch 499/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.1986 - accuracy: 0.9396 - val_loss: 0.2057 - val_accuracy: 0.9403\n",
      "Epoch 500/500\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.1985 - accuracy: 0.9395 - val_loss: 0.2055 - val_accuracy: 0.9403\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_151 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 240)               6000      \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 240)               57840     \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 240)               57840     \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 240)               57840     \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 51)                12291     \n",
      "=================================================================\n",
      "Total params: 192,411\n",
      "Trainable params: 192,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = x_d5.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = y_d5.copy()\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "train_input_d5 = inputs[:,2:]\n",
    "train_output_d5 = targets\n",
    "\n",
    "x_train_d5, x_test_d5, Y_train_d5, Y_test_d5 = train_test_split(train_input_d5, train_output_d5, train_size=0.75, shuffle=True)\n",
    "\n",
    "model_d5 = compile_FFNN_cv_model_DepthFive(5)\n",
    "print(\"Fit model on training data\")\n",
    "history = model_d5.fit(\n",
    "    x=x_train_d5,\n",
    "    y=Y_train_d5,\n",
    "    validation_split=.25,\n",
    "    epochs=500\n",
    ")\n",
    "model_d5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Epoch vs. Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss (MSE)')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Depth 5 Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Epoch vs. Accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Depth 5 Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d5.save(\"model_d5.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/800\n",
      "480/480 [==============================] - 0s 376us/step - loss: 0.6858 - accuracy: 0.5593 - val_loss: 0.6774 - val_accuracy: 0.6239\n",
      "Epoch 2/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.6692 - accuracy: 0.6532 - val_loss: 0.6601 - val_accuracy: 0.6914\n",
      "Epoch 3/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.6491 - accuracy: 0.7337 - val_loss: 0.6361 - val_accuracy: 0.7836\n",
      "Epoch 4/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.6183 - accuracy: 0.8165 - val_loss: 0.5958 - val_accuracy: 0.8526\n",
      "Epoch 5/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.5629 - accuracy: 0.8836 - val_loss: 0.5198 - val_accuracy: 0.9045\n",
      "Epoch 6/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.4608 - accuracy: 0.9124 - val_loss: 0.3907 - val_accuracy: 0.9218\n",
      "Epoch 7/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.3282 - accuracy: 0.9367 - val_loss: 0.2777 - val_accuracy: 0.9385\n",
      "Epoch 8/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2527 - accuracy: 0.9389 - val_loss: 0.2419 - val_accuracy: 0.9385\n",
      "Epoch 9/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2339 - accuracy: 0.9389 - val_loss: 0.2348 - val_accuracy: 0.9385\n",
      "Epoch 10/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2297 - accuracy: 0.9389 - val_loss: 0.2325 - val_accuracy: 0.9385\n",
      "Epoch 11/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2280 - accuracy: 0.9389 - val_loss: 0.2313 - val_accuracy: 0.9385\n",
      "Epoch 12/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2271 - accuracy: 0.9389 - val_loss: 0.2306 - val_accuracy: 0.9385\n",
      "Epoch 13/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2265 - accuracy: 0.9389 - val_loss: 0.2302 - val_accuracy: 0.9385\n",
      "Epoch 14/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2262 - accuracy: 0.9389 - val_loss: 0.2299 - val_accuracy: 0.9385\n",
      "Epoch 15/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2259 - accuracy: 0.9389 - val_loss: 0.2297 - val_accuracy: 0.9385\n",
      "Epoch 16/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2258 - accuracy: 0.9389 - val_loss: 0.2296 - val_accuracy: 0.9385\n",
      "Epoch 17/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2256 - accuracy: 0.9389 - val_loss: 0.2294 - val_accuracy: 0.9385\n",
      "Epoch 18/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2256 - accuracy: 0.9389 - val_loss: 0.2293 - val_accuracy: 0.9385\n",
      "Epoch 19/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2255 - accuracy: 0.9389 - val_loss: 0.2292 - val_accuracy: 0.9385\n",
      "Epoch 20/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2254 - accuracy: 0.9389 - val_loss: 0.2291 - val_accuracy: 0.9385\n",
      "Epoch 21/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2254 - accuracy: 0.9389 - val_loss: 0.2291 - val_accuracy: 0.9385\n",
      "Epoch 22/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2253 - accuracy: 0.9389 - val_loss: 0.2290 - val_accuracy: 0.9385\n",
      "Epoch 23/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2253 - accuracy: 0.9389 - val_loss: 0.2289 - val_accuracy: 0.9385\n",
      "Epoch 24/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2253 - accuracy: 0.9389 - val_loss: 0.2289 - val_accuracy: 0.9385\n",
      "Epoch 25/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2252 - accuracy: 0.9389 - val_loss: 0.2288 - val_accuracy: 0.9385\n",
      "Epoch 26/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2252 - accuracy: 0.9389 - val_loss: 0.2288 - val_accuracy: 0.9385\n",
      "Epoch 27/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2251 - accuracy: 0.9389 - val_loss: 0.2287 - val_accuracy: 0.9385\n",
      "Epoch 28/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2251 - accuracy: 0.9389 - val_loss: 0.2287 - val_accuracy: 0.9385\n",
      "Epoch 29/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2250 - accuracy: 0.9389 - val_loss: 0.2287 - val_accuracy: 0.9385\n",
      "Epoch 30/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2250 - accuracy: 0.9389 - val_loss: 0.2286 - val_accuracy: 0.9385\n",
      "Epoch 31/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2250 - accuracy: 0.9389 - val_loss: 0.2286 - val_accuracy: 0.9385\n",
      "Epoch 32/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2250 - accuracy: 0.9389 - val_loss: 0.2286 - val_accuracy: 0.9385\n",
      "Epoch 33/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2249 - accuracy: 0.9389 - val_loss: 0.2286 - val_accuracy: 0.9385\n",
      "Epoch 34/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2249 - accuracy: 0.9389 - val_loss: 0.2285 - val_accuracy: 0.9385\n",
      "Epoch 35/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2249 - accuracy: 0.9389 - val_loss: 0.2285 - val_accuracy: 0.9385\n",
      "Epoch 36/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2248 - accuracy: 0.9389 - val_loss: 0.2285 - val_accuracy: 0.9385\n",
      "Epoch 37/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2248 - accuracy: 0.9389 - val_loss: 0.2285 - val_accuracy: 0.9385\n",
      "Epoch 38/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2248 - accuracy: 0.9389 - val_loss: 0.2284 - val_accuracy: 0.9385\n",
      "Epoch 39/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2248 - accuracy: 0.9389 - val_loss: 0.2284 - val_accuracy: 0.9385\n",
      "Epoch 40/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2247 - accuracy: 0.9389 - val_loss: 0.2284 - val_accuracy: 0.9385\n",
      "Epoch 41/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2247 - accuracy: 0.9389 - val_loss: 0.2284 - val_accuracy: 0.9385\n",
      "Epoch 42/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2247 - accuracy: 0.9389 - val_loss: 0.2283 - val_accuracy: 0.9385\n",
      "Epoch 43/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2247 - accuracy: 0.9389 - val_loss: 0.2283 - val_accuracy: 0.9385\n",
      "Epoch 44/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2247 - accuracy: 0.9389 - val_loss: 0.2283 - val_accuracy: 0.9385\n",
      "Epoch 45/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2246 - accuracy: 0.9389 - val_loss: 0.2283 - val_accuracy: 0.9385\n",
      "Epoch 46/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2246 - accuracy: 0.9389 - val_loss: 0.2282 - val_accuracy: 0.9385\n",
      "Epoch 47/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2246 - accuracy: 0.9389 - val_loss: 0.2282 - val_accuracy: 0.9385\n",
      "Epoch 48/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2246 - accuracy: 0.9389 - val_loss: 0.2282 - val_accuracy: 0.9385\n",
      "Epoch 49/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2245 - accuracy: 0.9389 - val_loss: 0.2282 - val_accuracy: 0.9385\n",
      "Epoch 50/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2245 - accuracy: 0.9389 - val_loss: 0.2282 - val_accuracy: 0.9385\n",
      "Epoch 51/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2244 - accuracy: 0.9389 - val_loss: 0.2282 - val_accuracy: 0.9385\n",
      "Epoch 52/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2244 - accuracy: 0.9389 - val_loss: 0.2281 - val_accuracy: 0.9385\n",
      "Epoch 53/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2244 - accuracy: 0.9389 - val_loss: 0.2281 - val_accuracy: 0.9385\n",
      "Epoch 54/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2244 - accuracy: 0.9389 - val_loss: 0.2281 - val_accuracy: 0.9385\n",
      "Epoch 55/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2244 - accuracy: 0.9389 - val_loss: 0.2281 - val_accuracy: 0.9385\n",
      "Epoch 56/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 90us/step - loss: 0.2243 - accuracy: 0.9389 - val_loss: 0.2280 - val_accuracy: 0.9385\n",
      "Epoch 57/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2243 - accuracy: 0.9389 - val_loss: 0.2280 - val_accuracy: 0.9385\n",
      "Epoch 58/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2243 - accuracy: 0.9389 - val_loss: 0.2280 - val_accuracy: 0.9385\n",
      "Epoch 59/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.2243 - accuracy: 0.9389 - val_loss: 0.2280 - val_accuracy: 0.9385\n",
      "Epoch 60/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2242 - accuracy: 0.9389 - val_loss: 0.2279 - val_accuracy: 0.9385\n",
      "Epoch 61/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2242 - accuracy: 0.9389 - val_loss: 0.2279 - val_accuracy: 0.9385\n",
      "Epoch 62/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2242 - accuracy: 0.9389 - val_loss: 0.2279 - val_accuracy: 0.9385\n",
      "Epoch 63/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2241 - accuracy: 0.9389 - val_loss: 0.2279 - val_accuracy: 0.9385\n",
      "Epoch 64/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2242 - accuracy: 0.9389 - val_loss: 0.2279 - val_accuracy: 0.9385\n",
      "Epoch 65/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2241 - accuracy: 0.9389 - val_loss: 0.2279 - val_accuracy: 0.9385\n",
      "Epoch 66/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2241 - accuracy: 0.9389 - val_loss: 0.2278 - val_accuracy: 0.9385\n",
      "Epoch 67/800\n",
      "480/480 [==============================] - 0s 75us/step - loss: 0.2241 - accuracy: 0.9389 - val_loss: 0.2278 - val_accuracy: 0.9385\n",
      "Epoch 68/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2240 - accuracy: 0.9389 - val_loss: 0.2278 - val_accuracy: 0.9385\n",
      "Epoch 69/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2240 - accuracy: 0.9389 - val_loss: 0.2278 - val_accuracy: 0.9385\n",
      "Epoch 70/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2240 - accuracy: 0.9389 - val_loss: 0.2277 - val_accuracy: 0.9385\n",
      "Epoch 71/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2240 - accuracy: 0.9389 - val_loss: 0.2277 - val_accuracy: 0.9385\n",
      "Epoch 72/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2239 - accuracy: 0.9389 - val_loss: 0.2277 - val_accuracy: 0.9385\n",
      "Epoch 73/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2239 - accuracy: 0.9389 - val_loss: 0.2277 - val_accuracy: 0.9385\n",
      "Epoch 74/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2239 - accuracy: 0.9389 - val_loss: 0.2277 - val_accuracy: 0.9385\n",
      "Epoch 75/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2239 - accuracy: 0.9389 - val_loss: 0.2276 - val_accuracy: 0.9385\n",
      "Epoch 76/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2238 - accuracy: 0.9389 - val_loss: 0.2276 - val_accuracy: 0.9385\n",
      "Epoch 77/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2238 - accuracy: 0.9389 - val_loss: 0.2276 - val_accuracy: 0.9385\n",
      "Epoch 78/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2238 - accuracy: 0.9389 - val_loss: 0.2275 - val_accuracy: 0.9385\n",
      "Epoch 79/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2238 - accuracy: 0.9389 - val_loss: 0.2275 - val_accuracy: 0.9385\n",
      "Epoch 80/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2237 - accuracy: 0.9389 - val_loss: 0.2275 - val_accuracy: 0.9385\n",
      "Epoch 81/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2238 - accuracy: 0.9389 - val_loss: 0.2275 - val_accuracy: 0.9385\n",
      "Epoch 82/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2237 - accuracy: 0.9389 - val_loss: 0.2274 - val_accuracy: 0.9385\n",
      "Epoch 83/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2237 - accuracy: 0.9389 - val_loss: 0.2274 - val_accuracy: 0.9385\n",
      "Epoch 84/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2237 - accuracy: 0.9389 - val_loss: 0.2274 - val_accuracy: 0.9385\n",
      "Epoch 85/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2236 - accuracy: 0.9389 - val_loss: 0.2274 - val_accuracy: 0.9385\n",
      "Epoch 86/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2236 - accuracy: 0.9389 - val_loss: 0.2274 - val_accuracy: 0.9385\n",
      "Epoch 87/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2236 - accuracy: 0.9389 - val_loss: 0.2274 - val_accuracy: 0.9385\n",
      "Epoch 88/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2236 - accuracy: 0.9389 - val_loss: 0.2273 - val_accuracy: 0.9385\n",
      "Epoch 89/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2235 - accuracy: 0.9389 - val_loss: 0.2273 - val_accuracy: 0.9385\n",
      "Epoch 90/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2235 - accuracy: 0.9389 - val_loss: 0.2273 - val_accuracy: 0.9385\n",
      "Epoch 91/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2235 - accuracy: 0.9389 - val_loss: 0.2273 - val_accuracy: 0.9385\n",
      "Epoch 92/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2235 - accuracy: 0.9389 - val_loss: 0.2273 - val_accuracy: 0.9385\n",
      "Epoch 93/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2234 - accuracy: 0.9389 - val_loss: 0.2273 - val_accuracy: 0.9385\n",
      "Epoch 94/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2234 - accuracy: 0.9389 - val_loss: 0.2272 - val_accuracy: 0.9385\n",
      "Epoch 95/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2233 - accuracy: 0.9389 - val_loss: 0.2272 - val_accuracy: 0.9385\n",
      "Epoch 96/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2234 - accuracy: 0.9389 - val_loss: 0.2272 - val_accuracy: 0.9385\n",
      "Epoch 97/800\n",
      "480/480 [==============================] - 0s 91us/step - loss: 0.2233 - accuracy: 0.9389 - val_loss: 0.2271 - val_accuracy: 0.9385\n",
      "Epoch 98/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2233 - accuracy: 0.9389 - val_loss: 0.2271 - val_accuracy: 0.9385\n",
      "Epoch 99/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2233 - accuracy: 0.9389 - val_loss: 0.2271 - val_accuracy: 0.9385\n",
      "Epoch 100/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2232 - accuracy: 0.9389 - val_loss: 0.2271 - val_accuracy: 0.9385\n",
      "Epoch 101/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2232 - accuracy: 0.9389 - val_loss: 0.2270 - val_accuracy: 0.9385\n",
      "Epoch 102/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2232 - accuracy: 0.9389 - val_loss: 0.2270 - val_accuracy: 0.9385\n",
      "Epoch 103/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2231 - accuracy: 0.9389 - val_loss: 0.2270 - val_accuracy: 0.9385\n",
      "Epoch 104/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2231 - accuracy: 0.9389 - val_loss: 0.2270 - val_accuracy: 0.9385\n",
      "Epoch 105/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2231 - accuracy: 0.9389 - val_loss: 0.2269 - val_accuracy: 0.9385\n",
      "Epoch 106/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2231 - accuracy: 0.9389 - val_loss: 0.2269 - val_accuracy: 0.9385\n",
      "Epoch 107/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2230 - accuracy: 0.9389 - val_loss: 0.2269 - val_accuracy: 0.9385\n",
      "Epoch 108/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2230 - accuracy: 0.9389 - val_loss: 0.2269 - val_accuracy: 0.9385\n",
      "Epoch 109/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2230 - accuracy: 0.9389 - val_loss: 0.2269 - val_accuracy: 0.9385\n",
      "Epoch 110/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2230 - accuracy: 0.9389 - val_loss: 0.2269 - val_accuracy: 0.9385\n",
      "Epoch 111/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2229 - accuracy: 0.9389 - val_loss: 0.2268 - val_accuracy: 0.9385\n",
      "Epoch 112/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.2229 - accuracy: 0.9389 - val_loss: 0.2268 - val_accuracy: 0.9385\n",
      "Epoch 113/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2229 - accuracy: 0.9389 - val_loss: 0.2268 - val_accuracy: 0.9385\n",
      "Epoch 114/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2229 - accuracy: 0.9389 - val_loss: 0.2267 - val_accuracy: 0.9385\n",
      "Epoch 115/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.2228 - accuracy: 0.9389 - val_loss: 0.2267 - val_accuracy: 0.9385\n",
      "Epoch 116/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2228 - accuracy: 0.9389 - val_loss: 0.2267 - val_accuracy: 0.9385\n",
      "Epoch 117/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2227 - accuracy: 0.9389 - val_loss: 0.2267 - val_accuracy: 0.9385\n",
      "Epoch 118/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2228 - accuracy: 0.9389 - val_loss: 0.2266 - val_accuracy: 0.9385\n",
      "Epoch 119/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2228 - accuracy: 0.9389 - val_loss: 0.2266 - val_accuracy: 0.9385\n",
      "Epoch 120/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2227 - accuracy: 0.9389 - val_loss: 0.2266 - val_accuracy: 0.9385\n",
      "Epoch 121/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2227 - accuracy: 0.9389 - val_loss: 0.2266 - val_accuracy: 0.9385\n",
      "Epoch 122/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2226 - accuracy: 0.9389 - val_loss: 0.2265 - val_accuracy: 0.9385\n",
      "Epoch 123/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2226 - accuracy: 0.9389 - val_loss: 0.2265 - val_accuracy: 0.9385\n",
      "Epoch 124/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2226 - accuracy: 0.9389 - val_loss: 0.2265 - val_accuracy: 0.9385\n",
      "Epoch 125/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2226 - accuracy: 0.9389 - val_loss: 0.2265 - val_accuracy: 0.9385\n",
      "Epoch 126/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2225 - accuracy: 0.9389 - val_loss: 0.2265 - val_accuracy: 0.9385\n",
      "Epoch 127/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2225 - accuracy: 0.9389 - val_loss: 0.2264 - val_accuracy: 0.9385\n",
      "Epoch 128/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2225 - accuracy: 0.9389 - val_loss: 0.2264 - val_accuracy: 0.9385\n",
      "Epoch 129/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2225 - accuracy: 0.9389 - val_loss: 0.2264 - val_accuracy: 0.9385\n",
      "Epoch 130/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2224 - accuracy: 0.9389 - val_loss: 0.2264 - val_accuracy: 0.9385\n",
      "Epoch 131/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2224 - accuracy: 0.9389 - val_loss: 0.2263 - val_accuracy: 0.9385\n",
      "Epoch 132/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2223 - accuracy: 0.9389 - val_loss: 0.2263 - val_accuracy: 0.9385\n",
      "Epoch 133/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2223 - accuracy: 0.9389 - val_loss: 0.2263 - val_accuracy: 0.9385\n",
      "Epoch 134/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2223 - accuracy: 0.9389 - val_loss: 0.2262 - val_accuracy: 0.9385\n",
      "Epoch 135/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2222 - accuracy: 0.9389 - val_loss: 0.2262 - val_accuracy: 0.9385\n",
      "Epoch 136/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2223 - accuracy: 0.9389 - val_loss: 0.2262 - val_accuracy: 0.9385\n",
      "Epoch 137/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2222 - accuracy: 0.9389 - val_loss: 0.2262 - val_accuracy: 0.9385\n",
      "Epoch 138/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2222 - accuracy: 0.9389 - val_loss: 0.2261 - val_accuracy: 0.9385\n",
      "Epoch 139/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2221 - accuracy: 0.9389 - val_loss: 0.2261 - val_accuracy: 0.9385\n",
      "Epoch 140/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2221 - accuracy: 0.9389 - val_loss: 0.2261 - val_accuracy: 0.9385\n",
      "Epoch 141/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2221 - accuracy: 0.9389 - val_loss: 0.2261 - val_accuracy: 0.9385\n",
      "Epoch 142/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2221 - accuracy: 0.9389 - val_loss: 0.2261 - val_accuracy: 0.9385\n",
      "Epoch 143/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2221 - accuracy: 0.9389 - val_loss: 0.2260 - val_accuracy: 0.9385\n",
      "Epoch 144/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2220 - accuracy: 0.9389 - val_loss: 0.2260 - val_accuracy: 0.9385\n",
      "Epoch 145/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2220 - accuracy: 0.9389 - val_loss: 0.2260 - val_accuracy: 0.9385\n",
      "Epoch 146/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2219 - accuracy: 0.9389 - val_loss: 0.2259 - val_accuracy: 0.9385\n",
      "Epoch 147/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2219 - accuracy: 0.9389 - val_loss: 0.2259 - val_accuracy: 0.9385\n",
      "Epoch 148/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2219 - accuracy: 0.9389 - val_loss: 0.2259 - val_accuracy: 0.9385\n",
      "Epoch 149/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2218 - accuracy: 0.9389 - val_loss: 0.2259 - val_accuracy: 0.9385\n",
      "Epoch 150/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2218 - accuracy: 0.9389 - val_loss: 0.2259 - val_accuracy: 0.9385\n",
      "Epoch 151/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2218 - accuracy: 0.9389 - val_loss: 0.2258 - val_accuracy: 0.9385\n",
      "Epoch 152/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2218 - accuracy: 0.9389 - val_loss: 0.2258 - val_accuracy: 0.9385\n",
      "Epoch 153/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2217 - accuracy: 0.9389 - val_loss: 0.2258 - val_accuracy: 0.9385\n",
      "Epoch 154/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2217 - accuracy: 0.9389 - val_loss: 0.2258 - val_accuracy: 0.9385\n",
      "Epoch 155/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2217 - accuracy: 0.9389 - val_loss: 0.2257 - val_accuracy: 0.9385\n",
      "Epoch 156/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2216 - accuracy: 0.9389 - val_loss: 0.2257 - val_accuracy: 0.9385\n",
      "Epoch 157/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2216 - accuracy: 0.9389 - val_loss: 0.2257 - val_accuracy: 0.9385\n",
      "Epoch 158/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2215 - accuracy: 0.9389 - val_loss: 0.2256 - val_accuracy: 0.9385\n",
      "Epoch 159/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2215 - accuracy: 0.9389 - val_loss: 0.2256 - val_accuracy: 0.9385\n",
      "Epoch 160/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2215 - accuracy: 0.9389 - val_loss: 0.2256 - val_accuracy: 0.9385\n",
      "Epoch 161/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2214 - accuracy: 0.9389 - val_loss: 0.2256 - val_accuracy: 0.9385\n",
      "Epoch 162/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2214 - accuracy: 0.9389 - val_loss: 0.2255 - val_accuracy: 0.9385\n",
      "Epoch 163/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2213 - accuracy: 0.9389 - val_loss: 0.2255 - val_accuracy: 0.9385\n",
      "Epoch 164/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2213 - accuracy: 0.9389 - val_loss: 0.2254 - val_accuracy: 0.9385\n",
      "Epoch 165/800\n",
      "480/480 [==============================] - 0s 104us/step - loss: 0.2213 - accuracy: 0.9389 - val_loss: 0.2254 - val_accuracy: 0.9385\n",
      "Epoch 166/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2212 - accuracy: 0.9389 - val_loss: 0.2254 - val_accuracy: 0.9385\n",
      "Epoch 167/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2212 - accuracy: 0.9389 - val_loss: 0.2254 - val_accuracy: 0.9385\n",
      "Epoch 168/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 94us/step - loss: 0.2212 - accuracy: 0.9389 - val_loss: 0.2253 - val_accuracy: 0.9385\n",
      "Epoch 169/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2211 - accuracy: 0.9389 - val_loss: 0.2253 - val_accuracy: 0.9385\n",
      "Epoch 170/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2211 - accuracy: 0.9389 - val_loss: 0.2253 - val_accuracy: 0.9385\n",
      "Epoch 171/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2211 - accuracy: 0.9389 - val_loss: 0.2252 - val_accuracy: 0.9385\n",
      "Epoch 172/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2210 - accuracy: 0.9389 - val_loss: 0.2252 - val_accuracy: 0.9385\n",
      "Epoch 173/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2210 - accuracy: 0.9389 - val_loss: 0.2252 - val_accuracy: 0.9385\n",
      "Epoch 174/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.2209 - accuracy: 0.9389 - val_loss: 0.2251 - val_accuracy: 0.9385\n",
      "Epoch 175/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2209 - accuracy: 0.9389 - val_loss: 0.2251 - val_accuracy: 0.9385\n",
      "Epoch 176/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2209 - accuracy: 0.9389 - val_loss: 0.2250 - val_accuracy: 0.9385\n",
      "Epoch 177/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2208 - accuracy: 0.9389 - val_loss: 0.2250 - val_accuracy: 0.9385\n",
      "Epoch 178/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2208 - accuracy: 0.9389 - val_loss: 0.2250 - val_accuracy: 0.9385\n",
      "Epoch 179/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2207 - accuracy: 0.9389 - val_loss: 0.2250 - val_accuracy: 0.9385\n",
      "Epoch 180/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2207 - accuracy: 0.9389 - val_loss: 0.2249 - val_accuracy: 0.9385\n",
      "Epoch 181/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2207 - accuracy: 0.9389 - val_loss: 0.2249 - val_accuracy: 0.9385\n",
      "Epoch 182/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2206 - accuracy: 0.9389 - val_loss: 0.2248 - val_accuracy: 0.9385\n",
      "Epoch 183/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2205 - accuracy: 0.9389 - val_loss: 0.2248 - val_accuracy: 0.9385\n",
      "Epoch 184/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2205 - accuracy: 0.9389 - val_loss: 0.2248 - val_accuracy: 0.9385\n",
      "Epoch 185/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.2205 - accuracy: 0.9389 - val_loss: 0.2247 - val_accuracy: 0.9385\n",
      "Epoch 186/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2204 - accuracy: 0.9389 - val_loss: 0.2247 - val_accuracy: 0.9385\n",
      "Epoch 187/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2204 - accuracy: 0.9389 - val_loss: 0.2247 - val_accuracy: 0.9385\n",
      "Epoch 188/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2204 - accuracy: 0.9389 - val_loss: 0.2246 - val_accuracy: 0.9385\n",
      "Epoch 189/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2203 - accuracy: 0.9389 - val_loss: 0.2246 - val_accuracy: 0.9385\n",
      "Epoch 190/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2203 - accuracy: 0.9389 - val_loss: 0.2246 - val_accuracy: 0.9385\n",
      "Epoch 191/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2202 - accuracy: 0.9389 - val_loss: 0.2245 - val_accuracy: 0.9385\n",
      "Epoch 192/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2202 - accuracy: 0.9389 - val_loss: 0.2245 - val_accuracy: 0.9385\n",
      "Epoch 193/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2201 - accuracy: 0.9389 - val_loss: 0.2244 - val_accuracy: 0.9385\n",
      "Epoch 194/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2201 - accuracy: 0.9389 - val_loss: 0.2244 - val_accuracy: 0.9385\n",
      "Epoch 195/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2200 - accuracy: 0.9389 - val_loss: 0.2244 - val_accuracy: 0.9385\n",
      "Epoch 196/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2200 - accuracy: 0.9389 - val_loss: 0.2243 - val_accuracy: 0.9385\n",
      "Epoch 197/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2199 - accuracy: 0.9389 - val_loss: 0.2243 - val_accuracy: 0.9385\n",
      "Epoch 198/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2199 - accuracy: 0.9389 - val_loss: 0.2242 - val_accuracy: 0.9385\n",
      "Epoch 199/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2198 - accuracy: 0.9389 - val_loss: 0.2242 - val_accuracy: 0.9385\n",
      "Epoch 200/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2197 - accuracy: 0.9389 - val_loss: 0.2241 - val_accuracy: 0.9385\n",
      "Epoch 201/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2197 - accuracy: 0.9389 - val_loss: 0.2241 - val_accuracy: 0.9385\n",
      "Epoch 202/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2197 - accuracy: 0.9389 - val_loss: 0.2240 - val_accuracy: 0.9385\n",
      "Epoch 203/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2197 - accuracy: 0.9389 - val_loss: 0.2240 - val_accuracy: 0.9385\n",
      "Epoch 204/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2195 - accuracy: 0.9389 - val_loss: 0.2240 - val_accuracy: 0.9385\n",
      "Epoch 205/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2195 - accuracy: 0.9389 - val_loss: 0.2240 - val_accuracy: 0.9385\n",
      "Epoch 206/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2195 - accuracy: 0.9389 - val_loss: 0.2239 - val_accuracy: 0.9385\n",
      "Epoch 207/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2194 - accuracy: 0.9389 - val_loss: 0.2239 - val_accuracy: 0.9385\n",
      "Epoch 208/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2194 - accuracy: 0.9389 - val_loss: 0.2238 - val_accuracy: 0.9385\n",
      "Epoch 209/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2193 - accuracy: 0.9389 - val_loss: 0.2238 - val_accuracy: 0.9385\n",
      "Epoch 210/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2193 - accuracy: 0.9389 - val_loss: 0.2237 - val_accuracy: 0.9385\n",
      "Epoch 211/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2192 - accuracy: 0.9389 - val_loss: 0.2237 - val_accuracy: 0.9385\n",
      "Epoch 212/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2192 - accuracy: 0.9389 - val_loss: 0.2236 - val_accuracy: 0.9385\n",
      "Epoch 213/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2191 - accuracy: 0.9389 - val_loss: 0.2236 - val_accuracy: 0.9385\n",
      "Epoch 214/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2190 - accuracy: 0.9389 - val_loss: 0.2235 - val_accuracy: 0.9385\n",
      "Epoch 215/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2190 - accuracy: 0.9389 - val_loss: 0.2235 - val_accuracy: 0.9385\n",
      "Epoch 216/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2189 - accuracy: 0.9389 - val_loss: 0.2234 - val_accuracy: 0.9385\n",
      "Epoch 217/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2189 - accuracy: 0.9389 - val_loss: 0.2234 - val_accuracy: 0.9385\n",
      "Epoch 218/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2188 - accuracy: 0.9389 - val_loss: 0.2234 - val_accuracy: 0.9385\n",
      "Epoch 219/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2188 - accuracy: 0.9389 - val_loss: 0.2233 - val_accuracy: 0.9385\n",
      "Epoch 220/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2187 - accuracy: 0.9389 - val_loss: 0.2232 - val_accuracy: 0.9385\n",
      "Epoch 221/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2186 - accuracy: 0.9389 - val_loss: 0.2232 - val_accuracy: 0.9385\n",
      "Epoch 222/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2186 - accuracy: 0.9389 - val_loss: 0.2232 - val_accuracy: 0.9385\n",
      "Epoch 223/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2185 - accuracy: 0.9389 - val_loss: 0.2231 - val_accuracy: 0.9385\n",
      "Epoch 224/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.2184 - accuracy: 0.9389 - val_loss: 0.2230 - val_accuracy: 0.9385\n",
      "Epoch 225/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2184 - accuracy: 0.9389 - val_loss: 0.2230 - val_accuracy: 0.9385\n",
      "Epoch 226/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2183 - accuracy: 0.9389 - val_loss: 0.2229 - val_accuracy: 0.9385\n",
      "Epoch 227/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2183 - accuracy: 0.9389 - val_loss: 0.2229 - val_accuracy: 0.9385\n",
      "Epoch 228/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2182 - accuracy: 0.9389 - val_loss: 0.2229 - val_accuracy: 0.9385\n",
      "Epoch 229/800\n",
      "480/480 [==============================] - 0s 93us/step - loss: 0.2181 - accuracy: 0.9389 - val_loss: 0.2228 - val_accuracy: 0.9385\n",
      "Epoch 230/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2181 - accuracy: 0.9389 - val_loss: 0.2227 - val_accuracy: 0.9385\n",
      "Epoch 231/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2180 - accuracy: 0.9389 - val_loss: 0.2227 - val_accuracy: 0.9385\n",
      "Epoch 232/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2179 - accuracy: 0.9389 - val_loss: 0.2226 - val_accuracy: 0.9385\n",
      "Epoch 233/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2179 - accuracy: 0.9389 - val_loss: 0.2226 - val_accuracy: 0.9385\n",
      "Epoch 234/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2178 - accuracy: 0.9389 - val_loss: 0.2225 - val_accuracy: 0.9385\n",
      "Epoch 235/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2178 - accuracy: 0.9389 - val_loss: 0.2225 - val_accuracy: 0.9385\n",
      "Epoch 236/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2177 - accuracy: 0.9389 - val_loss: 0.2225 - val_accuracy: 0.9385\n",
      "Epoch 237/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2177 - accuracy: 0.9389 - val_loss: 0.2224 - val_accuracy: 0.9385\n",
      "Epoch 238/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2176 - accuracy: 0.9389 - val_loss: 0.2224 - val_accuracy: 0.9385\n",
      "Epoch 239/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2175 - accuracy: 0.9389 - val_loss: 0.2223 - val_accuracy: 0.9385\n",
      "Epoch 240/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2174 - accuracy: 0.9389 - val_loss: 0.2222 - val_accuracy: 0.9385\n",
      "Epoch 241/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2174 - accuracy: 0.9389 - val_loss: 0.2221 - val_accuracy: 0.9385\n",
      "Epoch 242/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2173 - accuracy: 0.9389 - val_loss: 0.2221 - val_accuracy: 0.9385\n",
      "Epoch 243/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2172 - accuracy: 0.9389 - val_loss: 0.2220 - val_accuracy: 0.9385\n",
      "Epoch 244/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2171 - accuracy: 0.9389 - val_loss: 0.2220 - val_accuracy: 0.9385\n",
      "Epoch 245/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2171 - accuracy: 0.9389 - val_loss: 0.2219 - val_accuracy: 0.9385\n",
      "Epoch 246/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2170 - accuracy: 0.9389 - val_loss: 0.2218 - val_accuracy: 0.9385\n",
      "Epoch 247/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2169 - accuracy: 0.9389 - val_loss: 0.2218 - val_accuracy: 0.9385\n",
      "Epoch 248/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.2168 - accuracy: 0.9389 - val_loss: 0.2217 - val_accuracy: 0.9385\n",
      "Epoch 249/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2168 - accuracy: 0.9389 - val_loss: 0.2217 - val_accuracy: 0.9385\n",
      "Epoch 250/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2167 - accuracy: 0.9389 - val_loss: 0.2216 - val_accuracy: 0.9385\n",
      "Epoch 251/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2166 - accuracy: 0.9389 - val_loss: 0.2215 - val_accuracy: 0.9385\n",
      "Epoch 252/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2166 - accuracy: 0.9389 - val_loss: 0.2215 - val_accuracy: 0.9385\n",
      "Epoch 253/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2164 - accuracy: 0.9389 - val_loss: 0.2214 - val_accuracy: 0.9385\n",
      "Epoch 254/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2164 - accuracy: 0.9389 - val_loss: 0.2214 - val_accuracy: 0.9385\n",
      "Epoch 255/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2163 - accuracy: 0.9389 - val_loss: 0.2213 - val_accuracy: 0.9385\n",
      "Epoch 256/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2162 - accuracy: 0.9389 - val_loss: 0.2212 - val_accuracy: 0.9385\n",
      "Epoch 257/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2161 - accuracy: 0.9389 - val_loss: 0.2212 - val_accuracy: 0.9385\n",
      "Epoch 258/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2161 - accuracy: 0.9389 - val_loss: 0.2211 - val_accuracy: 0.9385\n",
      "Epoch 259/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2160 - accuracy: 0.9389 - val_loss: 0.2211 - val_accuracy: 0.9385\n",
      "Epoch 260/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2159 - accuracy: 0.9389 - val_loss: 0.2210 - val_accuracy: 0.9385\n",
      "Epoch 261/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2158 - accuracy: 0.9389 - val_loss: 0.2209 - val_accuracy: 0.9385\n",
      "Epoch 262/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2158 - accuracy: 0.9389 - val_loss: 0.2209 - val_accuracy: 0.9385\n",
      "Epoch 263/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2157 - accuracy: 0.9389 - val_loss: 0.2208 - val_accuracy: 0.9385\n",
      "Epoch 264/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2156 - accuracy: 0.9389 - val_loss: 0.2208 - val_accuracy: 0.9385\n",
      "Epoch 265/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2155 - accuracy: 0.9389 - val_loss: 0.2207 - val_accuracy: 0.9385\n",
      "Epoch 266/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2154 - accuracy: 0.9389 - val_loss: 0.2207 - val_accuracy: 0.9385\n",
      "Epoch 267/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2153 - accuracy: 0.9389 - val_loss: 0.2206 - val_accuracy: 0.9385\n",
      "Epoch 268/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2152 - accuracy: 0.9389 - val_loss: 0.2205 - val_accuracy: 0.9385\n",
      "Epoch 269/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2152 - accuracy: 0.9389 - val_loss: 0.2204 - val_accuracy: 0.9385\n",
      "Epoch 270/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2151 - accuracy: 0.9389 - val_loss: 0.2204 - val_accuracy: 0.9385\n",
      "Epoch 271/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2150 - accuracy: 0.9389 - val_loss: 0.2203 - val_accuracy: 0.9385\n",
      "Epoch 272/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2149 - accuracy: 0.9389 - val_loss: 0.2202 - val_accuracy: 0.9385\n",
      "Epoch 273/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2148 - accuracy: 0.9389 - val_loss: 0.2201 - val_accuracy: 0.9385\n",
      "Epoch 274/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2147 - accuracy: 0.9389 - val_loss: 0.2201 - val_accuracy: 0.9385\n",
      "Epoch 275/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2147 - accuracy: 0.9389 - val_loss: 0.2200 - val_accuracy: 0.9385\n",
      "Epoch 276/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2145 - accuracy: 0.9389 - val_loss: 0.2199 - val_accuracy: 0.9385\n",
      "Epoch 277/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2145 - accuracy: 0.9389 - val_loss: 0.2198 - val_accuracy: 0.9385\n",
      "Epoch 278/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2143 - accuracy: 0.9389 - val_loss: 0.2198 - val_accuracy: 0.9385\n",
      "Epoch 279/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2143 - accuracy: 0.9389 - val_loss: 0.2197 - val_accuracy: 0.9385\n",
      "Epoch 280/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.2142 - accuracy: 0.9389 - val_loss: 0.2197 - val_accuracy: 0.9385\n",
      "Epoch 281/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2141 - accuracy: 0.9389 - val_loss: 0.2196 - val_accuracy: 0.9385\n",
      "Epoch 282/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2140 - accuracy: 0.9389 - val_loss: 0.2195 - val_accuracy: 0.9385\n",
      "Epoch 283/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2139 - accuracy: 0.9389 - val_loss: 0.2195 - val_accuracy: 0.9385\n",
      "Epoch 284/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2138 - accuracy: 0.9389 - val_loss: 0.2194 - val_accuracy: 0.9385\n",
      "Epoch 285/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2137 - accuracy: 0.9389 - val_loss: 0.2193 - val_accuracy: 0.9385\n",
      "Epoch 286/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2136 - accuracy: 0.9389 - val_loss: 0.2192 - val_accuracy: 0.9385\n",
      "Epoch 287/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2135 - accuracy: 0.9389 - val_loss: 0.2192 - val_accuracy: 0.9385\n",
      "Epoch 288/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2134 - accuracy: 0.9389 - val_loss: 0.2191 - val_accuracy: 0.9385\n",
      "Epoch 289/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2133 - accuracy: 0.9389 - val_loss: 0.2190 - val_accuracy: 0.9385\n",
      "Epoch 290/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2133 - accuracy: 0.9389 - val_loss: 0.2189 - val_accuracy: 0.9385\n",
      "Epoch 291/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2132 - accuracy: 0.9389 - val_loss: 0.2189 - val_accuracy: 0.9385\n",
      "Epoch 292/800\n",
      "480/480 [==============================] - 0s 80us/step - loss: 0.2131 - accuracy: 0.9389 - val_loss: 0.2188 - val_accuracy: 0.9385\n",
      "Epoch 293/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2129 - accuracy: 0.9389 - val_loss: 0.2187 - val_accuracy: 0.9385\n",
      "Epoch 294/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2128 - accuracy: 0.9389 - val_loss: 0.2187 - val_accuracy: 0.9385\n",
      "Epoch 295/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2127 - accuracy: 0.9389 - val_loss: 0.2186 - val_accuracy: 0.9385\n",
      "Epoch 296/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2127 - accuracy: 0.9389 - val_loss: 0.2185 - val_accuracy: 0.9385\n",
      "Epoch 297/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2126 - accuracy: 0.9389 - val_loss: 0.2184 - val_accuracy: 0.9385\n",
      "Epoch 298/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2124 - accuracy: 0.9389 - val_loss: 0.2183 - val_accuracy: 0.9385\n",
      "Epoch 299/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2124 - accuracy: 0.9389 - val_loss: 0.2183 - val_accuracy: 0.9385\n",
      "Epoch 300/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2123 - accuracy: 0.9389 - val_loss: 0.2182 - val_accuracy: 0.9385\n",
      "Epoch 301/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2121 - accuracy: 0.9389 - val_loss: 0.2181 - val_accuracy: 0.9385\n",
      "Epoch 302/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2121 - accuracy: 0.9389 - val_loss: 0.2180 - val_accuracy: 0.9385\n",
      "Epoch 303/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2119 - accuracy: 0.9389 - val_loss: 0.2180 - val_accuracy: 0.9385\n",
      "Epoch 304/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2119 - accuracy: 0.9389 - val_loss: 0.2179 - val_accuracy: 0.9385\n",
      "Epoch 305/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2117 - accuracy: 0.9389 - val_loss: 0.2178 - val_accuracy: 0.9385\n",
      "Epoch 306/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2116 - accuracy: 0.9389 - val_loss: 0.2177 - val_accuracy: 0.9385\n",
      "Epoch 307/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2115 - accuracy: 0.9389 - val_loss: 0.2177 - val_accuracy: 0.9385\n",
      "Epoch 308/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2115 - accuracy: 0.9389 - val_loss: 0.2176 - val_accuracy: 0.9385\n",
      "Epoch 309/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2113 - accuracy: 0.9389 - val_loss: 0.2175 - val_accuracy: 0.9385\n",
      "Epoch 310/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2112 - accuracy: 0.9389 - val_loss: 0.2174 - val_accuracy: 0.9385\n",
      "Epoch 311/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2111 - accuracy: 0.9389 - val_loss: 0.2174 - val_accuracy: 0.9385\n",
      "Epoch 312/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2110 - accuracy: 0.9389 - val_loss: 0.2173 - val_accuracy: 0.9385\n",
      "Epoch 313/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2110 - accuracy: 0.9389 - val_loss: 0.2172 - val_accuracy: 0.9385\n",
      "Epoch 314/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2108 - accuracy: 0.9389 - val_loss: 0.2171 - val_accuracy: 0.9385\n",
      "Epoch 315/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2107 - accuracy: 0.9389 - val_loss: 0.2170 - val_accuracy: 0.9385\n",
      "Epoch 316/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2106 - accuracy: 0.9389 - val_loss: 0.2170 - val_accuracy: 0.9385\n",
      "Epoch 317/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2105 - accuracy: 0.9389 - val_loss: 0.2169 - val_accuracy: 0.9385\n",
      "Epoch 318/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2104 - accuracy: 0.9389 - val_loss: 0.2168 - val_accuracy: 0.9385\n",
      "Epoch 319/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2103 - accuracy: 0.9389 - val_loss: 0.2167 - val_accuracy: 0.9385\n",
      "Epoch 320/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2102 - accuracy: 0.9389 - val_loss: 0.2166 - val_accuracy: 0.9385\n",
      "Epoch 321/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2100 - accuracy: 0.9389 - val_loss: 0.2165 - val_accuracy: 0.9385\n",
      "Epoch 322/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2100 - accuracy: 0.9389 - val_loss: 0.2165 - val_accuracy: 0.9385\n",
      "Epoch 323/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2098 - accuracy: 0.9389 - val_loss: 0.2164 - val_accuracy: 0.9385\n",
      "Epoch 324/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2097 - accuracy: 0.9389 - val_loss: 0.2163 - val_accuracy: 0.9385\n",
      "Epoch 325/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2096 - accuracy: 0.9389 - val_loss: 0.2162 - val_accuracy: 0.9385\n",
      "Epoch 326/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2095 - accuracy: 0.9389 - val_loss: 0.2162 - val_accuracy: 0.9385\n",
      "Epoch 327/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2094 - accuracy: 0.9389 - val_loss: 0.2160 - val_accuracy: 0.9385\n",
      "Epoch 328/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2092 - accuracy: 0.9389 - val_loss: 0.2160 - val_accuracy: 0.9385\n",
      "Epoch 329/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2091 - accuracy: 0.9389 - val_loss: 0.2160 - val_accuracy: 0.9385\n",
      "Epoch 330/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2091 - accuracy: 0.9389 - val_loss: 0.2159 - val_accuracy: 0.9385\n",
      "Epoch 331/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2089 - accuracy: 0.9389 - val_loss: 0.2157 - val_accuracy: 0.9385\n",
      "Epoch 332/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2088 - accuracy: 0.9389 - val_loss: 0.2157 - val_accuracy: 0.9385\n",
      "Epoch 333/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2087 - accuracy: 0.9389 - val_loss: 0.2156 - val_accuracy: 0.9385\n",
      "Epoch 334/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2086 - accuracy: 0.9389 - val_loss: 0.2155 - val_accuracy: 0.9385\n",
      "Epoch 335/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2085 - accuracy: 0.9389 - val_loss: 0.2155 - val_accuracy: 0.9385\n",
      "Epoch 336/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.2084 - accuracy: 0.9389 - val_loss: 0.2154 - val_accuracy: 0.9385\n",
      "Epoch 337/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2083 - accuracy: 0.9389 - val_loss: 0.2153 - val_accuracy: 0.9385\n",
      "Epoch 338/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2082 - accuracy: 0.9389 - val_loss: 0.2152 - val_accuracy: 0.9385\n",
      "Epoch 339/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2081 - accuracy: 0.9389 - val_loss: 0.2151 - val_accuracy: 0.9385\n",
      "Epoch 340/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2079 - accuracy: 0.9389 - val_loss: 0.2151 - val_accuracy: 0.9385\n",
      "Epoch 341/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2078 - accuracy: 0.9389 - val_loss: 0.2149 - val_accuracy: 0.9385\n",
      "Epoch 342/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2077 - accuracy: 0.9389 - val_loss: 0.2149 - val_accuracy: 0.9385\n",
      "Epoch 343/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2076 - accuracy: 0.9389 - val_loss: 0.2148 - val_accuracy: 0.9385\n",
      "Epoch 344/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2075 - accuracy: 0.9389 - val_loss: 0.2148 - val_accuracy: 0.9385\n",
      "Epoch 345/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2074 - accuracy: 0.9389 - val_loss: 0.2147 - val_accuracy: 0.9385\n",
      "Epoch 346/800\n",
      "480/480 [==============================] - 0s 106us/step - loss: 0.2073 - accuracy: 0.9389 - val_loss: 0.2147 - val_accuracy: 0.9385\n",
      "Epoch 347/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2072 - accuracy: 0.9389 - val_loss: 0.2145 - val_accuracy: 0.9385\n",
      "Epoch 348/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2071 - accuracy: 0.9389 - val_loss: 0.2145 - val_accuracy: 0.9385\n",
      "Epoch 349/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2070 - accuracy: 0.9389 - val_loss: 0.2144 - val_accuracy: 0.9385\n",
      "Epoch 350/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2068 - accuracy: 0.9389 - val_loss: 0.2143 - val_accuracy: 0.9385\n",
      "Epoch 351/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2067 - accuracy: 0.9389 - val_loss: 0.2142 - val_accuracy: 0.9385\n",
      "Epoch 352/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2066 - accuracy: 0.9389 - val_loss: 0.2142 - val_accuracy: 0.9385\n",
      "Epoch 353/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2065 - accuracy: 0.9390 - val_loss: 0.2141 - val_accuracy: 0.9385\n",
      "Epoch 354/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2063 - accuracy: 0.9389 - val_loss: 0.2140 - val_accuracy: 0.9385\n",
      "Epoch 355/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2063 - accuracy: 0.9390 - val_loss: 0.2139 - val_accuracy: 0.9385\n",
      "Epoch 356/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2062 - accuracy: 0.9389 - val_loss: 0.2139 - val_accuracy: 0.9385\n",
      "Epoch 357/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2060 - accuracy: 0.9389 - val_loss: 0.2138 - val_accuracy: 0.9384\n",
      "Epoch 358/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2059 - accuracy: 0.9389 - val_loss: 0.2137 - val_accuracy: 0.9384\n",
      "Epoch 359/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2058 - accuracy: 0.9389 - val_loss: 0.2136 - val_accuracy: 0.9384\n",
      "Epoch 360/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2057 - accuracy: 0.9389 - val_loss: 0.2136 - val_accuracy: 0.9384\n",
      "Epoch 361/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2055 - accuracy: 0.9389 - val_loss: 0.2135 - val_accuracy: 0.9384\n",
      "Epoch 362/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2054 - accuracy: 0.9389 - val_loss: 0.2134 - val_accuracy: 0.9384\n",
      "Epoch 363/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2053 - accuracy: 0.9389 - val_loss: 0.2133 - val_accuracy: 0.9384\n",
      "Epoch 364/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2052 - accuracy: 0.9389 - val_loss: 0.2132 - val_accuracy: 0.9384\n",
      "Epoch 365/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2051 - accuracy: 0.9389 - val_loss: 0.2132 - val_accuracy: 0.9384\n",
      "Epoch 366/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2050 - accuracy: 0.9389 - val_loss: 0.2131 - val_accuracy: 0.9384\n",
      "Epoch 367/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2049 - accuracy: 0.9390 - val_loss: 0.2130 - val_accuracy: 0.9384\n",
      "Epoch 368/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2048 - accuracy: 0.9389 - val_loss: 0.2129 - val_accuracy: 0.9384\n",
      "Epoch 369/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2047 - accuracy: 0.9389 - val_loss: 0.2129 - val_accuracy: 0.9384\n",
      "Epoch 370/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2045 - accuracy: 0.9389 - val_loss: 0.2128 - val_accuracy: 0.9384\n",
      "Epoch 371/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2044 - accuracy: 0.9390 - val_loss: 0.2128 - val_accuracy: 0.9384\n",
      "Epoch 372/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2043 - accuracy: 0.9390 - val_loss: 0.2127 - val_accuracy: 0.9384\n",
      "Epoch 373/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2041 - accuracy: 0.9391 - val_loss: 0.2126 - val_accuracy: 0.9384\n",
      "Epoch 374/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2041 - accuracy: 0.9389 - val_loss: 0.2125 - val_accuracy: 0.9384\n",
      "Epoch 375/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2039 - accuracy: 0.9391 - val_loss: 0.2125 - val_accuracy: 0.9384\n",
      "Epoch 376/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2038 - accuracy: 0.9390 - val_loss: 0.2124 - val_accuracy: 0.9384\n",
      "Epoch 377/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2037 - accuracy: 0.9389 - val_loss: 0.2123 - val_accuracy: 0.9384\n",
      "Epoch 378/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2036 - accuracy: 0.9390 - val_loss: 0.2122 - val_accuracy: 0.9384\n",
      "Epoch 379/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2035 - accuracy: 0.9390 - val_loss: 0.2121 - val_accuracy: 0.9384\n",
      "Epoch 380/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2034 - accuracy: 0.9391 - val_loss: 0.2121 - val_accuracy: 0.9384\n",
      "Epoch 381/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2033 - accuracy: 0.9391 - val_loss: 0.2120 - val_accuracy: 0.9384\n",
      "Epoch 382/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2032 - accuracy: 0.9390 - val_loss: 0.2119 - val_accuracy: 0.9384\n",
      "Epoch 383/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2030 - accuracy: 0.9390 - val_loss: 0.2118 - val_accuracy: 0.9384\n",
      "Epoch 384/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2029 - accuracy: 0.9390 - val_loss: 0.2117 - val_accuracy: 0.9384\n",
      "Epoch 385/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2028 - accuracy: 0.9391 - val_loss: 0.2117 - val_accuracy: 0.9384\n",
      "Epoch 386/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2026 - accuracy: 0.9391 - val_loss: 0.2117 - val_accuracy: 0.9384\n",
      "Epoch 387/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2025 - accuracy: 0.9391 - val_loss: 0.2116 - val_accuracy: 0.9384\n",
      "Epoch 388/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2025 - accuracy: 0.9391 - val_loss: 0.2114 - val_accuracy: 0.9384\n",
      "Epoch 389/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2023 - accuracy: 0.9391 - val_loss: 0.2114 - val_accuracy: 0.9384\n",
      "Epoch 390/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2022 - accuracy: 0.9390 - val_loss: 0.2114 - val_accuracy: 0.9384\n",
      "Epoch 391/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2021 - accuracy: 0.9391 - val_loss: 0.2112 - val_accuracy: 0.9384\n",
      "Epoch 392/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.2020 - accuracy: 0.9391 - val_loss: 0.2112 - val_accuracy: 0.9384\n",
      "Epoch 393/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2018 - accuracy: 0.9390 - val_loss: 0.2111 - val_accuracy: 0.9384\n",
      "Epoch 394/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2018 - accuracy: 0.9391 - val_loss: 0.2110 - val_accuracy: 0.9384\n",
      "Epoch 395/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2016 - accuracy: 0.9391 - val_loss: 0.2111 - val_accuracy: 0.9384\n",
      "Epoch 396/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2015 - accuracy: 0.9391 - val_loss: 0.2110 - val_accuracy: 0.9384\n",
      "Epoch 397/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2014 - accuracy: 0.9391 - val_loss: 0.2108 - val_accuracy: 0.9384\n",
      "Epoch 398/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2013 - accuracy: 0.9391 - val_loss: 0.2108 - val_accuracy: 0.9384\n",
      "Epoch 399/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2012 - accuracy: 0.9391 - val_loss: 0.2107 - val_accuracy: 0.9384\n",
      "Epoch 400/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2010 - accuracy: 0.9391 - val_loss: 0.2107 - val_accuracy: 0.9384\n",
      "Epoch 401/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2010 - accuracy: 0.9391 - val_loss: 0.2106 - val_accuracy: 0.9384\n",
      "Epoch 402/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.2008 - accuracy: 0.9391 - val_loss: 0.2105 - val_accuracy: 0.9384\n",
      "Epoch 403/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2007 - accuracy: 0.9391 - val_loss: 0.2104 - val_accuracy: 0.9384\n",
      "Epoch 404/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2006 - accuracy: 0.9391 - val_loss: 0.2104 - val_accuracy: 0.9384\n",
      "Epoch 405/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2005 - accuracy: 0.9391 - val_loss: 0.2103 - val_accuracy: 0.9384\n",
      "Epoch 406/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2004 - accuracy: 0.9391 - val_loss: 0.2102 - val_accuracy: 0.9384\n",
      "Epoch 407/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2003 - accuracy: 0.9391 - val_loss: 0.2101 - val_accuracy: 0.9384\n",
      "Epoch 408/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2002 - accuracy: 0.9391 - val_loss: 0.2100 - val_accuracy: 0.9384\n",
      "Epoch 409/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2001 - accuracy: 0.9391 - val_loss: 0.2099 - val_accuracy: 0.9384\n",
      "Epoch 410/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1999 - accuracy: 0.9391 - val_loss: 0.2099 - val_accuracy: 0.9384\n",
      "Epoch 411/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1999 - accuracy: 0.9391 - val_loss: 0.2098 - val_accuracy: 0.9384\n",
      "Epoch 412/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1997 - accuracy: 0.9392 - val_loss: 0.2097 - val_accuracy: 0.9384\n",
      "Epoch 413/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1996 - accuracy: 0.9391 - val_loss: 0.2097 - val_accuracy: 0.9384\n",
      "Epoch 414/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1995 - accuracy: 0.9391 - val_loss: 0.2096 - val_accuracy: 0.9384\n",
      "Epoch 415/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1994 - accuracy: 0.9391 - val_loss: 0.2095 - val_accuracy: 0.9384\n",
      "Epoch 416/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1992 - accuracy: 0.9391 - val_loss: 0.2095 - val_accuracy: 0.9384\n",
      "Epoch 417/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1992 - accuracy: 0.9391 - val_loss: 0.2095 - val_accuracy: 0.9384\n",
      "Epoch 418/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1991 - accuracy: 0.9391 - val_loss: 0.2093 - val_accuracy: 0.9384\n",
      "Epoch 419/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1989 - accuracy: 0.9391 - val_loss: 0.2093 - val_accuracy: 0.9384\n",
      "Epoch 420/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1988 - accuracy: 0.9391 - val_loss: 0.2093 - val_accuracy: 0.9384\n",
      "Epoch 421/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1987 - accuracy: 0.9392 - val_loss: 0.2092 - val_accuracy: 0.9384\n",
      "Epoch 422/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.1986 - accuracy: 0.9392 - val_loss: 0.2091 - val_accuracy: 0.9384\n",
      "Epoch 423/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1985 - accuracy: 0.9391 - val_loss: 0.2090 - val_accuracy: 0.9385\n",
      "Epoch 424/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1984 - accuracy: 0.9392 - val_loss: 0.2089 - val_accuracy: 0.9385\n",
      "Epoch 425/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1983 - accuracy: 0.9391 - val_loss: 0.2088 - val_accuracy: 0.9385\n",
      "Epoch 426/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1981 - accuracy: 0.9392 - val_loss: 0.2087 - val_accuracy: 0.9385\n",
      "Epoch 427/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1980 - accuracy: 0.9393 - val_loss: 0.2087 - val_accuracy: 0.9384\n",
      "Epoch 428/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1979 - accuracy: 0.9391 - val_loss: 0.2086 - val_accuracy: 0.9385\n",
      "Epoch 429/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1978 - accuracy: 0.9391 - val_loss: 0.2085 - val_accuracy: 0.9385\n",
      "Epoch 430/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1976 - accuracy: 0.9391 - val_loss: 0.2085 - val_accuracy: 0.9385\n",
      "Epoch 431/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1975 - accuracy: 0.9391 - val_loss: 0.2084 - val_accuracy: 0.9385\n",
      "Epoch 432/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1975 - accuracy: 0.9391 - val_loss: 0.2084 - val_accuracy: 0.9385\n",
      "Epoch 433/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1973 - accuracy: 0.9391 - val_loss: 0.2083 - val_accuracy: 0.9385\n",
      "Epoch 434/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1972 - accuracy: 0.9392 - val_loss: 0.2081 - val_accuracy: 0.9385\n",
      "Epoch 435/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1970 - accuracy: 0.9392 - val_loss: 0.2081 - val_accuracy: 0.9385\n",
      "Epoch 436/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1970 - accuracy: 0.9392 - val_loss: 0.2081 - val_accuracy: 0.9385\n",
      "Epoch 437/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1968 - accuracy: 0.9392 - val_loss: 0.2080 - val_accuracy: 0.9385\n",
      "Epoch 438/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1967 - accuracy: 0.9392 - val_loss: 0.2079 - val_accuracy: 0.9385\n",
      "Epoch 439/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1966 - accuracy: 0.9392 - val_loss: 0.2078 - val_accuracy: 0.9385\n",
      "Epoch 440/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1965 - accuracy: 0.9393 - val_loss: 0.2077 - val_accuracy: 0.9385\n",
      "Epoch 441/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1964 - accuracy: 0.9393 - val_loss: 0.2077 - val_accuracy: 0.9385\n",
      "Epoch 442/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1962 - accuracy: 0.9393 - val_loss: 0.2076 - val_accuracy: 0.9385\n",
      "Epoch 443/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1961 - accuracy: 0.9393 - val_loss: 0.2075 - val_accuracy: 0.9385\n",
      "Epoch 444/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1960 - accuracy: 0.9392 - val_loss: 0.2073 - val_accuracy: 0.9385\n",
      "Epoch 445/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1959 - accuracy: 0.9393 - val_loss: 0.2073 - val_accuracy: 0.9385\n",
      "Epoch 446/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1957 - accuracy: 0.9393 - val_loss: 0.2072 - val_accuracy: 0.9385\n",
      "Epoch 447/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1956 - accuracy: 0.9393 - val_loss: 0.2072 - val_accuracy: 0.9385\n",
      "Epoch 448/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 81us/step - loss: 0.1955 - accuracy: 0.9393 - val_loss: 0.2071 - val_accuracy: 0.9385\n",
      "Epoch 449/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1954 - accuracy: 0.9393 - val_loss: 0.2071 - val_accuracy: 0.9384\n",
      "Epoch 450/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1953 - accuracy: 0.9394 - val_loss: 0.2070 - val_accuracy: 0.9385\n",
      "Epoch 451/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1952 - accuracy: 0.9393 - val_loss: 0.2069 - val_accuracy: 0.9385\n",
      "Epoch 452/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1951 - accuracy: 0.9393 - val_loss: 0.2069 - val_accuracy: 0.9384\n",
      "Epoch 453/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1949 - accuracy: 0.9393 - val_loss: 0.2068 - val_accuracy: 0.9385\n",
      "Epoch 454/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1948 - accuracy: 0.9393 - val_loss: 0.2067 - val_accuracy: 0.9385\n",
      "Epoch 455/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1947 - accuracy: 0.9393 - val_loss: 0.2065 - val_accuracy: 0.9385\n",
      "Epoch 456/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1946 - accuracy: 0.9393 - val_loss: 0.2065 - val_accuracy: 0.9385\n",
      "Epoch 457/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1944 - accuracy: 0.9393 - val_loss: 0.2064 - val_accuracy: 0.9384\n",
      "Epoch 458/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1943 - accuracy: 0.9393 - val_loss: 0.2063 - val_accuracy: 0.9385\n",
      "Epoch 459/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1942 - accuracy: 0.9393 - val_loss: 0.2063 - val_accuracy: 0.9384\n",
      "Epoch 460/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1941 - accuracy: 0.9393 - val_loss: 0.2062 - val_accuracy: 0.9384\n",
      "Epoch 461/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1939 - accuracy: 0.9393 - val_loss: 0.2061 - val_accuracy: 0.9384\n",
      "Epoch 462/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1938 - accuracy: 0.9393 - val_loss: 0.2061 - val_accuracy: 0.9385\n",
      "Epoch 463/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1937 - accuracy: 0.9393 - val_loss: 0.2060 - val_accuracy: 0.9385\n",
      "Epoch 464/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1936 - accuracy: 0.9392 - val_loss: 0.2059 - val_accuracy: 0.9382\n",
      "Epoch 465/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1935 - accuracy: 0.9394 - val_loss: 0.2058 - val_accuracy: 0.9384\n",
      "Epoch 466/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1933 - accuracy: 0.9393 - val_loss: 0.2057 - val_accuracy: 0.9382\n",
      "Epoch 467/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1932 - accuracy: 0.9393 - val_loss: 0.2056 - val_accuracy: 0.9384\n",
      "Epoch 468/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1931 - accuracy: 0.9392 - val_loss: 0.2056 - val_accuracy: 0.9384\n",
      "Epoch 469/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1929 - accuracy: 0.9393 - val_loss: 0.2056 - val_accuracy: 0.9382\n",
      "Epoch 470/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1928 - accuracy: 0.9393 - val_loss: 0.2053 - val_accuracy: 0.9384\n",
      "Epoch 471/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1927 - accuracy: 0.9393 - val_loss: 0.2053 - val_accuracy: 0.9382\n",
      "Epoch 472/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1927 - accuracy: 0.9393 - val_loss: 0.2053 - val_accuracy: 0.9382\n",
      "Epoch 473/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1924 - accuracy: 0.9392 - val_loss: 0.2051 - val_accuracy: 0.9384\n",
      "Epoch 474/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1923 - accuracy: 0.9393 - val_loss: 0.2050 - val_accuracy: 0.9384\n",
      "Epoch 475/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1922 - accuracy: 0.9392 - val_loss: 0.2049 - val_accuracy: 0.9384\n",
      "Epoch 476/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1920 - accuracy: 0.9393 - val_loss: 0.2049 - val_accuracy: 0.9382\n",
      "Epoch 477/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1919 - accuracy: 0.9393 - val_loss: 0.2048 - val_accuracy: 0.9384\n",
      "Epoch 478/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1918 - accuracy: 0.9392 - val_loss: 0.2047 - val_accuracy: 0.9384\n",
      "Epoch 479/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1917 - accuracy: 0.9393 - val_loss: 0.2046 - val_accuracy: 0.9384\n",
      "Epoch 480/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1916 - accuracy: 0.9393 - val_loss: 0.2045 - val_accuracy: 0.9382\n",
      "Epoch 481/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1914 - accuracy: 0.9393 - val_loss: 0.2044 - val_accuracy: 0.9382\n",
      "Epoch 482/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1913 - accuracy: 0.9393 - val_loss: 0.2044 - val_accuracy: 0.9384\n",
      "Epoch 483/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1912 - accuracy: 0.9393 - val_loss: 0.2043 - val_accuracy: 0.9384\n",
      "Epoch 484/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1910 - accuracy: 0.9393 - val_loss: 0.2042 - val_accuracy: 0.9381\n",
      "Epoch 485/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1909 - accuracy: 0.9394 - val_loss: 0.2041 - val_accuracy: 0.9384\n",
      "Epoch 486/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1908 - accuracy: 0.9393 - val_loss: 0.2040 - val_accuracy: 0.9382\n",
      "Epoch 487/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1907 - accuracy: 0.9394 - val_loss: 0.2039 - val_accuracy: 0.9382\n",
      "Epoch 488/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1905 - accuracy: 0.9395 - val_loss: 0.2039 - val_accuracy: 0.9385\n",
      "Epoch 489/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1905 - accuracy: 0.9394 - val_loss: 0.2038 - val_accuracy: 0.9386\n",
      "Epoch 490/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1903 - accuracy: 0.9394 - val_loss: 0.2036 - val_accuracy: 0.9384\n",
      "Epoch 491/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1902 - accuracy: 0.9395 - val_loss: 0.2036 - val_accuracy: 0.9384\n",
      "Epoch 492/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1900 - accuracy: 0.9396 - val_loss: 0.2036 - val_accuracy: 0.9382\n",
      "Epoch 493/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1899 - accuracy: 0.9396 - val_loss: 0.2035 - val_accuracy: 0.9386\n",
      "Epoch 494/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1897 - accuracy: 0.9396 - val_loss: 0.2034 - val_accuracy: 0.9382\n",
      "Epoch 495/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1897 - accuracy: 0.9396 - val_loss: 0.2033 - val_accuracy: 0.9385\n",
      "Epoch 496/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1895 - accuracy: 0.9394 - val_loss: 0.2032 - val_accuracy: 0.9382\n",
      "Epoch 497/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1894 - accuracy: 0.9394 - val_loss: 0.2031 - val_accuracy: 0.9386\n",
      "Epoch 498/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1893 - accuracy: 0.9396 - val_loss: 0.2030 - val_accuracy: 0.9386\n",
      "Epoch 499/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1891 - accuracy: 0.9398 - val_loss: 0.2029 - val_accuracy: 0.9385\n",
      "Epoch 500/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1890 - accuracy: 0.9395 - val_loss: 0.2029 - val_accuracy: 0.9386\n",
      "Epoch 501/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1888 - accuracy: 0.9395 - val_loss: 0.2027 - val_accuracy: 0.9384\n",
      "Epoch 502/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1888 - accuracy: 0.9395 - val_loss: 0.2026 - val_accuracy: 0.9382\n",
      "Epoch 503/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1886 - accuracy: 0.9397 - val_loss: 0.2026 - val_accuracy: 0.9382\n",
      "Epoch 504/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 90us/step - loss: 0.1884 - accuracy: 0.9396 - val_loss: 0.2026 - val_accuracy: 0.9385\n",
      "Epoch 505/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1884 - accuracy: 0.9397 - val_loss: 0.2025 - val_accuracy: 0.9382\n",
      "Epoch 506/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1882 - accuracy: 0.9396 - val_loss: 0.2024 - val_accuracy: 0.9387\n",
      "Epoch 507/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1881 - accuracy: 0.9397 - val_loss: 0.2023 - val_accuracy: 0.9385\n",
      "Epoch 508/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1880 - accuracy: 0.9396 - val_loss: 0.2022 - val_accuracy: 0.9382\n",
      "Epoch 509/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1879 - accuracy: 0.9396 - val_loss: 0.2022 - val_accuracy: 0.9386\n",
      "Epoch 510/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1876 - accuracy: 0.9396 - val_loss: 0.2020 - val_accuracy: 0.9385\n",
      "Epoch 511/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1875 - accuracy: 0.9398 - val_loss: 0.2020 - val_accuracy: 0.9386\n",
      "Epoch 512/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1874 - accuracy: 0.9398 - val_loss: 0.2020 - val_accuracy: 0.9386\n",
      "Epoch 513/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1872 - accuracy: 0.9397 - val_loss: 0.2018 - val_accuracy: 0.9382\n",
      "Epoch 514/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1871 - accuracy: 0.9397 - val_loss: 0.2018 - val_accuracy: 0.9384\n",
      "Epoch 515/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1870 - accuracy: 0.9397 - val_loss: 0.2016 - val_accuracy: 0.9385\n",
      "Epoch 516/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1869 - accuracy: 0.9397 - val_loss: 0.2016 - val_accuracy: 0.9385\n",
      "Epoch 517/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1868 - accuracy: 0.9399 - val_loss: 0.2015 - val_accuracy: 0.9385\n",
      "Epoch 518/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1866 - accuracy: 0.9397 - val_loss: 0.2014 - val_accuracy: 0.9386\n",
      "Epoch 519/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1865 - accuracy: 0.9398 - val_loss: 0.2012 - val_accuracy: 0.9385\n",
      "Epoch 520/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1864 - accuracy: 0.9398 - val_loss: 0.2012 - val_accuracy: 0.9385\n",
      "Epoch 521/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1863 - accuracy: 0.9400 - val_loss: 0.2011 - val_accuracy: 0.9385\n",
      "Epoch 522/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1861 - accuracy: 0.9397 - val_loss: 0.2011 - val_accuracy: 0.9385\n",
      "Epoch 523/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1860 - accuracy: 0.9398 - val_loss: 0.2011 - val_accuracy: 0.9385\n",
      "Epoch 524/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1858 - accuracy: 0.9399 - val_loss: 0.2009 - val_accuracy: 0.9385\n",
      "Epoch 525/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1857 - accuracy: 0.9398 - val_loss: 0.2007 - val_accuracy: 0.9386\n",
      "Epoch 526/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1856 - accuracy: 0.9399 - val_loss: 0.2008 - val_accuracy: 0.9385\n",
      "Epoch 527/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1855 - accuracy: 0.9397 - val_loss: 0.2009 - val_accuracy: 0.9385\n",
      "Epoch 528/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1853 - accuracy: 0.9401 - val_loss: 0.2007 - val_accuracy: 0.9386\n",
      "Epoch 529/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1852 - accuracy: 0.9398 - val_loss: 0.2005 - val_accuracy: 0.9386\n",
      "Epoch 530/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1850 - accuracy: 0.9401 - val_loss: 0.2004 - val_accuracy: 0.9387\n",
      "Epoch 531/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1849 - accuracy: 0.9400 - val_loss: 0.2003 - val_accuracy: 0.9386\n",
      "Epoch 532/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1848 - accuracy: 0.9401 - val_loss: 0.2003 - val_accuracy: 0.9386\n",
      "Epoch 533/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1846 - accuracy: 0.9401 - val_loss: 0.2002 - val_accuracy: 0.9386\n",
      "Epoch 534/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1845 - accuracy: 0.9400 - val_loss: 0.2002 - val_accuracy: 0.9385\n",
      "Epoch 535/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.1844 - accuracy: 0.9402 - val_loss: 0.2001 - val_accuracy: 0.9384\n",
      "Epoch 536/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1843 - accuracy: 0.9400 - val_loss: 0.2001 - val_accuracy: 0.9384\n",
      "Epoch 537/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1842 - accuracy: 0.9402 - val_loss: 0.1999 - val_accuracy: 0.9386\n",
      "Epoch 538/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1840 - accuracy: 0.9402 - val_loss: 0.1998 - val_accuracy: 0.9387\n",
      "Epoch 539/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1839 - accuracy: 0.9403 - val_loss: 0.1996 - val_accuracy: 0.9385\n",
      "Epoch 540/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1837 - accuracy: 0.9402 - val_loss: 0.1996 - val_accuracy: 0.9384\n",
      "Epoch 541/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1836 - accuracy: 0.9402 - val_loss: 0.1995 - val_accuracy: 0.9384\n",
      "Epoch 542/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1835 - accuracy: 0.9403 - val_loss: 0.1996 - val_accuracy: 0.9385\n",
      "Epoch 543/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1834 - accuracy: 0.9402 - val_loss: 0.1995 - val_accuracy: 0.9386\n",
      "Epoch 544/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1832 - accuracy: 0.9402 - val_loss: 0.1994 - val_accuracy: 0.9386\n",
      "Epoch 545/800\n",
      "480/480 [==============================] - 0s 100us/step - loss: 0.1831 - accuracy: 0.9404 - val_loss: 0.1993 - val_accuracy: 0.9386\n",
      "Epoch 546/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1830 - accuracy: 0.9404 - val_loss: 0.1991 - val_accuracy: 0.9384\n",
      "Epoch 547/800\n",
      "480/480 [==============================] - 0s 95us/step - loss: 0.1828 - accuracy: 0.9402 - val_loss: 0.1992 - val_accuracy: 0.9385\n",
      "Epoch 548/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1827 - accuracy: 0.9406 - val_loss: 0.1990 - val_accuracy: 0.9385\n",
      "Epoch 549/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1825 - accuracy: 0.9407 - val_loss: 0.1990 - val_accuracy: 0.9384\n",
      "Epoch 550/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1825 - accuracy: 0.9405 - val_loss: 0.1989 - val_accuracy: 0.9385\n",
      "Epoch 551/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1823 - accuracy: 0.9405 - val_loss: 0.1988 - val_accuracy: 0.9385\n",
      "Epoch 552/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1822 - accuracy: 0.9408 - val_loss: 0.1988 - val_accuracy: 0.9387\n",
      "Epoch 553/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1820 - accuracy: 0.9404 - val_loss: 0.1988 - val_accuracy: 0.9384\n",
      "Epoch 554/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1819 - accuracy: 0.9406 - val_loss: 0.1985 - val_accuracy: 0.9386\n",
      "Epoch 555/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1818 - accuracy: 0.9406 - val_loss: 0.1985 - val_accuracy: 0.9387\n",
      "Epoch 556/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1817 - accuracy: 0.9406 - val_loss: 0.1984 - val_accuracy: 0.9386\n",
      "Epoch 557/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1816 - accuracy: 0.9406 - val_loss: 0.1983 - val_accuracy: 0.9387\n",
      "Epoch 558/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1814 - accuracy: 0.9407 - val_loss: 0.1982 - val_accuracy: 0.9387\n",
      "Epoch 559/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1813 - accuracy: 0.9408 - val_loss: 0.1982 - val_accuracy: 0.9391\n",
      "Epoch 560/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.1812 - accuracy: 0.9406 - val_loss: 0.1981 - val_accuracy: 0.9388\n",
      "Epoch 561/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1810 - accuracy: 0.9406 - val_loss: 0.1982 - val_accuracy: 0.9390\n",
      "Epoch 562/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1809 - accuracy: 0.9408 - val_loss: 0.1980 - val_accuracy: 0.9386\n",
      "Epoch 563/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1807 - accuracy: 0.9406 - val_loss: 0.1979 - val_accuracy: 0.9390\n",
      "Epoch 564/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1807 - accuracy: 0.9408 - val_loss: 0.1979 - val_accuracy: 0.9391\n",
      "Epoch 565/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1805 - accuracy: 0.9411 - val_loss: 0.1978 - val_accuracy: 0.9391\n",
      "Epoch 566/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.1803 - accuracy: 0.9407 - val_loss: 0.1978 - val_accuracy: 0.9391\n",
      "Epoch 567/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1802 - accuracy: 0.9408 - val_loss: 0.1977 - val_accuracy: 0.9391\n",
      "Epoch 568/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1801 - accuracy: 0.9406 - val_loss: 0.1976 - val_accuracy: 0.9390\n",
      "Epoch 569/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.1800 - accuracy: 0.9410 - val_loss: 0.1975 - val_accuracy: 0.9390\n",
      "Epoch 570/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.1799 - accuracy: 0.9412 - val_loss: 0.1975 - val_accuracy: 0.9390\n",
      "Epoch 571/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1796 - accuracy: 0.9411 - val_loss: 0.1974 - val_accuracy: 0.9388\n",
      "Epoch 572/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1796 - accuracy: 0.9411 - val_loss: 0.1972 - val_accuracy: 0.9388\n",
      "Epoch 573/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1794 - accuracy: 0.9411 - val_loss: 0.1973 - val_accuracy: 0.9387\n",
      "Epoch 574/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1793 - accuracy: 0.9411 - val_loss: 0.1972 - val_accuracy: 0.9387\n",
      "Epoch 575/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1792 - accuracy: 0.9412 - val_loss: 0.1970 - val_accuracy: 0.9388\n",
      "Epoch 576/800\n",
      "480/480 [==============================] - 0s 80us/step - loss: 0.1792 - accuracy: 0.9410 - val_loss: 0.1971 - val_accuracy: 0.9386\n",
      "Epoch 577/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1790 - accuracy: 0.9411 - val_loss: 0.1968 - val_accuracy: 0.9393\n",
      "Epoch 578/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1788 - accuracy: 0.9412 - val_loss: 0.1970 - val_accuracy: 0.9385\n",
      "Epoch 579/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1787 - accuracy: 0.9410 - val_loss: 0.1970 - val_accuracy: 0.9391\n",
      "Epoch 580/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1787 - accuracy: 0.9411 - val_loss: 0.1967 - val_accuracy: 0.9388\n",
      "Epoch 581/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1785 - accuracy: 0.9412 - val_loss: 0.1966 - val_accuracy: 0.9393\n",
      "Epoch 582/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1784 - accuracy: 0.9413 - val_loss: 0.1966 - val_accuracy: 0.9388\n",
      "Epoch 583/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1782 - accuracy: 0.9413 - val_loss: 0.1965 - val_accuracy: 0.9388\n",
      "Epoch 584/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1781 - accuracy: 0.9413 - val_loss: 0.1966 - val_accuracy: 0.9390\n",
      "Epoch 585/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1780 - accuracy: 0.9412 - val_loss: 0.1964 - val_accuracy: 0.9388\n",
      "Epoch 586/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1779 - accuracy: 0.9412 - val_loss: 0.1963 - val_accuracy: 0.9387\n",
      "Epoch 587/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1777 - accuracy: 0.9412 - val_loss: 0.1963 - val_accuracy: 0.9390\n",
      "Epoch 588/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1776 - accuracy: 0.9411 - val_loss: 0.1964 - val_accuracy: 0.9386\n",
      "Epoch 589/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1775 - accuracy: 0.9412 - val_loss: 0.1962 - val_accuracy: 0.9390\n",
      "Epoch 590/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1774 - accuracy: 0.9412 - val_loss: 0.1961 - val_accuracy: 0.9386\n",
      "Epoch 591/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1773 - accuracy: 0.9412 - val_loss: 0.1961 - val_accuracy: 0.9386\n",
      "Epoch 592/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1771 - accuracy: 0.9414 - val_loss: 0.1960 - val_accuracy: 0.9388\n",
      "Epoch 593/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1770 - accuracy: 0.9413 - val_loss: 0.1958 - val_accuracy: 0.9385\n",
      "Epoch 594/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1769 - accuracy: 0.9412 - val_loss: 0.1958 - val_accuracy: 0.9388\n",
      "Epoch 595/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1767 - accuracy: 0.9413 - val_loss: 0.1958 - val_accuracy: 0.9387\n",
      "Epoch 596/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1767 - accuracy: 0.9413 - val_loss: 0.1956 - val_accuracy: 0.9388\n",
      "Epoch 597/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1766 - accuracy: 0.9413 - val_loss: 0.1957 - val_accuracy: 0.9392\n",
      "Epoch 598/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1765 - accuracy: 0.9415 - val_loss: 0.1956 - val_accuracy: 0.9388\n",
      "Epoch 599/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1764 - accuracy: 0.9413 - val_loss: 0.1955 - val_accuracy: 0.9388\n",
      "Epoch 600/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1762 - accuracy: 0.9414 - val_loss: 0.1955 - val_accuracy: 0.9387\n",
      "Epoch 601/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1761 - accuracy: 0.9414 - val_loss: 0.1954 - val_accuracy: 0.9390\n",
      "Epoch 602/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1759 - accuracy: 0.9411 - val_loss: 0.1953 - val_accuracy: 0.9390\n",
      "Epoch 603/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1759 - accuracy: 0.9414 - val_loss: 0.1952 - val_accuracy: 0.9387\n",
      "Epoch 604/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1757 - accuracy: 0.9413 - val_loss: 0.1952 - val_accuracy: 0.9392\n",
      "Epoch 605/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1756 - accuracy: 0.9414 - val_loss: 0.1952 - val_accuracy: 0.9395\n",
      "Epoch 606/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1754 - accuracy: 0.9411 - val_loss: 0.1951 - val_accuracy: 0.9390\n",
      "Epoch 607/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1753 - accuracy: 0.9417 - val_loss: 0.1951 - val_accuracy: 0.9391\n",
      "Epoch 608/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1752 - accuracy: 0.9412 - val_loss: 0.1951 - val_accuracy: 0.9393\n",
      "Epoch 609/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1751 - accuracy: 0.9415 - val_loss: 0.1952 - val_accuracy: 0.9392\n",
      "Epoch 610/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1751 - accuracy: 0.9414 - val_loss: 0.1946 - val_accuracy: 0.9390\n",
      "Epoch 611/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1749 - accuracy: 0.9415 - val_loss: 0.1947 - val_accuracy: 0.9388\n",
      "Epoch 612/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1747 - accuracy: 0.9415 - val_loss: 0.1946 - val_accuracy: 0.9390\n",
      "Epoch 613/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1747 - accuracy: 0.9415 - val_loss: 0.1944 - val_accuracy: 0.9388\n",
      "Epoch 614/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1746 - accuracy: 0.9415 - val_loss: 0.1944 - val_accuracy: 0.9390\n",
      "Epoch 615/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1745 - accuracy: 0.9415 - val_loss: 0.1945 - val_accuracy: 0.9391\n",
      "Epoch 616/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 88us/step - loss: 0.1743 - accuracy: 0.9417 - val_loss: 0.1943 - val_accuracy: 0.9391\n",
      "Epoch 617/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1742 - accuracy: 0.9413 - val_loss: 0.1943 - val_accuracy: 0.9387\n",
      "Epoch 618/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1741 - accuracy: 0.9415 - val_loss: 0.1941 - val_accuracy: 0.9387\n",
      "Epoch 619/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1739 - accuracy: 0.9414 - val_loss: 0.1941 - val_accuracy: 0.9387\n",
      "Epoch 620/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1739 - accuracy: 0.9416 - val_loss: 0.1941 - val_accuracy: 0.9392\n",
      "Epoch 621/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1737 - accuracy: 0.9415 - val_loss: 0.1940 - val_accuracy: 0.9390\n",
      "Epoch 622/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1736 - accuracy: 0.9416 - val_loss: 0.1940 - val_accuracy: 0.9392\n",
      "Epoch 623/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1735 - accuracy: 0.9417 - val_loss: 0.1939 - val_accuracy: 0.9392\n",
      "Epoch 624/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1734 - accuracy: 0.9414 - val_loss: 0.1936 - val_accuracy: 0.9390\n",
      "Epoch 625/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1733 - accuracy: 0.9417 - val_loss: 0.1939 - val_accuracy: 0.9395\n",
      "Epoch 626/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1731 - accuracy: 0.9416 - val_loss: 0.1937 - val_accuracy: 0.9393\n",
      "Epoch 627/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1732 - accuracy: 0.9417 - val_loss: 0.1936 - val_accuracy: 0.9390\n",
      "Epoch 628/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1730 - accuracy: 0.9416 - val_loss: 0.1934 - val_accuracy: 0.9387\n",
      "Epoch 629/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1728 - accuracy: 0.9416 - val_loss: 0.1937 - val_accuracy: 0.9395\n",
      "Epoch 630/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1728 - accuracy: 0.9416 - val_loss: 0.1934 - val_accuracy: 0.9393\n",
      "Epoch 631/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1726 - accuracy: 0.9416 - val_loss: 0.1935 - val_accuracy: 0.9393\n",
      "Epoch 632/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1725 - accuracy: 0.9416 - val_loss: 0.1933 - val_accuracy: 0.9388\n",
      "Epoch 633/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1724 - accuracy: 0.9415 - val_loss: 0.1932 - val_accuracy: 0.9388\n",
      "Epoch 634/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1723 - accuracy: 0.9414 - val_loss: 0.1932 - val_accuracy: 0.9392\n",
      "Epoch 635/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1723 - accuracy: 0.9415 - val_loss: 0.1931 - val_accuracy: 0.9392\n",
      "Epoch 636/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1720 - accuracy: 0.9419 - val_loss: 0.1932 - val_accuracy: 0.9391\n",
      "Epoch 637/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1720 - accuracy: 0.9416 - val_loss: 0.1930 - val_accuracy: 0.9391\n",
      "Epoch 638/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1719 - accuracy: 0.9420 - val_loss: 0.1930 - val_accuracy: 0.9391\n",
      "Epoch 639/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1718 - accuracy: 0.9420 - val_loss: 0.1929 - val_accuracy: 0.9388\n",
      "Epoch 640/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1716 - accuracy: 0.9421 - val_loss: 0.1930 - val_accuracy: 0.9392\n",
      "Epoch 641/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1716 - accuracy: 0.9417 - val_loss: 0.1927 - val_accuracy: 0.9388\n",
      "Epoch 642/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1714 - accuracy: 0.9422 - val_loss: 0.1927 - val_accuracy: 0.9393\n",
      "Epoch 643/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1713 - accuracy: 0.9418 - val_loss: 0.1927 - val_accuracy: 0.9391\n",
      "Epoch 644/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1712 - accuracy: 0.9420 - val_loss: 0.1927 - val_accuracy: 0.9391\n",
      "Epoch 645/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1712 - accuracy: 0.9420 - val_loss: 0.1926 - val_accuracy: 0.9393\n",
      "Epoch 646/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1710 - accuracy: 0.9420 - val_loss: 0.1924 - val_accuracy: 0.9391\n",
      "Epoch 647/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1708 - accuracy: 0.9420 - val_loss: 0.1925 - val_accuracy: 0.9395\n",
      "Epoch 648/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1708 - accuracy: 0.9424 - val_loss: 0.1925 - val_accuracy: 0.9390\n",
      "Epoch 649/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1707 - accuracy: 0.9420 - val_loss: 0.1922 - val_accuracy: 0.9390\n",
      "Epoch 650/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1705 - accuracy: 0.9422 - val_loss: 0.1923 - val_accuracy: 0.9392\n",
      "Epoch 651/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1705 - accuracy: 0.9420 - val_loss: 0.1922 - val_accuracy: 0.9393\n",
      "Epoch 652/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1703 - accuracy: 0.9422 - val_loss: 0.1922 - val_accuracy: 0.9391\n",
      "Epoch 653/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1702 - accuracy: 0.9422 - val_loss: 0.1922 - val_accuracy: 0.9396\n",
      "Epoch 654/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1701 - accuracy: 0.9422 - val_loss: 0.1921 - val_accuracy: 0.9393\n",
      "Epoch 655/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1701 - accuracy: 0.9424 - val_loss: 0.1920 - val_accuracy: 0.9390\n",
      "Epoch 656/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1698 - accuracy: 0.9422 - val_loss: 0.1917 - val_accuracy: 0.9392\n",
      "Epoch 657/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1698 - accuracy: 0.9422 - val_loss: 0.1917 - val_accuracy: 0.9396\n",
      "Epoch 658/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1696 - accuracy: 0.9423 - val_loss: 0.1918 - val_accuracy: 0.9395\n",
      "Epoch 659/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1696 - accuracy: 0.9422 - val_loss: 0.1917 - val_accuracy: 0.9393\n",
      "Epoch 660/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1694 - accuracy: 0.9424 - val_loss: 0.1917 - val_accuracy: 0.9392\n",
      "Epoch 661/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1694 - accuracy: 0.9422 - val_loss: 0.1915 - val_accuracy: 0.9395\n",
      "Epoch 662/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1692 - accuracy: 0.9426 - val_loss: 0.1915 - val_accuracy: 0.9395\n",
      "Epoch 663/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1691 - accuracy: 0.9421 - val_loss: 0.1916 - val_accuracy: 0.9392\n",
      "Epoch 664/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1690 - accuracy: 0.9422 - val_loss: 0.1915 - val_accuracy: 0.9395\n",
      "Epoch 665/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1689 - accuracy: 0.9424 - val_loss: 0.1913 - val_accuracy: 0.9397\n",
      "Epoch 666/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1688 - accuracy: 0.9420 - val_loss: 0.1913 - val_accuracy: 0.9395\n",
      "Epoch 667/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1687 - accuracy: 0.9425 - val_loss: 0.1910 - val_accuracy: 0.9393\n",
      "Epoch 668/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1686 - accuracy: 0.9426 - val_loss: 0.1909 - val_accuracy: 0.9397\n",
      "Epoch 669/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1686 - accuracy: 0.9426 - val_loss: 0.1910 - val_accuracy: 0.9395\n",
      "Epoch 670/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1684 - accuracy: 0.9425 - val_loss: 0.1910 - val_accuracy: 0.9393\n",
      "Epoch 671/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1682 - accuracy: 0.9424 - val_loss: 0.1907 - val_accuracy: 0.9390\n",
      "Epoch 672/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.1681 - accuracy: 0.9420 - val_loss: 0.1908 - val_accuracy: 0.9393\n",
      "Epoch 673/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1681 - accuracy: 0.9424 - val_loss: 0.1907 - val_accuracy: 0.9393\n",
      "Epoch 674/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1680 - accuracy: 0.9425 - val_loss: 0.1906 - val_accuracy: 0.9391\n",
      "Epoch 675/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1678 - accuracy: 0.9423 - val_loss: 0.1905 - val_accuracy: 0.9391\n",
      "Epoch 676/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1677 - accuracy: 0.9425 - val_loss: 0.1905 - val_accuracy: 0.9391\n",
      "Epoch 677/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1676 - accuracy: 0.9423 - val_loss: 0.1904 - val_accuracy: 0.9387\n",
      "Epoch 678/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1676 - accuracy: 0.9421 - val_loss: 0.1905 - val_accuracy: 0.9393\n",
      "Epoch 679/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1674 - accuracy: 0.9426 - val_loss: 0.1904 - val_accuracy: 0.9392\n",
      "Epoch 680/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1672 - accuracy: 0.9426 - val_loss: 0.1902 - val_accuracy: 0.9390\n",
      "Epoch 681/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1671 - accuracy: 0.9426 - val_loss: 0.1904 - val_accuracy: 0.9393\n",
      "Epoch 682/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1670 - accuracy: 0.9426 - val_loss: 0.1901 - val_accuracy: 0.9386\n",
      "Epoch 683/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1669 - accuracy: 0.9427 - val_loss: 0.1900 - val_accuracy: 0.9388\n",
      "Epoch 684/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1668 - accuracy: 0.9427 - val_loss: 0.1900 - val_accuracy: 0.9392\n",
      "Epoch 685/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1667 - accuracy: 0.9429 - val_loss: 0.1900 - val_accuracy: 0.9391\n",
      "Epoch 686/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1666 - accuracy: 0.9426 - val_loss: 0.1899 - val_accuracy: 0.9392\n",
      "Epoch 687/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1665 - accuracy: 0.9427 - val_loss: 0.1899 - val_accuracy: 0.9390\n",
      "Epoch 688/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1664 - accuracy: 0.9428 - val_loss: 0.1897 - val_accuracy: 0.9391\n",
      "Epoch 689/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1663 - accuracy: 0.9429 - val_loss: 0.1898 - val_accuracy: 0.9390\n",
      "Epoch 690/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1662 - accuracy: 0.9429 - val_loss: 0.1895 - val_accuracy: 0.9391\n",
      "Epoch 691/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1661 - accuracy: 0.9429 - val_loss: 0.1896 - val_accuracy: 0.9390\n",
      "Epoch 692/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1659 - accuracy: 0.9431 - val_loss: 0.1896 - val_accuracy: 0.9390\n",
      "Epoch 693/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1659 - accuracy: 0.9426 - val_loss: 0.1895 - val_accuracy: 0.9388\n",
      "Epoch 694/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1657 - accuracy: 0.9427 - val_loss: 0.1894 - val_accuracy: 0.9390\n",
      "Epoch 695/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1656 - accuracy: 0.9429 - val_loss: 0.1893 - val_accuracy: 0.9390\n",
      "Epoch 696/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1655 - accuracy: 0.9431 - val_loss: 0.1892 - val_accuracy: 0.9390\n",
      "Epoch 697/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1654 - accuracy: 0.9431 - val_loss: 0.1891 - val_accuracy: 0.9391\n",
      "Epoch 698/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1653 - accuracy: 0.9432 - val_loss: 0.1890 - val_accuracy: 0.9391\n",
      "Epoch 699/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1651 - accuracy: 0.9428 - val_loss: 0.1890 - val_accuracy: 0.9390\n",
      "Epoch 700/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1651 - accuracy: 0.9428 - val_loss: 0.1890 - val_accuracy: 0.9387\n",
      "Epoch 701/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1650 - accuracy: 0.9430 - val_loss: 0.1888 - val_accuracy: 0.9388\n",
      "Epoch 702/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1649 - accuracy: 0.9431 - val_loss: 0.1887 - val_accuracy: 0.9390\n",
      "Epoch 703/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1647 - accuracy: 0.9431 - val_loss: 0.1891 - val_accuracy: 0.9387\n",
      "Epoch 704/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1647 - accuracy: 0.9430 - val_loss: 0.1888 - val_accuracy: 0.9390\n",
      "Epoch 705/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1645 - accuracy: 0.9432 - val_loss: 0.1886 - val_accuracy: 0.9388\n",
      "Epoch 706/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1644 - accuracy: 0.9433 - val_loss: 0.1883 - val_accuracy: 0.9390\n",
      "Epoch 707/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1643 - accuracy: 0.9431 - val_loss: 0.1884 - val_accuracy: 0.9390\n",
      "Epoch 708/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1642 - accuracy: 0.9432 - val_loss: 0.1883 - val_accuracy: 0.9391\n",
      "Epoch 709/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1641 - accuracy: 0.9431 - val_loss: 0.1883 - val_accuracy: 0.9391\n",
      "Epoch 710/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1639 - accuracy: 0.9431 - val_loss: 0.1882 - val_accuracy: 0.9391\n",
      "Epoch 711/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1639 - accuracy: 0.9433 - val_loss: 0.1884 - val_accuracy: 0.9387\n",
      "Epoch 712/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1637 - accuracy: 0.9432 - val_loss: 0.1883 - val_accuracy: 0.9387\n",
      "Epoch 713/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1636 - accuracy: 0.9431 - val_loss: 0.1881 - val_accuracy: 0.9388\n",
      "Epoch 714/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1636 - accuracy: 0.9431 - val_loss: 0.1882 - val_accuracy: 0.9391\n",
      "Epoch 715/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1635 - accuracy: 0.9432 - val_loss: 0.1880 - val_accuracy: 0.9392\n",
      "Epoch 716/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1633 - accuracy: 0.9434 - val_loss: 0.1878 - val_accuracy: 0.9388\n",
      "Epoch 717/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1632 - accuracy: 0.9432 - val_loss: 0.1879 - val_accuracy: 0.9390\n",
      "Epoch 718/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1631 - accuracy: 0.9435 - val_loss: 0.1877 - val_accuracy: 0.9391\n",
      "Epoch 719/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1630 - accuracy: 0.9430 - val_loss: 0.1876 - val_accuracy: 0.9392\n",
      "Epoch 720/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1629 - accuracy: 0.9435 - val_loss: 0.1877 - val_accuracy: 0.9386\n",
      "Epoch 721/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1628 - accuracy: 0.9433 - val_loss: 0.1877 - val_accuracy: 0.9391\n",
      "Epoch 722/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1627 - accuracy: 0.9431 - val_loss: 0.1874 - val_accuracy: 0.9392\n",
      "Epoch 723/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1626 - accuracy: 0.9430 - val_loss: 0.1873 - val_accuracy: 0.9393\n",
      "Epoch 724/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1624 - accuracy: 0.9431 - val_loss: 0.1876 - val_accuracy: 0.9392\n",
      "Epoch 725/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1624 - accuracy: 0.9433 - val_loss: 0.1874 - val_accuracy: 0.9393\n",
      "Epoch 726/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1623 - accuracy: 0.9435 - val_loss: 0.1876 - val_accuracy: 0.9386\n",
      "Epoch 727/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1621 - accuracy: 0.9435 - val_loss: 0.1876 - val_accuracy: 0.9386\n",
      "Epoch 728/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.1620 - accuracy: 0.9433 - val_loss: 0.1871 - val_accuracy: 0.9395\n",
      "Epoch 729/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1619 - accuracy: 0.9436 - val_loss: 0.1872 - val_accuracy: 0.9386\n",
      "Epoch 730/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1619 - accuracy: 0.9437 - val_loss: 0.1873 - val_accuracy: 0.9392\n",
      "Epoch 731/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1617 - accuracy: 0.9434 - val_loss: 0.1868 - val_accuracy: 0.9391\n",
      "Epoch 732/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1616 - accuracy: 0.9438 - val_loss: 0.1869 - val_accuracy: 0.9391\n",
      "Epoch 733/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1615 - accuracy: 0.9435 - val_loss: 0.1869 - val_accuracy: 0.9393\n",
      "Epoch 734/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1615 - accuracy: 0.9434 - val_loss: 0.1868 - val_accuracy: 0.9391\n",
      "Epoch 735/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1614 - accuracy: 0.9438 - val_loss: 0.1870 - val_accuracy: 0.9388\n",
      "Epoch 736/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1611 - accuracy: 0.9437 - val_loss: 0.1867 - val_accuracy: 0.9391\n",
      "Epoch 737/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1611 - accuracy: 0.9435 - val_loss: 0.1868 - val_accuracy: 0.9386\n",
      "Epoch 738/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1610 - accuracy: 0.9435 - val_loss: 0.1867 - val_accuracy: 0.9385\n",
      "Epoch 739/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1609 - accuracy: 0.9435 - val_loss: 0.1866 - val_accuracy: 0.9388\n",
      "Epoch 740/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1608 - accuracy: 0.9435 - val_loss: 0.1866 - val_accuracy: 0.9386\n",
      "Epoch 741/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1606 - accuracy: 0.9436 - val_loss: 0.1867 - val_accuracy: 0.9386\n",
      "Epoch 742/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1606 - accuracy: 0.9435 - val_loss: 0.1863 - val_accuracy: 0.9398\n",
      "Epoch 743/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1604 - accuracy: 0.9440 - val_loss: 0.1863 - val_accuracy: 0.9395\n",
      "Epoch 744/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1603 - accuracy: 0.9439 - val_loss: 0.1861 - val_accuracy: 0.9388\n",
      "Epoch 745/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1602 - accuracy: 0.9438 - val_loss: 0.1862 - val_accuracy: 0.9390\n",
      "Epoch 746/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1601 - accuracy: 0.9440 - val_loss: 0.1863 - val_accuracy: 0.9388\n",
      "Epoch 747/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1600 - accuracy: 0.9439 - val_loss: 0.1862 - val_accuracy: 0.9388\n",
      "Epoch 748/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1599 - accuracy: 0.9438 - val_loss: 0.1860 - val_accuracy: 0.9391\n",
      "Epoch 749/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.1597 - accuracy: 0.9442 - val_loss: 0.1860 - val_accuracy: 0.9390\n",
      "Epoch 750/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1597 - accuracy: 0.9440 - val_loss: 0.1859 - val_accuracy: 0.9392\n",
      "Epoch 751/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1596 - accuracy: 0.9440 - val_loss: 0.1860 - val_accuracy: 0.9393\n",
      "Epoch 752/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1594 - accuracy: 0.9441 - val_loss: 0.1856 - val_accuracy: 0.9395\n",
      "Epoch 753/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1594 - accuracy: 0.9440 - val_loss: 0.1858 - val_accuracy: 0.9393\n",
      "Epoch 754/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1592 - accuracy: 0.9442 - val_loss: 0.1856 - val_accuracy: 0.9390\n",
      "Epoch 755/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1591 - accuracy: 0.9442 - val_loss: 0.1856 - val_accuracy: 0.9393\n",
      "Epoch 756/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1591 - accuracy: 0.9445 - val_loss: 0.1854 - val_accuracy: 0.9395\n",
      "Epoch 757/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1589 - accuracy: 0.9442 - val_loss: 0.1854 - val_accuracy: 0.9392\n",
      "Epoch 758/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1588 - accuracy: 0.9441 - val_loss: 0.1854 - val_accuracy: 0.9393\n",
      "Epoch 759/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1587 - accuracy: 0.9443 - val_loss: 0.1854 - val_accuracy: 0.9398\n",
      "Epoch 760/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1585 - accuracy: 0.9446 - val_loss: 0.1855 - val_accuracy: 0.9393\n",
      "Epoch 761/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1585 - accuracy: 0.9442 - val_loss: 0.1855 - val_accuracy: 0.9398\n",
      "Epoch 762/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1584 - accuracy: 0.9447 - val_loss: 0.1852 - val_accuracy: 0.9393\n",
      "Epoch 763/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1583 - accuracy: 0.9444 - val_loss: 0.1850 - val_accuracy: 0.9401\n",
      "Epoch 764/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1582 - accuracy: 0.9444 - val_loss: 0.1850 - val_accuracy: 0.9396\n",
      "Epoch 765/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1580 - accuracy: 0.9446 - val_loss: 0.1851 - val_accuracy: 0.9396\n",
      "Epoch 766/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1579 - accuracy: 0.9447 - val_loss: 0.1851 - val_accuracy: 0.9393\n",
      "Epoch 767/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1578 - accuracy: 0.9449 - val_loss: 0.1849 - val_accuracy: 0.9398\n",
      "Epoch 768/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1578 - accuracy: 0.9444 - val_loss: 0.1848 - val_accuracy: 0.9400\n",
      "Epoch 769/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1576 - accuracy: 0.9443 - val_loss: 0.1847 - val_accuracy: 0.9401\n",
      "Epoch 770/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1575 - accuracy: 0.9452 - val_loss: 0.1846 - val_accuracy: 0.9398\n",
      "Epoch 771/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1574 - accuracy: 0.9447 - val_loss: 0.1845 - val_accuracy: 0.9401\n",
      "Epoch 772/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1574 - accuracy: 0.9451 - val_loss: 0.1844 - val_accuracy: 0.9398\n",
      "Epoch 773/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1573 - accuracy: 0.9451 - val_loss: 0.1844 - val_accuracy: 0.9404\n",
      "Epoch 774/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1571 - accuracy: 0.9447 - val_loss: 0.1845 - val_accuracy: 0.9396\n",
      "Epoch 775/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1571 - accuracy: 0.9450 - val_loss: 0.1842 - val_accuracy: 0.9401\n",
      "Epoch 776/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1569 - accuracy: 0.9449 - val_loss: 0.1844 - val_accuracy: 0.9398\n",
      "Epoch 777/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1568 - accuracy: 0.9453 - val_loss: 0.1842 - val_accuracy: 0.9396\n",
      "Epoch 778/800\n",
      "480/480 [==============================] - 0s 104us/step - loss: 0.1567 - accuracy: 0.9452 - val_loss: 0.1842 - val_accuracy: 0.9406\n",
      "Epoch 779/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1566 - accuracy: 0.9453 - val_loss: 0.1841 - val_accuracy: 0.9400\n",
      "Epoch 780/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.1565 - accuracy: 0.9455 - val_loss: 0.1840 - val_accuracy: 0.9402\n",
      "Epoch 781/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1563 - accuracy: 0.9450 - val_loss: 0.1841 - val_accuracy: 0.9403\n",
      "Epoch 782/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1563 - accuracy: 0.9451 - val_loss: 0.1840 - val_accuracy: 0.9406\n",
      "Epoch 783/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1562 - accuracy: 0.9453 - val_loss: 0.1839 - val_accuracy: 0.9403\n",
      "Epoch 784/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 83us/step - loss: 0.1561 - accuracy: 0.9455 - val_loss: 0.1838 - val_accuracy: 0.9400\n",
      "Epoch 785/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1560 - accuracy: 0.9455 - val_loss: 0.1838 - val_accuracy: 0.9406\n",
      "Epoch 786/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1559 - accuracy: 0.9453 - val_loss: 0.1836 - val_accuracy: 0.9402\n",
      "Epoch 787/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1558 - accuracy: 0.9452 - val_loss: 0.1837 - val_accuracy: 0.9406\n",
      "Epoch 788/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1557 - accuracy: 0.9455 - val_loss: 0.1835 - val_accuracy: 0.9408\n",
      "Epoch 789/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1555 - accuracy: 0.9458 - val_loss: 0.1837 - val_accuracy: 0.9403\n",
      "Epoch 790/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1554 - accuracy: 0.9456 - val_loss: 0.1835 - val_accuracy: 0.9401\n",
      "Epoch 791/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1554 - accuracy: 0.9455 - val_loss: 0.1835 - val_accuracy: 0.9408\n",
      "Epoch 792/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1552 - accuracy: 0.9454 - val_loss: 0.1833 - val_accuracy: 0.9407\n",
      "Epoch 793/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1552 - accuracy: 0.9455 - val_loss: 0.1834 - val_accuracy: 0.9403\n",
      "Epoch 794/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1550 - accuracy: 0.9454 - val_loss: 0.1833 - val_accuracy: 0.9406\n",
      "Epoch 795/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1550 - accuracy: 0.9454 - val_loss: 0.1833 - val_accuracy: 0.9404\n",
      "Epoch 796/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1549 - accuracy: 0.9456 - val_loss: 0.1831 - val_accuracy: 0.9409\n",
      "Epoch 797/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1547 - accuracy: 0.9459 - val_loss: 0.1834 - val_accuracy: 0.9397\n",
      "Epoch 798/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1546 - accuracy: 0.9458 - val_loss: 0.1833 - val_accuracy: 0.9407\n",
      "Epoch 799/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1545 - accuracy: 0.9457 - val_loss: 0.1831 - val_accuracy: 0.9406\n",
      "Epoch 800/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1545 - accuracy: 0.9458 - val_loss: 0.1830 - val_accuracy: 0.9403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:122: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/800\n",
      "480/480 [==============================] - 0s 327us/step - loss: 0.6780 - accuracy: 0.6242 - val_loss: 0.6587 - val_accuracy: 0.7572\n",
      "Epoch 2/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.6393 - accuracy: 0.8222 - val_loss: 0.6140 - val_accuracy: 0.8661\n",
      "Epoch 3/800\n",
      "480/480 [==============================] - 0s 98us/step - loss: 0.5796 - accuracy: 0.8982 - val_loss: 0.5320 - val_accuracy: 0.9164\n",
      "Epoch 4/800\n",
      "480/480 [==============================] - 0s 102us/step - loss: 0.4672 - accuracy: 0.9310 - val_loss: 0.3889 - val_accuracy: 0.9368\n",
      "Epoch 5/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.3215 - accuracy: 0.9397 - val_loss: 0.2726 - val_accuracy: 0.9368\n",
      "Epoch 6/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2471 - accuracy: 0.9397 - val_loss: 0.2433 - val_accuracy: 0.9368\n",
      "Epoch 7/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2312 - accuracy: 0.9397 - val_loss: 0.2384 - val_accuracy: 0.9368\n",
      "Epoch 8/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2277 - accuracy: 0.9397 - val_loss: 0.2369 - val_accuracy: 0.9368\n",
      "Epoch 9/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2262 - accuracy: 0.9397 - val_loss: 0.2362 - val_accuracy: 0.9368\n",
      "Epoch 10/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2254 - accuracy: 0.9397 - val_loss: 0.2358 - val_accuracy: 0.9368\n",
      "Epoch 11/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2248 - accuracy: 0.9397 - val_loss: 0.2356 - val_accuracy: 0.9368\n",
      "Epoch 12/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2245 - accuracy: 0.9397 - val_loss: 0.2355 - val_accuracy: 0.9368\n",
      "Epoch 13/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2243 - accuracy: 0.9397 - val_loss: 0.2354 - val_accuracy: 0.9368\n",
      "Epoch 14/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2241 - accuracy: 0.9397 - val_loss: 0.2354 - val_accuracy: 0.9368\n",
      "Epoch 15/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2240 - accuracy: 0.9397 - val_loss: 0.2353 - val_accuracy: 0.9368\n",
      "Epoch 16/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2239 - accuracy: 0.9397 - val_loss: 0.2353 - val_accuracy: 0.9368\n",
      "Epoch 17/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2239 - accuracy: 0.9397 - val_loss: 0.2353 - val_accuracy: 0.9368\n",
      "Epoch 18/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2238 - accuracy: 0.9397 - val_loss: 0.2352 - val_accuracy: 0.9368\n",
      "Epoch 19/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2237 - accuracy: 0.9397 - val_loss: 0.2352 - val_accuracy: 0.9368\n",
      "Epoch 20/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2236 - accuracy: 0.9397 - val_loss: 0.2351 - val_accuracy: 0.9368\n",
      "Epoch 21/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2236 - accuracy: 0.9397 - val_loss: 0.2351 - val_accuracy: 0.9368\n",
      "Epoch 22/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2236 - accuracy: 0.9397 - val_loss: 0.2350 - val_accuracy: 0.9368\n",
      "Epoch 23/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2235 - accuracy: 0.9397 - val_loss: 0.2350 - val_accuracy: 0.9368\n",
      "Epoch 24/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2235 - accuracy: 0.9397 - val_loss: 0.2350 - val_accuracy: 0.9368\n",
      "Epoch 25/800\n",
      "480/480 [==============================] - 0s 91us/step - loss: 0.2234 - accuracy: 0.9397 - val_loss: 0.2350 - val_accuracy: 0.9368\n",
      "Epoch 26/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2234 - accuracy: 0.9397 - val_loss: 0.2349 - val_accuracy: 0.9368\n",
      "Epoch 27/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2233 - accuracy: 0.9397 - val_loss: 0.2349 - val_accuracy: 0.9368\n",
      "Epoch 28/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2233 - accuracy: 0.9397 - val_loss: 0.2350 - val_accuracy: 0.9368\n",
      "Epoch 29/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2233 - accuracy: 0.9397 - val_loss: 0.2349 - val_accuracy: 0.9368\n",
      "Epoch 30/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2232 - accuracy: 0.9397 - val_loss: 0.2348 - val_accuracy: 0.9368\n",
      "Epoch 31/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2232 - accuracy: 0.9397 - val_loss: 0.2348 - val_accuracy: 0.9368\n",
      "Epoch 32/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2232 - accuracy: 0.9397 - val_loss: 0.2348 - val_accuracy: 0.9368\n",
      "Epoch 33/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2232 - accuracy: 0.9397 - val_loss: 0.2348 - val_accuracy: 0.9368\n",
      "Epoch 34/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2231 - accuracy: 0.9397 - val_loss: 0.2347 - val_accuracy: 0.9368\n",
      "Epoch 35/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2231 - accuracy: 0.9397 - val_loss: 0.2347 - val_accuracy: 0.9368\n",
      "Epoch 36/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2230 - accuracy: 0.9397 - val_loss: 0.2347 - val_accuracy: 0.9368\n",
      "Epoch 37/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2230 - accuracy: 0.9397 - val_loss: 0.2346 - val_accuracy: 0.9368\n",
      "Epoch 38/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2230 - accuracy: 0.9397 - val_loss: 0.2346 - val_accuracy: 0.9368\n",
      "Epoch 39/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2229 - accuracy: 0.9397 - val_loss: 0.2346 - val_accuracy: 0.9368\n",
      "Epoch 40/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2229 - accuracy: 0.9397 - val_loss: 0.2346 - val_accuracy: 0.9368\n",
      "Epoch 41/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2229 - accuracy: 0.9397 - val_loss: 0.2346 - val_accuracy: 0.9368\n",
      "Epoch 42/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2228 - accuracy: 0.9397 - val_loss: 0.2346 - val_accuracy: 0.9368\n",
      "Epoch 43/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2228 - accuracy: 0.9397 - val_loss: 0.2345 - val_accuracy: 0.9368\n",
      "Epoch 44/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2228 - accuracy: 0.9397 - val_loss: 0.2345 - val_accuracy: 0.9368\n",
      "Epoch 45/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2228 - accuracy: 0.9397 - val_loss: 0.2345 - val_accuracy: 0.9368\n",
      "Epoch 46/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2227 - accuracy: 0.9397 - val_loss: 0.2344 - val_accuracy: 0.9368\n",
      "Epoch 47/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2227 - accuracy: 0.9397 - val_loss: 0.2344 - val_accuracy: 0.9368\n",
      "Epoch 48/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2227 - accuracy: 0.9397 - val_loss: 0.2344 - val_accuracy: 0.9368\n",
      "Epoch 49/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2226 - accuracy: 0.9397 - val_loss: 0.2344 - val_accuracy: 0.9368\n",
      "Epoch 50/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2226 - accuracy: 0.9397 - val_loss: 0.2344 - val_accuracy: 0.9368\n",
      "Epoch 51/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2226 - accuracy: 0.9397 - val_loss: 0.2343 - val_accuracy: 0.9368\n",
      "Epoch 52/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2225 - accuracy: 0.9397 - val_loss: 0.2343 - val_accuracy: 0.9368\n",
      "Epoch 53/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2225 - accuracy: 0.9397 - val_loss: 0.2343 - val_accuracy: 0.9368\n",
      "Epoch 54/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2225 - accuracy: 0.9397 - val_loss: 0.2343 - val_accuracy: 0.9368\n",
      "Epoch 55/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2225 - accuracy: 0.9397 - val_loss: 0.2343 - val_accuracy: 0.9368\n",
      "Epoch 56/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.2224 - accuracy: 0.9397 - val_loss: 0.2343 - val_accuracy: 0.9368\n",
      "Epoch 57/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2224 - accuracy: 0.9397 - val_loss: 0.2342 - val_accuracy: 0.9368\n",
      "Epoch 58/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2223 - accuracy: 0.9397 - val_loss: 0.2342 - val_accuracy: 0.9368\n",
      "Epoch 59/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2223 - accuracy: 0.9397 - val_loss: 0.2342 - val_accuracy: 0.9368\n",
      "Epoch 60/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2223 - accuracy: 0.9397 - val_loss: 0.2342 - val_accuracy: 0.9368\n",
      "Epoch 61/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2222 - accuracy: 0.9397 - val_loss: 0.2341 - val_accuracy: 0.9368\n",
      "Epoch 62/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2222 - accuracy: 0.9397 - val_loss: 0.2341 - val_accuracy: 0.9368\n",
      "Epoch 63/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2222 - accuracy: 0.9397 - val_loss: 0.2341 - val_accuracy: 0.9368\n",
      "Epoch 64/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2222 - accuracy: 0.9397 - val_loss: 0.2341 - val_accuracy: 0.9368\n",
      "Epoch 65/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2221 - accuracy: 0.9397 - val_loss: 0.2340 - val_accuracy: 0.9368\n",
      "Epoch 66/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2221 - accuracy: 0.9397 - val_loss: 0.2340 - val_accuracy: 0.9368\n",
      "Epoch 67/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2221 - accuracy: 0.9397 - val_loss: 0.2339 - val_accuracy: 0.9368\n",
      "Epoch 68/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2221 - accuracy: 0.9397 - val_loss: 0.2340 - val_accuracy: 0.9368\n",
      "Epoch 69/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2221 - accuracy: 0.9397 - val_loss: 0.2340 - val_accuracy: 0.9368\n",
      "Epoch 70/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2220 - accuracy: 0.9397 - val_loss: 0.2340 - val_accuracy: 0.9368\n",
      "Epoch 71/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2220 - accuracy: 0.9397 - val_loss: 0.2340 - val_accuracy: 0.9368\n",
      "Epoch 72/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2219 - accuracy: 0.9397 - val_loss: 0.2339 - val_accuracy: 0.9368\n",
      "Epoch 73/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2219 - accuracy: 0.9397 - val_loss: 0.2339 - val_accuracy: 0.9368\n",
      "Epoch 74/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2219 - accuracy: 0.9397 - val_loss: 0.2339 - val_accuracy: 0.9368\n",
      "Epoch 75/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2219 - accuracy: 0.9397 - val_loss: 0.2339 - val_accuracy: 0.9368\n",
      "Epoch 76/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2218 - accuracy: 0.9397 - val_loss: 0.2339 - val_accuracy: 0.9368\n",
      "Epoch 77/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2218 - accuracy: 0.9397 - val_loss: 0.2338 - val_accuracy: 0.9368\n",
      "Epoch 78/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2218 - accuracy: 0.9397 - val_loss: 0.2338 - val_accuracy: 0.9368\n",
      "Epoch 79/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2218 - accuracy: 0.9397 - val_loss: 0.2338 - val_accuracy: 0.9368\n",
      "Epoch 80/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2217 - accuracy: 0.9397 - val_loss: 0.2338 - val_accuracy: 0.9368\n",
      "Epoch 81/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2217 - accuracy: 0.9397 - val_loss: 0.2338 - val_accuracy: 0.9368\n",
      "Epoch 82/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2216 - accuracy: 0.9397 - val_loss: 0.2337 - val_accuracy: 0.9368\n",
      "Epoch 83/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2216 - accuracy: 0.9397 - val_loss: 0.2337 - val_accuracy: 0.9368\n",
      "Epoch 84/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2216 - accuracy: 0.9397 - val_loss: 0.2337 - val_accuracy: 0.9368\n",
      "Epoch 85/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2215 - accuracy: 0.9397 - val_loss: 0.2336 - val_accuracy: 0.9368\n",
      "Epoch 86/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2215 - accuracy: 0.9397 - val_loss: 0.2337 - val_accuracy: 0.9368\n",
      "Epoch 87/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2216 - accuracy: 0.9397 - val_loss: 0.2336 - val_accuracy: 0.9368\n",
      "Epoch 88/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2214 - accuracy: 0.9397 - val_loss: 0.2336 - val_accuracy: 0.9368\n",
      "Epoch 89/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2214 - accuracy: 0.9397 - val_loss: 0.2336 - val_accuracy: 0.9368\n",
      "Epoch 90/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2214 - accuracy: 0.9397 - val_loss: 0.2336 - val_accuracy: 0.9368\n",
      "Epoch 91/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2214 - accuracy: 0.9397 - val_loss: 0.2335 - val_accuracy: 0.9368\n",
      "Epoch 92/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2214 - accuracy: 0.9397 - val_loss: 0.2335 - val_accuracy: 0.9368\n",
      "Epoch 93/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2213 - accuracy: 0.9397 - val_loss: 0.2335 - val_accuracy: 0.9368\n",
      "Epoch 94/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2213 - accuracy: 0.9397 - val_loss: 0.2334 - val_accuracy: 0.9368\n",
      "Epoch 95/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2213 - accuracy: 0.9397 - val_loss: 0.2334 - val_accuracy: 0.9368\n",
      "Epoch 96/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2213 - accuracy: 0.9397 - val_loss: 0.2334 - val_accuracy: 0.9368\n",
      "Epoch 97/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2212 - accuracy: 0.9397 - val_loss: 0.2334 - val_accuracy: 0.9368\n",
      "Epoch 98/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2212 - accuracy: 0.9397 - val_loss: 0.2334 - val_accuracy: 0.9368\n",
      "Epoch 99/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2211 - accuracy: 0.9397 - val_loss: 0.2333 - val_accuracy: 0.9368\n",
      "Epoch 100/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2211 - accuracy: 0.9397 - val_loss: 0.2333 - val_accuracy: 0.9368\n",
      "Epoch 101/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2211 - accuracy: 0.9397 - val_loss: 0.2333 - val_accuracy: 0.9368\n",
      "Epoch 102/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2211 - accuracy: 0.9397 - val_loss: 0.2332 - val_accuracy: 0.9368\n",
      "Epoch 103/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2210 - accuracy: 0.9397 - val_loss: 0.2333 - val_accuracy: 0.9368\n",
      "Epoch 104/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2210 - accuracy: 0.9397 - val_loss: 0.2332 - val_accuracy: 0.9368\n",
      "Epoch 105/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2210 - accuracy: 0.9397 - val_loss: 0.2332 - val_accuracy: 0.9368\n",
      "Epoch 106/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2209 - accuracy: 0.9397 - val_loss: 0.2332 - val_accuracy: 0.9368\n",
      "Epoch 107/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2209 - accuracy: 0.9397 - val_loss: 0.2332 - val_accuracy: 0.9368\n",
      "Epoch 108/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2209 - accuracy: 0.9397 - val_loss: 0.2332 - val_accuracy: 0.9368\n",
      "Epoch 109/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2209 - accuracy: 0.9397 - val_loss: 0.2332 - val_accuracy: 0.9368\n",
      "Epoch 110/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2209 - accuracy: 0.9397 - val_loss: 0.2331 - val_accuracy: 0.9368\n",
      "Epoch 111/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2208 - accuracy: 0.9397 - val_loss: 0.2330 - val_accuracy: 0.9368\n",
      "Epoch 112/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 90us/step - loss: 0.2208 - accuracy: 0.9397 - val_loss: 0.2330 - val_accuracy: 0.9368\n",
      "Epoch 113/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2207 - accuracy: 0.9397 - val_loss: 0.2330 - val_accuracy: 0.9368\n",
      "Epoch 114/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2207 - accuracy: 0.9397 - val_loss: 0.2330 - val_accuracy: 0.9368\n",
      "Epoch 115/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2207 - accuracy: 0.9397 - val_loss: 0.2330 - val_accuracy: 0.9368\n",
      "Epoch 116/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2206 - accuracy: 0.9397 - val_loss: 0.2329 - val_accuracy: 0.9368\n",
      "Epoch 117/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2206 - accuracy: 0.9397 - val_loss: 0.2330 - val_accuracy: 0.9368\n",
      "Epoch 118/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2206 - accuracy: 0.9397 - val_loss: 0.2329 - val_accuracy: 0.9368\n",
      "Epoch 119/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2205 - accuracy: 0.9397 - val_loss: 0.2329 - val_accuracy: 0.9368\n",
      "Epoch 120/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2205 - accuracy: 0.9397 - val_loss: 0.2329 - val_accuracy: 0.9368\n",
      "Epoch 121/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2205 - accuracy: 0.9397 - val_loss: 0.2329 - val_accuracy: 0.9368\n",
      "Epoch 122/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2205 - accuracy: 0.9397 - val_loss: 0.2328 - val_accuracy: 0.9368\n",
      "Epoch 123/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2204 - accuracy: 0.9397 - val_loss: 0.2328 - val_accuracy: 0.9368\n",
      "Epoch 124/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2204 - accuracy: 0.9397 - val_loss: 0.2327 - val_accuracy: 0.9368\n",
      "Epoch 125/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2203 - accuracy: 0.9397 - val_loss: 0.2327 - val_accuracy: 0.9368\n",
      "Epoch 126/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2203 - accuracy: 0.9397 - val_loss: 0.2327 - val_accuracy: 0.9368\n",
      "Epoch 127/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2203 - accuracy: 0.9397 - val_loss: 0.2327 - val_accuracy: 0.9368\n",
      "Epoch 128/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2202 - accuracy: 0.9397 - val_loss: 0.2327 - val_accuracy: 0.9368\n",
      "Epoch 129/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2202 - accuracy: 0.9397 - val_loss: 0.2327 - val_accuracy: 0.9368\n",
      "Epoch 130/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2202 - accuracy: 0.9397 - val_loss: 0.2326 - val_accuracy: 0.9368\n",
      "Epoch 131/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2201 - accuracy: 0.9397 - val_loss: 0.2326 - val_accuracy: 0.9368\n",
      "Epoch 132/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2201 - accuracy: 0.9397 - val_loss: 0.2326 - val_accuracy: 0.9368\n",
      "Epoch 133/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2201 - accuracy: 0.9397 - val_loss: 0.2326 - val_accuracy: 0.9368\n",
      "Epoch 134/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2201 - accuracy: 0.9397 - val_loss: 0.2325 - val_accuracy: 0.9368\n",
      "Epoch 135/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2200 - accuracy: 0.9397 - val_loss: 0.2325 - val_accuracy: 0.9368\n",
      "Epoch 136/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2200 - accuracy: 0.9397 - val_loss: 0.2325 - val_accuracy: 0.9368\n",
      "Epoch 137/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2199 - accuracy: 0.9397 - val_loss: 0.2324 - val_accuracy: 0.9368\n",
      "Epoch 138/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2199 - accuracy: 0.9397 - val_loss: 0.2324 - val_accuracy: 0.9368\n",
      "Epoch 139/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2199 - accuracy: 0.9397 - val_loss: 0.2324 - val_accuracy: 0.9368\n",
      "Epoch 140/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2198 - accuracy: 0.9397 - val_loss: 0.2324 - val_accuracy: 0.9368\n",
      "Epoch 141/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2198 - accuracy: 0.9397 - val_loss: 0.2324 - val_accuracy: 0.9368\n",
      "Epoch 142/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2197 - accuracy: 0.9397 - val_loss: 0.2324 - val_accuracy: 0.9368\n",
      "Epoch 143/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2197 - accuracy: 0.9397 - val_loss: 0.2323 - val_accuracy: 0.9368\n",
      "Epoch 144/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2196 - accuracy: 0.9397 - val_loss: 0.2323 - val_accuracy: 0.9368\n",
      "Epoch 145/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2196 - accuracy: 0.9397 - val_loss: 0.2322 - val_accuracy: 0.9368\n",
      "Epoch 146/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2196 - accuracy: 0.9397 - val_loss: 0.2322 - val_accuracy: 0.9368\n",
      "Epoch 147/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2195 - accuracy: 0.9397 - val_loss: 0.2322 - val_accuracy: 0.9368\n",
      "Epoch 148/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2195 - accuracy: 0.9397 - val_loss: 0.2321 - val_accuracy: 0.9368\n",
      "Epoch 149/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2195 - accuracy: 0.9397 - val_loss: 0.2321 - val_accuracy: 0.9368\n",
      "Epoch 150/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2195 - accuracy: 0.9397 - val_loss: 0.2321 - val_accuracy: 0.9368\n",
      "Epoch 151/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2194 - accuracy: 0.9397 - val_loss: 0.2321 - val_accuracy: 0.9368\n",
      "Epoch 152/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2193 - accuracy: 0.9397 - val_loss: 0.2321 - val_accuracy: 0.9368\n",
      "Epoch 153/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2193 - accuracy: 0.9397 - val_loss: 0.2320 - val_accuracy: 0.9368\n",
      "Epoch 154/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2193 - accuracy: 0.9397 - val_loss: 0.2319 - val_accuracy: 0.9368\n",
      "Epoch 155/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2192 - accuracy: 0.9397 - val_loss: 0.2319 - val_accuracy: 0.9368\n",
      "Epoch 156/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2192 - accuracy: 0.9397 - val_loss: 0.2319 - val_accuracy: 0.9368\n",
      "Epoch 157/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2191 - accuracy: 0.9397 - val_loss: 0.2319 - val_accuracy: 0.9368\n",
      "Epoch 158/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2191 - accuracy: 0.9397 - val_loss: 0.2318 - val_accuracy: 0.9368\n",
      "Epoch 159/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2191 - accuracy: 0.9397 - val_loss: 0.2318 - val_accuracy: 0.9368\n",
      "Epoch 160/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2190 - accuracy: 0.9397 - val_loss: 0.2318 - val_accuracy: 0.9368\n",
      "Epoch 161/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2190 - accuracy: 0.9397 - val_loss: 0.2318 - val_accuracy: 0.9368\n",
      "Epoch 162/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2189 - accuracy: 0.9397 - val_loss: 0.2316 - val_accuracy: 0.9368\n",
      "Epoch 163/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2188 - accuracy: 0.9397 - val_loss: 0.2316 - val_accuracy: 0.9368\n",
      "Epoch 164/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2188 - accuracy: 0.9397 - val_loss: 0.2316 - val_accuracy: 0.9368\n",
      "Epoch 165/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2188 - accuracy: 0.9397 - val_loss: 0.2316 - val_accuracy: 0.9368\n",
      "Epoch 166/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2187 - accuracy: 0.9397 - val_loss: 0.2315 - val_accuracy: 0.9368\n",
      "Epoch 167/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2187 - accuracy: 0.9397 - val_loss: 0.2315 - val_accuracy: 0.9368\n",
      "Epoch 168/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 83us/step - loss: 0.2187 - accuracy: 0.9397 - val_loss: 0.2314 - val_accuracy: 0.9368\n",
      "Epoch 169/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2186 - accuracy: 0.9397 - val_loss: 0.2314 - val_accuracy: 0.9368\n",
      "Epoch 170/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2185 - accuracy: 0.9397 - val_loss: 0.2314 - val_accuracy: 0.9368\n",
      "Epoch 171/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2185 - accuracy: 0.9397 - val_loss: 0.2314 - val_accuracy: 0.9368\n",
      "Epoch 172/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2184 - accuracy: 0.9397 - val_loss: 0.2313 - val_accuracy: 0.9368\n",
      "Epoch 173/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2184 - accuracy: 0.9397 - val_loss: 0.2313 - val_accuracy: 0.9368\n",
      "Epoch 174/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2184 - accuracy: 0.9397 - val_loss: 0.2313 - val_accuracy: 0.9368\n",
      "Epoch 175/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2183 - accuracy: 0.9397 - val_loss: 0.2312 - val_accuracy: 0.9368\n",
      "Epoch 176/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2183 - accuracy: 0.9397 - val_loss: 0.2312 - val_accuracy: 0.9368\n",
      "Epoch 177/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2182 - accuracy: 0.9397 - val_loss: 0.2311 - val_accuracy: 0.9368\n",
      "Epoch 178/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2182 - accuracy: 0.9397 - val_loss: 0.2311 - val_accuracy: 0.9368\n",
      "Epoch 179/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2181 - accuracy: 0.9397 - val_loss: 0.2312 - val_accuracy: 0.9368\n",
      "Epoch 180/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2181 - accuracy: 0.9397 - val_loss: 0.2311 - val_accuracy: 0.9368\n",
      "Epoch 181/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2180 - accuracy: 0.9397 - val_loss: 0.2311 - val_accuracy: 0.9368\n",
      "Epoch 182/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2180 - accuracy: 0.9397 - val_loss: 0.2310 - val_accuracy: 0.9368\n",
      "Epoch 183/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2179 - accuracy: 0.9397 - val_loss: 0.2310 - val_accuracy: 0.9368\n",
      "Epoch 184/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2179 - accuracy: 0.9397 - val_loss: 0.2310 - val_accuracy: 0.9368\n",
      "Epoch 185/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2178 - accuracy: 0.9397 - val_loss: 0.2309 - val_accuracy: 0.9368\n",
      "Epoch 186/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2177 - accuracy: 0.9397 - val_loss: 0.2309 - val_accuracy: 0.9368\n",
      "Epoch 187/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2177 - accuracy: 0.9397 - val_loss: 0.2309 - val_accuracy: 0.9368\n",
      "Epoch 188/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2176 - accuracy: 0.9397 - val_loss: 0.2308 - val_accuracy: 0.9368\n",
      "Epoch 189/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2176 - accuracy: 0.9397 - val_loss: 0.2308 - val_accuracy: 0.9368\n",
      "Epoch 190/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2176 - accuracy: 0.9397 - val_loss: 0.2308 - val_accuracy: 0.9368\n",
      "Epoch 191/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2175 - accuracy: 0.9397 - val_loss: 0.2307 - val_accuracy: 0.9368\n",
      "Epoch 192/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2174 - accuracy: 0.9397 - val_loss: 0.2307 - val_accuracy: 0.9368\n",
      "Epoch 193/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2174 - accuracy: 0.9397 - val_loss: 0.2306 - val_accuracy: 0.9368\n",
      "Epoch 194/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2173 - accuracy: 0.9397 - val_loss: 0.2306 - val_accuracy: 0.9368\n",
      "Epoch 195/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2173 - accuracy: 0.9397 - val_loss: 0.2305 - val_accuracy: 0.9368\n",
      "Epoch 196/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2172 - accuracy: 0.9397 - val_loss: 0.2305 - val_accuracy: 0.9368\n",
      "Epoch 197/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2172 - accuracy: 0.9397 - val_loss: 0.2304 - val_accuracy: 0.9368\n",
      "Epoch 198/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2171 - accuracy: 0.9397 - val_loss: 0.2304 - val_accuracy: 0.9368\n",
      "Epoch 199/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2171 - accuracy: 0.9397 - val_loss: 0.2303 - val_accuracy: 0.9368\n",
      "Epoch 200/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2170 - accuracy: 0.9397 - val_loss: 0.2303 - val_accuracy: 0.9368\n",
      "Epoch 201/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2169 - accuracy: 0.9397 - val_loss: 0.2302 - val_accuracy: 0.9368\n",
      "Epoch 202/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2169 - accuracy: 0.9397 - val_loss: 0.2301 - val_accuracy: 0.9368\n",
      "Epoch 203/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2168 - accuracy: 0.9397 - val_loss: 0.2301 - val_accuracy: 0.9368\n",
      "Epoch 204/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2168 - accuracy: 0.9397 - val_loss: 0.2301 - val_accuracy: 0.9368\n",
      "Epoch 205/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2167 - accuracy: 0.9397 - val_loss: 0.2300 - val_accuracy: 0.9368\n",
      "Epoch 206/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2166 - accuracy: 0.9397 - val_loss: 0.2299 - val_accuracy: 0.9368\n",
      "Epoch 207/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2165 - accuracy: 0.9397 - val_loss: 0.2299 - val_accuracy: 0.9368\n",
      "Epoch 208/800\n",
      "480/480 [==============================] - 0s 80us/step - loss: 0.2165 - accuracy: 0.9397 - val_loss: 0.2299 - val_accuracy: 0.9368\n",
      "Epoch 209/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2164 - accuracy: 0.9397 - val_loss: 0.2298 - val_accuracy: 0.9368\n",
      "Epoch 210/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2163 - accuracy: 0.9397 - val_loss: 0.2298 - val_accuracy: 0.9368\n",
      "Epoch 211/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2163 - accuracy: 0.9397 - val_loss: 0.2297 - val_accuracy: 0.9368\n",
      "Epoch 212/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2162 - accuracy: 0.9397 - val_loss: 0.2296 - val_accuracy: 0.9368\n",
      "Epoch 213/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2162 - accuracy: 0.9397 - val_loss: 0.2296 - val_accuracy: 0.9368\n",
      "Epoch 214/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2160 - accuracy: 0.9397 - val_loss: 0.2295 - val_accuracy: 0.9368\n",
      "Epoch 215/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2160 - accuracy: 0.9397 - val_loss: 0.2295 - val_accuracy: 0.9368\n",
      "Epoch 216/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2159 - accuracy: 0.9397 - val_loss: 0.2295 - val_accuracy: 0.9368\n",
      "Epoch 217/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2159 - accuracy: 0.9397 - val_loss: 0.2294 - val_accuracy: 0.9368\n",
      "Epoch 218/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2158 - accuracy: 0.9397 - val_loss: 0.2293 - val_accuracy: 0.9368\n",
      "Epoch 219/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2157 - accuracy: 0.9397 - val_loss: 0.2293 - val_accuracy: 0.9368\n",
      "Epoch 220/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2156 - accuracy: 0.9397 - val_loss: 0.2292 - val_accuracy: 0.9368\n",
      "Epoch 221/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2156 - accuracy: 0.9397 - val_loss: 0.2292 - val_accuracy: 0.9368\n",
      "Epoch 222/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2155 - accuracy: 0.9397 - val_loss: 0.2291 - val_accuracy: 0.9368\n",
      "Epoch 223/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2155 - accuracy: 0.9397 - val_loss: 0.2291 - val_accuracy: 0.9368\n",
      "Epoch 224/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.2154 - accuracy: 0.9397 - val_loss: 0.2290 - val_accuracy: 0.9368\n",
      "Epoch 225/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2153 - accuracy: 0.9397 - val_loss: 0.2289 - val_accuracy: 0.9368\n",
      "Epoch 226/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2152 - accuracy: 0.9397 - val_loss: 0.2289 - val_accuracy: 0.9368\n",
      "Epoch 227/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2151 - accuracy: 0.9397 - val_loss: 0.2288 - val_accuracy: 0.9368\n",
      "Epoch 228/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2151 - accuracy: 0.9397 - val_loss: 0.2287 - val_accuracy: 0.9368\n",
      "Epoch 229/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2149 - accuracy: 0.9397 - val_loss: 0.2287 - val_accuracy: 0.9368\n",
      "Epoch 230/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2149 - accuracy: 0.9397 - val_loss: 0.2286 - val_accuracy: 0.9368\n",
      "Epoch 231/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2148 - accuracy: 0.9397 - val_loss: 0.2286 - val_accuracy: 0.9368\n",
      "Epoch 232/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2147 - accuracy: 0.9397 - val_loss: 0.2286 - val_accuracy: 0.9368\n",
      "Epoch 233/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2146 - accuracy: 0.9397 - val_loss: 0.2285 - val_accuracy: 0.9368\n",
      "Epoch 234/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2145 - accuracy: 0.9397 - val_loss: 0.2284 - val_accuracy: 0.9368\n",
      "Epoch 235/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2144 - accuracy: 0.9397 - val_loss: 0.2284 - val_accuracy: 0.9368\n",
      "Epoch 236/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2144 - accuracy: 0.9397 - val_loss: 0.2283 - val_accuracy: 0.9368\n",
      "Epoch 237/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2143 - accuracy: 0.9397 - val_loss: 0.2282 - val_accuracy: 0.9368\n",
      "Epoch 238/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2142 - accuracy: 0.9397 - val_loss: 0.2282 - val_accuracy: 0.9368\n",
      "Epoch 239/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2141 - accuracy: 0.9397 - val_loss: 0.2281 - val_accuracy: 0.9368\n",
      "Epoch 240/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2140 - accuracy: 0.9397 - val_loss: 0.2280 - val_accuracy: 0.9368\n",
      "Epoch 241/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2140 - accuracy: 0.9397 - val_loss: 0.2280 - val_accuracy: 0.9368\n",
      "Epoch 242/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2139 - accuracy: 0.9397 - val_loss: 0.2279 - val_accuracy: 0.9368\n",
      "Epoch 243/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2138 - accuracy: 0.9397 - val_loss: 0.2278 - val_accuracy: 0.9368\n",
      "Epoch 244/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2136 - accuracy: 0.9397 - val_loss: 0.2277 - val_accuracy: 0.9368\n",
      "Epoch 245/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2136 - accuracy: 0.9397 - val_loss: 0.2276 - val_accuracy: 0.9368\n",
      "Epoch 246/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2135 - accuracy: 0.9397 - val_loss: 0.2276 - val_accuracy: 0.9368\n",
      "Epoch 247/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.2134 - accuracy: 0.9397 - val_loss: 0.2276 - val_accuracy: 0.9368\n",
      "Epoch 248/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2133 - accuracy: 0.9397 - val_loss: 0.2275 - val_accuracy: 0.9368\n",
      "Epoch 249/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2132 - accuracy: 0.9397 - val_loss: 0.2273 - val_accuracy: 0.9368\n",
      "Epoch 250/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2131 - accuracy: 0.9397 - val_loss: 0.2273 - val_accuracy: 0.9368\n",
      "Epoch 251/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2130 - accuracy: 0.9397 - val_loss: 0.2272 - val_accuracy: 0.9368\n",
      "Epoch 252/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2129 - accuracy: 0.9397 - val_loss: 0.2272 - val_accuracy: 0.9368\n",
      "Epoch 253/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2127 - accuracy: 0.9397 - val_loss: 0.2271 - val_accuracy: 0.9368\n",
      "Epoch 254/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2127 - accuracy: 0.9397 - val_loss: 0.2270 - val_accuracy: 0.9368\n",
      "Epoch 255/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2126 - accuracy: 0.9397 - val_loss: 0.2270 - val_accuracy: 0.9368\n",
      "Epoch 256/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2124 - accuracy: 0.9397 - val_loss: 0.2268 - val_accuracy: 0.9368\n",
      "Epoch 257/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2124 - accuracy: 0.9397 - val_loss: 0.2268 - val_accuracy: 0.9368\n",
      "Epoch 258/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2123 - accuracy: 0.9397 - val_loss: 0.2267 - val_accuracy: 0.9368\n",
      "Epoch 259/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2121 - accuracy: 0.9397 - val_loss: 0.2266 - val_accuracy: 0.9368\n",
      "Epoch 260/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2120 - accuracy: 0.9397 - val_loss: 0.2265 - val_accuracy: 0.9368\n",
      "Epoch 261/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2119 - accuracy: 0.9397 - val_loss: 0.2263 - val_accuracy: 0.9368\n",
      "Epoch 262/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2118 - accuracy: 0.9397 - val_loss: 0.2263 - val_accuracy: 0.9368\n",
      "Epoch 263/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2117 - accuracy: 0.9397 - val_loss: 0.2262 - val_accuracy: 0.9368\n",
      "Epoch 264/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2116 - accuracy: 0.9397 - val_loss: 0.2262 - val_accuracy: 0.9368\n",
      "Epoch 265/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2115 - accuracy: 0.9397 - val_loss: 0.2261 - val_accuracy: 0.9368\n",
      "Epoch 266/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2114 - accuracy: 0.9397 - val_loss: 0.2260 - val_accuracy: 0.9368\n",
      "Epoch 267/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2112 - accuracy: 0.9397 - val_loss: 0.2259 - val_accuracy: 0.9368\n",
      "Epoch 268/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2112 - accuracy: 0.9397 - val_loss: 0.2258 - val_accuracy: 0.9368\n",
      "Epoch 269/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2110 - accuracy: 0.9397 - val_loss: 0.2257 - val_accuracy: 0.9368\n",
      "Epoch 270/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2109 - accuracy: 0.9397 - val_loss: 0.2256 - val_accuracy: 0.9368\n",
      "Epoch 271/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2108 - accuracy: 0.9397 - val_loss: 0.2255 - val_accuracy: 0.9368\n",
      "Epoch 272/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2107 - accuracy: 0.9397 - val_loss: 0.2254 - val_accuracy: 0.9368\n",
      "Epoch 273/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2105 - accuracy: 0.9397 - val_loss: 0.2253 - val_accuracy: 0.9368\n",
      "Epoch 274/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2104 - accuracy: 0.9397 - val_loss: 0.2252 - val_accuracy: 0.9368\n",
      "Epoch 275/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2103 - accuracy: 0.9397 - val_loss: 0.2252 - val_accuracy: 0.9368\n",
      "Epoch 276/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2102 - accuracy: 0.9397 - val_loss: 0.2251 - val_accuracy: 0.9368\n",
      "Epoch 277/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2100 - accuracy: 0.9397 - val_loss: 0.2249 - val_accuracy: 0.9368\n",
      "Epoch 278/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2099 - accuracy: 0.9397 - val_loss: 0.2248 - val_accuracy: 0.9368\n",
      "Epoch 279/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2097 - accuracy: 0.9397 - val_loss: 0.2248 - val_accuracy: 0.9368\n",
      "Epoch 280/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 81us/step - loss: 0.2096 - accuracy: 0.9397 - val_loss: 0.2246 - val_accuracy: 0.9368\n",
      "Epoch 281/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2095 - accuracy: 0.9397 - val_loss: 0.2245 - val_accuracy: 0.9368\n",
      "Epoch 282/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2094 - accuracy: 0.9397 - val_loss: 0.2245 - val_accuracy: 0.9368\n",
      "Epoch 283/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2092 - accuracy: 0.9397 - val_loss: 0.2243 - val_accuracy: 0.9368\n",
      "Epoch 284/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2091 - accuracy: 0.9397 - val_loss: 0.2242 - val_accuracy: 0.9368\n",
      "Epoch 285/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2089 - accuracy: 0.9397 - val_loss: 0.2241 - val_accuracy: 0.9368\n",
      "Epoch 286/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2089 - accuracy: 0.9397 - val_loss: 0.2240 - val_accuracy: 0.9368\n",
      "Epoch 287/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2087 - accuracy: 0.9397 - val_loss: 0.2240 - val_accuracy: 0.9368\n",
      "Epoch 288/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2086 - accuracy: 0.9397 - val_loss: 0.2239 - val_accuracy: 0.9368\n",
      "Epoch 289/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2085 - accuracy: 0.9397 - val_loss: 0.2238 - val_accuracy: 0.9368\n",
      "Epoch 290/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2083 - accuracy: 0.9397 - val_loss: 0.2237 - val_accuracy: 0.9368\n",
      "Epoch 291/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2081 - accuracy: 0.9397 - val_loss: 0.2236 - val_accuracy: 0.9368\n",
      "Epoch 292/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2080 - accuracy: 0.9397 - val_loss: 0.2235 - val_accuracy: 0.9368\n",
      "Epoch 293/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2079 - accuracy: 0.9397 - val_loss: 0.2234 - val_accuracy: 0.9368\n",
      "Epoch 294/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2077 - accuracy: 0.9397 - val_loss: 0.2233 - val_accuracy: 0.9368\n",
      "Epoch 295/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2076 - accuracy: 0.9397 - val_loss: 0.2232 - val_accuracy: 0.9368\n",
      "Epoch 296/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2075 - accuracy: 0.9397 - val_loss: 0.2231 - val_accuracy: 0.9368\n",
      "Epoch 297/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2073 - accuracy: 0.9397 - val_loss: 0.2229 - val_accuracy: 0.9368\n",
      "Epoch 298/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2071 - accuracy: 0.9397 - val_loss: 0.2228 - val_accuracy: 0.9368\n",
      "Epoch 299/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2070 - accuracy: 0.9397 - val_loss: 0.2227 - val_accuracy: 0.9368\n",
      "Epoch 300/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2069 - accuracy: 0.9397 - val_loss: 0.2226 - val_accuracy: 0.9368\n",
      "Epoch 301/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2067 - accuracy: 0.9397 - val_loss: 0.2225 - val_accuracy: 0.9368\n",
      "Epoch 302/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2065 - accuracy: 0.9397 - val_loss: 0.2224 - val_accuracy: 0.9368\n",
      "Epoch 303/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2064 - accuracy: 0.9397 - val_loss: 0.2223 - val_accuracy: 0.9368\n",
      "Epoch 304/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2062 - accuracy: 0.9397 - val_loss: 0.2222 - val_accuracy: 0.9368\n",
      "Epoch 305/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2061 - accuracy: 0.9397 - val_loss: 0.2221 - val_accuracy: 0.9368\n",
      "Epoch 306/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2059 - accuracy: 0.9397 - val_loss: 0.2219 - val_accuracy: 0.9368\n",
      "Epoch 307/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2058 - accuracy: 0.9397 - val_loss: 0.2219 - val_accuracy: 0.9368\n",
      "Epoch 308/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2056 - accuracy: 0.9397 - val_loss: 0.2217 - val_accuracy: 0.9368\n",
      "Epoch 309/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2054 - accuracy: 0.9397 - val_loss: 0.2216 - val_accuracy: 0.9368\n",
      "Epoch 310/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2053 - accuracy: 0.9397 - val_loss: 0.2215 - val_accuracy: 0.9368\n",
      "Epoch 311/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.2052 - accuracy: 0.9397 - val_loss: 0.2213 - val_accuracy: 0.9368\n",
      "Epoch 312/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2050 - accuracy: 0.9397 - val_loss: 0.2212 - val_accuracy: 0.9368\n",
      "Epoch 313/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2048 - accuracy: 0.9397 - val_loss: 0.2212 - val_accuracy: 0.9368\n",
      "Epoch 314/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2047 - accuracy: 0.9397 - val_loss: 0.2210 - val_accuracy: 0.9368\n",
      "Epoch 315/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2045 - accuracy: 0.9397 - val_loss: 0.2209 - val_accuracy: 0.9368\n",
      "Epoch 316/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2043 - accuracy: 0.9397 - val_loss: 0.2208 - val_accuracy: 0.9368\n",
      "Epoch 317/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2042 - accuracy: 0.9397 - val_loss: 0.2207 - val_accuracy: 0.9368\n",
      "Epoch 318/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2041 - accuracy: 0.9397 - val_loss: 0.2207 - val_accuracy: 0.9368\n",
      "Epoch 319/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2039 - accuracy: 0.9397 - val_loss: 0.2205 - val_accuracy: 0.9368\n",
      "Epoch 320/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2037 - accuracy: 0.9397 - val_loss: 0.2204 - val_accuracy: 0.9368\n",
      "Epoch 321/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2035 - accuracy: 0.9397 - val_loss: 0.2202 - val_accuracy: 0.9368\n",
      "Epoch 322/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2034 - accuracy: 0.9397 - val_loss: 0.2201 - val_accuracy: 0.9368\n",
      "Epoch 323/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2033 - accuracy: 0.9397 - val_loss: 0.2200 - val_accuracy: 0.9368\n",
      "Epoch 324/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2031 - accuracy: 0.9397 - val_loss: 0.2199 - val_accuracy: 0.9368\n",
      "Epoch 325/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2029 - accuracy: 0.9398 - val_loss: 0.2198 - val_accuracy: 0.9368\n",
      "Epoch 326/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2028 - accuracy: 0.9398 - val_loss: 0.2196 - val_accuracy: 0.9368\n",
      "Epoch 327/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2026 - accuracy: 0.9398 - val_loss: 0.2194 - val_accuracy: 0.9368\n",
      "Epoch 328/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2024 - accuracy: 0.9398 - val_loss: 0.2194 - val_accuracy: 0.9368\n",
      "Epoch 329/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2023 - accuracy: 0.9398 - val_loss: 0.2194 - val_accuracy: 0.9368\n",
      "Epoch 330/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2021 - accuracy: 0.9398 - val_loss: 0.2192 - val_accuracy: 0.9368\n",
      "Epoch 331/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2019 - accuracy: 0.9398 - val_loss: 0.2190 - val_accuracy: 0.9368\n",
      "Epoch 332/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2017 - accuracy: 0.9397 - val_loss: 0.2189 - val_accuracy: 0.9368\n",
      "Epoch 333/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2017 - accuracy: 0.9398 - val_loss: 0.2188 - val_accuracy: 0.9368\n",
      "Epoch 334/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2014 - accuracy: 0.9397 - val_loss: 0.2186 - val_accuracy: 0.9368\n",
      "Epoch 335/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2013 - accuracy: 0.9397 - val_loss: 0.2186 - val_accuracy: 0.9368\n",
      "Epoch 336/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 81us/step - loss: 0.2011 - accuracy: 0.9397 - val_loss: 0.2184 - val_accuracy: 0.9368\n",
      "Epoch 337/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2009 - accuracy: 0.9397 - val_loss: 0.2184 - val_accuracy: 0.9368\n",
      "Epoch 338/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2008 - accuracy: 0.9397 - val_loss: 0.2183 - val_accuracy: 0.9368\n",
      "Epoch 339/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2006 - accuracy: 0.9397 - val_loss: 0.2182 - val_accuracy: 0.9368\n",
      "Epoch 340/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2005 - accuracy: 0.9397 - val_loss: 0.2179 - val_accuracy: 0.9368\n",
      "Epoch 341/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2003 - accuracy: 0.9397 - val_loss: 0.2178 - val_accuracy: 0.9368\n",
      "Epoch 342/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2001 - accuracy: 0.9398 - val_loss: 0.2177 - val_accuracy: 0.9368\n",
      "Epoch 343/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1999 - accuracy: 0.9397 - val_loss: 0.2176 - val_accuracy: 0.9368\n",
      "Epoch 344/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1997 - accuracy: 0.9398 - val_loss: 0.2174 - val_accuracy: 0.9368\n",
      "Epoch 345/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1996 - accuracy: 0.9397 - val_loss: 0.2173 - val_accuracy: 0.9368\n",
      "Epoch 346/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1994 - accuracy: 0.9398 - val_loss: 0.2172 - val_accuracy: 0.9368\n",
      "Epoch 347/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1993 - accuracy: 0.9398 - val_loss: 0.2171 - val_accuracy: 0.9368\n",
      "Epoch 348/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1991 - accuracy: 0.9398 - val_loss: 0.2170 - val_accuracy: 0.9368\n",
      "Epoch 349/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1989 - accuracy: 0.9399 - val_loss: 0.2168 - val_accuracy: 0.9369\n",
      "Epoch 350/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1988 - accuracy: 0.9399 - val_loss: 0.2167 - val_accuracy: 0.9369\n",
      "Epoch 351/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1986 - accuracy: 0.9399 - val_loss: 0.2166 - val_accuracy: 0.9369\n",
      "Epoch 352/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1984 - accuracy: 0.9399 - val_loss: 0.2163 - val_accuracy: 0.9369\n",
      "Epoch 353/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1982 - accuracy: 0.9399 - val_loss: 0.2161 - val_accuracy: 0.9369\n",
      "Epoch 354/800\n",
      "480/480 [==============================] - 0s 106us/step - loss: 0.1980 - accuracy: 0.9399 - val_loss: 0.2161 - val_accuracy: 0.9369\n",
      "Epoch 355/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1979 - accuracy: 0.9400 - val_loss: 0.2160 - val_accuracy: 0.9369\n",
      "Epoch 356/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.1977 - accuracy: 0.9399 - val_loss: 0.2159 - val_accuracy: 0.9369\n",
      "Epoch 357/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1975 - accuracy: 0.9399 - val_loss: 0.2158 - val_accuracy: 0.9369\n",
      "Epoch 358/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1974 - accuracy: 0.9399 - val_loss: 0.2157 - val_accuracy: 0.9369\n",
      "Epoch 359/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1972 - accuracy: 0.9398 - val_loss: 0.2156 - val_accuracy: 0.9369\n",
      "Epoch 360/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1970 - accuracy: 0.9399 - val_loss: 0.2155 - val_accuracy: 0.9369\n",
      "Epoch 361/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1968 - accuracy: 0.9399 - val_loss: 0.2154 - val_accuracy: 0.9369\n",
      "Epoch 362/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1966 - accuracy: 0.9399 - val_loss: 0.2152 - val_accuracy: 0.9369\n",
      "Epoch 363/800\n",
      "480/480 [==============================] - 0s 91us/step - loss: 0.1965 - accuracy: 0.9399 - val_loss: 0.2152 - val_accuracy: 0.9369\n",
      "Epoch 364/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1963 - accuracy: 0.9399 - val_loss: 0.2150 - val_accuracy: 0.9369\n",
      "Epoch 365/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1961 - accuracy: 0.9399 - val_loss: 0.2148 - val_accuracy: 0.9369\n",
      "Epoch 366/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1959 - accuracy: 0.9400 - val_loss: 0.2147 - val_accuracy: 0.9369\n",
      "Epoch 367/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1958 - accuracy: 0.9400 - val_loss: 0.2146 - val_accuracy: 0.9369\n",
      "Epoch 368/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1956 - accuracy: 0.9398 - val_loss: 0.2145 - val_accuracy: 0.9369\n",
      "Epoch 369/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1954 - accuracy: 0.9398 - val_loss: 0.2144 - val_accuracy: 0.9369\n",
      "Epoch 370/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1953 - accuracy: 0.9399 - val_loss: 0.2142 - val_accuracy: 0.9369\n",
      "Epoch 371/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1951 - accuracy: 0.9400 - val_loss: 0.2141 - val_accuracy: 0.9369\n",
      "Epoch 372/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1949 - accuracy: 0.9400 - val_loss: 0.2140 - val_accuracy: 0.9369\n",
      "Epoch 373/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1948 - accuracy: 0.9400 - val_loss: 0.2140 - val_accuracy: 0.9369\n",
      "Epoch 374/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1946 - accuracy: 0.9400 - val_loss: 0.2138 - val_accuracy: 0.9369\n",
      "Epoch 375/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1944 - accuracy: 0.9400 - val_loss: 0.2136 - val_accuracy: 0.9369\n",
      "Epoch 376/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1942 - accuracy: 0.9400 - val_loss: 0.2135 - val_accuracy: 0.9370\n",
      "Epoch 377/800\n",
      "480/480 [==============================] - 0s 93us/step - loss: 0.1940 - accuracy: 0.9400 - val_loss: 0.2133 - val_accuracy: 0.9370\n",
      "Epoch 378/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1939 - accuracy: 0.9401 - val_loss: 0.2132 - val_accuracy: 0.9369\n",
      "Epoch 379/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1937 - accuracy: 0.9400 - val_loss: 0.2130 - val_accuracy: 0.9369\n",
      "Epoch 380/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1935 - accuracy: 0.9400 - val_loss: 0.2129 - val_accuracy: 0.9370\n",
      "Epoch 381/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1934 - accuracy: 0.9400 - val_loss: 0.2129 - val_accuracy: 0.9369\n",
      "Epoch 382/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1932 - accuracy: 0.9400 - val_loss: 0.2128 - val_accuracy: 0.9370\n",
      "Epoch 383/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1930 - accuracy: 0.9399 - val_loss: 0.2126 - val_accuracy: 0.9370\n",
      "Epoch 384/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1928 - accuracy: 0.9400 - val_loss: 0.2127 - val_accuracy: 0.9370\n",
      "Epoch 385/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1926 - accuracy: 0.9400 - val_loss: 0.2125 - val_accuracy: 0.9370\n",
      "Epoch 386/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1925 - accuracy: 0.9400 - val_loss: 0.2122 - val_accuracy: 0.9369\n",
      "Epoch 387/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1923 - accuracy: 0.9401 - val_loss: 0.2121 - val_accuracy: 0.9369\n",
      "Epoch 388/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1921 - accuracy: 0.9401 - val_loss: 0.2121 - val_accuracy: 0.9370\n",
      "Epoch 389/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1920 - accuracy: 0.9400 - val_loss: 0.2119 - val_accuracy: 0.9370\n",
      "Epoch 390/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1919 - accuracy: 0.9399 - val_loss: 0.2118 - val_accuracy: 0.9369\n",
      "Epoch 391/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1917 - accuracy: 0.9400 - val_loss: 0.2116 - val_accuracy: 0.9369\n",
      "Epoch 392/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.1915 - accuracy: 0.9399 - val_loss: 0.2115 - val_accuracy: 0.9369\n",
      "Epoch 393/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.1913 - accuracy: 0.9401 - val_loss: 0.2113 - val_accuracy: 0.9369\n",
      "Epoch 394/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1912 - accuracy: 0.9400 - val_loss: 0.2113 - val_accuracy: 0.9369\n",
      "Epoch 395/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1910 - accuracy: 0.9400 - val_loss: 0.2112 - val_accuracy: 0.9369\n",
      "Epoch 396/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1909 - accuracy: 0.9400 - val_loss: 0.2111 - val_accuracy: 0.9369\n",
      "Epoch 397/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1907 - accuracy: 0.9401 - val_loss: 0.2110 - val_accuracy: 0.9369\n",
      "Epoch 398/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1905 - accuracy: 0.9402 - val_loss: 0.2109 - val_accuracy: 0.9369\n",
      "Epoch 399/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1904 - accuracy: 0.9401 - val_loss: 0.2108 - val_accuracy: 0.9369\n",
      "Epoch 400/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1902 - accuracy: 0.9401 - val_loss: 0.2106 - val_accuracy: 0.9369\n",
      "Epoch 401/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1900 - accuracy: 0.9402 - val_loss: 0.2104 - val_accuracy: 0.9369\n",
      "Epoch 402/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1899 - accuracy: 0.9401 - val_loss: 0.2104 - val_accuracy: 0.9369\n",
      "Epoch 403/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1897 - accuracy: 0.9401 - val_loss: 0.2102 - val_accuracy: 0.9369\n",
      "Epoch 404/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1896 - accuracy: 0.9401 - val_loss: 0.2102 - val_accuracy: 0.9369\n",
      "Epoch 405/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1894 - accuracy: 0.9400 - val_loss: 0.2101 - val_accuracy: 0.9369\n",
      "Epoch 406/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1892 - accuracy: 0.9401 - val_loss: 0.2098 - val_accuracy: 0.9369\n",
      "Epoch 407/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1891 - accuracy: 0.9402 - val_loss: 0.2099 - val_accuracy: 0.9370\n",
      "Epoch 408/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1889 - accuracy: 0.9401 - val_loss: 0.2098 - val_accuracy: 0.9370\n",
      "Epoch 409/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1887 - accuracy: 0.9402 - val_loss: 0.2097 - val_accuracy: 0.9370\n",
      "Epoch 410/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1886 - accuracy: 0.9400 - val_loss: 0.2096 - val_accuracy: 0.9370\n",
      "Epoch 411/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1885 - accuracy: 0.9401 - val_loss: 0.2096 - val_accuracy: 0.9370\n",
      "Epoch 412/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1883 - accuracy: 0.9400 - val_loss: 0.2093 - val_accuracy: 0.9370\n",
      "Epoch 413/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1881 - accuracy: 0.9401 - val_loss: 0.2093 - val_accuracy: 0.9370\n",
      "Epoch 414/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1880 - accuracy: 0.9401 - val_loss: 0.2091 - val_accuracy: 0.9370\n",
      "Epoch 415/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1878 - accuracy: 0.9401 - val_loss: 0.2089 - val_accuracy: 0.9370\n",
      "Epoch 416/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1876 - accuracy: 0.9401 - val_loss: 0.2087 - val_accuracy: 0.9370\n",
      "Epoch 417/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1874 - accuracy: 0.9401 - val_loss: 0.2086 - val_accuracy: 0.9370\n",
      "Epoch 418/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1873 - accuracy: 0.9401 - val_loss: 0.2086 - val_accuracy: 0.9370\n",
      "Epoch 419/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1871 - accuracy: 0.9403 - val_loss: 0.2085 - val_accuracy: 0.9370\n",
      "Epoch 420/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1870 - accuracy: 0.9403 - val_loss: 0.2083 - val_accuracy: 0.9370\n",
      "Epoch 421/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1868 - accuracy: 0.9402 - val_loss: 0.2083 - val_accuracy: 0.9370\n",
      "Epoch 422/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1867 - accuracy: 0.9403 - val_loss: 0.2084 - val_accuracy: 0.9371\n",
      "Epoch 423/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1865 - accuracy: 0.9402 - val_loss: 0.2082 - val_accuracy: 0.9371\n",
      "Epoch 424/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1863 - accuracy: 0.9402 - val_loss: 0.2081 - val_accuracy: 0.9371\n",
      "Epoch 425/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1862 - accuracy: 0.9403 - val_loss: 0.2078 - val_accuracy: 0.9370\n",
      "Epoch 426/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1860 - accuracy: 0.9402 - val_loss: 0.2079 - val_accuracy: 0.9371\n",
      "Epoch 427/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1859 - accuracy: 0.9404 - val_loss: 0.2078 - val_accuracy: 0.9371\n",
      "Epoch 428/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1857 - accuracy: 0.9402 - val_loss: 0.2075 - val_accuracy: 0.9371\n",
      "Epoch 429/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1857 - accuracy: 0.9404 - val_loss: 0.2074 - val_accuracy: 0.9371\n",
      "Epoch 430/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1854 - accuracy: 0.9402 - val_loss: 0.2075 - val_accuracy: 0.9371\n",
      "Epoch 431/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1853 - accuracy: 0.9403 - val_loss: 0.2073 - val_accuracy: 0.9371\n",
      "Epoch 432/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1851 - accuracy: 0.9402 - val_loss: 0.2072 - val_accuracy: 0.9371\n",
      "Epoch 433/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1849 - accuracy: 0.9404 - val_loss: 0.2072 - val_accuracy: 0.9371\n",
      "Epoch 434/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1848 - accuracy: 0.9402 - val_loss: 0.2070 - val_accuracy: 0.9371\n",
      "Epoch 435/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1847 - accuracy: 0.9403 - val_loss: 0.2070 - val_accuracy: 0.9371\n",
      "Epoch 436/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1846 - accuracy: 0.9402 - val_loss: 0.2068 - val_accuracy: 0.9371\n",
      "Epoch 437/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1843 - accuracy: 0.9403 - val_loss: 0.2069 - val_accuracy: 0.9373\n",
      "Epoch 438/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1841 - accuracy: 0.9404 - val_loss: 0.2065 - val_accuracy: 0.9371\n",
      "Epoch 439/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1841 - accuracy: 0.9404 - val_loss: 0.2066 - val_accuracy: 0.9371\n",
      "Epoch 440/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1839 - accuracy: 0.9405 - val_loss: 0.2063 - val_accuracy: 0.9373\n",
      "Epoch 441/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1837 - accuracy: 0.9404 - val_loss: 0.2062 - val_accuracy: 0.9373\n",
      "Epoch 442/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1835 - accuracy: 0.9406 - val_loss: 0.2061 - val_accuracy: 0.9371\n",
      "Epoch 443/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1834 - accuracy: 0.9405 - val_loss: 0.2062 - val_accuracy: 0.9371\n",
      "Epoch 444/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1833 - accuracy: 0.9406 - val_loss: 0.2060 - val_accuracy: 0.9371\n",
      "Epoch 445/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1831 - accuracy: 0.9404 - val_loss: 0.2060 - val_accuracy: 0.9374\n",
      "Epoch 446/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1829 - accuracy: 0.9406 - val_loss: 0.2058 - val_accuracy: 0.9373\n",
      "Epoch 447/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1828 - accuracy: 0.9406 - val_loss: 0.2055 - val_accuracy: 0.9373\n",
      "Epoch 448/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 83us/step - loss: 0.1827 - accuracy: 0.9407 - val_loss: 0.2055 - val_accuracy: 0.9373\n",
      "Epoch 449/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1825 - accuracy: 0.9407 - val_loss: 0.2053 - val_accuracy: 0.9373\n",
      "Epoch 450/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1823 - accuracy: 0.9404 - val_loss: 0.2053 - val_accuracy: 0.9374\n",
      "Epoch 451/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1822 - accuracy: 0.9406 - val_loss: 0.2051 - val_accuracy: 0.9374\n",
      "Epoch 452/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1820 - accuracy: 0.9408 - val_loss: 0.2050 - val_accuracy: 0.9374\n",
      "Epoch 453/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1818 - accuracy: 0.9408 - val_loss: 0.2051 - val_accuracy: 0.9374\n",
      "Epoch 454/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1817 - accuracy: 0.9407 - val_loss: 0.2049 - val_accuracy: 0.9374\n",
      "Epoch 455/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1815 - accuracy: 0.9408 - val_loss: 0.2049 - val_accuracy: 0.9374\n",
      "Epoch 456/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1814 - accuracy: 0.9407 - val_loss: 0.2049 - val_accuracy: 0.9373\n",
      "Epoch 457/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1812 - accuracy: 0.9408 - val_loss: 0.2045 - val_accuracy: 0.9373\n",
      "Epoch 458/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1811 - accuracy: 0.9408 - val_loss: 0.2045 - val_accuracy: 0.9373\n",
      "Epoch 459/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1809 - accuracy: 0.9409 - val_loss: 0.2043 - val_accuracy: 0.9374\n",
      "Epoch 460/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1807 - accuracy: 0.9408 - val_loss: 0.2043 - val_accuracy: 0.9374\n",
      "Epoch 461/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1806 - accuracy: 0.9408 - val_loss: 0.2042 - val_accuracy: 0.9374\n",
      "Epoch 462/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1805 - accuracy: 0.9408 - val_loss: 0.2042 - val_accuracy: 0.9374\n",
      "Epoch 463/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1804 - accuracy: 0.9409 - val_loss: 0.2041 - val_accuracy: 0.9373\n",
      "Epoch 464/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1802 - accuracy: 0.9409 - val_loss: 0.2039 - val_accuracy: 0.9373\n",
      "Epoch 465/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1800 - accuracy: 0.9408 - val_loss: 0.2038 - val_accuracy: 0.9373\n",
      "Epoch 466/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1799 - accuracy: 0.9410 - val_loss: 0.2036 - val_accuracy: 0.9373\n",
      "Epoch 467/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1797 - accuracy: 0.9408 - val_loss: 0.2036 - val_accuracy: 0.9373\n",
      "Epoch 468/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1796 - accuracy: 0.9409 - val_loss: 0.2033 - val_accuracy: 0.9373\n",
      "Epoch 469/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1794 - accuracy: 0.9409 - val_loss: 0.2034 - val_accuracy: 0.9373\n",
      "Epoch 470/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1792 - accuracy: 0.9410 - val_loss: 0.2033 - val_accuracy: 0.9374\n",
      "Epoch 471/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1791 - accuracy: 0.9410 - val_loss: 0.2030 - val_accuracy: 0.9373\n",
      "Epoch 472/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1789 - accuracy: 0.9411 - val_loss: 0.2029 - val_accuracy: 0.9373\n",
      "Epoch 473/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1788 - accuracy: 0.9411 - val_loss: 0.2030 - val_accuracy: 0.9373\n",
      "Epoch 474/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.1787 - accuracy: 0.9411 - val_loss: 0.2028 - val_accuracy: 0.9373\n",
      "Epoch 475/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1785 - accuracy: 0.9410 - val_loss: 0.2027 - val_accuracy: 0.9373\n",
      "Epoch 476/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1783 - accuracy: 0.9411 - val_loss: 0.2026 - val_accuracy: 0.9373\n",
      "Epoch 477/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1782 - accuracy: 0.9412 - val_loss: 0.2025 - val_accuracy: 0.9374\n",
      "Epoch 478/800\n",
      "480/480 [==============================] - 0s 119us/step - loss: 0.1780 - accuracy: 0.9411 - val_loss: 0.2024 - val_accuracy: 0.9373\n",
      "Epoch 479/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.1779 - accuracy: 0.9410 - val_loss: 0.2022 - val_accuracy: 0.9373\n",
      "Epoch 480/800\n",
      "480/480 [==============================] - 0s 98us/step - loss: 0.1777 - accuracy: 0.9411 - val_loss: 0.2023 - val_accuracy: 0.9373\n",
      "Epoch 481/800\n",
      "480/480 [==============================] - 0s 100us/step - loss: 0.1776 - accuracy: 0.9413 - val_loss: 0.2022 - val_accuracy: 0.9374\n",
      "Epoch 482/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1774 - accuracy: 0.9412 - val_loss: 0.2021 - val_accuracy: 0.9373\n",
      "Epoch 483/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.1772 - accuracy: 0.9412 - val_loss: 0.2020 - val_accuracy: 0.9374\n",
      "Epoch 484/800\n",
      "480/480 [==============================] - ETA: 0s - loss: 0.1713 - accuracy: 0.94 - 0s 90us/step - loss: 0.1771 - accuracy: 0.9409 - val_loss: 0.2019 - val_accuracy: 0.9375\n",
      "Epoch 485/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1769 - accuracy: 0.9413 - val_loss: 0.2016 - val_accuracy: 0.9374\n",
      "Epoch 486/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1767 - accuracy: 0.9413 - val_loss: 0.2017 - val_accuracy: 0.9374\n",
      "Epoch 487/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1767 - accuracy: 0.9411 - val_loss: 0.2018 - val_accuracy: 0.9375\n",
      "Epoch 488/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1765 - accuracy: 0.9415 - val_loss: 0.2016 - val_accuracy: 0.9375\n",
      "Epoch 489/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1764 - accuracy: 0.9412 - val_loss: 0.2013 - val_accuracy: 0.9377\n",
      "Epoch 490/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1761 - accuracy: 0.9412 - val_loss: 0.2013 - val_accuracy: 0.9375\n",
      "Epoch 491/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1760 - accuracy: 0.9416 - val_loss: 0.2012 - val_accuracy: 0.9376\n",
      "Epoch 492/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1759 - accuracy: 0.9411 - val_loss: 0.2010 - val_accuracy: 0.9377\n",
      "Epoch 493/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1757 - accuracy: 0.9415 - val_loss: 0.2007 - val_accuracy: 0.9376\n",
      "Epoch 494/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1756 - accuracy: 0.9415 - val_loss: 0.2009 - val_accuracy: 0.9376\n",
      "Epoch 495/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1754 - accuracy: 0.9414 - val_loss: 0.2007 - val_accuracy: 0.9377\n",
      "Epoch 496/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1752 - accuracy: 0.9412 - val_loss: 0.2006 - val_accuracy: 0.9376\n",
      "Epoch 497/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1752 - accuracy: 0.9413 - val_loss: 0.2006 - val_accuracy: 0.9376\n",
      "Epoch 498/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1749 - accuracy: 0.9413 - val_loss: 0.2003 - val_accuracy: 0.9377\n",
      "Epoch 499/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1748 - accuracy: 0.9412 - val_loss: 0.2002 - val_accuracy: 0.9375\n",
      "Epoch 500/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1746 - accuracy: 0.9414 - val_loss: 0.2002 - val_accuracy: 0.9376\n",
      "Epoch 501/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1745 - accuracy: 0.9415 - val_loss: 0.2002 - val_accuracy: 0.9377\n",
      "Epoch 502/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1743 - accuracy: 0.9414 - val_loss: 0.2002 - val_accuracy: 0.9376\n",
      "Epoch 503/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1742 - accuracy: 0.9415 - val_loss: 0.2000 - val_accuracy: 0.9377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1740 - accuracy: 0.9416 - val_loss: 0.1999 - val_accuracy: 0.9377\n",
      "Epoch 505/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1739 - accuracy: 0.9414 - val_loss: 0.1997 - val_accuracy: 0.9377\n",
      "Epoch 506/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1738 - accuracy: 0.9414 - val_loss: 0.1997 - val_accuracy: 0.9379\n",
      "Epoch 507/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1736 - accuracy: 0.9414 - val_loss: 0.1995 - val_accuracy: 0.9377\n",
      "Epoch 508/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1734 - accuracy: 0.9417 - val_loss: 0.1994 - val_accuracy: 0.9379\n",
      "Epoch 509/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1732 - accuracy: 0.9415 - val_loss: 0.1994 - val_accuracy: 0.9380\n",
      "Epoch 510/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1732 - accuracy: 0.9416 - val_loss: 0.1995 - val_accuracy: 0.9379\n",
      "Epoch 511/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1729 - accuracy: 0.9415 - val_loss: 0.1993 - val_accuracy: 0.9379\n",
      "Epoch 512/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1728 - accuracy: 0.9415 - val_loss: 0.1992 - val_accuracy: 0.9377\n",
      "Epoch 513/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1727 - accuracy: 0.9417 - val_loss: 0.1992 - val_accuracy: 0.9380\n",
      "Epoch 514/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1725 - accuracy: 0.9415 - val_loss: 0.1990 - val_accuracy: 0.9379\n",
      "Epoch 515/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1724 - accuracy: 0.9416 - val_loss: 0.1990 - val_accuracy: 0.9380\n",
      "Epoch 516/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1723 - accuracy: 0.9417 - val_loss: 0.1989 - val_accuracy: 0.9381\n",
      "Epoch 517/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1721 - accuracy: 0.9418 - val_loss: 0.1987 - val_accuracy: 0.9381\n",
      "Epoch 518/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1720 - accuracy: 0.9417 - val_loss: 0.1985 - val_accuracy: 0.9382\n",
      "Epoch 519/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1717 - accuracy: 0.9415 - val_loss: 0.1983 - val_accuracy: 0.9379\n",
      "Epoch 520/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1717 - accuracy: 0.9417 - val_loss: 0.1984 - val_accuracy: 0.9382\n",
      "Epoch 521/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1715 - accuracy: 0.9416 - val_loss: 0.1982 - val_accuracy: 0.9382\n",
      "Epoch 522/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1713 - accuracy: 0.9418 - val_loss: 0.1982 - val_accuracy: 0.9385\n",
      "Epoch 523/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1713 - accuracy: 0.9420 - val_loss: 0.1980 - val_accuracy: 0.9381\n",
      "Epoch 524/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1711 - accuracy: 0.9420 - val_loss: 0.1982 - val_accuracy: 0.9381\n",
      "Epoch 525/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1710 - accuracy: 0.9419 - val_loss: 0.1979 - val_accuracy: 0.9381\n",
      "Epoch 526/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1708 - accuracy: 0.9419 - val_loss: 0.1979 - val_accuracy: 0.9379\n",
      "Epoch 527/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1706 - accuracy: 0.9418 - val_loss: 0.1978 - val_accuracy: 0.9380\n",
      "Epoch 528/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1705 - accuracy: 0.9420 - val_loss: 0.1977 - val_accuracy: 0.9385\n",
      "Epoch 529/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1704 - accuracy: 0.9419 - val_loss: 0.1977 - val_accuracy: 0.9382\n",
      "Epoch 530/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1702 - accuracy: 0.9420 - val_loss: 0.1977 - val_accuracy: 0.9381\n",
      "Epoch 531/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1701 - accuracy: 0.9420 - val_loss: 0.1974 - val_accuracy: 0.9384\n",
      "Epoch 532/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1700 - accuracy: 0.9421 - val_loss: 0.1974 - val_accuracy: 0.9384\n",
      "Epoch 533/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1698 - accuracy: 0.9420 - val_loss: 0.1974 - val_accuracy: 0.9384\n",
      "Epoch 534/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1697 - accuracy: 0.9422 - val_loss: 0.1974 - val_accuracy: 0.9384\n",
      "Epoch 535/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1696 - accuracy: 0.9421 - val_loss: 0.1973 - val_accuracy: 0.9385\n",
      "Epoch 536/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1694 - accuracy: 0.9421 - val_loss: 0.1971 - val_accuracy: 0.9386\n",
      "Epoch 537/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1693 - accuracy: 0.9422 - val_loss: 0.1972 - val_accuracy: 0.9385\n",
      "Epoch 538/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1692 - accuracy: 0.9423 - val_loss: 0.1969 - val_accuracy: 0.9385\n",
      "Epoch 539/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1690 - accuracy: 0.9422 - val_loss: 0.1970 - val_accuracy: 0.9384\n",
      "Epoch 540/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1689 - accuracy: 0.9425 - val_loss: 0.1968 - val_accuracy: 0.9385\n",
      "Epoch 541/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1687 - accuracy: 0.9424 - val_loss: 0.1967 - val_accuracy: 0.9384\n",
      "Epoch 542/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1686 - accuracy: 0.9426 - val_loss: 0.1967 - val_accuracy: 0.9385\n",
      "Epoch 543/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1686 - accuracy: 0.9424 - val_loss: 0.1967 - val_accuracy: 0.9386\n",
      "Epoch 544/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1684 - accuracy: 0.9424 - val_loss: 0.1964 - val_accuracy: 0.9388\n",
      "Epoch 545/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1683 - accuracy: 0.9424 - val_loss: 0.1964 - val_accuracy: 0.9384\n",
      "Epoch 546/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1681 - accuracy: 0.9425 - val_loss: 0.1961 - val_accuracy: 0.9387\n",
      "Epoch 547/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1680 - accuracy: 0.9426 - val_loss: 0.1962 - val_accuracy: 0.9386\n",
      "Epoch 548/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1678 - accuracy: 0.9429 - val_loss: 0.1963 - val_accuracy: 0.9386\n",
      "Epoch 549/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1678 - accuracy: 0.9422 - val_loss: 0.1962 - val_accuracy: 0.9386\n",
      "Epoch 550/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1677 - accuracy: 0.9426 - val_loss: 0.1962 - val_accuracy: 0.9386\n",
      "Epoch 551/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1674 - accuracy: 0.9429 - val_loss: 0.1962 - val_accuracy: 0.9387\n",
      "Epoch 552/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1673 - accuracy: 0.9429 - val_loss: 0.1962 - val_accuracy: 0.9386\n",
      "Epoch 553/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1672 - accuracy: 0.9429 - val_loss: 0.1962 - val_accuracy: 0.9385\n",
      "Epoch 554/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1670 - accuracy: 0.9424 - val_loss: 0.1958 - val_accuracy: 0.9388\n",
      "Epoch 555/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1669 - accuracy: 0.9428 - val_loss: 0.1959 - val_accuracy: 0.9388\n",
      "Epoch 556/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1670 - accuracy: 0.9427 - val_loss: 0.1957 - val_accuracy: 0.9387\n",
      "Epoch 557/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1667 - accuracy: 0.9427 - val_loss: 0.1956 - val_accuracy: 0.9390\n",
      "Epoch 558/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1666 - accuracy: 0.9429 - val_loss: 0.1956 - val_accuracy: 0.9387\n",
      "Epoch 559/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1664 - accuracy: 0.9429 - val_loss: 0.1957 - val_accuracy: 0.9390\n",
      "Epoch 560/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.1664 - accuracy: 0.9430 - val_loss: 0.1954 - val_accuracy: 0.9388\n",
      "Epoch 561/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1662 - accuracy: 0.9430 - val_loss: 0.1954 - val_accuracy: 0.9391\n",
      "Epoch 562/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1661 - accuracy: 0.9431 - val_loss: 0.1952 - val_accuracy: 0.9388\n",
      "Epoch 563/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1660 - accuracy: 0.9430 - val_loss: 0.1953 - val_accuracy: 0.9390\n",
      "Epoch 564/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1659 - accuracy: 0.9430 - val_loss: 0.1952 - val_accuracy: 0.9386\n",
      "Epoch 565/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1658 - accuracy: 0.9429 - val_loss: 0.1953 - val_accuracy: 0.9391\n",
      "Epoch 566/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1657 - accuracy: 0.9430 - val_loss: 0.1953 - val_accuracy: 0.9390\n",
      "Epoch 567/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1655 - accuracy: 0.9429 - val_loss: 0.1953 - val_accuracy: 0.9390\n",
      "Epoch 568/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1654 - accuracy: 0.9432 - val_loss: 0.1952 - val_accuracy: 0.9390\n",
      "Epoch 569/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1653 - accuracy: 0.9430 - val_loss: 0.1952 - val_accuracy: 0.9388\n",
      "Epoch 570/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1652 - accuracy: 0.9432 - val_loss: 0.1949 - val_accuracy: 0.9392\n",
      "Epoch 571/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1650 - accuracy: 0.9432 - val_loss: 0.1948 - val_accuracy: 0.9388\n",
      "Epoch 572/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1649 - accuracy: 0.9430 - val_loss: 0.1950 - val_accuracy: 0.9393\n",
      "Epoch 573/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1649 - accuracy: 0.9431 - val_loss: 0.1947 - val_accuracy: 0.9387\n",
      "Epoch 574/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1647 - accuracy: 0.9430 - val_loss: 0.1948 - val_accuracy: 0.9396\n",
      "Epoch 575/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1646 - accuracy: 0.9433 - val_loss: 0.1946 - val_accuracy: 0.9391\n",
      "Epoch 576/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1645 - accuracy: 0.9433 - val_loss: 0.1946 - val_accuracy: 0.9390\n",
      "Epoch 577/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1644 - accuracy: 0.9431 - val_loss: 0.1944 - val_accuracy: 0.9390\n",
      "Epoch 578/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1643 - accuracy: 0.9433 - val_loss: 0.1946 - val_accuracy: 0.9388\n",
      "Epoch 579/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1642 - accuracy: 0.9434 - val_loss: 0.1946 - val_accuracy: 0.9395\n",
      "Epoch 580/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1641 - accuracy: 0.9433 - val_loss: 0.1945 - val_accuracy: 0.9395\n",
      "Epoch 581/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1639 - accuracy: 0.9432 - val_loss: 0.1948 - val_accuracy: 0.9388\n",
      "Epoch 582/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1639 - accuracy: 0.9432 - val_loss: 0.1945 - val_accuracy: 0.9392\n",
      "Epoch 583/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1636 - accuracy: 0.9431 - val_loss: 0.1942 - val_accuracy: 0.9393\n",
      "Epoch 584/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1636 - accuracy: 0.9430 - val_loss: 0.1943 - val_accuracy: 0.9393\n",
      "Epoch 585/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1635 - accuracy: 0.9435 - val_loss: 0.1941 - val_accuracy: 0.9396\n",
      "Epoch 586/800\n",
      "480/480 [==============================] - 0s 108us/step - loss: 0.1635 - accuracy: 0.9433 - val_loss: 0.1944 - val_accuracy: 0.9392\n",
      "Epoch 587/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1633 - accuracy: 0.9434 - val_loss: 0.1940 - val_accuracy: 0.9395\n",
      "Epoch 588/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1631 - accuracy: 0.9432 - val_loss: 0.1938 - val_accuracy: 0.9395\n",
      "Epoch 589/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1631 - accuracy: 0.9432 - val_loss: 0.1939 - val_accuracy: 0.9393\n",
      "Epoch 590/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1629 - accuracy: 0.9433 - val_loss: 0.1939 - val_accuracy: 0.9392\n",
      "Epoch 591/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1628 - accuracy: 0.9433 - val_loss: 0.1939 - val_accuracy: 0.9395\n",
      "Epoch 592/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1627 - accuracy: 0.9433 - val_loss: 0.1941 - val_accuracy: 0.9392\n",
      "Epoch 593/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1627 - accuracy: 0.9433 - val_loss: 0.1938 - val_accuracy: 0.9397\n",
      "Epoch 594/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1625 - accuracy: 0.9432 - val_loss: 0.1936 - val_accuracy: 0.9396\n",
      "Epoch 595/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1624 - accuracy: 0.9436 - val_loss: 0.1937 - val_accuracy: 0.9395\n",
      "Epoch 596/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1624 - accuracy: 0.9437 - val_loss: 0.1936 - val_accuracy: 0.9396\n",
      "Epoch 597/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1622 - accuracy: 0.9435 - val_loss: 0.1935 - val_accuracy: 0.9395\n",
      "Epoch 598/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1621 - accuracy: 0.9435 - val_loss: 0.1935 - val_accuracy: 0.9396\n",
      "Epoch 599/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1620 - accuracy: 0.9431 - val_loss: 0.1937 - val_accuracy: 0.9391\n",
      "Epoch 600/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1619 - accuracy: 0.9433 - val_loss: 0.1936 - val_accuracy: 0.9393\n",
      "Epoch 601/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1617 - accuracy: 0.9439 - val_loss: 0.1933 - val_accuracy: 0.9397\n",
      "Epoch 602/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1617 - accuracy: 0.9436 - val_loss: 0.1936 - val_accuracy: 0.9396\n",
      "Epoch 603/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1616 - accuracy: 0.9437 - val_loss: 0.1936 - val_accuracy: 0.9396\n",
      "Epoch 604/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1614 - accuracy: 0.9435 - val_loss: 0.1937 - val_accuracy: 0.9392\n",
      "Epoch 605/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1614 - accuracy: 0.9438 - val_loss: 0.1933 - val_accuracy: 0.9395\n",
      "Epoch 606/800\n",
      "480/480 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.94 - 0s 88us/step - loss: 0.1613 - accuracy: 0.9437 - val_loss: 0.1931 - val_accuracy: 0.9396\n",
      "Epoch 607/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1611 - accuracy: 0.9435 - val_loss: 0.1930 - val_accuracy: 0.9395\n",
      "Epoch 608/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1611 - accuracy: 0.9436 - val_loss: 0.1933 - val_accuracy: 0.9396\n",
      "Epoch 609/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1609 - accuracy: 0.9436 - val_loss: 0.1931 - val_accuracy: 0.9400\n",
      "Epoch 610/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1609 - accuracy: 0.9436 - val_loss: 0.1932 - val_accuracy: 0.9395\n",
      "Epoch 611/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1607 - accuracy: 0.9436 - val_loss: 0.1932 - val_accuracy: 0.9395\n",
      "Epoch 612/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1607 - accuracy: 0.9436 - val_loss: 0.1933 - val_accuracy: 0.9392\n",
      "Epoch 613/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1606 - accuracy: 0.9437 - val_loss: 0.1931 - val_accuracy: 0.9392\n",
      "Epoch 614/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1606 - accuracy: 0.9436 - val_loss: 0.1928 - val_accuracy: 0.9396\n",
      "Epoch 615/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1604 - accuracy: 0.9437 - val_loss: 0.1931 - val_accuracy: 0.9393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1603 - accuracy: 0.9438 - val_loss: 0.1930 - val_accuracy: 0.9393\n",
      "Epoch 617/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1601 - accuracy: 0.9437 - val_loss: 0.1930 - val_accuracy: 0.9395\n",
      "Epoch 618/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1601 - accuracy: 0.9441 - val_loss: 0.1930 - val_accuracy: 0.9392\n",
      "Epoch 619/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1599 - accuracy: 0.9439 - val_loss: 0.1929 - val_accuracy: 0.9396\n",
      "Epoch 620/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1598 - accuracy: 0.9438 - val_loss: 0.1927 - val_accuracy: 0.9390\n",
      "Epoch 621/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1598 - accuracy: 0.9440 - val_loss: 0.1927 - val_accuracy: 0.9396\n",
      "Epoch 622/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1596 - accuracy: 0.9439 - val_loss: 0.1924 - val_accuracy: 0.9391\n",
      "Epoch 623/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1595 - accuracy: 0.9438 - val_loss: 0.1925 - val_accuracy: 0.9393\n",
      "Epoch 624/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1596 - accuracy: 0.9438 - val_loss: 0.1924 - val_accuracy: 0.9391\n",
      "Epoch 625/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1593 - accuracy: 0.9439 - val_loss: 0.1924 - val_accuracy: 0.9391\n",
      "Epoch 626/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1593 - accuracy: 0.9441 - val_loss: 0.1924 - val_accuracy: 0.9393\n",
      "Epoch 627/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1592 - accuracy: 0.9439 - val_loss: 0.1925 - val_accuracy: 0.9392\n",
      "Epoch 628/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1590 - accuracy: 0.9442 - val_loss: 0.1924 - val_accuracy: 0.9390\n",
      "Epoch 629/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1589 - accuracy: 0.9442 - val_loss: 0.1921 - val_accuracy: 0.9393\n",
      "Epoch 630/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1588 - accuracy: 0.9440 - val_loss: 0.1920 - val_accuracy: 0.9393\n",
      "Epoch 631/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1587 - accuracy: 0.9440 - val_loss: 0.1922 - val_accuracy: 0.9392\n",
      "Epoch 632/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1586 - accuracy: 0.9444 - val_loss: 0.1923 - val_accuracy: 0.9390\n",
      "Epoch 633/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1586 - accuracy: 0.9440 - val_loss: 0.1921 - val_accuracy: 0.9391\n",
      "Epoch 634/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1584 - accuracy: 0.9442 - val_loss: 0.1922 - val_accuracy: 0.9392\n",
      "Epoch 635/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1583 - accuracy: 0.9442 - val_loss: 0.1921 - val_accuracy: 0.9392\n",
      "Epoch 636/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1582 - accuracy: 0.9443 - val_loss: 0.1918 - val_accuracy: 0.9392\n",
      "Epoch 637/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1582 - accuracy: 0.9440 - val_loss: 0.1918 - val_accuracy: 0.9393\n",
      "Epoch 638/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1580 - accuracy: 0.9442 - val_loss: 0.1919 - val_accuracy: 0.9393\n",
      "Epoch 639/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1579 - accuracy: 0.9444 - val_loss: 0.1920 - val_accuracy: 0.9390\n",
      "Epoch 640/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1578 - accuracy: 0.9444 - val_loss: 0.1920 - val_accuracy: 0.9392\n",
      "Epoch 641/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1577 - accuracy: 0.9442 - val_loss: 0.1920 - val_accuracy: 0.9393\n",
      "Epoch 642/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1577 - accuracy: 0.9443 - val_loss: 0.1918 - val_accuracy: 0.9393\n",
      "Epoch 643/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1576 - accuracy: 0.9444 - val_loss: 0.1917 - val_accuracy: 0.9395\n",
      "Epoch 644/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1573 - accuracy: 0.9446 - val_loss: 0.1919 - val_accuracy: 0.9393\n",
      "Epoch 645/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1574 - accuracy: 0.9447 - val_loss: 0.1916 - val_accuracy: 0.9392\n",
      "Epoch 646/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1572 - accuracy: 0.9448 - val_loss: 0.1917 - val_accuracy: 0.9395\n",
      "Epoch 647/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1571 - accuracy: 0.9446 - val_loss: 0.1914 - val_accuracy: 0.9393\n",
      "Epoch 648/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1570 - accuracy: 0.9447 - val_loss: 0.1912 - val_accuracy: 0.9396\n",
      "Epoch 649/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1569 - accuracy: 0.9450 - val_loss: 0.1913 - val_accuracy: 0.9398\n",
      "Epoch 650/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1567 - accuracy: 0.9445 - val_loss: 0.1914 - val_accuracy: 0.9396\n",
      "Epoch 651/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1567 - accuracy: 0.9445 - val_loss: 0.1914 - val_accuracy: 0.9396\n",
      "Epoch 652/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1566 - accuracy: 0.9448 - val_loss: 0.1916 - val_accuracy: 0.9393\n",
      "Epoch 653/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1564 - accuracy: 0.9451 - val_loss: 0.1913 - val_accuracy: 0.9393\n",
      "Epoch 654/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1563 - accuracy: 0.9446 - val_loss: 0.1912 - val_accuracy: 0.9392\n",
      "Epoch 655/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1562 - accuracy: 0.9448 - val_loss: 0.1911 - val_accuracy: 0.9392\n",
      "Epoch 656/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1561 - accuracy: 0.9452 - val_loss: 0.1914 - val_accuracy: 0.9391\n",
      "Epoch 657/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1560 - accuracy: 0.9447 - val_loss: 0.1910 - val_accuracy: 0.9396\n",
      "Epoch 658/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1559 - accuracy: 0.9448 - val_loss: 0.1911 - val_accuracy: 0.9392\n",
      "Epoch 659/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1559 - accuracy: 0.9449 - val_loss: 0.1910 - val_accuracy: 0.9396\n",
      "Epoch 660/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1558 - accuracy: 0.9451 - val_loss: 0.1908 - val_accuracy: 0.9395\n",
      "Epoch 661/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1556 - accuracy: 0.9449 - val_loss: 0.1909 - val_accuracy: 0.9395\n",
      "Epoch 662/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1555 - accuracy: 0.9449 - val_loss: 0.1907 - val_accuracy: 0.9395\n",
      "Epoch 663/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1553 - accuracy: 0.9451 - val_loss: 0.1907 - val_accuracy: 0.9393\n",
      "Epoch 664/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1553 - accuracy: 0.9447 - val_loss: 0.1907 - val_accuracy: 0.9396\n",
      "Epoch 665/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.1552 - accuracy: 0.9447 - val_loss: 0.1905 - val_accuracy: 0.9397\n",
      "Epoch 666/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1551 - accuracy: 0.9451 - val_loss: 0.1906 - val_accuracy: 0.9392\n",
      "Epoch 667/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1550 - accuracy: 0.9448 - val_loss: 0.1906 - val_accuracy: 0.9391\n",
      "Epoch 668/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1549 - accuracy: 0.9453 - val_loss: 0.1903 - val_accuracy: 0.9393\n",
      "Epoch 669/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1548 - accuracy: 0.9448 - val_loss: 0.1904 - val_accuracy: 0.9395\n",
      "Epoch 670/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1548 - accuracy: 0.9448 - val_loss: 0.1902 - val_accuracy: 0.9393\n",
      "Epoch 671/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1545 - accuracy: 0.9452 - val_loss: 0.1905 - val_accuracy: 0.9395\n",
      "Epoch 672/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.1545 - accuracy: 0.9452 - val_loss: 0.1905 - val_accuracy: 0.9393\n",
      "Epoch 673/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1544 - accuracy: 0.9451 - val_loss: 0.1901 - val_accuracy: 0.9396\n",
      "Epoch 674/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1543 - accuracy: 0.9452 - val_loss: 0.1902 - val_accuracy: 0.9396\n",
      "Epoch 675/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1542 - accuracy: 0.9453 - val_loss: 0.1901 - val_accuracy: 0.9392\n",
      "Epoch 676/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1539 - accuracy: 0.9455 - val_loss: 0.1901 - val_accuracy: 0.9395\n",
      "Epoch 677/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1539 - accuracy: 0.9451 - val_loss: 0.1904 - val_accuracy: 0.9390\n",
      "Epoch 678/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1538 - accuracy: 0.9451 - val_loss: 0.1901 - val_accuracy: 0.9391\n",
      "Epoch 679/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1537 - accuracy: 0.9454 - val_loss: 0.1898 - val_accuracy: 0.9396\n",
      "Epoch 680/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1536 - accuracy: 0.9455 - val_loss: 0.1898 - val_accuracy: 0.9395\n",
      "Epoch 681/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1535 - accuracy: 0.9454 - val_loss: 0.1900 - val_accuracy: 0.9392\n",
      "Epoch 682/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1535 - accuracy: 0.9449 - val_loss: 0.1898 - val_accuracy: 0.9396\n",
      "Epoch 683/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1533 - accuracy: 0.9456 - val_loss: 0.1898 - val_accuracy: 0.9395\n",
      "Epoch 684/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1531 - accuracy: 0.9455 - val_loss: 0.1898 - val_accuracy: 0.9396\n",
      "Epoch 685/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1530 - accuracy: 0.9451 - val_loss: 0.1898 - val_accuracy: 0.9397\n",
      "Epoch 686/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1529 - accuracy: 0.9458 - val_loss: 0.1896 - val_accuracy: 0.9395\n",
      "Epoch 687/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1527 - accuracy: 0.9458 - val_loss: 0.1895 - val_accuracy: 0.9400\n",
      "Epoch 688/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1527 - accuracy: 0.9454 - val_loss: 0.1895 - val_accuracy: 0.9396\n",
      "Epoch 689/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1527 - accuracy: 0.9457 - val_loss: 0.1895 - val_accuracy: 0.9395\n",
      "Epoch 690/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.1524 - accuracy: 0.9453 - val_loss: 0.1897 - val_accuracy: 0.9397\n",
      "Epoch 691/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1524 - accuracy: 0.9458 - val_loss: 0.1894 - val_accuracy: 0.9397\n",
      "Epoch 692/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1523 - accuracy: 0.9456 - val_loss: 0.1891 - val_accuracy: 0.9400\n",
      "Epoch 693/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1521 - accuracy: 0.9457 - val_loss: 0.1892 - val_accuracy: 0.9398\n",
      "Epoch 694/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1520 - accuracy: 0.9457 - val_loss: 0.1894 - val_accuracy: 0.9397\n",
      "Epoch 695/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1519 - accuracy: 0.9458 - val_loss: 0.1894 - val_accuracy: 0.9395\n",
      "Epoch 696/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.1519 - accuracy: 0.9458 - val_loss: 0.1893 - val_accuracy: 0.9395\n",
      "Epoch 697/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1516 - accuracy: 0.9454 - val_loss: 0.1892 - val_accuracy: 0.9397\n",
      "Epoch 698/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1517 - accuracy: 0.9461 - val_loss: 0.1889 - val_accuracy: 0.9397\n",
      "Epoch 699/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1515 - accuracy: 0.9458 - val_loss: 0.1892 - val_accuracy: 0.9395\n",
      "Epoch 700/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1514 - accuracy: 0.9461 - val_loss: 0.1891 - val_accuracy: 0.9393\n",
      "Epoch 701/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1513 - accuracy: 0.9459 - val_loss: 0.1887 - val_accuracy: 0.9402\n",
      "Epoch 702/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1512 - accuracy: 0.9462 - val_loss: 0.1891 - val_accuracy: 0.9397\n",
      "Epoch 703/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1511 - accuracy: 0.9457 - val_loss: 0.1891 - val_accuracy: 0.9393\n",
      "Epoch 704/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1510 - accuracy: 0.9460 - val_loss: 0.1888 - val_accuracy: 0.9400\n",
      "Epoch 705/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1509 - accuracy: 0.9461 - val_loss: 0.1886 - val_accuracy: 0.9396\n",
      "Epoch 706/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1508 - accuracy: 0.9460 - val_loss: 0.1884 - val_accuracy: 0.9398\n",
      "Epoch 707/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1506 - accuracy: 0.9459 - val_loss: 0.1885 - val_accuracy: 0.9397\n",
      "Epoch 708/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1505 - accuracy: 0.9460 - val_loss: 0.1883 - val_accuracy: 0.9400\n",
      "Epoch 709/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1504 - accuracy: 0.9460 - val_loss: 0.1883 - val_accuracy: 0.9396\n",
      "Epoch 710/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1503 - accuracy: 0.9462 - val_loss: 0.1884 - val_accuracy: 0.9398\n",
      "Epoch 711/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1502 - accuracy: 0.9461 - val_loss: 0.1881 - val_accuracy: 0.9397\n",
      "Epoch 712/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1501 - accuracy: 0.9464 - val_loss: 0.1881 - val_accuracy: 0.9393\n",
      "Epoch 713/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1500 - accuracy: 0.9464 - val_loss: 0.1882 - val_accuracy: 0.9401\n",
      "Epoch 714/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1499 - accuracy: 0.9463 - val_loss: 0.1882 - val_accuracy: 0.9393\n",
      "Epoch 715/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1498 - accuracy: 0.9467 - val_loss: 0.1881 - val_accuracy: 0.9398\n",
      "Epoch 716/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1497 - accuracy: 0.9463 - val_loss: 0.1881 - val_accuracy: 0.9396\n",
      "Epoch 717/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1494 - accuracy: 0.9460 - val_loss: 0.1880 - val_accuracy: 0.9400\n",
      "Epoch 718/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1494 - accuracy: 0.9462 - val_loss: 0.1883 - val_accuracy: 0.9391\n",
      "Epoch 719/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1493 - accuracy: 0.9465 - val_loss: 0.1879 - val_accuracy: 0.9401\n",
      "Epoch 720/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1493 - accuracy: 0.9464 - val_loss: 0.1878 - val_accuracy: 0.9398\n",
      "Epoch 721/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1491 - accuracy: 0.9468 - val_loss: 0.1881 - val_accuracy: 0.9395\n",
      "Epoch 722/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1490 - accuracy: 0.9464 - val_loss: 0.1878 - val_accuracy: 0.9401\n",
      "Epoch 723/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1489 - accuracy: 0.9466 - val_loss: 0.1878 - val_accuracy: 0.9397\n",
      "Epoch 724/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1487 - accuracy: 0.9467 - val_loss: 0.1877 - val_accuracy: 0.9400\n",
      "Epoch 725/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1486 - accuracy: 0.9463 - val_loss: 0.1878 - val_accuracy: 0.9398\n",
      "Epoch 726/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1486 - accuracy: 0.9469 - val_loss: 0.1877 - val_accuracy: 0.9396\n",
      "Epoch 727/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1485 - accuracy: 0.9471 - val_loss: 0.1875 - val_accuracy: 0.9402\n",
      "Epoch 728/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 88us/step - loss: 0.1483 - accuracy: 0.9464 - val_loss: 0.1874 - val_accuracy: 0.9401\n",
      "Epoch 729/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1482 - accuracy: 0.9468 - val_loss: 0.1876 - val_accuracy: 0.9396\n",
      "Epoch 730/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1480 - accuracy: 0.9469 - val_loss: 0.1874 - val_accuracy: 0.9398\n",
      "Epoch 731/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1480 - accuracy: 0.9466 - val_loss: 0.1877 - val_accuracy: 0.9390\n",
      "Epoch 732/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1479 - accuracy: 0.9468 - val_loss: 0.1874 - val_accuracy: 0.9392\n",
      "Epoch 733/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1477 - accuracy: 0.9470 - val_loss: 0.1874 - val_accuracy: 0.9397\n",
      "Epoch 734/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1477 - accuracy: 0.9467 - val_loss: 0.1872 - val_accuracy: 0.9395\n",
      "Epoch 735/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1476 - accuracy: 0.9471 - val_loss: 0.1873 - val_accuracy: 0.9392\n",
      "Epoch 736/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1474 - accuracy: 0.9472 - val_loss: 0.1871 - val_accuracy: 0.9397\n",
      "Epoch 737/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1474 - accuracy: 0.9472 - val_loss: 0.1870 - val_accuracy: 0.9397\n",
      "Epoch 738/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1473 - accuracy: 0.9471 - val_loss: 0.1871 - val_accuracy: 0.9391\n",
      "Epoch 739/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1471 - accuracy: 0.9470 - val_loss: 0.1872 - val_accuracy: 0.9395\n",
      "Epoch 740/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1470 - accuracy: 0.9471 - val_loss: 0.1868 - val_accuracy: 0.9396\n",
      "Epoch 741/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1468 - accuracy: 0.9475 - val_loss: 0.1868 - val_accuracy: 0.9395\n",
      "Epoch 742/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1468 - accuracy: 0.9469 - val_loss: 0.1864 - val_accuracy: 0.9403\n",
      "Epoch 743/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1467 - accuracy: 0.9471 - val_loss: 0.1866 - val_accuracy: 0.9395\n",
      "Epoch 744/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1467 - accuracy: 0.9475 - val_loss: 0.1867 - val_accuracy: 0.9400\n",
      "Epoch 745/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1466 - accuracy: 0.9474 - val_loss: 0.1867 - val_accuracy: 0.9396\n",
      "Epoch 746/800\n",
      "480/480 [==============================] - 0s 91us/step - loss: 0.1464 - accuracy: 0.9477 - val_loss: 0.1864 - val_accuracy: 0.9393\n",
      "Epoch 747/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1463 - accuracy: 0.9472 - val_loss: 0.1864 - val_accuracy: 0.9397\n",
      "Epoch 748/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1461 - accuracy: 0.9471 - val_loss: 0.1865 - val_accuracy: 0.9393\n",
      "Epoch 749/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1460 - accuracy: 0.9473 - val_loss: 0.1866 - val_accuracy: 0.9391\n",
      "Epoch 750/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1461 - accuracy: 0.9473 - val_loss: 0.1863 - val_accuracy: 0.9398\n",
      "Epoch 751/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1458 - accuracy: 0.9476 - val_loss: 0.1863 - val_accuracy: 0.9392\n",
      "Epoch 752/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1457 - accuracy: 0.9474 - val_loss: 0.1861 - val_accuracy: 0.9400\n",
      "Epoch 753/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1456 - accuracy: 0.9473 - val_loss: 0.1862 - val_accuracy: 0.9393\n",
      "Epoch 754/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1454 - accuracy: 0.9475 - val_loss: 0.1863 - val_accuracy: 0.9387\n",
      "Epoch 755/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1455 - accuracy: 0.9476 - val_loss: 0.1858 - val_accuracy: 0.9397\n",
      "Epoch 756/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1453 - accuracy: 0.9471 - val_loss: 0.1863 - val_accuracy: 0.9388\n",
      "Epoch 757/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1453 - accuracy: 0.9473 - val_loss: 0.1861 - val_accuracy: 0.9393\n",
      "Epoch 758/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1451 - accuracy: 0.9475 - val_loss: 0.1861 - val_accuracy: 0.9395\n",
      "Epoch 759/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1451 - accuracy: 0.9476 - val_loss: 0.1859 - val_accuracy: 0.9393\n",
      "Epoch 760/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1449 - accuracy: 0.9478 - val_loss: 0.1861 - val_accuracy: 0.9396\n",
      "Epoch 761/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1449 - accuracy: 0.9476 - val_loss: 0.1862 - val_accuracy: 0.9396\n",
      "Epoch 762/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1447 - accuracy: 0.9475 - val_loss: 0.1859 - val_accuracy: 0.9398\n",
      "Epoch 763/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1447 - accuracy: 0.9477 - val_loss: 0.1860 - val_accuracy: 0.9398\n",
      "Epoch 764/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1445 - accuracy: 0.9479 - val_loss: 0.1860 - val_accuracy: 0.9396\n",
      "Epoch 765/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1444 - accuracy: 0.9473 - val_loss: 0.1856 - val_accuracy: 0.9400\n",
      "Epoch 766/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1444 - accuracy: 0.9476 - val_loss: 0.1860 - val_accuracy: 0.9391\n",
      "Epoch 767/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1443 - accuracy: 0.9478 - val_loss: 0.1858 - val_accuracy: 0.9397\n",
      "Epoch 768/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1441 - accuracy: 0.9480 - val_loss: 0.1855 - val_accuracy: 0.9396\n",
      "Epoch 769/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1440 - accuracy: 0.9475 - val_loss: 0.1855 - val_accuracy: 0.9390\n",
      "Epoch 770/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1440 - accuracy: 0.9480 - val_loss: 0.1854 - val_accuracy: 0.9392\n",
      "Epoch 771/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1438 - accuracy: 0.9480 - val_loss: 0.1853 - val_accuracy: 0.9392\n",
      "Epoch 772/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1437 - accuracy: 0.9482 - val_loss: 0.1857 - val_accuracy: 0.9391\n",
      "Epoch 773/800\n",
      "480/480 [==============================] - ETA: 0s - loss: 0.1285 - accuracy: 0.94 - 0s 83us/step - loss: 0.1437 - accuracy: 0.9478 - val_loss: 0.1853 - val_accuracy: 0.9397\n",
      "Epoch 774/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1436 - accuracy: 0.9478 - val_loss: 0.1852 - val_accuracy: 0.9392\n",
      "Epoch 775/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1435 - accuracy: 0.9480 - val_loss: 0.1852 - val_accuracy: 0.9393\n",
      "Epoch 776/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1433 - accuracy: 0.9482 - val_loss: 0.1852 - val_accuracy: 0.9398\n",
      "Epoch 777/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1433 - accuracy: 0.9482 - val_loss: 0.1853 - val_accuracy: 0.9396\n",
      "Epoch 778/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1432 - accuracy: 0.9483 - val_loss: 0.1853 - val_accuracy: 0.9392\n",
      "Epoch 779/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1430 - accuracy: 0.9480 - val_loss: 0.1853 - val_accuracy: 0.9398\n",
      "Epoch 780/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1430 - accuracy: 0.9481 - val_loss: 0.1851 - val_accuracy: 0.9393\n",
      "Epoch 781/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1429 - accuracy: 0.9481 - val_loss: 0.1854 - val_accuracy: 0.9391\n",
      "Epoch 782/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1428 - accuracy: 0.9485 - val_loss: 0.1851 - val_accuracy: 0.9393\n",
      "Epoch 783/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1427 - accuracy: 0.9485 - val_loss: 0.1850 - val_accuracy: 0.9396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 784/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1426 - accuracy: 0.9483 - val_loss: 0.1848 - val_accuracy: 0.9395\n",
      "Epoch 785/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1425 - accuracy: 0.9483 - val_loss: 0.1849 - val_accuracy: 0.9396\n",
      "Epoch 786/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1424 - accuracy: 0.9485 - val_loss: 0.1847 - val_accuracy: 0.9396\n",
      "Epoch 787/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1423 - accuracy: 0.9489 - val_loss: 0.1849 - val_accuracy: 0.9397\n",
      "Epoch 788/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1422 - accuracy: 0.9485 - val_loss: 0.1850 - val_accuracy: 0.9390\n",
      "Epoch 789/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1421 - accuracy: 0.9480 - val_loss: 0.1846 - val_accuracy: 0.9398\n",
      "Epoch 790/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1419 - accuracy: 0.9484 - val_loss: 0.1846 - val_accuracy: 0.9397\n",
      "Epoch 791/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1418 - accuracy: 0.9487 - val_loss: 0.1847 - val_accuracy: 0.9398\n",
      "Epoch 792/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1419 - accuracy: 0.9482 - val_loss: 0.1847 - val_accuracy: 0.9395\n",
      "Epoch 793/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1417 - accuracy: 0.9484 - val_loss: 0.1847 - val_accuracy: 0.9396\n",
      "Epoch 794/800\n",
      "480/480 [==============================] - 0s 96us/step - loss: 0.1417 - accuracy: 0.9484 - val_loss: 0.1844 - val_accuracy: 0.9398\n",
      "Epoch 795/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1415 - accuracy: 0.9485 - val_loss: 0.1847 - val_accuracy: 0.9395\n",
      "Epoch 796/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1414 - accuracy: 0.9484 - val_loss: 0.1845 - val_accuracy: 0.9401\n",
      "Epoch 797/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1413 - accuracy: 0.9486 - val_loss: 0.1844 - val_accuracy: 0.9400\n",
      "Epoch 798/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1413 - accuracy: 0.9486 - val_loss: 0.1843 - val_accuracy: 0.9398\n",
      "Epoch 799/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1412 - accuracy: 0.9486 - val_loss: 0.1845 - val_accuracy: 0.9398\n",
      "Epoch 800/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1411 - accuracy: 0.9489 - val_loss: 0.1842 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:122: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/800\n",
      "480/480 [==============================] - 0s 354us/step - loss: 0.6779 - accuracy: 0.6459 - val_loss: 0.6648 - val_accuracy: 0.7456\n",
      "Epoch 2/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.6503 - accuracy: 0.7933 - val_loss: 0.6333 - val_accuracy: 0.8332\n",
      "Epoch 3/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.6099 - accuracy: 0.8651 - val_loss: 0.5811 - val_accuracy: 0.9013\n",
      "Epoch 4/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.5364 - accuracy: 0.9187 - val_loss: 0.4816 - val_accuracy: 0.9189\n",
      "Epoch 5/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.4087 - accuracy: 0.9329 - val_loss: 0.3391 - val_accuracy: 0.9363\n",
      "Epoch 6/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2844 - accuracy: 0.9405 - val_loss: 0.2603 - val_accuracy: 0.9363\n",
      "Epoch 7/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2379 - accuracy: 0.9405 - val_loss: 0.2437 - val_accuracy: 0.9363\n",
      "Epoch 8/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2286 - accuracy: 0.9405 - val_loss: 0.2404 - val_accuracy: 0.9363\n",
      "Epoch 9/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2260 - accuracy: 0.9405 - val_loss: 0.2390 - val_accuracy: 0.9363\n",
      "Epoch 10/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2248 - accuracy: 0.9405 - val_loss: 0.2381 - val_accuracy: 0.9363\n",
      "Epoch 11/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2240 - accuracy: 0.9405 - val_loss: 0.2376 - val_accuracy: 0.9363\n",
      "Epoch 12/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2235 - accuracy: 0.9405 - val_loss: 0.2372 - val_accuracy: 0.9363\n",
      "Epoch 13/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2231 - accuracy: 0.9405 - val_loss: 0.2369 - val_accuracy: 0.9363\n",
      "Epoch 14/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2229 - accuracy: 0.9405 - val_loss: 0.2367 - val_accuracy: 0.9363\n",
      "Epoch 15/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2227 - accuracy: 0.9405 - val_loss: 0.2366 - val_accuracy: 0.9363\n",
      "Epoch 16/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2226 - accuracy: 0.9405 - val_loss: 0.2364 - val_accuracy: 0.9363\n",
      "Epoch 17/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2225 - accuracy: 0.9405 - val_loss: 0.2363 - val_accuracy: 0.9363\n",
      "Epoch 18/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2223 - accuracy: 0.9405 - val_loss: 0.2362 - val_accuracy: 0.9363\n",
      "Epoch 19/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2223 - accuracy: 0.9405 - val_loss: 0.2361 - val_accuracy: 0.9363\n",
      "Epoch 20/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2222 - accuracy: 0.9405 - val_loss: 0.2361 - val_accuracy: 0.9363\n",
      "Epoch 21/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2222 - accuracy: 0.9405 - val_loss: 0.2361 - val_accuracy: 0.9363\n",
      "Epoch 22/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2221 - accuracy: 0.9405 - val_loss: 0.2360 - val_accuracy: 0.9363\n",
      "Epoch 23/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2220 - accuracy: 0.9405 - val_loss: 0.2359 - val_accuracy: 0.9363\n",
      "Epoch 24/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2220 - accuracy: 0.9405 - val_loss: 0.2359 - val_accuracy: 0.9363\n",
      "Epoch 25/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2219 - accuracy: 0.9405 - val_loss: 0.2359 - val_accuracy: 0.9363\n",
      "Epoch 26/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2219 - accuracy: 0.9405 - val_loss: 0.2358 - val_accuracy: 0.9363\n",
      "Epoch 27/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2218 - accuracy: 0.9405 - val_loss: 0.2358 - val_accuracy: 0.9363\n",
      "Epoch 28/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2218 - accuracy: 0.9405 - val_loss: 0.2357 - val_accuracy: 0.9363\n",
      "Epoch 29/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2217 - accuracy: 0.9405 - val_loss: 0.2357 - val_accuracy: 0.9363\n",
      "Epoch 30/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2217 - accuracy: 0.9405 - val_loss: 0.2357 - val_accuracy: 0.9363\n",
      "Epoch 31/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2217 - accuracy: 0.9405 - val_loss: 0.2356 - val_accuracy: 0.9363\n",
      "Epoch 32/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2216 - accuracy: 0.9405 - val_loss: 0.2356 - val_accuracy: 0.9363\n",
      "Epoch 33/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2216 - accuracy: 0.9405 - val_loss: 0.2356 - val_accuracy: 0.9363\n",
      "Epoch 34/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2216 - accuracy: 0.9405 - val_loss: 0.2356 - val_accuracy: 0.9363\n",
      "Epoch 35/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2215 - accuracy: 0.9405 - val_loss: 0.2355 - val_accuracy: 0.9363\n",
      "Epoch 36/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2215 - accuracy: 0.9405 - val_loss: 0.2354 - val_accuracy: 0.9363\n",
      "Epoch 37/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2215 - accuracy: 0.9405 - val_loss: 0.2354 - val_accuracy: 0.9363\n",
      "Epoch 38/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2214 - accuracy: 0.9405 - val_loss: 0.2354 - val_accuracy: 0.9363\n",
      "Epoch 39/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2214 - accuracy: 0.9405 - val_loss: 0.2353 - val_accuracy: 0.9363\n",
      "Epoch 40/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2214 - accuracy: 0.9405 - val_loss: 0.2353 - val_accuracy: 0.9363\n",
      "Epoch 41/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2213 - accuracy: 0.9405 - val_loss: 0.2353 - val_accuracy: 0.9363\n",
      "Epoch 42/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2213 - accuracy: 0.9405 - val_loss: 0.2352 - val_accuracy: 0.9363\n",
      "Epoch 43/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2213 - accuracy: 0.9405 - val_loss: 0.2352 - val_accuracy: 0.9363\n",
      "Epoch 44/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2212 - accuracy: 0.9405 - val_loss: 0.2352 - val_accuracy: 0.9363\n",
      "Epoch 45/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2212 - accuracy: 0.9405 - val_loss: 0.2351 - val_accuracy: 0.9363\n",
      "Epoch 46/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2212 - accuracy: 0.9405 - val_loss: 0.2351 - val_accuracy: 0.9363\n",
      "Epoch 47/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2211 - accuracy: 0.9405 - val_loss: 0.2351 - val_accuracy: 0.9363\n",
      "Epoch 48/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2211 - accuracy: 0.9405 - val_loss: 0.2350 - val_accuracy: 0.9363\n",
      "Epoch 49/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2211 - accuracy: 0.9405 - val_loss: 0.2350 - val_accuracy: 0.9363\n",
      "Epoch 50/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2210 - accuracy: 0.9405 - val_loss: 0.2350 - val_accuracy: 0.9363\n",
      "Epoch 51/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2210 - accuracy: 0.9405 - val_loss: 0.2349 - val_accuracy: 0.9363\n",
      "Epoch 52/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2210 - accuracy: 0.9405 - val_loss: 0.2349 - val_accuracy: 0.9363\n",
      "Epoch 53/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2209 - accuracy: 0.9405 - val_loss: 0.2349 - val_accuracy: 0.9363\n",
      "Epoch 54/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2209 - accuracy: 0.9405 - val_loss: 0.2349 - val_accuracy: 0.9363\n",
      "Epoch 55/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2209 - accuracy: 0.9405 - val_loss: 0.2349 - val_accuracy: 0.9363\n",
      "Epoch 56/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.2208 - accuracy: 0.9405 - val_loss: 0.2348 - val_accuracy: 0.9363\n",
      "Epoch 57/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2208 - accuracy: 0.9405 - val_loss: 0.2348 - val_accuracy: 0.9363\n",
      "Epoch 58/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2208 - accuracy: 0.9405 - val_loss: 0.2348 - val_accuracy: 0.9363\n",
      "Epoch 59/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2208 - accuracy: 0.9405 - val_loss: 0.2348 - val_accuracy: 0.9363\n",
      "Epoch 60/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2207 - accuracy: 0.9405 - val_loss: 0.2347 - val_accuracy: 0.9363\n",
      "Epoch 61/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2207 - accuracy: 0.9405 - val_loss: 0.2347 - val_accuracy: 0.9363\n",
      "Epoch 62/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2207 - accuracy: 0.9405 - val_loss: 0.2347 - val_accuracy: 0.9363\n",
      "Epoch 63/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2206 - accuracy: 0.9405 - val_loss: 0.2346 - val_accuracy: 0.9363\n",
      "Epoch 64/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2206 - accuracy: 0.9405 - val_loss: 0.2346 - val_accuracy: 0.9363\n",
      "Epoch 65/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2206 - accuracy: 0.9405 - val_loss: 0.2346 - val_accuracy: 0.9363\n",
      "Epoch 66/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2206 - accuracy: 0.9405 - val_loss: 0.2345 - val_accuracy: 0.9363\n",
      "Epoch 67/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2205 - accuracy: 0.9405 - val_loss: 0.2345 - val_accuracy: 0.9363\n",
      "Epoch 68/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2205 - accuracy: 0.9405 - val_loss: 0.2345 - val_accuracy: 0.9363\n",
      "Epoch 69/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2205 - accuracy: 0.9405 - val_loss: 0.2345 - val_accuracy: 0.9363\n",
      "Epoch 70/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2205 - accuracy: 0.9405 - val_loss: 0.2344 - val_accuracy: 0.9363\n",
      "Epoch 71/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2204 - accuracy: 0.9405 - val_loss: 0.2344 - val_accuracy: 0.9363\n",
      "Epoch 72/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2204 - accuracy: 0.9405 - val_loss: 0.2344 - val_accuracy: 0.9363\n",
      "Epoch 73/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2204 - accuracy: 0.9405 - val_loss: 0.2344 - val_accuracy: 0.9363\n",
      "Epoch 74/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2204 - accuracy: 0.9405 - val_loss: 0.2344 - val_accuracy: 0.9363\n",
      "Epoch 75/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2203 - accuracy: 0.9405 - val_loss: 0.2343 - val_accuracy: 0.9363\n",
      "Epoch 76/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2203 - accuracy: 0.9405 - val_loss: 0.2343 - val_accuracy: 0.9363\n",
      "Epoch 77/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2203 - accuracy: 0.9405 - val_loss: 0.2342 - val_accuracy: 0.9363\n",
      "Epoch 78/800\n",
      "480/480 [==============================] - 0s 104us/step - loss: 0.2202 - accuracy: 0.9405 - val_loss: 0.2342 - val_accuracy: 0.9363\n",
      "Epoch 79/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2202 - accuracy: 0.9405 - val_loss: 0.2342 - val_accuracy: 0.9363\n",
      "Epoch 80/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2202 - accuracy: 0.9405 - val_loss: 0.2342 - val_accuracy: 0.9363\n",
      "Epoch 81/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2201 - accuracy: 0.9405 - val_loss: 0.2342 - val_accuracy: 0.9363\n",
      "Epoch 82/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2201 - accuracy: 0.9405 - val_loss: 0.2341 - val_accuracy: 0.9363\n",
      "Epoch 83/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.2201 - accuracy: 0.9405 - val_loss: 0.2341 - val_accuracy: 0.9363\n",
      "Epoch 84/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2200 - accuracy: 0.9405 - val_loss: 0.2341 - val_accuracy: 0.9363\n",
      "Epoch 85/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2201 - accuracy: 0.9405 - val_loss: 0.2340 - val_accuracy: 0.9363\n",
      "Epoch 86/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2200 - accuracy: 0.9405 - val_loss: 0.2340 - val_accuracy: 0.9363\n",
      "Epoch 87/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2200 - accuracy: 0.9405 - val_loss: 0.2339 - val_accuracy: 0.9363\n",
      "Epoch 88/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2199 - accuracy: 0.9405 - val_loss: 0.2339 - val_accuracy: 0.9363\n",
      "Epoch 89/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2199 - accuracy: 0.9405 - val_loss: 0.2339 - val_accuracy: 0.9363\n",
      "Epoch 90/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.2199 - accuracy: 0.9405 - val_loss: 0.2339 - val_accuracy: 0.9363\n",
      "Epoch 91/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2198 - accuracy: 0.9405 - val_loss: 0.2339 - val_accuracy: 0.9363\n",
      "Epoch 92/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2198 - accuracy: 0.9405 - val_loss: 0.2338 - val_accuracy: 0.9363\n",
      "Epoch 93/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2197 - accuracy: 0.9405 - val_loss: 0.2338 - val_accuracy: 0.9363\n",
      "Epoch 94/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2198 - accuracy: 0.9405 - val_loss: 0.2338 - val_accuracy: 0.9363\n",
      "Epoch 95/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2197 - accuracy: 0.9405 - val_loss: 0.2338 - val_accuracy: 0.9363\n",
      "Epoch 96/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2197 - accuracy: 0.9405 - val_loss: 0.2338 - val_accuracy: 0.9363\n",
      "Epoch 97/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2197 - accuracy: 0.9405 - val_loss: 0.2337 - val_accuracy: 0.9363\n",
      "Epoch 98/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.2196 - accuracy: 0.9405 - val_loss: 0.2337 - val_accuracy: 0.9363\n",
      "Epoch 99/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2196 - accuracy: 0.9405 - val_loss: 0.2337 - val_accuracy: 0.9363\n",
      "Epoch 100/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2195 - accuracy: 0.9405 - val_loss: 0.2336 - val_accuracy: 0.9363\n",
      "Epoch 101/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2195 - accuracy: 0.9405 - val_loss: 0.2336 - val_accuracy: 0.9363\n",
      "Epoch 102/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2195 - accuracy: 0.9405 - val_loss: 0.2336 - val_accuracy: 0.9363\n",
      "Epoch 103/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2195 - accuracy: 0.9405 - val_loss: 0.2336 - val_accuracy: 0.9363\n",
      "Epoch 104/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2195 - accuracy: 0.9405 - val_loss: 0.2336 - val_accuracy: 0.9363\n",
      "Epoch 105/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2194 - accuracy: 0.9405 - val_loss: 0.2335 - val_accuracy: 0.9363\n",
      "Epoch 106/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2193 - accuracy: 0.9405 - val_loss: 0.2335 - val_accuracy: 0.9363\n",
      "Epoch 107/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2194 - accuracy: 0.9405 - val_loss: 0.2335 - val_accuracy: 0.9363\n",
      "Epoch 108/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2193 - accuracy: 0.9405 - val_loss: 0.2335 - val_accuracy: 0.9363\n",
      "Epoch 109/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2193 - accuracy: 0.9405 - val_loss: 0.2334 - val_accuracy: 0.9363\n",
      "Epoch 110/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2193 - accuracy: 0.9405 - val_loss: 0.2334 - val_accuracy: 0.9363\n",
      "Epoch 111/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2192 - accuracy: 0.9405 - val_loss: 0.2334 - val_accuracy: 0.9363\n",
      "Epoch 112/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 88us/step - loss: 0.2192 - accuracy: 0.9405 - val_loss: 0.2333 - val_accuracy: 0.9363\n",
      "Epoch 113/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2192 - accuracy: 0.9405 - val_loss: 0.2333 - val_accuracy: 0.9363\n",
      "Epoch 114/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2191 - accuracy: 0.9405 - val_loss: 0.2333 - val_accuracy: 0.9363\n",
      "Epoch 115/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2191 - accuracy: 0.9405 - val_loss: 0.2332 - val_accuracy: 0.9363\n",
      "Epoch 116/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2191 - accuracy: 0.9405 - val_loss: 0.2332 - val_accuracy: 0.9363\n",
      "Epoch 117/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2190 - accuracy: 0.9405 - val_loss: 0.2332 - val_accuracy: 0.9363\n",
      "Epoch 118/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2190 - accuracy: 0.9405 - val_loss: 0.2331 - val_accuracy: 0.9363\n",
      "Epoch 119/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2190 - accuracy: 0.9405 - val_loss: 0.2331 - val_accuracy: 0.9363\n",
      "Epoch 120/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2189 - accuracy: 0.9405 - val_loss: 0.2331 - val_accuracy: 0.9363\n",
      "Epoch 121/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2189 - accuracy: 0.9405 - val_loss: 0.2331 - val_accuracy: 0.9363\n",
      "Epoch 122/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2188 - accuracy: 0.9405 - val_loss: 0.2330 - val_accuracy: 0.9363\n",
      "Epoch 123/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2189 - accuracy: 0.9405 - val_loss: 0.2330 - val_accuracy: 0.9363\n",
      "Epoch 124/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2188 - accuracy: 0.9405 - val_loss: 0.2330 - val_accuracy: 0.9363\n",
      "Epoch 125/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2188 - accuracy: 0.9405 - val_loss: 0.2330 - val_accuracy: 0.9363\n",
      "Epoch 126/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2188 - accuracy: 0.9405 - val_loss: 0.2330 - val_accuracy: 0.9363\n",
      "Epoch 127/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2187 - accuracy: 0.9405 - val_loss: 0.2329 - val_accuracy: 0.9363\n",
      "Epoch 128/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2187 - accuracy: 0.9405 - val_loss: 0.2329 - val_accuracy: 0.9363\n",
      "Epoch 129/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2186 - accuracy: 0.9405 - val_loss: 0.2329 - val_accuracy: 0.9363\n",
      "Epoch 130/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2186 - accuracy: 0.9405 - val_loss: 0.2329 - val_accuracy: 0.9363\n",
      "Epoch 131/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2186 - accuracy: 0.9405 - val_loss: 0.2328 - val_accuracy: 0.9363\n",
      "Epoch 132/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2185 - accuracy: 0.9405 - val_loss: 0.2328 - val_accuracy: 0.9363\n",
      "Epoch 133/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2185 - accuracy: 0.9405 - val_loss: 0.2327 - val_accuracy: 0.9363\n",
      "Epoch 134/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2185 - accuracy: 0.9405 - val_loss: 0.2327 - val_accuracy: 0.9363\n",
      "Epoch 135/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2184 - accuracy: 0.9405 - val_loss: 0.2326 - val_accuracy: 0.9363\n",
      "Epoch 136/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2184 - accuracy: 0.9405 - val_loss: 0.2326 - val_accuracy: 0.9363\n",
      "Epoch 137/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2183 - accuracy: 0.9405 - val_loss: 0.2326 - val_accuracy: 0.9363\n",
      "Epoch 138/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2183 - accuracy: 0.9405 - val_loss: 0.2326 - val_accuracy: 0.9363\n",
      "Epoch 139/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2183 - accuracy: 0.9405 - val_loss: 0.2326 - val_accuracy: 0.9363\n",
      "Epoch 140/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2182 - accuracy: 0.9405 - val_loss: 0.2325 - val_accuracy: 0.9363\n",
      "Epoch 141/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2182 - accuracy: 0.9405 - val_loss: 0.2325 - val_accuracy: 0.9363\n",
      "Epoch 142/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2181 - accuracy: 0.9405 - val_loss: 0.2325 - val_accuracy: 0.9363\n",
      "Epoch 143/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2181 - accuracy: 0.9405 - val_loss: 0.2325 - val_accuracy: 0.9363\n",
      "Epoch 144/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2180 - accuracy: 0.9405 - val_loss: 0.2324 - val_accuracy: 0.9363\n",
      "Epoch 145/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2180 - accuracy: 0.9405 - val_loss: 0.2323 - val_accuracy: 0.9363\n",
      "Epoch 146/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2180 - accuracy: 0.9405 - val_loss: 0.2323 - val_accuracy: 0.9363\n",
      "Epoch 147/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2179 - accuracy: 0.9405 - val_loss: 0.2323 - val_accuracy: 0.9363\n",
      "Epoch 148/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2179 - accuracy: 0.9405 - val_loss: 0.2323 - val_accuracy: 0.9363\n",
      "Epoch 149/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2178 - accuracy: 0.9405 - val_loss: 0.2322 - val_accuracy: 0.9363\n",
      "Epoch 150/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2178 - accuracy: 0.9405 - val_loss: 0.2322 - val_accuracy: 0.9363\n",
      "Epoch 151/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2178 - accuracy: 0.9405 - val_loss: 0.2322 - val_accuracy: 0.9363\n",
      "Epoch 152/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2177 - accuracy: 0.9405 - val_loss: 0.2321 - val_accuracy: 0.9363\n",
      "Epoch 153/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2177 - accuracy: 0.9405 - val_loss: 0.2321 - val_accuracy: 0.9363\n",
      "Epoch 154/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2176 - accuracy: 0.9405 - val_loss: 0.2320 - val_accuracy: 0.9363\n",
      "Epoch 155/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2176 - accuracy: 0.9405 - val_loss: 0.2320 - val_accuracy: 0.9363\n",
      "Epoch 156/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.2176 - accuracy: 0.9405 - val_loss: 0.2320 - val_accuracy: 0.9363\n",
      "Epoch 157/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2175 - accuracy: 0.9405 - val_loss: 0.2319 - val_accuracy: 0.9363\n",
      "Epoch 158/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2175 - accuracy: 0.9405 - val_loss: 0.2319 - val_accuracy: 0.9363\n",
      "Epoch 159/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2174 - accuracy: 0.9405 - val_loss: 0.2319 - val_accuracy: 0.9363\n",
      "Epoch 160/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2174 - accuracy: 0.9405 - val_loss: 0.2318 - val_accuracy: 0.9363\n",
      "Epoch 161/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2173 - accuracy: 0.9405 - val_loss: 0.2318 - val_accuracy: 0.9363\n",
      "Epoch 162/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2173 - accuracy: 0.9405 - val_loss: 0.2317 - val_accuracy: 0.9363\n",
      "Epoch 163/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2172 - accuracy: 0.9405 - val_loss: 0.2317 - val_accuracy: 0.9363\n",
      "Epoch 164/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2172 - accuracy: 0.9405 - val_loss: 0.2317 - val_accuracy: 0.9363\n",
      "Epoch 165/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2171 - accuracy: 0.9405 - val_loss: 0.2317 - val_accuracy: 0.9363\n",
      "Epoch 166/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2171 - accuracy: 0.9405 - val_loss: 0.2316 - val_accuracy: 0.9363\n",
      "Epoch 167/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2170 - accuracy: 0.9405 - val_loss: 0.2316 - val_accuracy: 0.9363\n",
      "Epoch 168/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 83us/step - loss: 0.2170 - accuracy: 0.9405 - val_loss: 0.2315 - val_accuracy: 0.9363\n",
      "Epoch 169/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2169 - accuracy: 0.9405 - val_loss: 0.2315 - val_accuracy: 0.9363\n",
      "Epoch 170/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2169 - accuracy: 0.9405 - val_loss: 0.2314 - val_accuracy: 0.9363\n",
      "Epoch 171/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2169 - accuracy: 0.9405 - val_loss: 0.2314 - val_accuracy: 0.9363\n",
      "Epoch 172/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2168 - accuracy: 0.9405 - val_loss: 0.2314 - val_accuracy: 0.9363\n",
      "Epoch 173/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2168 - accuracy: 0.9405 - val_loss: 0.2313 - val_accuracy: 0.9363\n",
      "Epoch 174/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2167 - accuracy: 0.9405 - val_loss: 0.2313 - val_accuracy: 0.9363\n",
      "Epoch 175/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2167 - accuracy: 0.9405 - val_loss: 0.2313 - val_accuracy: 0.9363\n",
      "Epoch 176/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2166 - accuracy: 0.9405 - val_loss: 0.2312 - val_accuracy: 0.9363\n",
      "Epoch 177/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2166 - accuracy: 0.9405 - val_loss: 0.2311 - val_accuracy: 0.9363\n",
      "Epoch 178/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2165 - accuracy: 0.9405 - val_loss: 0.2311 - val_accuracy: 0.9363\n",
      "Epoch 179/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2164 - accuracy: 0.9405 - val_loss: 0.2311 - val_accuracy: 0.9363\n",
      "Epoch 180/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2164 - accuracy: 0.9405 - val_loss: 0.2310 - val_accuracy: 0.9363\n",
      "Epoch 181/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2163 - accuracy: 0.9405 - val_loss: 0.2309 - val_accuracy: 0.9363\n",
      "Epoch 182/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2163 - accuracy: 0.9405 - val_loss: 0.2309 - val_accuracy: 0.9363\n",
      "Epoch 183/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2163 - accuracy: 0.9405 - val_loss: 0.2309 - val_accuracy: 0.9363\n",
      "Epoch 184/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2162 - accuracy: 0.9405 - val_loss: 0.2309 - val_accuracy: 0.9363\n",
      "Epoch 185/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2161 - accuracy: 0.9405 - val_loss: 0.2309 - val_accuracy: 0.9363\n",
      "Epoch 186/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2161 - accuracy: 0.9405 - val_loss: 0.2308 - val_accuracy: 0.9363\n",
      "Epoch 187/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2160 - accuracy: 0.9405 - val_loss: 0.2308 - val_accuracy: 0.9363\n",
      "Epoch 188/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2160 - accuracy: 0.9405 - val_loss: 0.2308 - val_accuracy: 0.9363\n",
      "Epoch 189/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2159 - accuracy: 0.9405 - val_loss: 0.2307 - val_accuracy: 0.9363\n",
      "Epoch 190/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2159 - accuracy: 0.9405 - val_loss: 0.2306 - val_accuracy: 0.9363\n",
      "Epoch 191/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2158 - accuracy: 0.9405 - val_loss: 0.2306 - val_accuracy: 0.9363\n",
      "Epoch 192/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2157 - accuracy: 0.9405 - val_loss: 0.2305 - val_accuracy: 0.9363\n",
      "Epoch 193/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2157 - accuracy: 0.9405 - val_loss: 0.2305 - val_accuracy: 0.9363\n",
      "Epoch 194/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2156 - accuracy: 0.9405 - val_loss: 0.2304 - val_accuracy: 0.9363\n",
      "Epoch 195/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2155 - accuracy: 0.9405 - val_loss: 0.2303 - val_accuracy: 0.9363\n",
      "Epoch 196/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2155 - accuracy: 0.9405 - val_loss: 0.2303 - val_accuracy: 0.9363\n",
      "Epoch 197/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2154 - accuracy: 0.9405 - val_loss: 0.2302 - val_accuracy: 0.9363\n",
      "Epoch 198/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2154 - accuracy: 0.9405 - val_loss: 0.2302 - val_accuracy: 0.9363\n",
      "Epoch 199/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2153 - accuracy: 0.9405 - val_loss: 0.2302 - val_accuracy: 0.9363\n",
      "Epoch 200/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2153 - accuracy: 0.9405 - val_loss: 0.2302 - val_accuracy: 0.9363\n",
      "Epoch 201/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2152 - accuracy: 0.9405 - val_loss: 0.2301 - val_accuracy: 0.9363\n",
      "Epoch 202/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2151 - accuracy: 0.9405 - val_loss: 0.2300 - val_accuracy: 0.9363\n",
      "Epoch 203/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2150 - accuracy: 0.9405 - val_loss: 0.2299 - val_accuracy: 0.9363\n",
      "Epoch 204/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2150 - accuracy: 0.9405 - val_loss: 0.2300 - val_accuracy: 0.9363\n",
      "Epoch 205/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2149 - accuracy: 0.9405 - val_loss: 0.2298 - val_accuracy: 0.9363\n",
      "Epoch 206/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2148 - accuracy: 0.9405 - val_loss: 0.2298 - val_accuracy: 0.9363\n",
      "Epoch 207/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2148 - accuracy: 0.9405 - val_loss: 0.2297 - val_accuracy: 0.9363\n",
      "Epoch 208/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2147 - accuracy: 0.9405 - val_loss: 0.2297 - val_accuracy: 0.9363\n",
      "Epoch 209/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2146 - accuracy: 0.9405 - val_loss: 0.2296 - val_accuracy: 0.9363\n",
      "Epoch 210/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2146 - accuracy: 0.9405 - val_loss: 0.2296 - val_accuracy: 0.9363\n",
      "Epoch 211/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2145 - accuracy: 0.9405 - val_loss: 0.2294 - val_accuracy: 0.9363\n",
      "Epoch 212/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2144 - accuracy: 0.9405 - val_loss: 0.2295 - val_accuracy: 0.9363\n",
      "Epoch 213/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2143 - accuracy: 0.9405 - val_loss: 0.2293 - val_accuracy: 0.9363\n",
      "Epoch 214/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2143 - accuracy: 0.9405 - val_loss: 0.2293 - val_accuracy: 0.9363\n",
      "Epoch 215/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2142 - accuracy: 0.9405 - val_loss: 0.2292 - val_accuracy: 0.9363\n",
      "Epoch 216/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2141 - accuracy: 0.9405 - val_loss: 0.2292 - val_accuracy: 0.9363\n",
      "Epoch 217/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2141 - accuracy: 0.9405 - val_loss: 0.2291 - val_accuracy: 0.9363\n",
      "Epoch 218/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2140 - accuracy: 0.9405 - val_loss: 0.2290 - val_accuracy: 0.9363\n",
      "Epoch 219/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2139 - accuracy: 0.9405 - val_loss: 0.2290 - val_accuracy: 0.9363\n",
      "Epoch 220/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2138 - accuracy: 0.9405 - val_loss: 0.2289 - val_accuracy: 0.9363\n",
      "Epoch 221/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2137 - accuracy: 0.9405 - val_loss: 0.2288 - val_accuracy: 0.9363\n",
      "Epoch 222/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2137 - accuracy: 0.9405 - val_loss: 0.2287 - val_accuracy: 0.9363\n",
      "Epoch 223/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2135 - accuracy: 0.9405 - val_loss: 0.2287 - val_accuracy: 0.9363\n",
      "Epoch 224/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 83us/step - loss: 0.2135 - accuracy: 0.9405 - val_loss: 0.2286 - val_accuracy: 0.9363\n",
      "Epoch 225/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2134 - accuracy: 0.9405 - val_loss: 0.2286 - val_accuracy: 0.9363\n",
      "Epoch 226/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2133 - accuracy: 0.9405 - val_loss: 0.2285 - val_accuracy: 0.9363\n",
      "Epoch 227/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2133 - accuracy: 0.9405 - val_loss: 0.2284 - val_accuracy: 0.9363\n",
      "Epoch 228/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2132 - accuracy: 0.9405 - val_loss: 0.2284 - val_accuracy: 0.9363\n",
      "Epoch 229/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2131 - accuracy: 0.9405 - val_loss: 0.2283 - val_accuracy: 0.9363\n",
      "Epoch 230/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2130 - accuracy: 0.9405 - val_loss: 0.2283 - val_accuracy: 0.9363\n",
      "Epoch 231/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2129 - accuracy: 0.9405 - val_loss: 0.2282 - val_accuracy: 0.9363\n",
      "Epoch 232/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2128 - accuracy: 0.9405 - val_loss: 0.2281 - val_accuracy: 0.9363\n",
      "Epoch 233/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2127 - accuracy: 0.9405 - val_loss: 0.2281 - val_accuracy: 0.9363\n",
      "Epoch 234/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2126 - accuracy: 0.9405 - val_loss: 0.2280 - val_accuracy: 0.9363\n",
      "Epoch 235/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2126 - accuracy: 0.9405 - val_loss: 0.2279 - val_accuracy: 0.9363\n",
      "Epoch 236/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2125 - accuracy: 0.9405 - val_loss: 0.2279 - val_accuracy: 0.9363\n",
      "Epoch 237/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2124 - accuracy: 0.9405 - val_loss: 0.2278 - val_accuracy: 0.9363\n",
      "Epoch 238/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2123 - accuracy: 0.9405 - val_loss: 0.2277 - val_accuracy: 0.9363\n",
      "Epoch 239/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2122 - accuracy: 0.9405 - val_loss: 0.2277 - val_accuracy: 0.9363\n",
      "Epoch 240/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2121 - accuracy: 0.9405 - val_loss: 0.2276 - val_accuracy: 0.9363\n",
      "Epoch 241/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2120 - accuracy: 0.9405 - val_loss: 0.2275 - val_accuracy: 0.9363\n",
      "Epoch 242/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2119 - accuracy: 0.9405 - val_loss: 0.2274 - val_accuracy: 0.9363\n",
      "Epoch 243/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2118 - accuracy: 0.9405 - val_loss: 0.2274 - val_accuracy: 0.9363\n",
      "Epoch 244/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2117 - accuracy: 0.9405 - val_loss: 0.2273 - val_accuracy: 0.9363\n",
      "Epoch 245/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2116 - accuracy: 0.9405 - val_loss: 0.2272 - val_accuracy: 0.9363\n",
      "Epoch 246/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2115 - accuracy: 0.9405 - val_loss: 0.2271 - val_accuracy: 0.9363\n",
      "Epoch 247/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2114 - accuracy: 0.9405 - val_loss: 0.2270 - val_accuracy: 0.9363\n",
      "Epoch 248/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2113 - accuracy: 0.9405 - val_loss: 0.2270 - val_accuracy: 0.9363\n",
      "Epoch 249/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2112 - accuracy: 0.9405 - val_loss: 0.2269 - val_accuracy: 0.9363\n",
      "Epoch 250/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2112 - accuracy: 0.9405 - val_loss: 0.2269 - val_accuracy: 0.9363\n",
      "Epoch 251/800\n",
      "480/480 [==============================] - 0s 80us/step - loss: 0.2110 - accuracy: 0.9405 - val_loss: 0.2268 - val_accuracy: 0.9363\n",
      "Epoch 252/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2109 - accuracy: 0.9405 - val_loss: 0.2267 - val_accuracy: 0.9363\n",
      "Epoch 253/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2108 - accuracy: 0.9405 - val_loss: 0.2266 - val_accuracy: 0.9363\n",
      "Epoch 254/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2107 - accuracy: 0.9405 - val_loss: 0.2265 - val_accuracy: 0.9363\n",
      "Epoch 255/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2106 - accuracy: 0.9405 - val_loss: 0.2264 - val_accuracy: 0.9363\n",
      "Epoch 256/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2106 - accuracy: 0.9405 - val_loss: 0.2263 - val_accuracy: 0.9363\n",
      "Epoch 257/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2105 - accuracy: 0.9405 - val_loss: 0.2262 - val_accuracy: 0.9363\n",
      "Epoch 258/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2104 - accuracy: 0.9405 - val_loss: 0.2262 - val_accuracy: 0.9363\n",
      "Epoch 259/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2103 - accuracy: 0.9405 - val_loss: 0.2261 - val_accuracy: 0.9363\n",
      "Epoch 260/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2101 - accuracy: 0.9405 - val_loss: 0.2261 - val_accuracy: 0.9363\n",
      "Epoch 261/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2100 - accuracy: 0.9405 - val_loss: 0.2260 - val_accuracy: 0.9363\n",
      "Epoch 262/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2099 - accuracy: 0.9405 - val_loss: 0.2259 - val_accuracy: 0.9363\n",
      "Epoch 263/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2098 - accuracy: 0.9405 - val_loss: 0.2258 - val_accuracy: 0.9363\n",
      "Epoch 264/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2098 - accuracy: 0.9405 - val_loss: 0.2257 - val_accuracy: 0.9363\n",
      "Epoch 265/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2096 - accuracy: 0.9405 - val_loss: 0.2256 - val_accuracy: 0.9363\n",
      "Epoch 266/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2095 - accuracy: 0.9405 - val_loss: 0.2256 - val_accuracy: 0.9363\n",
      "Epoch 267/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2094 - accuracy: 0.9405 - val_loss: 0.2255 - val_accuracy: 0.9363\n",
      "Epoch 268/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2093 - accuracy: 0.9405 - val_loss: 0.2254 - val_accuracy: 0.9363\n",
      "Epoch 269/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2092 - accuracy: 0.9405 - val_loss: 0.2253 - val_accuracy: 0.9363\n",
      "Epoch 270/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2091 - accuracy: 0.9405 - val_loss: 0.2253 - val_accuracy: 0.9363\n",
      "Epoch 271/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2090 - accuracy: 0.9405 - val_loss: 0.2252 - val_accuracy: 0.9363\n",
      "Epoch 272/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2089 - accuracy: 0.9405 - val_loss: 0.2250 - val_accuracy: 0.9363\n",
      "Epoch 273/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2088 - accuracy: 0.9405 - val_loss: 0.2250 - val_accuracy: 0.9363\n",
      "Epoch 274/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2087 - accuracy: 0.9405 - val_loss: 0.2249 - val_accuracy: 0.9363\n",
      "Epoch 275/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2086 - accuracy: 0.9405 - val_loss: 0.2249 - val_accuracy: 0.9363\n",
      "Epoch 276/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2085 - accuracy: 0.9405 - val_loss: 0.2248 - val_accuracy: 0.9363\n",
      "Epoch 277/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2084 - accuracy: 0.9405 - val_loss: 0.2247 - val_accuracy: 0.9363\n",
      "Epoch 278/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2082 - accuracy: 0.9405 - val_loss: 0.2246 - val_accuracy: 0.9363\n",
      "Epoch 279/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2082 - accuracy: 0.9405 - val_loss: 0.2245 - val_accuracy: 0.9363\n",
      "Epoch 280/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 79us/step - loss: 0.2080 - accuracy: 0.9405 - val_loss: 0.2244 - val_accuracy: 0.9363\n",
      "Epoch 281/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2079 - accuracy: 0.9405 - val_loss: 0.2243 - val_accuracy: 0.9363\n",
      "Epoch 282/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2079 - accuracy: 0.9405 - val_loss: 0.2242 - val_accuracy: 0.9363\n",
      "Epoch 283/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2077 - accuracy: 0.9405 - val_loss: 0.2242 - val_accuracy: 0.9363\n",
      "Epoch 284/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2076 - accuracy: 0.9405 - val_loss: 0.2240 - val_accuracy: 0.9363\n",
      "Epoch 285/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2075 - accuracy: 0.9405 - val_loss: 0.2240 - val_accuracy: 0.9363\n",
      "Epoch 286/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2074 - accuracy: 0.9405 - val_loss: 0.2239 - val_accuracy: 0.9363\n",
      "Epoch 287/800\n",
      "480/480 [==============================] - 0s 77us/step - loss: 0.2073 - accuracy: 0.9405 - val_loss: 0.2238 - val_accuracy: 0.9363\n",
      "Epoch 288/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2072 - accuracy: 0.9405 - val_loss: 0.2237 - val_accuracy: 0.9363\n",
      "Epoch 289/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2071 - accuracy: 0.9405 - val_loss: 0.2237 - val_accuracy: 0.9363\n",
      "Epoch 290/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2070 - accuracy: 0.9405 - val_loss: 0.2237 - val_accuracy: 0.9363\n",
      "Epoch 291/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2069 - accuracy: 0.9405 - val_loss: 0.2235 - val_accuracy: 0.9363\n",
      "Epoch 292/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2067 - accuracy: 0.9405 - val_loss: 0.2234 - val_accuracy: 0.9363\n",
      "Epoch 293/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2066 - accuracy: 0.9405 - val_loss: 0.2233 - val_accuracy: 0.9363\n",
      "Epoch 294/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2065 - accuracy: 0.9405 - val_loss: 0.2233 - val_accuracy: 0.9363\n",
      "Epoch 295/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2064 - accuracy: 0.9405 - val_loss: 0.2232 - val_accuracy: 0.9363\n",
      "Epoch 296/800\n",
      "480/480 [==============================] - 0s 101us/step - loss: 0.2063 - accuracy: 0.9405 - val_loss: 0.2231 - val_accuracy: 0.9363\n",
      "Epoch 297/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2062 - accuracy: 0.9405 - val_loss: 0.2230 - val_accuracy: 0.9363\n",
      "Epoch 298/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2061 - accuracy: 0.9405 - val_loss: 0.2230 - val_accuracy: 0.9363\n",
      "Epoch 299/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2060 - accuracy: 0.9405 - val_loss: 0.2229 - val_accuracy: 0.9363\n",
      "Epoch 300/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2058 - accuracy: 0.9405 - val_loss: 0.2228 - val_accuracy: 0.9363\n",
      "Epoch 301/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.2058 - accuracy: 0.9405 - val_loss: 0.2227 - val_accuracy: 0.9363\n",
      "Epoch 302/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2056 - accuracy: 0.9405 - val_loss: 0.2226 - val_accuracy: 0.9363\n",
      "Epoch 303/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2056 - accuracy: 0.9405 - val_loss: 0.2225 - val_accuracy: 0.9363\n",
      "Epoch 304/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2054 - accuracy: 0.9405 - val_loss: 0.2224 - val_accuracy: 0.9363\n",
      "Epoch 305/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2053 - accuracy: 0.9405 - val_loss: 0.2224 - val_accuracy: 0.9363\n",
      "Epoch 306/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2052 - accuracy: 0.9405 - val_loss: 0.2223 - val_accuracy: 0.9363\n",
      "Epoch 307/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2051 - accuracy: 0.9405 - val_loss: 0.2222 - val_accuracy: 0.9363\n",
      "Epoch 308/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2049 - accuracy: 0.9406 - val_loss: 0.2221 - val_accuracy: 0.9363\n",
      "Epoch 309/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2048 - accuracy: 0.9405 - val_loss: 0.2220 - val_accuracy: 0.9363\n",
      "Epoch 310/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2048 - accuracy: 0.9406 - val_loss: 0.2220 - val_accuracy: 0.9363\n",
      "Epoch 311/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2046 - accuracy: 0.9405 - val_loss: 0.2218 - val_accuracy: 0.9363\n",
      "Epoch 312/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2045 - accuracy: 0.9405 - val_loss: 0.2217 - val_accuracy: 0.9363\n",
      "Epoch 313/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2044 - accuracy: 0.9406 - val_loss: 0.2217 - val_accuracy: 0.9363\n",
      "Epoch 314/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2043 - accuracy: 0.9406 - val_loss: 0.2216 - val_accuracy: 0.9363\n",
      "Epoch 315/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2042 - accuracy: 0.9406 - val_loss: 0.2214 - val_accuracy: 0.9363\n",
      "Epoch 316/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2040 - accuracy: 0.9406 - val_loss: 0.2214 - val_accuracy: 0.9363\n",
      "Epoch 317/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2040 - accuracy: 0.9406 - val_loss: 0.2213 - val_accuracy: 0.9363\n",
      "Epoch 318/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2038 - accuracy: 0.9406 - val_loss: 0.2212 - val_accuracy: 0.9363\n",
      "Epoch 319/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2037 - accuracy: 0.9406 - val_loss: 0.2210 - val_accuracy: 0.9363\n",
      "Epoch 320/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2036 - accuracy: 0.9406 - val_loss: 0.2210 - val_accuracy: 0.9363\n",
      "Epoch 321/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2035 - accuracy: 0.9406 - val_loss: 0.2209 - val_accuracy: 0.9363\n",
      "Epoch 322/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2033 - accuracy: 0.9406 - val_loss: 0.2208 - val_accuracy: 0.9363\n",
      "Epoch 323/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2032 - accuracy: 0.9406 - val_loss: 0.2208 - val_accuracy: 0.9363\n",
      "Epoch 324/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2031 - accuracy: 0.9406 - val_loss: 0.2207 - val_accuracy: 0.9363\n",
      "Epoch 325/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2030 - accuracy: 0.9406 - val_loss: 0.2206 - val_accuracy: 0.9363\n",
      "Epoch 326/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2029 - accuracy: 0.9406 - val_loss: 0.2205 - val_accuracy: 0.9363\n",
      "Epoch 327/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2028 - accuracy: 0.9406 - val_loss: 0.2204 - val_accuracy: 0.9363\n",
      "Epoch 328/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2027 - accuracy: 0.9406 - val_loss: 0.2203 - val_accuracy: 0.9363\n",
      "Epoch 329/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2025 - accuracy: 0.9406 - val_loss: 0.2202 - val_accuracy: 0.9363\n",
      "Epoch 330/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2024 - accuracy: 0.9406 - val_loss: 0.2201 - val_accuracy: 0.9363\n",
      "Epoch 331/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2023 - accuracy: 0.9407 - val_loss: 0.2201 - val_accuracy: 0.9363\n",
      "Epoch 332/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2022 - accuracy: 0.9406 - val_loss: 0.2199 - val_accuracy: 0.9363\n",
      "Epoch 333/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2021 - accuracy: 0.9406 - val_loss: 0.2199 - val_accuracy: 0.9363\n",
      "Epoch 334/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2019 - accuracy: 0.9407 - val_loss: 0.2198 - val_accuracy: 0.9363\n",
      "Epoch 335/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2018 - accuracy: 0.9407 - val_loss: 0.2197 - val_accuracy: 0.9363\n",
      "Epoch 336/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.2017 - accuracy: 0.9407 - val_loss: 0.2196 - val_accuracy: 0.9363\n",
      "Epoch 337/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2016 - accuracy: 0.9407 - val_loss: 0.2195 - val_accuracy: 0.9363\n",
      "Epoch 338/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2015 - accuracy: 0.9407 - val_loss: 0.2194 - val_accuracy: 0.9363\n",
      "Epoch 339/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2013 - accuracy: 0.9407 - val_loss: 0.2194 - val_accuracy: 0.9363\n",
      "Epoch 340/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2012 - accuracy: 0.9407 - val_loss: 0.2193 - val_accuracy: 0.9363\n",
      "Epoch 341/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2011 - accuracy: 0.9407 - val_loss: 0.2192 - val_accuracy: 0.9363\n",
      "Epoch 342/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2010 - accuracy: 0.9407 - val_loss: 0.2191 - val_accuracy: 0.9363\n",
      "Epoch 343/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2008 - accuracy: 0.9408 - val_loss: 0.2189 - val_accuracy: 0.9364\n",
      "Epoch 344/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2008 - accuracy: 0.9407 - val_loss: 0.2188 - val_accuracy: 0.9364\n",
      "Epoch 345/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2006 - accuracy: 0.9407 - val_loss: 0.2187 - val_accuracy: 0.9364\n",
      "Epoch 346/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2005 - accuracy: 0.9407 - val_loss: 0.2186 - val_accuracy: 0.9364\n",
      "Epoch 347/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2004 - accuracy: 0.9408 - val_loss: 0.2185 - val_accuracy: 0.9364\n",
      "Epoch 348/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2003 - accuracy: 0.9408 - val_loss: 0.2184 - val_accuracy: 0.9364\n",
      "Epoch 349/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2001 - accuracy: 0.9408 - val_loss: 0.2183 - val_accuracy: 0.9365\n",
      "Epoch 350/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2000 - accuracy: 0.9408 - val_loss: 0.2183 - val_accuracy: 0.9365\n",
      "Epoch 351/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1998 - accuracy: 0.9408 - val_loss: 0.2182 - val_accuracy: 0.9366\n",
      "Epoch 352/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1998 - accuracy: 0.9408 - val_loss: 0.2181 - val_accuracy: 0.9366\n",
      "Epoch 353/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1996 - accuracy: 0.9408 - val_loss: 0.2180 - val_accuracy: 0.9365\n",
      "Epoch 354/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1995 - accuracy: 0.9408 - val_loss: 0.2179 - val_accuracy: 0.9366\n",
      "Epoch 355/800\n",
      "480/480 [==============================] - 0s 80us/step - loss: 0.1994 - accuracy: 0.9408 - val_loss: 0.2178 - val_accuracy: 0.9366\n",
      "Epoch 356/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.1993 - accuracy: 0.9408 - val_loss: 0.2177 - val_accuracy: 0.9365\n",
      "Epoch 357/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1991 - accuracy: 0.9408 - val_loss: 0.2176 - val_accuracy: 0.9366\n",
      "Epoch 358/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1990 - accuracy: 0.9408 - val_loss: 0.2174 - val_accuracy: 0.9366\n",
      "Epoch 359/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1989 - accuracy: 0.9408 - val_loss: 0.2174 - val_accuracy: 0.9366\n",
      "Epoch 360/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1987 - accuracy: 0.9407 - val_loss: 0.2173 - val_accuracy: 0.9366\n",
      "Epoch 361/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1986 - accuracy: 0.9408 - val_loss: 0.2171 - val_accuracy: 0.9366\n",
      "Epoch 362/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1985 - accuracy: 0.9408 - val_loss: 0.2170 - val_accuracy: 0.9366\n",
      "Epoch 363/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1984 - accuracy: 0.9408 - val_loss: 0.2170 - val_accuracy: 0.9366\n",
      "Epoch 364/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1982 - accuracy: 0.9407 - val_loss: 0.2169 - val_accuracy: 0.9366\n",
      "Epoch 365/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1981 - accuracy: 0.9408 - val_loss: 0.2167 - val_accuracy: 0.9366\n",
      "Epoch 366/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1980 - accuracy: 0.9408 - val_loss: 0.2166 - val_accuracy: 0.9366\n",
      "Epoch 367/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1978 - accuracy: 0.9408 - val_loss: 0.2166 - val_accuracy: 0.9366\n",
      "Epoch 368/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1977 - accuracy: 0.9407 - val_loss: 0.2165 - val_accuracy: 0.9366\n",
      "Epoch 369/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1976 - accuracy: 0.9408 - val_loss: 0.2164 - val_accuracy: 0.9366\n",
      "Epoch 370/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1975 - accuracy: 0.9408 - val_loss: 0.2162 - val_accuracy: 0.9366\n",
      "Epoch 371/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1973 - accuracy: 0.9408 - val_loss: 0.2162 - val_accuracy: 0.9366\n",
      "Epoch 372/800\n",
      "480/480 [==============================] - 0s 80us/step - loss: 0.1972 - accuracy: 0.9408 - val_loss: 0.2161 - val_accuracy: 0.9366\n",
      "Epoch 373/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1971 - accuracy: 0.9408 - val_loss: 0.2160 - val_accuracy: 0.9366\n",
      "Epoch 374/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1970 - accuracy: 0.9408 - val_loss: 0.2159 - val_accuracy: 0.9366\n",
      "Epoch 375/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1968 - accuracy: 0.9408 - val_loss: 0.2159 - val_accuracy: 0.9366\n",
      "Epoch 376/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1967 - accuracy: 0.9408 - val_loss: 0.2158 - val_accuracy: 0.9366\n",
      "Epoch 377/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1966 - accuracy: 0.9408 - val_loss: 0.2156 - val_accuracy: 0.9366\n",
      "Epoch 378/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1964 - accuracy: 0.9408 - val_loss: 0.2156 - val_accuracy: 0.9366\n",
      "Epoch 379/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1963 - accuracy: 0.9408 - val_loss: 0.2154 - val_accuracy: 0.9366\n",
      "Epoch 380/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1962 - accuracy: 0.9408 - val_loss: 0.2153 - val_accuracy: 0.9366\n",
      "Epoch 381/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1961 - accuracy: 0.9408 - val_loss: 0.2153 - val_accuracy: 0.9366\n",
      "Epoch 382/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1959 - accuracy: 0.9408 - val_loss: 0.2151 - val_accuracy: 0.9366\n",
      "Epoch 383/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1958 - accuracy: 0.9408 - val_loss: 0.2149 - val_accuracy: 0.9366\n",
      "Epoch 384/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1957 - accuracy: 0.9408 - val_loss: 0.2148 - val_accuracy: 0.9366\n",
      "Epoch 385/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1955 - accuracy: 0.9408 - val_loss: 0.2149 - val_accuracy: 0.9366\n",
      "Epoch 386/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1954 - accuracy: 0.9409 - val_loss: 0.2147 - val_accuracy: 0.9366\n",
      "Epoch 387/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1953 - accuracy: 0.9408 - val_loss: 0.2146 - val_accuracy: 0.9366\n",
      "Epoch 388/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1952 - accuracy: 0.9409 - val_loss: 0.2144 - val_accuracy: 0.9366\n",
      "Epoch 389/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1950 - accuracy: 0.9409 - val_loss: 0.2144 - val_accuracy: 0.9366\n",
      "Epoch 390/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1949 - accuracy: 0.9409 - val_loss: 0.2143 - val_accuracy: 0.9366\n",
      "Epoch 391/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1948 - accuracy: 0.9410 - val_loss: 0.2143 - val_accuracy: 0.9366\n",
      "Epoch 392/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 90us/step - loss: 0.1946 - accuracy: 0.9408 - val_loss: 0.2141 - val_accuracy: 0.9366\n",
      "Epoch 393/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1945 - accuracy: 0.9408 - val_loss: 0.2139 - val_accuracy: 0.9366\n",
      "Epoch 394/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1944 - accuracy: 0.9408 - val_loss: 0.2139 - val_accuracy: 0.9366\n",
      "Epoch 395/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1943 - accuracy: 0.9408 - val_loss: 0.2138 - val_accuracy: 0.9366\n",
      "Epoch 396/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1941 - accuracy: 0.9409 - val_loss: 0.2137 - val_accuracy: 0.9366\n",
      "Epoch 397/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1940 - accuracy: 0.9409 - val_loss: 0.2136 - val_accuracy: 0.9366\n",
      "Epoch 398/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1939 - accuracy: 0.9409 - val_loss: 0.2135 - val_accuracy: 0.9366\n",
      "Epoch 399/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1938 - accuracy: 0.9409 - val_loss: 0.2135 - val_accuracy: 0.9366\n",
      "Epoch 400/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1936 - accuracy: 0.9409 - val_loss: 0.2134 - val_accuracy: 0.9366\n",
      "Epoch 401/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1935 - accuracy: 0.9409 - val_loss: 0.2133 - val_accuracy: 0.9366\n",
      "Epoch 402/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1933 - accuracy: 0.9408 - val_loss: 0.2130 - val_accuracy: 0.9366\n",
      "Epoch 403/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1933 - accuracy: 0.9410 - val_loss: 0.2129 - val_accuracy: 0.9366\n",
      "Epoch 404/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1931 - accuracy: 0.9410 - val_loss: 0.2129 - val_accuracy: 0.9366\n",
      "Epoch 405/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1929 - accuracy: 0.9409 - val_loss: 0.2129 - val_accuracy: 0.9366\n",
      "Epoch 406/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1929 - accuracy: 0.9410 - val_loss: 0.2128 - val_accuracy: 0.9366\n",
      "Epoch 407/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1927 - accuracy: 0.9409 - val_loss: 0.2126 - val_accuracy: 0.9366\n",
      "Epoch 408/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1926 - accuracy: 0.9410 - val_loss: 0.2125 - val_accuracy: 0.9366\n",
      "Epoch 409/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1925 - accuracy: 0.9411 - val_loss: 0.2125 - val_accuracy: 0.9368\n",
      "Epoch 410/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1924 - accuracy: 0.9410 - val_loss: 0.2123 - val_accuracy: 0.9368\n",
      "Epoch 411/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1922 - accuracy: 0.9409 - val_loss: 0.2122 - val_accuracy: 0.9366\n",
      "Epoch 412/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1921 - accuracy: 0.9411 - val_loss: 0.2121 - val_accuracy: 0.9368\n",
      "Epoch 413/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1920 - accuracy: 0.9410 - val_loss: 0.2119 - val_accuracy: 0.9368\n",
      "Epoch 414/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1919 - accuracy: 0.9410 - val_loss: 0.2119 - val_accuracy: 0.9366\n",
      "Epoch 415/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1917 - accuracy: 0.9410 - val_loss: 0.2118 - val_accuracy: 0.9366\n",
      "Epoch 416/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1916 - accuracy: 0.9410 - val_loss: 0.2117 - val_accuracy: 0.9368\n",
      "Epoch 417/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1915 - accuracy: 0.9410 - val_loss: 0.2115 - val_accuracy: 0.9368\n",
      "Epoch 418/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1913 - accuracy: 0.9409 - val_loss: 0.2115 - val_accuracy: 0.9369\n",
      "Epoch 419/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1912 - accuracy: 0.9410 - val_loss: 0.2116 - val_accuracy: 0.9369\n",
      "Epoch 420/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1911 - accuracy: 0.9411 - val_loss: 0.2114 - val_accuracy: 0.9368\n",
      "Epoch 421/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.1909 - accuracy: 0.9409 - val_loss: 0.2113 - val_accuracy: 0.9369\n",
      "Epoch 422/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1908 - accuracy: 0.9409 - val_loss: 0.2112 - val_accuracy: 0.9368\n",
      "Epoch 423/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1907 - accuracy: 0.9410 - val_loss: 0.2111 - val_accuracy: 0.9369\n",
      "Epoch 424/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1907 - accuracy: 0.9409 - val_loss: 0.2110 - val_accuracy: 0.9369\n",
      "Epoch 425/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1905 - accuracy: 0.9409 - val_loss: 0.2109 - val_accuracy: 0.9369\n",
      "Epoch 426/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1904 - accuracy: 0.9410 - val_loss: 0.2108 - val_accuracy: 0.9369\n",
      "Epoch 427/800\n",
      "480/480 [==============================] - 0s 80us/step - loss: 0.1903 - accuracy: 0.9411 - val_loss: 0.2107 - val_accuracy: 0.9369\n",
      "Epoch 428/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1902 - accuracy: 0.9409 - val_loss: 0.2107 - val_accuracy: 0.9369\n",
      "Epoch 429/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1900 - accuracy: 0.9410 - val_loss: 0.2105 - val_accuracy: 0.9369\n",
      "Epoch 430/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1899 - accuracy: 0.9411 - val_loss: 0.2105 - val_accuracy: 0.9369\n",
      "Epoch 431/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1898 - accuracy: 0.9410 - val_loss: 0.2104 - val_accuracy: 0.9369\n",
      "Epoch 432/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1896 - accuracy: 0.9410 - val_loss: 0.2103 - val_accuracy: 0.9369\n",
      "Epoch 433/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1895 - accuracy: 0.9410 - val_loss: 0.2102 - val_accuracy: 0.9369\n",
      "Epoch 434/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1894 - accuracy: 0.9410 - val_loss: 0.2102 - val_accuracy: 0.9369\n",
      "Epoch 435/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1893 - accuracy: 0.9410 - val_loss: 0.2099 - val_accuracy: 0.9369\n",
      "Epoch 436/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1892 - accuracy: 0.9410 - val_loss: 0.2097 - val_accuracy: 0.9369\n",
      "Epoch 437/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1890 - accuracy: 0.9410 - val_loss: 0.2097 - val_accuracy: 0.9369\n",
      "Epoch 438/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1889 - accuracy: 0.9410 - val_loss: 0.2097 - val_accuracy: 0.9369\n",
      "Epoch 439/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1888 - accuracy: 0.9411 - val_loss: 0.2096 - val_accuracy: 0.9369\n",
      "Epoch 440/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1887 - accuracy: 0.9410 - val_loss: 0.2095 - val_accuracy: 0.9369\n",
      "Epoch 441/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1886 - accuracy: 0.9409 - val_loss: 0.2093 - val_accuracy: 0.9369\n",
      "Epoch 442/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1884 - accuracy: 0.9411 - val_loss: 0.2094 - val_accuracy: 0.9369\n",
      "Epoch 443/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1883 - accuracy: 0.9410 - val_loss: 0.2092 - val_accuracy: 0.9369\n",
      "Epoch 444/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1881 - accuracy: 0.9411 - val_loss: 0.2091 - val_accuracy: 0.9369\n",
      "Epoch 445/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1880 - accuracy: 0.9409 - val_loss: 0.2090 - val_accuracy: 0.9369\n",
      "Epoch 446/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1880 - accuracy: 0.9412 - val_loss: 0.2089 - val_accuracy: 0.9369\n",
      "Epoch 447/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1878 - accuracy: 0.9410 - val_loss: 0.2088 - val_accuracy: 0.9369\n",
      "Epoch 448/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 87us/step - loss: 0.1877 - accuracy: 0.9410 - val_loss: 0.2087 - val_accuracy: 0.9369\n",
      "Epoch 449/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1875 - accuracy: 0.9411 - val_loss: 0.2086 - val_accuracy: 0.9369\n",
      "Epoch 450/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1874 - accuracy: 0.9411 - val_loss: 0.2085 - val_accuracy: 0.9369\n",
      "Epoch 451/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1873 - accuracy: 0.9409 - val_loss: 0.2085 - val_accuracy: 0.9369\n",
      "Epoch 452/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1872 - accuracy: 0.9411 - val_loss: 0.2083 - val_accuracy: 0.9369\n",
      "Epoch 453/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1871 - accuracy: 0.9411 - val_loss: 0.2083 - val_accuracy: 0.9369\n",
      "Epoch 454/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1869 - accuracy: 0.9410 - val_loss: 0.2082 - val_accuracy: 0.9370\n",
      "Epoch 455/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1868 - accuracy: 0.9411 - val_loss: 0.2080 - val_accuracy: 0.9369\n",
      "Epoch 456/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1868 - accuracy: 0.9411 - val_loss: 0.2079 - val_accuracy: 0.9369\n",
      "Epoch 457/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1866 - accuracy: 0.9411 - val_loss: 0.2080 - val_accuracy: 0.9370\n",
      "Epoch 458/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1865 - accuracy: 0.9411 - val_loss: 0.2078 - val_accuracy: 0.9369\n",
      "Epoch 459/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1863 - accuracy: 0.9411 - val_loss: 0.2078 - val_accuracy: 0.9370\n",
      "Epoch 460/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1863 - accuracy: 0.9412 - val_loss: 0.2077 - val_accuracy: 0.9370\n",
      "Epoch 461/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1861 - accuracy: 0.9413 - val_loss: 0.2075 - val_accuracy: 0.9370\n",
      "Epoch 462/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1860 - accuracy: 0.9412 - val_loss: 0.2075 - val_accuracy: 0.9370\n",
      "Epoch 463/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1858 - accuracy: 0.9413 - val_loss: 0.2075 - val_accuracy: 0.9370\n",
      "Epoch 464/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1858 - accuracy: 0.9410 - val_loss: 0.2074 - val_accuracy: 0.9370\n",
      "Epoch 465/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1856 - accuracy: 0.9412 - val_loss: 0.2073 - val_accuracy: 0.9370\n",
      "Epoch 466/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1855 - accuracy: 0.9411 - val_loss: 0.2072 - val_accuracy: 0.9369\n",
      "Epoch 467/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1853 - accuracy: 0.9411 - val_loss: 0.2070 - val_accuracy: 0.9369\n",
      "Epoch 468/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1853 - accuracy: 0.9412 - val_loss: 0.2069 - val_accuracy: 0.9370\n",
      "Epoch 469/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1851 - accuracy: 0.9413 - val_loss: 0.2067 - val_accuracy: 0.9370\n",
      "Epoch 470/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1850 - accuracy: 0.9413 - val_loss: 0.2068 - val_accuracy: 0.9368\n",
      "Epoch 471/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1849 - accuracy: 0.9413 - val_loss: 0.2066 - val_accuracy: 0.9369\n",
      "Epoch 472/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1847 - accuracy: 0.9410 - val_loss: 0.2066 - val_accuracy: 0.9368\n",
      "Epoch 473/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1846 - accuracy: 0.9414 - val_loss: 0.2064 - val_accuracy: 0.9368\n",
      "Epoch 474/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1845 - accuracy: 0.9414 - val_loss: 0.2063 - val_accuracy: 0.9369\n",
      "Epoch 475/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1844 - accuracy: 0.9414 - val_loss: 0.2063 - val_accuracy: 0.9366\n",
      "Epoch 476/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1842 - accuracy: 0.9413 - val_loss: 0.2061 - val_accuracy: 0.9366\n",
      "Epoch 477/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1841 - accuracy: 0.9413 - val_loss: 0.2061 - val_accuracy: 0.9366\n",
      "Epoch 478/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1840 - accuracy: 0.9413 - val_loss: 0.2061 - val_accuracy: 0.9370\n",
      "Epoch 479/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1839 - accuracy: 0.9415 - val_loss: 0.2058 - val_accuracy: 0.9366\n",
      "Epoch 480/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1838 - accuracy: 0.9414 - val_loss: 0.2059 - val_accuracy: 0.9368\n",
      "Epoch 481/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1836 - accuracy: 0.9413 - val_loss: 0.2055 - val_accuracy: 0.9368\n",
      "Epoch 482/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1835 - accuracy: 0.9413 - val_loss: 0.2056 - val_accuracy: 0.9366\n",
      "Epoch 483/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1834 - accuracy: 0.9414 - val_loss: 0.2055 - val_accuracy: 0.9366\n",
      "Epoch 484/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1833 - accuracy: 0.9413 - val_loss: 0.2056 - val_accuracy: 0.9366\n",
      "Epoch 485/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.1832 - accuracy: 0.9414 - val_loss: 0.2054 - val_accuracy: 0.9368\n",
      "Epoch 486/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1829 - accuracy: 0.9413 - val_loss: 0.2053 - val_accuracy: 0.9366\n",
      "Epoch 487/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1828 - accuracy: 0.9415 - val_loss: 0.2052 - val_accuracy: 0.9368\n",
      "Epoch 488/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1827 - accuracy: 0.9413 - val_loss: 0.2049 - val_accuracy: 0.9366\n",
      "Epoch 489/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1826 - accuracy: 0.9415 - val_loss: 0.2050 - val_accuracy: 0.9366\n",
      "Epoch 490/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1825 - accuracy: 0.9414 - val_loss: 0.2048 - val_accuracy: 0.9366\n",
      "Epoch 491/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1823 - accuracy: 0.9416 - val_loss: 0.2048 - val_accuracy: 0.9366\n",
      "Epoch 492/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1822 - accuracy: 0.9413 - val_loss: 0.2046 - val_accuracy: 0.9366\n",
      "Epoch 493/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1821 - accuracy: 0.9416 - val_loss: 0.2045 - val_accuracy: 0.9366\n",
      "Epoch 494/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1819 - accuracy: 0.9416 - val_loss: 0.2047 - val_accuracy: 0.9366\n",
      "Epoch 495/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1817 - accuracy: 0.9414 - val_loss: 0.2044 - val_accuracy: 0.9366\n",
      "Epoch 496/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1817 - accuracy: 0.9415 - val_loss: 0.2043 - val_accuracy: 0.9368\n",
      "Epoch 497/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1816 - accuracy: 0.9414 - val_loss: 0.2040 - val_accuracy: 0.9368\n",
      "Epoch 498/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1814 - accuracy: 0.9414 - val_loss: 0.2042 - val_accuracy: 0.9366\n",
      "Epoch 499/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1813 - accuracy: 0.9415 - val_loss: 0.2041 - val_accuracy: 0.9366\n",
      "Epoch 500/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1812 - accuracy: 0.9415 - val_loss: 0.2039 - val_accuracy: 0.9368\n",
      "Epoch 501/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1810 - accuracy: 0.9413 - val_loss: 0.2037 - val_accuracy: 0.9366\n",
      "Epoch 502/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1810 - accuracy: 0.9414 - val_loss: 0.2038 - val_accuracy: 0.9366\n",
      "Epoch 503/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1808 - accuracy: 0.9414 - val_loss: 0.2037 - val_accuracy: 0.9366\n",
      "Epoch 504/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 86us/step - loss: 0.1807 - accuracy: 0.9414 - val_loss: 0.2034 - val_accuracy: 0.9366\n",
      "Epoch 505/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1805 - accuracy: 0.9415 - val_loss: 0.2033 - val_accuracy: 0.9365\n",
      "Epoch 506/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1804 - accuracy: 0.9414 - val_loss: 0.2034 - val_accuracy: 0.9364\n",
      "Epoch 507/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1803 - accuracy: 0.9415 - val_loss: 0.2032 - val_accuracy: 0.9365\n",
      "Epoch 508/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1801 - accuracy: 0.9413 - val_loss: 0.2032 - val_accuracy: 0.9366\n",
      "Epoch 509/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1800 - accuracy: 0.9413 - val_loss: 0.2030 - val_accuracy: 0.9365\n",
      "Epoch 510/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1799 - accuracy: 0.9413 - val_loss: 0.2030 - val_accuracy: 0.9364\n",
      "Epoch 511/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1798 - accuracy: 0.9413 - val_loss: 0.2030 - val_accuracy: 0.9364\n",
      "Epoch 512/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1797 - accuracy: 0.9413 - val_loss: 0.2029 - val_accuracy: 0.9364\n",
      "Epoch 513/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1795 - accuracy: 0.9415 - val_loss: 0.2027 - val_accuracy: 0.9364\n",
      "Epoch 514/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1793 - accuracy: 0.9416 - val_loss: 0.2027 - val_accuracy: 0.9364\n",
      "Epoch 515/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1792 - accuracy: 0.9413 - val_loss: 0.2026 - val_accuracy: 0.9363\n",
      "Epoch 516/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1791 - accuracy: 0.9414 - val_loss: 0.2025 - val_accuracy: 0.9363\n",
      "Epoch 517/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1789 - accuracy: 0.9414 - val_loss: 0.2024 - val_accuracy: 0.9364\n",
      "Epoch 518/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1789 - accuracy: 0.9415 - val_loss: 0.2021 - val_accuracy: 0.9364\n",
      "Epoch 519/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1788 - accuracy: 0.9414 - val_loss: 0.2022 - val_accuracy: 0.9364\n",
      "Epoch 520/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1785 - accuracy: 0.9415 - val_loss: 0.2022 - val_accuracy: 0.9364\n",
      "Epoch 521/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1785 - accuracy: 0.9414 - val_loss: 0.2019 - val_accuracy: 0.9364\n",
      "Epoch 522/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1784 - accuracy: 0.9415 - val_loss: 0.2017 - val_accuracy: 0.9363\n",
      "Epoch 523/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1782 - accuracy: 0.9414 - val_loss: 0.2018 - val_accuracy: 0.9364\n",
      "Epoch 524/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1780 - accuracy: 0.9417 - val_loss: 0.2016 - val_accuracy: 0.9365\n",
      "Epoch 525/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1779 - accuracy: 0.9416 - val_loss: 0.2015 - val_accuracy: 0.9364\n",
      "Epoch 526/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1779 - accuracy: 0.9414 - val_loss: 0.2014 - val_accuracy: 0.9365\n",
      "Epoch 527/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1777 - accuracy: 0.9415 - val_loss: 0.2013 - val_accuracy: 0.9365\n",
      "Epoch 528/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1776 - accuracy: 0.9416 - val_loss: 0.2015 - val_accuracy: 0.9365\n",
      "Epoch 529/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1775 - accuracy: 0.9415 - val_loss: 0.2013 - val_accuracy: 0.9363\n",
      "Epoch 530/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1773 - accuracy: 0.9417 - val_loss: 0.2012 - val_accuracy: 0.9365\n",
      "Epoch 531/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1772 - accuracy: 0.9416 - val_loss: 0.2009 - val_accuracy: 0.9363\n",
      "Epoch 532/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1770 - accuracy: 0.9415 - val_loss: 0.2010 - val_accuracy: 0.9364\n",
      "Epoch 533/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1769 - accuracy: 0.9413 - val_loss: 0.2009 - val_accuracy: 0.9363\n",
      "Epoch 534/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1767 - accuracy: 0.9415 - val_loss: 0.2006 - val_accuracy: 0.9363\n",
      "Epoch 535/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1767 - accuracy: 0.9418 - val_loss: 0.2008 - val_accuracy: 0.9365\n",
      "Epoch 536/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1764 - accuracy: 0.9417 - val_loss: 0.2006 - val_accuracy: 0.9363\n",
      "Epoch 537/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1764 - accuracy: 0.9417 - val_loss: 0.2007 - val_accuracy: 0.9360\n",
      "Epoch 538/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1763 - accuracy: 0.9417 - val_loss: 0.2006 - val_accuracy: 0.9362\n",
      "Epoch 539/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1761 - accuracy: 0.9419 - val_loss: 0.2004 - val_accuracy: 0.9362\n",
      "Epoch 540/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1760 - accuracy: 0.9419 - val_loss: 0.2001 - val_accuracy: 0.9363\n",
      "Epoch 541/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1758 - accuracy: 0.9420 - val_loss: 0.1999 - val_accuracy: 0.9362\n",
      "Epoch 542/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1758 - accuracy: 0.9418 - val_loss: 0.2002 - val_accuracy: 0.9359\n",
      "Epoch 543/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1756 - accuracy: 0.9420 - val_loss: 0.2001 - val_accuracy: 0.9362\n",
      "Epoch 544/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1754 - accuracy: 0.9418 - val_loss: 0.1998 - val_accuracy: 0.9360\n",
      "Epoch 545/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1753 - accuracy: 0.9418 - val_loss: 0.1998 - val_accuracy: 0.9359\n",
      "Epoch 546/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1752 - accuracy: 0.9418 - val_loss: 0.1996 - val_accuracy: 0.9358\n",
      "Epoch 547/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1751 - accuracy: 0.9420 - val_loss: 0.1996 - val_accuracy: 0.9360\n",
      "Epoch 548/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1750 - accuracy: 0.9420 - val_loss: 0.1995 - val_accuracy: 0.9362\n",
      "Epoch 549/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1749 - accuracy: 0.9420 - val_loss: 0.1994 - val_accuracy: 0.9358\n",
      "Epoch 550/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1747 - accuracy: 0.9422 - val_loss: 0.1995 - val_accuracy: 0.9358\n",
      "Epoch 551/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1745 - accuracy: 0.9421 - val_loss: 0.1992 - val_accuracy: 0.9362\n",
      "Epoch 552/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1744 - accuracy: 0.9419 - val_loss: 0.1991 - val_accuracy: 0.9357\n",
      "Epoch 553/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1743 - accuracy: 0.9421 - val_loss: 0.1991 - val_accuracy: 0.9357\n",
      "Epoch 554/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1742 - accuracy: 0.9422 - val_loss: 0.1988 - val_accuracy: 0.9355\n",
      "Epoch 555/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1741 - accuracy: 0.9421 - val_loss: 0.1990 - val_accuracy: 0.9358\n",
      "Epoch 556/800\n",
      "480/480 [==============================] - 0s 104us/step - loss: 0.1739 - accuracy: 0.9421 - val_loss: 0.1989 - val_accuracy: 0.9360\n",
      "Epoch 557/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1738 - accuracy: 0.9420 - val_loss: 0.1989 - val_accuracy: 0.9358\n",
      "Epoch 558/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1737 - accuracy: 0.9423 - val_loss: 0.1988 - val_accuracy: 0.9358\n",
      "Epoch 559/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1736 - accuracy: 0.9424 - val_loss: 0.1986 - val_accuracy: 0.9358\n",
      "Epoch 560/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 83us/step - loss: 0.1734 - accuracy: 0.9422 - val_loss: 0.1987 - val_accuracy: 0.9359\n",
      "Epoch 561/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1733 - accuracy: 0.9422 - val_loss: 0.1985 - val_accuracy: 0.9354\n",
      "Epoch 562/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1731 - accuracy: 0.9423 - val_loss: 0.1983 - val_accuracy: 0.9358\n",
      "Epoch 563/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1730 - accuracy: 0.9422 - val_loss: 0.1982 - val_accuracy: 0.9357\n",
      "Epoch 564/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1729 - accuracy: 0.9421 - val_loss: 0.1983 - val_accuracy: 0.9358\n",
      "Epoch 565/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1728 - accuracy: 0.9422 - val_loss: 0.1981 - val_accuracy: 0.9358\n",
      "Epoch 566/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1726 - accuracy: 0.9423 - val_loss: 0.1981 - val_accuracy: 0.9358\n",
      "Epoch 567/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1725 - accuracy: 0.9422 - val_loss: 0.1980 - val_accuracy: 0.9355\n",
      "Epoch 568/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1724 - accuracy: 0.9423 - val_loss: 0.1976 - val_accuracy: 0.9355\n",
      "Epoch 569/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1723 - accuracy: 0.9424 - val_loss: 0.1978 - val_accuracy: 0.9355\n",
      "Epoch 570/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1722 - accuracy: 0.9424 - val_loss: 0.1978 - val_accuracy: 0.9355\n",
      "Epoch 571/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1721 - accuracy: 0.9424 - val_loss: 0.1974 - val_accuracy: 0.9355\n",
      "Epoch 572/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1720 - accuracy: 0.9424 - val_loss: 0.1974 - val_accuracy: 0.9354\n",
      "Epoch 573/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1718 - accuracy: 0.9422 - val_loss: 0.1974 - val_accuracy: 0.9357\n",
      "Epoch 574/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1716 - accuracy: 0.9422 - val_loss: 0.1973 - val_accuracy: 0.9357\n",
      "Epoch 575/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1715 - accuracy: 0.9423 - val_loss: 0.1970 - val_accuracy: 0.9357\n",
      "Epoch 576/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1714 - accuracy: 0.9422 - val_loss: 0.1971 - val_accuracy: 0.9359\n",
      "Epoch 577/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1713 - accuracy: 0.9423 - val_loss: 0.1970 - val_accuracy: 0.9354\n",
      "Epoch 578/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1712 - accuracy: 0.9424 - val_loss: 0.1970 - val_accuracy: 0.9358\n",
      "Epoch 579/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1711 - accuracy: 0.9423 - val_loss: 0.1973 - val_accuracy: 0.9358\n",
      "Epoch 580/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1710 - accuracy: 0.9424 - val_loss: 0.1969 - val_accuracy: 0.9357\n",
      "Epoch 581/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1708 - accuracy: 0.9424 - val_loss: 0.1968 - val_accuracy: 0.9357\n",
      "Epoch 582/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1707 - accuracy: 0.9422 - val_loss: 0.1969 - val_accuracy: 0.9355\n",
      "Epoch 583/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1705 - accuracy: 0.9424 - val_loss: 0.1966 - val_accuracy: 0.9357\n",
      "Epoch 584/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1704 - accuracy: 0.9426 - val_loss: 0.1966 - val_accuracy: 0.9358\n",
      "Epoch 585/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1703 - accuracy: 0.9424 - val_loss: 0.1966 - val_accuracy: 0.9360\n",
      "Epoch 586/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1702 - accuracy: 0.9424 - val_loss: 0.1964 - val_accuracy: 0.9357\n",
      "Epoch 587/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1701 - accuracy: 0.9425 - val_loss: 0.1964 - val_accuracy: 0.9357\n",
      "Epoch 588/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1700 - accuracy: 0.9423 - val_loss: 0.1962 - val_accuracy: 0.9355\n",
      "Epoch 589/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1699 - accuracy: 0.9426 - val_loss: 0.1960 - val_accuracy: 0.9358\n",
      "Epoch 590/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1698 - accuracy: 0.9424 - val_loss: 0.1959 - val_accuracy: 0.9358\n",
      "Epoch 591/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1695 - accuracy: 0.9427 - val_loss: 0.1958 - val_accuracy: 0.9355\n",
      "Epoch 592/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1694 - accuracy: 0.9424 - val_loss: 0.1960 - val_accuracy: 0.9359\n",
      "Epoch 593/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1693 - accuracy: 0.9427 - val_loss: 0.1958 - val_accuracy: 0.9355\n",
      "Epoch 594/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1693 - accuracy: 0.9424 - val_loss: 0.1957 - val_accuracy: 0.9357\n",
      "Epoch 595/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1692 - accuracy: 0.9424 - val_loss: 0.1957 - val_accuracy: 0.9359\n",
      "Epoch 596/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1690 - accuracy: 0.9424 - val_loss: 0.1957 - val_accuracy: 0.9359\n",
      "Epoch 597/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1689 - accuracy: 0.9427 - val_loss: 0.1954 - val_accuracy: 0.9360\n",
      "Epoch 598/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1688 - accuracy: 0.9428 - val_loss: 0.1955 - val_accuracy: 0.9359\n",
      "Epoch 599/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1686 - accuracy: 0.9423 - val_loss: 0.1954 - val_accuracy: 0.9359\n",
      "Epoch 600/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1685 - accuracy: 0.9426 - val_loss: 0.1955 - val_accuracy: 0.9357\n",
      "Epoch 601/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1685 - accuracy: 0.9426 - val_loss: 0.1952 - val_accuracy: 0.9355\n",
      "Epoch 602/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1683 - accuracy: 0.9426 - val_loss: 0.1951 - val_accuracy: 0.9354\n",
      "Epoch 603/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1682 - accuracy: 0.9426 - val_loss: 0.1952 - val_accuracy: 0.9353\n",
      "Epoch 604/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1681 - accuracy: 0.9429 - val_loss: 0.1948 - val_accuracy: 0.9355\n",
      "Epoch 605/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1680 - accuracy: 0.9424 - val_loss: 0.1951 - val_accuracy: 0.9358\n",
      "Epoch 606/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1678 - accuracy: 0.9426 - val_loss: 0.1951 - val_accuracy: 0.9355\n",
      "Epoch 607/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1678 - accuracy: 0.9427 - val_loss: 0.1950 - val_accuracy: 0.9355\n",
      "Epoch 608/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1677 - accuracy: 0.9429 - val_loss: 0.1949 - val_accuracy: 0.9353\n",
      "Epoch 609/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1674 - accuracy: 0.9427 - val_loss: 0.1949 - val_accuracy: 0.9354\n",
      "Epoch 610/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1673 - accuracy: 0.9430 - val_loss: 0.1950 - val_accuracy: 0.9355\n",
      "Epoch 611/800\n",
      "480/480 [==============================] - 0s 121us/step - loss: 0.1673 - accuracy: 0.9426 - val_loss: 0.1946 - val_accuracy: 0.9354\n",
      "Epoch 612/800\n",
      "480/480 [==============================] - 0s 96us/step - loss: 0.1672 - accuracy: 0.9427 - val_loss: 0.1945 - val_accuracy: 0.9352\n",
      "Epoch 613/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1670 - accuracy: 0.9426 - val_loss: 0.1946 - val_accuracy: 0.9355\n",
      "Epoch 614/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1670 - accuracy: 0.9430 - val_loss: 0.1944 - val_accuracy: 0.9355\n",
      "Epoch 615/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1668 - accuracy: 0.9430 - val_loss: 0.1946 - val_accuracy: 0.9354\n",
      "Epoch 616/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.1667 - accuracy: 0.9429 - val_loss: 0.1943 - val_accuracy: 0.9355\n",
      "Epoch 617/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1666 - accuracy: 0.9431 - val_loss: 0.1942 - val_accuracy: 0.9355\n",
      "Epoch 618/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1665 - accuracy: 0.9431 - val_loss: 0.1943 - val_accuracy: 0.9355\n",
      "Epoch 619/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1665 - accuracy: 0.9432 - val_loss: 0.1943 - val_accuracy: 0.9352\n",
      "Epoch 620/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1663 - accuracy: 0.9430 - val_loss: 0.1942 - val_accuracy: 0.9352\n",
      "Epoch 621/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1662 - accuracy: 0.9430 - val_loss: 0.1939 - val_accuracy: 0.9353\n",
      "Epoch 622/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1661 - accuracy: 0.9429 - val_loss: 0.1940 - val_accuracy: 0.9354\n",
      "Epoch 623/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1660 - accuracy: 0.9433 - val_loss: 0.1939 - val_accuracy: 0.9354\n",
      "Epoch 624/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1658 - accuracy: 0.9433 - val_loss: 0.1939 - val_accuracy: 0.9353\n",
      "Epoch 625/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1657 - accuracy: 0.9431 - val_loss: 0.1937 - val_accuracy: 0.9357\n",
      "Epoch 626/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1657 - accuracy: 0.9432 - val_loss: 0.1938 - val_accuracy: 0.9357\n",
      "Epoch 627/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1655 - accuracy: 0.9433 - val_loss: 0.1936 - val_accuracy: 0.9354\n",
      "Epoch 628/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1655 - accuracy: 0.9431 - val_loss: 0.1936 - val_accuracy: 0.9352\n",
      "Epoch 629/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1653 - accuracy: 0.9434 - val_loss: 0.1937 - val_accuracy: 0.9353\n",
      "Epoch 630/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1652 - accuracy: 0.9435 - val_loss: 0.1934 - val_accuracy: 0.9354\n",
      "Epoch 631/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1652 - accuracy: 0.9433 - val_loss: 0.1935 - val_accuracy: 0.9353\n",
      "Epoch 632/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1651 - accuracy: 0.9435 - val_loss: 0.1934 - val_accuracy: 0.9355\n",
      "Epoch 633/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1649 - accuracy: 0.9432 - val_loss: 0.1932 - val_accuracy: 0.9354\n",
      "Epoch 634/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1649 - accuracy: 0.9434 - val_loss: 0.1934 - val_accuracy: 0.9353\n",
      "Epoch 635/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1647 - accuracy: 0.9434 - val_loss: 0.1933 - val_accuracy: 0.9357\n",
      "Epoch 636/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1646 - accuracy: 0.9433 - val_loss: 0.1933 - val_accuracy: 0.9352\n",
      "Epoch 637/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1646 - accuracy: 0.9432 - val_loss: 0.1931 - val_accuracy: 0.9353\n",
      "Epoch 638/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1644 - accuracy: 0.9433 - val_loss: 0.1931 - val_accuracy: 0.9353\n",
      "Epoch 639/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1643 - accuracy: 0.9434 - val_loss: 0.1930 - val_accuracy: 0.9354\n",
      "Epoch 640/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1642 - accuracy: 0.9436 - val_loss: 0.1931 - val_accuracy: 0.9357\n",
      "Epoch 641/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1642 - accuracy: 0.9437 - val_loss: 0.1931 - val_accuracy: 0.9353\n",
      "Epoch 642/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1641 - accuracy: 0.9435 - val_loss: 0.1928 - val_accuracy: 0.9354\n",
      "Epoch 643/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1640 - accuracy: 0.9437 - val_loss: 0.1926 - val_accuracy: 0.9358\n",
      "Epoch 644/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1638 - accuracy: 0.9437 - val_loss: 0.1928 - val_accuracy: 0.9354\n",
      "Epoch 645/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1637 - accuracy: 0.9438 - val_loss: 0.1927 - val_accuracy: 0.9354\n",
      "Epoch 646/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1637 - accuracy: 0.9435 - val_loss: 0.1927 - val_accuracy: 0.9353\n",
      "Epoch 647/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1636 - accuracy: 0.9436 - val_loss: 0.1927 - val_accuracy: 0.9357\n",
      "Epoch 648/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1635 - accuracy: 0.9438 - val_loss: 0.1925 - val_accuracy: 0.9358\n",
      "Epoch 649/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1633 - accuracy: 0.9438 - val_loss: 0.1923 - val_accuracy: 0.9358\n",
      "Epoch 650/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1632 - accuracy: 0.9435 - val_loss: 0.1924 - val_accuracy: 0.9357\n",
      "Epoch 651/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1632 - accuracy: 0.9437 - val_loss: 0.1922 - val_accuracy: 0.9355\n",
      "Epoch 652/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1630 - accuracy: 0.9437 - val_loss: 0.1923 - val_accuracy: 0.9355\n",
      "Epoch 653/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1629 - accuracy: 0.9438 - val_loss: 0.1925 - val_accuracy: 0.9358\n",
      "Epoch 654/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1628 - accuracy: 0.9438 - val_loss: 0.1922 - val_accuracy: 0.9359\n",
      "Epoch 655/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1628 - accuracy: 0.9437 - val_loss: 0.1923 - val_accuracy: 0.9355\n",
      "Epoch 656/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1627 - accuracy: 0.9440 - val_loss: 0.1921 - val_accuracy: 0.9354\n",
      "Epoch 657/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1626 - accuracy: 0.9440 - val_loss: 0.1922 - val_accuracy: 0.9354\n",
      "Epoch 658/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1624 - accuracy: 0.9438 - val_loss: 0.1922 - val_accuracy: 0.9362\n",
      "Epoch 659/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1624 - accuracy: 0.9439 - val_loss: 0.1921 - val_accuracy: 0.9357\n",
      "Epoch 660/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1624 - accuracy: 0.9441 - val_loss: 0.1920 - val_accuracy: 0.9357\n",
      "Epoch 661/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1623 - accuracy: 0.9438 - val_loss: 0.1919 - val_accuracy: 0.9358\n",
      "Epoch 662/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1622 - accuracy: 0.9443 - val_loss: 0.1919 - val_accuracy: 0.9357\n",
      "Epoch 663/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1620 - accuracy: 0.9438 - val_loss: 0.1918 - val_accuracy: 0.9354\n",
      "Epoch 664/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1620 - accuracy: 0.9440 - val_loss: 0.1918 - val_accuracy: 0.9355\n",
      "Epoch 665/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1619 - accuracy: 0.9439 - val_loss: 0.1917 - val_accuracy: 0.9353\n",
      "Epoch 666/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1618 - accuracy: 0.9437 - val_loss: 0.1916 - val_accuracy: 0.9353\n",
      "Epoch 667/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1618 - accuracy: 0.9438 - val_loss: 0.1915 - val_accuracy: 0.9358\n",
      "Epoch 668/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1616 - accuracy: 0.9443 - val_loss: 0.1913 - val_accuracy: 0.9354\n",
      "Epoch 669/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1615 - accuracy: 0.9442 - val_loss: 0.1915 - val_accuracy: 0.9355\n",
      "Epoch 670/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1615 - accuracy: 0.9442 - val_loss: 0.1914 - val_accuracy: 0.9355\n",
      "Epoch 671/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1613 - accuracy: 0.9442 - val_loss: 0.1912 - val_accuracy: 0.9355\n",
      "Epoch 672/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 79us/step - loss: 0.1613 - accuracy: 0.9440 - val_loss: 0.1910 - val_accuracy: 0.9360\n",
      "Epoch 673/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1611 - accuracy: 0.9442 - val_loss: 0.1913 - val_accuracy: 0.9355\n",
      "Epoch 674/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1611 - accuracy: 0.9442 - val_loss: 0.1913 - val_accuracy: 0.9359\n",
      "Epoch 675/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1610 - accuracy: 0.9442 - val_loss: 0.1913 - val_accuracy: 0.9358\n",
      "Epoch 676/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1608 - accuracy: 0.9442 - val_loss: 0.1912 - val_accuracy: 0.9358\n",
      "Epoch 677/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1608 - accuracy: 0.9442 - val_loss: 0.1913 - val_accuracy: 0.9357\n",
      "Epoch 678/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1607 - accuracy: 0.9443 - val_loss: 0.1912 - val_accuracy: 0.9360\n",
      "Epoch 679/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.1606 - accuracy: 0.9443 - val_loss: 0.1911 - val_accuracy: 0.9359\n",
      "Epoch 680/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1605 - accuracy: 0.9444 - val_loss: 0.1911 - val_accuracy: 0.9355\n",
      "Epoch 681/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1605 - accuracy: 0.9444 - val_loss: 0.1909 - val_accuracy: 0.9359\n",
      "Epoch 682/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1603 - accuracy: 0.9446 - val_loss: 0.1909 - val_accuracy: 0.9355\n",
      "Epoch 683/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1602 - accuracy: 0.9444 - val_loss: 0.1910 - val_accuracy: 0.9354\n",
      "Epoch 684/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1601 - accuracy: 0.9444 - val_loss: 0.1907 - val_accuracy: 0.9359\n",
      "Epoch 685/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1601 - accuracy: 0.9446 - val_loss: 0.1910 - val_accuracy: 0.9359\n",
      "Epoch 686/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1600 - accuracy: 0.9445 - val_loss: 0.1905 - val_accuracy: 0.9359\n",
      "Epoch 687/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1598 - accuracy: 0.9445 - val_loss: 0.1907 - val_accuracy: 0.9363\n",
      "Epoch 688/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1598 - accuracy: 0.9444 - val_loss: 0.1907 - val_accuracy: 0.9360\n",
      "Epoch 689/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1595 - accuracy: 0.9446 - val_loss: 0.1906 - val_accuracy: 0.9363\n",
      "Epoch 690/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1596 - accuracy: 0.9446 - val_loss: 0.1904 - val_accuracy: 0.9362\n",
      "Epoch 691/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1595 - accuracy: 0.9444 - val_loss: 0.1904 - val_accuracy: 0.9358\n",
      "Epoch 692/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1594 - accuracy: 0.9446 - val_loss: 0.1903 - val_accuracy: 0.9358\n",
      "Epoch 693/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1593 - accuracy: 0.9447 - val_loss: 0.1905 - val_accuracy: 0.9360\n",
      "Epoch 694/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1592 - accuracy: 0.9446 - val_loss: 0.1904 - val_accuracy: 0.9355\n",
      "Epoch 695/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1592 - accuracy: 0.9446 - val_loss: 0.1904 - val_accuracy: 0.9359\n",
      "Epoch 696/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1591 - accuracy: 0.9446 - val_loss: 0.1901 - val_accuracy: 0.9357\n",
      "Epoch 697/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1590 - accuracy: 0.9445 - val_loss: 0.1903 - val_accuracy: 0.9359\n",
      "Epoch 698/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1589 - accuracy: 0.9446 - val_loss: 0.1902 - val_accuracy: 0.9358\n",
      "Epoch 699/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1588 - accuracy: 0.9447 - val_loss: 0.1901 - val_accuracy: 0.9360\n",
      "Epoch 700/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1587 - accuracy: 0.9449 - val_loss: 0.1899 - val_accuracy: 0.9359\n",
      "Epoch 701/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1585 - accuracy: 0.9450 - val_loss: 0.1900 - val_accuracy: 0.9355\n",
      "Epoch 702/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1584 - accuracy: 0.9446 - val_loss: 0.1900 - val_accuracy: 0.9354\n",
      "Epoch 703/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1584 - accuracy: 0.9448 - val_loss: 0.1897 - val_accuracy: 0.9360\n",
      "Epoch 704/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1584 - accuracy: 0.9446 - val_loss: 0.1898 - val_accuracy: 0.9354\n",
      "Epoch 705/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1582 - accuracy: 0.9450 - val_loss: 0.1900 - val_accuracy: 0.9357\n",
      "Epoch 706/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1583 - accuracy: 0.9447 - val_loss: 0.1898 - val_accuracy: 0.9359\n",
      "Epoch 707/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1580 - accuracy: 0.9446 - val_loss: 0.1897 - val_accuracy: 0.9355\n",
      "Epoch 708/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.1579 - accuracy: 0.9449 - val_loss: 0.1898 - val_accuracy: 0.9362\n",
      "Epoch 709/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1579 - accuracy: 0.9450 - val_loss: 0.1896 - val_accuracy: 0.9359\n",
      "Epoch 710/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1578 - accuracy: 0.9449 - val_loss: 0.1895 - val_accuracy: 0.9362\n",
      "Epoch 711/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1577 - accuracy: 0.9452 - val_loss: 0.1895 - val_accuracy: 0.9362\n",
      "Epoch 712/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1576 - accuracy: 0.9451 - val_loss: 0.1895 - val_accuracy: 0.9360\n",
      "Epoch 713/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1575 - accuracy: 0.9450 - val_loss: 0.1893 - val_accuracy: 0.9360\n",
      "Epoch 714/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1574 - accuracy: 0.9449 - val_loss: 0.1893 - val_accuracy: 0.9359\n",
      "Epoch 715/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1573 - accuracy: 0.9448 - val_loss: 0.1894 - val_accuracy: 0.9360\n",
      "Epoch 716/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1573 - accuracy: 0.9449 - val_loss: 0.1892 - val_accuracy: 0.9360\n",
      "Epoch 717/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1571 - accuracy: 0.9453 - val_loss: 0.1891 - val_accuracy: 0.9363\n",
      "Epoch 718/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1571 - accuracy: 0.9453 - val_loss: 0.1892 - val_accuracy: 0.9364\n",
      "Epoch 719/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1569 - accuracy: 0.9451 - val_loss: 0.1892 - val_accuracy: 0.9363\n",
      "Epoch 720/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1569 - accuracy: 0.9451 - val_loss: 0.1891 - val_accuracy: 0.9362\n",
      "Epoch 721/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1567 - accuracy: 0.9451 - val_loss: 0.1889 - val_accuracy: 0.9355\n",
      "Epoch 722/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1567 - accuracy: 0.9451 - val_loss: 0.1891 - val_accuracy: 0.9360\n",
      "Epoch 723/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1566 - accuracy: 0.9452 - val_loss: 0.1890 - val_accuracy: 0.9360\n",
      "Epoch 724/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1564 - accuracy: 0.9451 - val_loss: 0.1888 - val_accuracy: 0.9359\n",
      "Epoch 725/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1565 - accuracy: 0.9452 - val_loss: 0.1886 - val_accuracy: 0.9362\n",
      "Epoch 726/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1563 - accuracy: 0.9453 - val_loss: 0.1885 - val_accuracy: 0.9362\n",
      "Epoch 727/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1562 - accuracy: 0.9453 - val_loss: 0.1886 - val_accuracy: 0.9362\n",
      "Epoch 728/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 83us/step - loss: 0.1562 - accuracy: 0.9449 - val_loss: 0.1887 - val_accuracy: 0.9362\n",
      "Epoch 729/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1560 - accuracy: 0.9451 - val_loss: 0.1886 - val_accuracy: 0.9364\n",
      "Epoch 730/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1559 - accuracy: 0.9454 - val_loss: 0.1885 - val_accuracy: 0.9365\n",
      "Epoch 731/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1558 - accuracy: 0.9450 - val_loss: 0.1884 - val_accuracy: 0.9363\n",
      "Epoch 732/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1557 - accuracy: 0.9452 - val_loss: 0.1885 - val_accuracy: 0.9363\n",
      "Epoch 733/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1557 - accuracy: 0.9455 - val_loss: 0.1883 - val_accuracy: 0.9363\n",
      "Epoch 734/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1555 - accuracy: 0.9455 - val_loss: 0.1883 - val_accuracy: 0.9364\n",
      "Epoch 735/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1554 - accuracy: 0.9455 - val_loss: 0.1882 - val_accuracy: 0.9362\n",
      "Epoch 736/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1555 - accuracy: 0.9455 - val_loss: 0.1882 - val_accuracy: 0.9363\n",
      "Epoch 737/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1553 - accuracy: 0.9454 - val_loss: 0.1883 - val_accuracy: 0.9360\n",
      "Epoch 738/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1552 - accuracy: 0.9455 - val_loss: 0.1881 - val_accuracy: 0.9366\n",
      "Epoch 739/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1551 - accuracy: 0.9458 - val_loss: 0.1881 - val_accuracy: 0.9366\n",
      "Epoch 740/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1550 - accuracy: 0.9453 - val_loss: 0.1881 - val_accuracy: 0.9366\n",
      "Epoch 741/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1549 - accuracy: 0.9453 - val_loss: 0.1878 - val_accuracy: 0.9363\n",
      "Epoch 742/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1547 - accuracy: 0.9456 - val_loss: 0.1879 - val_accuracy: 0.9362\n",
      "Epoch 743/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1547 - accuracy: 0.9458 - val_loss: 0.1875 - val_accuracy: 0.9359\n",
      "Epoch 744/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1545 - accuracy: 0.9457 - val_loss: 0.1878 - val_accuracy: 0.9369\n",
      "Epoch 745/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1546 - accuracy: 0.9455 - val_loss: 0.1878 - val_accuracy: 0.9362\n",
      "Epoch 746/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1544 - accuracy: 0.9459 - val_loss: 0.1876 - val_accuracy: 0.9365\n",
      "Epoch 747/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1543 - accuracy: 0.9455 - val_loss: 0.1876 - val_accuracy: 0.9364\n",
      "Epoch 748/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1542 - accuracy: 0.9458 - val_loss: 0.1876 - val_accuracy: 0.9366\n",
      "Epoch 749/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1542 - accuracy: 0.9458 - val_loss: 0.1876 - val_accuracy: 0.9365\n",
      "Epoch 750/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1540 - accuracy: 0.9459 - val_loss: 0.1877 - val_accuracy: 0.9368\n",
      "Epoch 751/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1539 - accuracy: 0.9457 - val_loss: 0.1872 - val_accuracy: 0.9362\n",
      "Epoch 752/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1539 - accuracy: 0.9456 - val_loss: 0.1873 - val_accuracy: 0.9365\n",
      "Epoch 753/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1537 - accuracy: 0.9460 - val_loss: 0.1873 - val_accuracy: 0.9365\n",
      "Epoch 754/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1535 - accuracy: 0.9459 - val_loss: 0.1873 - val_accuracy: 0.9364\n",
      "Epoch 755/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1535 - accuracy: 0.9458 - val_loss: 0.1870 - val_accuracy: 0.9365\n",
      "Epoch 756/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1534 - accuracy: 0.9457 - val_loss: 0.1871 - val_accuracy: 0.9368\n",
      "Epoch 757/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1533 - accuracy: 0.9460 - val_loss: 0.1870 - val_accuracy: 0.9364\n",
      "Epoch 758/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1532 - accuracy: 0.9459 - val_loss: 0.1869 - val_accuracy: 0.9364\n",
      "Epoch 759/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1532 - accuracy: 0.9461 - val_loss: 0.1871 - val_accuracy: 0.9366\n",
      "Epoch 760/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1530 - accuracy: 0.9462 - val_loss: 0.1869 - val_accuracy: 0.9366\n",
      "Epoch 761/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1529 - accuracy: 0.9458 - val_loss: 0.1865 - val_accuracy: 0.9366\n",
      "Epoch 762/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1528 - accuracy: 0.9460 - val_loss: 0.1866 - val_accuracy: 0.9363\n",
      "Epoch 763/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1528 - accuracy: 0.9458 - val_loss: 0.1865 - val_accuracy: 0.9366\n",
      "Epoch 764/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1527 - accuracy: 0.9458 - val_loss: 0.1867 - val_accuracy: 0.9364\n",
      "Epoch 765/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1525 - accuracy: 0.9460 - val_loss: 0.1865 - val_accuracy: 0.9366\n",
      "Epoch 766/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1524 - accuracy: 0.9463 - val_loss: 0.1866 - val_accuracy: 0.9369\n",
      "Epoch 767/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1523 - accuracy: 0.9462 - val_loss: 0.1862 - val_accuracy: 0.9365\n",
      "Epoch 768/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1522 - accuracy: 0.9461 - val_loss: 0.1862 - val_accuracy: 0.9363\n",
      "Epoch 769/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1521 - accuracy: 0.9466 - val_loss: 0.1864 - val_accuracy: 0.9373\n",
      "Epoch 770/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1520 - accuracy: 0.9464 - val_loss: 0.1863 - val_accuracy: 0.9370\n",
      "Epoch 771/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1519 - accuracy: 0.9464 - val_loss: 0.1864 - val_accuracy: 0.9360\n",
      "Epoch 772/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1517 - accuracy: 0.9467 - val_loss: 0.1862 - val_accuracy: 0.9365\n",
      "Epoch 773/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1517 - accuracy: 0.9464 - val_loss: 0.1861 - val_accuracy: 0.9360\n",
      "Epoch 774/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1517 - accuracy: 0.9462 - val_loss: 0.1858 - val_accuracy: 0.9365\n",
      "Epoch 775/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1515 - accuracy: 0.9462 - val_loss: 0.1859 - val_accuracy: 0.9368\n",
      "Epoch 776/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1513 - accuracy: 0.9464 - val_loss: 0.1860 - val_accuracy: 0.9374\n",
      "Epoch 777/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1513 - accuracy: 0.9464 - val_loss: 0.1860 - val_accuracy: 0.9373\n",
      "Epoch 778/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1512 - accuracy: 0.9464 - val_loss: 0.1859 - val_accuracy: 0.9365\n",
      "Epoch 779/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1510 - accuracy: 0.9465 - val_loss: 0.1856 - val_accuracy: 0.9364\n",
      "Epoch 780/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1510 - accuracy: 0.9466 - val_loss: 0.1858 - val_accuracy: 0.9369\n",
      "Epoch 781/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1509 - accuracy: 0.9467 - val_loss: 0.1855 - val_accuracy: 0.9365\n",
      "Epoch 782/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1508 - accuracy: 0.9467 - val_loss: 0.1857 - val_accuracy: 0.9369\n",
      "Epoch 783/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1507 - accuracy: 0.9465 - val_loss: 0.1855 - val_accuracy: 0.9370\n",
      "Epoch 784/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 83us/step - loss: 0.1507 - accuracy: 0.9470 - val_loss: 0.1855 - val_accuracy: 0.9374\n",
      "Epoch 785/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1505 - accuracy: 0.9464 - val_loss: 0.1855 - val_accuracy: 0.9370\n",
      "Epoch 786/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1503 - accuracy: 0.9466 - val_loss: 0.1851 - val_accuracy: 0.9370\n",
      "Epoch 787/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1504 - accuracy: 0.9468 - val_loss: 0.1852 - val_accuracy: 0.9370\n",
      "Epoch 788/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1502 - accuracy: 0.9466 - val_loss: 0.1855 - val_accuracy: 0.9369\n",
      "Epoch 789/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1501 - accuracy: 0.9469 - val_loss: 0.1854 - val_accuracy: 0.9366\n",
      "Epoch 790/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1500 - accuracy: 0.9469 - val_loss: 0.1853 - val_accuracy: 0.9371\n",
      "Epoch 791/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1498 - accuracy: 0.9467 - val_loss: 0.1850 - val_accuracy: 0.9369\n",
      "Epoch 792/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1498 - accuracy: 0.9465 - val_loss: 0.1852 - val_accuracy: 0.9369\n",
      "Epoch 793/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1496 - accuracy: 0.9467 - val_loss: 0.1849 - val_accuracy: 0.9370\n",
      "Epoch 794/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1495 - accuracy: 0.9471 - val_loss: 0.1849 - val_accuracy: 0.9370\n",
      "Epoch 795/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1495 - accuracy: 0.9465 - val_loss: 0.1850 - val_accuracy: 0.9373\n",
      "Epoch 796/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1493 - accuracy: 0.9472 - val_loss: 0.1851 - val_accuracy: 0.9365\n",
      "Epoch 797/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1492 - accuracy: 0.9470 - val_loss: 0.1848 - val_accuracy: 0.9365\n",
      "Epoch 798/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1492 - accuracy: 0.9472 - val_loss: 0.1847 - val_accuracy: 0.9365\n",
      "Epoch 799/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1490 - accuracy: 0.9469 - val_loss: 0.1844 - val_accuracy: 0.9373\n",
      "Epoch 800/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1489 - accuracy: 0.9471 - val_loss: 0.1849 - val_accuracy: 0.9370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:122: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/800\n",
      "480/480 [==============================] - 0s 331us/step - loss: 0.6900 - accuracy: 0.5989 - val_loss: 0.6841 - val_accuracy: 0.6494\n",
      "Epoch 2/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.6783 - accuracy: 0.6885 - val_loss: 0.6721 - val_accuracy: 0.7244\n",
      "Epoch 3/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.6650 - accuracy: 0.7637 - val_loss: 0.6576 - val_accuracy: 0.8042\n",
      "Epoch 4/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.6477 - accuracy: 0.8366 - val_loss: 0.6371 - val_accuracy: 0.8631\n",
      "Epoch 5/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.6212 - accuracy: 0.8866 - val_loss: 0.6034 - val_accuracy: 0.8996\n",
      "Epoch 6/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.5746 - accuracy: 0.9153 - val_loss: 0.5408 - val_accuracy: 0.9190\n",
      "Epoch 7/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.4880 - accuracy: 0.9259 - val_loss: 0.4287 - val_accuracy: 0.9357\n",
      "Epoch 8/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.3586 - accuracy: 0.9401 - val_loss: 0.3036 - val_accuracy: 0.9363\n",
      "Epoch 9/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2639 - accuracy: 0.9402 - val_loss: 0.2525 - val_accuracy: 0.9363\n",
      "Epoch 10/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2353 - accuracy: 0.9402 - val_loss: 0.2421 - val_accuracy: 0.9363\n",
      "Epoch 11/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2288 - accuracy: 0.9402 - val_loss: 0.2393 - val_accuracy: 0.9363\n",
      "Epoch 12/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2263 - accuracy: 0.9402 - val_loss: 0.2380 - val_accuracy: 0.9363\n",
      "Epoch 13/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2248 - accuracy: 0.9402 - val_loss: 0.2372 - val_accuracy: 0.9363\n",
      "Epoch 14/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2238 - accuracy: 0.9402 - val_loss: 0.2367 - val_accuracy: 0.9363\n",
      "Epoch 15/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2232 - accuracy: 0.9402 - val_loss: 0.2364 - val_accuracy: 0.9363\n",
      "Epoch 16/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2227 - accuracy: 0.9402 - val_loss: 0.2363 - val_accuracy: 0.9363\n",
      "Epoch 17/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2224 - accuracy: 0.9402 - val_loss: 0.2361 - val_accuracy: 0.9363\n",
      "Epoch 18/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2222 - accuracy: 0.9402 - val_loss: 0.2361 - val_accuracy: 0.9363\n",
      "Epoch 19/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2220 - accuracy: 0.9402 - val_loss: 0.2360 - val_accuracy: 0.9363\n",
      "Epoch 20/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2219 - accuracy: 0.9402 - val_loss: 0.2360 - val_accuracy: 0.9363\n",
      "Epoch 21/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2218 - accuracy: 0.9402 - val_loss: 0.2359 - val_accuracy: 0.9363\n",
      "Epoch 22/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2217 - accuracy: 0.9402 - val_loss: 0.2359 - val_accuracy: 0.9363\n",
      "Epoch 23/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2217 - accuracy: 0.9402 - val_loss: 0.2358 - val_accuracy: 0.9363\n",
      "Epoch 24/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2217 - accuracy: 0.9402 - val_loss: 0.2358 - val_accuracy: 0.9363\n",
      "Epoch 25/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2216 - accuracy: 0.9402 - val_loss: 0.2358 - val_accuracy: 0.9363\n",
      "Epoch 26/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2216 - accuracy: 0.9402 - val_loss: 0.2358 - val_accuracy: 0.9363\n",
      "Epoch 27/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2215 - accuracy: 0.9402 - val_loss: 0.2358 - val_accuracy: 0.9363\n",
      "Epoch 28/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2215 - accuracy: 0.9402 - val_loss: 0.2357 - val_accuracy: 0.9363\n",
      "Epoch 29/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2214 - accuracy: 0.9402 - val_loss: 0.2357 - val_accuracy: 0.9363\n",
      "Epoch 30/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2214 - accuracy: 0.9402 - val_loss: 0.2356 - val_accuracy: 0.9363\n",
      "Epoch 31/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2214 - accuracy: 0.9402 - val_loss: 0.2356 - val_accuracy: 0.9363\n",
      "Epoch 32/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2214 - accuracy: 0.9402 - val_loss: 0.2355 - val_accuracy: 0.9363\n",
      "Epoch 33/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2214 - accuracy: 0.9402 - val_loss: 0.2355 - val_accuracy: 0.9363\n",
      "Epoch 34/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2213 - accuracy: 0.9402 - val_loss: 0.2355 - val_accuracy: 0.9363\n",
      "Epoch 35/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2212 - accuracy: 0.9402 - val_loss: 0.2355 - val_accuracy: 0.9363\n",
      "Epoch 36/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2212 - accuracy: 0.9402 - val_loss: 0.2355 - val_accuracy: 0.9363\n",
      "Epoch 37/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2212 - accuracy: 0.9402 - val_loss: 0.2354 - val_accuracy: 0.9363\n",
      "Epoch 38/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2212 - accuracy: 0.9402 - val_loss: 0.2354 - val_accuracy: 0.9363\n",
      "Epoch 39/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2211 - accuracy: 0.9402 - val_loss: 0.2353 - val_accuracy: 0.9363\n",
      "Epoch 40/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2211 - accuracy: 0.9402 - val_loss: 0.2353 - val_accuracy: 0.9363\n",
      "Epoch 41/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2211 - accuracy: 0.9402 - val_loss: 0.2353 - val_accuracy: 0.9363\n",
      "Epoch 42/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2211 - accuracy: 0.9402 - val_loss: 0.2353 - val_accuracy: 0.9363\n",
      "Epoch 43/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2211 - accuracy: 0.9402 - val_loss: 0.2352 - val_accuracy: 0.9363\n",
      "Epoch 44/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2210 - accuracy: 0.9402 - val_loss: 0.2352 - val_accuracy: 0.9363\n",
      "Epoch 45/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2210 - accuracy: 0.9402 - val_loss: 0.2352 - val_accuracy: 0.9363\n",
      "Epoch 46/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2210 - accuracy: 0.9402 - val_loss: 0.2352 - val_accuracy: 0.9363\n",
      "Epoch 47/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2210 - accuracy: 0.9402 - val_loss: 0.2352 - val_accuracy: 0.9363\n",
      "Epoch 48/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2209 - accuracy: 0.9402 - val_loss: 0.2351 - val_accuracy: 0.9363\n",
      "Epoch 49/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2209 - accuracy: 0.9402 - val_loss: 0.2351 - val_accuracy: 0.9363\n",
      "Epoch 50/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2209 - accuracy: 0.9402 - val_loss: 0.2351 - val_accuracy: 0.9363\n",
      "Epoch 51/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2209 - accuracy: 0.9402 - val_loss: 0.2350 - val_accuracy: 0.9363\n",
      "Epoch 52/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2208 - accuracy: 0.9402 - val_loss: 0.2350 - val_accuracy: 0.9363\n",
      "Epoch 53/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2208 - accuracy: 0.9402 - val_loss: 0.2350 - val_accuracy: 0.9363\n",
      "Epoch 54/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2208 - accuracy: 0.9402 - val_loss: 0.2350 - val_accuracy: 0.9363\n",
      "Epoch 55/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2207 - accuracy: 0.9402 - val_loss: 0.2349 - val_accuracy: 0.9363\n",
      "Epoch 56/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.2207 - accuracy: 0.9402 - val_loss: 0.2349 - val_accuracy: 0.9363\n",
      "Epoch 57/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2207 - accuracy: 0.9402 - val_loss: 0.2349 - val_accuracy: 0.9363\n",
      "Epoch 58/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2207 - accuracy: 0.9402 - val_loss: 0.2349 - val_accuracy: 0.9363\n",
      "Epoch 59/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2206 - accuracy: 0.9402 - val_loss: 0.2348 - val_accuracy: 0.9363\n",
      "Epoch 60/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2206 - accuracy: 0.9402 - val_loss: 0.2348 - val_accuracy: 0.9363\n",
      "Epoch 61/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2206 - accuracy: 0.9402 - val_loss: 0.2348 - val_accuracy: 0.9363\n",
      "Epoch 62/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2206 - accuracy: 0.9402 - val_loss: 0.2348 - val_accuracy: 0.9363\n",
      "Epoch 63/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2206 - accuracy: 0.9402 - val_loss: 0.2347 - val_accuracy: 0.9363\n",
      "Epoch 64/800\n",
      "480/480 [==============================] - 0s 98us/step - loss: 0.2205 - accuracy: 0.9402 - val_loss: 0.2347 - val_accuracy: 0.9363\n",
      "Epoch 65/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2205 - accuracy: 0.9402 - val_loss: 0.2347 - val_accuracy: 0.9363\n",
      "Epoch 66/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2205 - accuracy: 0.9402 - val_loss: 0.2347 - val_accuracy: 0.9363\n",
      "Epoch 67/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2205 - accuracy: 0.9402 - val_loss: 0.2347 - val_accuracy: 0.9363\n",
      "Epoch 68/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2204 - accuracy: 0.9402 - val_loss: 0.2347 - val_accuracy: 0.9363\n",
      "Epoch 69/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2204 - accuracy: 0.9402 - val_loss: 0.2347 - val_accuracy: 0.9363\n",
      "Epoch 70/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2204 - accuracy: 0.9402 - val_loss: 0.2346 - val_accuracy: 0.9363\n",
      "Epoch 71/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2204 - accuracy: 0.9402 - val_loss: 0.2346 - val_accuracy: 0.9363\n",
      "Epoch 72/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2204 - accuracy: 0.9402 - val_loss: 0.2346 - val_accuracy: 0.9363\n",
      "Epoch 73/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2204 - accuracy: 0.9402 - val_loss: 0.2345 - val_accuracy: 0.9363\n",
      "Epoch 74/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2203 - accuracy: 0.9402 - val_loss: 0.2345 - val_accuracy: 0.9363\n",
      "Epoch 75/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2203 - accuracy: 0.9402 - val_loss: 0.2345 - val_accuracy: 0.9363\n",
      "Epoch 76/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2203 - accuracy: 0.9402 - val_loss: 0.2345 - val_accuracy: 0.9363\n",
      "Epoch 77/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2202 - accuracy: 0.9402 - val_loss: 0.2345 - val_accuracy: 0.9363\n",
      "Epoch 78/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2202 - accuracy: 0.9402 - val_loss: 0.2344 - val_accuracy: 0.9363\n",
      "Epoch 79/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2202 - accuracy: 0.9402 - val_loss: 0.2344 - val_accuracy: 0.9363\n",
      "Epoch 80/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2202 - accuracy: 0.9402 - val_loss: 0.2344 - val_accuracy: 0.9363\n",
      "Epoch 81/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2202 - accuracy: 0.9402 - val_loss: 0.2343 - val_accuracy: 0.9363\n",
      "Epoch 82/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2201 - accuracy: 0.9402 - val_loss: 0.2343 - val_accuracy: 0.9363\n",
      "Epoch 83/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2201 - accuracy: 0.9402 - val_loss: 0.2343 - val_accuracy: 0.9363\n",
      "Epoch 84/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2201 - accuracy: 0.9402 - val_loss: 0.2343 - val_accuracy: 0.9363\n",
      "Epoch 85/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2201 - accuracy: 0.9402 - val_loss: 0.2343 - val_accuracy: 0.9363\n",
      "Epoch 86/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2201 - accuracy: 0.9402 - val_loss: 0.2343 - val_accuracy: 0.9363\n",
      "Epoch 87/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2201 - accuracy: 0.9402 - val_loss: 0.2342 - val_accuracy: 0.9363\n",
      "Epoch 88/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2200 - accuracy: 0.9402 - val_loss: 0.2342 - val_accuracy: 0.9363\n",
      "Epoch 89/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2200 - accuracy: 0.9402 - val_loss: 0.2342 - val_accuracy: 0.9363\n",
      "Epoch 90/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2200 - accuracy: 0.9402 - val_loss: 0.2342 - val_accuracy: 0.9363\n",
      "Epoch 91/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2199 - accuracy: 0.9402 - val_loss: 0.2341 - val_accuracy: 0.9363\n",
      "Epoch 92/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2199 - accuracy: 0.9402 - val_loss: 0.2341 - val_accuracy: 0.9363\n",
      "Epoch 93/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2199 - accuracy: 0.9402 - val_loss: 0.2341 - val_accuracy: 0.9363\n",
      "Epoch 94/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2199 - accuracy: 0.9402 - val_loss: 0.2341 - val_accuracy: 0.9363\n",
      "Epoch 95/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2199 - accuracy: 0.9402 - val_loss: 0.2341 - val_accuracy: 0.9363\n",
      "Epoch 96/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2198 - accuracy: 0.9402 - val_loss: 0.2341 - val_accuracy: 0.9363\n",
      "Epoch 97/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2198 - accuracy: 0.9402 - val_loss: 0.2341 - val_accuracy: 0.9363\n",
      "Epoch 98/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2198 - accuracy: 0.9402 - val_loss: 0.2340 - val_accuracy: 0.9363\n",
      "Epoch 99/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2198 - accuracy: 0.9402 - val_loss: 0.2340 - val_accuracy: 0.9363\n",
      "Epoch 100/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2197 - accuracy: 0.9402 - val_loss: 0.2340 - val_accuracy: 0.9363\n",
      "Epoch 101/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2197 - accuracy: 0.9402 - val_loss: 0.2339 - val_accuracy: 0.9363\n",
      "Epoch 102/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2197 - accuracy: 0.9402 - val_loss: 0.2339 - val_accuracy: 0.9363\n",
      "Epoch 103/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2197 - accuracy: 0.9402 - val_loss: 0.2339 - val_accuracy: 0.9363\n",
      "Epoch 104/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2197 - accuracy: 0.9402 - val_loss: 0.2339 - val_accuracy: 0.9363\n",
      "Epoch 105/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2196 - accuracy: 0.9402 - val_loss: 0.2339 - val_accuracy: 0.9363\n",
      "Epoch 106/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2196 - accuracy: 0.9402 - val_loss: 0.2338 - val_accuracy: 0.9363\n",
      "Epoch 107/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2196 - accuracy: 0.9402 - val_loss: 0.2338 - val_accuracy: 0.9363\n",
      "Epoch 108/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2196 - accuracy: 0.9402 - val_loss: 0.2338 - val_accuracy: 0.9363\n",
      "Epoch 109/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2195 - accuracy: 0.9402 - val_loss: 0.2338 - val_accuracy: 0.9363\n",
      "Epoch 110/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2195 - accuracy: 0.9402 - val_loss: 0.2337 - val_accuracy: 0.9363\n",
      "Epoch 111/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2195 - accuracy: 0.9402 - val_loss: 0.2337 - val_accuracy: 0.9363\n",
      "Epoch 112/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 84us/step - loss: 0.2195 - accuracy: 0.9402 - val_loss: 0.2337 - val_accuracy: 0.9363\n",
      "Epoch 113/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2194 - accuracy: 0.9402 - val_loss: 0.2337 - val_accuracy: 0.9363\n",
      "Epoch 114/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2194 - accuracy: 0.9402 - val_loss: 0.2337 - val_accuracy: 0.9363\n",
      "Epoch 115/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2194 - accuracy: 0.9402 - val_loss: 0.2336 - val_accuracy: 0.9363\n",
      "Epoch 116/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2194 - accuracy: 0.9402 - val_loss: 0.2336 - val_accuracy: 0.9363\n",
      "Epoch 117/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2193 - accuracy: 0.9402 - val_loss: 0.2336 - val_accuracy: 0.9363\n",
      "Epoch 118/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2193 - accuracy: 0.9402 - val_loss: 0.2336 - val_accuracy: 0.9363\n",
      "Epoch 119/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2193 - accuracy: 0.9402 - val_loss: 0.2336 - val_accuracy: 0.9363\n",
      "Epoch 120/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2193 - accuracy: 0.9402 - val_loss: 0.2335 - val_accuracy: 0.9363\n",
      "Epoch 121/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2193 - accuracy: 0.9402 - val_loss: 0.2335 - val_accuracy: 0.9363\n",
      "Epoch 122/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2192 - accuracy: 0.9402 - val_loss: 0.2335 - val_accuracy: 0.9363\n",
      "Epoch 123/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2192 - accuracy: 0.9402 - val_loss: 0.2335 - val_accuracy: 0.9363\n",
      "Epoch 124/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2192 - accuracy: 0.9402 - val_loss: 0.2334 - val_accuracy: 0.9363\n",
      "Epoch 125/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2191 - accuracy: 0.9402 - val_loss: 0.2334 - val_accuracy: 0.9363\n",
      "Epoch 126/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2192 - accuracy: 0.9402 - val_loss: 0.2333 - val_accuracy: 0.9363\n",
      "Epoch 127/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2191 - accuracy: 0.9402 - val_loss: 0.2333 - val_accuracy: 0.9363\n",
      "Epoch 128/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2191 - accuracy: 0.9402 - val_loss: 0.2333 - val_accuracy: 0.9363\n",
      "Epoch 129/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2191 - accuracy: 0.9402 - val_loss: 0.2333 - val_accuracy: 0.9363\n",
      "Epoch 130/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2191 - accuracy: 0.9402 - val_loss: 0.2333 - val_accuracy: 0.9363\n",
      "Epoch 131/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2190 - accuracy: 0.9402 - val_loss: 0.2332 - val_accuracy: 0.9363\n",
      "Epoch 132/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2190 - accuracy: 0.9402 - val_loss: 0.2332 - val_accuracy: 0.9363\n",
      "Epoch 133/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2190 - accuracy: 0.9402 - val_loss: 0.2332 - val_accuracy: 0.9363\n",
      "Epoch 134/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2190 - accuracy: 0.9402 - val_loss: 0.2332 - val_accuracy: 0.9363\n",
      "Epoch 135/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2189 - accuracy: 0.9402 - val_loss: 0.2332 - val_accuracy: 0.9363\n",
      "Epoch 136/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2189 - accuracy: 0.9402 - val_loss: 0.2332 - val_accuracy: 0.9363\n",
      "Epoch 137/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2189 - accuracy: 0.9402 - val_loss: 0.2331 - val_accuracy: 0.9363\n",
      "Epoch 138/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2188 - accuracy: 0.9402 - val_loss: 0.2331 - val_accuracy: 0.9363\n",
      "Epoch 139/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2188 - accuracy: 0.9402 - val_loss: 0.2330 - val_accuracy: 0.9363\n",
      "Epoch 140/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2188 - accuracy: 0.9402 - val_loss: 0.2330 - val_accuracy: 0.9363\n",
      "Epoch 141/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2188 - accuracy: 0.9402 - val_loss: 0.2330 - val_accuracy: 0.9363\n",
      "Epoch 142/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2187 - accuracy: 0.9402 - val_loss: 0.2330 - val_accuracy: 0.9363\n",
      "Epoch 143/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2187 - accuracy: 0.9402 - val_loss: 0.2330 - val_accuracy: 0.9363\n",
      "Epoch 144/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2187 - accuracy: 0.9402 - val_loss: 0.2329 - val_accuracy: 0.9363\n",
      "Epoch 145/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2187 - accuracy: 0.9402 - val_loss: 0.2329 - val_accuracy: 0.9363\n",
      "Epoch 146/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2186 - accuracy: 0.9402 - val_loss: 0.2329 - val_accuracy: 0.9363\n",
      "Epoch 147/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2186 - accuracy: 0.9402 - val_loss: 0.2329 - val_accuracy: 0.9363\n",
      "Epoch 148/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2186 - accuracy: 0.9402 - val_loss: 0.2328 - val_accuracy: 0.9363\n",
      "Epoch 149/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2185 - accuracy: 0.9402 - val_loss: 0.2328 - val_accuracy: 0.9363\n",
      "Epoch 150/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2185 - accuracy: 0.9402 - val_loss: 0.2328 - val_accuracy: 0.9363\n",
      "Epoch 151/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2185 - accuracy: 0.9402 - val_loss: 0.2327 - val_accuracy: 0.9363\n",
      "Epoch 152/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2185 - accuracy: 0.9402 - val_loss: 0.2327 - val_accuracy: 0.9363\n",
      "Epoch 153/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.2184 - accuracy: 0.9402 - val_loss: 0.2327 - val_accuracy: 0.9363\n",
      "Epoch 154/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2184 - accuracy: 0.9402 - val_loss: 0.2327 - val_accuracy: 0.9363\n",
      "Epoch 155/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2184 - accuracy: 0.9402 - val_loss: 0.2327 - val_accuracy: 0.9363\n",
      "Epoch 156/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2183 - accuracy: 0.9402 - val_loss: 0.2326 - val_accuracy: 0.9363\n",
      "Epoch 157/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2183 - accuracy: 0.9402 - val_loss: 0.2326 - val_accuracy: 0.9363\n",
      "Epoch 158/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2183 - accuracy: 0.9402 - val_loss: 0.2326 - val_accuracy: 0.9363\n",
      "Epoch 159/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2183 - accuracy: 0.9402 - val_loss: 0.2325 - val_accuracy: 0.9363\n",
      "Epoch 160/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2183 - accuracy: 0.9402 - val_loss: 0.2325 - val_accuracy: 0.9363\n",
      "Epoch 161/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2182 - accuracy: 0.9402 - val_loss: 0.2324 - val_accuracy: 0.9363\n",
      "Epoch 162/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.2182 - accuracy: 0.9402 - val_loss: 0.2324 - val_accuracy: 0.9363\n",
      "Epoch 163/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2181 - accuracy: 0.9402 - val_loss: 0.2324 - val_accuracy: 0.9363\n",
      "Epoch 164/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2181 - accuracy: 0.9402 - val_loss: 0.2324 - val_accuracy: 0.9363\n",
      "Epoch 165/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2181 - accuracy: 0.9402 - val_loss: 0.2324 - val_accuracy: 0.9363\n",
      "Epoch 166/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2181 - accuracy: 0.9402 - val_loss: 0.2323 - val_accuracy: 0.9363\n",
      "Epoch 167/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2180 - accuracy: 0.9402 - val_loss: 0.2323 - val_accuracy: 0.9363\n",
      "Epoch 168/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.2180 - accuracy: 0.9402 - val_loss: 0.2323 - val_accuracy: 0.9363\n",
      "Epoch 169/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2180 - accuracy: 0.9402 - val_loss: 0.2323 - val_accuracy: 0.9363\n",
      "Epoch 170/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2179 - accuracy: 0.9402 - val_loss: 0.2322 - val_accuracy: 0.9363\n",
      "Epoch 171/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2179 - accuracy: 0.9402 - val_loss: 0.2322 - val_accuracy: 0.9363\n",
      "Epoch 172/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2179 - accuracy: 0.9402 - val_loss: 0.2322 - val_accuracy: 0.9363\n",
      "Epoch 173/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2178 - accuracy: 0.9402 - val_loss: 0.2321 - val_accuracy: 0.9363\n",
      "Epoch 174/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2178 - accuracy: 0.9402 - val_loss: 0.2321 - val_accuracy: 0.9363\n",
      "Epoch 175/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2178 - accuracy: 0.9402 - val_loss: 0.2321 - val_accuracy: 0.9363\n",
      "Epoch 176/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2178 - accuracy: 0.9402 - val_loss: 0.2321 - val_accuracy: 0.9363\n",
      "Epoch 177/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2177 - accuracy: 0.9402 - val_loss: 0.2321 - val_accuracy: 0.9363\n",
      "Epoch 178/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2177 - accuracy: 0.9402 - val_loss: 0.2320 - val_accuracy: 0.9363\n",
      "Epoch 179/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2177 - accuracy: 0.9402 - val_loss: 0.2320 - val_accuracy: 0.9363\n",
      "Epoch 180/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2176 - accuracy: 0.9402 - val_loss: 0.2319 - val_accuracy: 0.9363\n",
      "Epoch 181/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2176 - accuracy: 0.9402 - val_loss: 0.2319 - val_accuracy: 0.9363\n",
      "Epoch 182/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2176 - accuracy: 0.9402 - val_loss: 0.2319 - val_accuracy: 0.9363\n",
      "Epoch 183/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2175 - accuracy: 0.9402 - val_loss: 0.2319 - val_accuracy: 0.9363\n",
      "Epoch 184/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2175 - accuracy: 0.9402 - val_loss: 0.2319 - val_accuracy: 0.9363\n",
      "Epoch 185/800\n",
      "480/480 [==============================] - 0s 77us/step - loss: 0.2175 - accuracy: 0.9402 - val_loss: 0.2318 - val_accuracy: 0.9363\n",
      "Epoch 186/800\n",
      "480/480 [==============================] - 0s 77us/step - loss: 0.2174 - accuracy: 0.9402 - val_loss: 0.2318 - val_accuracy: 0.9363\n",
      "Epoch 187/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2174 - accuracy: 0.9402 - val_loss: 0.2317 - val_accuracy: 0.9363\n",
      "Epoch 188/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2174 - accuracy: 0.9402 - val_loss: 0.2317 - val_accuracy: 0.9363\n",
      "Epoch 189/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2174 - accuracy: 0.9402 - val_loss: 0.2317 - val_accuracy: 0.9363\n",
      "Epoch 190/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2173 - accuracy: 0.9402 - val_loss: 0.2316 - val_accuracy: 0.9363\n",
      "Epoch 191/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2173 - accuracy: 0.9402 - val_loss: 0.2316 - val_accuracy: 0.9363\n",
      "Epoch 192/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2172 - accuracy: 0.9402 - val_loss: 0.2316 - val_accuracy: 0.9363\n",
      "Epoch 193/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2172 - accuracy: 0.9402 - val_loss: 0.2315 - val_accuracy: 0.9363\n",
      "Epoch 194/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2172 - accuracy: 0.9402 - val_loss: 0.2315 - val_accuracy: 0.9363\n",
      "Epoch 195/800\n",
      "480/480 [==============================] - 0s 106us/step - loss: 0.2171 - accuracy: 0.9402 - val_loss: 0.2315 - val_accuracy: 0.9363\n",
      "Epoch 196/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2171 - accuracy: 0.9402 - val_loss: 0.2314 - val_accuracy: 0.9363\n",
      "Epoch 197/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2171 - accuracy: 0.9402 - val_loss: 0.2314 - val_accuracy: 0.9363\n",
      "Epoch 198/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2171 - accuracy: 0.9402 - val_loss: 0.2314 - val_accuracy: 0.9363\n",
      "Epoch 199/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2170 - accuracy: 0.9402 - val_loss: 0.2314 - val_accuracy: 0.9363\n",
      "Epoch 200/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2169 - accuracy: 0.9402 - val_loss: 0.2313 - val_accuracy: 0.9363\n",
      "Epoch 201/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2169 - accuracy: 0.9402 - val_loss: 0.2313 - val_accuracy: 0.9363\n",
      "Epoch 202/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2169 - accuracy: 0.9402 - val_loss: 0.2312 - val_accuracy: 0.9363\n",
      "Epoch 203/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2168 - accuracy: 0.9402 - val_loss: 0.2312 - val_accuracy: 0.9363\n",
      "Epoch 204/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2168 - accuracy: 0.9402 - val_loss: 0.2312 - val_accuracy: 0.9363\n",
      "Epoch 205/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2168 - accuracy: 0.9402 - val_loss: 0.2311 - val_accuracy: 0.9363\n",
      "Epoch 206/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2167 - accuracy: 0.9402 - val_loss: 0.2311 - val_accuracy: 0.9363\n",
      "Epoch 207/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2167 - accuracy: 0.9402 - val_loss: 0.2311 - val_accuracy: 0.9363\n",
      "Epoch 208/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2166 - accuracy: 0.9402 - val_loss: 0.2310 - val_accuracy: 0.9363\n",
      "Epoch 209/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2166 - accuracy: 0.9402 - val_loss: 0.2310 - val_accuracy: 0.9363\n",
      "Epoch 210/800\n",
      "480/480 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.94 - 0s 83us/step - loss: 0.2166 - accuracy: 0.9402 - val_loss: 0.2309 - val_accuracy: 0.9363\n",
      "Epoch 211/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2165 - accuracy: 0.9402 - val_loss: 0.2309 - val_accuracy: 0.9363\n",
      "Epoch 212/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2165 - accuracy: 0.9402 - val_loss: 0.2308 - val_accuracy: 0.9363\n",
      "Epoch 213/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2164 - accuracy: 0.9402 - val_loss: 0.2308 - val_accuracy: 0.9363\n",
      "Epoch 214/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2164 - accuracy: 0.9402 - val_loss: 0.2307 - val_accuracy: 0.9363\n",
      "Epoch 215/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2163 - accuracy: 0.9402 - val_loss: 0.2307 - val_accuracy: 0.9363\n",
      "Epoch 216/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2163 - accuracy: 0.9402 - val_loss: 0.2307 - val_accuracy: 0.9363\n",
      "Epoch 217/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2163 - accuracy: 0.9402 - val_loss: 0.2306 - val_accuracy: 0.9363\n",
      "Epoch 218/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2162 - accuracy: 0.9402 - val_loss: 0.2306 - val_accuracy: 0.9363\n",
      "Epoch 219/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.2162 - accuracy: 0.9402 - val_loss: 0.2306 - val_accuracy: 0.9363\n",
      "Epoch 220/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2161 - accuracy: 0.9402 - val_loss: 0.2306 - val_accuracy: 0.9363\n",
      "Epoch 221/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2161 - accuracy: 0.9402 - val_loss: 0.2305 - val_accuracy: 0.9363\n",
      "Epoch 222/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2160 - accuracy: 0.9402 - val_loss: 0.2305 - val_accuracy: 0.9363\n",
      "Epoch 223/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2160 - accuracy: 0.9402 - val_loss: 0.2304 - val_accuracy: 0.9363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2160 - accuracy: 0.9402 - val_loss: 0.2304 - val_accuracy: 0.9363\n",
      "Epoch 225/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2159 - accuracy: 0.9402 - val_loss: 0.2303 - val_accuracy: 0.9363\n",
      "Epoch 226/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2159 - accuracy: 0.9402 - val_loss: 0.2302 - val_accuracy: 0.9363\n",
      "Epoch 227/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2158 - accuracy: 0.9402 - val_loss: 0.2302 - val_accuracy: 0.9363\n",
      "Epoch 228/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2157 - accuracy: 0.9402 - val_loss: 0.2302 - val_accuracy: 0.9363\n",
      "Epoch 229/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2157 - accuracy: 0.9402 - val_loss: 0.2301 - val_accuracy: 0.9363\n",
      "Epoch 230/800\n",
      "480/480 [==============================] - 0s 91us/step - loss: 0.2156 - accuracy: 0.9402 - val_loss: 0.2301 - val_accuracy: 0.9363\n",
      "Epoch 231/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2156 - accuracy: 0.9402 - val_loss: 0.2300 - val_accuracy: 0.9363\n",
      "Epoch 232/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2156 - accuracy: 0.9402 - val_loss: 0.2300 - val_accuracy: 0.9363\n",
      "Epoch 233/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2155 - accuracy: 0.9402 - val_loss: 0.2299 - val_accuracy: 0.9363\n",
      "Epoch 234/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2155 - accuracy: 0.9402 - val_loss: 0.2299 - val_accuracy: 0.9363\n",
      "Epoch 235/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2154 - accuracy: 0.9402 - val_loss: 0.2299 - val_accuracy: 0.9363\n",
      "Epoch 236/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2154 - accuracy: 0.9402 - val_loss: 0.2298 - val_accuracy: 0.9363\n",
      "Epoch 237/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2153 - accuracy: 0.9402 - val_loss: 0.2298 - val_accuracy: 0.9363\n",
      "Epoch 238/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2152 - accuracy: 0.9402 - val_loss: 0.2297 - val_accuracy: 0.9363\n",
      "Epoch 239/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2152 - accuracy: 0.9402 - val_loss: 0.2297 - val_accuracy: 0.9363\n",
      "Epoch 240/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2152 - accuracy: 0.9402 - val_loss: 0.2296 - val_accuracy: 0.9363\n",
      "Epoch 241/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2151 - accuracy: 0.9402 - val_loss: 0.2296 - val_accuracy: 0.9363\n",
      "Epoch 242/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2151 - accuracy: 0.9402 - val_loss: 0.2296 - val_accuracy: 0.9363\n",
      "Epoch 243/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2150 - accuracy: 0.9402 - val_loss: 0.2295 - val_accuracy: 0.9363\n",
      "Epoch 244/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2150 - accuracy: 0.9402 - val_loss: 0.2295 - val_accuracy: 0.9363\n",
      "Epoch 245/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2149 - accuracy: 0.9402 - val_loss: 0.2295 - val_accuracy: 0.9363\n",
      "Epoch 246/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2149 - accuracy: 0.9402 - val_loss: 0.2294 - val_accuracy: 0.9363\n",
      "Epoch 247/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2148 - accuracy: 0.9402 - val_loss: 0.2293 - val_accuracy: 0.9363\n",
      "Epoch 248/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2147 - accuracy: 0.9402 - val_loss: 0.2292 - val_accuracy: 0.9363\n",
      "Epoch 249/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2147 - accuracy: 0.9402 - val_loss: 0.2292 - val_accuracy: 0.9363\n",
      "Epoch 250/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2147 - accuracy: 0.9402 - val_loss: 0.2291 - val_accuracy: 0.9363\n",
      "Epoch 251/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2146 - accuracy: 0.9402 - val_loss: 0.2291 - val_accuracy: 0.9363\n",
      "Epoch 252/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2145 - accuracy: 0.9402 - val_loss: 0.2290 - val_accuracy: 0.9363\n",
      "Epoch 253/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2145 - accuracy: 0.9402 - val_loss: 0.2290 - val_accuracy: 0.9363\n",
      "Epoch 254/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2144 - accuracy: 0.9402 - val_loss: 0.2290 - val_accuracy: 0.9363\n",
      "Epoch 255/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2144 - accuracy: 0.9402 - val_loss: 0.2289 - val_accuracy: 0.9363\n",
      "Epoch 256/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2143 - accuracy: 0.9402 - val_loss: 0.2288 - val_accuracy: 0.9363\n",
      "Epoch 257/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2142 - accuracy: 0.9402 - val_loss: 0.2288 - val_accuracy: 0.9363\n",
      "Epoch 258/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2142 - accuracy: 0.9402 - val_loss: 0.2287 - val_accuracy: 0.9363\n",
      "Epoch 259/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2141 - accuracy: 0.9402 - val_loss: 0.2287 - val_accuracy: 0.9363\n",
      "Epoch 260/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2141 - accuracy: 0.9402 - val_loss: 0.2286 - val_accuracy: 0.9363\n",
      "Epoch 261/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2140 - accuracy: 0.9402 - val_loss: 0.2286 - val_accuracy: 0.9363\n",
      "Epoch 262/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2139 - accuracy: 0.9402 - val_loss: 0.2285 - val_accuracy: 0.9363\n",
      "Epoch 263/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2139 - accuracy: 0.9402 - val_loss: 0.2284 - val_accuracy: 0.9363\n",
      "Epoch 264/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2138 - accuracy: 0.9402 - val_loss: 0.2283 - val_accuracy: 0.9363\n",
      "Epoch 265/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2138 - accuracy: 0.9402 - val_loss: 0.2283 - val_accuracy: 0.9363\n",
      "Epoch 266/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2137 - accuracy: 0.9402 - val_loss: 0.2283 - val_accuracy: 0.9363\n",
      "Epoch 267/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2136 - accuracy: 0.9402 - val_loss: 0.2282 - val_accuracy: 0.9363\n",
      "Epoch 268/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2136 - accuracy: 0.9402 - val_loss: 0.2282 - val_accuracy: 0.9363\n",
      "Epoch 269/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2135 - accuracy: 0.9402 - val_loss: 0.2281 - val_accuracy: 0.9363\n",
      "Epoch 270/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2134 - accuracy: 0.9402 - val_loss: 0.2280 - val_accuracy: 0.9363\n",
      "Epoch 271/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2134 - accuracy: 0.9402 - val_loss: 0.2280 - val_accuracy: 0.9363\n",
      "Epoch 272/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2133 - accuracy: 0.9402 - val_loss: 0.2279 - val_accuracy: 0.9363\n",
      "Epoch 273/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2132 - accuracy: 0.9402 - val_loss: 0.2278 - val_accuracy: 0.9363\n",
      "Epoch 274/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2131 - accuracy: 0.9402 - val_loss: 0.2278 - val_accuracy: 0.9363\n",
      "Epoch 275/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2131 - accuracy: 0.9402 - val_loss: 0.2277 - val_accuracy: 0.9363\n",
      "Epoch 276/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2130 - accuracy: 0.9402 - val_loss: 0.2276 - val_accuracy: 0.9363\n",
      "Epoch 277/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2130 - accuracy: 0.9402 - val_loss: 0.2276 - val_accuracy: 0.9363\n",
      "Epoch 278/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2129 - accuracy: 0.9402 - val_loss: 0.2275 - val_accuracy: 0.9363\n",
      "Epoch 279/800\n",
      "480/480 [==============================] - 0s 80us/step - loss: 0.2128 - accuracy: 0.9402 - val_loss: 0.2275 - val_accuracy: 0.9363\n",
      "Epoch 280/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 90us/step - loss: 0.2127 - accuracy: 0.9402 - val_loss: 0.2274 - val_accuracy: 0.9363\n",
      "Epoch 281/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2127 - accuracy: 0.9402 - val_loss: 0.2273 - val_accuracy: 0.9363\n",
      "Epoch 282/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2126 - accuracy: 0.9402 - val_loss: 0.2272 - val_accuracy: 0.9363\n",
      "Epoch 283/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2125 - accuracy: 0.9402 - val_loss: 0.2272 - val_accuracy: 0.9363\n",
      "Epoch 284/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2124 - accuracy: 0.9402 - val_loss: 0.2271 - val_accuracy: 0.9363\n",
      "Epoch 285/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2124 - accuracy: 0.9402 - val_loss: 0.2270 - val_accuracy: 0.9363\n",
      "Epoch 286/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2123 - accuracy: 0.9402 - val_loss: 0.2269 - val_accuracy: 0.9363\n",
      "Epoch 287/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2122 - accuracy: 0.9402 - val_loss: 0.2269 - val_accuracy: 0.9363\n",
      "Epoch 288/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2121 - accuracy: 0.9402 - val_loss: 0.2268 - val_accuracy: 0.9363\n",
      "Epoch 289/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2120 - accuracy: 0.9402 - val_loss: 0.2268 - val_accuracy: 0.9363\n",
      "Epoch 290/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2119 - accuracy: 0.9402 - val_loss: 0.2267 - val_accuracy: 0.9363\n",
      "Epoch 291/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2118 - accuracy: 0.9402 - val_loss: 0.2266 - val_accuracy: 0.9363\n",
      "Epoch 292/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.2118 - accuracy: 0.9402 - val_loss: 0.2266 - val_accuracy: 0.9363\n",
      "Epoch 293/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.2117 - accuracy: 0.9402 - val_loss: 0.2265 - val_accuracy: 0.9363\n",
      "Epoch 294/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2116 - accuracy: 0.9402 - val_loss: 0.2264 - val_accuracy: 0.9363\n",
      "Epoch 295/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2115 - accuracy: 0.9402 - val_loss: 0.2263 - val_accuracy: 0.9363\n",
      "Epoch 296/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2115 - accuracy: 0.9402 - val_loss: 0.2262 - val_accuracy: 0.9363\n",
      "Epoch 297/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2113 - accuracy: 0.9402 - val_loss: 0.2261 - val_accuracy: 0.9363\n",
      "Epoch 298/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2112 - accuracy: 0.9402 - val_loss: 0.2260 - val_accuracy: 0.9363\n",
      "Epoch 299/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2112 - accuracy: 0.9402 - val_loss: 0.2260 - val_accuracy: 0.9363\n",
      "Epoch 300/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2111 - accuracy: 0.9402 - val_loss: 0.2259 - val_accuracy: 0.9363\n",
      "Epoch 301/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2110 - accuracy: 0.9402 - val_loss: 0.2259 - val_accuracy: 0.9363\n",
      "Epoch 302/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2109 - accuracy: 0.9402 - val_loss: 0.2257 - val_accuracy: 0.9363\n",
      "Epoch 303/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2108 - accuracy: 0.9402 - val_loss: 0.2256 - val_accuracy: 0.9363\n",
      "Epoch 304/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2107 - accuracy: 0.9402 - val_loss: 0.2256 - val_accuracy: 0.9363\n",
      "Epoch 305/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2106 - accuracy: 0.9402 - val_loss: 0.2254 - val_accuracy: 0.9363\n",
      "Epoch 306/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2105 - accuracy: 0.9402 - val_loss: 0.2254 - val_accuracy: 0.9363\n",
      "Epoch 307/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2104 - accuracy: 0.9402 - val_loss: 0.2253 - val_accuracy: 0.9363\n",
      "Epoch 308/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2104 - accuracy: 0.9402 - val_loss: 0.2252 - val_accuracy: 0.9363\n",
      "Epoch 309/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2103 - accuracy: 0.9402 - val_loss: 0.2251 - val_accuracy: 0.9363\n",
      "Epoch 310/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2102 - accuracy: 0.9402 - val_loss: 0.2250 - val_accuracy: 0.9363\n",
      "Epoch 311/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2101 - accuracy: 0.9402 - val_loss: 0.2250 - val_accuracy: 0.9363\n",
      "Epoch 312/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2099 - accuracy: 0.9402 - val_loss: 0.2248 - val_accuracy: 0.9363\n",
      "Epoch 313/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2099 - accuracy: 0.9402 - val_loss: 0.2248 - val_accuracy: 0.9363\n",
      "Epoch 314/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2098 - accuracy: 0.9402 - val_loss: 0.2247 - val_accuracy: 0.9363\n",
      "Epoch 315/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2097 - accuracy: 0.9402 - val_loss: 0.2246 - val_accuracy: 0.9363\n",
      "Epoch 316/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2096 - accuracy: 0.9402 - val_loss: 0.2245 - val_accuracy: 0.9363\n",
      "Epoch 317/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2094 - accuracy: 0.9402 - val_loss: 0.2244 - val_accuracy: 0.9363\n",
      "Epoch 318/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2093 - accuracy: 0.9402 - val_loss: 0.2243 - val_accuracy: 0.9363\n",
      "Epoch 319/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2092 - accuracy: 0.9402 - val_loss: 0.2242 - val_accuracy: 0.9363\n",
      "Epoch 320/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2091 - accuracy: 0.9402 - val_loss: 0.2241 - val_accuracy: 0.9363\n",
      "Epoch 321/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2090 - accuracy: 0.9402 - val_loss: 0.2240 - val_accuracy: 0.9363\n",
      "Epoch 322/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2089 - accuracy: 0.9402 - val_loss: 0.2240 - val_accuracy: 0.9363\n",
      "Epoch 323/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2088 - accuracy: 0.9402 - val_loss: 0.2238 - val_accuracy: 0.9363\n",
      "Epoch 324/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2087 - accuracy: 0.9402 - val_loss: 0.2237 - val_accuracy: 0.9363\n",
      "Epoch 325/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2086 - accuracy: 0.9402 - val_loss: 0.2237 - val_accuracy: 0.9363\n",
      "Epoch 326/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2085 - accuracy: 0.9402 - val_loss: 0.2235 - val_accuracy: 0.9363\n",
      "Epoch 327/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2083 - accuracy: 0.9402 - val_loss: 0.2234 - val_accuracy: 0.9363\n",
      "Epoch 328/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2082 - accuracy: 0.9402 - val_loss: 0.2234 - val_accuracy: 0.9363\n",
      "Epoch 329/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2081 - accuracy: 0.9402 - val_loss: 0.2232 - val_accuracy: 0.9363\n",
      "Epoch 330/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2080 - accuracy: 0.9402 - val_loss: 0.2231 - val_accuracy: 0.9363\n",
      "Epoch 331/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.2079 - accuracy: 0.9402 - val_loss: 0.2230 - val_accuracy: 0.9363\n",
      "Epoch 332/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2077 - accuracy: 0.9402 - val_loss: 0.2229 - val_accuracy: 0.9363\n",
      "Epoch 333/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2076 - accuracy: 0.9402 - val_loss: 0.2228 - val_accuracy: 0.9363\n",
      "Epoch 334/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2075 - accuracy: 0.9402 - val_loss: 0.2227 - val_accuracy: 0.9363\n",
      "Epoch 335/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2074 - accuracy: 0.9402 - val_loss: 0.2226 - val_accuracy: 0.9363\n",
      "Epoch 336/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 90us/step - loss: 0.2073 - accuracy: 0.9402 - val_loss: 0.2225 - val_accuracy: 0.9363\n",
      "Epoch 337/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2071 - accuracy: 0.9402 - val_loss: 0.2223 - val_accuracy: 0.9363\n",
      "Epoch 338/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2070 - accuracy: 0.9402 - val_loss: 0.2223 - val_accuracy: 0.9363\n",
      "Epoch 339/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2069 - accuracy: 0.9402 - val_loss: 0.2222 - val_accuracy: 0.9363\n",
      "Epoch 340/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2068 - accuracy: 0.9402 - val_loss: 0.2221 - val_accuracy: 0.9363\n",
      "Epoch 341/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2066 - accuracy: 0.9402 - val_loss: 0.2219 - val_accuracy: 0.9363\n",
      "Epoch 342/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2065 - accuracy: 0.9402 - val_loss: 0.2218 - val_accuracy: 0.9363\n",
      "Epoch 343/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2064 - accuracy: 0.9402 - val_loss: 0.2217 - val_accuracy: 0.9363\n",
      "Epoch 344/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2063 - accuracy: 0.9402 - val_loss: 0.2216 - val_accuracy: 0.9363\n",
      "Epoch 345/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2061 - accuracy: 0.9402 - val_loss: 0.2215 - val_accuracy: 0.9363\n",
      "Epoch 346/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2060 - accuracy: 0.9402 - val_loss: 0.2214 - val_accuracy: 0.9363\n",
      "Epoch 347/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2058 - accuracy: 0.9402 - val_loss: 0.2213 - val_accuracy: 0.9363\n",
      "Epoch 348/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2057 - accuracy: 0.9402 - val_loss: 0.2211 - val_accuracy: 0.9363\n",
      "Epoch 349/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2056 - accuracy: 0.9402 - val_loss: 0.2210 - val_accuracy: 0.9363\n",
      "Epoch 350/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2054 - accuracy: 0.9402 - val_loss: 0.2209 - val_accuracy: 0.9363\n",
      "Epoch 351/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2054 - accuracy: 0.9402 - val_loss: 0.2208 - val_accuracy: 0.9363\n",
      "Epoch 352/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2052 - accuracy: 0.9402 - val_loss: 0.2206 - val_accuracy: 0.9363\n",
      "Epoch 353/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2051 - accuracy: 0.9403 - val_loss: 0.2205 - val_accuracy: 0.9363\n",
      "Epoch 354/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2049 - accuracy: 0.9403 - val_loss: 0.2204 - val_accuracy: 0.9363\n",
      "Epoch 355/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2048 - accuracy: 0.9403 - val_loss: 0.2203 - val_accuracy: 0.9363\n",
      "Epoch 356/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2046 - accuracy: 0.9403 - val_loss: 0.2202 - val_accuracy: 0.9363\n",
      "Epoch 357/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2045 - accuracy: 0.9403 - val_loss: 0.2201 - val_accuracy: 0.9363\n",
      "Epoch 358/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2043 - accuracy: 0.9403 - val_loss: 0.2199 - val_accuracy: 0.9363\n",
      "Epoch 359/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2042 - accuracy: 0.9403 - val_loss: 0.2199 - val_accuracy: 0.9363\n",
      "Epoch 360/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2041 - accuracy: 0.9403 - val_loss: 0.2197 - val_accuracy: 0.9363\n",
      "Epoch 361/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2039 - accuracy: 0.9403 - val_loss: 0.2195 - val_accuracy: 0.9363\n",
      "Epoch 362/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2038 - accuracy: 0.9403 - val_loss: 0.2194 - val_accuracy: 0.9363\n",
      "Epoch 363/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2036 - accuracy: 0.9403 - val_loss: 0.2192 - val_accuracy: 0.9363\n",
      "Epoch 364/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2035 - accuracy: 0.9403 - val_loss: 0.2191 - val_accuracy: 0.9363\n",
      "Epoch 365/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2033 - accuracy: 0.9403 - val_loss: 0.2190 - val_accuracy: 0.9363\n",
      "Epoch 366/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2032 - accuracy: 0.9403 - val_loss: 0.2189 - val_accuracy: 0.9363\n",
      "Epoch 367/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2031 - accuracy: 0.9403 - val_loss: 0.2187 - val_accuracy: 0.9363\n",
      "Epoch 368/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2029 - accuracy: 0.9403 - val_loss: 0.2187 - val_accuracy: 0.9363\n",
      "Epoch 369/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2027 - accuracy: 0.9403 - val_loss: 0.2185 - val_accuracy: 0.9363\n",
      "Epoch 370/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2026 - accuracy: 0.9403 - val_loss: 0.2184 - val_accuracy: 0.9363\n",
      "Epoch 371/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2024 - accuracy: 0.9402 - val_loss: 0.2183 - val_accuracy: 0.9363\n",
      "Epoch 372/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2023 - accuracy: 0.9403 - val_loss: 0.2182 - val_accuracy: 0.9363\n",
      "Epoch 373/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2021 - accuracy: 0.9403 - val_loss: 0.2180 - val_accuracy: 0.9363\n",
      "Epoch 374/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2020 - accuracy: 0.9402 - val_loss: 0.2179 - val_accuracy: 0.9363\n",
      "Epoch 375/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2018 - accuracy: 0.9403 - val_loss: 0.2177 - val_accuracy: 0.9363\n",
      "Epoch 376/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2016 - accuracy: 0.9403 - val_loss: 0.2176 - val_accuracy: 0.9363\n",
      "Epoch 377/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2015 - accuracy: 0.9403 - val_loss: 0.2174 - val_accuracy: 0.9363\n",
      "Epoch 378/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2013 - accuracy: 0.9402 - val_loss: 0.2173 - val_accuracy: 0.9362\n",
      "Epoch 379/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2012 - accuracy: 0.9403 - val_loss: 0.2172 - val_accuracy: 0.9362\n",
      "Epoch 380/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2010 - accuracy: 0.9403 - val_loss: 0.2170 - val_accuracy: 0.9362\n",
      "Epoch 381/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2008 - accuracy: 0.9402 - val_loss: 0.2169 - val_accuracy: 0.9362\n",
      "Epoch 382/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2007 - accuracy: 0.9403 - val_loss: 0.2168 - val_accuracy: 0.9362\n",
      "Epoch 383/800\n",
      "480/480 [==============================] - ETA: 0s - loss: 0.2083 - accuracy: 0.93 - 0s 85us/step - loss: 0.2005 - accuracy: 0.9404 - val_loss: 0.2167 - val_accuracy: 0.9362\n",
      "Epoch 384/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2004 - accuracy: 0.9403 - val_loss: 0.2165 - val_accuracy: 0.9362\n",
      "Epoch 385/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2002 - accuracy: 0.9404 - val_loss: 0.2164 - val_accuracy: 0.9362\n",
      "Epoch 386/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2000 - accuracy: 0.9404 - val_loss: 0.2163 - val_accuracy: 0.9362\n",
      "Epoch 387/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1999 - accuracy: 0.9404 - val_loss: 0.2161 - val_accuracy: 0.9362\n",
      "Epoch 388/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1997 - accuracy: 0.9404 - val_loss: 0.2160 - val_accuracy: 0.9362\n",
      "Epoch 389/800\n",
      "480/480 [==============================] - 0s 80us/step - loss: 0.1995 - accuracy: 0.9404 - val_loss: 0.2158 - val_accuracy: 0.9362\n",
      "Epoch 390/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1994 - accuracy: 0.9404 - val_loss: 0.2157 - val_accuracy: 0.9362\n",
      "Epoch 391/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1993 - accuracy: 0.9404 - val_loss: 0.2155 - val_accuracy: 0.9362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1991 - accuracy: 0.9404 - val_loss: 0.2154 - val_accuracy: 0.9362\n",
      "Epoch 393/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1989 - accuracy: 0.9405 - val_loss: 0.2153 - val_accuracy: 0.9362\n",
      "Epoch 394/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1988 - accuracy: 0.9405 - val_loss: 0.2152 - val_accuracy: 0.9362\n",
      "Epoch 395/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1986 - accuracy: 0.9405 - val_loss: 0.2150 - val_accuracy: 0.9362\n",
      "Epoch 396/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1985 - accuracy: 0.9405 - val_loss: 0.2149 - val_accuracy: 0.9362\n",
      "Epoch 397/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1983 - accuracy: 0.9405 - val_loss: 0.2147 - val_accuracy: 0.9362\n",
      "Epoch 398/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1981 - accuracy: 0.9405 - val_loss: 0.2146 - val_accuracy: 0.9363\n",
      "Epoch 399/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1980 - accuracy: 0.9405 - val_loss: 0.2145 - val_accuracy: 0.9363\n",
      "Epoch 400/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1978 - accuracy: 0.9406 - val_loss: 0.2144 - val_accuracy: 0.9363\n",
      "Epoch 401/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1976 - accuracy: 0.9406 - val_loss: 0.2142 - val_accuracy: 0.9363\n",
      "Epoch 402/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1975 - accuracy: 0.9405 - val_loss: 0.2140 - val_accuracy: 0.9363\n",
      "Epoch 403/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1973 - accuracy: 0.9406 - val_loss: 0.2140 - val_accuracy: 0.9363\n",
      "Epoch 404/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1972 - accuracy: 0.9406 - val_loss: 0.2139 - val_accuracy: 0.9362\n",
      "Epoch 405/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1970 - accuracy: 0.9406 - val_loss: 0.2137 - val_accuracy: 0.9362\n",
      "Epoch 406/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1968 - accuracy: 0.9406 - val_loss: 0.2135 - val_accuracy: 0.9362\n",
      "Epoch 407/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1967 - accuracy: 0.9406 - val_loss: 0.2134 - val_accuracy: 0.9362\n",
      "Epoch 408/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1965 - accuracy: 0.9406 - val_loss: 0.2132 - val_accuracy: 0.9362\n",
      "Epoch 409/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1964 - accuracy: 0.9407 - val_loss: 0.2131 - val_accuracy: 0.9362\n",
      "Epoch 410/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1962 - accuracy: 0.9406 - val_loss: 0.2130 - val_accuracy: 0.9362\n",
      "Epoch 411/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.1961 - accuracy: 0.9408 - val_loss: 0.2129 - val_accuracy: 0.9362\n",
      "Epoch 412/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1959 - accuracy: 0.9407 - val_loss: 0.2128 - val_accuracy: 0.9362\n",
      "Epoch 413/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1958 - accuracy: 0.9408 - val_loss: 0.2127 - val_accuracy: 0.9362\n",
      "Epoch 414/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1955 - accuracy: 0.9407 - val_loss: 0.2126 - val_accuracy: 0.9363\n",
      "Epoch 415/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1955 - accuracy: 0.9407 - val_loss: 0.2124 - val_accuracy: 0.9363\n",
      "Epoch 416/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1952 - accuracy: 0.9408 - val_loss: 0.2123 - val_accuracy: 0.9363\n",
      "Epoch 417/800\n",
      "480/480 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.94 - 0s 88us/step - loss: 0.1951 - accuracy: 0.9408 - val_loss: 0.2121 - val_accuracy: 0.9363\n",
      "Epoch 418/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1949 - accuracy: 0.9407 - val_loss: 0.2119 - val_accuracy: 0.9363\n",
      "Epoch 419/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1948 - accuracy: 0.9408 - val_loss: 0.2118 - val_accuracy: 0.9363\n",
      "Epoch 420/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1946 - accuracy: 0.9407 - val_loss: 0.2117 - val_accuracy: 0.9363\n",
      "Epoch 421/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1945 - accuracy: 0.9408 - val_loss: 0.2115 - val_accuracy: 0.9363\n",
      "Epoch 422/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1943 - accuracy: 0.9410 - val_loss: 0.2115 - val_accuracy: 0.9363\n",
      "Epoch 423/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1942 - accuracy: 0.9408 - val_loss: 0.2113 - val_accuracy: 0.9363\n",
      "Epoch 424/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1940 - accuracy: 0.9408 - val_loss: 0.2111 - val_accuracy: 0.9363\n",
      "Epoch 425/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1938 - accuracy: 0.9409 - val_loss: 0.2110 - val_accuracy: 0.9363\n",
      "Epoch 426/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1937 - accuracy: 0.9410 - val_loss: 0.2110 - val_accuracy: 0.9363\n",
      "Epoch 427/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1936 - accuracy: 0.9409 - val_loss: 0.2108 - val_accuracy: 0.9363\n",
      "Epoch 428/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1934 - accuracy: 0.9409 - val_loss: 0.2107 - val_accuracy: 0.9363\n",
      "Epoch 429/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1933 - accuracy: 0.9409 - val_loss: 0.2106 - val_accuracy: 0.9363\n",
      "Epoch 430/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1931 - accuracy: 0.9410 - val_loss: 0.2105 - val_accuracy: 0.9363\n",
      "Epoch 431/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1929 - accuracy: 0.9410 - val_loss: 0.2103 - val_accuracy: 0.9363\n",
      "Epoch 432/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1929 - accuracy: 0.9410 - val_loss: 0.2102 - val_accuracy: 0.9363\n",
      "Epoch 433/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1926 - accuracy: 0.9410 - val_loss: 0.2101 - val_accuracy: 0.9363\n",
      "Epoch 434/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1925 - accuracy: 0.9409 - val_loss: 0.2099 - val_accuracy: 0.9363\n",
      "Epoch 435/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1923 - accuracy: 0.9410 - val_loss: 0.2098 - val_accuracy: 0.9363\n",
      "Epoch 436/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1921 - accuracy: 0.9411 - val_loss: 0.2098 - val_accuracy: 0.9363\n",
      "Epoch 437/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1921 - accuracy: 0.9410 - val_loss: 0.2096 - val_accuracy: 0.9363\n",
      "Epoch 438/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1918 - accuracy: 0.9411 - val_loss: 0.2095 - val_accuracy: 0.9363\n",
      "Epoch 439/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1917 - accuracy: 0.9411 - val_loss: 0.2094 - val_accuracy: 0.9363\n",
      "Epoch 440/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1916 - accuracy: 0.9411 - val_loss: 0.2093 - val_accuracy: 0.9364\n",
      "Epoch 441/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1914 - accuracy: 0.9411 - val_loss: 0.2091 - val_accuracy: 0.9364\n",
      "Epoch 442/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1912 - accuracy: 0.9411 - val_loss: 0.2091 - val_accuracy: 0.9363\n",
      "Epoch 443/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1911 - accuracy: 0.9412 - val_loss: 0.2089 - val_accuracy: 0.9363\n",
      "Epoch 444/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1910 - accuracy: 0.9411 - val_loss: 0.2087 - val_accuracy: 0.9364\n",
      "Epoch 445/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1908 - accuracy: 0.9412 - val_loss: 0.2087 - val_accuracy: 0.9364\n",
      "Epoch 446/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1906 - accuracy: 0.9413 - val_loss: 0.2085 - val_accuracy: 0.9364\n",
      "Epoch 447/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1905 - accuracy: 0.9413 - val_loss: 0.2084 - val_accuracy: 0.9364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1904 - accuracy: 0.9413 - val_loss: 0.2083 - val_accuracy: 0.9364\n",
      "Epoch 449/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1903 - accuracy: 0.9413 - val_loss: 0.2083 - val_accuracy: 0.9364\n",
      "Epoch 450/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1901 - accuracy: 0.9413 - val_loss: 0.2081 - val_accuracy: 0.9364\n",
      "Epoch 451/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1900 - accuracy: 0.9413 - val_loss: 0.2079 - val_accuracy: 0.9364\n",
      "Epoch 452/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1898 - accuracy: 0.9412 - val_loss: 0.2079 - val_accuracy: 0.9364\n",
      "Epoch 453/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1897 - accuracy: 0.9414 - val_loss: 0.2078 - val_accuracy: 0.9364\n",
      "Epoch 454/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1896 - accuracy: 0.9414 - val_loss: 0.2077 - val_accuracy: 0.9364\n",
      "Epoch 455/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1894 - accuracy: 0.9413 - val_loss: 0.2076 - val_accuracy: 0.9364\n",
      "Epoch 456/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1892 - accuracy: 0.9415 - val_loss: 0.2074 - val_accuracy: 0.9364\n",
      "Epoch 457/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1891 - accuracy: 0.9415 - val_loss: 0.2073 - val_accuracy: 0.9364\n",
      "Epoch 458/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1890 - accuracy: 0.9414 - val_loss: 0.2072 - val_accuracy: 0.9364\n",
      "Epoch 459/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1889 - accuracy: 0.9414 - val_loss: 0.2069 - val_accuracy: 0.9364\n",
      "Epoch 460/800\n",
      "480/480 [==============================] - 0s 102us/step - loss: 0.1887 - accuracy: 0.9415 - val_loss: 0.2069 - val_accuracy: 0.9365\n",
      "Epoch 461/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1886 - accuracy: 0.9415 - val_loss: 0.2068 - val_accuracy: 0.9365\n",
      "Epoch 462/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1885 - accuracy: 0.9415 - val_loss: 0.2068 - val_accuracy: 0.9364\n",
      "Epoch 463/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1883 - accuracy: 0.9415 - val_loss: 0.2066 - val_accuracy: 0.9365\n",
      "Epoch 464/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1882 - accuracy: 0.9414 - val_loss: 0.2066 - val_accuracy: 0.9365\n",
      "Epoch 465/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1880 - accuracy: 0.9415 - val_loss: 0.2066 - val_accuracy: 0.9365\n",
      "Epoch 466/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1879 - accuracy: 0.9416 - val_loss: 0.2064 - val_accuracy: 0.9365\n",
      "Epoch 467/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1878 - accuracy: 0.9415 - val_loss: 0.2063 - val_accuracy: 0.9364\n",
      "Epoch 468/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1876 - accuracy: 0.9414 - val_loss: 0.2063 - val_accuracy: 0.9365\n",
      "Epoch 469/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1875 - accuracy: 0.9415 - val_loss: 0.2060 - val_accuracy: 0.9366\n",
      "Epoch 470/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1873 - accuracy: 0.9415 - val_loss: 0.2060 - val_accuracy: 0.9368\n",
      "Epoch 471/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1873 - accuracy: 0.9415 - val_loss: 0.2059 - val_accuracy: 0.9365\n",
      "Epoch 472/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1871 - accuracy: 0.9416 - val_loss: 0.2058 - val_accuracy: 0.9364\n",
      "Epoch 473/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1870 - accuracy: 0.9415 - val_loss: 0.2057 - val_accuracy: 0.9368\n",
      "Epoch 474/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1869 - accuracy: 0.9415 - val_loss: 0.2055 - val_accuracy: 0.9364\n",
      "Epoch 475/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1867 - accuracy: 0.9414 - val_loss: 0.2054 - val_accuracy: 0.9368\n",
      "Epoch 476/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1866 - accuracy: 0.9415 - val_loss: 0.2052 - val_accuracy: 0.9366\n",
      "Epoch 477/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1865 - accuracy: 0.9417 - val_loss: 0.2053 - val_accuracy: 0.9365\n",
      "Epoch 478/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1863 - accuracy: 0.9416 - val_loss: 0.2052 - val_accuracy: 0.9365\n",
      "Epoch 479/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.1862 - accuracy: 0.9416 - val_loss: 0.2051 - val_accuracy: 0.9365\n",
      "Epoch 480/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1861 - accuracy: 0.9415 - val_loss: 0.2052 - val_accuracy: 0.9365\n",
      "Epoch 481/800\n",
      "480/480 [==============================] - ETA: 0s - loss: 0.1900 - accuracy: 0.94 - 0s 88us/step - loss: 0.1860 - accuracy: 0.9417 - val_loss: 0.2050 - val_accuracy: 0.9365\n",
      "Epoch 482/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1858 - accuracy: 0.9418 - val_loss: 0.2047 - val_accuracy: 0.9365\n",
      "Epoch 483/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1857 - accuracy: 0.9416 - val_loss: 0.2047 - val_accuracy: 0.9365\n",
      "Epoch 484/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1856 - accuracy: 0.9417 - val_loss: 0.2047 - val_accuracy: 0.9365\n",
      "Epoch 485/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1855 - accuracy: 0.9417 - val_loss: 0.2047 - val_accuracy: 0.9365\n",
      "Epoch 486/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1853 - accuracy: 0.9416 - val_loss: 0.2046 - val_accuracy: 0.9365\n",
      "Epoch 487/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1852 - accuracy: 0.9418 - val_loss: 0.2044 - val_accuracy: 0.9366\n",
      "Epoch 488/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1851 - accuracy: 0.9416 - val_loss: 0.2045 - val_accuracy: 0.9366\n",
      "Epoch 489/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1850 - accuracy: 0.9417 - val_loss: 0.2043 - val_accuracy: 0.9366\n",
      "Epoch 490/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1848 - accuracy: 0.9419 - val_loss: 0.2042 - val_accuracy: 0.9366\n",
      "Epoch 491/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1847 - accuracy: 0.9417 - val_loss: 0.2040 - val_accuracy: 0.9366\n",
      "Epoch 492/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1846 - accuracy: 0.9418 - val_loss: 0.2041 - val_accuracy: 0.9366\n",
      "Epoch 493/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1844 - accuracy: 0.9417 - val_loss: 0.2038 - val_accuracy: 0.9366\n",
      "Epoch 494/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1844 - accuracy: 0.9418 - val_loss: 0.2038 - val_accuracy: 0.9366\n",
      "Epoch 495/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1842 - accuracy: 0.9417 - val_loss: 0.2037 - val_accuracy: 0.9366\n",
      "Epoch 496/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1841 - accuracy: 0.9418 - val_loss: 0.2036 - val_accuracy: 0.9366\n",
      "Epoch 497/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1840 - accuracy: 0.9418 - val_loss: 0.2036 - val_accuracy: 0.9366\n",
      "Epoch 498/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1839 - accuracy: 0.9418 - val_loss: 0.2036 - val_accuracy: 0.9366\n",
      "Epoch 499/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1838 - accuracy: 0.9418 - val_loss: 0.2035 - val_accuracy: 0.9368\n",
      "Epoch 500/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1837 - accuracy: 0.9418 - val_loss: 0.2035 - val_accuracy: 0.9366\n",
      "Epoch 501/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1836 - accuracy: 0.9418 - val_loss: 0.2033 - val_accuracy: 0.9366\n",
      "Epoch 502/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1834 - accuracy: 0.9418 - val_loss: 0.2032 - val_accuracy: 0.9365\n",
      "Epoch 503/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1833 - accuracy: 0.9420 - val_loss: 0.2032 - val_accuracy: 0.9368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1832 - accuracy: 0.9420 - val_loss: 0.2031 - val_accuracy: 0.9365\n",
      "Epoch 505/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1831 - accuracy: 0.9419 - val_loss: 0.2030 - val_accuracy: 0.9366\n",
      "Epoch 506/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1829 - accuracy: 0.9420 - val_loss: 0.2030 - val_accuracy: 0.9366\n",
      "Epoch 507/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1828 - accuracy: 0.9420 - val_loss: 0.2029 - val_accuracy: 0.9366\n",
      "Epoch 508/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1827 - accuracy: 0.9419 - val_loss: 0.2028 - val_accuracy: 0.9364\n",
      "Epoch 509/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1825 - accuracy: 0.9418 - val_loss: 0.2027 - val_accuracy: 0.9366\n",
      "Epoch 510/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1825 - accuracy: 0.9420 - val_loss: 0.2026 - val_accuracy: 0.9365\n",
      "Epoch 511/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1823 - accuracy: 0.9418 - val_loss: 0.2026 - val_accuracy: 0.9365\n",
      "Epoch 512/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1822 - accuracy: 0.9418 - val_loss: 0.2025 - val_accuracy: 0.9365\n",
      "Epoch 513/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1821 - accuracy: 0.9420 - val_loss: 0.2024 - val_accuracy: 0.9365\n",
      "Epoch 514/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1820 - accuracy: 0.9420 - val_loss: 0.2024 - val_accuracy: 0.9364\n",
      "Epoch 515/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1819 - accuracy: 0.9419 - val_loss: 0.2023 - val_accuracy: 0.9365\n",
      "Epoch 516/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1818 - accuracy: 0.9420 - val_loss: 0.2023 - val_accuracy: 0.9365\n",
      "Epoch 517/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1817 - accuracy: 0.9420 - val_loss: 0.2021 - val_accuracy: 0.9365\n",
      "Epoch 518/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1816 - accuracy: 0.9420 - val_loss: 0.2021 - val_accuracy: 0.9364\n",
      "Epoch 519/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1814 - accuracy: 0.9420 - val_loss: 0.2021 - val_accuracy: 0.9365\n",
      "Epoch 520/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1813 - accuracy: 0.9422 - val_loss: 0.2019 - val_accuracy: 0.9365\n",
      "Epoch 521/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1812 - accuracy: 0.9420 - val_loss: 0.2018 - val_accuracy: 0.9366\n",
      "Epoch 522/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1811 - accuracy: 0.9421 - val_loss: 0.2018 - val_accuracy: 0.9365\n",
      "Epoch 523/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1810 - accuracy: 0.9420 - val_loss: 0.2016 - val_accuracy: 0.9364\n",
      "Epoch 524/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1809 - accuracy: 0.9421 - val_loss: 0.2016 - val_accuracy: 0.9366\n",
      "Epoch 525/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1807 - accuracy: 0.9422 - val_loss: 0.2016 - val_accuracy: 0.9368\n",
      "Epoch 526/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1807 - accuracy: 0.9421 - val_loss: 0.2015 - val_accuracy: 0.9365\n",
      "Epoch 527/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1806 - accuracy: 0.9424 - val_loss: 0.2014 - val_accuracy: 0.9366\n",
      "Epoch 528/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1804 - accuracy: 0.9423 - val_loss: 0.2015 - val_accuracy: 0.9366\n",
      "Epoch 529/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1803 - accuracy: 0.9422 - val_loss: 0.2014 - val_accuracy: 0.9365\n",
      "Epoch 530/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1802 - accuracy: 0.9423 - val_loss: 0.2012 - val_accuracy: 0.9370\n",
      "Epoch 531/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1801 - accuracy: 0.9422 - val_loss: 0.2012 - val_accuracy: 0.9366\n",
      "Epoch 532/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1800 - accuracy: 0.9423 - val_loss: 0.2010 - val_accuracy: 0.9365\n",
      "Epoch 533/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1799 - accuracy: 0.9424 - val_loss: 0.2010 - val_accuracy: 0.9369\n",
      "Epoch 534/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1797 - accuracy: 0.9422 - val_loss: 0.2009 - val_accuracy: 0.9369\n",
      "Epoch 535/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1797 - accuracy: 0.9423 - val_loss: 0.2007 - val_accuracy: 0.9369\n",
      "Epoch 536/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1796 - accuracy: 0.9423 - val_loss: 0.2007 - val_accuracy: 0.9369\n",
      "Epoch 537/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1795 - accuracy: 0.9424 - val_loss: 0.2007 - val_accuracy: 0.9369\n",
      "Epoch 538/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1794 - accuracy: 0.9425 - val_loss: 0.2007 - val_accuracy: 0.9369\n",
      "Epoch 539/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1793 - accuracy: 0.9423 - val_loss: 0.2007 - val_accuracy: 0.9369\n",
      "Epoch 540/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1791 - accuracy: 0.9425 - val_loss: 0.2007 - val_accuracy: 0.9369\n",
      "Epoch 541/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1790 - accuracy: 0.9426 - val_loss: 0.2004 - val_accuracy: 0.9369\n",
      "Epoch 542/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1790 - accuracy: 0.9424 - val_loss: 0.2003 - val_accuracy: 0.9369\n",
      "Epoch 543/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1788 - accuracy: 0.9425 - val_loss: 0.2002 - val_accuracy: 0.9370\n",
      "Epoch 544/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1788 - accuracy: 0.9426 - val_loss: 0.2004 - val_accuracy: 0.9368\n",
      "Epoch 545/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1787 - accuracy: 0.9425 - val_loss: 0.2003 - val_accuracy: 0.9368\n",
      "Epoch 546/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1786 - accuracy: 0.9425 - val_loss: 0.2002 - val_accuracy: 0.9369\n",
      "Epoch 547/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1784 - accuracy: 0.9427 - val_loss: 0.2000 - val_accuracy: 0.9370\n",
      "Epoch 548/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1784 - accuracy: 0.9425 - val_loss: 0.2001 - val_accuracy: 0.9369\n",
      "Epoch 549/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1782 - accuracy: 0.9424 - val_loss: 0.1999 - val_accuracy: 0.9368\n",
      "Epoch 550/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1781 - accuracy: 0.9426 - val_loss: 0.1999 - val_accuracy: 0.9368\n",
      "Epoch 551/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1779 - accuracy: 0.9426 - val_loss: 0.1999 - val_accuracy: 0.9368\n",
      "Epoch 552/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1779 - accuracy: 0.9427 - val_loss: 0.1998 - val_accuracy: 0.9366\n",
      "Epoch 553/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1779 - accuracy: 0.9426 - val_loss: 0.1998 - val_accuracy: 0.9366\n",
      "Epoch 554/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1777 - accuracy: 0.9425 - val_loss: 0.1997 - val_accuracy: 0.9368\n",
      "Epoch 555/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1775 - accuracy: 0.9428 - val_loss: 0.1996 - val_accuracy: 0.9368\n",
      "Epoch 556/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1775 - accuracy: 0.9427 - val_loss: 0.1996 - val_accuracy: 0.9368\n",
      "Epoch 557/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1774 - accuracy: 0.9427 - val_loss: 0.1995 - val_accuracy: 0.9368\n",
      "Epoch 558/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1772 - accuracy: 0.9426 - val_loss: 0.1994 - val_accuracy: 0.9368\n",
      "Epoch 559/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1771 - accuracy: 0.9426 - val_loss: 0.1994 - val_accuracy: 0.9369\n",
      "Epoch 560/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 90us/step - loss: 0.1770 - accuracy: 0.9429 - val_loss: 0.1993 - val_accuracy: 0.9369\n",
      "Epoch 561/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1770 - accuracy: 0.9428 - val_loss: 0.1993 - val_accuracy: 0.9369\n",
      "Epoch 562/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1769 - accuracy: 0.9429 - val_loss: 0.1994 - val_accuracy: 0.9366\n",
      "Epoch 563/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1767 - accuracy: 0.9429 - val_loss: 0.1992 - val_accuracy: 0.9368\n",
      "Epoch 564/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1767 - accuracy: 0.9427 - val_loss: 0.1991 - val_accuracy: 0.9366\n",
      "Epoch 565/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1766 - accuracy: 0.9426 - val_loss: 0.1992 - val_accuracy: 0.9366\n",
      "Epoch 566/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1765 - accuracy: 0.9427 - val_loss: 0.1991 - val_accuracy: 0.9368\n",
      "Epoch 567/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1763 - accuracy: 0.9426 - val_loss: 0.1989 - val_accuracy: 0.9369\n",
      "Epoch 568/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1763 - accuracy: 0.9427 - val_loss: 0.1989 - val_accuracy: 0.9366\n",
      "Epoch 569/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1761 - accuracy: 0.9428 - val_loss: 0.1989 - val_accuracy: 0.9366\n",
      "Epoch 570/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1761 - accuracy: 0.9428 - val_loss: 0.1988 - val_accuracy: 0.9366\n",
      "Epoch 571/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1760 - accuracy: 0.9427 - val_loss: 0.1987 - val_accuracy: 0.9366\n",
      "Epoch 572/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1759 - accuracy: 0.9427 - val_loss: 0.1987 - val_accuracy: 0.9366\n",
      "Epoch 573/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1757 - accuracy: 0.9427 - val_loss: 0.1986 - val_accuracy: 0.9366\n",
      "Epoch 574/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.1756 - accuracy: 0.9429 - val_loss: 0.1985 - val_accuracy: 0.9366\n",
      "Epoch 575/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1755 - accuracy: 0.9426 - val_loss: 0.1984 - val_accuracy: 0.9366\n",
      "Epoch 576/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1754 - accuracy: 0.9427 - val_loss: 0.1984 - val_accuracy: 0.9366\n",
      "Epoch 577/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1753 - accuracy: 0.9425 - val_loss: 0.1983 - val_accuracy: 0.9368\n",
      "Epoch 578/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1752 - accuracy: 0.9430 - val_loss: 0.1983 - val_accuracy: 0.9366\n",
      "Epoch 579/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.1751 - accuracy: 0.9428 - val_loss: 0.1982 - val_accuracy: 0.9369\n",
      "Epoch 580/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1751 - accuracy: 0.9428 - val_loss: 0.1981 - val_accuracy: 0.9366\n",
      "Epoch 581/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1750 - accuracy: 0.9429 - val_loss: 0.1981 - val_accuracy: 0.9365\n",
      "Epoch 582/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1748 - accuracy: 0.9426 - val_loss: 0.1983 - val_accuracy: 0.9365\n",
      "Epoch 583/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1747 - accuracy: 0.9426 - val_loss: 0.1982 - val_accuracy: 0.9366\n",
      "Epoch 584/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1746 - accuracy: 0.9428 - val_loss: 0.1981 - val_accuracy: 0.9365\n",
      "Epoch 585/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1746 - accuracy: 0.9430 - val_loss: 0.1979 - val_accuracy: 0.9365\n",
      "Epoch 586/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1744 - accuracy: 0.9428 - val_loss: 0.1979 - val_accuracy: 0.9366\n",
      "Epoch 587/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1744 - accuracy: 0.9429 - val_loss: 0.1978 - val_accuracy: 0.9365\n",
      "Epoch 588/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1743 - accuracy: 0.9427 - val_loss: 0.1978 - val_accuracy: 0.9365\n",
      "Epoch 589/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1741 - accuracy: 0.9430 - val_loss: 0.1977 - val_accuracy: 0.9366\n",
      "Epoch 590/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1740 - accuracy: 0.9431 - val_loss: 0.1979 - val_accuracy: 0.9368\n",
      "Epoch 591/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1740 - accuracy: 0.9430 - val_loss: 0.1976 - val_accuracy: 0.9366\n",
      "Epoch 592/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1738 - accuracy: 0.9430 - val_loss: 0.1976 - val_accuracy: 0.9368\n",
      "Epoch 593/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1737 - accuracy: 0.9427 - val_loss: 0.1976 - val_accuracy: 0.9365\n",
      "Epoch 594/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1736 - accuracy: 0.9430 - val_loss: 0.1976 - val_accuracy: 0.9365\n",
      "Epoch 595/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1735 - accuracy: 0.9433 - val_loss: 0.1975 - val_accuracy: 0.9366\n",
      "Epoch 596/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1735 - accuracy: 0.9430 - val_loss: 0.1974 - val_accuracy: 0.9369\n",
      "Epoch 597/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1734 - accuracy: 0.9429 - val_loss: 0.1973 - val_accuracy: 0.9368\n",
      "Epoch 598/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1733 - accuracy: 0.9429 - val_loss: 0.1973 - val_accuracy: 0.9370\n",
      "Epoch 599/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1732 - accuracy: 0.9433 - val_loss: 0.1972 - val_accuracy: 0.9368\n",
      "Epoch 600/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1732 - accuracy: 0.9431 - val_loss: 0.1972 - val_accuracy: 0.9365\n",
      "Epoch 601/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.1730 - accuracy: 0.9433 - val_loss: 0.1970 - val_accuracy: 0.9366\n",
      "Epoch 602/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1730 - accuracy: 0.9434 - val_loss: 0.1971 - val_accuracy: 0.9364\n",
      "Epoch 603/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1728 - accuracy: 0.9433 - val_loss: 0.1970 - val_accuracy: 0.9363\n",
      "Epoch 604/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1728 - accuracy: 0.9433 - val_loss: 0.1969 - val_accuracy: 0.9370\n",
      "Epoch 605/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1726 - accuracy: 0.9431 - val_loss: 0.1968 - val_accuracy: 0.9368\n",
      "Epoch 606/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1725 - accuracy: 0.9435 - val_loss: 0.1968 - val_accuracy: 0.9365\n",
      "Epoch 607/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1724 - accuracy: 0.9433 - val_loss: 0.1968 - val_accuracy: 0.9363\n",
      "Epoch 608/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1723 - accuracy: 0.9432 - val_loss: 0.1968 - val_accuracy: 0.9362\n",
      "Epoch 609/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1722 - accuracy: 0.9434 - val_loss: 0.1966 - val_accuracy: 0.9365\n",
      "Epoch 610/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1722 - accuracy: 0.9433 - val_loss: 0.1967 - val_accuracy: 0.9365\n",
      "Epoch 611/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1720 - accuracy: 0.9432 - val_loss: 0.1967 - val_accuracy: 0.9364\n",
      "Epoch 612/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1720 - accuracy: 0.9432 - val_loss: 0.1966 - val_accuracy: 0.9366\n",
      "Epoch 613/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1719 - accuracy: 0.9433 - val_loss: 0.1964 - val_accuracy: 0.9366\n",
      "Epoch 614/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1718 - accuracy: 0.9435 - val_loss: 0.1965 - val_accuracy: 0.9364\n",
      "Epoch 615/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1716 - accuracy: 0.9433 - val_loss: 0.1963 - val_accuracy: 0.9365\n",
      "Epoch 616/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 90us/step - loss: 0.1716 - accuracy: 0.9435 - val_loss: 0.1962 - val_accuracy: 0.9365\n",
      "Epoch 617/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1714 - accuracy: 0.9435 - val_loss: 0.1964 - val_accuracy: 0.9363\n",
      "Epoch 618/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1714 - accuracy: 0.9435 - val_loss: 0.1962 - val_accuracy: 0.9365\n",
      "Epoch 619/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1713 - accuracy: 0.9433 - val_loss: 0.1962 - val_accuracy: 0.9365\n",
      "Epoch 620/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1712 - accuracy: 0.9437 - val_loss: 0.1962 - val_accuracy: 0.9365\n",
      "Epoch 621/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1711 - accuracy: 0.9434 - val_loss: 0.1961 - val_accuracy: 0.9368\n",
      "Epoch 622/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1710 - accuracy: 0.9438 - val_loss: 0.1960 - val_accuracy: 0.9366\n",
      "Epoch 623/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1709 - accuracy: 0.9433 - val_loss: 0.1959 - val_accuracy: 0.9366\n",
      "Epoch 624/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1708 - accuracy: 0.9434 - val_loss: 0.1959 - val_accuracy: 0.9363\n",
      "Epoch 625/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1707 - accuracy: 0.9436 - val_loss: 0.1957 - val_accuracy: 0.9365\n",
      "Epoch 626/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1706 - accuracy: 0.9436 - val_loss: 0.1956 - val_accuracy: 0.9364\n",
      "Epoch 627/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1704 - accuracy: 0.9435 - val_loss: 0.1957 - val_accuracy: 0.9365\n",
      "Epoch 628/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1704 - accuracy: 0.9435 - val_loss: 0.1957 - val_accuracy: 0.9364\n",
      "Epoch 629/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1703 - accuracy: 0.9436 - val_loss: 0.1955 - val_accuracy: 0.9366\n",
      "Epoch 630/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1702 - accuracy: 0.9437 - val_loss: 0.1955 - val_accuracy: 0.9366\n",
      "Epoch 631/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1701 - accuracy: 0.9436 - val_loss: 0.1955 - val_accuracy: 0.9365\n",
      "Epoch 632/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1701 - accuracy: 0.9436 - val_loss: 0.1955 - val_accuracy: 0.9365\n",
      "Epoch 633/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1699 - accuracy: 0.9438 - val_loss: 0.1954 - val_accuracy: 0.9371\n",
      "Epoch 634/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1698 - accuracy: 0.9435 - val_loss: 0.1954 - val_accuracy: 0.9366\n",
      "Epoch 635/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1698 - accuracy: 0.9434 - val_loss: 0.1953 - val_accuracy: 0.9365\n",
      "Epoch 636/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1697 - accuracy: 0.9435 - val_loss: 0.1954 - val_accuracy: 0.9365\n",
      "Epoch 637/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1696 - accuracy: 0.9436 - val_loss: 0.1953 - val_accuracy: 0.9368\n",
      "Epoch 638/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1695 - accuracy: 0.9436 - val_loss: 0.1952 - val_accuracy: 0.9365\n",
      "Epoch 639/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1693 - accuracy: 0.9437 - val_loss: 0.1951 - val_accuracy: 0.9368\n",
      "Epoch 640/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1693 - accuracy: 0.9436 - val_loss: 0.1950 - val_accuracy: 0.9369\n",
      "Epoch 641/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1692 - accuracy: 0.9435 - val_loss: 0.1950 - val_accuracy: 0.9366\n",
      "Epoch 642/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1691 - accuracy: 0.9437 - val_loss: 0.1949 - val_accuracy: 0.9365\n",
      "Epoch 643/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1690 - accuracy: 0.9440 - val_loss: 0.1950 - val_accuracy: 0.9366\n",
      "Epoch 644/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1689 - accuracy: 0.9437 - val_loss: 0.1951 - val_accuracy: 0.9368\n",
      "Epoch 645/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1688 - accuracy: 0.9433 - val_loss: 0.1948 - val_accuracy: 0.9371\n",
      "Epoch 646/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1688 - accuracy: 0.9436 - val_loss: 0.1948 - val_accuracy: 0.9371\n",
      "Epoch 647/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1686 - accuracy: 0.9436 - val_loss: 0.1948 - val_accuracy: 0.9374\n",
      "Epoch 648/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1686 - accuracy: 0.9436 - val_loss: 0.1947 - val_accuracy: 0.9373\n",
      "Epoch 649/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1685 - accuracy: 0.9437 - val_loss: 0.1947 - val_accuracy: 0.9371\n",
      "Epoch 650/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1684 - accuracy: 0.9436 - val_loss: 0.1946 - val_accuracy: 0.9369\n",
      "Epoch 651/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1682 - accuracy: 0.9437 - val_loss: 0.1946 - val_accuracy: 0.9369\n",
      "Epoch 652/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1681 - accuracy: 0.9437 - val_loss: 0.1946 - val_accuracy: 0.9369\n",
      "Epoch 653/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1680 - accuracy: 0.9437 - val_loss: 0.1944 - val_accuracy: 0.9369\n",
      "Epoch 654/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1680 - accuracy: 0.9437 - val_loss: 0.1944 - val_accuracy: 0.9369\n",
      "Epoch 655/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1679 - accuracy: 0.9438 - val_loss: 0.1942 - val_accuracy: 0.9370\n",
      "Epoch 656/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1678 - accuracy: 0.9438 - val_loss: 0.1942 - val_accuracy: 0.9370\n",
      "Epoch 657/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1677 - accuracy: 0.9437 - val_loss: 0.1941 - val_accuracy: 0.9366\n",
      "Epoch 658/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1677 - accuracy: 0.9437 - val_loss: 0.1942 - val_accuracy: 0.9369\n",
      "Epoch 659/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1674 - accuracy: 0.9437 - val_loss: 0.1942 - val_accuracy: 0.9369\n",
      "Epoch 660/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1674 - accuracy: 0.9434 - val_loss: 0.1941 - val_accuracy: 0.9366\n",
      "Epoch 661/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1674 - accuracy: 0.9437 - val_loss: 0.1940 - val_accuracy: 0.9366\n",
      "Epoch 662/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1673 - accuracy: 0.9439 - val_loss: 0.1940 - val_accuracy: 0.9366\n",
      "Epoch 663/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1671 - accuracy: 0.9439 - val_loss: 0.1939 - val_accuracy: 0.9368\n",
      "Epoch 664/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1670 - accuracy: 0.9438 - val_loss: 0.1942 - val_accuracy: 0.9373\n",
      "Epoch 665/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1670 - accuracy: 0.9440 - val_loss: 0.1937 - val_accuracy: 0.9368\n",
      "Epoch 666/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1669 - accuracy: 0.9438 - val_loss: 0.1939 - val_accuracy: 0.9369\n",
      "Epoch 667/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1668 - accuracy: 0.9440 - val_loss: 0.1940 - val_accuracy: 0.9369\n",
      "Epoch 668/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1667 - accuracy: 0.9440 - val_loss: 0.1939 - val_accuracy: 0.9365\n",
      "Epoch 669/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1665 - accuracy: 0.9438 - val_loss: 0.1937 - val_accuracy: 0.9368\n",
      "Epoch 670/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1665 - accuracy: 0.9440 - val_loss: 0.1937 - val_accuracy: 0.9369\n",
      "Epoch 671/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1664 - accuracy: 0.9438 - val_loss: 0.1938 - val_accuracy: 0.9368\n",
      "Epoch 672/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 91us/step - loss: 0.1662 - accuracy: 0.9440 - val_loss: 0.1937 - val_accuracy: 0.9369\n",
      "Epoch 673/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1662 - accuracy: 0.9440 - val_loss: 0.1935 - val_accuracy: 0.9368\n",
      "Epoch 674/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1661 - accuracy: 0.9441 - val_loss: 0.1934 - val_accuracy: 0.9369\n",
      "Epoch 675/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1660 - accuracy: 0.9437 - val_loss: 0.1935 - val_accuracy: 0.9368\n",
      "Epoch 676/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1658 - accuracy: 0.9439 - val_loss: 0.1934 - val_accuracy: 0.9368\n",
      "Epoch 677/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1658 - accuracy: 0.9442 - val_loss: 0.1934 - val_accuracy: 0.9366\n",
      "Epoch 678/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1657 - accuracy: 0.9440 - val_loss: 0.1935 - val_accuracy: 0.9368\n",
      "Epoch 679/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1657 - accuracy: 0.9440 - val_loss: 0.1932 - val_accuracy: 0.9370\n",
      "Epoch 680/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1655 - accuracy: 0.9440 - val_loss: 0.1931 - val_accuracy: 0.9370\n",
      "Epoch 681/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1654 - accuracy: 0.9440 - val_loss: 0.1932 - val_accuracy: 0.9366\n",
      "Epoch 682/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1654 - accuracy: 0.9440 - val_loss: 0.1933 - val_accuracy: 0.9368\n",
      "Epoch 683/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1652 - accuracy: 0.9437 - val_loss: 0.1932 - val_accuracy: 0.9373\n",
      "Epoch 684/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1651 - accuracy: 0.9441 - val_loss: 0.1930 - val_accuracy: 0.9371\n",
      "Epoch 685/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1650 - accuracy: 0.9438 - val_loss: 0.1928 - val_accuracy: 0.9369\n",
      "Epoch 686/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1650 - accuracy: 0.9439 - val_loss: 0.1929 - val_accuracy: 0.9373\n",
      "Epoch 687/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1648 - accuracy: 0.9441 - val_loss: 0.1929 - val_accuracy: 0.9369\n",
      "Epoch 688/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1647 - accuracy: 0.9439 - val_loss: 0.1928 - val_accuracy: 0.9371\n",
      "Epoch 689/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1646 - accuracy: 0.9442 - val_loss: 0.1927 - val_accuracy: 0.9370\n",
      "Epoch 690/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1646 - accuracy: 0.9443 - val_loss: 0.1927 - val_accuracy: 0.9370\n",
      "Epoch 691/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1645 - accuracy: 0.9440 - val_loss: 0.1928 - val_accuracy: 0.9370\n",
      "Epoch 692/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1643 - accuracy: 0.9439 - val_loss: 0.1927 - val_accuracy: 0.9373\n",
      "Epoch 693/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1643 - accuracy: 0.9440 - val_loss: 0.1925 - val_accuracy: 0.9371\n",
      "Epoch 694/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1642 - accuracy: 0.9442 - val_loss: 0.1925 - val_accuracy: 0.9371\n",
      "Epoch 695/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1640 - accuracy: 0.9443 - val_loss: 0.1925 - val_accuracy: 0.9368\n",
      "Epoch 696/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1640 - accuracy: 0.9441 - val_loss: 0.1924 - val_accuracy: 0.9376\n",
      "Epoch 697/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1638 - accuracy: 0.9444 - val_loss: 0.1923 - val_accuracy: 0.9371\n",
      "Epoch 698/800\n",
      "480/480 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.95 - 0s 90us/step - loss: 0.1638 - accuracy: 0.9444 - val_loss: 0.1922 - val_accuracy: 0.9373\n",
      "Epoch 699/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1636 - accuracy: 0.9441 - val_loss: 0.1923 - val_accuracy: 0.9373\n",
      "Epoch 700/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1636 - accuracy: 0.9444 - val_loss: 0.1922 - val_accuracy: 0.9370\n",
      "Epoch 701/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1635 - accuracy: 0.9444 - val_loss: 0.1924 - val_accuracy: 0.9373\n",
      "Epoch 702/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1634 - accuracy: 0.9444 - val_loss: 0.1923 - val_accuracy: 0.9371\n",
      "Epoch 703/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1634 - accuracy: 0.9441 - val_loss: 0.1921 - val_accuracy: 0.9371\n",
      "Epoch 704/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1632 - accuracy: 0.9444 - val_loss: 0.1920 - val_accuracy: 0.9373\n",
      "Epoch 705/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1631 - accuracy: 0.9441 - val_loss: 0.1921 - val_accuracy: 0.9370\n",
      "Epoch 706/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1630 - accuracy: 0.9446 - val_loss: 0.1920 - val_accuracy: 0.9368\n",
      "Epoch 707/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1630 - accuracy: 0.9444 - val_loss: 0.1919 - val_accuracy: 0.9369\n",
      "Epoch 708/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1628 - accuracy: 0.9443 - val_loss: 0.1919 - val_accuracy: 0.9371\n",
      "Epoch 709/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1627 - accuracy: 0.9443 - val_loss: 0.1919 - val_accuracy: 0.9373\n",
      "Epoch 710/800\n",
      "480/480 [==============================] - 0s 106us/step - loss: 0.1626 - accuracy: 0.9444 - val_loss: 0.1917 - val_accuracy: 0.9376\n",
      "Epoch 711/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1625 - accuracy: 0.9447 - val_loss: 0.1917 - val_accuracy: 0.9376\n",
      "Epoch 712/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1624 - accuracy: 0.9447 - val_loss: 0.1916 - val_accuracy: 0.9375\n",
      "Epoch 713/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1624 - accuracy: 0.9445 - val_loss: 0.1915 - val_accuracy: 0.9374\n",
      "Epoch 714/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1623 - accuracy: 0.9443 - val_loss: 0.1916 - val_accuracy: 0.9371\n",
      "Epoch 715/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1622 - accuracy: 0.9445 - val_loss: 0.1915 - val_accuracy: 0.9373\n",
      "Epoch 716/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1620 - accuracy: 0.9447 - val_loss: 0.1914 - val_accuracy: 0.9374\n",
      "Epoch 717/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1619 - accuracy: 0.9446 - val_loss: 0.1915 - val_accuracy: 0.9370\n",
      "Epoch 718/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1619 - accuracy: 0.9450 - val_loss: 0.1914 - val_accuracy: 0.9376\n",
      "Epoch 719/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1617 - accuracy: 0.9447 - val_loss: 0.1914 - val_accuracy: 0.9371\n",
      "Epoch 720/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1616 - accuracy: 0.9446 - val_loss: 0.1913 - val_accuracy: 0.9369\n",
      "Epoch 721/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1615 - accuracy: 0.9445 - val_loss: 0.1913 - val_accuracy: 0.9375\n",
      "Epoch 722/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1615 - accuracy: 0.9447 - val_loss: 0.1912 - val_accuracy: 0.9376\n",
      "Epoch 723/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1613 - accuracy: 0.9449 - val_loss: 0.1912 - val_accuracy: 0.9374\n",
      "Epoch 724/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1613 - accuracy: 0.9447 - val_loss: 0.1911 - val_accuracy: 0.9371\n",
      "Epoch 725/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1611 - accuracy: 0.9446 - val_loss: 0.1911 - val_accuracy: 0.9371\n",
      "Epoch 726/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1611 - accuracy: 0.9445 - val_loss: 0.1910 - val_accuracy: 0.9373\n",
      "Epoch 727/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1609 - accuracy: 0.9446 - val_loss: 0.1910 - val_accuracy: 0.9368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 728/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1610 - accuracy: 0.9448 - val_loss: 0.1910 - val_accuracy: 0.9365\n",
      "Epoch 729/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1608 - accuracy: 0.9447 - val_loss: 0.1909 - val_accuracy: 0.9368\n",
      "Epoch 730/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1607 - accuracy: 0.9446 - val_loss: 0.1908 - val_accuracy: 0.9373\n",
      "Epoch 731/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1606 - accuracy: 0.9447 - val_loss: 0.1907 - val_accuracy: 0.9365\n",
      "Epoch 732/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1606 - accuracy: 0.9447 - val_loss: 0.1908 - val_accuracy: 0.9376\n",
      "Epoch 733/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1604 - accuracy: 0.9447 - val_loss: 0.1909 - val_accuracy: 0.9371\n",
      "Epoch 734/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1604 - accuracy: 0.9449 - val_loss: 0.1907 - val_accuracy: 0.9373\n",
      "Epoch 735/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1602 - accuracy: 0.9446 - val_loss: 0.1908 - val_accuracy: 0.9373\n",
      "Epoch 736/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1601 - accuracy: 0.9449 - val_loss: 0.1906 - val_accuracy: 0.9365\n",
      "Epoch 737/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1599 - accuracy: 0.9449 - val_loss: 0.1908 - val_accuracy: 0.9368\n",
      "Epoch 738/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1600 - accuracy: 0.9448 - val_loss: 0.1906 - val_accuracy: 0.9366\n",
      "Epoch 739/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1598 - accuracy: 0.9449 - val_loss: 0.1904 - val_accuracy: 0.9364\n",
      "Epoch 740/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1597 - accuracy: 0.9446 - val_loss: 0.1904 - val_accuracy: 0.9370\n",
      "Epoch 741/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1597 - accuracy: 0.9445 - val_loss: 0.1903 - val_accuracy: 0.9373\n",
      "Epoch 742/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1596 - accuracy: 0.9448 - val_loss: 0.1904 - val_accuracy: 0.9365\n",
      "Epoch 743/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1595 - accuracy: 0.9451 - val_loss: 0.1902 - val_accuracy: 0.9376\n",
      "Epoch 744/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1594 - accuracy: 0.9450 - val_loss: 0.1902 - val_accuracy: 0.9369\n",
      "Epoch 745/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1592 - accuracy: 0.9448 - val_loss: 0.1902 - val_accuracy: 0.9371\n",
      "Epoch 746/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.1592 - accuracy: 0.9449 - val_loss: 0.1903 - val_accuracy: 0.9370\n",
      "Epoch 747/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1592 - accuracy: 0.9449 - val_loss: 0.1902 - val_accuracy: 0.9369\n",
      "Epoch 748/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1590 - accuracy: 0.9449 - val_loss: 0.1901 - val_accuracy: 0.9369\n",
      "Epoch 749/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1590 - accuracy: 0.9449 - val_loss: 0.1901 - val_accuracy: 0.9374\n",
      "Epoch 750/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1588 - accuracy: 0.9449 - val_loss: 0.1900 - val_accuracy: 0.9369\n",
      "Epoch 751/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1588 - accuracy: 0.9450 - val_loss: 0.1898 - val_accuracy: 0.9371\n",
      "Epoch 752/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1586 - accuracy: 0.9446 - val_loss: 0.1900 - val_accuracy: 0.9369\n",
      "Epoch 753/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1585 - accuracy: 0.9449 - val_loss: 0.1900 - val_accuracy: 0.9370\n",
      "Epoch 754/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1584 - accuracy: 0.9453 - val_loss: 0.1900 - val_accuracy: 0.9366\n",
      "Epoch 755/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1584 - accuracy: 0.9452 - val_loss: 0.1898 - val_accuracy: 0.9369\n",
      "Epoch 756/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1583 - accuracy: 0.9453 - val_loss: 0.1899 - val_accuracy: 0.9374\n",
      "Epoch 757/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1582 - accuracy: 0.9457 - val_loss: 0.1898 - val_accuracy: 0.9373\n",
      "Epoch 758/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1581 - accuracy: 0.9452 - val_loss: 0.1897 - val_accuracy: 0.9375\n",
      "Epoch 759/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1580 - accuracy: 0.9447 - val_loss: 0.1899 - val_accuracy: 0.9371\n",
      "Epoch 760/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1579 - accuracy: 0.9451 - val_loss: 0.1898 - val_accuracy: 0.9376\n",
      "Epoch 761/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1579 - accuracy: 0.9452 - val_loss: 0.1897 - val_accuracy: 0.9371\n",
      "Epoch 762/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1578 - accuracy: 0.9451 - val_loss: 0.1896 - val_accuracy: 0.9369\n",
      "Epoch 763/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1576 - accuracy: 0.9450 - val_loss: 0.1894 - val_accuracy: 0.9375\n",
      "Epoch 764/800\n",
      "480/480 [==============================] - 0s 77us/step - loss: 0.1575 - accuracy: 0.9455 - val_loss: 0.1896 - val_accuracy: 0.9370\n",
      "Epoch 765/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1574 - accuracy: 0.9455 - val_loss: 0.1895 - val_accuracy: 0.9371\n",
      "Epoch 766/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1574 - accuracy: 0.9454 - val_loss: 0.1896 - val_accuracy: 0.9365\n",
      "Epoch 767/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1573 - accuracy: 0.9455 - val_loss: 0.1895 - val_accuracy: 0.9374\n",
      "Epoch 768/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.1572 - accuracy: 0.9455 - val_loss: 0.1896 - val_accuracy: 0.9377\n",
      "Epoch 769/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1571 - accuracy: 0.9455 - val_loss: 0.1895 - val_accuracy: 0.9376\n",
      "Epoch 770/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1571 - accuracy: 0.9455 - val_loss: 0.1895 - val_accuracy: 0.9371\n",
      "Epoch 771/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1570 - accuracy: 0.9457 - val_loss: 0.1892 - val_accuracy: 0.9369\n",
      "Epoch 772/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1569 - accuracy: 0.9456 - val_loss: 0.1892 - val_accuracy: 0.9374\n",
      "Epoch 773/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1568 - accuracy: 0.9456 - val_loss: 0.1892 - val_accuracy: 0.9380\n",
      "Epoch 774/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1567 - accuracy: 0.9457 - val_loss: 0.1892 - val_accuracy: 0.9375\n",
      "Epoch 775/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1567 - accuracy: 0.9456 - val_loss: 0.1892 - val_accuracy: 0.9376\n",
      "Epoch 776/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1565 - accuracy: 0.9457 - val_loss: 0.1892 - val_accuracy: 0.9371\n",
      "Epoch 777/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1564 - accuracy: 0.9455 - val_loss: 0.1891 - val_accuracy: 0.9376\n",
      "Epoch 778/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1563 - accuracy: 0.9454 - val_loss: 0.1892 - val_accuracy: 0.9374\n",
      "Epoch 779/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1563 - accuracy: 0.9458 - val_loss: 0.1890 - val_accuracy: 0.9376\n",
      "Epoch 780/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1562 - accuracy: 0.9455 - val_loss: 0.1889 - val_accuracy: 0.9375\n",
      "Epoch 781/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1561 - accuracy: 0.9460 - val_loss: 0.1890 - val_accuracy: 0.9376\n",
      "Epoch 782/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1559 - accuracy: 0.9460 - val_loss: 0.1890 - val_accuracy: 0.9382\n",
      "Epoch 783/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1561 - accuracy: 0.9456 - val_loss: 0.1891 - val_accuracy: 0.9380\n",
      "Epoch 784/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 90us/step - loss: 0.1559 - accuracy: 0.9457 - val_loss: 0.1888 - val_accuracy: 0.9380\n",
      "Epoch 785/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1557 - accuracy: 0.9457 - val_loss: 0.1887 - val_accuracy: 0.9379\n",
      "Epoch 786/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1557 - accuracy: 0.9458 - val_loss: 0.1890 - val_accuracy: 0.9377\n",
      "Epoch 787/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1556 - accuracy: 0.9456 - val_loss: 0.1891 - val_accuracy: 0.9374\n",
      "Epoch 788/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1555 - accuracy: 0.9461 - val_loss: 0.1890 - val_accuracy: 0.9376\n",
      "Epoch 789/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1555 - accuracy: 0.9455 - val_loss: 0.1888 - val_accuracy: 0.9377\n",
      "Epoch 790/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1554 - accuracy: 0.9458 - val_loss: 0.1889 - val_accuracy: 0.9377\n",
      "Epoch 791/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1554 - accuracy: 0.9459 - val_loss: 0.1889 - val_accuracy: 0.9379\n",
      "Epoch 792/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1552 - accuracy: 0.9459 - val_loss: 0.1887 - val_accuracy: 0.9375\n",
      "Epoch 793/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1551 - accuracy: 0.9460 - val_loss: 0.1889 - val_accuracy: 0.9376\n",
      "Epoch 794/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1551 - accuracy: 0.9458 - val_loss: 0.1886 - val_accuracy: 0.9381\n",
      "Epoch 795/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1549 - accuracy: 0.9463 - val_loss: 0.1884 - val_accuracy: 0.9379\n",
      "Epoch 796/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1548 - accuracy: 0.9462 - val_loss: 0.1885 - val_accuracy: 0.9382\n",
      "Epoch 797/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1548 - accuracy: 0.9462 - val_loss: 0.1887 - val_accuracy: 0.9374\n",
      "Epoch 798/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1547 - accuracy: 0.9459 - val_loss: 0.1885 - val_accuracy: 0.9377\n",
      "Epoch 799/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1546 - accuracy: 0.9461 - val_loss: 0.1887 - val_accuracy: 0.9379\n",
      "Epoch 800/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1546 - accuracy: 0.9458 - val_loss: 0.1884 - val_accuracy: 0.9379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:122: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/800\n",
      "480/480 [==============================] - 0s 335us/step - loss: 0.6930 - accuracy: 0.5020 - val_loss: 0.6831 - val_accuracy: 0.6176\n",
      "Epoch 2/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.6747 - accuracy: 0.6728 - val_loss: 0.6651 - val_accuracy: 0.7130\n",
      "Epoch 3/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.6547 - accuracy: 0.7480 - val_loss: 0.6424 - val_accuracy: 0.7767\n",
      "Epoch 4/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.6274 - accuracy: 0.7976 - val_loss: 0.6086 - val_accuracy: 0.8140\n",
      "Epoch 5/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.5828 - accuracy: 0.8310 - val_loss: 0.5490 - val_accuracy: 0.8473\n",
      "Epoch 6/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.5027 - accuracy: 0.8609 - val_loss: 0.4446 - val_accuracy: 0.8963\n",
      "Epoch 7/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.3830 - accuracy: 0.9194 - val_loss: 0.3214 - val_accuracy: 0.9293\n",
      "Epoch 8/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2812 - accuracy: 0.9391 - val_loss: 0.2552 - val_accuracy: 0.9382\n",
      "Epoch 9/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2413 - accuracy: 0.9398 - val_loss: 0.2387 - val_accuracy: 0.9382\n",
      "Epoch 10/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2314 - accuracy: 0.9398 - val_loss: 0.2345 - val_accuracy: 0.9382\n",
      "Epoch 11/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2281 - accuracy: 0.9398 - val_loss: 0.2328 - val_accuracy: 0.9382\n",
      "Epoch 12/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2265 - accuracy: 0.9398 - val_loss: 0.2317 - val_accuracy: 0.9382\n",
      "Epoch 13/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2254 - accuracy: 0.9398 - val_loss: 0.2312 - val_accuracy: 0.9382\n",
      "Epoch 14/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2247 - accuracy: 0.9398 - val_loss: 0.2308 - val_accuracy: 0.9382\n",
      "Epoch 15/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2242 - accuracy: 0.9398 - val_loss: 0.2305 - val_accuracy: 0.9382\n",
      "Epoch 16/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2239 - accuracy: 0.9398 - val_loss: 0.2303 - val_accuracy: 0.9382\n",
      "Epoch 17/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2237 - accuracy: 0.9398 - val_loss: 0.2302 - val_accuracy: 0.9382\n",
      "Epoch 18/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2235 - accuracy: 0.9398 - val_loss: 0.2301 - val_accuracy: 0.9382\n",
      "Epoch 19/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2234 - accuracy: 0.9398 - val_loss: 0.2300 - val_accuracy: 0.9382\n",
      "Epoch 20/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2233 - accuracy: 0.9398 - val_loss: 0.2300 - val_accuracy: 0.9382\n",
      "Epoch 21/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2232 - accuracy: 0.9398 - val_loss: 0.2300 - val_accuracy: 0.9382\n",
      "Epoch 22/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2231 - accuracy: 0.9398 - val_loss: 0.2299 - val_accuracy: 0.9382\n",
      "Epoch 23/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2231 - accuracy: 0.9398 - val_loss: 0.2298 - val_accuracy: 0.9382\n",
      "Epoch 24/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2231 - accuracy: 0.9398 - val_loss: 0.2298 - val_accuracy: 0.9382\n",
      "Epoch 25/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2230 - accuracy: 0.9398 - val_loss: 0.2298 - val_accuracy: 0.9382\n",
      "Epoch 26/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2229 - accuracy: 0.9398 - val_loss: 0.2298 - val_accuracy: 0.9382\n",
      "Epoch 27/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2229 - accuracy: 0.9398 - val_loss: 0.2297 - val_accuracy: 0.9382\n",
      "Epoch 28/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2229 - accuracy: 0.9398 - val_loss: 0.2297 - val_accuracy: 0.9382\n",
      "Epoch 29/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2228 - accuracy: 0.9398 - val_loss: 0.2297 - val_accuracy: 0.9382\n",
      "Epoch 30/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2228 - accuracy: 0.9398 - val_loss: 0.2297 - val_accuracy: 0.9382\n",
      "Epoch 31/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2228 - accuracy: 0.9398 - val_loss: 0.2296 - val_accuracy: 0.9382\n",
      "Epoch 32/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2228 - accuracy: 0.9398 - val_loss: 0.2296 - val_accuracy: 0.9382\n",
      "Epoch 33/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2227 - accuracy: 0.9398 - val_loss: 0.2296 - val_accuracy: 0.9382\n",
      "Epoch 34/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2227 - accuracy: 0.9398 - val_loss: 0.2296 - val_accuracy: 0.9382\n",
      "Epoch 35/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2227 - accuracy: 0.9398 - val_loss: 0.2295 - val_accuracy: 0.9382\n",
      "Epoch 36/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2226 - accuracy: 0.9398 - val_loss: 0.2295 - val_accuracy: 0.9382\n",
      "Epoch 37/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2226 - accuracy: 0.9398 - val_loss: 0.2295 - val_accuracy: 0.9382\n",
      "Epoch 38/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2226 - accuracy: 0.9398 - val_loss: 0.2295 - val_accuracy: 0.9382\n",
      "Epoch 39/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.2226 - accuracy: 0.9398 - val_loss: 0.2295 - val_accuracy: 0.9382\n",
      "Epoch 40/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2225 - accuracy: 0.9398 - val_loss: 0.2294 - val_accuracy: 0.9382\n",
      "Epoch 41/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2225 - accuracy: 0.9398 - val_loss: 0.2294 - val_accuracy: 0.9382\n",
      "Epoch 42/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2225 - accuracy: 0.9398 - val_loss: 0.2294 - val_accuracy: 0.9382\n",
      "Epoch 43/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2225 - accuracy: 0.9398 - val_loss: 0.2294 - val_accuracy: 0.9382\n",
      "Epoch 44/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2224 - accuracy: 0.9398 - val_loss: 0.2293 - val_accuracy: 0.9382\n",
      "Epoch 45/800\n",
      "480/480 [==============================] - 0s 91us/step - loss: 0.2224 - accuracy: 0.9398 - val_loss: 0.2293 - val_accuracy: 0.9382\n",
      "Epoch 46/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2224 - accuracy: 0.9398 - val_loss: 0.2293 - val_accuracy: 0.9382\n",
      "Epoch 47/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.2223 - accuracy: 0.9398 - val_loss: 0.2293 - val_accuracy: 0.9382\n",
      "Epoch 48/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2223 - accuracy: 0.9398 - val_loss: 0.2293 - val_accuracy: 0.9382\n",
      "Epoch 49/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2223 - accuracy: 0.9398 - val_loss: 0.2293 - val_accuracy: 0.9382\n",
      "Epoch 50/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2223 - accuracy: 0.9398 - val_loss: 0.2293 - val_accuracy: 0.9382\n",
      "Epoch 51/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.2222 - accuracy: 0.9398 - val_loss: 0.2292 - val_accuracy: 0.9382\n",
      "Epoch 52/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2222 - accuracy: 0.9398 - val_loss: 0.2292 - val_accuracy: 0.9382\n",
      "Epoch 53/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2222 - accuracy: 0.9398 - val_loss: 0.2292 - val_accuracy: 0.9382\n",
      "Epoch 54/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2221 - accuracy: 0.9398 - val_loss: 0.2291 - val_accuracy: 0.9382\n",
      "Epoch 55/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2221 - accuracy: 0.9398 - val_loss: 0.2291 - val_accuracy: 0.9382\n",
      "Epoch 56/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.2221 - accuracy: 0.9398 - val_loss: 0.2291 - val_accuracy: 0.9382\n",
      "Epoch 57/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2221 - accuracy: 0.9398 - val_loss: 0.2291 - val_accuracy: 0.9382\n",
      "Epoch 58/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2220 - accuracy: 0.9398 - val_loss: 0.2291 - val_accuracy: 0.9382\n",
      "Epoch 59/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2220 - accuracy: 0.9398 - val_loss: 0.2291 - val_accuracy: 0.9382\n",
      "Epoch 60/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2220 - accuracy: 0.9398 - val_loss: 0.2291 - val_accuracy: 0.9382\n",
      "Epoch 61/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2219 - accuracy: 0.9398 - val_loss: 0.2290 - val_accuracy: 0.9382\n",
      "Epoch 62/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2219 - accuracy: 0.9398 - val_loss: 0.2290 - val_accuracy: 0.9382\n",
      "Epoch 63/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2219 - accuracy: 0.9398 - val_loss: 0.2290 - val_accuracy: 0.9382\n",
      "Epoch 64/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.2219 - accuracy: 0.9398 - val_loss: 0.2290 - val_accuracy: 0.9382\n",
      "Epoch 65/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2218 - accuracy: 0.9398 - val_loss: 0.2290 - val_accuracy: 0.9382\n",
      "Epoch 66/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2218 - accuracy: 0.9398 - val_loss: 0.2289 - val_accuracy: 0.9382\n",
      "Epoch 67/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2218 - accuracy: 0.9398 - val_loss: 0.2289 - val_accuracy: 0.9382\n",
      "Epoch 68/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2217 - accuracy: 0.9398 - val_loss: 0.2289 - val_accuracy: 0.9382\n",
      "Epoch 69/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2217 - accuracy: 0.9398 - val_loss: 0.2289 - val_accuracy: 0.9382\n",
      "Epoch 70/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2217 - accuracy: 0.9398 - val_loss: 0.2289 - val_accuracy: 0.9382\n",
      "Epoch 71/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2217 - accuracy: 0.9398 - val_loss: 0.2288 - val_accuracy: 0.9382\n",
      "Epoch 72/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2217 - accuracy: 0.9398 - val_loss: 0.2288 - val_accuracy: 0.9382\n",
      "Epoch 73/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2216 - accuracy: 0.9398 - val_loss: 0.2288 - val_accuracy: 0.9382\n",
      "Epoch 74/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2216 - accuracy: 0.9398 - val_loss: 0.2287 - val_accuracy: 0.9382\n",
      "Epoch 75/800\n",
      "480/480 [==============================] - 0s 91us/step - loss: 0.2216 - accuracy: 0.9398 - val_loss: 0.2287 - val_accuracy: 0.9382\n",
      "Epoch 76/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2215 - accuracy: 0.9398 - val_loss: 0.2287 - val_accuracy: 0.9382\n",
      "Epoch 77/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2215 - accuracy: 0.9398 - val_loss: 0.2287 - val_accuracy: 0.9382\n",
      "Epoch 78/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2215 - accuracy: 0.9398 - val_loss: 0.2287 - val_accuracy: 0.9382\n",
      "Epoch 79/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2215 - accuracy: 0.9398 - val_loss: 0.2286 - val_accuracy: 0.9382\n",
      "Epoch 80/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2214 - accuracy: 0.9398 - val_loss: 0.2286 - val_accuracy: 0.9382\n",
      "Epoch 81/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2215 - accuracy: 0.9398 - val_loss: 0.2286 - val_accuracy: 0.9382\n",
      "Epoch 82/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2214 - accuracy: 0.9398 - val_loss: 0.2286 - val_accuracy: 0.9382\n",
      "Epoch 83/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2214 - accuracy: 0.9398 - val_loss: 0.2286 - val_accuracy: 0.9382\n",
      "Epoch 84/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2213 - accuracy: 0.9398 - val_loss: 0.2286 - val_accuracy: 0.9382\n",
      "Epoch 85/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2214 - accuracy: 0.9398 - val_loss: 0.2286 - val_accuracy: 0.9382\n",
      "Epoch 86/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2213 - accuracy: 0.9398 - val_loss: 0.2286 - val_accuracy: 0.9382\n",
      "Epoch 87/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2213 - accuracy: 0.9398 - val_loss: 0.2285 - val_accuracy: 0.9382\n",
      "Epoch 88/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2212 - accuracy: 0.9398 - val_loss: 0.2285 - val_accuracy: 0.9382\n",
      "Epoch 89/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2212 - accuracy: 0.9398 - val_loss: 0.2285 - val_accuracy: 0.9382\n",
      "Epoch 90/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2212 - accuracy: 0.9398 - val_loss: 0.2285 - val_accuracy: 0.9382\n",
      "Epoch 91/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2212 - accuracy: 0.9398 - val_loss: 0.2285 - val_accuracy: 0.9382\n",
      "Epoch 92/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2212 - accuracy: 0.9398 - val_loss: 0.2284 - val_accuracy: 0.9382\n",
      "Epoch 93/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2211 - accuracy: 0.9398 - val_loss: 0.2284 - val_accuracy: 0.9382\n",
      "Epoch 94/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2211 - accuracy: 0.9398 - val_loss: 0.2284 - val_accuracy: 0.9382\n",
      "Epoch 95/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2211 - accuracy: 0.9398 - val_loss: 0.2284 - val_accuracy: 0.9382\n",
      "Epoch 96/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2211 - accuracy: 0.9398 - val_loss: 0.2284 - val_accuracy: 0.9382\n",
      "Epoch 97/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2210 - accuracy: 0.9398 - val_loss: 0.2284 - val_accuracy: 0.9382\n",
      "Epoch 98/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2210 - accuracy: 0.9398 - val_loss: 0.2284 - val_accuracy: 0.9382\n",
      "Epoch 99/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2210 - accuracy: 0.9398 - val_loss: 0.2284 - val_accuracy: 0.9382\n",
      "Epoch 100/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2210 - accuracy: 0.9398 - val_loss: 0.2283 - val_accuracy: 0.9382\n",
      "Epoch 101/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2210 - accuracy: 0.9398 - val_loss: 0.2283 - val_accuracy: 0.9382\n",
      "Epoch 102/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2209 - accuracy: 0.9398 - val_loss: 0.2283 - val_accuracy: 0.9382\n",
      "Epoch 103/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2209 - accuracy: 0.9398 - val_loss: 0.2282 - val_accuracy: 0.9382\n",
      "Epoch 104/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2209 - accuracy: 0.9398 - val_loss: 0.2282 - val_accuracy: 0.9382\n",
      "Epoch 105/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2209 - accuracy: 0.9398 - val_loss: 0.2282 - val_accuracy: 0.9382\n",
      "Epoch 106/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2208 - accuracy: 0.9398 - val_loss: 0.2282 - val_accuracy: 0.9382\n",
      "Epoch 107/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2208 - accuracy: 0.9398 - val_loss: 0.2282 - val_accuracy: 0.9382\n",
      "Epoch 108/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2208 - accuracy: 0.9398 - val_loss: 0.2282 - val_accuracy: 0.9382\n",
      "Epoch 109/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2207 - accuracy: 0.9398 - val_loss: 0.2281 - val_accuracy: 0.9382\n",
      "Epoch 110/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2207 - accuracy: 0.9398 - val_loss: 0.2281 - val_accuracy: 0.9382\n",
      "Epoch 111/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2207 - accuracy: 0.9398 - val_loss: 0.2281 - val_accuracy: 0.9382\n",
      "Epoch 112/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 88us/step - loss: 0.2207 - accuracy: 0.9398 - val_loss: 0.2281 - val_accuracy: 0.9382\n",
      "Epoch 113/800\n",
      "480/480 [==============================] - 0s 91us/step - loss: 0.2206 - accuracy: 0.9398 - val_loss: 0.2281 - val_accuracy: 0.9382\n",
      "Epoch 114/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2206 - accuracy: 0.9398 - val_loss: 0.2281 - val_accuracy: 0.9382\n",
      "Epoch 115/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2206 - accuracy: 0.9398 - val_loss: 0.2280 - val_accuracy: 0.9382\n",
      "Epoch 116/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2206 - accuracy: 0.9398 - val_loss: 0.2280 - val_accuracy: 0.9382\n",
      "Epoch 117/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2206 - accuracy: 0.9398 - val_loss: 0.2280 - val_accuracy: 0.9382\n",
      "Epoch 118/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2205 - accuracy: 0.9398 - val_loss: 0.2280 - val_accuracy: 0.9382\n",
      "Epoch 119/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2205 - accuracy: 0.9398 - val_loss: 0.2279 - val_accuracy: 0.9382\n",
      "Epoch 120/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2205 - accuracy: 0.9398 - val_loss: 0.2280 - val_accuracy: 0.9382\n",
      "Epoch 121/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2204 - accuracy: 0.9398 - val_loss: 0.2279 - val_accuracy: 0.9382\n",
      "Epoch 122/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2205 - accuracy: 0.9398 - val_loss: 0.2279 - val_accuracy: 0.9382\n",
      "Epoch 123/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2204 - accuracy: 0.9398 - val_loss: 0.2279 - val_accuracy: 0.9382\n",
      "Epoch 124/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2204 - accuracy: 0.9398 - val_loss: 0.2279 - val_accuracy: 0.9382\n",
      "Epoch 125/800\n",
      "480/480 [==============================] - 0s 91us/step - loss: 0.2203 - accuracy: 0.9398 - val_loss: 0.2279 - val_accuracy: 0.9382\n",
      "Epoch 126/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2203 - accuracy: 0.9398 - val_loss: 0.2278 - val_accuracy: 0.9382\n",
      "Epoch 127/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2203 - accuracy: 0.9398 - val_loss: 0.2279 - val_accuracy: 0.9382\n",
      "Epoch 128/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2203 - accuracy: 0.9398 - val_loss: 0.2278 - val_accuracy: 0.9382\n",
      "Epoch 129/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2202 - accuracy: 0.9398 - val_loss: 0.2278 - val_accuracy: 0.9382\n",
      "Epoch 130/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2202 - accuracy: 0.9398 - val_loss: 0.2278 - val_accuracy: 0.9382\n",
      "Epoch 131/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2201 - accuracy: 0.9398 - val_loss: 0.2278 - val_accuracy: 0.9382\n",
      "Epoch 132/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2202 - accuracy: 0.9398 - val_loss: 0.2277 - val_accuracy: 0.9382\n",
      "Epoch 133/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2201 - accuracy: 0.9398 - val_loss: 0.2278 - val_accuracy: 0.9382\n",
      "Epoch 134/800\n",
      "480/480 [==============================] - ETA: 0s - loss: 0.2218 - accuracy: 0.93 - 0s 83us/step - loss: 0.2201 - accuracy: 0.9398 - val_loss: 0.2277 - val_accuracy: 0.9382\n",
      "Epoch 135/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2201 - accuracy: 0.9398 - val_loss: 0.2277 - val_accuracy: 0.9382\n",
      "Epoch 136/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2200 - accuracy: 0.9398 - val_loss: 0.2276 - val_accuracy: 0.9382\n",
      "Epoch 137/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2200 - accuracy: 0.9398 - val_loss: 0.2276 - val_accuracy: 0.9382\n",
      "Epoch 138/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2200 - accuracy: 0.9398 - val_loss: 0.2276 - val_accuracy: 0.9382\n",
      "Epoch 139/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2199 - accuracy: 0.9398 - val_loss: 0.2276 - val_accuracy: 0.9382\n",
      "Epoch 140/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2199 - accuracy: 0.9398 - val_loss: 0.2276 - val_accuracy: 0.9382\n",
      "Epoch 141/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2199 - accuracy: 0.9398 - val_loss: 0.2276 - val_accuracy: 0.9382\n",
      "Epoch 142/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2199 - accuracy: 0.9398 - val_loss: 0.2276 - val_accuracy: 0.9382\n",
      "Epoch 143/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2198 - accuracy: 0.9398 - val_loss: 0.2275 - val_accuracy: 0.9382\n",
      "Epoch 144/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2198 - accuracy: 0.9398 - val_loss: 0.2275 - val_accuracy: 0.9382\n",
      "Epoch 145/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2198 - accuracy: 0.9398 - val_loss: 0.2275 - val_accuracy: 0.9382\n",
      "Epoch 146/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2197 - accuracy: 0.9398 - val_loss: 0.2274 - val_accuracy: 0.9382\n",
      "Epoch 147/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2197 - accuracy: 0.9398 - val_loss: 0.2274 - val_accuracy: 0.9382\n",
      "Epoch 148/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2197 - accuracy: 0.9398 - val_loss: 0.2274 - val_accuracy: 0.9382\n",
      "Epoch 149/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2197 - accuracy: 0.9398 - val_loss: 0.2274 - val_accuracy: 0.9382\n",
      "Epoch 150/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2197 - accuracy: 0.9398 - val_loss: 0.2274 - val_accuracy: 0.9382\n",
      "Epoch 151/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2196 - accuracy: 0.9398 - val_loss: 0.2274 - val_accuracy: 0.9382\n",
      "Epoch 152/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2196 - accuracy: 0.9398 - val_loss: 0.2273 - val_accuracy: 0.9382\n",
      "Epoch 153/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2196 - accuracy: 0.9398 - val_loss: 0.2273 - val_accuracy: 0.9382\n",
      "Epoch 154/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2195 - accuracy: 0.9398 - val_loss: 0.2273 - val_accuracy: 0.9382\n",
      "Epoch 155/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2195 - accuracy: 0.9398 - val_loss: 0.2273 - val_accuracy: 0.9382\n",
      "Epoch 156/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2194 - accuracy: 0.9398 - val_loss: 0.2272 - val_accuracy: 0.9382\n",
      "Epoch 157/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2194 - accuracy: 0.9398 - val_loss: 0.2272 - val_accuracy: 0.9382\n",
      "Epoch 158/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2194 - accuracy: 0.9398 - val_loss: 0.2272 - val_accuracy: 0.9382\n",
      "Epoch 159/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2194 - accuracy: 0.9398 - val_loss: 0.2272 - val_accuracy: 0.9382\n",
      "Epoch 160/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2193 - accuracy: 0.9398 - val_loss: 0.2272 - val_accuracy: 0.9382\n",
      "Epoch 161/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2193 - accuracy: 0.9398 - val_loss: 0.2271 - val_accuracy: 0.9382\n",
      "Epoch 162/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2192 - accuracy: 0.9398 - val_loss: 0.2271 - val_accuracy: 0.9382\n",
      "Epoch 163/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2192 - accuracy: 0.9398 - val_loss: 0.2270 - val_accuracy: 0.9382\n",
      "Epoch 164/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2192 - accuracy: 0.9398 - val_loss: 0.2270 - val_accuracy: 0.9382\n",
      "Epoch 165/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2191 - accuracy: 0.9398 - val_loss: 0.2271 - val_accuracy: 0.9382\n",
      "Epoch 166/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2191 - accuracy: 0.9398 - val_loss: 0.2270 - val_accuracy: 0.9382\n",
      "Epoch 167/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2191 - accuracy: 0.9398 - val_loss: 0.2270 - val_accuracy: 0.9382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2191 - accuracy: 0.9398 - val_loss: 0.2270 - val_accuracy: 0.9382\n",
      "Epoch 169/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2190 - accuracy: 0.9398 - val_loss: 0.2270 - val_accuracy: 0.9382\n",
      "Epoch 170/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2190 - accuracy: 0.9398 - val_loss: 0.2269 - val_accuracy: 0.9382\n",
      "Epoch 171/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2189 - accuracy: 0.9398 - val_loss: 0.2269 - val_accuracy: 0.9382\n",
      "Epoch 172/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2189 - accuracy: 0.9398 - val_loss: 0.2268 - val_accuracy: 0.9382\n",
      "Epoch 173/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2189 - accuracy: 0.9398 - val_loss: 0.2268 - val_accuracy: 0.9382\n",
      "Epoch 174/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2189 - accuracy: 0.9398 - val_loss: 0.2268 - val_accuracy: 0.9382\n",
      "Epoch 175/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2188 - accuracy: 0.9398 - val_loss: 0.2268 - val_accuracy: 0.9382\n",
      "Epoch 176/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2187 - accuracy: 0.9398 - val_loss: 0.2268 - val_accuracy: 0.9382\n",
      "Epoch 177/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2187 - accuracy: 0.9398 - val_loss: 0.2267 - val_accuracy: 0.9382\n",
      "Epoch 178/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2187 - accuracy: 0.9398 - val_loss: 0.2267 - val_accuracy: 0.9382\n",
      "Epoch 179/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2186 - accuracy: 0.9398 - val_loss: 0.2267 - val_accuracy: 0.9382\n",
      "Epoch 180/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2186 - accuracy: 0.9398 - val_loss: 0.2267 - val_accuracy: 0.9382\n",
      "Epoch 181/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2186 - accuracy: 0.9398 - val_loss: 0.2266 - val_accuracy: 0.9382\n",
      "Epoch 182/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2185 - accuracy: 0.9398 - val_loss: 0.2266 - val_accuracy: 0.9382\n",
      "Epoch 183/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2185 - accuracy: 0.9398 - val_loss: 0.2266 - val_accuracy: 0.9382\n",
      "Epoch 184/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2185 - accuracy: 0.9398 - val_loss: 0.2265 - val_accuracy: 0.9382\n",
      "Epoch 185/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2184 - accuracy: 0.9398 - val_loss: 0.2265 - val_accuracy: 0.9382\n",
      "Epoch 186/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2184 - accuracy: 0.9398 - val_loss: 0.2265 - val_accuracy: 0.9382\n",
      "Epoch 187/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.2183 - accuracy: 0.9398 - val_loss: 0.2265 - val_accuracy: 0.9382\n",
      "Epoch 188/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2183 - accuracy: 0.9398 - val_loss: 0.2264 - val_accuracy: 0.9382\n",
      "Epoch 189/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2183 - accuracy: 0.9398 - val_loss: 0.2264 - val_accuracy: 0.9382\n",
      "Epoch 190/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2183 - accuracy: 0.9398 - val_loss: 0.2264 - val_accuracy: 0.9382\n",
      "Epoch 191/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2182 - accuracy: 0.9398 - val_loss: 0.2263 - val_accuracy: 0.9382\n",
      "Epoch 192/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2182 - accuracy: 0.9398 - val_loss: 0.2263 - val_accuracy: 0.9382\n",
      "Epoch 193/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2181 - accuracy: 0.9398 - val_loss: 0.2263 - val_accuracy: 0.9382\n",
      "Epoch 194/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2181 - accuracy: 0.9398 - val_loss: 0.2263 - val_accuracy: 0.9382\n",
      "Epoch 195/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2180 - accuracy: 0.9398 - val_loss: 0.2262 - val_accuracy: 0.9382\n",
      "Epoch 196/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2180 - accuracy: 0.9398 - val_loss: 0.2262 - val_accuracy: 0.9382\n",
      "Epoch 197/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2179 - accuracy: 0.9398 - val_loss: 0.2261 - val_accuracy: 0.9382\n",
      "Epoch 198/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2179 - accuracy: 0.9398 - val_loss: 0.2261 - val_accuracy: 0.9382\n",
      "Epoch 199/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2179 - accuracy: 0.9398 - val_loss: 0.2261 - val_accuracy: 0.9382\n",
      "Epoch 200/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2178 - accuracy: 0.9398 - val_loss: 0.2261 - val_accuracy: 0.9382\n",
      "Epoch 201/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2178 - accuracy: 0.9398 - val_loss: 0.2261 - val_accuracy: 0.9382\n",
      "Epoch 202/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2177 - accuracy: 0.9398 - val_loss: 0.2260 - val_accuracy: 0.9382\n",
      "Epoch 203/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2177 - accuracy: 0.9398 - val_loss: 0.2260 - val_accuracy: 0.9382\n",
      "Epoch 204/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2176 - accuracy: 0.9398 - val_loss: 0.2260 - val_accuracy: 0.9382\n",
      "Epoch 205/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2176 - accuracy: 0.9398 - val_loss: 0.2259 - val_accuracy: 0.9382\n",
      "Epoch 206/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2175 - accuracy: 0.9398 - val_loss: 0.2259 - val_accuracy: 0.9382\n",
      "Epoch 207/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2175 - accuracy: 0.9398 - val_loss: 0.2259 - val_accuracy: 0.9382\n",
      "Epoch 208/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2175 - accuracy: 0.9398 - val_loss: 0.2258 - val_accuracy: 0.9382\n",
      "Epoch 209/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2174 - accuracy: 0.9398 - val_loss: 0.2258 - val_accuracy: 0.9382\n",
      "Epoch 210/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2173 - accuracy: 0.9398 - val_loss: 0.2258 - val_accuracy: 0.9382\n",
      "Epoch 211/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2173 - accuracy: 0.9398 - val_loss: 0.2257 - val_accuracy: 0.9382\n",
      "Epoch 212/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2172 - accuracy: 0.9398 - val_loss: 0.2257 - val_accuracy: 0.9382\n",
      "Epoch 213/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2172 - accuracy: 0.9398 - val_loss: 0.2257 - val_accuracy: 0.9382\n",
      "Epoch 214/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2171 - accuracy: 0.9398 - val_loss: 0.2256 - val_accuracy: 0.9382\n",
      "Epoch 215/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2171 - accuracy: 0.9398 - val_loss: 0.2256 - val_accuracy: 0.9382\n",
      "Epoch 216/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2170 - accuracy: 0.9398 - val_loss: 0.2255 - val_accuracy: 0.9382\n",
      "Epoch 217/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2170 - accuracy: 0.9398 - val_loss: 0.2255 - val_accuracy: 0.9382\n",
      "Epoch 218/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2169 - accuracy: 0.9398 - val_loss: 0.2255 - val_accuracy: 0.9382\n",
      "Epoch 219/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2169 - accuracy: 0.9398 - val_loss: 0.2255 - val_accuracy: 0.9382\n",
      "Epoch 220/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2169 - accuracy: 0.9398 - val_loss: 0.2254 - val_accuracy: 0.9382\n",
      "Epoch 221/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2168 - accuracy: 0.9398 - val_loss: 0.2254 - val_accuracy: 0.9382\n",
      "Epoch 222/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2167 - accuracy: 0.9398 - val_loss: 0.2253 - val_accuracy: 0.9382\n",
      "Epoch 223/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2167 - accuracy: 0.9398 - val_loss: 0.2253 - val_accuracy: 0.9382\n",
      "Epoch 224/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.2166 - accuracy: 0.9398 - val_loss: 0.2252 - val_accuracy: 0.9382\n",
      "Epoch 225/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2166 - accuracy: 0.9398 - val_loss: 0.2252 - val_accuracy: 0.9382\n",
      "Epoch 226/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2165 - accuracy: 0.9398 - val_loss: 0.2252 - val_accuracy: 0.9382\n",
      "Epoch 227/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2165 - accuracy: 0.9398 - val_loss: 0.2251 - val_accuracy: 0.9382\n",
      "Epoch 228/800\n",
      "480/480 [==============================] - 0s 96us/step - loss: 0.2164 - accuracy: 0.9398 - val_loss: 0.2251 - val_accuracy: 0.9382\n",
      "Epoch 229/800\n",
      "480/480 [==============================] - 0s 100us/step - loss: 0.2163 - accuracy: 0.9398 - val_loss: 0.2251 - val_accuracy: 0.9382\n",
      "Epoch 230/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.2163 - accuracy: 0.9398 - val_loss: 0.2250 - val_accuracy: 0.9382\n",
      "Epoch 231/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2162 - accuracy: 0.9398 - val_loss: 0.2250 - val_accuracy: 0.9382\n",
      "Epoch 232/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2162 - accuracy: 0.9398 - val_loss: 0.2249 - val_accuracy: 0.9382\n",
      "Epoch 233/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2161 - accuracy: 0.9398 - val_loss: 0.2248 - val_accuracy: 0.9382\n",
      "Epoch 234/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2161 - accuracy: 0.9398 - val_loss: 0.2248 - val_accuracy: 0.9382\n",
      "Epoch 235/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2160 - accuracy: 0.9398 - val_loss: 0.2248 - val_accuracy: 0.9382\n",
      "Epoch 236/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2159 - accuracy: 0.9398 - val_loss: 0.2247 - val_accuracy: 0.9382\n",
      "Epoch 237/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2159 - accuracy: 0.9398 - val_loss: 0.2246 - val_accuracy: 0.9382\n",
      "Epoch 238/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2158 - accuracy: 0.9398 - val_loss: 0.2246 - val_accuracy: 0.9382\n",
      "Epoch 239/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2157 - accuracy: 0.9398 - val_loss: 0.2245 - val_accuracy: 0.9382\n",
      "Epoch 240/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2157 - accuracy: 0.9398 - val_loss: 0.2245 - val_accuracy: 0.9382\n",
      "Epoch 241/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2156 - accuracy: 0.9398 - val_loss: 0.2245 - val_accuracy: 0.9382\n",
      "Epoch 242/800\n",
      "480/480 [==============================] - 0s 96us/step - loss: 0.2155 - accuracy: 0.9398 - val_loss: 0.2244 - val_accuracy: 0.9382\n",
      "Epoch 243/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2155 - accuracy: 0.9398 - val_loss: 0.2244 - val_accuracy: 0.9382\n",
      "Epoch 244/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2154 - accuracy: 0.9398 - val_loss: 0.2243 - val_accuracy: 0.9382\n",
      "Epoch 245/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2153 - accuracy: 0.9398 - val_loss: 0.2242 - val_accuracy: 0.9382\n",
      "Epoch 246/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2152 - accuracy: 0.9398 - val_loss: 0.2242 - val_accuracy: 0.9382\n",
      "Epoch 247/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2152 - accuracy: 0.9398 - val_loss: 0.2241 - val_accuracy: 0.9382\n",
      "Epoch 248/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2151 - accuracy: 0.9398 - val_loss: 0.2241 - val_accuracy: 0.9382\n",
      "Epoch 249/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2150 - accuracy: 0.9398 - val_loss: 0.2240 - val_accuracy: 0.9382\n",
      "Epoch 250/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.2149 - accuracy: 0.9398 - val_loss: 0.2240 - val_accuracy: 0.9382\n",
      "Epoch 251/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2149 - accuracy: 0.9398 - val_loss: 0.2239 - val_accuracy: 0.9382\n",
      "Epoch 252/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.2149 - accuracy: 0.9398 - val_loss: 0.2239 - val_accuracy: 0.9382\n",
      "Epoch 253/800\n",
      "480/480 [==============================] - 0s 100us/step - loss: 0.2148 - accuracy: 0.9398 - val_loss: 0.2238 - val_accuracy: 0.9382\n",
      "Epoch 254/800\n",
      "480/480 [==============================] - 0s 98us/step - loss: 0.2147 - accuracy: 0.9398 - val_loss: 0.2238 - val_accuracy: 0.9382\n",
      "Epoch 255/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2146 - accuracy: 0.9398 - val_loss: 0.2238 - val_accuracy: 0.9382\n",
      "Epoch 256/800\n",
      "480/480 [==============================] - 0s 96us/step - loss: 0.2145 - accuracy: 0.9398 - val_loss: 0.2236 - val_accuracy: 0.9382\n",
      "Epoch 257/800\n",
      "480/480 [==============================] - 0s 102us/step - loss: 0.2145 - accuracy: 0.9398 - val_loss: 0.2236 - val_accuracy: 0.9382\n",
      "Epoch 258/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.2144 - accuracy: 0.9398 - val_loss: 0.2235 - val_accuracy: 0.9382\n",
      "Epoch 259/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2143 - accuracy: 0.9398 - val_loss: 0.2235 - val_accuracy: 0.9382\n",
      "Epoch 260/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2142 - accuracy: 0.9398 - val_loss: 0.2234 - val_accuracy: 0.9382\n",
      "Epoch 261/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2142 - accuracy: 0.9398 - val_loss: 0.2234 - val_accuracy: 0.9382\n",
      "Epoch 262/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2140 - accuracy: 0.9398 - val_loss: 0.2233 - val_accuracy: 0.9382\n",
      "Epoch 263/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2140 - accuracy: 0.9398 - val_loss: 0.2233 - val_accuracy: 0.9382\n",
      "Epoch 264/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2139 - accuracy: 0.9398 - val_loss: 0.2232 - val_accuracy: 0.9382\n",
      "Epoch 265/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2138 - accuracy: 0.9398 - val_loss: 0.2231 - val_accuracy: 0.9382\n",
      "Epoch 266/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2137 - accuracy: 0.9398 - val_loss: 0.2231 - val_accuracy: 0.9382\n",
      "Epoch 267/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2136 - accuracy: 0.9398 - val_loss: 0.2230 - val_accuracy: 0.9382\n",
      "Epoch 268/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2136 - accuracy: 0.9398 - val_loss: 0.2229 - val_accuracy: 0.9382\n",
      "Epoch 269/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2135 - accuracy: 0.9398 - val_loss: 0.2229 - val_accuracy: 0.9382\n",
      "Epoch 270/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2134 - accuracy: 0.9398 - val_loss: 0.2228 - val_accuracy: 0.9382\n",
      "Epoch 271/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2133 - accuracy: 0.9398 - val_loss: 0.2228 - val_accuracy: 0.9382\n",
      "Epoch 272/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2132 - accuracy: 0.9398 - val_loss: 0.2227 - val_accuracy: 0.9382\n",
      "Epoch 273/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2131 - accuracy: 0.9398 - val_loss: 0.2226 - val_accuracy: 0.9382\n",
      "Epoch 274/800\n",
      "480/480 [==============================] - 0s 104us/step - loss: 0.2131 - accuracy: 0.9398 - val_loss: 0.2226 - val_accuracy: 0.9382\n",
      "Epoch 275/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2130 - accuracy: 0.9398 - val_loss: 0.2225 - val_accuracy: 0.9382\n",
      "Epoch 276/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2129 - accuracy: 0.9398 - val_loss: 0.2225 - val_accuracy: 0.9382\n",
      "Epoch 277/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2127 - accuracy: 0.9398 - val_loss: 0.2224 - val_accuracy: 0.9382\n",
      "Epoch 278/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2126 - accuracy: 0.9398 - val_loss: 0.2223 - val_accuracy: 0.9382\n",
      "Epoch 279/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2126 - accuracy: 0.9398 - val_loss: 0.2221 - val_accuracy: 0.9382\n",
      "Epoch 280/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 88us/step - loss: 0.2124 - accuracy: 0.9398 - val_loss: 0.2221 - val_accuracy: 0.9382\n",
      "Epoch 281/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2123 - accuracy: 0.9398 - val_loss: 0.2220 - val_accuracy: 0.9382\n",
      "Epoch 282/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2122 - accuracy: 0.9398 - val_loss: 0.2220 - val_accuracy: 0.9382\n",
      "Epoch 283/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2121 - accuracy: 0.9398 - val_loss: 0.2219 - val_accuracy: 0.9382\n",
      "Epoch 284/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2120 - accuracy: 0.9398 - val_loss: 0.2218 - val_accuracy: 0.9382\n",
      "Epoch 285/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2119 - accuracy: 0.9398 - val_loss: 0.2217 - val_accuracy: 0.9382\n",
      "Epoch 286/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.2118 - accuracy: 0.9398 - val_loss: 0.2217 - val_accuracy: 0.9382\n",
      "Epoch 287/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2117 - accuracy: 0.9398 - val_loss: 0.2215 - val_accuracy: 0.9382\n",
      "Epoch 288/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2116 - accuracy: 0.9398 - val_loss: 0.2215 - val_accuracy: 0.9382\n",
      "Epoch 289/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2115 - accuracy: 0.9398 - val_loss: 0.2214 - val_accuracy: 0.9382\n",
      "Epoch 290/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2114 - accuracy: 0.9398 - val_loss: 0.2213 - val_accuracy: 0.9382\n",
      "Epoch 291/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2113 - accuracy: 0.9398 - val_loss: 0.2212 - val_accuracy: 0.9382\n",
      "Epoch 292/800\n",
      "480/480 [==============================] - 0s 150us/step - loss: 0.2112 - accuracy: 0.9398 - val_loss: 0.2211 - val_accuracy: 0.9382\n",
      "Epoch 293/800\n",
      "480/480 [==============================] - 0s 113us/step - loss: 0.2110 - accuracy: 0.9398 - val_loss: 0.2210 - val_accuracy: 0.9382\n",
      "Epoch 294/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.2109 - accuracy: 0.9398 - val_loss: 0.2210 - val_accuracy: 0.9382\n",
      "Epoch 295/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.2107 - accuracy: 0.9398 - val_loss: 0.2209 - val_accuracy: 0.9382\n",
      "Epoch 296/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2106 - accuracy: 0.9398 - val_loss: 0.2208 - val_accuracy: 0.9382\n",
      "Epoch 297/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2105 - accuracy: 0.9398 - val_loss: 0.2207 - val_accuracy: 0.9382\n",
      "Epoch 298/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2104 - accuracy: 0.9398 - val_loss: 0.2206 - val_accuracy: 0.9382\n",
      "Epoch 299/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2102 - accuracy: 0.9398 - val_loss: 0.2205 - val_accuracy: 0.9382\n",
      "Epoch 300/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2101 - accuracy: 0.9398 - val_loss: 0.2204 - val_accuracy: 0.9382\n",
      "Epoch 301/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2100 - accuracy: 0.9398 - val_loss: 0.2203 - val_accuracy: 0.9382\n",
      "Epoch 302/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2099 - accuracy: 0.9398 - val_loss: 0.2203 - val_accuracy: 0.9382\n",
      "Epoch 303/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2098 - accuracy: 0.9398 - val_loss: 0.2201 - val_accuracy: 0.9382\n",
      "Epoch 304/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2097 - accuracy: 0.9398 - val_loss: 0.2201 - val_accuracy: 0.9382\n",
      "Epoch 305/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2095 - accuracy: 0.9398 - val_loss: 0.2200 - val_accuracy: 0.9382\n",
      "Epoch 306/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2094 - accuracy: 0.9398 - val_loss: 0.2199 - val_accuracy: 0.9382\n",
      "Epoch 307/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2093 - accuracy: 0.9398 - val_loss: 0.2197 - val_accuracy: 0.9382\n",
      "Epoch 308/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2091 - accuracy: 0.9398 - val_loss: 0.2196 - val_accuracy: 0.9382\n",
      "Epoch 309/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.2090 - accuracy: 0.9398 - val_loss: 0.2195 - val_accuracy: 0.9382\n",
      "Epoch 310/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2089 - accuracy: 0.9398 - val_loss: 0.2194 - val_accuracy: 0.9382\n",
      "Epoch 311/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2087 - accuracy: 0.9398 - val_loss: 0.2194 - val_accuracy: 0.9382\n",
      "Epoch 312/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2086 - accuracy: 0.9398 - val_loss: 0.2192 - val_accuracy: 0.9382\n",
      "Epoch 313/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2085 - accuracy: 0.9398 - val_loss: 0.2192 - val_accuracy: 0.9382\n",
      "Epoch 314/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2083 - accuracy: 0.9398 - val_loss: 0.2191 - val_accuracy: 0.9382\n",
      "Epoch 315/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2083 - accuracy: 0.9398 - val_loss: 0.2190 - val_accuracy: 0.9382\n",
      "Epoch 316/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2081 - accuracy: 0.9398 - val_loss: 0.2189 - val_accuracy: 0.9382\n",
      "Epoch 317/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.2080 - accuracy: 0.9398 - val_loss: 0.2188 - val_accuracy: 0.9382\n",
      "Epoch 318/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2079 - accuracy: 0.9398 - val_loss: 0.2187 - val_accuracy: 0.9382\n",
      "Epoch 319/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2077 - accuracy: 0.9398 - val_loss: 0.2186 - val_accuracy: 0.9382\n",
      "Epoch 320/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2076 - accuracy: 0.9398 - val_loss: 0.2185 - val_accuracy: 0.9382\n",
      "Epoch 321/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2074 - accuracy: 0.9398 - val_loss: 0.2184 - val_accuracy: 0.9382\n",
      "Epoch 322/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2073 - accuracy: 0.9398 - val_loss: 0.2183 - val_accuracy: 0.9382\n",
      "Epoch 323/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2072 - accuracy: 0.9398 - val_loss: 0.2181 - val_accuracy: 0.9382\n",
      "Epoch 324/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2070 - accuracy: 0.9398 - val_loss: 0.2181 - val_accuracy: 0.9382\n",
      "Epoch 325/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2069 - accuracy: 0.9398 - val_loss: 0.2180 - val_accuracy: 0.9382\n",
      "Epoch 326/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2067 - accuracy: 0.9398 - val_loss: 0.2178 - val_accuracy: 0.9382\n",
      "Epoch 327/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2066 - accuracy: 0.9398 - val_loss: 0.2177 - val_accuracy: 0.9382\n",
      "Epoch 328/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2065 - accuracy: 0.9398 - val_loss: 0.2176 - val_accuracy: 0.9382\n",
      "Epoch 329/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2063 - accuracy: 0.9398 - val_loss: 0.2175 - val_accuracy: 0.9382\n",
      "Epoch 330/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2062 - accuracy: 0.9398 - val_loss: 0.2174 - val_accuracy: 0.9382\n",
      "Epoch 331/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2061 - accuracy: 0.9398 - val_loss: 0.2173 - val_accuracy: 0.9382\n",
      "Epoch 332/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2060 - accuracy: 0.9398 - val_loss: 0.2172 - val_accuracy: 0.9382\n",
      "Epoch 333/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2058 - accuracy: 0.9398 - val_loss: 0.2171 - val_accuracy: 0.9382\n",
      "Epoch 334/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2057 - accuracy: 0.9398 - val_loss: 0.2170 - val_accuracy: 0.9382\n",
      "Epoch 335/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2055 - accuracy: 0.9398 - val_loss: 0.2169 - val_accuracy: 0.9382\n",
      "Epoch 336/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 88us/step - loss: 0.2054 - accuracy: 0.9398 - val_loss: 0.2168 - val_accuracy: 0.9382\n",
      "Epoch 337/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2053 - accuracy: 0.9398 - val_loss: 0.2167 - val_accuracy: 0.9382\n",
      "Epoch 338/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2051 - accuracy: 0.9398 - val_loss: 0.2166 - val_accuracy: 0.9382\n",
      "Epoch 339/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2050 - accuracy: 0.9398 - val_loss: 0.2165 - val_accuracy: 0.9382\n",
      "Epoch 340/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2049 - accuracy: 0.9398 - val_loss: 0.2164 - val_accuracy: 0.9382\n",
      "Epoch 341/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2047 - accuracy: 0.9398 - val_loss: 0.2163 - val_accuracy: 0.9382\n",
      "Epoch 342/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2046 - accuracy: 0.9398 - val_loss: 0.2162 - val_accuracy: 0.9382\n",
      "Epoch 343/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2044 - accuracy: 0.9398 - val_loss: 0.2161 - val_accuracy: 0.9382\n",
      "Epoch 344/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2043 - accuracy: 0.9398 - val_loss: 0.2160 - val_accuracy: 0.9382\n",
      "Epoch 345/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2042 - accuracy: 0.9398 - val_loss: 0.2159 - val_accuracy: 0.9382\n",
      "Epoch 346/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2041 - accuracy: 0.9398 - val_loss: 0.2158 - val_accuracy: 0.9382\n",
      "Epoch 347/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2039 - accuracy: 0.9398 - val_loss: 0.2157 - val_accuracy: 0.9382\n",
      "Epoch 348/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2038 - accuracy: 0.9398 - val_loss: 0.2157 - val_accuracy: 0.9382\n",
      "Epoch 349/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2036 - accuracy: 0.9398 - val_loss: 0.2155 - val_accuracy: 0.9382\n",
      "Epoch 350/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2035 - accuracy: 0.9398 - val_loss: 0.2154 - val_accuracy: 0.9382\n",
      "Epoch 351/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2033 - accuracy: 0.9398 - val_loss: 0.2153 - val_accuracy: 0.9382\n",
      "Epoch 352/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2032 - accuracy: 0.9398 - val_loss: 0.2152 - val_accuracy: 0.9382\n",
      "Epoch 353/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2031 - accuracy: 0.9398 - val_loss: 0.2151 - val_accuracy: 0.9382\n",
      "Epoch 354/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2029 - accuracy: 0.9398 - val_loss: 0.2150 - val_accuracy: 0.9382\n",
      "Epoch 355/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2028 - accuracy: 0.9398 - val_loss: 0.2149 - val_accuracy: 0.9382\n",
      "Epoch 356/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2027 - accuracy: 0.9398 - val_loss: 0.2148 - val_accuracy: 0.9382\n",
      "Epoch 357/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2025 - accuracy: 0.9398 - val_loss: 0.2147 - val_accuracy: 0.9382\n",
      "Epoch 358/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2024 - accuracy: 0.9398 - val_loss: 0.2146 - val_accuracy: 0.9382\n",
      "Epoch 359/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2023 - accuracy: 0.9398 - val_loss: 0.2145 - val_accuracy: 0.9382\n",
      "Epoch 360/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2021 - accuracy: 0.9398 - val_loss: 0.2143 - val_accuracy: 0.9382\n",
      "Epoch 361/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2020 - accuracy: 0.9398 - val_loss: 0.2143 - val_accuracy: 0.9382\n",
      "Epoch 362/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2019 - accuracy: 0.9398 - val_loss: 0.2142 - val_accuracy: 0.9382\n",
      "Epoch 363/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.2017 - accuracy: 0.9398 - val_loss: 0.2141 - val_accuracy: 0.9382\n",
      "Epoch 364/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.2016 - accuracy: 0.9398 - val_loss: 0.2140 - val_accuracy: 0.9382\n",
      "Epoch 365/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2014 - accuracy: 0.9398 - val_loss: 0.2139 - val_accuracy: 0.9382\n",
      "Epoch 366/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.2013 - accuracy: 0.9399 - val_loss: 0.2138 - val_accuracy: 0.9382\n",
      "Epoch 367/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2012 - accuracy: 0.9398 - val_loss: 0.2137 - val_accuracy: 0.9382\n",
      "Epoch 368/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2010 - accuracy: 0.9398 - val_loss: 0.2136 - val_accuracy: 0.9382\n",
      "Epoch 369/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2009 - accuracy: 0.9397 - val_loss: 0.2135 - val_accuracy: 0.9382\n",
      "Epoch 370/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2008 - accuracy: 0.9398 - val_loss: 0.2134 - val_accuracy: 0.9382\n",
      "Epoch 371/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2006 - accuracy: 0.9397 - val_loss: 0.2133 - val_accuracy: 0.9381\n",
      "Epoch 372/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2005 - accuracy: 0.9398 - val_loss: 0.2132 - val_accuracy: 0.9381\n",
      "Epoch 373/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.2004 - accuracy: 0.9398 - val_loss: 0.2131 - val_accuracy: 0.9381\n",
      "Epoch 374/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.2002 - accuracy: 0.9398 - val_loss: 0.2130 - val_accuracy: 0.9381\n",
      "Epoch 375/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.2001 - accuracy: 0.9399 - val_loss: 0.2129 - val_accuracy: 0.9381\n",
      "Epoch 376/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.2000 - accuracy: 0.9398 - val_loss: 0.2128 - val_accuracy: 0.9381\n",
      "Epoch 377/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1998 - accuracy: 0.9399 - val_loss: 0.2127 - val_accuracy: 0.9381\n",
      "Epoch 378/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1997 - accuracy: 0.9399 - val_loss: 0.2126 - val_accuracy: 0.9381\n",
      "Epoch 379/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1996 - accuracy: 0.9399 - val_loss: 0.2125 - val_accuracy: 0.9381\n",
      "Epoch 380/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1994 - accuracy: 0.9399 - val_loss: 0.2123 - val_accuracy: 0.9381\n",
      "Epoch 381/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1993 - accuracy: 0.9398 - val_loss: 0.2123 - val_accuracy: 0.9381\n",
      "Epoch 382/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1992 - accuracy: 0.9399 - val_loss: 0.2123 - val_accuracy: 0.9381\n",
      "Epoch 383/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1990 - accuracy: 0.9399 - val_loss: 0.2122 - val_accuracy: 0.9381\n",
      "Epoch 384/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1989 - accuracy: 0.9399 - val_loss: 0.2121 - val_accuracy: 0.9381\n",
      "Epoch 385/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1988 - accuracy: 0.9399 - val_loss: 0.2119 - val_accuracy: 0.9381\n",
      "Epoch 386/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1986 - accuracy: 0.9400 - val_loss: 0.2119 - val_accuracy: 0.9381\n",
      "Epoch 387/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1985 - accuracy: 0.9399 - val_loss: 0.2118 - val_accuracy: 0.9381\n",
      "Epoch 388/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1984 - accuracy: 0.9399 - val_loss: 0.2117 - val_accuracy: 0.9381\n",
      "Epoch 389/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1982 - accuracy: 0.9399 - val_loss: 0.2116 - val_accuracy: 0.9381\n",
      "Epoch 390/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1980 - accuracy: 0.9400 - val_loss: 0.2116 - val_accuracy: 0.9381\n",
      "Epoch 391/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1979 - accuracy: 0.9399 - val_loss: 0.2114 - val_accuracy: 0.9384\n",
      "Epoch 392/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 81us/step - loss: 0.1978 - accuracy: 0.9400 - val_loss: 0.2113 - val_accuracy: 0.9382\n",
      "Epoch 393/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1976 - accuracy: 0.9399 - val_loss: 0.2112 - val_accuracy: 0.9381\n",
      "Epoch 394/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1975 - accuracy: 0.9400 - val_loss: 0.2111 - val_accuracy: 0.9382\n",
      "Epoch 395/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1973 - accuracy: 0.9400 - val_loss: 0.2111 - val_accuracy: 0.9382\n",
      "Epoch 396/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1972 - accuracy: 0.9399 - val_loss: 0.2110 - val_accuracy: 0.9382\n",
      "Epoch 397/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1971 - accuracy: 0.9400 - val_loss: 0.2109 - val_accuracy: 0.9384\n",
      "Epoch 398/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1970 - accuracy: 0.9399 - val_loss: 0.2107 - val_accuracy: 0.9384\n",
      "Epoch 399/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1968 - accuracy: 0.9399 - val_loss: 0.2106 - val_accuracy: 0.9384\n",
      "Epoch 400/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1967 - accuracy: 0.9399 - val_loss: 0.2105 - val_accuracy: 0.9384\n",
      "Epoch 401/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1965 - accuracy: 0.9399 - val_loss: 0.2104 - val_accuracy: 0.9384\n",
      "Epoch 402/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1964 - accuracy: 0.9400 - val_loss: 0.2103 - val_accuracy: 0.9384\n",
      "Epoch 403/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1963 - accuracy: 0.9399 - val_loss: 0.2102 - val_accuracy: 0.9384\n",
      "Epoch 404/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1961 - accuracy: 0.9400 - val_loss: 0.2102 - val_accuracy: 0.9384\n",
      "Epoch 405/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1960 - accuracy: 0.9400 - val_loss: 0.2101 - val_accuracy: 0.9384\n",
      "Epoch 406/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1959 - accuracy: 0.9399 - val_loss: 0.2099 - val_accuracy: 0.9384\n",
      "Epoch 407/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1958 - accuracy: 0.9400 - val_loss: 0.2099 - val_accuracy: 0.9384\n",
      "Epoch 408/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1955 - accuracy: 0.9400 - val_loss: 0.2098 - val_accuracy: 0.9384\n",
      "Epoch 409/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1954 - accuracy: 0.9399 - val_loss: 0.2097 - val_accuracy: 0.9384\n",
      "Epoch 410/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1953 - accuracy: 0.9400 - val_loss: 0.2096 - val_accuracy: 0.9385\n",
      "Epoch 411/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1951 - accuracy: 0.9401 - val_loss: 0.2096 - val_accuracy: 0.9384\n",
      "Epoch 412/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1950 - accuracy: 0.9400 - val_loss: 0.2095 - val_accuracy: 0.9385\n",
      "Epoch 413/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1948 - accuracy: 0.9400 - val_loss: 0.2093 - val_accuracy: 0.9384\n",
      "Epoch 414/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1947 - accuracy: 0.9401 - val_loss: 0.2092 - val_accuracy: 0.9385\n",
      "Epoch 415/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1946 - accuracy: 0.9400 - val_loss: 0.2092 - val_accuracy: 0.9385\n",
      "Epoch 416/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1944 - accuracy: 0.9401 - val_loss: 0.2091 - val_accuracy: 0.9386\n",
      "Epoch 417/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1943 - accuracy: 0.9400 - val_loss: 0.2090 - val_accuracy: 0.9386\n",
      "Epoch 418/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1941 - accuracy: 0.9402 - val_loss: 0.2089 - val_accuracy: 0.9387\n",
      "Epoch 419/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1940 - accuracy: 0.9402 - val_loss: 0.2088 - val_accuracy: 0.9387\n",
      "Epoch 420/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1938 - accuracy: 0.9403 - val_loss: 0.2087 - val_accuracy: 0.9387\n",
      "Epoch 421/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1938 - accuracy: 0.9402 - val_loss: 0.2087 - val_accuracy: 0.9387\n",
      "Epoch 422/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1935 - accuracy: 0.9402 - val_loss: 0.2085 - val_accuracy: 0.9387\n",
      "Epoch 423/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1934 - accuracy: 0.9402 - val_loss: 0.2084 - val_accuracy: 0.9387\n",
      "Epoch 424/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1932 - accuracy: 0.9403 - val_loss: 0.2083 - val_accuracy: 0.9387\n",
      "Epoch 425/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1931 - accuracy: 0.9403 - val_loss: 0.2082 - val_accuracy: 0.9387\n",
      "Epoch 426/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1930 - accuracy: 0.9403 - val_loss: 0.2082 - val_accuracy: 0.9387\n",
      "Epoch 427/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1929 - accuracy: 0.9404 - val_loss: 0.2080 - val_accuracy: 0.9387\n",
      "Epoch 428/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1927 - accuracy: 0.9403 - val_loss: 0.2081 - val_accuracy: 0.9386\n",
      "Epoch 429/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1926 - accuracy: 0.9403 - val_loss: 0.2079 - val_accuracy: 0.9387\n",
      "Epoch 430/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1924 - accuracy: 0.9404 - val_loss: 0.2078 - val_accuracy: 0.9387\n",
      "Epoch 431/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1923 - accuracy: 0.9403 - val_loss: 0.2077 - val_accuracy: 0.9387\n",
      "Epoch 432/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1921 - accuracy: 0.9404 - val_loss: 0.2076 - val_accuracy: 0.9387\n",
      "Epoch 433/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1920 - accuracy: 0.9403 - val_loss: 0.2077 - val_accuracy: 0.9387\n",
      "Epoch 434/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1918 - accuracy: 0.9403 - val_loss: 0.2075 - val_accuracy: 0.9388\n",
      "Epoch 435/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1917 - accuracy: 0.9404 - val_loss: 0.2074 - val_accuracy: 0.9388\n",
      "Epoch 436/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1916 - accuracy: 0.9404 - val_loss: 0.2072 - val_accuracy: 0.9388\n",
      "Epoch 437/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1914 - accuracy: 0.9404 - val_loss: 0.2071 - val_accuracy: 0.9387\n",
      "Epoch 438/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1913 - accuracy: 0.9404 - val_loss: 0.2070 - val_accuracy: 0.9387\n",
      "Epoch 439/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1911 - accuracy: 0.9405 - val_loss: 0.2070 - val_accuracy: 0.9388\n",
      "Epoch 440/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1910 - accuracy: 0.9405 - val_loss: 0.2069 - val_accuracy: 0.9387\n",
      "Epoch 441/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1908 - accuracy: 0.9404 - val_loss: 0.2067 - val_accuracy: 0.9387\n",
      "Epoch 442/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1907 - accuracy: 0.9404 - val_loss: 0.2066 - val_accuracy: 0.9387\n",
      "Epoch 443/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1905 - accuracy: 0.9404 - val_loss: 0.2066 - val_accuracy: 0.9387\n",
      "Epoch 444/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.1904 - accuracy: 0.9404 - val_loss: 0.2065 - val_accuracy: 0.9387\n",
      "Epoch 445/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1902 - accuracy: 0.9405 - val_loss: 0.2063 - val_accuracy: 0.9388\n",
      "Epoch 446/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.1901 - accuracy: 0.9404 - val_loss: 0.2064 - val_accuracy: 0.9390\n",
      "Epoch 447/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1900 - accuracy: 0.9404 - val_loss: 0.2062 - val_accuracy: 0.9388\n",
      "Epoch 448/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.1898 - accuracy: 0.9405 - val_loss: 0.2061 - val_accuracy: 0.9388\n",
      "Epoch 449/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1897 - accuracy: 0.9404 - val_loss: 0.2061 - val_accuracy: 0.9387\n",
      "Epoch 450/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1895 - accuracy: 0.9404 - val_loss: 0.2060 - val_accuracy: 0.9387\n",
      "Epoch 451/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1894 - accuracy: 0.9405 - val_loss: 0.2058 - val_accuracy: 0.9388\n",
      "Epoch 452/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1893 - accuracy: 0.9404 - val_loss: 0.2057 - val_accuracy: 0.9388\n",
      "Epoch 453/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1891 - accuracy: 0.9405 - val_loss: 0.2057 - val_accuracy: 0.9388\n",
      "Epoch 454/800\n",
      "480/480 [==============================] - 0s 79us/step - loss: 0.1890 - accuracy: 0.9404 - val_loss: 0.2057 - val_accuracy: 0.9388\n",
      "Epoch 455/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1888 - accuracy: 0.9404 - val_loss: 0.2055 - val_accuracy: 0.9390\n",
      "Epoch 456/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1887 - accuracy: 0.9404 - val_loss: 0.2056 - val_accuracy: 0.9390\n",
      "Epoch 457/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1885 - accuracy: 0.9405 - val_loss: 0.2054 - val_accuracy: 0.9391\n",
      "Epoch 458/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1884 - accuracy: 0.9404 - val_loss: 0.2052 - val_accuracy: 0.9388\n",
      "Epoch 459/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1882 - accuracy: 0.9405 - val_loss: 0.2052 - val_accuracy: 0.9388\n",
      "Epoch 460/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1881 - accuracy: 0.9403 - val_loss: 0.2052 - val_accuracy: 0.9388\n",
      "Epoch 461/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1880 - accuracy: 0.9404 - val_loss: 0.2051 - val_accuracy: 0.9388\n",
      "Epoch 462/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1878 - accuracy: 0.9404 - val_loss: 0.2049 - val_accuracy: 0.9391\n",
      "Epoch 463/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1877 - accuracy: 0.9404 - val_loss: 0.2047 - val_accuracy: 0.9390\n",
      "Epoch 464/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1875 - accuracy: 0.9403 - val_loss: 0.2049 - val_accuracy: 0.9390\n",
      "Epoch 465/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1874 - accuracy: 0.9404 - val_loss: 0.2047 - val_accuracy: 0.9390\n",
      "Epoch 466/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1872 - accuracy: 0.9404 - val_loss: 0.2047 - val_accuracy: 0.9390\n",
      "Epoch 467/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1872 - accuracy: 0.9405 - val_loss: 0.2045 - val_accuracy: 0.9391\n",
      "Epoch 468/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1869 - accuracy: 0.9404 - val_loss: 0.2044 - val_accuracy: 0.9390\n",
      "Epoch 469/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1868 - accuracy: 0.9404 - val_loss: 0.2044 - val_accuracy: 0.9391\n",
      "Epoch 470/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1867 - accuracy: 0.9403 - val_loss: 0.2044 - val_accuracy: 0.9391\n",
      "Epoch 471/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1865 - accuracy: 0.9404 - val_loss: 0.2041 - val_accuracy: 0.9390\n",
      "Epoch 472/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1864 - accuracy: 0.9404 - val_loss: 0.2040 - val_accuracy: 0.9391\n",
      "Epoch 473/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1862 - accuracy: 0.9404 - val_loss: 0.2039 - val_accuracy: 0.9391\n",
      "Epoch 474/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1862 - accuracy: 0.9404 - val_loss: 0.2039 - val_accuracy: 0.9391\n",
      "Epoch 475/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1860 - accuracy: 0.9404 - val_loss: 0.2038 - val_accuracy: 0.9391\n",
      "Epoch 476/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1859 - accuracy: 0.9404 - val_loss: 0.2037 - val_accuracy: 0.9391\n",
      "Epoch 477/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1856 - accuracy: 0.9404 - val_loss: 0.2037 - val_accuracy: 0.9391\n",
      "Epoch 478/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1856 - accuracy: 0.9406 - val_loss: 0.2035 - val_accuracy: 0.9391\n",
      "Epoch 479/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1854 - accuracy: 0.9406 - val_loss: 0.2035 - val_accuracy: 0.9391\n",
      "Epoch 480/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1852 - accuracy: 0.9404 - val_loss: 0.2034 - val_accuracy: 0.9391\n",
      "Epoch 481/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1852 - accuracy: 0.9406 - val_loss: 0.2034 - val_accuracy: 0.9391\n",
      "Epoch 482/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1850 - accuracy: 0.9406 - val_loss: 0.2032 - val_accuracy: 0.9391\n",
      "Epoch 483/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1848 - accuracy: 0.9405 - val_loss: 0.2031 - val_accuracy: 0.9392\n",
      "Epoch 484/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1847 - accuracy: 0.9404 - val_loss: 0.2030 - val_accuracy: 0.9390\n",
      "Epoch 485/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1845 - accuracy: 0.9405 - val_loss: 0.2030 - val_accuracy: 0.9391\n",
      "Epoch 486/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1844 - accuracy: 0.9407 - val_loss: 0.2029 - val_accuracy: 0.9391\n",
      "Epoch 487/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1843 - accuracy: 0.9404 - val_loss: 0.2029 - val_accuracy: 0.9390\n",
      "Epoch 488/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1842 - accuracy: 0.9404 - val_loss: 0.2028 - val_accuracy: 0.9391\n",
      "Epoch 489/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1840 - accuracy: 0.9404 - val_loss: 0.2027 - val_accuracy: 0.9391\n",
      "Epoch 490/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1839 - accuracy: 0.9406 - val_loss: 0.2026 - val_accuracy: 0.9391\n",
      "Epoch 491/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1837 - accuracy: 0.9408 - val_loss: 0.2025 - val_accuracy: 0.9391\n",
      "Epoch 492/800\n",
      "480/480 [==============================] - 0s 86us/step - loss: 0.1836 - accuracy: 0.9406 - val_loss: 0.2025 - val_accuracy: 0.9391\n",
      "Epoch 493/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1835 - accuracy: 0.9407 - val_loss: 0.2022 - val_accuracy: 0.9391\n",
      "Epoch 494/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1833 - accuracy: 0.9408 - val_loss: 0.2022 - val_accuracy: 0.9390\n",
      "Epoch 495/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1832 - accuracy: 0.9406 - val_loss: 0.2023 - val_accuracy: 0.9390\n",
      "Epoch 496/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1830 - accuracy: 0.9408 - val_loss: 0.2021 - val_accuracy: 0.9390\n",
      "Epoch 497/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1829 - accuracy: 0.9406 - val_loss: 0.2020 - val_accuracy: 0.9390\n",
      "Epoch 498/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1827 - accuracy: 0.9407 - val_loss: 0.2019 - val_accuracy: 0.9388\n",
      "Epoch 499/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1826 - accuracy: 0.9408 - val_loss: 0.2018 - val_accuracy: 0.9388\n",
      "Epoch 500/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1825 - accuracy: 0.9406 - val_loss: 0.2017 - val_accuracy: 0.9388\n",
      "Epoch 501/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1823 - accuracy: 0.9405 - val_loss: 0.2017 - val_accuracy: 0.9388\n",
      "Epoch 502/800\n",
      "480/480 [==============================] - 0s 98us/step - loss: 0.1822 - accuracy: 0.9408 - val_loss: 0.2017 - val_accuracy: 0.9390\n",
      "Epoch 503/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1820 - accuracy: 0.9409 - val_loss: 0.2017 - val_accuracy: 0.9390\n",
      "Epoch 504/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.1819 - accuracy: 0.9408 - val_loss: 0.2015 - val_accuracy: 0.9391\n",
      "Epoch 505/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1818 - accuracy: 0.9408 - val_loss: 0.2014 - val_accuracy: 0.9390\n",
      "Epoch 506/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1816 - accuracy: 0.9406 - val_loss: 0.2014 - val_accuracy: 0.9390\n",
      "Epoch 507/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1815 - accuracy: 0.9410 - val_loss: 0.2014 - val_accuracy: 0.9388\n",
      "Epoch 508/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1813 - accuracy: 0.9408 - val_loss: 0.2010 - val_accuracy: 0.9387\n",
      "Epoch 509/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1812 - accuracy: 0.9408 - val_loss: 0.2009 - val_accuracy: 0.9388\n",
      "Epoch 510/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1811 - accuracy: 0.9408 - val_loss: 0.2009 - val_accuracy: 0.9390\n",
      "Epoch 511/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1809 - accuracy: 0.9411 - val_loss: 0.2007 - val_accuracy: 0.9386\n",
      "Epoch 512/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1808 - accuracy: 0.9410 - val_loss: 0.2007 - val_accuracy: 0.9387\n",
      "Epoch 513/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1807 - accuracy: 0.9409 - val_loss: 0.2005 - val_accuracy: 0.9388\n",
      "Epoch 514/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1805 - accuracy: 0.9408 - val_loss: 0.2006 - val_accuracy: 0.9390\n",
      "Epoch 515/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1804 - accuracy: 0.9408 - val_loss: 0.2004 - val_accuracy: 0.9387\n",
      "Epoch 516/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1802 - accuracy: 0.9408 - val_loss: 0.2002 - val_accuracy: 0.9391\n",
      "Epoch 517/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1801 - accuracy: 0.9409 - val_loss: 0.2001 - val_accuracy: 0.9388\n",
      "Epoch 518/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1799 - accuracy: 0.9411 - val_loss: 0.2000 - val_accuracy: 0.9390\n",
      "Epoch 519/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1797 - accuracy: 0.9410 - val_loss: 0.1998 - val_accuracy: 0.9387\n",
      "Epoch 520/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1796 - accuracy: 0.9412 - val_loss: 0.1997 - val_accuracy: 0.9390\n",
      "Epoch 521/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1795 - accuracy: 0.9409 - val_loss: 0.1998 - val_accuracy: 0.9388\n",
      "Epoch 522/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1793 - accuracy: 0.9409 - val_loss: 0.1998 - val_accuracy: 0.9388\n",
      "Epoch 523/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1791 - accuracy: 0.9412 - val_loss: 0.1998 - val_accuracy: 0.9387\n",
      "Epoch 524/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1790 - accuracy: 0.9411 - val_loss: 0.1997 - val_accuracy: 0.9388\n",
      "Epoch 525/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1789 - accuracy: 0.9411 - val_loss: 0.1994 - val_accuracy: 0.9388\n",
      "Epoch 526/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1788 - accuracy: 0.9413 - val_loss: 0.1992 - val_accuracy: 0.9388\n",
      "Epoch 527/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1785 - accuracy: 0.9411 - val_loss: 0.1993 - val_accuracy: 0.9390\n",
      "Epoch 528/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1784 - accuracy: 0.9413 - val_loss: 0.1993 - val_accuracy: 0.9387\n",
      "Epoch 529/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1783 - accuracy: 0.9410 - val_loss: 0.1992 - val_accuracy: 0.9388\n",
      "Epoch 530/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1781 - accuracy: 0.9414 - val_loss: 0.1990 - val_accuracy: 0.9387\n",
      "Epoch 531/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1780 - accuracy: 0.9411 - val_loss: 0.1989 - val_accuracy: 0.9388\n",
      "Epoch 532/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1778 - accuracy: 0.9413 - val_loss: 0.1989 - val_accuracy: 0.9388\n",
      "Epoch 533/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1777 - accuracy: 0.9413 - val_loss: 0.1987 - val_accuracy: 0.9388\n",
      "Epoch 534/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1776 - accuracy: 0.9411 - val_loss: 0.1986 - val_accuracy: 0.9388\n",
      "Epoch 535/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1774 - accuracy: 0.9412 - val_loss: 0.1985 - val_accuracy: 0.9387\n",
      "Epoch 536/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1772 - accuracy: 0.9411 - val_loss: 0.1983 - val_accuracy: 0.9387\n",
      "Epoch 537/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1771 - accuracy: 0.9411 - val_loss: 0.1985 - val_accuracy: 0.9386\n",
      "Epoch 538/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1770 - accuracy: 0.9412 - val_loss: 0.1984 - val_accuracy: 0.9388\n",
      "Epoch 539/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1767 - accuracy: 0.9412 - val_loss: 0.1982 - val_accuracy: 0.9388\n",
      "Epoch 540/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1766 - accuracy: 0.9411 - val_loss: 0.1979 - val_accuracy: 0.9386\n",
      "Epoch 541/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1764 - accuracy: 0.9411 - val_loss: 0.1979 - val_accuracy: 0.9386\n",
      "Epoch 542/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1764 - accuracy: 0.9413 - val_loss: 0.1978 - val_accuracy: 0.9387\n",
      "Epoch 543/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1763 - accuracy: 0.9414 - val_loss: 0.1977 - val_accuracy: 0.9390\n",
      "Epoch 544/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1760 - accuracy: 0.9415 - val_loss: 0.1976 - val_accuracy: 0.9390\n",
      "Epoch 545/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1759 - accuracy: 0.9414 - val_loss: 0.1975 - val_accuracy: 0.9390\n",
      "Epoch 546/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1758 - accuracy: 0.9411 - val_loss: 0.1976 - val_accuracy: 0.9386\n",
      "Epoch 547/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1756 - accuracy: 0.9413 - val_loss: 0.1974 - val_accuracy: 0.9390\n",
      "Epoch 548/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1754 - accuracy: 0.9413 - val_loss: 0.1974 - val_accuracy: 0.9391\n",
      "Epoch 549/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1753 - accuracy: 0.9412 - val_loss: 0.1973 - val_accuracy: 0.9386\n",
      "Epoch 550/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1751 - accuracy: 0.9413 - val_loss: 0.1970 - val_accuracy: 0.9388\n",
      "Epoch 551/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1749 - accuracy: 0.9413 - val_loss: 0.1969 - val_accuracy: 0.9391\n",
      "Epoch 552/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1748 - accuracy: 0.9413 - val_loss: 0.1968 - val_accuracy: 0.9385\n",
      "Epoch 553/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1747 - accuracy: 0.9414 - val_loss: 0.1969 - val_accuracy: 0.9388\n",
      "Epoch 554/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1745 - accuracy: 0.9413 - val_loss: 0.1968 - val_accuracy: 0.9391\n",
      "Epoch 555/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1743 - accuracy: 0.9417 - val_loss: 0.1964 - val_accuracy: 0.9388\n",
      "Epoch 556/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1743 - accuracy: 0.9414 - val_loss: 0.1964 - val_accuracy: 0.9388\n",
      "Epoch 557/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1741 - accuracy: 0.9417 - val_loss: 0.1964 - val_accuracy: 0.9390\n",
      "Epoch 558/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1738 - accuracy: 0.9415 - val_loss: 0.1962 - val_accuracy: 0.9387\n",
      "Epoch 559/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1737 - accuracy: 0.9414 - val_loss: 0.1961 - val_accuracy: 0.9391\n",
      "Epoch 560/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 83us/step - loss: 0.1736 - accuracy: 0.9415 - val_loss: 0.1961 - val_accuracy: 0.9390\n",
      "Epoch 561/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1734 - accuracy: 0.9416 - val_loss: 0.1959 - val_accuracy: 0.9388\n",
      "Epoch 562/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1733 - accuracy: 0.9415 - val_loss: 0.1957 - val_accuracy: 0.9388\n",
      "Epoch 563/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1731 - accuracy: 0.9415 - val_loss: 0.1958 - val_accuracy: 0.9391\n",
      "Epoch 564/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1730 - accuracy: 0.9415 - val_loss: 0.1958 - val_accuracy: 0.9391\n",
      "Epoch 565/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1728 - accuracy: 0.9416 - val_loss: 0.1957 - val_accuracy: 0.9391\n",
      "Epoch 566/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1726 - accuracy: 0.9415 - val_loss: 0.1958 - val_accuracy: 0.9388\n",
      "Epoch 567/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1725 - accuracy: 0.9417 - val_loss: 0.1955 - val_accuracy: 0.9390\n",
      "Epoch 568/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1724 - accuracy: 0.9417 - val_loss: 0.1955 - val_accuracy: 0.9390\n",
      "Epoch 569/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1722 - accuracy: 0.9420 - val_loss: 0.1954 - val_accuracy: 0.9390\n",
      "Epoch 570/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1720 - accuracy: 0.9417 - val_loss: 0.1951 - val_accuracy: 0.9390\n",
      "Epoch 571/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1719 - accuracy: 0.9418 - val_loss: 0.1950 - val_accuracy: 0.9388\n",
      "Epoch 572/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1717 - accuracy: 0.9415 - val_loss: 0.1951 - val_accuracy: 0.9390\n",
      "Epoch 573/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1715 - accuracy: 0.9417 - val_loss: 0.1952 - val_accuracy: 0.9393\n",
      "Epoch 574/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1715 - accuracy: 0.9416 - val_loss: 0.1949 - val_accuracy: 0.9391\n",
      "Epoch 575/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1713 - accuracy: 0.9420 - val_loss: 0.1947 - val_accuracy: 0.9391\n",
      "Epoch 576/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1712 - accuracy: 0.9418 - val_loss: 0.1947 - val_accuracy: 0.9391\n",
      "Epoch 577/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1710 - accuracy: 0.9417 - val_loss: 0.1945 - val_accuracy: 0.9390\n",
      "Epoch 578/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1709 - accuracy: 0.9418 - val_loss: 0.1943 - val_accuracy: 0.9391\n",
      "Epoch 579/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1707 - accuracy: 0.9420 - val_loss: 0.1944 - val_accuracy: 0.9391\n",
      "Epoch 580/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1706 - accuracy: 0.9419 - val_loss: 0.1943 - val_accuracy: 0.9390\n",
      "Epoch 581/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1704 - accuracy: 0.9420 - val_loss: 0.1942 - val_accuracy: 0.9391\n",
      "Epoch 582/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1703 - accuracy: 0.9420 - val_loss: 0.1943 - val_accuracy: 0.9391\n",
      "Epoch 583/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1701 - accuracy: 0.9420 - val_loss: 0.1941 - val_accuracy: 0.9391\n",
      "Epoch 584/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1699 - accuracy: 0.9420 - val_loss: 0.1943 - val_accuracy: 0.9390\n",
      "Epoch 585/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1698 - accuracy: 0.9417 - val_loss: 0.1940 - val_accuracy: 0.9391\n",
      "Epoch 586/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1697 - accuracy: 0.9422 - val_loss: 0.1938 - val_accuracy: 0.9393\n",
      "Epoch 587/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1695 - accuracy: 0.9423 - val_loss: 0.1938 - val_accuracy: 0.9391\n",
      "Epoch 588/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1693 - accuracy: 0.9421 - val_loss: 0.1938 - val_accuracy: 0.9391\n",
      "Epoch 589/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1692 - accuracy: 0.9420 - val_loss: 0.1937 - val_accuracy: 0.9391\n",
      "Epoch 590/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1691 - accuracy: 0.9419 - val_loss: 0.1935 - val_accuracy: 0.9391\n",
      "Epoch 591/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1688 - accuracy: 0.9421 - val_loss: 0.1934 - val_accuracy: 0.9390\n",
      "Epoch 592/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1687 - accuracy: 0.9418 - val_loss: 0.1934 - val_accuracy: 0.9388\n",
      "Epoch 593/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1686 - accuracy: 0.9422 - val_loss: 0.1933 - val_accuracy: 0.9391\n",
      "Epoch 594/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1685 - accuracy: 0.9423 - val_loss: 0.1935 - val_accuracy: 0.9392\n",
      "Epoch 595/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1684 - accuracy: 0.9422 - val_loss: 0.1929 - val_accuracy: 0.9392\n",
      "Epoch 596/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1681 - accuracy: 0.9424 - val_loss: 0.1931 - val_accuracy: 0.9390\n",
      "Epoch 597/800\n",
      "480/480 [==============================] - 0s 82us/step - loss: 0.1681 - accuracy: 0.9422 - val_loss: 0.1929 - val_accuracy: 0.9388\n",
      "Epoch 598/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1678 - accuracy: 0.9424 - val_loss: 0.1929 - val_accuracy: 0.9392\n",
      "Epoch 599/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1677 - accuracy: 0.9422 - val_loss: 0.1929 - val_accuracy: 0.9391\n",
      "Epoch 600/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1676 - accuracy: 0.9425 - val_loss: 0.1929 - val_accuracy: 0.9391\n",
      "Epoch 601/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1674 - accuracy: 0.9422 - val_loss: 0.1927 - val_accuracy: 0.9392\n",
      "Epoch 602/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1672 - accuracy: 0.9427 - val_loss: 0.1928 - val_accuracy: 0.9391\n",
      "Epoch 603/800\n",
      "480/480 [==============================] - 0s 84us/step - loss: 0.1670 - accuracy: 0.9423 - val_loss: 0.1926 - val_accuracy: 0.9391\n",
      "Epoch 604/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1669 - accuracy: 0.9424 - val_loss: 0.1925 - val_accuracy: 0.9392\n",
      "Epoch 605/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1667 - accuracy: 0.9426 - val_loss: 0.1925 - val_accuracy: 0.9393\n",
      "Epoch 606/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1667 - accuracy: 0.9426 - val_loss: 0.1920 - val_accuracy: 0.9390\n",
      "Epoch 607/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1665 - accuracy: 0.9425 - val_loss: 0.1921 - val_accuracy: 0.9390\n",
      "Epoch 608/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1664 - accuracy: 0.9423 - val_loss: 0.1920 - val_accuracy: 0.9391\n",
      "Epoch 609/800\n",
      "480/480 [==============================] - 0s 89us/step - loss: 0.1663 - accuracy: 0.9429 - val_loss: 0.1920 - val_accuracy: 0.9390\n",
      "Epoch 610/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1661 - accuracy: 0.9424 - val_loss: 0.1919 - val_accuracy: 0.9391\n",
      "Epoch 611/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1659 - accuracy: 0.9428 - val_loss: 0.1919 - val_accuracy: 0.9390\n",
      "Epoch 612/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1657 - accuracy: 0.9427 - val_loss: 0.1916 - val_accuracy: 0.9391\n",
      "Epoch 613/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1656 - accuracy: 0.9426 - val_loss: 0.1914 - val_accuracy: 0.9388\n",
      "Epoch 614/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1655 - accuracy: 0.9431 - val_loss: 0.1915 - val_accuracy: 0.9391\n",
      "Epoch 615/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1654 - accuracy: 0.9426 - val_loss: 0.1914 - val_accuracy: 0.9387\n",
      "Epoch 616/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 88us/step - loss: 0.1652 - accuracy: 0.9428 - val_loss: 0.1913 - val_accuracy: 0.9392\n",
      "Epoch 617/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1650 - accuracy: 0.9434 - val_loss: 0.1914 - val_accuracy: 0.9390\n",
      "Epoch 618/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1648 - accuracy: 0.9429 - val_loss: 0.1913 - val_accuracy: 0.9391\n",
      "Epoch 619/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1647 - accuracy: 0.9430 - val_loss: 0.1913 - val_accuracy: 0.9396\n",
      "Epoch 620/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1646 - accuracy: 0.9433 - val_loss: 0.1910 - val_accuracy: 0.9392\n",
      "Epoch 621/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1645 - accuracy: 0.9432 - val_loss: 0.1909 - val_accuracy: 0.9390\n",
      "Epoch 622/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1644 - accuracy: 0.9432 - val_loss: 0.1910 - val_accuracy: 0.9391\n",
      "Epoch 623/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1642 - accuracy: 0.9431 - val_loss: 0.1908 - val_accuracy: 0.9392\n",
      "Epoch 624/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1641 - accuracy: 0.9437 - val_loss: 0.1907 - val_accuracy: 0.9392\n",
      "Epoch 625/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1639 - accuracy: 0.9433 - val_loss: 0.1909 - val_accuracy: 0.9391\n",
      "Epoch 626/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1638 - accuracy: 0.9435 - val_loss: 0.1908 - val_accuracy: 0.9393\n",
      "Epoch 627/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1636 - accuracy: 0.9434 - val_loss: 0.1906 - val_accuracy: 0.9393\n",
      "Epoch 628/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1635 - accuracy: 0.9435 - val_loss: 0.1906 - val_accuracy: 0.9392\n",
      "Epoch 629/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1634 - accuracy: 0.9437 - val_loss: 0.1907 - val_accuracy: 0.9393\n",
      "Epoch 630/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1631 - accuracy: 0.9437 - val_loss: 0.1906 - val_accuracy: 0.9395\n",
      "Epoch 631/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1631 - accuracy: 0.9436 - val_loss: 0.1908 - val_accuracy: 0.9388\n",
      "Epoch 632/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1630 - accuracy: 0.9438 - val_loss: 0.1905 - val_accuracy: 0.9392\n",
      "Epoch 633/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1627 - accuracy: 0.9439 - val_loss: 0.1905 - val_accuracy: 0.9392\n",
      "Epoch 634/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1626 - accuracy: 0.9435 - val_loss: 0.1900 - val_accuracy: 0.9395\n",
      "Epoch 635/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1625 - accuracy: 0.9438 - val_loss: 0.1899 - val_accuracy: 0.9395\n",
      "Epoch 636/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1623 - accuracy: 0.9436 - val_loss: 0.1901 - val_accuracy: 0.9395\n",
      "Epoch 637/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1623 - accuracy: 0.9437 - val_loss: 0.1902 - val_accuracy: 0.9395\n",
      "Epoch 638/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1621 - accuracy: 0.9440 - val_loss: 0.1905 - val_accuracy: 0.9392\n",
      "Epoch 639/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1619 - accuracy: 0.9438 - val_loss: 0.1901 - val_accuracy: 0.9391\n",
      "Epoch 640/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1618 - accuracy: 0.9440 - val_loss: 0.1899 - val_accuracy: 0.9397\n",
      "Epoch 641/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1617 - accuracy: 0.9439 - val_loss: 0.1901 - val_accuracy: 0.9396\n",
      "Epoch 642/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1615 - accuracy: 0.9438 - val_loss: 0.1898 - val_accuracy: 0.9398\n",
      "Epoch 643/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1614 - accuracy: 0.9440 - val_loss: 0.1898 - val_accuracy: 0.9400\n",
      "Epoch 644/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1613 - accuracy: 0.9441 - val_loss: 0.1896 - val_accuracy: 0.9396\n",
      "Epoch 645/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1612 - accuracy: 0.9438 - val_loss: 0.1896 - val_accuracy: 0.9397\n",
      "Epoch 646/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1610 - accuracy: 0.9440 - val_loss: 0.1895 - val_accuracy: 0.9395\n",
      "Epoch 647/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1609 - accuracy: 0.9438 - val_loss: 0.1897 - val_accuracy: 0.9397\n",
      "Epoch 648/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1607 - accuracy: 0.9442 - val_loss: 0.1896 - val_accuracy: 0.9397\n",
      "Epoch 649/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1607 - accuracy: 0.9439 - val_loss: 0.1894 - val_accuracy: 0.9397\n",
      "Epoch 650/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1605 - accuracy: 0.9440 - val_loss: 0.1893 - val_accuracy: 0.9392\n",
      "Epoch 651/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1603 - accuracy: 0.9441 - val_loss: 0.1893 - val_accuracy: 0.9395\n",
      "Epoch 652/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1602 - accuracy: 0.9443 - val_loss: 0.1892 - val_accuracy: 0.9398\n",
      "Epoch 653/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1601 - accuracy: 0.9442 - val_loss: 0.1891 - val_accuracy: 0.9393\n",
      "Epoch 654/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1600 - accuracy: 0.9444 - val_loss: 0.1890 - val_accuracy: 0.9398\n",
      "Epoch 655/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1598 - accuracy: 0.9445 - val_loss: 0.1890 - val_accuracy: 0.9395\n",
      "Epoch 656/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1597 - accuracy: 0.9442 - val_loss: 0.1891 - val_accuracy: 0.9393\n",
      "Epoch 657/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1595 - accuracy: 0.9446 - val_loss: 0.1888 - val_accuracy: 0.9397\n",
      "Epoch 658/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1594 - accuracy: 0.9442 - val_loss: 0.1890 - val_accuracy: 0.9395\n",
      "Epoch 659/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1593 - accuracy: 0.9448 - val_loss: 0.1888 - val_accuracy: 0.9392\n",
      "Epoch 660/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1592 - accuracy: 0.9445 - val_loss: 0.1888 - val_accuracy: 0.9396\n",
      "Epoch 661/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1591 - accuracy: 0.9446 - val_loss: 0.1888 - val_accuracy: 0.9396\n",
      "Epoch 662/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1589 - accuracy: 0.9448 - val_loss: 0.1888 - val_accuracy: 0.9388\n",
      "Epoch 663/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1589 - accuracy: 0.9444 - val_loss: 0.1889 - val_accuracy: 0.9398\n",
      "Epoch 664/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1586 - accuracy: 0.9448 - val_loss: 0.1887 - val_accuracy: 0.9397\n",
      "Epoch 665/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1586 - accuracy: 0.9446 - val_loss: 0.1891 - val_accuracy: 0.9396\n",
      "Epoch 666/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1585 - accuracy: 0.9448 - val_loss: 0.1886 - val_accuracy: 0.9396\n",
      "Epoch 667/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1583 - accuracy: 0.9446 - val_loss: 0.1885 - val_accuracy: 0.9391\n",
      "Epoch 668/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1581 - accuracy: 0.9450 - val_loss: 0.1886 - val_accuracy: 0.9396\n",
      "Epoch 669/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1581 - accuracy: 0.9451 - val_loss: 0.1886 - val_accuracy: 0.9400\n",
      "Epoch 670/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1579 - accuracy: 0.9450 - val_loss: 0.1885 - val_accuracy: 0.9392\n",
      "Epoch 671/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1578 - accuracy: 0.9449 - val_loss: 0.1884 - val_accuracy: 0.9396\n",
      "Epoch 672/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 90us/step - loss: 0.1577 - accuracy: 0.9451 - val_loss: 0.1884 - val_accuracy: 0.9395\n",
      "Epoch 673/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1575 - accuracy: 0.9453 - val_loss: 0.1884 - val_accuracy: 0.9400\n",
      "Epoch 674/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1574 - accuracy: 0.9449 - val_loss: 0.1884 - val_accuracy: 0.9396\n",
      "Epoch 675/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1573 - accuracy: 0.9453 - val_loss: 0.1882 - val_accuracy: 0.9401\n",
      "Epoch 676/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1572 - accuracy: 0.9450 - val_loss: 0.1884 - val_accuracy: 0.9397\n",
      "Epoch 677/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1570 - accuracy: 0.9453 - val_loss: 0.1883 - val_accuracy: 0.9396\n",
      "Epoch 678/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1570 - accuracy: 0.9452 - val_loss: 0.1884 - val_accuracy: 0.9404\n",
      "Epoch 679/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1568 - accuracy: 0.9453 - val_loss: 0.1883 - val_accuracy: 0.9397\n",
      "Epoch 680/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1567 - accuracy: 0.9453 - val_loss: 0.1882 - val_accuracy: 0.9393\n",
      "Epoch 681/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1566 - accuracy: 0.9454 - val_loss: 0.1879 - val_accuracy: 0.9397\n",
      "Epoch 682/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1564 - accuracy: 0.9452 - val_loss: 0.1879 - val_accuracy: 0.9402\n",
      "Epoch 683/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1564 - accuracy: 0.9454 - val_loss: 0.1880 - val_accuracy: 0.9395\n",
      "Epoch 684/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1562 - accuracy: 0.9455 - val_loss: 0.1878 - val_accuracy: 0.9401\n",
      "Epoch 685/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1561 - accuracy: 0.9453 - val_loss: 0.1879 - val_accuracy: 0.9396\n",
      "Epoch 686/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1561 - accuracy: 0.9453 - val_loss: 0.1879 - val_accuracy: 0.9395\n",
      "Epoch 687/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1560 - accuracy: 0.9455 - val_loss: 0.1877 - val_accuracy: 0.9395\n",
      "Epoch 688/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1559 - accuracy: 0.9456 - val_loss: 0.1880 - val_accuracy: 0.9396\n",
      "Epoch 689/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1557 - accuracy: 0.9457 - val_loss: 0.1879 - val_accuracy: 0.9397\n",
      "Epoch 690/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1556 - accuracy: 0.9458 - val_loss: 0.1877 - val_accuracy: 0.9400\n",
      "Epoch 691/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1554 - accuracy: 0.9453 - val_loss: 0.1879 - val_accuracy: 0.9392\n",
      "Epoch 692/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1553 - accuracy: 0.9456 - val_loss: 0.1877 - val_accuracy: 0.9400\n",
      "Epoch 693/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1553 - accuracy: 0.9455 - val_loss: 0.1876 - val_accuracy: 0.9400\n",
      "Epoch 694/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1552 - accuracy: 0.9459 - val_loss: 0.1877 - val_accuracy: 0.9398\n",
      "Epoch 695/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1550 - accuracy: 0.9458 - val_loss: 0.1874 - val_accuracy: 0.9396\n",
      "Epoch 696/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1548 - accuracy: 0.9456 - val_loss: 0.1874 - val_accuracy: 0.9401\n",
      "Epoch 697/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1547 - accuracy: 0.9455 - val_loss: 0.1873 - val_accuracy: 0.9401\n",
      "Epoch 698/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1547 - accuracy: 0.9457 - val_loss: 0.1874 - val_accuracy: 0.9402\n",
      "Epoch 699/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1545 - accuracy: 0.9457 - val_loss: 0.1875 - val_accuracy: 0.9396\n",
      "Epoch 700/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1545 - accuracy: 0.9459 - val_loss: 0.1877 - val_accuracy: 0.9397\n",
      "Epoch 701/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1544 - accuracy: 0.9458 - val_loss: 0.1874 - val_accuracy: 0.9395\n",
      "Epoch 702/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1542 - accuracy: 0.9458 - val_loss: 0.1874 - val_accuracy: 0.9401\n",
      "Epoch 703/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1541 - accuracy: 0.9454 - val_loss: 0.1873 - val_accuracy: 0.9402\n",
      "Epoch 704/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1539 - accuracy: 0.9456 - val_loss: 0.1873 - val_accuracy: 0.9398\n",
      "Epoch 705/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1538 - accuracy: 0.9459 - val_loss: 0.1873 - val_accuracy: 0.9396\n",
      "Epoch 706/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1537 - accuracy: 0.9459 - val_loss: 0.1874 - val_accuracy: 0.9393\n",
      "Epoch 707/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1537 - accuracy: 0.9457 - val_loss: 0.1873 - val_accuracy: 0.9398\n",
      "Epoch 708/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1534 - accuracy: 0.9462 - val_loss: 0.1872 - val_accuracy: 0.9395\n",
      "Epoch 709/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1535 - accuracy: 0.9459 - val_loss: 0.1874 - val_accuracy: 0.9395\n",
      "Epoch 710/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1534 - accuracy: 0.9459 - val_loss: 0.1871 - val_accuracy: 0.9397\n",
      "Epoch 711/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1532 - accuracy: 0.9457 - val_loss: 0.1873 - val_accuracy: 0.9393\n",
      "Epoch 712/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1531 - accuracy: 0.9457 - val_loss: 0.1872 - val_accuracy: 0.9393\n",
      "Epoch 713/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1530 - accuracy: 0.9461 - val_loss: 0.1873 - val_accuracy: 0.9401\n",
      "Epoch 714/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1529 - accuracy: 0.9460 - val_loss: 0.1873 - val_accuracy: 0.9398\n",
      "Epoch 715/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1527 - accuracy: 0.9460 - val_loss: 0.1870 - val_accuracy: 0.9396\n",
      "Epoch 716/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1527 - accuracy: 0.9461 - val_loss: 0.1869 - val_accuracy: 0.9402\n",
      "Epoch 717/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1525 - accuracy: 0.9462 - val_loss: 0.1868 - val_accuracy: 0.9398\n",
      "Epoch 718/800\n",
      "480/480 [==============================] - 0s 87us/step - loss: 0.1524 - accuracy: 0.9460 - val_loss: 0.1869 - val_accuracy: 0.9397\n",
      "Epoch 719/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1523 - accuracy: 0.9462 - val_loss: 0.1875 - val_accuracy: 0.9400\n",
      "Epoch 720/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1523 - accuracy: 0.9464 - val_loss: 0.1871 - val_accuracy: 0.9396\n",
      "Epoch 721/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1522 - accuracy: 0.9466 - val_loss: 0.1873 - val_accuracy: 0.9400\n",
      "Epoch 722/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1520 - accuracy: 0.9466 - val_loss: 0.1869 - val_accuracy: 0.9403\n",
      "Epoch 723/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1520 - accuracy: 0.9462 - val_loss: 0.1867 - val_accuracy: 0.9402\n",
      "Epoch 724/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1519 - accuracy: 0.9464 - val_loss: 0.1867 - val_accuracy: 0.9396\n",
      "Epoch 725/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1517 - accuracy: 0.9466 - val_loss: 0.1866 - val_accuracy: 0.9402\n",
      "Epoch 726/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1515 - accuracy: 0.9464 - val_loss: 0.1869 - val_accuracy: 0.9398\n",
      "Epoch 727/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1516 - accuracy: 0.9467 - val_loss: 0.1867 - val_accuracy: 0.9403\n",
      "Epoch 728/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 85us/step - loss: 0.1513 - accuracy: 0.9465 - val_loss: 0.1866 - val_accuracy: 0.9400\n",
      "Epoch 729/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1513 - accuracy: 0.9464 - val_loss: 0.1864 - val_accuracy: 0.9406\n",
      "Epoch 730/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1512 - accuracy: 0.9463 - val_loss: 0.1865 - val_accuracy: 0.9403\n",
      "Epoch 731/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1512 - accuracy: 0.9463 - val_loss: 0.1864 - val_accuracy: 0.9401\n",
      "Epoch 732/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1510 - accuracy: 0.9464 - val_loss: 0.1867 - val_accuracy: 0.9404\n",
      "Epoch 733/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1510 - accuracy: 0.9464 - val_loss: 0.1865 - val_accuracy: 0.9402\n",
      "Epoch 734/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1507 - accuracy: 0.9469 - val_loss: 0.1865 - val_accuracy: 0.9401\n",
      "Epoch 735/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1507 - accuracy: 0.9467 - val_loss: 0.1865 - val_accuracy: 0.9406\n",
      "Epoch 736/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1506 - accuracy: 0.9467 - val_loss: 0.1866 - val_accuracy: 0.9404\n",
      "Epoch 737/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1504 - accuracy: 0.9468 - val_loss: 0.1865 - val_accuracy: 0.9407\n",
      "Epoch 738/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1504 - accuracy: 0.9469 - val_loss: 0.1867 - val_accuracy: 0.9398\n",
      "Epoch 739/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1504 - accuracy: 0.9468 - val_loss: 0.1863 - val_accuracy: 0.9403\n",
      "Epoch 740/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1500 - accuracy: 0.9468 - val_loss: 0.1865 - val_accuracy: 0.9402\n",
      "Epoch 741/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1500 - accuracy: 0.9467 - val_loss: 0.1864 - val_accuracy: 0.9396\n",
      "Epoch 742/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1499 - accuracy: 0.9470 - val_loss: 0.1863 - val_accuracy: 0.9403\n",
      "Epoch 743/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1500 - accuracy: 0.9473 - val_loss: 0.1861 - val_accuracy: 0.9402\n",
      "Epoch 744/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1498 - accuracy: 0.9469 - val_loss: 0.1862 - val_accuracy: 0.9404\n",
      "Epoch 745/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1497 - accuracy: 0.9470 - val_loss: 0.1861 - val_accuracy: 0.9401\n",
      "Epoch 746/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1497 - accuracy: 0.9469 - val_loss: 0.1863 - val_accuracy: 0.9409\n",
      "Epoch 747/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1495 - accuracy: 0.9468 - val_loss: 0.1864 - val_accuracy: 0.9403\n",
      "Epoch 748/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1494 - accuracy: 0.9473 - val_loss: 0.1859 - val_accuracy: 0.9406\n",
      "Epoch 749/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1492 - accuracy: 0.9474 - val_loss: 0.1863 - val_accuracy: 0.9400\n",
      "Epoch 750/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1491 - accuracy: 0.9473 - val_loss: 0.1863 - val_accuracy: 0.9406\n",
      "Epoch 751/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1491 - accuracy: 0.9471 - val_loss: 0.1860 - val_accuracy: 0.9403\n",
      "Epoch 752/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1489 - accuracy: 0.9471 - val_loss: 0.1862 - val_accuracy: 0.9403\n",
      "Epoch 753/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1489 - accuracy: 0.9471 - val_loss: 0.1859 - val_accuracy: 0.9407\n",
      "Epoch 754/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1487 - accuracy: 0.9469 - val_loss: 0.1860 - val_accuracy: 0.9401\n",
      "Epoch 755/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1487 - accuracy: 0.9473 - val_loss: 0.1857 - val_accuracy: 0.9401\n",
      "Epoch 756/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1485 - accuracy: 0.9472 - val_loss: 0.1860 - val_accuracy: 0.9407\n",
      "Epoch 757/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1485 - accuracy: 0.9478 - val_loss: 0.1856 - val_accuracy: 0.9402\n",
      "Epoch 758/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1485 - accuracy: 0.9471 - val_loss: 0.1858 - val_accuracy: 0.9407\n",
      "Epoch 759/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1483 - accuracy: 0.9472 - val_loss: 0.1862 - val_accuracy: 0.9406\n",
      "Epoch 760/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1481 - accuracy: 0.9472 - val_loss: 0.1860 - val_accuracy: 0.9403\n",
      "Epoch 761/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1481 - accuracy: 0.9476 - val_loss: 0.1859 - val_accuracy: 0.9407\n",
      "Epoch 762/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1481 - accuracy: 0.9472 - val_loss: 0.1860 - val_accuracy: 0.9403\n",
      "Epoch 763/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1479 - accuracy: 0.9479 - val_loss: 0.1857 - val_accuracy: 0.9406\n",
      "Epoch 764/800\n",
      "480/480 [==============================] - 0s 81us/step - loss: 0.1478 - accuracy: 0.9475 - val_loss: 0.1860 - val_accuracy: 0.9403\n",
      "Epoch 765/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1477 - accuracy: 0.9475 - val_loss: 0.1859 - val_accuracy: 0.9406\n",
      "Epoch 766/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1477 - accuracy: 0.9477 - val_loss: 0.1859 - val_accuracy: 0.9406\n",
      "Epoch 767/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1476 - accuracy: 0.9472 - val_loss: 0.1854 - val_accuracy: 0.9403\n",
      "Epoch 768/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1475 - accuracy: 0.9477 - val_loss: 0.1856 - val_accuracy: 0.9406\n",
      "Epoch 769/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1474 - accuracy: 0.9474 - val_loss: 0.1858 - val_accuracy: 0.9403\n",
      "Epoch 770/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1473 - accuracy: 0.9478 - val_loss: 0.1855 - val_accuracy: 0.9409\n",
      "Epoch 771/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1471 - accuracy: 0.9473 - val_loss: 0.1860 - val_accuracy: 0.9411\n",
      "Epoch 772/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1470 - accuracy: 0.9480 - val_loss: 0.1854 - val_accuracy: 0.9404\n",
      "Epoch 773/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1470 - accuracy: 0.9478 - val_loss: 0.1857 - val_accuracy: 0.9403\n",
      "Epoch 774/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1468 - accuracy: 0.9479 - val_loss: 0.1856 - val_accuracy: 0.9406\n",
      "Epoch 775/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1468 - accuracy: 0.9475 - val_loss: 0.1857 - val_accuracy: 0.9408\n",
      "Epoch 776/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1468 - accuracy: 0.9479 - val_loss: 0.1855 - val_accuracy: 0.9408\n",
      "Epoch 777/800\n",
      "480/480 [==============================] - 0s 102us/step - loss: 0.1466 - accuracy: 0.9475 - val_loss: 0.1858 - val_accuracy: 0.9411\n",
      "Epoch 778/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1466 - accuracy: 0.9482 - val_loss: 0.1856 - val_accuracy: 0.9403\n",
      "Epoch 779/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1464 - accuracy: 0.9473 - val_loss: 0.1853 - val_accuracy: 0.9407\n",
      "Epoch 780/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1463 - accuracy: 0.9477 - val_loss: 0.1854 - val_accuracy: 0.9407\n",
      "Epoch 781/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1463 - accuracy: 0.9482 - val_loss: 0.1854 - val_accuracy: 0.9402\n",
      "Epoch 782/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1461 - accuracy: 0.9480 - val_loss: 0.1855 - val_accuracy: 0.9408\n",
      "Epoch 783/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1461 - accuracy: 0.9479 - val_loss: 0.1852 - val_accuracy: 0.9407\n",
      "Epoch 784/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 0s 81us/step - loss: 0.1459 - accuracy: 0.9479 - val_loss: 0.1855 - val_accuracy: 0.9406\n",
      "Epoch 785/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1459 - accuracy: 0.9482 - val_loss: 0.1854 - val_accuracy: 0.9404\n",
      "Epoch 786/800\n",
      "480/480 [==============================] - 0s 85us/step - loss: 0.1458 - accuracy: 0.9483 - val_loss: 0.1853 - val_accuracy: 0.9407\n",
      "Epoch 787/800\n",
      "480/480 [==============================] - 0s 83us/step - loss: 0.1456 - accuracy: 0.9483 - val_loss: 0.1853 - val_accuracy: 0.9408\n",
      "Epoch 788/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1456 - accuracy: 0.9486 - val_loss: 0.1857 - val_accuracy: 0.9406\n",
      "Epoch 789/800\n",
      "480/480 [==============================] - 0s 90us/step - loss: 0.1456 - accuracy: 0.9480 - val_loss: 0.1850 - val_accuracy: 0.9406\n",
      "Epoch 790/800\n",
      "480/480 [==============================] - 0s 100us/step - loss: 0.1454 - accuracy: 0.9482 - val_loss: 0.1853 - val_accuracy: 0.9406\n",
      "Epoch 791/800\n",
      "480/480 [==============================] - 0s 104us/step - loss: 0.1453 - accuracy: 0.9483 - val_loss: 0.1854 - val_accuracy: 0.9407\n",
      "Epoch 792/800\n",
      "480/480 [==============================] - 0s 104us/step - loss: 0.1452 - accuracy: 0.9483 - val_loss: 0.1852 - val_accuracy: 0.9409\n",
      "Epoch 793/800\n",
      "480/480 [==============================] - 0s 92us/step - loss: 0.1451 - accuracy: 0.9482 - val_loss: 0.1851 - val_accuracy: 0.9406\n",
      "Epoch 794/800\n",
      "480/480 [==============================] - 0s 108us/step - loss: 0.1451 - accuracy: 0.9485 - val_loss: 0.1849 - val_accuracy: 0.9412\n",
      "Epoch 795/800\n",
      "480/480 [==============================] - 0s 98us/step - loss: 0.1450 - accuracy: 0.9487 - val_loss: 0.1853 - val_accuracy: 0.9403\n",
      "Epoch 796/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.1449 - accuracy: 0.9489 - val_loss: 0.1850 - val_accuracy: 0.9408\n",
      "Epoch 797/800\n",
      "480/480 [==============================] - 0s 94us/step - loss: 0.1448 - accuracy: 0.9484 - val_loss: 0.1850 - val_accuracy: 0.9406\n",
      "Epoch 798/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1446 - accuracy: 0.9487 - val_loss: 0.1849 - val_accuracy: 0.9408\n",
      "Epoch 799/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1447 - accuracy: 0.9485 - val_loss: 0.1856 - val_accuracy: 0.9408\n",
      "Epoch 800/800\n",
      "480/480 [==============================] - 0s 88us/step - loss: 0.1445 - accuracy: 0.9487 - val_loss: 0.1851 - val_accuracy: 0.9408\n",
      "[160, 0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:122: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[160, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[149, 5]\n",
      "[5, 1]\n",
      "[151, 3]\n",
      "[0, 6]\n",
      "[149, 3]\n",
      "[6, 2]\n",
      "[152, 0]\n",
      "[1, 7]\n",
      "[152, 4]\n",
      "[2, 2]\n",
      "[153, 3]\n",
      "[3, 1]\n",
      "[145, 4]\n",
      "[7, 4]\n",
      "[142, 7]\n",
      "[6, 5]\n",
      "[135, 13]\n",
      "[10, 2]\n",
      "[147, 1]\n",
      "[1, 11]\n",
      "[141, 11]\n",
      "[6, 2]\n",
      "[150, 2]\n",
      "[0, 8]\n",
      "[138, 6]\n",
      "[16, 0]\n",
      "[144, 0]\n",
      "[0, 16]\n",
      "both b and c are zero\n",
      "[146, 1]\n",
      "[8, 5]\n",
      "[143, 4]\n",
      "[4, 9]\n",
      "[143, 4]\n",
      "[5, 8]\n",
      "[142, 5]\n",
      "[2, 11]\n",
      "[142, 4]\n",
      "[6, 8]\n",
      "[142, 4]\n",
      "[6, 8]\n",
      "[149, 0]\n",
      "[0, 11]\n",
      "both b and c are zero\n",
      "[149, 0]\n",
      "[0, 11]\n",
      "both b and c are zero\n",
      "[140, 2]\n",
      "[12, 6]\n",
      "[141, 1]\n",
      "[5, 13]\n",
      "[147, 5]\n",
      "[6, 2]\n",
      "[148, 4]\n",
      "[2, 6]\n",
      "[146, 3]\n",
      "[7, 4]\n",
      "[141, 8]\n",
      "[3, 8]\n",
      "[142, 9]\n",
      "[6, 3]\n",
      "[151, 0]\n",
      "[1, 8]\n",
      "[131, 16]\n",
      "[8, 5]\n",
      "[146, 1]\n",
      "[2, 11]\n",
      "[145, 4]\n",
      "[8, 3]\n",
      "[146, 3]\n",
      "[4, 7]\n",
      "[148, 4]\n",
      "[8, 0]\n",
      "[152, 0]\n",
      "[0, 8]\n",
      "both b and c are zero\n",
      "[151, 3]\n",
      "[5, 1]\n",
      "[152, 2]\n",
      "[1, 5]\n",
      "[147, 0]\n",
      "[1, 12]\n",
      "[147, 0]\n",
      "[1, 12]\n",
      "[145, 0]\n",
      "[0, 15]\n",
      "both b and c are zero\n",
      "[145, 0]\n",
      "[0, 15]\n",
      "both b and c are zero\n",
      "[149, 0]\n",
      "[10, 1]\n",
      "[148, 1]\n",
      "[3, 8]\n",
      "[150, 1]\n",
      "[9, 0]\n",
      "[149, 2]\n",
      "[2, 7]\n",
      "[146, 3]\n",
      "[10, 1]\n",
      "[149, 0]\n",
      "[0, 11]\n",
      "both b and c are zero\n",
      "[146, 4]\n",
      "[9, 1]\n",
      "[143, 7]\n",
      "[6, 4]\n",
      "[135, 12]\n",
      "[10, 3]\n",
      "[145, 2]\n",
      "[3, 10]\n",
      "[153, 0]\n",
      "[2, 5]\n",
      "[153, 0]\n",
      "[2, 5]\n",
      "[141, 6]\n",
      "[6, 7]\n",
      "[145, 2]\n",
      "[4, 9]\n",
      "[152, 0]\n",
      "[0, 8]\n",
      "both b and c are zero\n",
      "[151, 1]\n",
      "[0, 8]\n",
      "[148, 1]\n",
      "[6, 5]\n",
      "[147, 2]\n",
      "[3, 8]\n",
      "[142, 3]\n",
      "[13, 2]\n",
      "[145, 0]\n",
      "[3, 12]\n",
      "[144, 4]\n",
      "[9, 3]\n",
      "[148, 0]\n",
      "[4, 8]\n",
      "[148, 1]\n",
      "[4, 7]\n",
      "[145, 4]\n",
      "[5, 6]\n",
      "[149, 4]\n",
      "[6, 1]\n",
      "[148, 5]\n",
      "[0, 7]\n",
      "[148, 3]\n",
      "[8, 1]\n",
      "[147, 4]\n",
      "[3, 6]\n",
      "[146, 2]\n",
      "[10, 2]\n",
      "[145, 3]\n",
      "[5, 7]\n",
      "[143, 2]\n",
      "[12, 3]\n",
      "[142, 3]\n",
      "[3, 12]\n",
      "[142, 8]\n",
      "[7, 3]\n",
      "[149, 1]\n",
      "[1, 9]\n",
      "[147, 5]\n",
      "[6, 2]\n",
      "[150, 2]\n",
      "[3, 5]\n",
      "[151, 4]\n",
      "[3, 2]\n",
      "[150, 5]\n",
      "[2, 3]\n",
      "[149, 4]\n",
      "[7, 0]\n",
      "[150, 3]\n",
      "[1, 6]\n",
      "[151, 2]\n",
      "[3, 4]\n",
      "[150, 3]\n",
      "[2, 5]\n",
      "[142, 6]\n",
      "[9, 3]\n",
      "[147, 1]\n",
      "[1, 11]\n",
      "[149, 1]\n",
      "[7, 3]\n",
      "[150, 0]\n",
      "[2, 8]\n",
      "[150, 0]\n",
      "[7, 3]\n",
      "[148, 2]\n",
      "[4, 6]\n",
      "[150, 5]\n",
      "[4, 1]\n",
      "[153, 2]\n",
      "[3, 2]\n",
      "[138, 9]\n",
      "[7, 6]\n",
      "[147, 0]\n",
      "[1, 12]\n",
      "[147, 1]\n",
      "[4, 8]\n",
      "[147, 1]\n",
      "[4, 8]\n",
      "[146, 7]\n",
      "[5, 2]\n",
      "[153, 0]\n",
      "[0, 7]\n",
      "both b and c are zero\n",
      "[149, 0]\n",
      "[2, 9]\n",
      "[149, 0]\n",
      "[2, 9]\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds of MWPM:\n",
      "> Accuracy: 0.9536519607843127 (+- 0.004298239806754727)\n",
      "> F1: 0.6211026571232708(+- 0.027087897835525808)\n",
      "> Time: 7.130287899999999 (+- 0.10554789655147011)\n",
      "##############################################################################\n",
      "Average scores for all folds of PLUT:\n",
      "> Accuracy: 0.9379901960784295 (+- 0.0006622184355933695)\n",
      "> F1: 0.04589524487249916(+- 0.01562893517538009)\n",
      "> Time: 0.0026028800000000006 (+- 0.0004920722280316173)\n",
      "##############################################################################\n",
      "Average scores for all folds of NN:\n",
      "> Accuracy: 0.9402205910402183 (+- 0.0026629116565982354)\n",
      "> F1: 0.2746612881230622(+- 0.0402859289496934)\n",
      "> Time: 0.0474112 (+- 0.002059504869622793)\n",
      "##############################################################################\n",
      "> AUC for class : 0.012578616352201255 (+- 0.0)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 0\n",
      "> AUC for class X00: 0.38290722368434305 (+- 0.08421495869816877)\n",
      "X^2 for MWPM and NN: 0.1\n",
      "X^2 for PLUT and NN: 1.3333333333333333\n",
      "> AUC for class X01: 0.7967304242698672 (+- 0.05667020047932611)\n",
      "X^2 for MWPM and NN: 1.7777777777777777\n",
      "X^2 for PLUT and NN: 4.0\n",
      "> AUC for class X02: 0.9110869886542925 (+- 0.06527967587340959)\n",
      "X^2 for MWPM and NN: 0.16666666666666666\n",
      "X^2 for PLUT and NN: 0.16666666666666666\n",
      "> AUC for class X03: 0.8959310145921615 (+- 0.07158563064453316)\n",
      "X^2 for MWPM and NN: 1.4545454545454546\n",
      "X^2 for PLUT and NN: 0.0\n",
      "> AUC for class X04: 0.7977440932871982 (+- 0.055301192914356666)\n",
      "X^2 for MWPM and NN: 0.17391304347826086\n",
      "X^2 for PLUT and NN: 0.5\n",
      "> AUC for class X10: 0.6328928847393047 (+- 0.06504939079768195)\n",
      "X^2 for MWPM and NN: 0.9411764705882353\n",
      "X^2 for PLUT and NN: 0.5\n",
      "> AUC for class X11: 0.8527119171033645 (+- 0.05522389790224067)\n",
      "X^2 for MWPM and NN: 5.5\n",
      "X^2 for PLUT and NN: 0\n",
      "> AUC for class X12: 0.8460541829933058 (+- 0.02486303862525353)\n",
      "X^2 for MWPM and NN: 7.111111111111111\n",
      "X^2 for PLUT and NN: 0.125\n",
      "> AUC for class X13: 0.9028741962135733 (+- 0.06366299183557114)\n",
      "X^2 for MWPM and NN: 0.4444444444444444\n",
      "X^2 for PLUT and NN: 0.5714285714285714\n",
      "> AUC for class X14: 0.8032697136768429 (+- 0.05489887730691311)\n",
      "X^2 for MWPM and NN: 0.9\n",
      "X^2 for PLUT and NN: 0.9\n",
      "> AUC for class X20: 0.7124862946905036 (+- 0.08507901431095814)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 0\n",
      "> AUC for class X21: 0.8624971413423956 (+- 0.050582685431259766)\n",
      "X^2 for MWPM and NN: 8.642857142857142\n",
      "X^2 for PLUT and NN: 4.166666666666667\n",
      "> AUC for class X22: 0.8429378869733786 (+- 0.1277939925520416)\n",
      "X^2 for MWPM and NN: 0.36363636363636365\n",
      "X^2 for PLUT and NN: 0.16666666666666666\n",
      "> AUC for class X23: 0.8722071818623084 (+- 0.08066693090999119)\n",
      "X^2 for MWPM and NN: 2.5\n",
      "X^2 for PLUT and NN: 1.4545454545454546\n",
      "> AUC for class X24: 0.7504310505811157 (+- 0.08316789845566)\n",
      "X^2 for MWPM and NN: 0.26666666666666666\n",
      "X^2 for PLUT and NN: 4.0\n",
      "> AUC for class X30: 0.7163294938634119 (+- 0.04115900672267825)\n",
      "X^2 for MWPM and NN: 2.0416666666666665\n",
      "X^2 for PLUT and NN: 1.3333333333333333\n",
      "> AUC for class X31: 0.8911713189452504 (+- 0.015431072516896375)\n",
      "X^2 for MWPM and NN: 2.0833333333333335\n",
      "X^2 for PLUT and NN: 0.5714285714285714\n",
      "> AUC for class X32: 0.8369703522920204 (+- 0.07356391755052993)\n",
      "X^2 for MWPM and NN: 2.0833333333333335\n",
      "X^2 for PLUT and NN: 0\n",
      "> AUC for class X33: 0.8521382882015285 (+- 0.08512831116607542)\n",
      "X^2 for MWPM and NN: 1.125\n",
      "X^2 for PLUT and NN: 0.0\n",
      "> AUC for class X34: 0.7450868234656346 (+- 0.10897228164534009)\n",
      "X^2 for MWPM and NN: 4.0\n",
      "X^2 for PLUT and NN: 4.0\n",
      "> AUC for class X40: 0.725048305634374 (+- 0.10365275619429647)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 0\n",
      "> AUC for class X41: 0.9493812294487027 (+- 0.022225979581340056)\n",
      "X^2 for MWPM and NN: 12.1\n",
      "X^2 for PLUT and NN: 2.25\n",
      "> AUC for class X42: 0.9166128939644583 (+- 0.04274445876163137)\n",
      "X^2 for MWPM and NN: 8.1\n",
      "X^2 for PLUT and NN: 0.25\n",
      "> AUC for class X43: 0.9155225619539294 (+- 0.044575467721712524)\n",
      "X^2 for MWPM and NN: 4.923076923076923\n",
      "X^2 for PLUT and NN: 0\n",
      "> AUC for class X44: 0.8890826058402821 (+- 0.04155421540317)\n",
      "X^2 for MWPM and NN: 2.769230769230769\n",
      "X^2 for PLUT and NN: 0.0\n",
      "> AUC for class Z00: 0.8162056983431848 (+- 0.04744552581188394)\n",
      "X^2 for MWPM and NN: 0.045454545454545456\n",
      "X^2 for PLUT and NN: 0.8\n",
      "> AUC for class Z01: 0.8457566198479286 (+- 0.0416498762470579)\n",
      "X^2 for MWPM and NN: 4.5\n",
      "X^2 for PLUT and NN: 4.5\n",
      "> AUC for class Z02: 0.7545028604845191 (+- 0.07090881925736892)\n",
      "X^2 for MWPM and NN: 0.08333333333333333\n",
      "X^2 for PLUT and NN: 1.5\n",
      "> AUC for class Z03: 0.7624930116241989 (+- 0.06956420625808588)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 0.0\n",
      "> AUC for class Z04: 0.910609605954724 (+- 0.03008410580418326)\n",
      "X^2 for MWPM and NN: 5.142857142857143\n",
      "X^2 for PLUT and NN: 0.8\n",
      "> AUC for class Z10: 0.938075099182744 (+- 0.03364937440359077)\n",
      "X^2 for MWPM and NN: 7.5625\n",
      "X^2 for PLUT and NN: 5.333333333333333\n",
      "> AUC for class Z11: 0.8471515988426972 (+- 0.020620929501608484)\n",
      "X^2 for MWPM and NN: 2.769230769230769\n",
      "X^2 for PLUT and NN: 6.25\n",
      "> AUC for class Z12: 0.9076246123945069 (+- 0.04575013681051208)\n",
      "X^2 for MWPM and NN: 3.2\n",
      "X^2 for PLUT and NN: 0.4444444444444444\n",
      "> AUC for class Z13: 0.8669983319316472 (+- 0.02192836446208379)\n",
      "X^2 for MWPM and NN: 0.9\n",
      "X^2 for PLUT and NN: 3.2\n",
      "> AUC for class Z14: 0.9460596221024792 (+- 0.02116999868056303)\n",
      "X^2 for MWPM and NN: 3.272727272727273\n",
      "X^2 for PLUT and NN: 0.0\n",
      "> AUC for class Z20: 0.9060886589989601 (+- 0.0710587396775378)\n",
      "X^2 for MWPM and NN: 6.75\n",
      "X^2 for PLUT and NN: 1.125\n",
      "> AUC for class Z21: 0.8663116860031751 (+- 0.08192464950245439)\n",
      "X^2 for MWPM and NN: 8.642857142857142\n",
      "X^2 for PLUT and NN: 0.16666666666666666\n",
      "> AUC for class Z22: 0.8532559139784948 (+- 0.05774762527782723)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 0.5\n",
      "> AUC for class Z23: 0.8687428104201438 (+- 0.027979323130525525)\n",
      "X^2 for MWPM and NN: 0.36363636363636365\n",
      "X^2 for PLUT and NN: 0.8\n",
      "> AUC for class Z24: 0.9118814244674736 (+- 0.04704460706262984)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 0.5714285714285714\n",
      "> AUC for class Z30: 0.8921426067305319 (+- 0.01888593519365631)\n",
      "X^2 for MWPM and NN: 1.4545454545454546\n",
      "X^2 for PLUT and NN: 0.25\n",
      "> AUC for class Z31: 0.7765302937655189 (+- 0.06722372302081155)\n",
      "X^2 for MWPM and NN: 0.8\n",
      "X^2 for PLUT and NN: 0.0\n",
      "> AUC for class Z32: 0.8434822763438852 (+- 0.029752693066103945)\n",
      "X^2 for MWPM and NN: 1.0666666666666667\n",
      "X^2 for PLUT and NN: 0.5\n",
      "> AUC for class Z33: 0.7652936561353283 (+- 0.11856917750885923)\n",
      "X^2 for MWPM and NN: 6.125\n",
      "X^2 for PLUT and NN: 4.5\n",
      "> AUC for class Z34: 0.8961853118781953 (+- 0.03482296724700113)\n",
      "X^2 for MWPM and NN: 9.142857142857142\n",
      "X^2 for PLUT and NN: 1.5\n",
      "> AUC for class Z40: 0.8534114509591019 (+- 0.10001834706040408)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 0.8\n",
      "> AUC for class Z41: 0.767033757504599 (+- 0.09074893944736025)\n",
      "X^2 for MWPM and NN: 0.0625\n",
      "X^2 for PLUT and NN: 4.0\n",
      "> AUC for class Z42: 0.7601491918399691 (+- 0.06359375475138569)\n",
      "X^2 for MWPM and NN: 3.2\n",
      "X^2 for PLUT and NN: 3.2\n",
      "> AUC for class Z43: 0.7321190621482259 (+- 0.10377419615041339)\n",
      "X^2 for MWPM and NN: 0.08333333333333333\n",
      "X^2 for PLUT and NN: 0\n",
      "> AUC for class Z44: 0.7646114507354796 (+- 0.05200558687488872)\n",
      "X^2 for MWPM and NN: 4.5\n",
      "X^2 for PLUT and NN: 4.5\n",
      "###################################################################################\n",
      "TOTAL F1 NN: [0.26198083067092653, 0.32463768115942027, 0.31024930747922436, 0.21052631578947367, 0.26591230551626593]\n",
      "TOTAL F1 PLUT: [0.04914933837429111, 0.07434944237918215, 0.03383458646616541, 0.041666666666666664, 0.030476190476190473]\n",
      "TOTAL F1 MWPM: [0.6652763295099061, 0.6359918200408997, 0.5947006869479883, 0.5932539682539684, 0.6162904808635917]\n",
      "TOTAL ACC NN: [0.9428921937942505, 0.9431372880935669, 0.9406862258911133, 0.9379901885986328, 0.9363970588235278]\n",
      "TOTAL ACC PLUT: [0.9383578431372527, 0.9389705882352924, 0.9370098039215673, 0.9379901960784303, 0.9376225490196054]\n",
      "TOTAL ACC MWPM: [0.9606617647058814, 0.956372549019607, 0.94938725490196, 0.9497549019607832, 0.9520833333333322]\n",
      "TOTAL TIME NN: [0.0450107, 0.0480121, 0.0460108, 0.0470108, 0.0510116]\n",
      "TOTAL TIME PLUT: [0.0029997, 0.0030002, 0.0020008, 0.003014, 0.0019997]\n",
      "TOTAL TIME MWPM: [7.036315199999996, 7.025009899999999, 7.2433079999999945, 7.0751788000000015, 7.271627599999999]\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "inputs = x_d5.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = np.array(y_d5)\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "n_classes = 51\n",
    "\n",
    "acc_per_fold = []\n",
    "f1_per_fold = []\n",
    "time_per_fold = []\n",
    "\n",
    "acc_per_fold_plut = []\n",
    "f1_per_fold_plut = []\n",
    "time_per_fold_plut = []\n",
    "\n",
    "acc_per_fold_mwpm = []\n",
    "f1_per_fold_mwpm = []\n",
    "time_per_fold_mwpm = []\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "aucs_classes = {}\n",
    "for i in mlb.classes_:\n",
    "    aucs_classes[i] = []\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for i, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "    i_train = inputs[train].copy()\n",
    "    i_test = inputs[test].copy()\n",
    "    x_test_d5 = i_test[:,:2]\n",
    "    inputs_train = i_train[:,3:]\n",
    "    inputs_test = i_test[:,3:]\n",
    "    \n",
    "    ####################################################################################################\n",
    "    #test MWPM decoder for this fold\n",
    "    decoding_d5, time_mwpm = do_new_decoding(x_test_d5, 5, 0)\n",
    "    decoding_d5['combine'] = decoding_d5[[0, 1]].values.tolist()\n",
    "    decoding_d5['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "    decoding_d5 = np.array(decoding_d5[0])\n",
    "                                              \n",
    "    time_per_fold_mwpm.append(time_mwpm)\n",
    "                                              \n",
    "    pred_mwpm = mlb.transform(decoding_d5)\n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_mwpm)\n",
    "    else:\n",
    "        acc, contingency_mwpm = partial_accuracy_and_contingency(targets[test], pred_mwpm, mlb)\n",
    "        \n",
    "    acc_per_fold_mwpm.append(acc)\n",
    "    f1_per_fold_mwpm.append(f1_score(targets[test], pred_mwpm, average='micro'))\n",
    "    \n",
    "    #####################################################################################################\n",
    "    #test the plut decoder for this fold\n",
    "    \n",
    "    lookup_d5 = lookup_decoder(5)\n",
    "    \n",
    "    lookup_d5 = train_plut(lookup_d5, inputs_train, targets[train])\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    pred_plut_d5 = test_plut(lookup_d5, inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_plut_d5)\n",
    "    else:\n",
    "        acc, contingency_plut = partial_accuracy_and_contingency(targets[test], pred_plut_d5, mlb)\n",
    "        \n",
    "    acc_per_fold_plut.append(acc)\n",
    "    f1_per_fold_plut.append(f1_score(targets[test], pred_plut_d5, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #Test the NN decoder for this fold\n",
    "    \n",
    "    model_d5 = compile_FFNN_cv_model_DepthFive(5)\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    \n",
    "    history = model_d5.fit(\n",
    "    inputs_train,\n",
    "    targets[train],\n",
    "    validation_split=.25,\n",
    "    epochs = 800)\n",
    "    \n",
    "   # Generate generalization metrics\n",
    "    scores = model_d5.evaluate(inputs_test, targets[test], verbose=0)\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    predictions_d5 = model_d5.predict(inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    #threshold based on previous tests with train_test_split in hyperparameter tuning\n",
    "    pred=predictions_d5.copy() #change here\n",
    "    pred[pred>=.4]=1 \n",
    "    pred[pred<.4]=0\n",
    "    \n",
    "    if fold_no < 5:\n",
    "        acc = scores[1]\n",
    "    else:\n",
    "        acc, contingency_nn = partial_accuracy_and_contingency(targets[test], pred, mlb)\n",
    "\n",
    "    acc_per_fold.append(acc)\n",
    "    f1_per_fold.append(f1_score(targets[test], pred, average='micro'))\n",
    "\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d5.ravel())\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    \n",
    "    #get the AUCs of each class, used to get average AUC of each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d5[:, i]) \n",
    "        aucs_classes[mlb.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "        \n",
    "        \n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print(\"##############################################################################\")\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print(\"##############################################################################\")\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "print(\"##############################################################################\")\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "    \n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 5 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D7 Training, Testing, and Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data sets from CSV\n",
    "\n",
    "#### Data sets for D7:\n",
    "* Original:\n",
    "    - \"depth7_all_combos.csv\"\n",
    "* Randomly-sampled, with replacement (version 2):\n",
    "    - \"v2samples-d7-1000.csv\"\n",
    "    - \"v2samples-d7-10000.csv\"\n",
    "    - \"v2samples-d7-50000.csv\"\n",
    "* Randomly-sampled, without replacement (version 3):\n",
    "    - \"v3samples-d7-1000.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData_d7 = pd.read_csv(\"depth7_all_combos.csv\")\n",
    "trainData_d7 = trainData_d7.applymap(lambda x: add_noise(x,.01))\n",
    "\n",
    "#These four lines remove duplicates\n",
    "trainData_d7['Labels'] = trainData_d7['Labels'].map(lambda x: create_list_from_string(x))\n",
    "trainData_d7['Labels'] = trainData_d7['Labels'].astype(str)\n",
    "trainData_d7 = trainData_d7.drop_duplicates('Labels', keep='first', ignore_index=True)\n",
    "trainData_d7['Labels'] = trainData_d7['Labels'].map(lambda x: create_list_from_string(x))\n",
    "\n",
    "testData_d7_MWPM = graph_with_errs_d7(trainData_d7)\n",
    "\n",
    "#transforms the data to encoding for ML\n",
    "mlb_d7 = MultiLabelBinarizer()\n",
    "mlb_d7.fit(trainData_d7['Labels'])\n",
    "df = pd.DataFrame(mlb_d7.transform(trainData_d7['Labels']))\n",
    "df['Labels']= df.values.tolist()\n",
    "trainData_d7 = trainData_d7.drop(['Labels'], axis=1)\n",
    "trainData_d7 = pd.concat([df[\"Labels\"],testData_d7_MWPM, trainData_d7], axis=1, ignore_index=True)\n",
    "trainData_d7.columns = [\"Labels\",\"XSyn\", \"ZSyn\",\"X0\", \"Z1\", \"X2\", \"X3\", \"Z4\", \"X5\", \"X6\", \"Z7\", \"X8\", \"Z9\", \"Z10\", \"X11\", \"Z12\", \"X13\", \"Z14\", \"X15\", \"Z16\", \"Z17\", \"X18\", \"Z19\",\"X20\", \"Z21\", \"X22\", \"Z23\", \"Z24\", \"X25\", \"Z26\", \"X27\", \"Z28\", \"X29\", \"Z30\", \"Z31\", \"X32\", \"Z33\", \"X34\", \"Z35\", \"X36\", \"Z37\", \"Z38\", \"X39\", \"X40\", \"Z41\", \"X42\", \"X43\", \"Z44\", \"X45\", \"X46\", \"Z47\"]\n",
    "\n",
    "y_d7 = trainData_d7[\"Labels\"]\n",
    "x_d7 = trainData_d7.drop([\"Labels\"], axis=1)\n",
    "\n",
    "x_d7 = x_d7.replace([-1], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = x_d7.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = y_d7.copy()\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "train_input_d7 = inputs[:,2:]\n",
    "train_output_d7 = targets\n",
    "\n",
    "x_train_d7, x_test_d7, Y_train_d7, Y_test_d7 = train_test_split(train_input_d7, train_output_d7, train_size=0.75, shuffle=True)\n",
    "\n",
    "model_d7 = compile_FFNN_cv_model_DepthSeven(7)\n",
    "print(\"Fit model on training data\")\n",
    "history = model_d7.fit(\n",
    "    x=x_train_d7,\n",
    "    y=Y_train_d7,\n",
    "    validation_split=.25,\n",
    "    epochs=150\n",
    ")\n",
    "model_d7.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Epoch vs. Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Depth 7 Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Epoch vs. Accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Depth 7 Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d7.save(\"model_d7.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "inputs = x_d7.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = np.array(y_d7)\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "n_classes = 99\n",
    "\n",
    "acc_per_fold = []\n",
    "f1_per_fold = []\n",
    "time_per_fold = []\n",
    "\n",
    "acc_per_fold_plut = []\n",
    "f1_per_fold_plut = []\n",
    "time_per_fold_plut = []\n",
    "\n",
    "acc_per_fold_mwpm = []\n",
    "f1_per_fold_mwpm = []\n",
    "time_per_fold_mwpm = []\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "aucs_classes = {}\n",
    "for i in mlb_d7.classes_:\n",
    "    aucs_classes[i] = []\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for i, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "    i_train = inputs[train].copy()\n",
    "    i_test = inputs[test].copy()\n",
    "    t_test = targets[test].copy()\n",
    "    x_test_d7 = i_test[:,:2]\n",
    "    inputs_train = i_train[:,3:]\n",
    "    inputs_test = i_test[:,3:]\n",
    "    indices = np.random.choice(inputs[test].shape[0], 20000, replace=False)\n",
    "    x_test_d7 = x_test_d7[indices]\n",
    "    inputs_test_2 = inputs_test[indices]\n",
    "    targets_test_2 = targets[test][indices]\n",
    "    \n",
    "    ####################################################################################################\n",
    "    #test MWPM decoder for this fold\n",
    "    \n",
    "    decoding_d7, time_mwpm = do_new_decoding(x_test_d7, 7, 0)\n",
    "    decoding_d7['combine'] = decoding_d7[[0, 1]].values.tolist()\n",
    "    decoding_d7['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "    decoding_d7 = np.array(decoding_d7[0])\n",
    "                                              \n",
    "    time_per_fold_mwpm.append(time_mwpm)\n",
    "                                              \n",
    "    pred_mwpm = mlb_d7.transform(decoding_d7)\n",
    "\n",
    "    if fold_no < 3:\n",
    "        acc = partial_accuracy(targets_test_2, pred_mwpm)\n",
    "    else:\n",
    "        acc, contingency_mwpm = partial_accuracy_and_contingency(targets_test_2, pred_mwpm, mlb_d7)\n",
    "        \n",
    "    acc_per_fold_mwpm.append(acc)\n",
    "    f1_per_fold_mwpm.append(f1_score(targets_test_2, pred_mwpm, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #test the plut decoder for this fold\n",
    "    \n",
    "    lookup_d7 = lookup_decoder(7)\n",
    "    \n",
    "    lookup_d7 = train_plut(lookup_d7, inputs_train, targets[train])\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    pred_plut_d7 = test_plut(lookup_d7, inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    if fold_no < 3:\n",
    "        acc = partial_accuracy(targets[test], pred_plut_d7)\n",
    "        f1 = f1_score(targets[test], pred_plut_d7, average='micro')\n",
    "    else:\n",
    "        pred_plut_d7 = test_plut(lookup_d7, inputs_test_2)\n",
    "        f1 = f1_score(targets_test_2, pred_plut_d7, average='micro')\n",
    "        acc, contingency_plut = partial_accuracy_and_contingency(targets_test_2, pred_plut_d7, mlb_d7)\n",
    "        \n",
    "    acc_per_fold_plut.append(acc)\n",
    "    f1_per_fold_plut.append(f1)\n",
    "    \n",
    "    #####################################################################################################\n",
    "    #Test the NN decoder for this fold\n",
    "    \n",
    "    model_d7 = compile_FFNN_cv_model_DepthSeven(7)\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = model_d7.fit(\n",
    "        x=inputs_train ,\n",
    "        y=targets[train],\n",
    "        validation_split=.25,\n",
    "        epochs= 150)\n",
    "    \n",
    "   # Generate generalization metrics\n",
    "    scores = model_d7.evaluate(inputs_test, targets[test], verbose=0)\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    predictions_d7 = model_d7.predict(inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    #threshold based on previous tests with train_test_split in hyperparameter tuning\n",
    "    pred=predictions_d7.copy() #change here\n",
    "    pred[pred>=.5]=1 \n",
    "    pred[pred<.5]=0\n",
    "     \n",
    "    if fold_no < 3:\n",
    "        acc = scores[1]\n",
    "        f1 = f1_score(targets[test], pred, average='micro')\n",
    "    else:\n",
    "        pred = model_d7.predict(inputs_test_2)\n",
    "        pred[pred>=.5]=1 \n",
    "        pred[pred<.5]=0\n",
    "        acc, contingency_nn = partial_accuracy_and_contingency(targets_test_2, pred, mlb_d7)\n",
    "        f1 = f1_score(targets_test_2, pred, average='micro')\n",
    " \n",
    "    acc_per_fold.append(acc)\n",
    "    f1_per_fold.append(f1)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d7.ravel())\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    \n",
    "    #get the AUCs of each class, used to get average AUC of each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d7[:, i]) \n",
    "        aucs_classes[mlb_d7.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "\n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb_d7.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 7 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
