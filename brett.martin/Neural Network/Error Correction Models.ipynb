{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import circuits\n",
    "\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import precision_score,accuracy_score, f1_score, recall_score, hamming_loss\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import backend as K\n",
    "\n",
    "from collections import defaultdict\n",
    "from math import log2\n",
    "\n",
    "print (pd.__version__)\n",
    "RUN_CONFIGURATION_LOOP = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_with_errs_d3(df):\n",
    "    x_data = []\n",
    "    z_data = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        x_data.append([])\n",
    "        z_data.append([])\n",
    "        if df.loc[i].at[\"X0\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 0.5))\n",
    "        if df.loc[i].at[\"Z1\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 0.5))\n",
    "        if df.loc[i].at[\"X2\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 1.5))\n",
    "        if df.loc[i].at[\"Z3\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 2.5))\n",
    "        if df.loc[i].at[\"Z4\"] == -1:\n",
    "            z_data[i].append((0, 1.5, -0.5))\n",
    "        if df.loc[i].at[\"X5\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 0.5))\n",
    "        if df.loc[i].at[\"X6\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 1.5))\n",
    "        if df.loc[i].at[\"Z7\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 1.5))\n",
    "        x_data[i] = str(x_data[i])\n",
    "        z_data[i] = str(z_data[i])\n",
    "        \n",
    "    graph_df = pd.DataFrame({\"XSyn\":x_data, \"ZSyn\":z_data})\n",
    "    return graph_df\n",
    "        \n",
    "\n",
    "def graph_with_errs_d5(df):\n",
    "    x_data = []\n",
    "    z_data = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        x_data.append([])\n",
    "        z_data.append([])\n",
    "        if df.loc[i].at[\"X0\"] == -1:\n",
    "             x_data[i].append((0, -0.5, 0.5))\n",
    "        if df.loc[i].at[\"Z1\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 0.5))\n",
    "        if df.loc[i].at[\"X2\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 1.5))\n",
    "        if df.loc[i].at[\"X3\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 2.5))\n",
    "        if df.loc[i].at[\"Z4\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 2.5))\n",
    "        if df.loc[i].at[\"X5\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 3.5))\n",
    "        if df.loc[i].at[\"Z6\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 4.5))\n",
    "        if df.loc[i].at[\"Z7\"] == -1:\n",
    "            z_data[i].append((0, 1.5, -0.5))\n",
    "        if df.loc[i].at[\"X8\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 0.5))\n",
    "        if df.loc[i].at[\"Z9\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 1.5))\n",
    "        if df.loc[i].at[\"X10\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 2.5))\n",
    "        if df.loc[i].at[\"Z11\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 3.5))\n",
    "        if df.loc[i].at[\"Z12\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 0.5))\n",
    "        if df.loc[i].at[\"X13\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 1.5))\n",
    "        if df.loc[i].at[\"Z14\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 2.5))\n",
    "        if df.loc[i].at[\"X15\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 3.5))\n",
    "        if df.loc[i].at[\"Z16\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 4.5))\n",
    "        if df.loc[i].at[\"Z17\"] == -1:\n",
    "            z_data[i].append((0, 3.5, -0.5))\n",
    "        if df.loc[i].at[\"X18\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 0.5))\n",
    "        if df.loc[i].at[\"X19\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 1.5))\n",
    "        if df.loc[i].at[\"Z20\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 1.5))\n",
    "        if df.loc[i].at[\"X21\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 2.5))\n",
    "        if df.loc[i].at[\"X22\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 3.5))\n",
    "        if df.loc[i].at[\"Z23\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 3.5))\n",
    "        x_data[i] = str(x_data[i])\n",
    "        z_data[i] = str(z_data[i])\n",
    "            \n",
    "    graph_df = pd.DataFrame({\"XSyn\":x_data, \"ZSyn\":z_data})\n",
    "    return graph_df\n",
    "\n",
    "\n",
    "def graph_with_errs_d7(df):\n",
    "    x_data = []\n",
    "    z_data = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        x_data.append([])\n",
    "        z_data.append([])\n",
    "        if df.loc[i].at[\"X0\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 0.5))\n",
    "        if df.loc[i].at[\"Z1\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 0.5))\n",
    "        if df.loc[i].at[\"X2\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 1.5))\n",
    "        if df.loc[i].at[\"X3\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 2.5))\n",
    "        if df.loc[i].at[\"Z4\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 2.5))\n",
    "        if df.loc[i].at[\"X5\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 3.5))\n",
    "        if df.loc[i].at[\"X6\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 4.5))\n",
    "        if df.loc[i].at[\"Z7\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 4.5))\n",
    "        if df.loc[i].at[\"X8\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 5.5))\n",
    "        if df.loc[i].at[\"Z9\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 6.5))\n",
    "        if df.loc[i].at[\"Z10\"] == -1:\n",
    "            z_data[i].append((0, 1.5, -0.5))\n",
    "        if df.loc[i].at[\"X11\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 0.5))\n",
    "        if df.loc[i].at[\"Z12\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 1.5))\n",
    "        if df.loc[i].at[\"X13\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 2.5))\n",
    "        if df.loc[i].at[\"Z14\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 3.5))\n",
    "        if df.loc[i].at[\"X15\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 4.5))\n",
    "        if df.loc[i].at[\"Z16\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 5.5))\n",
    "        if df.loc[i].at[\"Z17\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 0.5))\n",
    "        if df.loc[i].at[\"X18\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 1.5))\n",
    "        if df.loc[i].at[\"Z19\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 2.5))\n",
    "        if df.loc[i].at[\"X20\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 3.5))\n",
    "        if df.loc[i].at[\"Z21\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 4.5))\n",
    "        if df.loc[i].at[\"X22\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 5.5))\n",
    "        if df.loc[i].at[\"Z23\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 6.5))\n",
    "        if df.loc[i].at[\"Z24\"] == -1:\n",
    "            z_data[i].append((0, 3.5, -0.5))\n",
    "        if df.loc[i].at[\"X25\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 0.5))\n",
    "        if df.loc[i].at[\"Z26\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 1.5))\n",
    "        if df.loc[i].at[\"X27\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 2.5))\n",
    "        if df.loc[i].at[\"Z28\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 3.5))\n",
    "        if df.loc[i].at[\"X29\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 4.5))\n",
    "        if df.loc[i].at[\"Z30\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 5.5))\n",
    "        if df.loc[i].at[\"Z31\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 0.5))\n",
    "        if df.loc[i].at[\"X32\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 1.5))\n",
    "        if df.loc[i].at[\"Z33\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 2.5))\n",
    "        if df.loc[i].at[\"X34\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 3.5))\n",
    "        if df.loc[i].at[\"Z35\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 4.5))\n",
    "        if df.loc[i].at[\"X36\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 5.5))\n",
    "        if df.loc[i].at[\"Z37\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 6.5))\n",
    "        if df.loc[i].at[\"Z38\"] == -1:\n",
    "            z_data[i].append((0, 5.5, -0.5))\n",
    "        if df.loc[i].at[\"X39\"] == -1:\n",
    "            x_data[i].append((0, 5.5, 0.5))\n",
    "        if df.loc[i].at[\"X40\"] == -1:\n",
    "            x_data[i].append((0, 6.5, 1.5))\n",
    "        if df.loc[i].at[\"Z41\"] == -1:\n",
    "            z_data[i].append((0, 5.5, 1.5))\n",
    "        if df.loc[i].at[\"X42\"] == -1:\n",
    "            x_data[i].append((0, 5.5, 2.5))\n",
    "        if df.loc[i].at[\"X43\"] == -1:\n",
    "            x_data[i].append((0, 6.5, 3.5))\n",
    "        if df.loc[i].at[\"Z44\"] == -1:\n",
    "            z_data[i].append((0, 5.5, 3.5))\n",
    "        if df.loc[i].at[\"X45\"] == -1:\n",
    "            x_data[i].append((0, 5.5, 4.5))\n",
    "        if df.loc[i].at[\"X46\"] == -1:\n",
    "            x_data[i].append((0, 6.5, 5.5))\n",
    "        if df.loc[i].at[\"Z47\"] == -1: \n",
    "            z_data[i].append((0, 5.5, 5.5))\n",
    "        x_data[i] = str(x_data[i])\n",
    "        z_data[i] = str(z_data[i])\n",
    "        \n",
    "    graph_df = pd.DataFrame({\"XSyn\":x_data, \"ZSyn\":z_data})\n",
    "    return graph_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MWPM functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_measurement_errs(curr_syn, prob_err, x_syn, depth):\n",
    "    #x_syn is True if it is x syndrome, False if it is Z syndrome\n",
    "    total_time = 0\n",
    "    new_syn = []\n",
    "    if x_syn:\n",
    "        for i in curr_syn:\n",
    "            rand = random.random()\n",
    "            if rand > prob_err:\n",
    "                new_syn.append(i)\n",
    "        return (new_syn + return_xmeasurement_errs(depth, prob_err))\n",
    "    else:\n",
    "        for i in curr_syn:\n",
    "            rand = random.random()\n",
    "            if rand > prob_err:\n",
    "                new_syn.append(i)\n",
    "        return (new_syn + return_zmeasurement_errs(depth, prob_err))\n",
    "\n",
    "\n",
    "def do_new_decoding(data, depth, prob_err):\n",
    "    decoder = circuits.GraphDecoder(depth,1)\n",
    "    G = decoder.S['Z']\n",
    "    df = pd.DataFrame()\n",
    "    syn = []\n",
    "    total_time = 0\n",
    "    \n",
    "    for row in data:\n",
    "        x_input = []\n",
    "        z_input = []\n",
    "        x_type = True\n",
    "        for col in row:\n",
    "            if not col == \"[]\":\n",
    "                col = eval(col)\n",
    "                for c in col:\n",
    "                    if x_type:\n",
    "                        x_input.append(c)\n",
    "                    else:\n",
    "                        z_input.append(c)\n",
    "            x_type = not x_type  \n",
    "            \n",
    "        if prob_err > 0:\n",
    "            syndromes_x = add_measurement_errs(x_input, prob_err, True, depth)\n",
    "            syndromes_z = add_measurement_errs(z_input, prob_err, False, depth)\n",
    "        else:\n",
    "            syndromes_x = x_input\n",
    "            syndromes_z = z_input\n",
    "\n",
    "        start = time.time_ns()\n",
    "        error_graph_x, paths_x = decoder.make_error_graph(syndromes_x,'X')\n",
    "        matching_graph_x = decoder.matching_graph(error_graph_x,'X')\n",
    "        matches_x = decoder.matching(matching_graph_x,'X')\n",
    "        flips_x = decoder.calculate_qubit_flips(matches_x, paths_x,'X')\n",
    "        syn_x = (translate_errors(flips_x))\n",
    "\n",
    "        error_graph_z, paths_z = decoder.make_error_graph(syndromes_z,'Z')\n",
    "        matching_graph_z = decoder.matching_graph(error_graph_z,'Z')\n",
    "        matches_z = decoder.matching(matching_graph_z,'Z')\n",
    "        flips_z = decoder.calculate_qubit_flips(matches_z, paths_z,'Z')\n",
    "        syn_z = translate_errors(flips_z)\n",
    "        df = df.append(pd.Series([syn_x, syn_z]), ignore_index=True)\n",
    "        end = time.time_ns()\n",
    "        total_time += (end - start)/ (10 ** 9)\n",
    "    return (df, total_time) \n",
    "\n",
    "\n",
    "def return_xmeasurement_errs(depth, prob):\n",
    "    \n",
    "    new_errs = []\n",
    "    \n",
    "    if depth == 3:\n",
    "        errs = [(0, -0.5, 0.5), (0, 0.5, 1.5), (0, 1.5, 0.5), (0, 2.5, 1.5)]\n",
    "    elif depth == 5:\n",
    "        errs = [(0, -0.5, 0.5), (0, 0.5, 1.5), (0, -0.5, 2.5), (0, 0.5, 3.5), (0, 1.5, 0.5), (0, 1.5, 2.5),\n",
    "                        (0, 2.5, 1.5), (0, 2.5, 3.5), (0, 3.5, 0.5), (0, 4.5, 1.5), (0, 3.5, 2.5), (0, 4.5, 3.5)]\n",
    "    else:\n",
    "        errs = [(0, -0.5, 0.5), (0, 0.5, 1.5), (0, -0.5, 2.5), (0, 0.5, 3.5), (0, -0.5, 4.5), (0, 0.5, 5.5),\n",
    "                        (0, 1.5, 0.5), (0, 1.5, 2.5), (0, 1.5, 4.5), (0, 2.5, 1.5), (0, 2.5, 3.5), (0, 2.5, 5.5),\n",
    "                        (0, 3.5, 0.5),  (0, 3.5, 2.5), (0, 3.5, 4.5), (0, 4.5, 1.5), (0, 4.5, 3.5), (0, 4.5, 5.5),\n",
    "                       (0, 5.5, 0.5), (0, 6.5, 1.5), (0, 5.5, 2.5), (0, 6.5, 3.5), (0, 5.5, 4.5), (0, 6.5, 5.5)]\n",
    "    for e in errs:\n",
    "        rand = random.random()\n",
    "        if rand <= prob:\n",
    "            new_errs.append(e)\n",
    "            \n",
    "    return new_errs\n",
    "            \n",
    "\n",
    "def return_zmeasurement_errs(depth, prob):\n",
    "    \n",
    "    new_errs = []\n",
    "    \n",
    "    if depth == 3:\n",
    "        errs = [(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 1.5, -0.5), (0, 1.5, 1.5)]\n",
    "    elif depth == 5:\n",
    "        errs = [(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 0.5, 4.5), (0, 1.5, -0.5), (0, 1.5, 1.5), (0, 1.5, 3.5),\n",
    "                        (0, 2.5, 0.5), (0, 2.5, 2.5), (0, 2.5, 4.5), (0, 3.5, -0.5), (0, 3.5, 1.5), (0, 3.5, 3.5)]\n",
    "    else:\n",
    "        errs = [(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 0.5, 4.5), (0, 0.5, 6.5), (0, 1.5, -0.5), (0, 1.5, 1.5),\n",
    "                        (0, 1.5, 3.5), (0, 1.5, 5.5), (0, 2.5, 0.5), (0, 2.5, 2.5), (0, 2.5, 4.5), (0, 2.5, 6.5),\n",
    "                        (0, 3.5, -0.5),  (0, 3.5, 1.5), (0, 3.5, 3.5), (0, 3.5, 5.5), (0, 4.5, 0.5), (0, 4.5, 2.5),\n",
    "                       (0, 4.5, 4.5), (0, 4.5, 6.5), (0, 5.5, -0.5), (0, 5.5, 1.5), (0, 5.5, 3.5), (0, 5.5, 5.5)]\n",
    "        \n",
    "    for e in errs:\n",
    "        rand = random.random()\n",
    "        if rand <= prob:\n",
    "            new_errs.append(e)\n",
    "            \n",
    "    return new_errs\n",
    "\n",
    "\n",
    "def translate_errors (phys_errs):\n",
    "    flipX = np.array([(0, 1),(1, 0)])\n",
    "    flipZ = np.array([(1, 0), (0, -1)])\n",
    "    errs = []\n",
    "    str2 = \"\"\n",
    "    for qubit, flip in phys_errs.items():\n",
    "        row = int(qubit[1])\n",
    "        col = int(qubit[2])\n",
    "        if str(flip) == \"X\":\n",
    "            str1 = \"X\"\n",
    "        elif str(flip) == \"Z\":\n",
    "            str1 = \"Z\"\n",
    "        else:\n",
    "            str1 = \"X\"\n",
    "            str2 = \"Z\"\n",
    "        str1 += str(row) + str(col)\n",
    "        errs.append(str1)\n",
    "        if str2 != \"\":\n",
    "            str2 += str(row) +str(col)\n",
    "            errs.append(str2)\n",
    "            str2 = \"\"\n",
    "    return errs   \n",
    "\n",
    "\n",
    "def translate_to_graph(df_graph, labels, mlb):\n",
    "#go through labels given\n",
    "    indices = []\n",
    "    labels = mlb.inverse_transform(labels)\n",
    "    \n",
    "    for row in labels:\n",
    "        label_str = str(row)\n",
    "        for index, r in df_graph.iterrows():\n",
    "            if label_str == \"('',)\":\n",
    "                if str(r[\"Labels\"]) == \"[' ']\":\n",
    "                    indices.append([index])\n",
    "                    break\n",
    "            if set(row) == set(r[\"Labels\"]):\n",
    "                indices.append([index])\n",
    "                break\n",
    "\n",
    "    df_syns = df_graph.drop(['Labels'], axis=1)\n",
    "    return_df = pd.DataFrame()\n",
    "    for i in indices:\n",
    "        return_df = return_df.append(df_syns.loc[i])\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list_from_string(err_list):\n",
    "    newstring = err_list.replace(\"'\", \"\")\n",
    "    new_err_list = newstring.strip('][').split(', ')\n",
    "    return sorted(set(new_err_list))\n",
    "\n",
    "\n",
    "def create_string_from_list(err_list):\n",
    "    return_string = \"[\"\n",
    "    if err_list[0] == \"''\":\n",
    "        return \"[' ']\"\n",
    "    else:\n",
    "        for index, i in enumerate(err_list):\n",
    "            return_string = return_string +  \"'\" + i + \"'\"\n",
    "            if index < (len(err_list)-1):\n",
    "                return_string += \", \"\n",
    "    return return_string + \"]\"\n",
    "        \n",
    "\n",
    "#take in two 2d arrays of predicted values, true values, and threshold to determine labels. \n",
    "#calculates the partial accuracy of the predicted values, averaged out for all obersvations\n",
    "def partial_accuracy(y_pred, y_true):\n",
    "    total = 0\n",
    "    rows = y_pred.shape[0]\n",
    "    cols = y_pred.shape[1]\n",
    "    for i in range(0, rows):\n",
    "        row_correct = 0\n",
    "        for j in range(0, cols):\n",
    "            if y_pred[i,j] == y_true[i,j]:\n",
    "                row_correct += 1\n",
    "        total += row_correct/cols\n",
    "    return total/rows\n",
    "\n",
    "\n",
    "def partial_accuracy_and_contingency(y_pred, y_true, mlb):\n",
    "    total = 0\n",
    "    a= np.zeros(shape=y_true.shape)\n",
    "    rows = y_pred.shape[0]\n",
    "    cols = y_pred.shape[1]\n",
    "    df = pd.DataFrame(a, columns = mlb.classes_)\n",
    "    for i in range(0, rows):\n",
    "        row_correct = 0\n",
    "        for j, label in enumerate(mlb.classes_):\n",
    "            if y_pred[i,j] == y_true[i,j]:\n",
    "                row_correct += 1\n",
    "                df.at[i, label] = 1\n",
    "            else:\n",
    "                df.at[i, label] = 0\n",
    "\n",
    "        total += row_correct/cols\n",
    "\n",
    "    return (total/rows, df)\n",
    "\n",
    "\n",
    "def contingency_table_and_t (clf1, clf2):\n",
    "    a = 0 #clf1 pos, clf2 pos\n",
    "    b = 0 #clf1 pos, clf2 neg\n",
    "    c = 0 #clf1 neg, clf2 pos\n",
    "    d = 0 #clf1 neg, clf2 neg\n",
    "    \n",
    "    for index, value in clf1.items():\n",
    "        if value == 1 and clf2[index] == 1:\n",
    "            a+=1\n",
    "        elif value == 1 and clf2[index] == 0: #classifier 1 right, classifier 2 wrong\n",
    "            b+=1\n",
    "        elif value == 0 and clf2[index] == 1: #classifier 1 wrong, classifier 2 right\n",
    "            c+=1\n",
    "        else:\n",
    "            d+=1\n",
    "    print(\"[\"+str(a)+\", \"+str(b)+\"]\")\n",
    "    print(\"[\"+str(c)+\", \"+str(d)+\"]\")\n",
    "    if b == 0 and c ==0:\n",
    "        print(\"both b and c are zero\")\n",
    "        t=0\n",
    "    else:\n",
    "        t = (((b-c)-1)**2)/(b+c)\n",
    "    return ([[a,b],[c,d]], t)\n",
    "\n",
    "\n",
    "def add_noise(val, noise_level):\n",
    "    rand = random.uniform(0, 1)\n",
    "    if rand <= noise_level:\n",
    "        if val == -1:\n",
    "            val = 1\n",
    "        elif val == 1:\n",
    "            val = -1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup table functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAllBinaryStrings(n, arr, i, lookup):  \n",
    "    if i == n: \n",
    "        lookup.setBitStringArray(arr, n)  \n",
    "        return\n",
    "      \n",
    "    # First assign \"0\" at ith position  \n",
    "    # and try for all other permutations  \n",
    "    # for remaining positions  \n",
    "    arr[i] = 0\n",
    "    generateAllBinaryStrings(n, arr, i + 1, lookup)  \n",
    "  \n",
    "    # And then assign \"1\" at ith position  , \n",
    "    # and try for all other permutations  \n",
    "    # for remaining positions  \n",
    "    arr[i] = 1\n",
    "    generateAllBinaryStrings(n, arr, i + 1, lookup)\n",
    "\n",
    "\n",
    "class lookup_decoder:\n",
    "    \n",
    "    def __init__(self, depth):\n",
    "        #self.lookupTable = defaultdict()\n",
    "        self.lookupTable = {}\n",
    "        self.distributions = {}\n",
    "        self.depth = depth\n",
    "        #generating all possible syndrome observations\n",
    "        #arr = [None] * (depth**2 - 1)\n",
    "        #generateAllBinaryStrings((depth**2 - 1), arr, 0, self)\n",
    "        \n",
    "    def setBitStringArray(self, arr, n): \n",
    "        new_str = \"\"\n",
    "        for i in range(0, n):  \n",
    "            new_str += str(arr[i])\n",
    "        self.lookupTable.update({new_str:defaultdict()})  \n",
    "        \n",
    "    def update_table (self, syndrome, phys_errs):\n",
    "        #all the keys are made in the init, so simply update the physical error combinations for the given syndrome\n",
    "        if syndrome not in self.lookupTable:\n",
    "            self.lookupTable[syndrome] = {}\n",
    "            self.lookupTable[syndrome][phys_errs] = 1\n",
    "            return\n",
    "        \n",
    "        if phys_errs not in self.lookupTable[syndrome]:\n",
    "            self.lookupTable[syndrome].update({phys_errs: 1})\n",
    "        else:\n",
    "            self.lookupTable[syndrome][phys_errs] += 1\n",
    "     \n",
    "    def get_probable_error(self, syndrome):\n",
    "        return_key = []\n",
    "\n",
    "        if syndrome not in self.lookupTable.keys():\n",
    "            for i in range(2* int(self.depth**2) + 1):\n",
    "                return_key.append(0)\n",
    "            return return_key\n",
    "        \n",
    "        key, value = max(self.lookupTable[syndrome].items(), key=lambda x:x[1])\n",
    "        \n",
    "        for character in key:\n",
    "            if character == '0' or character == '1':\n",
    "                return_key.append(int(character))\n",
    "                \n",
    "        return return_key\n",
    "        \n",
    "    def make_distribution_graph(self, syn):\n",
    "        \n",
    "        plt.bar(list(self.lookupTable[syn].keys()), self.lookupTable[syn].values(), color='g')\n",
    "        plt.show()\n",
    "        \n",
    "    def syndrome_count_graph(self):\n",
    "        graph_dict = {}\n",
    "        for syn in self.lookupTable:\n",
    "            graph_dict.update({syn:sum(self.lookupTable[syn].values())})\n",
    "        plt.ylim((0,4))\n",
    "        plt.bar(graph_dict.keys(), graph_dict.values())\n",
    "        plt.show()\n",
    "    \n",
    "    def length_of_lookup(self):\n",
    "        print(len(self.lookupTable))\n",
    "            \n",
    "    def get_entropies(self):\n",
    "        entropies = {}\n",
    "        for syn in self.lookupTable:\n",
    "            total = sum(self.lookupTable[syn].values())\n",
    "            h = 0\n",
    "            for key in self.lookupTable[syn]:\n",
    "                p = self.lookupTable[syn][key]/total\n",
    "                h += p+log2(p)\n",
    "            entropies[syn] = -h\n",
    "        print(entropies)\n",
    "            \n",
    "    def get_syndromes(self):\n",
    "        return self.lookupTable.keys()\n",
    "                     \n",
    "    def print_lookup(self):\n",
    "        for syn in self.lookupTable:\n",
    "            print(self.lookupTable[syn])\n",
    "            \n",
    "\n",
    "def train_plut(table, data_x, data_y):\n",
    "    i = 0\n",
    "    for index, x in enumerate(data_x):\n",
    "        syn = \"\".join([str(i) for i in x])\n",
    "        syn = syn.replace(\".0\",\"\")\n",
    "        labels = np.array2string(np.array(data_y[i]), precision=1, separator='',suppress_small=True).replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "        table.update_table(syn, labels)\n",
    "        i+=1\n",
    "    return table\n",
    "\n",
    "\n",
    "def test_plut(table, test_set):\n",
    "    predictions_lookup = []\n",
    "    for index, x in enumerate(test_set):\n",
    "        syn_x = \"\".join([str(i) for i in x])\n",
    "        syn_x = syn_x.replace(\".0\",\"\")\n",
    "        predictions_lookup.append(table.get_probable_error(syn_x))\n",
    "    return np.array(predictions_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model compilation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_FFNN_model_DepthThree(depth):\n",
    "    model = Sequential()\n",
    "    layers = 4\n",
    "    \n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    \n",
    "    for i in range(layers):\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(18 , activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(lr=0.05),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_FFNN_cv_model_DepthThree(depth):\n",
    "    model = Sequential()\n",
    "    layers = 4\n",
    "\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    \n",
    "    for i in range(layers):\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(19 , activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(lr=0.05),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_FFNN_cv_model_DepthFive(depth):\n",
    "    model = Sequential()\n",
    "    layers = 4\n",
    "    \n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    \n",
    "    for i in range(layers):\n",
    "        model.add(Dense(240, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(51, activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(learning_rate=0.05),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_FFNN_cv_model_DepthSeven(depth):\n",
    "    model = Sequential()\n",
    "    layers = 4\n",
    "    \n",
    "    model.add(Dense(48, activation='relu'))\n",
    "    \n",
    "    for i in range(layers):\n",
    "        model.add(Dense(400, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(99, activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(learning_rate=0.05),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D3 Training, Testing, and Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data sets from CSV\n",
    "\n",
    "#### Data sets for D3:\n",
    "* Original:\n",
    "    - \"depth3_all_combos.csv\"\n",
    "* Exhaustive:\n",
    "    - \"ex-samples-d3.csv\"\n",
    "* Randomly-sampled, with replacement (version 2):\n",
    "    - \"v2samples-d3-1000.csv\"\n",
    "    - \"v2samples-d3-10000.csv\"\n",
    "    - \"v2samples-d3-100000.csv\"\n",
    "* Randomly-sampled, without replacement (version 3):\n",
    "    - \"v3samples-d3-1000.csv\"\n",
    "    - \"v3samples-d3-10000.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported and formatted in 13.901138544082642 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "trainData_d3 = pd.read_csv(\"SAMPLES/v3samples-d3-10000.csv\")\n",
    "\n",
    "trainData_d3[\"Labels\"] = trainData_d3['Labels'].map(lambda x: create_list_from_string(x))\n",
    "trainData_d3 = trainData_d3.applymap(lambda x: add_noise(x,.01))\n",
    "\n",
    "testData_d3_MWPM = graph_with_errs_d3(trainData_d3)\n",
    "\n",
    "mlb_d3 = MultiLabelBinarizer()\n",
    "mlb_d3.fit(trainData_d3[\"Labels\"])\n",
    "df = pd.DataFrame(mlb_d3.transform(trainData_d3['Labels']))\n",
    "df['Labels']= df.values.tolist()\n",
    "trainData_d3 = trainData_d3.drop(['Labels'], axis=1)\n",
    "trainData_d3 = pd.concat([df['Labels'], testData_d3_MWPM, trainData_d3], axis=1, ignore_index=True)\n",
    "trainData_d3.columns = [\"Labels\",\"XSyn\", \"ZSyn\", \"X0\", \"Z1\", \"X2\", \"Z3\", \"Z4\", \"X5\", \"X6\", \"Z7\"]\n",
    "\n",
    "y_d3 = trainData_d3[\"Labels\"]\n",
    "x_d3 = trainData_d3.drop([\"Labels\"], axis=1)\n",
    "\n",
    "x_d3 = x_d3.replace([-1], 0)\n",
    "print(\"Data imported and formatted in %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Train on 5625 samples, validate on 1875 samples\n",
      "Epoch 1/200\n",
      "5625/5625 [==============================] - 0s 59us/step - loss: 0.6442 - accuracy: 0.7006 - val_loss: 0.5934 - val_accuracy: 0.7446\n",
      "Epoch 2/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5770 - accuracy: 0.7443 - val_loss: 0.5717 - val_accuracy: 0.7447\n",
      "Epoch 3/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5706 - accuracy: 0.7443 - val_loss: 0.5702 - val_accuracy: 0.7447\n",
      "Epoch 4/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5694 - accuracy: 0.7443 - val_loss: 0.5692 - val_accuracy: 0.7447\n",
      "Epoch 5/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5684 - accuracy: 0.7443 - val_loss: 0.5682 - val_accuracy: 0.7447\n",
      "Epoch 6/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5674 - accuracy: 0.7443 - val_loss: 0.5672 - val_accuracy: 0.7447\n",
      "Epoch 7/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5664 - accuracy: 0.7443 - val_loss: 0.5662 - val_accuracy: 0.7447\n",
      "Epoch 8/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5652 - accuracy: 0.7443 - val_loss: 0.5649 - val_accuracy: 0.7447\n",
      "Epoch 9/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5640 - accuracy: 0.7443 - val_loss: 0.5637 - val_accuracy: 0.7447\n",
      "Epoch 10/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5627 - accuracy: 0.7443 - val_loss: 0.5622 - val_accuracy: 0.7448\n",
      "Epoch 11/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5613 - accuracy: 0.7442 - val_loss: 0.5612 - val_accuracy: 0.7447\n",
      "Epoch 12/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5601 - accuracy: 0.7444 - val_loss: 0.5600 - val_accuracy: 0.7447\n",
      "Epoch 13/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5590 - accuracy: 0.7442 - val_loss: 0.5590 - val_accuracy: 0.7447\n",
      "Epoch 14/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5580 - accuracy: 0.7444 - val_loss: 0.5583 - val_accuracy: 0.7449\n",
      "Epoch 15/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5571 - accuracy: 0.7442 - val_loss: 0.5574 - val_accuracy: 0.7446\n",
      "Epoch 16/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5562 - accuracy: 0.7442 - val_loss: 0.5566 - val_accuracy: 0.7444\n",
      "Epoch 17/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5555 - accuracy: 0.7442 - val_loss: 0.5559 - val_accuracy: 0.7445\n",
      "Epoch 18/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5547 - accuracy: 0.7444 - val_loss: 0.5552 - val_accuracy: 0.7445\n",
      "Epoch 19/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5539 - accuracy: 0.7441 - val_loss: 0.5543 - val_accuracy: 0.7447\n",
      "Epoch 20/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5529 - accuracy: 0.7441 - val_loss: 0.5535 - val_accuracy: 0.7447\n",
      "Epoch 21/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5520 - accuracy: 0.7441 - val_loss: 0.5524 - val_accuracy: 0.7444\n",
      "Epoch 22/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5508 - accuracy: 0.7442 - val_loss: 0.5511 - val_accuracy: 0.7447\n",
      "Epoch 23/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5494 - accuracy: 0.7441 - val_loss: 0.5498 - val_accuracy: 0.7444\n",
      "Epoch 24/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5479 - accuracy: 0.7441 - val_loss: 0.5485 - val_accuracy: 0.7447\n",
      "Epoch 25/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5463 - accuracy: 0.7440 - val_loss: 0.5471 - val_accuracy: 0.7444\n",
      "Epoch 26/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5448 - accuracy: 0.7441 - val_loss: 0.5457 - val_accuracy: 0.7448\n",
      "Epoch 27/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5437 - accuracy: 0.7442 - val_loss: 0.5444 - val_accuracy: 0.7446\n",
      "Epoch 28/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5424 - accuracy: 0.7442 - val_loss: 0.5433 - val_accuracy: 0.7445\n",
      "Epoch 29/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5414 - accuracy: 0.7442 - val_loss: 0.5423 - val_accuracy: 0.7446\n",
      "Epoch 30/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5404 - accuracy: 0.7439 - val_loss: 0.5416 - val_accuracy: 0.7447\n",
      "Epoch 31/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5395 - accuracy: 0.7441 - val_loss: 0.5405 - val_accuracy: 0.7442\n",
      "Epoch 32/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5387 - accuracy: 0.7442 - val_loss: 0.5398 - val_accuracy: 0.7445\n",
      "Epoch 33/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5379 - accuracy: 0.7440 - val_loss: 0.5387 - val_accuracy: 0.7447\n",
      "Epoch 34/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5372 - accuracy: 0.7441 - val_loss: 0.5381 - val_accuracy: 0.7446\n",
      "Epoch 35/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5364 - accuracy: 0.7446 - val_loss: 0.5377 - val_accuracy: 0.7440\n",
      "Epoch 36/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5359 - accuracy: 0.7441 - val_loss: 0.5367 - val_accuracy: 0.7444\n",
      "Epoch 37/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5352 - accuracy: 0.7443 - val_loss: 0.5363 - val_accuracy: 0.7445\n",
      "Epoch 38/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5347 - accuracy: 0.7443 - val_loss: 0.5356 - val_accuracy: 0.7443\n",
      "Epoch 39/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5342 - accuracy: 0.7443 - val_loss: 0.5352 - val_accuracy: 0.7439\n",
      "Epoch 40/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5338 - accuracy: 0.7441 - val_loss: 0.5348 - val_accuracy: 0.7437\n",
      "Epoch 41/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5334 - accuracy: 0.7441 - val_loss: 0.5343 - val_accuracy: 0.7444\n",
      "Epoch 42/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.5331 - accuracy: 0.7443 - val_loss: 0.5337 - val_accuracy: 0.7440\n",
      "Epoch 43/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5328 - accuracy: 0.7443 - val_loss: 0.5334 - val_accuracy: 0.7442\n",
      "Epoch 44/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5325 - accuracy: 0.7440 - val_loss: 0.5331 - val_accuracy: 0.7437\n",
      "Epoch 45/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5323 - accuracy: 0.7443 - val_loss: 0.5327 - val_accuracy: 0.7441\n",
      "Epoch 46/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5320 - accuracy: 0.7442 - val_loss: 0.5324 - val_accuracy: 0.7437\n",
      "Epoch 47/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5318 - accuracy: 0.7443 - val_loss: 0.5325 - val_accuracy: 0.7437\n",
      "Epoch 48/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.5316 - accuracy: 0.7447 - val_loss: 0.5321 - val_accuracy: 0.7438\n",
      "Epoch 49/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5314 - accuracy: 0.7444 - val_loss: 0.5324 - val_accuracy: 0.7430\n",
      "Epoch 50/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5313 - accuracy: 0.7438 - val_loss: 0.5317 - val_accuracy: 0.7438\n",
      "Epoch 51/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5311 - accuracy: 0.7440 - val_loss: 0.5317 - val_accuracy: 0.7431\n",
      "Epoch 52/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5309 - accuracy: 0.7443 - val_loss: 0.5313 - val_accuracy: 0.7431\n",
      "Epoch 53/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5307 - accuracy: 0.7445 - val_loss: 0.5314 - val_accuracy: 0.7433\n",
      "Epoch 54/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5306 - accuracy: 0.7445 - val_loss: 0.5313 - val_accuracy: 0.7427\n",
      "Epoch 55/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5306 - accuracy: 0.7439 - val_loss: 0.5309 - val_accuracy: 0.7441\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.5304 - accuracy: 0.7445 - val_loss: 0.5308 - val_accuracy: 0.7447\n",
      "Epoch 57/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5303 - accuracy: 0.7445 - val_loss: 0.5306 - val_accuracy: 0.7432\n",
      "Epoch 58/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5301 - accuracy: 0.7442 - val_loss: 0.5304 - val_accuracy: 0.7432\n",
      "Epoch 59/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5300 - accuracy: 0.7439 - val_loss: 0.5303 - val_accuracy: 0.7433\n",
      "Epoch 60/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.5300 - accuracy: 0.7443 - val_loss: 0.5301 - val_accuracy: 0.7441\n",
      "Epoch 61/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5297 - accuracy: 0.7445 - val_loss: 0.5300 - val_accuracy: 0.7434\n",
      "Epoch 62/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5296 - accuracy: 0.7444 - val_loss: 0.5295 - val_accuracy: 0.7432\n",
      "Epoch 63/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5294 - accuracy: 0.7439 - val_loss: 0.5297 - val_accuracy: 0.7441\n",
      "Epoch 64/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5294 - accuracy: 0.7443 - val_loss: 0.5297 - val_accuracy: 0.7440\n",
      "Epoch 65/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5293 - accuracy: 0.7445 - val_loss: 0.5292 - val_accuracy: 0.7429\n",
      "Epoch 66/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5291 - accuracy: 0.7441 - val_loss: 0.5294 - val_accuracy: 0.7440\n",
      "Epoch 67/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5291 - accuracy: 0.7438 - val_loss: 0.5289 - val_accuracy: 0.7437\n",
      "Epoch 68/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5288 - accuracy: 0.7445 - val_loss: 0.5287 - val_accuracy: 0.7438\n",
      "Epoch 69/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5288 - accuracy: 0.7438 - val_loss: 0.5285 - val_accuracy: 0.7435\n",
      "Epoch 70/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5286 - accuracy: 0.7441 - val_loss: 0.5283 - val_accuracy: 0.7435\n",
      "Epoch 71/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5285 - accuracy: 0.7440 - val_loss: 0.5281 - val_accuracy: 0.7433\n",
      "Epoch 72/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5283 - accuracy: 0.7442 - val_loss: 0.5283 - val_accuracy: 0.7439\n",
      "Epoch 73/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5282 - accuracy: 0.7445 - val_loss: 0.5278 - val_accuracy: 0.7436\n",
      "Epoch 74/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5281 - accuracy: 0.7443 - val_loss: 0.5277 - val_accuracy: 0.7431\n",
      "Epoch 75/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.5279 - accuracy: 0.7448 - val_loss: 0.5278 - val_accuracy: 0.7434\n",
      "Epoch 76/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5278 - accuracy: 0.7444 - val_loss: 0.5273 - val_accuracy: 0.7431\n",
      "Epoch 77/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5275 - accuracy: 0.7441 - val_loss: 0.5271 - val_accuracy: 0.7444\n",
      "Epoch 78/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5275 - accuracy: 0.7445 - val_loss: 0.5272 - val_accuracy: 0.7433\n",
      "Epoch 79/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5274 - accuracy: 0.7445 - val_loss: 0.5268 - val_accuracy: 0.7440\n",
      "Epoch 80/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5271 - accuracy: 0.7441 - val_loss: 0.5269 - val_accuracy: 0.7439\n",
      "Epoch 81/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5269 - accuracy: 0.7441 - val_loss: 0.5267 - val_accuracy: 0.7445\n",
      "Epoch 82/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5268 - accuracy: 0.7443 - val_loss: 0.5265 - val_accuracy: 0.7434\n",
      "Epoch 83/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5266 - accuracy: 0.7441 - val_loss: 0.5265 - val_accuracy: 0.7436\n",
      "Epoch 84/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5265 - accuracy: 0.7447 - val_loss: 0.5260 - val_accuracy: 0.7446\n",
      "Epoch 85/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5263 - accuracy: 0.7443 - val_loss: 0.5258 - val_accuracy: 0.7438\n",
      "Epoch 86/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5261 - accuracy: 0.7443 - val_loss: 0.5257 - val_accuracy: 0.7449\n",
      "Epoch 87/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5259 - accuracy: 0.7442 - val_loss: 0.5252 - val_accuracy: 0.7442\n",
      "Epoch 88/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5256 - accuracy: 0.7442 - val_loss: 0.5253 - val_accuracy: 0.7439\n",
      "Epoch 89/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5254 - accuracy: 0.7446 - val_loss: 0.5250 - val_accuracy: 0.7442\n",
      "Epoch 90/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5252 - accuracy: 0.7441 - val_loss: 0.5247 - val_accuracy: 0.7438\n",
      "Epoch 91/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5249 - accuracy: 0.7442 - val_loss: 0.5245 - val_accuracy: 0.7444\n",
      "Epoch 92/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.5248 - accuracy: 0.7442 - val_loss: 0.5242 - val_accuracy: 0.7438\n",
      "Epoch 93/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5245 - accuracy: 0.7442 - val_loss: 0.5241 - val_accuracy: 0.7435\n",
      "Epoch 94/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5243 - accuracy: 0.7444 - val_loss: 0.5240 - val_accuracy: 0.7435\n",
      "Epoch 95/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5240 - accuracy: 0.7442 - val_loss: 0.5235 - val_accuracy: 0.7446\n",
      "Epoch 96/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5238 - accuracy: 0.7432 - val_loss: 0.5233 - val_accuracy: 0.7434\n",
      "Epoch 97/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5236 - accuracy: 0.7448 - val_loss: 0.5235 - val_accuracy: 0.7433\n",
      "Epoch 98/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5235 - accuracy: 0.7445 - val_loss: 0.5237 - val_accuracy: 0.7444\n",
      "Epoch 99/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5233 - accuracy: 0.7439 - val_loss: 0.5230 - val_accuracy: 0.7439\n",
      "Epoch 100/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5232 - accuracy: 0.7443 - val_loss: 0.5228 - val_accuracy: 0.7447\n",
      "Epoch 101/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5228 - accuracy: 0.7445 - val_loss: 0.5227 - val_accuracy: 0.7436\n",
      "Epoch 102/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5227 - accuracy: 0.7446 - val_loss: 0.5223 - val_accuracy: 0.7450\n",
      "Epoch 103/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5225 - accuracy: 0.7448 - val_loss: 0.5222 - val_accuracy: 0.7449\n",
      "Epoch 104/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5224 - accuracy: 0.7444 - val_loss: 0.5224 - val_accuracy: 0.7440\n",
      "Epoch 105/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5222 - accuracy: 0.7445 - val_loss: 0.5219 - val_accuracy: 0.7447\n",
      "Epoch 106/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5221 - accuracy: 0.7442 - val_loss: 0.5218 - val_accuracy: 0.7457\n",
      "Epoch 107/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5219 - accuracy: 0.7440 - val_loss: 0.5217 - val_accuracy: 0.7452\n",
      "Epoch 108/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5217 - accuracy: 0.7444 - val_loss: 0.5214 - val_accuracy: 0.7444\n",
      "Epoch 109/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5216 - accuracy: 0.7450 - val_loss: 0.5224 - val_accuracy: 0.7436\n",
      "Epoch 110/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5216 - accuracy: 0.7444 - val_loss: 0.5214 - val_accuracy: 0.7455\n",
      "Epoch 111/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5215 - accuracy: 0.7442 - val_loss: 0.5216 - val_accuracy: 0.7442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5213 - accuracy: 0.7449 - val_loss: 0.5213 - val_accuracy: 0.7448\n",
      "Epoch 113/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5213 - accuracy: 0.7451 - val_loss: 0.5212 - val_accuracy: 0.7444\n",
      "Epoch 114/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5211 - accuracy: 0.7451 - val_loss: 0.5213 - val_accuracy: 0.7450\n",
      "Epoch 115/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5211 - accuracy: 0.7449 - val_loss: 0.5210 - val_accuracy: 0.7443\n",
      "Epoch 116/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5210 - accuracy: 0.7449 - val_loss: 0.5218 - val_accuracy: 0.7437\n",
      "Epoch 117/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.5209 - accuracy: 0.7449 - val_loss: 0.5213 - val_accuracy: 0.7445\n",
      "Epoch 118/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5209 - accuracy: 0.7451 - val_loss: 0.5213 - val_accuracy: 0.7441\n",
      "Epoch 119/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5208 - accuracy: 0.7451 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
      "Epoch 120/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5208 - accuracy: 0.7449 - val_loss: 0.5209 - val_accuracy: 0.7445\n",
      "Epoch 121/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5207 - accuracy: 0.7449 - val_loss: 0.5207 - val_accuracy: 0.7441\n",
      "Epoch 122/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5207 - accuracy: 0.7449 - val_loss: 0.5211 - val_accuracy: 0.7440\n",
      "Epoch 123/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5205 - accuracy: 0.7454 - val_loss: 0.5214 - val_accuracy: 0.7439\n",
      "Epoch 124/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5207 - accuracy: 0.7455 - val_loss: 0.5208 - val_accuracy: 0.7441\n",
      "Epoch 125/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5206 - accuracy: 0.7454 - val_loss: 0.5205 - val_accuracy: 0.7444\n",
      "Epoch 126/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5206 - accuracy: 0.7452 - val_loss: 0.5209 - val_accuracy: 0.7438\n",
      "Epoch 127/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.5205 - accuracy: 0.7453 - val_loss: 0.5204 - val_accuracy: 0.7450\n",
      "Epoch 128/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5205 - accuracy: 0.7458 - val_loss: 0.5216 - val_accuracy: 0.7430\n",
      "Epoch 129/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5204 - accuracy: 0.7459 - val_loss: 0.5206 - val_accuracy: 0.7446\n",
      "Epoch 130/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5204 - accuracy: 0.7449 - val_loss: 0.5203 - val_accuracy: 0.7447\n",
      "Epoch 131/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5204 - accuracy: 0.7452 - val_loss: 0.5209 - val_accuracy: 0.7446\n",
      "Epoch 132/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5204 - accuracy: 0.7456 - val_loss: 0.5215 - val_accuracy: 0.7436\n",
      "Epoch 133/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5203 - accuracy: 0.7456 - val_loss: 0.5205 - val_accuracy: 0.7436\n",
      "Epoch 134/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5203 - accuracy: 0.7454 - val_loss: 0.5204 - val_accuracy: 0.7444\n",
      "Epoch 135/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5203 - accuracy: 0.7447 - val_loss: 0.5203 - val_accuracy: 0.7447\n",
      "Epoch 136/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5202 - accuracy: 0.7454 - val_loss: 0.5201 - val_accuracy: 0.7456\n",
      "Epoch 137/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5202 - accuracy: 0.7453 - val_loss: 0.5202 - val_accuracy: 0.7453\n",
      "Epoch 138/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5202 - accuracy: 0.7456 - val_loss: 0.5205 - val_accuracy: 0.7447\n",
      "Epoch 139/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5202 - accuracy: 0.7451 - val_loss: 0.5203 - val_accuracy: 0.7457\n",
      "Epoch 140/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5202 - accuracy: 0.7458 - val_loss: 0.5205 - val_accuracy: 0.7437\n",
      "Epoch 141/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5201 - accuracy: 0.7450 - val_loss: 0.5201 - val_accuracy: 0.7461\n",
      "Epoch 142/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5202 - accuracy: 0.7453 - val_loss: 0.5204 - val_accuracy: 0.7438\n",
      "Epoch 143/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5201 - accuracy: 0.7455 - val_loss: 0.5205 - val_accuracy: 0.7444\n",
      "Epoch 144/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5201 - accuracy: 0.7454 - val_loss: 0.5201 - val_accuracy: 0.7441\n",
      "Epoch 145/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5201 - accuracy: 0.7456 - val_loss: 0.5202 - val_accuracy: 0.7453\n",
      "Epoch 146/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5200 - accuracy: 0.7454 - val_loss: 0.5204 - val_accuracy: 0.7447\n",
      "Epoch 147/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5201 - accuracy: 0.7451 - val_loss: 0.5202 - val_accuracy: 0.7453\n",
      "Epoch 148/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5199 - accuracy: 0.7454 - val_loss: 0.5209 - val_accuracy: 0.7439\n",
      "Epoch 149/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5200 - accuracy: 0.7451 - val_loss: 0.5202 - val_accuracy: 0.7442\n",
      "Epoch 150/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5199 - accuracy: 0.7456 - val_loss: 0.5203 - val_accuracy: 0.7438\n",
      "Epoch 151/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5199 - accuracy: 0.7457 - val_loss: 0.5203 - val_accuracy: 0.7455\n",
      "Epoch 152/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5199 - accuracy: 0.7461 - val_loss: 0.5204 - val_accuracy: 0.7439\n",
      "Epoch 153/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5199 - accuracy: 0.7460 - val_loss: 0.5202 - val_accuracy: 0.7452\n",
      "Epoch 154/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5199 - accuracy: 0.7462 - val_loss: 0.5199 - val_accuracy: 0.7458\n",
      "Epoch 155/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5199 - accuracy: 0.7458 - val_loss: 0.5201 - val_accuracy: 0.7446\n",
      "Epoch 156/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5199 - accuracy: 0.7455 - val_loss: 0.5207 - val_accuracy: 0.7449\n",
      "Epoch 157/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5199 - accuracy: 0.7460 - val_loss: 0.5201 - val_accuracy: 0.7448\n",
      "Epoch 158/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5199 - accuracy: 0.7454 - val_loss: 0.5200 - val_accuracy: 0.7449\n",
      "Epoch 159/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5198 - accuracy: 0.7457 - val_loss: 0.5199 - val_accuracy: 0.7443\n",
      "Epoch 160/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5198 - accuracy: 0.7453 - val_loss: 0.5206 - val_accuracy: 0.7453\n",
      "Epoch 161/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5198 - accuracy: 0.7470 - val_loss: 0.5204 - val_accuracy: 0.7449\n",
      "Epoch 162/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5198 - accuracy: 0.7459 - val_loss: 0.5200 - val_accuracy: 0.7447\n",
      "Epoch 163/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5198 - accuracy: 0.7456 - val_loss: 0.5201 - val_accuracy: 0.7442\n",
      "Epoch 164/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5198 - accuracy: 0.7461 - val_loss: 0.5201 - val_accuracy: 0.7438\n",
      "Epoch 165/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5198 - accuracy: 0.7458 - val_loss: 0.5201 - val_accuracy: 0.7446\n",
      "Epoch 166/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5197 - accuracy: 0.7453 - val_loss: 0.5199 - val_accuracy: 0.7450\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5196 - accuracy: 0.7461 - val_loss: 0.5206 - val_accuracy: 0.7445\n",
      "Epoch 168/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5197 - accuracy: 0.7461 - val_loss: 0.5202 - val_accuracy: 0.7446\n",
      "Epoch 169/200\n",
      "5625/5625 [==============================] - 0s 33us/step - loss: 0.5197 - accuracy: 0.7456 - val_loss: 0.5200 - val_accuracy: 0.7453\n",
      "Epoch 170/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5198 - accuracy: 0.7453 - val_loss: 0.5198 - val_accuracy: 0.7449\n",
      "Epoch 171/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5196 - accuracy: 0.7458 - val_loss: 0.5200 - val_accuracy: 0.7441\n",
      "Epoch 172/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5197 - accuracy: 0.7459 - val_loss: 0.5200 - val_accuracy: 0.7442\n",
      "Epoch 173/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5196 - accuracy: 0.7462 - val_loss: 0.5204 - val_accuracy: 0.7434\n",
      "Epoch 174/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5196 - accuracy: 0.7458 - val_loss: 0.5199 - val_accuracy: 0.7447\n",
      "Epoch 175/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5196 - accuracy: 0.7466 - val_loss: 0.5200 - val_accuracy: 0.7450\n",
      "Epoch 176/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5197 - accuracy: 0.7459 - val_loss: 0.5200 - val_accuracy: 0.7455\n",
      "Epoch 177/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5196 - accuracy: 0.7465 - val_loss: 0.5200 - val_accuracy: 0.7450\n",
      "Epoch 178/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5196 - accuracy: 0.7465 - val_loss: 0.5205 - val_accuracy: 0.7448\n",
      "Epoch 179/200\n",
      "5625/5625 [==============================] - 0s 36us/step - loss: 0.5196 - accuracy: 0.7459 - val_loss: 0.5202 - val_accuracy: 0.7449\n",
      "Epoch 180/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5195 - accuracy: 0.7459 - val_loss: 0.5203 - val_accuracy: 0.7444\n",
      "Epoch 181/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5195 - accuracy: 0.7457 - val_loss: 0.5199 - val_accuracy: 0.7456\n",
      "Epoch 182/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5195 - accuracy: 0.7462 - val_loss: 0.5197 - val_accuracy: 0.7450\n",
      "Epoch 183/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5195 - accuracy: 0.7467 - val_loss: 0.5200 - val_accuracy: 0.7456\n",
      "Epoch 184/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5194 - accuracy: 0.7455 - val_loss: 0.5208 - val_accuracy: 0.7450\n",
      "Epoch 185/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5195 - accuracy: 0.7459 - val_loss: 0.5198 - val_accuracy: 0.7456\n",
      "Epoch 186/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5195 - accuracy: 0.7462 - val_loss: 0.5199 - val_accuracy: 0.7457\n",
      "Epoch 187/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5194 - accuracy: 0.7457 - val_loss: 0.5202 - val_accuracy: 0.7449\n",
      "Epoch 188/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5194 - accuracy: 0.7461 - val_loss: 0.5197 - val_accuracy: 0.7458\n",
      "Epoch 189/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5194 - accuracy: 0.7459 - val_loss: 0.5198 - val_accuracy: 0.7450\n",
      "Epoch 190/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5194 - accuracy: 0.7463 - val_loss: 0.5204 - val_accuracy: 0.7454\n",
      "Epoch 191/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5194 - accuracy: 0.7466 - val_loss: 0.5203 - val_accuracy: 0.7447\n",
      "Epoch 192/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5194 - accuracy: 0.7460 - val_loss: 0.5199 - val_accuracy: 0.7451\n",
      "Epoch 193/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5193 - accuracy: 0.7462 - val_loss: 0.5198 - val_accuracy: 0.7459\n",
      "Epoch 194/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5193 - accuracy: 0.7458 - val_loss: 0.5200 - val_accuracy: 0.7449\n",
      "Epoch 195/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5192 - accuracy: 0.7465 - val_loss: 0.5203 - val_accuracy: 0.7442\n",
      "Epoch 196/200\n",
      "5625/5625 [==============================] - 0s 35us/step - loss: 0.5193 - accuracy: 0.7464 - val_loss: 0.5198 - val_accuracy: 0.7454\n",
      "Epoch 197/200\n",
      "5625/5625 [==============================] - 0s 38us/step - loss: 0.5192 - accuracy: 0.7463 - val_loss: 0.5200 - val_accuracy: 0.7444\n",
      "Epoch 198/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5193 - accuracy: 0.7455 - val_loss: 0.5202 - val_accuracy: 0.7443\n",
      "Epoch 199/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5192 - accuracy: 0.7464 - val_loss: 0.5204 - val_accuracy: 0.7444\n",
      "Epoch 200/200\n",
      "5625/5625 [==============================] - 0s 34us/step - loss: 0.5193 - accuracy: 0.7465 - val_loss: 0.5199 - val_accuracy: 0.7460\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_151 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 18)                594       \n",
      "=================================================================\n",
      "Total params: 4,122\n",
      "Trainable params: 4,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model trained in 40.09910988807678 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "inputs = x_d3.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = y_d3.copy()\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "train_input_d3 = inputs[:,2:]\n",
    "train_output_d3 = targets[:,1:]\n",
    "\n",
    "x_train_d3, x_test_d3, Y_train_d3, Y_test_d3 = train_test_split(train_input_d3, train_output_d3, train_size=0.75, shuffle=True)\n",
    "\n",
    "model = compile_FFNN_model_DepthThree(3)\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x=x_train_d3,\n",
    "    y=Y_train_d3,\n",
    "    validation_split=.25,\n",
    "    epochs=200\n",
    ")\n",
    "model.summary()\n",
    "print(\"Model trained in %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate confusion matrix and F1 scores on test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive:   1507\n",
      "False positive:  1549\n",
      "True negative:   30194\n",
      "False negative:  9250\n"
     ]
    }
   ],
   "source": [
    "predictions_d3 = model.predict(x_test_d3)\n",
    "\n",
    "y_pred = predictions_d3\n",
    "y_test = Y_test_d3\n",
    "\n",
    "y_pred[y_pred>=.5]=1 \n",
    "y_pred[y_pred<.5]=0\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(len(y_pred)-1):\n",
    "    for j in range(len(y_test[0])-1):\n",
    "        if y_test[i][j] == y_pred[i][j] and y_test[i][j] == 1:\n",
    "            TP += 1\n",
    "        if y_pred[i][j] == 1 and y_test[i][j] != y_pred[i][j]:\n",
    "            FP += 1\n",
    "        if y_test[i][j] == y_pred[i][j] and y_test[i][j] == 0:\n",
    "            TN += 1\n",
    "        if y_pred[i][j] == 0 and y_test[i][j] != y_pred[i][j]:\n",
    "            FN += 1\n",
    "            \n",
    "print(\"True positive:   \" + str(TP) + \"\\nFalse positive:  \" + str(FP) + \"\\nTrue negative:   \" + str(TN) + \"\\nFalse negative:  \" + str(FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Epoch vs. Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss (MSE)')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Depth 3 Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Epoch vs. Accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAJcCAYAAABAGii1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAACFg0lEQVR4nO3dd3ib1d3/8ffX8t6ZznD2ICQhCSSEDWGPsgqUQimFLkpbOh94gK5fHzroHhRKSxelFCijBcqGQNiEDEJCIHs6e8d7SOf3x7kVyzNOkCzb+ryuy5dt6ZZ0jiXr/uhMc84hIiIiIl1fWrILICIiIiIdo+AmIiIi0k0ouImIiIh0EwpuIiIiIt2EgpuIiIhIN6HgJiIiItJNKLiJSJdiZmvM7LRkl6OjzGy4mTkzS+/AsVeb2WudUS4R6ZkU3ESkTUGIqjazcjPbbWZvmNm1ZhaX9w4zu9vMfvghbn+ymS0KyrbDzP5jZoPbOX6NmdWZWd9ml78ThK/hB1uWeDGzfDOrMLOnk10WEel6FNxEZH/Oc84VAMOAnwA3An9JbpH2eR840zlXDAwClgN37uc2q4HLo7+Y2WFAbqIKeBAuBmqB081sQGc+cEdaDUUkuRTcRKRDnHN7nHOPAx8HrjKziQBmlmVmvzCzdWa2xcz+YGY5wXUzzKzMzL5lZtuDFq8rguuuAa4A/jdoYfpvzMNNMbOFZrbHzP5lZtltlGmLc25jzEVhYPR+qvIP4FMxv18F3BN7gJkVmdk9ZrbNzNaa2XeirYxmFgrqu93MVgEfaeW2fzGzTWa2wcx+aGah/ZQp1lXAH4CFwCeb3ffxQavnbjNbb2ZXB5fnmNkvg7LuMbPXgstmmFlZs/vY1xVtZt83s4fN7F4z2wtcbWbTzezN4DE2mdntZpYZc/sJZva8me0Mnu9vmdkAM6sysz4xxx0R/P0yDqDuIrIfCm4ickCcc28DZcAJwUU/AcYCU/ChaTDwvZibDAD6BpdfBdxlZoc45+4C/gn8zDmX75w7L+Y2lwJnASOAScDVbZXHzIaa2W6gGrge+Nl+qvAWUGhmhwaB6jLg3mbH/A4oAkYCJ+GD3qeD6z4PnAscDkwDLml227uBBvzf4nDgDOBz+ylTtC7DgBn4v8s/iQmYwXVPB2Xrh/97Lwiu/gUwFTgW6A38LxDpyGMCFwAPA8XBY4aBb+Cfs2OAU4EvBWUoAF4AnsG3cI4GZjrnNgOz8M9b1JXAA865+g6WQ0Q6QMFNRA7GRqC3mRlwDfAN59xO51w58GN8GIr1XedcrXPuZeBJmp7gW3Obc26jc24n8F98SGmVc25d0FXaF/gOsKQD5Y+2up0OfABsiF4RE+Zuds6VO+fWAL/EBxGCsv/GObc+KN+tMbctAc4Bvu6cq3TObQV+Tcu/R1uuBBY6594HHgAmmNnhwXWfAF5wzt3vnKt3zu1wzi0IWgI/A3zNObfBORd2zr3hnKvt4GO+6Zx71DkXcc5VO+fmOefecs41BHX/Iz68gg+sm51zv3TO1QR/n9nBdX8naCEM/oaX4//OIhJHGs8gIgdjMLAT3/KTC8zzGQ4AA2K7Bnc55ypjfl+Lb61pz+aYn6s6cDzOuZ1m9nfgXTMb7JxraOfwfwCv4Fv07ml2XV8gIyhnbJmjkx4GAeubXRc1LLjtppi/R1qz49vzKeBPQX02mNnL+FbKd4AhwMpWbtMXyG7juo5oUjYzGwv8Ct+amIs/T8wLrm6rDACPAX8wsxHAIcCeoHVWROJILW4ickDM7Eh8iHkN2I7vopzgnCsOvoqcc/kxN+llZnkxvw/Ft9gBuDgXLx3oDxS2d5Bzbi1+ksI5wL+bXb0dqMeHsKihNLbKbcIHmNjrotbjJxb0jfl7FDrnJuyv4GZ2LDAGuNnMNpvZZuAo4BPBpIH1wKhWbrodqGnjukpiJl4ELWH9mh3T/Dm4E99qOcY5Vwh8Cx/Go/Ub2Vr5nXM1wIP4VrcrUWubSEIouIlIh5hZoZmdi+/Cu9c5t8g5F8G3EP3azPoHxw02szOb3fz/zCzTzE7Ad7c9FFy+hTaCQAfLdJGZHWJmaWbWD99S9E7Qhbk/nwVOadYaiHMujA8gPzKzgmBs2TdpHAf3IPBVMys1s17ATTG33QQ8B/wy+HulmdkoMzuJ/bsKeB4Yj+8angJMBHKAs/Hjz04zs0vNLN3M+pjZlOA5+CvwKzMbFEyeOMbMsoBlQLaZfSSYJPAdIGs/5SgA9gIVZjYO+GLMdU8AA83s6+YnpRSY2VEx19+DH494PgpuIgmh4CYi+/NfMyvHt7Z8Gx+OPh1z/Y3ACuCtYGbiC/iusqjNwC58K9s/gWudc9FxaH8BxgczGB89iLINxg+ULwcW4Qfkf7QjN3TOrXTOzW3j6q/gW6tW4VsW78OHI/BB9VngXWA+LVvsPgVk4pcq2YUf+D+wvbIEs2YvBX7nnNsc87UaH4Cucs6tw7cQ/g++m3oBMDm4i+vx9Z8TXPdTIM05twc/seDP+BbDSvzEkvZcjx9PVx7U9V/RK4IxjKcD5+Gf1+XAyTHXv45/DuYHrZoiEmfmXLx7KkREPDObgW+dK01yUaSTmNmLwH3OuT8nuywiPZEmJ4iISFwE4x+PwC8xIiIJoK5SERH50IIZvS/gl0IpT3Z5RHoqdZWKiIiIdBNqcRMRERHpJlJijFvfvn3d8OHDE/oYlZWV5OXl7f/AHkr1T936p3LdQfVX/VO3/qlcd0hs/efNm7fdOdd8zUUgRYLb8OHDmTu3rVn/8TFr1ixmzJiR0MfoylT/1K1/KtcdVH/VP3Xrn8p1h8TW38zaXE5HXaUiIiIi3YSCm4iIiEg3oeAmIiIi0k0ouImIiIh0EwpuIiIiIt2EgpuIiIhIN6HgJiIiItJNKLiJiIiIdBMKbiIiIiLdhIKbiIiISDeh4CYiIiLSTSi4iYiIiHQTCm4iIiIi3YSCm4iIiEg3oeAmIiIi0k0kNLiZ2VlmttTMVpjZTa1cP8zMZprZQjObZWalza4vNLMyM7s95rJZwX0uCL76J7IOIiIiIl1FwoKbmYWAO4CzgfHA5WY2vtlhvwDucc5NAm4Bbm12/Q+AV1q5+yucc1OCr61xLrqIiIhIl5TIFrfpwArn3CrnXB3wAHBBs2PGAy8GP78Ue72ZTQVKgOcSWEYRERGRbsOcc4m5Y7NLgLOcc58Lfr8SOMo5d13MMfcBs51zvzWzi4BHgL7ALnyg+yRwGjAtejszmwX0AcLB8T90rVTCzK4BrgEoKSmZ+sADDySknlEVFRXk5+cn9DG6MtU/deufynUH1V/1T936p3LdIbH1P/nkk+c556a1dl16Qh6x464Hbjezq/FdohvwgexLwFPOuTIza36bK5xzG8ysAB/crgTuaX6Qc+4u4C6AadOmuRkzZiSqDgDMmjWLRD9GV6b6p279U7nuoPqr/qlb/1SuOySv/okMbhuAITG/lwaX7eOc2whcBGBm+cDFzrndZnYMcIKZfQnIBzLNrMI5d5NzbkNw2/KgxW46rQQ3ERERkZ4mkcFtDjDGzEbgA9tlwCdiDzCzvsBO51wEuBn4K4Bz7oqYY67Gd5XeZGbpQLFzbruZZQDnAi8ksA4iIiIiXUbCgptzrsHMrgOeBULAX51zi83sFmCuc+5xYAZwq5k5fFfpl/dzt1nAs0FoC+FD258SVQcREZG42bIYNsyHKVdAmpZRbdOih+HN26HXCOgzGuqrYE8ZhDLhwjsh9CGiS/lm2LsBBk+NX3k7WULHuDnnngKeanbZ92J+fhh4eD/3cTdwd/BzJdB9/9oiIpIYezfCPz4KkTBk5cMhH4GTbmj/NvU1sGs19BsHLcdTx8/u9fDSj+Hd+wEHa9+AC26HtFDrx0fCsGMlbHoXNr8Lgw6HiRe3/xjblsG6N2HqVQdXxoY6SM88uNvGU/VueOoGyMjxP7//qA9sOb2gfBMcdS2UfogY8OIP4YPH4ca1iX3OEyjZkxNERBJr3VuwYR4cs78GfTlglTtIC9e1ft3OVfDI5+DSf0DR4MSXZdNC2LYERs7wrSqv/Aymfx5yils/vq4K7rsU1rwK/cfD4Z8E52D9Wz4wfOJfkJnX9uM5BytnYpH9lKtyO/zheKivhmO/4kPIq7+Ahhq46C4IZfjjaivgrTthxQuweRHUVzbeR+9R7Qe3+hp44HLYsQIGTGxsTXIOqndBbu/2y7j4P/Dol+CTj8CwY/dToVbU7IH0nP0Hv0jYf8Uet2stpKU3vkZe/pkv86ceg4GTIFzvry/fBL861D8/7QW3HSvh4U/DJX+DPqNaXr/1fV/eyu2Q369j9Xv6Jlj+HNRVQF0lXP0kDJrSsdsmgNpqRXqq6t3+DT2VrHkNPnii6WVv3gHPfgsWP5qUIiXM/H/4VqbW7CmDV38Jkf2lijasfcO3wLQnEoY/HMeI1W3MDXv/MR+Y33/s4MpwoCq2+O8X3AEX/B7CdbDkydaPra+Bf13hXy/HfsW37jz7LXju27D+bR/mVre29nuMtW/AvRczZP2j7R/32q+hdi98/kU44wdw6nfh9Ftg8b/hd0fAs9+GN38Ptx0OL/0QXASOuNJ3CV77Ohz9Zdizvv3n8uWf+tAWyoLZdzVe/sZtPuyUb2n7thvmw3++6Lsj3/ln+3VpTSQMvz8WXvj+/o+9/3L40QC442i4/xPw68Pgt5Pgtik+tG5bBm//0dd/4CR/m1CGbxkrHARFQ2H97PYf49Vf+ZbKxf9ueZ1z/jHAt7Tuq0PEB/nWbF8Bs++EvL4w9iyYerVv/UsiBTeRnuovp8PDn0l2KVqq2OZD1KKHYeGDvqUkEo7Pfb/6S3j6f5tetvUD//3Jb/rH7gl2r4PHr/PPb2sn9Ll/g5m3+G62A7X5Pfjb2fDSj/Zz3CIo30Tf7XNavz4afFY83/TyXWv8CXR/wvWw9Bn415Xwx5OgZm/7x1cEm+jk9YPBR0DxMHjvkZbHOQePfBZWvuhD3hk/9KHqK/Phm0vg64sgIxdWzGz/8da+AcCQ9f/xH5Jas2cDvP0nmPwJ3xIWddzXfEtkv0Ph7bvg2Zuh90j47Avwuefh7J/ClOA2fUb6EFrRRvjauABe/61vMZx6lQ8sFVv918s/8y17q2a1ftu9G+GBT/hQMuYMWPJEY2CvrYAHr4It77f/d9gwH/aW+Va79p7XtW/C8mdh7JnQaxhsXwqDJsNZP4VRp8IzN8GfT/Mtd6d8t/X7GHoUrJvd9uPs2QAL/+V/XvFiy+vLN0Fduf9556rGy+f9FX49wde5ubl/9S1+l/4Dzr8NzvyRL38SKbiJ9ES71sL2ZbD0SVj9avzvf+fq1t/kOuKZm+Chq/zJ89+fhz+eAD8dAY9/te3bbH4PZv0UHroa7r0EastbP65ymx94XLXT/15f49+gDz3P3+bJb+4/NFTthP9+zQfLWG//CZ7/3v5bojrDlsX++7o3fQtFc2Vv++9rXmt6eUcC09JgWPLsP8LeTW0fFwSznJrNPozFaqjzXdQWgjWvN7ZmrJ8Dv53ceqCKtf5tuO0IuP/jvvVr0wJ4dz+LqFdsgexiSM/yLTQTL/KBpXJ70+P2bvQB5cT/hcOvaLy8zygoHOhvP/wEH+zaLeNbkNuHjIYK36rbmld+5lvQZtzY8rrx58MVD8INK+ELr8JnnoEhR7Y8rjgICbvXtbwuEvEBPq+vD6DTr/Ehb97dfixXQw1kFrQd3J74pg/Elz8A0z4DNbth9cv+url/8ePL9tdiujzY3Kh8o2/pasusH0Nef7j4L74b+ivz4OP3wtHXwuX3w9lByDzl25DfxhbkQ46Cis2we23r17/1e//3nnix/x9oHva3LWn8eWdMi9u6t6B6J6xsFtbrqmDBvXDo+VBQ0nbdOpmCm0j5ZnjpVti29MBvW1cFf/sIBXuXf7gyVO6AWT/x42CiavbC386BX02AHw+Gu8/t+P1FT9hZhfD8dw++y6wtfznDnzAOxoZ5MPp0+PIc+NJsuOhP/pP3/L+33qpSX+3/DrNu9a0cK573J/bWVO7w36PBZsdycGGY8FE4+Vt+UPLSp9su25rX/XikeXfDO/c2vW7uX33Lxr0X+TE4yRSt3/AT4IX/8+N6oiJh3woCTYPbmtf86+ilW31rlnO+5fPeS5oGr6VP+dafSIMPHm1Z/QpkF/mfV77U9LoN83zX29SrIVzbWI45f/bf593d+n0657sN/3a2D18f/ydcvxwGT/MBNfo6Lt8Cr/wcwg2Nt63cCvkxJ9eJF/vnvnnw2BH8r444oe26jToFdq5sGUijImH/Ghx/AVv7HesDQ/S1t+9xVvrX0LRPQ/HQth8ru9B3C7Y1UD5629bCytrXfcvnaf/nu+/6jvGtV2/9Ht75hw9yo0/1Yax5aA/X+8uPuNK37I06xb9fLH7U/8+9cbs/rr0wBv7/se8hgMGyZxovj4Qbn681r/nXy/HfgMzclvdhBkd9AW5eD0d/se3HGnq0/76ule7S6l3+dTXxIpj6af/6bd7dHe0mzSxo2uIWbZVv3rX+3sN+PNz0z7ddpiRQcBN5+y54+Sdwx3S49+LGk2JHbHkP1r5G753vdPw2zjUdmxSuhwc/5YNJ7Il2y3v+jbn/oVB6pG952NXGJ801rzXtBlzzGuT2gbNuhY3vwPv/6Xj59qdmjz9Jvv9Y08DQnHPwzLf8J/+o6t1+bMmwY6DfWOg/DiZd6k8w4E+WzS1/Dmr3+IHTX/TdU/veaJs/XlXQurLlveC44BN2v0PhmK/4v8kH/229vGvfgL+f61tcBh3RtIXDOf/7gMP8GJs/n9ayJaczbX3fj/e56C4/2P3xrzaemLd+4AdR5/bxdYp2Q8//h2/RePkn8OdT/QeBh67yJ97Xf+uP2bvJv16i3W7z72l6gosK1/vWvomXUJvZB1Y1C26rXwEMTvrfoNvxed+Sufg/Puy19Vp+607fbTjmTPjCy3DouX6M01Ff8GO4Vr3ow8C/P+dfV7GhomJr05aakonQdyy812ys0/YguPUZ0/bfd9Qp/nvzQBq19X0/bm3I0awZ/gkfUl//ddNj5vzZtziecH3bj9MR7QW3RQ9BRh6Mj9kG/KhrfYjJKoQTb/CTNfZu8H+/WJve9eUeeoz/PT0LDjnHt0bO/Zv/H+89EjYvbLNoGXW7/etl0sf8e1T0Q1G4Af50Cvxmom8pn/kDyB/gQ2x70rPav77/eF+v9W81vTwS8a/hugrfDT3kKMjMb9mCtm2Jb5UdNKVxjFu4wfdOgA+e4Xr/s3O+lb3/+Ma/UReh4Cay6mUYOBlO/o5vqXjkcx3rUoJ9rXTZNe0M/m3u/cf8gOFHv+RD0NM3wtogsO0pazxuT7DRyJk/gnN+4X9uPl4I/BvNPz7adGzX2tf87LDJl0P/Cb5Vpq0uvgX3wd/Pg0c+7wcY7y+QRMvlIn6tpba89Xt46w7/5hf95B09CQyc0vTYPqP99+3NTi7gT055/f0JKK+v/3lrK+Nuast9NxH4rlXwx6Wl+/sPpfu/ydrXWy/vujd9nT43E4Yf75+LaLmrd/mTwuRPwBUP+ZPg4jiG4QO15X0oGe8HbM+4yT/f0TAb7SY96os+XGxeCA21viVt8uW+e2rPBv+3OffXfk2xBff7YBVtMRl7tj/pp2XAc99tPJlFbXzH/z1GnsTO3pP9/1DsOMU1r/pWpIIBvlVw+fP+dRau9S2sWLA0RjPvPeKXvrjsn00HgI+/0Lemzf6jf11FW1L2xvy/VGxpGtzMfKvb2tebflDavsy3uBQMaPvv23cMFA1peeKPWhcEh6FHU5U3xAend+5t2rK99nU/JuvDdrFl5PjXfPOu0oZa/15y6LlNW7FGnwbjzvXj5HJ7+/8baNldGozRaxJKJnzUd5e+8H0ffqZ+2oe+5q2Jgd47g5bdMWfAIWf5Lu29m3zr9KYF/jmb9WMftI7/hq/Lh5EWgtJpjS1u4XqY8xf/ofu1X/t6DzjMz1odfoIfpxj7Xr59GfQ7xAfS6AeSXav9+8a4c/37cfT9Yf1s/79z5Oe63LIhCm6S2qp3w8b5/hP+STfAmT/2J7QVHdyQY/tBBLfVL/sT4rv3+/E+c/8Cx1znP503CW7r/ffCwX78Ta/h/gTY3O51wQy6J/wb7O51/mv4Cf6N7qQb/Kf1DfNaL8+bv/cTBNbP9m9+8/ezg9zeILiVTIR3/uk/dTe38kV47jtQMMifCKJBK9pC0jy49R4JltayVaBmDyx7znd/RNe8KhnfeqtoZUyLY7TFbdsSH9qiyw8MO97/LWL/zlHlm31rUG5v38oRrvWtDtB40iweAiNOgsLSluPHOktDne/u6z/e/37YJf5vFw2SZXN9a9sRV/rf17zmn4/avTDhQj/e72sL/CD8aZ/xy6Q0VPvnfenTfkxV/0N9sDnhf/zr6o8n+fFpUdFxUMOOZ1evKf45jj639dX+tTQ86IocfZo/Ob7+Gx8Gxp4JI070QS426FTt9K/RsWe1PFGmZ/qyLn8OZv5f431HP0SAb3HObxaSxl8IOFj2bONl25dD39Htn4zNYNTJsOqVpt2xUeve9K/taGvYmDN9uI++zmvLfRfmkKPbfowDUTy0ZQvlihf83/2wjzW9PC3NB9/Jl/nfe4/wz2nz4LbuTf9/FxssR53sW7TCtb6lcOBkf3kbk1z67JjrW9IGTPKtdQAL/ulnx444qXHSx/m3w5GfPaiqtzDkaP93rtrpx8k++U2/bt9Ff4aP3d143OhT/f96bIvxtqW+Fbb3SKja4d9fos/ZMV/2EyOWPOlD8RPf8K+nSZfGp9xxpOAmqW3t676VJfqpdOLFPii99puO3T4YM3FAwa1sLgw/Dj77PBQM9CfS02/xrSexgWLvBt/qkJXvTySjT/ctDc2X+NjX5F/nZ1StCT4xDjvOf4+u6RQ7MDeqZi9sXezHlXx9oe9SXLOfyQzRQHnmjyBcx+ANzcaF7N0ED33aL2p6ZdBNFf10v3GBb8nI69P0NulZ/uQUHX8U9cET/iQSe3LqP8HXpflM1KqgVaDfob71Kdzg35T7H9p4THSNqmh5YpVv8s8HtBwQvi+4DfXPxfDjgtdOB1tm42n7Mj9+p2SC/z2/v28hjM7qW/82lE73wavPGB/cFj/qu4hGnORvk1XgX1fg72f4Cb41a/XL/gQcDTUn3eDHmVXv8rOUX7/NX776FSg5DPL6sKtXcHKPdpeuf9u/FqOPNeY0/71ym2/BAd8Vu3strIt5Hla+CDgf9Foz9dP+A09OL3+CTs9p/BBRV+lnC+Y1W5er3yH++NgPLduX+5P3/ow6xXfRb5zf8rp1s/14q+jfaXjwvxYN82Vz/fvK0KP2/zgd0WtYyxa3RQ/5gB5972rPyJP8JKVoCI1EfKvh0GZrtqVnweFX+tfDmNN96xX4D3bNhRvotWuBf77M/P978TA/G7m2wrf4mfkPnUdc2bhe3Yc1ZDrg4O/n+xbHM34En3/Jd9fGPsboU/336Ozgyh1+KEW/cT7Mgp+gsHUJYD6kjj7VB7cXf+jfO86/3f+vdDEKbtLzRcJ+DNDGVsahrZrlx+CUBrO50jP9J6+1r/k33/3Z1+K2vWV3Umvqqnxr0eBpvsn/S2/6aeZpISgqbdbiVuZbdqLGnOHHpKxrFjqis6OKh/kB/mte8yeraItMYakfB9NacNsQnGCGBCeYESf4N/T2Zk7uKfOtg8NPgHEfYfCGp5qugbT6Zd8ScOHvfWgqGtLYFbzp3cZP8c31Gd04/ihq0UO+pTF2e5qS8X6sVuysMGjs4h05w4e9zQt9K0W/mOBWMiEYY9VKa1n55sbus+Ih/ntrwQ18KK7c1jg2pr4G/nOtb72si1k4Naq+xrfA7E/VTr+EQ1trSkFjC0H0+QXfxbVjua/XjuWNsxOHH+9D6tKnfFdQWwukHv0lPyuwocZ3ecU69Fy4zg/E5/nv+g8162b7VjOgPrPYh7joeLDVr/jXx7CgC673SL+AbHaxb/EDX5aswqbrhq14AXJ6+67S1hSUwGX3wZWP+i7zotLGDxHRpUCat7iZ+fGK0f/9ukrfvdq3nfFtUSNO8i2ZzZcF2b3e30dsF2PxUP//F32dr5/tb1s6ff+P0xHFQ4Ou++DDSm25bx2dcFHHAtHIGT6Eblrgf9++zM+iHHZMy2PP+jFc/YT/2+X29mMpWxvnVjaHjIZKH/DAH3/I2f79ZPo1TT8wxVPpNP+33bIITv1/cOx1rbee9h7pt8yKDi8J3qv3dZWC/9C77QMfjDPzYNxH/IeBN27zE2vGnpGYOnxICm7S9e0p8zPh7r/84Jag2LHCB5oF97W8btUs3woTe0I74lP+5P76b9q/3/pqHwyKhmBEWu9+a27Tu36mW+m0xsuibzqxJyLw3UBFMcFt+PF+gc3m3aW71kB6NpzwTR/OFv/bB4voXohpaf7NqrUB/euiJ5igPMNP8OGwtVaG2HIVDvJhc/LlfjmE2PvescKfuPsHLULDjvPhoWavv67N4DbGT3aItmJVbPUhcOIlTd+Yo4Fla7Pu0ujEhJFBS897jwCu6QkkLeRPuK2Ncyvf3NjiVtRKcMsq9OED/HMBjQHw/cd81/ezN8OvJ/oxPrFm/wHuOrntZUzAn5Qf+ZxvsWivq37LYt/yFBs+Dj3fP4/Pfcf/XhoT3Gr3Bt2kH237Psee6QNyVlFjS22srAK4+M8+cL3w/3wwDoIbAKNm+K63O472S2MMOrxpS8W5v/Zj26JjnDJzfSvqew/7rqxIxNd51CltbwMF/kRaEjz/RYMbu0qj3eTNgxv4Nd22fuBDW7Qrvr2JCVG5vf1ruPkQg5jxbU0MP8G3dkci/m/Rf4KfMRoPxUMhUu9bhSHozqtp2U3almjrZzRcRz/8dWTQ/cBJrc8sXTkTR1rTFr+pV/vX4oybOlaug5FVAMd+Fc681b/ntWfChf51tX1546oBfcf61zr4197WJY0f7sae5f+Piof55VW6KAU3Sa7d65uOP2nu2W/Dbw7zM+GWPgVlbSz22Z5oS0fzN+C9G/0nz+ibWlRWARz5ed9N19raSVE7VgCu8RNnW2sLxYqWf/C0ltcVlfoyRcf97FnfdKugzFx/Im4e3Hau9m9EEy/xM6nqqxqDRVT/Q1tf7mT9W74VKnqSHX48YO2v/banrDFQ9hvnv2+Pue8dK/wn2H3jyo71J9bF/wZcy/FtUX1G+W1+oien9x/zn94Pu6Tpcf3G+TI2Xxg02uI29BgfbKKzCZt/8h92rC9j7GrykUjTrtKsfN8NFX3+96z3YS4aIHuP9MdGg9u8u/1ln3nWtxw+eX3TpV02zg9OvO10qb/808bB8NExeq3Z+r4/+cS2tOT19UFq0wJ/4hl0hL88+jrILm4MtK1JC/lgFbsFU3OhDL+N0JgzfYiNba2Z/Akf+PqM8mOrmp/0Rp7UsvUidvLD5nf9a6StbtLWFMa0UEcXp21t/a/BU/2HpU0LG1t0O9JVCn7x213NWnbXveknN0S7qqOGH+9bsbYs8q318eomhZZd9+8/7us/pIMtenl9/fjON27zH47WvuknPERbntozYJK/TfMPzWtep7xgVNMtxfofCh//R9vbjMXL6f8Hx3xp/8cd/WX/ofaVn/v3v4xc/3+cVeDrv21ZMF40eB/L7R2sM/dgl+wijVJwk+R65Wd+v8CNC1pe11DnWyrGnOEHucKBLdURFQ1umxc17QJcFQywbm2MyCHnAK797q1oEBoTnJDaWqoj1oa5/k24tT3yCgf7k3vlVv8mWbO7aYtb9LF2LG/aTbhrte8SyMr3g/ihZXDrd4hfuDJ2/bFI2J9ghsScYHJ7+0kHa5qtfxRrz/rGcvUaTsTSG7sMwc8Mjc4ShcYWnLfu9N/banGLtiBFT64rZvpA2jx4Zeb6E07zFrfK7f6NOafY17d8o2+h7DWi6XHDgr9NbKtb1Q4/biwa3MC/wce2uMWuxWUWdEO+Tm7lOt+CccRVvhXmuK/6oBAbLKOv27ZWv1/ypA9uU67wrUGb2wlu0RmlzUVb1EomNI5fKxjgu+umXLH/LrUh01t2kzaXnukXa/3au41ruIEvz1WP+0Hx5/2m9S645goH+haTJU/4XR6gcVxSRxSV+r9nQ137wS0aYjfOD15b1rHAAv61s2tt0/GUG9+BwYe3bBkMxrm52X/wM27juYREbHBrqPMt0WPPOLDZjh+908+wfiDY6mvYMR27/cBJgGv6YaK+GjbMZXfxhDZvdrC2ldfyt9dXc+PDC/nZM0v4y2urueOlFXzvsff47qPvsWRz07UenXNU1Dawdkcle2uaDVfJ7+dnhS56KFhvbkxjT0Tvkf6DUqSB9RnDeWReGS8v28aSvqdR06sDLbJJlJ7sAkiKi44je+47cNV/m76RRAdhH/Yx/6k5f8DBBbfoG064zp/so2NoVr/sW1VKJra8TZ/gjb29dcq2L/OtGyNOJGIh0tpcrDPS+GZRNq/tT+LR7rk9ZY2f9gqbB7fT4Zkb/RtO72DZkl1rGsPnSTf5xTCb1ynaFbB1SeNJdctif4IZ0qw8I07wXX0NtS3XVYpEfKtgYdASGEqnOmcgedGFLSMRvxZb7OKmfUb5LqxtS/xz2NbyCNHuqx0r/Elvzasw6eOtH1syvmWLW9V237IAvv5b3gtappq9zQ2c5Mf8rX2jMehGW/lil4goHtrYBbx7XcsuxGHHwaKHGLXybt9yNCVYhT8aTDct8Jth11U2vo6aB7cN8+Dln8Oyp33Lxkd+CY99uekMzljVu/34qv6tBLdx58GT/9Py+fzc8/GdRJGWtv9NyzvqmOtg3t/9xISBk5sEr9eWb2dkvzwGFbexhETRYMD5565iK2CQ27flcQUl/v9owzz/d+g1DDKyWxy2fmcVvfIyyc+Keb30Huk/TO0p87dzjvC2ZewYfTGxEbG8pp6nVxgnhwZQ/M6/yDB4YvdQTqlrIDfzwE+z63dW8cIHWzh74kAGFGU3flDatda3+NVV+MlKHRSOOFbX9aLvR/5I8SMfDyZOHNvubarrwsxbu4ux+eN8XTctpGbgkcxZs5O6Fa9wariOx8vHsuKBd9hVVc8hAwq4dNoQRvfP33cf9eEISzeX88GmveysrGNPdT0Di7K54PDBFGZn4JxjYdke5qzZybqdVSzfUsHba3YSjjj65GWyp7qehoh/7RbnZlBbH+Efb63l9PElDC7O4d2y3SzdXE5VnQ/WGSHjxDH9OHPiAEp75VCUk4GNuJpDZv+J0I4VLC85m2dmLqemIcyZVb2YFHSxf+GZSt53jd3BmelpHD6kmHEDCti0p4Z1O6voV5DFWRMHcMb4AfQr2M96cwmm4CbJU7PXnxh7j/Qn6eXP+bE2UdGQFg0hJRPa70Jqy+ZF/k1q3Rt+nbZBh/uAsWqW715Ka6XhOaeXD3XNl6eItW2p/yScmUdtVj9yWusqnfVTv9zHZ5/zTfZ7y2Dwl1u/v+ib8571visq9rKo3iN9+Fk323+SrNjiu0ajrUpFg/1g3eb6HRKUOSa4RTdrbn6iH36CXyurbE7LlrvKrf5EFlOuqtxS8qJdpeWbfHn6jGq8jZnvnlz8H7/wZVsKBvoWsx0rfNnqKtpugek/wXdl11U1rmFVub3xxD1gIiyk9QHSoQwfnmNb3Mo3N5Yhqniof01W7/JjxJqvfh/8bfrsnBesMxa0ohYN8V2T0QHdWz8AYsbtRa19w+8QkF3s1xA86gt+DFjJRD8+r3p3yy6naJCM6aaLRBwNEUdmXh/49NOttyZ1oXWo6sMRMkLB/1xGNpHTbyHt4aupGX4q0Th1z5tr+N5jiynITufWiw7j3EmDWt5R9MPDnjL/d83rS60zWjulusFHsHPZW+wOZzKwdBTRVc/CEcfz72/mr6+v4e3VO+mbn8kNZx7Cx6YOIS3NGmcf7lpNVd5gfv/4q1xfX8HvFqaRV7iE/zljLG9vbuCGX77MtvJa7sgbz0fsRbZaH657chs5z73AiWP7csq4/uytbmD+ul1s2VvDEUN7ccyoPkwYVET/gizS0oxIxLGtopa/vLaau19fQ104wi+eXcr/nHEIF08tJTe3hE2rl8DmrZSmZfBe5mQWv72OpZvL2VNdT1VdAxEHvXMz6ZWXSV1DhF1VdWzYXc3iDXuorAtjBv/X52qurPgbT1aMof6dMrburWXRhj2s3FZJ3/xMhvfJY0dlLS8t2UZ1fRhwLMgpYtGrM7nmiaFU14f5augpTk43/r5tDNl1uyjMzuD117Zz1yurOHRgIRkho7ouzLqdVdQ2NC75EkozwhHHrU8v4ZRx/VlYtod1O/1EnIKsdIb1zeULJ47kwsMHM7akgEjEsae6npzMENkZIXZX1XH3G2v462uraYg4Jg4q4uNHDmFAYTZ98rNYunkvTy7cxMwlW5s8/zeln8q16U/waFkBd6xdRijNyE4vYFIaREjjMxeeyZQRA9hdVcemPTW8u343s1fv5KF5ZQwuzmFo71xWbqvg2/95j+88+h73fe5ojhnVbGZ8J1Jwk+TZOB9wfpDps9/yY11GndrYQrLlPb8qfLTbrWSC7zoNN7RsRXn7T767q/mg2IqtPtwc9zUfWjbOBz7rQ0n5Jj8YtS29R7W+anxUdDFHoCa7PznNu0qXPOUXnwQ/4zC6lUvsxIRY+4JbWUxwG9z0GDPfpRUNXdEu097NugNb3PeQljNL18/2IbB5IBl2rG9JXP1qy+AWHVMUbR3EBzfWvx2sL9bG4O9hx/ng1lY3KfgA3WeUv4+VM323zvATWj+2ZDzgfH0GB11hVdsbB6dHg0107EpzQ472z01tuW/dbLXFbZgfAB4dG1k8pOl99BntH69ii99lIMqCpQWiA7pjP2zEtrhFW5uvm9O0i2/ApMbbNf/7R7uH+49nR0UtD80r45+z17J1by2fPm4EX5xxOEU5rXeJNoQjLN1Szvy1u3hn/W5yM0Occ9hAjhrRh1Bay2C3dW8N985ex56qOr58ymj6F/hY5Zxj/c5q1u6sZMOuaqr3hJkR3GZbeS23v7icJZvLqW2IEEozPnr4YC6ZWkplbQM/e2Yp/5q7nhPH9uPms8eRnRHixtdKGFj3JRbPmcQNpZuprgvzvccWc/Ih/dhdXc91973DC+9v4dxJgzhyeG+KcoP6Bf8vbk8ZO7asp6ounxO/8wxnTRjATWePY3jfvH3lfXb3IM6qe5wCl86D6yYwcf1udlXV8ZOnlrB0SzmDi3P4n9PHMmvZNm58ZBF3v7GW8ycP4ozSEkYBs96czfc3OgbumgOZMPyQyfzg5ZU8PK+M7RW1TBxcyO+vOIJpu3bDYy/Sb8IMHpx6DP99dyMvfLCFZxf7531I7xxKCrK55621/Pk1/7+bGUqjd14mOyprqQ87zOCSI0q5bPoQbpu5glueeJ9bnnifhzOLqC9fQi8r5003livuWgBAXmaI3vmZ5GSEMIx3g7plhtLolZdJ/4IsLp5aymGDi9i4u4YHPyjkd9unse2FGsC/Rkt75TCmfz47Kut4dMEGsjNCXDK1lBmH9GPZlgrWvDGKAVVLuWRqKacc2p9jXvs91E3k54f2Z8YM/+xvLa/h3/M38Nry7aSHjOyiECeO7ceUIcVMHOwDam5miEUb9vCPN9fy3PtbmFRaxHWnjObkQ/rTNz8Ta/YBIy3N6JXXOHGsODeTr582lutOHo2Ztfq6vfnsQ1m+tYIdlbXsra7HzCjNHEfdrB18+Yxr+Ubp4aSH0mBhJfz7QdJ6j+CSo0Y3uY/zJrf8oOCcY+mWcp59bwtThhS3uL4zKbhJ8kRPXEOP8oNN//VJPzMvunDolsV+IHo0pJVM9N2dO1Y0PSGH6+GlH/tWkSM/33SNsOgYtZKJvqVtQ7AswHuP+PFP0UUjW9NndNubM4cbfDmCwdTVOQPotTtmuZEdK31YGzjZLxz636/5iRhpGY0n5uayi/yg5z0bILvch6fYFqCoIUf5PTfLtzQOnG4+jqu51maWrp/t//bNW2Nyin0Z17wK3Nz0un3BrTFQVuWW+jFdO1c1rsPWp+kbIaNO8SE8diZia/qM9uMdK7b4sVltzcqLzljd+n5jcKvc0Xh56ZG++3js2a3fPjpGbPsy3w0fbXGLnZUYBLUlbz3NOKA2v7Rpa44ZjDmDyqUvkTdiRtP7HzgJZt/FwnXbOGTDQrIyC/xyA7Etbns3QmYBLq8fM9/fwvpdVZQUZlOaMYRJAJsX4YYdx6vLt/PEwo0M65PHx7fMpzijgOuf3sZT771HXTjC9BG9mVxazB9fWcn9b6/jnMMGMrm0iKF9cinbWc3KbRUsLNvDu2W793Up9c3PorK2gXvfWkff/CyuOmYYnzp2OIXZ6by9eicPzFnPEws30hBxpKcZjy7YyLfOGUd5TQP3vb2OVduaLnnyzOY3mTa8F39/Yy019WGOGNqLgux0tlfU8Z1H3+O3M5dTWx+mqi7MBVMGMWvpNs657VUyQmlkpadx8hmfY9m7G/nCP+ZhBseM7MOdn5xKKM34zQvL+NMrq3l0wUbMYEBhNv0LsynJauAu4HePvswJ4TXUhQq5fPoQHluwkZlLtnDGhAGM7JvHhl3VbFrbh7MyIdMa2JgxhO/9/nUiDob2zuW2yw/nnIkDSA+lcd0po3n83Y388eVV/PSZJfyMCEuyMljywUIKSo7jR8dnwtvw2QvPZNDhxq+eX8apgx0/+tRxPgz0OgnS0rERJzF9RG+mj+jNLRdMYPnWCopzM/aF35r6MO+s282KbRWU7axiR2UdffOzGFCYxdGj+jBugH/d3/3pI3n+/S0s31rBoFVjKdnyMqG6cpYc9r/84ZCpjB9YSGmvHN862EFfO20MFbUNVNY2UFUXpigng94x4cg51yRAnXpoCaSdAy/+kB9Mr4f+xfDQPD+DNEb/gmyuPWkU1540ivZMKi3m5x8r5ucdLnFL6aFWekkCaWnGIQMKgGaTC8Y8Q5PFcKIt0x1ctsTMGDegcN9zk0wKbpI8ZXP9GKScXn6ZgV4j/D6S0eC29f2mEweirShb3msa3FbM9LO5wAeyo65pvC7a2jHgMH+Cf/WXvpXl/Uf94N72puv3GQnv3ufHKGXm+dDy9/PgrJ/4gBGui2lxK4FN2/ykgoxcvwekGVx6j2+5WfminyU56PBWx9cA/viiwb6rtLbYt4a1NqA82rVZ9rZvcbO09jexjuo3LljkFB8adq/z+xq2ZuRJfk2ymj1NB6HvC26NXaWVecHP25f5wJqR2zJw9hkFN61vu+77jhvTOJv0lO+0fVzvEX4B1i3vM3/dLn7y5AfcW76V+VuM5/77PgvW72LV9i/zucUZfLm/a/FJPjrmr6JsMd9+NY1r9ixhfG5fLJgJW1Mf5tHlcBlQuexlSIPj/rCCoyYYP7n4MAqC8TmPDPwmj648jdDdcwlHHJdPH8pHJg3EDZiMhWv53zsf5qc5bzC63yHkpdVTv2cTd720goyQcfnWNWTnDeCzf5vDK8u2NSne3KwiFr/yEj98YzzLt1aQn5VORW0Dp2fO4j03kheWbOPy6UO44uhhjC3xJ6gvbtzDbTOX8+TCjdz/duNs6MxQ2r7xR4cPLeaIob0o7ZVDTX2El5Zu5aG56/nl88u465VV9M7PZO2OKvKz0rniqGFcfexwws5x48MLufER/yHoiKHF/ODCiYzpn8+Awmz+8N83eGVzFbNX7+S0Q/vzrXMOZWQ/P87JOccbK3fwp1dXkZ5m3HjWOMaUFLC7qo47X17J3uoGvn7aGEoKs/ncCSP448sr+WBTOT+9ZBLZGX7w/w1njuMrp4xhwfrdzFm9kzU7qthaXsOmKkdFWgHTe1Uytqqa7NFTOeqiSXzjtLH8+oVlvLJsO08v2kTEwRePORn3zo8xHNd89CzKFhQxeUgxVx49jMz0xhBgZlwwZTAXTBnM5j01vLJsG3UvD+HTAx3XXnE8PPW4n7ldMJCzDzPOPmwgs2bNagwSRaXwlXlNWqTNbN9zFJWdEeKYUX32291mZpwxYQBnTAAi42D9EwCMO+EixvVvZ8uu/cjPSm86lq/ZY7Yw/ZpgH9nvwKnf9TttDD8ODmDd8S6n9wjAWs4O7gYU3CQ5nPPdldEZmWZ+PNOC+/yg+NoK330V+0/Vd6zvPtuyuOkSEYse8uGvYCAsfKBpcNv8nh8Lk9vbzy5zEXjrD75FZ8JF7Zexd/DJcecqH/xWvuR/fujTvusV/EQAfFcp4MNQ+Ubf0vfRPzauF3Tub3xrX3Tz6rZEF+GtLW85vi1q4CTferV+tm8pKixte2HVWP3H+SBavQveuB2wtpdfGHu237R5xQt+N4movRv8iSu6nhlQnRO0vm1f6lshe49qfdxgO6Ft/rpdbN5Twzl9x/jnCHy3eQznHM8u3sKLS7ZwwZTBHNvvEHavWcAn35jNgKwGMl0dr2xw/LNsLZNKi5g4qIhfPLeMZVsq+MGFE/lg017mr9vFqH75nDhqCFlpmTz2/EyeqOrLeaHVZGUW8sG7G3lr1Q6eWrSJ+qoKLsuGI0KraQjlcsHUidz95lqWby3nV5dO4c5ZK3ly0Sb65mQyONMPvP7yffN5ZvEgDgnlch1w6eAdjNq+lkc3Hc/Uor1ENq7i5x/48YDTM5ex1+Uyb8dO/t954zlv8iC2ldeydkcVu587hMGVy8nNS+eXH5vMuZMHUrFjE33u3EDtoZcy+8JTyWt24p0wqIg/XjkN5xxrdlRRtquKob1zKe2V22qXUk7QVXrOYQNZvHEPf3x5Fbuq6vjqKWM457CB5GQ2zpp88AvH8NLSrQwqzuHQgU0/7Jw1IoMffOpEtuytobRXbpPrzIzjRvfluNFNJw0U52Zy89lNWzoyQmlcd0rrs/myM0IcPbIPR49sFnTuHMbRRTWwZ8e+SS/9C7O59SLfql3XEGFvTT1987Ng/VjYvpTiIeO57dBWZp82M6Aom0uPHALLx8KeYBjE9mV+ZmJ7Ywaj//PxFv1wVljauAxPZ8kughk3w1PX+31MwY8b3tKBRaW7qtzeft/h2MW9uwkFN0mO3Wv9mKTY8V6jToU5f/bjpaKDuWODW3qmD0qxG4zXVgSbZ1/mA8Nz3/Zr8/QL1mnavKhx25Zol9rrv/HjvWInQrQm2t23Y6W/j7K3/QKlWfmNY9eCx6nOKWms17v3+xXgYxc8ze3tP4nvb0mGolLfVVhX0Vju5tKzfMvd+rf9MgW9h7d/n1HRmaUf/Bfe/qNfaDg6aSGwalsF2RkhSgYfieX2peyNh/nZwhGMG1DApUcOof+e9VA4mIgDnCMtzQin5/iTyfblsH05Nf0O44WFG6mpjxCORAilpZGflU5uZojq+jCVtQ00RBx5memEneO+2Wt5a5VvMb39pFzOBcjpTXmv8bz+nm8xqQ9HuOfNtcxbu4uMkPHg3DL+XNSXyTVzGNo7l3sv7g9/ges/ehzfnHwm6aE0nHP8ftZKfv7sUh5/d2OTeuZkhHg0bQDD3Hoe+eKxjPx3HYt2F/OV+98hJyPE6eNL+OTR0+DBXlj1LtJ7jeG7503glENL+NI/53Pu714jPc246exxjI2s45STj6chHOH3s1b6Vq9IhGtys/l07/ew7VVU9hrHuzsWcmbWXp770onkZ6VTfOfXWVE4nhc+eRIDi/zMyb75WT4YbTwaZv+Bx66dvu81k7XdzzQ97LhzoY3WEvBhaUTfPEYEY7w6YsKgIm67vI0dC/DdT6ce2vZm6RmhtBahrVMUlfr3g4aaVpcCyUxP86EN/NjQqh0tt8Xan14j/HhP5/xrPLq9VWfrFSwJMvrU5Ew2mXq13xZt3Zv+vaT5tnXd0ZiOz8ztShTcJDmi49uiK7yDH4idlu4Hpu8bZN5sWYuSCf6NI2rJk34W42GX+qbv57/rW91O/Z7fZmj7Mr+NCfiB54WDfavRxIt992d7omMgogPu18/xWwmd9n/w1zP9oPagG7Eme0BjvZY85bsWmi+l0ZFWsaJSqNqOq92LHdLG+CyAIdNxs/9IJJRD9ZhzidTUk5+Z3mSsi3OOvdUNbNpbzfqd1ZStzuLTQN0TNxBKzyV06vf2Hfvehj387Nml+7rsMkLGj9MmcmblS8xNv5InFm7iNy8s55ncJex0+Vzx3aepDztCaUZmmuO+nP6ULJ3DgNq1/GnbZH65sJXtxdowoDCb73zkUN5atZNvvbKac7NgW/9jueC3r7NxT+O+rP0LsvjJRYdx/pRB/Hv+Bt5/oZTT7AUe/OQYCmv8Cvpp+f1IC7qtzIwvnzyaiYOLeHPlDqYO68XUYb34YNNennlvM5UrR3NM2gpCQ4qhfjtHTjqdf0yczhFDezW2ZhUN8S2UQWvHcaP78tiXj+N3L67gk0cP5fChvZg1y+92kR5K46unjuG0Q0tYua2CjLmTsWC7nc9efB7V7xn5c16luF+eHxNYu41J48dDUSvLXQyY5Lvity9r/PCy5jXf2tneBI9UUzgYlj3jf25t14RYp/2fX37kQENP7xF+Yehdqzu+XVYi9J/gPxB2dLeEeAtlwBk/gPsvS154FUDBTZKlbI4fCxW7HlV2oR+QvvJF39qU16/lp+iS8bDowcalEhY95E+uQ47y3XOjToGFD/rlFbZ94E+QsS1Xgw5vDG77k5Xvx5ntXAU1e3DblvBk5Chsax/OvvIx0moaF7Otzyj0rXhv3wWRelYPvZg+NfUUZnd8Y+VwxPHmtmyOByxcx5vbs5kecazdUckdL61kR2Ut1540iqNH9mFl9gRGhesIhev43YIIf5z3HGkGBdkZ5GSEqKrzA4+jayABGBEuy84mJ1LDDyovYfZfPyAnI8Te6gaWbimnKCeDG848hF65mazfVUVo10coXDqLNy/PZnXRdP45ex195m9nc8FYPjN1BNkZIcIRxwcr17ClaiiHV/htssaMP5z/nng8xbkZhNKMhrBfILOqroHsjBAF2emkmVFVF6amPsy4gQVkpYe44qhhfOLPtfx40yd5ZdlEsvuG+Mdnp9O/IJuIc4zom7dv3NMnjx6G63sB3Hs3hXuXNe5S0Mo6XieN7cdJYxtbWfZ13b18DLz0kl+WpmIrmcWDOWFMs9aY4mCfxpgxhMP75vHLS9sOT+MHFTJ+UCGUTQpm/xqhARPI3/SOfz1W7wzK6xqXtGgu+prdvKhpcBt6dPw26+4JYmddt7b4bqy8PgfXShT9ABfdsaSjuy7EW34/uHH1/o9LpLFnwUd+tf8hH5JQCm6SHGVzfYhqvqzHqFPgpR/6YNbaoNFoC9zW9/1+mStf9CvVR8dUTboM/v05ePy6xkVsY4PbIWf7JSSajZ9qU5/RsGMlC956gSk4Htw0kFfum8/EwYWcMX44a+YvYP2uKgoidUzLHUz+nmUsyRjPWfdspihnB9eeNIrLjhzCym0VLFi/m5XbKlizvYqK2gYumDKIS48cQkZaGjOXbOHPr64me0MNxwcNc397r4Fv/epl1u6oJDM9jYLsDC676y0mDi5ky8YIc4IGvROPnk6/4kPZW13P3hofkHIz08nJDNEnL5MBRdkMLMrhkAEF5PzzcMIV2xky5WssfH87oTRjWJ9czj5sAJ8+bkTTpSTqh8HP/h+29ClGfuQUvnvmSJi7i+OPmMLxJzWOT5o1axMz8k6EJx8F4KwTj4fSmAkNHZSTGeIvVx3JtfemcfzgIq4/85B9Qa01Fn19bH2/8bk+kBNzv0MAF2xb5ZouBRIVXbG+I5M/mou2jPUe6Vt3o8GiYkvj9kFtBbc+o/2s582L/DCAim3+dTv5sgMvR08WMwmAvP2PWzso0Rnb0a35khXcugIzOPKzyS5FylNwk87XUOtbMaLrmsWKBrfda+HQ81peHz1Zz7vbzybNyIXDr2y8/tDz/Ar2i//ju1Az85sulXH4J/3Xfjjn2FvTQGVoEIUbnmfW6ieZlG78+CufZvbGen79wjJ+9fwySgqzGFycw2sbGngzrYDTQ/CIO5lvnTOON1fu4KfPLOGnzzSundY7L5PhfXJJSzN++OQH/Pp5v+NAZV2YAYXZ/N85x8ML/tjLTz+WXywK8dnjR3DNiaMoyE7n3rfWct/b6zj76MlEVg8jbfdajps2jeMGdnALn4/9nZClcXV+P64+cT8noIwc/3wsfQrO+blvqYTWJ03EnsxiF989QL3zMnnwCx3cKii/v18kecvixvGIra2c35bomL9VwcbbrS29El27rfkabh0xMFj2ZUDwYSPalVexpXHrscJWFpYF/4GmZLxfJDgShrXBnqhtrWuXqmKD7/66Sg9W8VA/c3vNa/57R7fLEkkQBTfpfNuW+vE7rY3VGTTFzxCt3tV6i1vBQH/9wn/5sPDxfzYNChnZcOHv/dZBK2b68NHaDEegbFcVVXVh+uVnUVnXwMPzynhkfhllu6r37RD0hVCImzN2cWH+B1AwjtKBJZQOhAsPH0x1fXjflPrnZr7EmJ3TqVu2ghu+cTOZuQVcc+Io5qzZyZsrdzBuQAFThhbvW8cJYFHZHu59ay1pacZ5k4OFUCN18IIBjpOnH8HJJzcNIp87YSSfOyE4cTxylA+4+1t8t8nf7wBPboec4/eS3DjfL4sCrQe36CSH3L7++ekMZr6rfev7fqxhevb+xy3G6j3Cr6sXXauvteAWnb13MLP4+h3qu/ujW2XtC25b/Ybq0HKB5VhTPw3//aqfxRf9EKLxbU1F/35p6Yl73aVn+tf87nU+tDUfuyrSyRTcpPNFF4Ht30owSwv5tdsW/6f14GbmW9gqt8HZP2t7HbaMHDj03FavqqkP89uZy7nrlVWEY8aAARw/ui8XTB5MKM3IyQwxI7IXXr6f4TXvw/jG1fFDadZkHaTMkDH8wu9D7Tcht3HNpiOH9+bI4a3v63hYaRE/vaTZYrxpWf4EX7Pbtya156hrfWjNKmj/uA9j7Fk+EN19buOg7Na69/L6+fDUfOHdRCuZAPP/4R83r9+BDTwPZfjbbQtej60Ft5Ez4CvzD64VMT0Tvr7Id3lC067S8s0+iGW18foFvxvD5kXwxm3+WI1va6lgEGD+uW/jA1pc9Brhg1sqd5NKl6HgJp1v6/u+paOtk+GUT/rNlNtq5TjjBwf8kBt3V7Nk815WbavkgTnrWbG1gkunlXLi2H5sK6+lIew4a+IAhvRutqTB1jp4Ofh5yPT2HyQje/8LzHZEUalvOdpfCCmd6r8SKa8PfO4FmPMXeO/ffmeH1oKbmQ+SRQfRpfhh9B/vZ/xtmL//oNvq7cf54Gahxg3qY5l9qK5fMmJmjGbm+679iq1+rb7CQft/js/6id+NYtWslttfiQ/H+SX7n5jwYfUeCatfTt6MUpEYCm7S+bYt8Z9c22o9GHOa/zpAzjlWbPXb+xTmZFDaK4eyXdXc8+YaXl2+fd9xw/rk8vfPTG8y07BNvYLVtXFNly5JpCM+5Rfg7SoGHAbn/QbOutWXq61wevK3OrVYQGOr7I7lbS8m3J7oh4P8Et/am0hmPmBUbPE7V7Q1MSFWKB0+drff0u2wSxNbvu5q4CS/TEYiRYcjNN+DVyQJFNykbbvX+ZNLvE9oW9/3y37EgXOOuWt3cf/b65i1dBs7K+taHDOgMJtvnj6W40b3YWTf/CabFu9XRrZvRard03lv2rEblnclGTlNW5C6gthW2QOZmLDv9sHYvNZmlCZCdFP6vRs7vqRCTi8/OURa9/F78R+uEijYIaU7bo8kPY+Cm7Ru/Rz46xlw7Ff9BvDxUlvuA+ERBx9O1u6o5PUVO1i0YQ+zV+9g1bZK8rPSOWNCCUeP7MPhQ4qprAtTtquK7PQQJx3Sj4x2NiXer1EnAy6xY2jk4GTl+y2Gdq1pvatzf6IzS1sb35YI+f39GM+KzW3PKJUD0xmTBcacAVc/1XSnF5EkUXCTlupr4LEv+T0j5/4NTrzBnyDjYZvfp5H+h7a4ak91PRt2VVNd7xePraoLU10XpiA7nYFFOdQ0hPnzq6t4+r3NOAeF2ekcVlrEF04cybmTBrXYu3HKkOL4lPn82+JzP5IY/Sf44HYwY9x6j/TjLTsrROWXwAdPAK79GaXStaSlabcA6TIU3KSlWbf6rXZmfMvvyfnu/TD98wd/f841DsKO7jPaLLit31nFR257lb01De3eVUF2Ol+aMYqPTR3CsD65WDL27JOupWQ8LH3ywPegBD+4/eP/6LxNu/NL2LcPb0fGuImINKPgJk2VzfPLDxzxKZhxIyx/Fmb/AaZ99sC6CmvL/ZIe7z0Ca9+AKx6GkSf5bqL0HCgevu/QSMRxw8PvEnHwu8sPpzAng9zMEDkZIXIyQ5TXNLBxdzVVdWHOmFByQNtISQqIbpt2MF2l4HfT6Cyx4VLBTUQOgoKbNHIOnr3Ztwqc8UN/2VFf9FtIrZwJY07v+P3881JY90bjdj9v3hEEt/f9EgwxIfAfb63lrVU7+enFh3He5Na7rOLW7Sk9z+hT/ZjJoR3ccSGZYlf31xg3ETkIGm0tjVbM9Jtin/S/fjFVgPEX+I3W37qz4/ez7k0f2k7/gV+89MjPw/Ln/DikrR/sayEJRxxvr97JT55ewoxD+nHptE5eA0x6huwiPw4xpzjZJdm/aHDLyGv8HxMROQBqcRPPOXjpR35fvikxe3mmZ8JR18DMW3yX57Bj939fr/+WmoxeXL/iCEp2fcCheadxsf0Se/WXULGF7bkj+cED7/Dysm3srqqnODeDn1w0SePVpOeLLhRbNPjAdnkQEQkouIm37Bm/H+X5t/uwFuuoL/rZpU/dANe87BcFbcvWJbDsGe5suJjZZTVUrFhHdX2YoswjOHX+P0gDbni5nrnpWzlz4gCOH92XE8f2o/eBrK0m0l1Fg5u6SUXkICm4pbLyzbD2dait8F2hvUbA5MtaHpeZ68e8PXQVzPubn2G6cQGseQ2O/mKTBXrrX/stYTJ5seACZn19BrmZIVZuq+TlpzeTtnoOAGMPm87Pzz2evvnarFlSTHqWXyi4s7cGE5EeQ8Etlf3367Dsaf9zWjpc8te2t6EafwGMOAle/IHfF/Ld+wHnx+xM+pg/Zu9GbNGDPBg+me99/IR966qN7p/P6Cs/TcNtvyOtagc3f/wUdRNJ6rrsPrW4ichBU3BLVc5B2RwYfyGc+SPIKoTswraPN4OzfwZ/OA4WPQTHXgfLn4dXfwkTL2ZDRYS3//INJkeg4ogvcuTwZnsHpqWRfsHv/ObaCm2SyoYelewSiEg3puCWqvZugKrtMPx4KCrt2G36j4NPPwN5fakpGMqCqsEcveAmfv67X/PG5hD/yXqGNwZ9is+eN6P12484IW7FFxERSUUKbqlq4zv++6DDD+x2Q44kEnF87Z/zeGHxYF7MKuHC8vu5ND9CJGsAx159K6THeVN6ERERARTcUtfGd/y4tpIJB3zTO15awbOLt/CtcyYwJPfbpD3xVX/FeX+K356mIiIi0oIW4E1VG9/x+4Vm5LR5yNbyGurDkSaXvbhkC796YRkXThnE508YSdqUy6F4GLuLxsNhH0t0qUVERFKaWtxSkXM+uI07t42rHX96dRU/fWYpQ3rl8D9nHML0Eb25/cUVPDBnHRMGFfKTi4MFc9Mz4Qsv8+6bczlJkw5EREQSSsEtFe1eB9W7Wh3ftqeqnv95aAEvfLCVU8b1Z8Ouar5y/zuYQciMjx85hG+ePpbsjJhxbDm9cGna+F1ERCTRFNxSUTsTE258ZCEvL9vG988bz1XHDifi4PF3N/D+xr188uhhDOuT18mFFRERkSgFt1S08R1Iy2gxMeHd9bt5ZvFmvnHaWK4+bgQAIYOPHl7KRw9w8qmIiIjEnyYnpKKN7/jQlt50y6lfPLeUXrkZfOb44ckpl4iIiLRLwS3VOOf3GW3WTTp71Q5eXb6dL80YTUG2xquJiIh0RQpuqWbnKqjdA4Om7LvIOccvnltKSWEWVx4zLHllExERkXYpuKWaxf/234f77acawhFufGQhc9bs4qunjmk6W1RERES6FE1OSCWRMMy7B0acCH1GUV0X5rr75jNzyVa+euoYPjF9aLJLKCIiIu1QcEslK1+EPevg9P+jriHCZ/8+h7dW7eCHF07kk0eri1RERKSrU3BLJXP/Bnn9cOM+wnceXcQbK3fwy49N5uKppckumYiIiHSAxrilir0bYdkzMOUK7nxtPQ/OLeOrp45RaBMREelGFNxSxfx/gAvz3sCP8rNnlnL+5EF847QxyS6ViIiIHAAFt1SwbSm88TsYfRq3vxOmKCeDWy86zG8SLyIiIt2GgltPV7MHHvgEZGSz/vif8Oz7m/nk0UPJy9LwRhERke5GZ++eLBKBf18Du9bAVf/lTwtqyUhL46pjhie7ZCIiInIQ1OLWk6143k9IOONH7Oo7jQfnruf8KYPoX5id7JKJiIjIQVBw68l2rfHfD7uEf85eS019hM+fMDKpRRIREZGDp+DWk5VvgrQMyOnN4+9u5JiRfThkQEGySyUiIiIHKaHBzczOMrOlZrbCzG5q5fphZjbTzBaa2SwzK212faGZlZnZ7TGXTTWzRcF93maaGtm28i2QX0J5XZjlWys4emSfZJdIREREPoSEBTczCwF3AGcD44HLzWx8s8N+AdzjnJsE3ALc2uz6HwCvNLvsTuDzwJjg66w4F73nKN8EBQNYtGEPzsHkIUXJLpGIiIh8CIlscZsOrHDOrXLO1QEPABc0O2Y88GLw80ux15vZVKAEeC7msoFAoXPuLeecA+4BLkxYDbq7ii1QMIB31+8BYMqQ4uSWR0RERD6URC4HMhhYH/N7GXBUs2PeBS4Cfgt8FCgwsz7ALuCXwCeB05rdZ1mz+xzc2oOb2TXANQAlJSXMmjXrYOvRIRUVFQl/jAN13M71bE0fxgubllOSayx4+42EPVZXrH9nSuX6p3LdQfVX/VO3/qlcd0he/ZO9jtv1wO1mdjW+S3QDEAa+BDzlnCs72CFszrm7gLsApk2b5mbMmBGP8rZp1qxZJPoxDkh9DcwqZ/C4qWx8PYOjx/ZmxozDE/ZwXa7+nSyV65/KdQfVX/VP3fqnct0hefVPZHDbAAyJ+b00uGwf59xGfIsbZpYPXOyc221mxwAnmNmXgHwg08wq8C1zpe3dpwQqtgCwJ70Pm/bUMLm0OLnlERERkQ8tkcFtDjDGzEbgw9VlwCdiDzCzvsBO51wEuBn4K4Bz7oqYY64Gpjnnbgp+32tmRwOzgU8Bv0tgHbqv8s0ArKjOB2CyxreJiIh0ewmbnOCcawCuA54FPgAedM4tNrNbzOz84LAZwFIzW4afiPCjDtz1l4A/AyuAlcDT8S57j1Dhg9vC3dmkpxkTBhUmuUAiIiLyYSV0jJtz7ingqWaXfS/m54eBh/dzH3cDd8f8PheYGM9y9khBi9vs7ZkcOjCf7IxQkgskIiIiH5Z2Tuipyjfj0jJ4Y6PT+m0iIiI9hIJbT1W+mYbcfuytjWhigoiISA+h4NZTVWxmb3pfQAvvioiI9BQKbj1V+Wa2uGLys9IZ1S8/2aURERGROFBw66nKN7G6toBJpUWkpR3cIsYiIiLStSi49UQNtVC9i2WVuVq/TUREpAdRcOuJgqVANkZ6aWKCiIhID6Lg1hMF211tdb00MUFERKQHUXDrico3ARDO7c+AouwkF0ZERETiRcGtJyr3LW4lpcOTWw4RERGJq4RueSXJUbOrjJALMWrY0GQXRUREROJILW7d3bZlUFfV5KLdW8vYSjFThvROUqFEREQkERTcuqv6anj6JrjjSPjXFRCJ7LuqducGtrliDivVHqUiIiI9iYJbd7RjJfzxJJh9J4w4EVa+CG/93l9XX0NOxVoqMvtRkJ2R3HKKiIhIXGmMW3f0xm2wpwyu/A+MPBn+9Ul44ftQPITIy7+gf8MmZg2+KtmlFBERkThTi1t3VDYXhh4No04BMzj/d5DXDx78FA071/CZuusZcso1yS6liIiIxJla3Lqb2grY+j6MO7fxstzecOnf4e27+Nqmj7AmqxdHj9TEBBERkZ5GLW7dzcZ3wEWgdFrTy4dMZ9nxv+bpskwunz4UM20sLyIi0tMouHU3ZXP898FTW1x13+x1ZIbSuHhqaScXSkRERDqDglt3UzYX+oz23aMxaurD/Ht+GWdOHEDvvMwkFU5EREQSScGtO3EONsyFwdNaXPXv+RvYW9PAJ6ZrtwQREZGeSsGtO9mzHiq2tBjftquyjp8/u4SpwzQpQUREpCdTcOtOouPbmgW3W5/+gPKaBn700YmalCAiItKDKbh1J2VzIT0bSibuu+jt1Tt5cG4Znz1hBOMGFCaxcCIiIpJoCm7dSdlcGHQ4hPxWVtvKa7npkYUMLs7ha6eOSXLhREREJNEU3LqLhjrY9O6+ZUBWb6/k4jvfYNOeGn7xscnkZmotZRERkZ5OZ/vuomIzhGuh3yEs21LOZXe9BcD91xzNlCHFyS2biIiIdAoFt+6icpv/ntef+2avo6qugae+egIj++Unt1wiIiLSadRV2l1URINbP8p2VTG8T55Cm4iISIpRcOsuoi1u+f0o21VNaa/c5JZHREREOp2CW3cRBDeX24f1O6so7ZWT5AKJiIhIZ1Nw6y4qt0FmPrvrM6isCzOkt1rcREREUo2CW3dRuQ3y+lK2qxpALW4iIiIpSMGtu6jcBnn9Wb+rClBwExERSUUKbt1F5fZ9M0oBTU4QERFJQQpu3UXF1n1dpYXZ6RTlZCS7RCIiItLJFNy6g0gEqnyL2/qdVZqYICIikqIU3LqD6l3gIpDfP1jDTePbREREUpGCW3ewbw0331U6ROPbREREUpKCW3dQuRWAvaFiquvDanETERFJUQpu3UHQ4rapoQDQjFIREZFUpeDWHVRuB2BtTR6AJieIiIikKAW37qBiK1gaqyozAS2+KyIikqoU3LqDym2Q25f1u2vonZdJXlZ6skskIiIiSaDg1h3s2zVBS4GIiIikMgW37qByG+T77a4U3ERERFKXglt3ULkVl9tPa7iJiIikOAW37qByO7VZvalriDCgKDvZpREREZEkUXDr6uqqoK6C6ozeANpcXkREJIUpuHV1weK7lUFwK8hWcBMREUlVCm5dXbD4bnmoGICCbC0FIiIikqoU3Lq6oMVtj4KbiIhIylNw6+qC4LaTIgAKstRVKiIikqoU3Lq6yq0AbHd+g3m1uImIiKQuBbeurnI7ZOazu963tOUruImIiKQsBbeurnI75PahvKaenIwQGSE9ZSIiIqlKKaCrq94Jub2pqG1Qa5uIiEiKU3Dr6qp2Qk5v9tY0aHybiIhIilNw6+qCFrfymgYtvisiIpLiFNy6uqpdkNOb8pp6CtXiJiIiktIU3LqycAPU7vFj3NRVKiIikvIU3Lqy6l3+e47vKs3PUnATERFJZQpuXVn1Tv8913eVaoybiIhIalNw68qqfHALZ/eisi6srlIREZEUl9DgZmZnmdlSM1thZje1cv0wM5tpZgvNbJaZlcZcPt/MFpjZYjO7NuY2s4L7XBB89U9kHZIqaHGrChUCqMVNREQkxSWsCcfMQsAdwOlAGTDHzB53zr0fc9gvgHucc383s1OAW4ErgU3AMc65WjPLB94LbrsxuN0Vzrm5iSp7lxG0uFWECoGtanETERFJcYlscZsOrHDOrXLO1QEPABc0O2Y88GLw80vR651zdc652uDyrASXs+sKWtz2kg9AgSYniIiIpDRzziXmjs0uAc5yzn0u+P1K4Cjn3HUxx9wHzHbO/dbMLgIeAfo653aY2RDgSWA0cINz7o7gNrOAPkA4OP6HrpVKmNk1wDUAJSUlUx944IGE1DOqoqKC/Pz8uN7nyJV/p7TsMf408UFunVPLDdOymdA3FNfHiJdE1L87SeX6p3LdQfVX/VO3/qlcd0hs/U8++eR5zrlprV2X7Cac64Hbzexq4BVgAz6Q4ZxbD0wys0HAo2b2sHNuC76bdIOZFeCD25XAPc3v2Dl3F3AXwLRp09yMGTMSWpFZs2YR98fY+wjs7MPo8YfBnLkcf9RUJg8pju9jxElC6t+NpHL9U7nuoPqr/qlb/1SuOySv/onsgtwADIn5vTS4bB/n3Ebn3EXOucOBbweX7W5+DPAecELw+4bgezlwH75Ltmeq3rVvuytAY9xERERSXCKD2xxgjJmNMLNM4DLg8dgDzKyvmUXLcDPw1+DyUjPLCX7uBRwPLDWzdDPrG1yeAZyLD3U9U3S7q1of3PIV3ERERFJawoKbc64BuA54FvgAeNA5t9jMbjGz84PDZuAD2TKgBPhRcPmhwGwzexd4GfiFc24RfqLCs2a2EFiAb8H7U6LqkHT7NpivB6BQy4GIiIiktIQ24TjnngKeanbZ92J+fhh4uJXbPQ9MauXySmBq/EvaRVXthMFTKa9pICNkZKWn5uRaERER8ZQEuirnmrS4FWRnYGbJLpWIiIgkkYJbV1VXCeE6yOlNRU2DJiaIiIiIgluX1WSD+QbytfiuiIhIylNw66qC7a7I8cFNLW4iIiKi4NZVxbS47Q3GuImIiEhqU3DrqtTiJiIiIs0ouHVV1bv895xeVNQ2aA03ERERUXDrsoIWN5dTTEWtJieIiIiIglvXVb0TMguoCocIR5y6SkVERETBrcuq2gm5vWI2mFdXqYiISKpTcOuqqoMN5oN9StXiJiIiIgpuXVV0u6ta3+KWr+AmIiKS8hTcuqqqnfuWAgEoVHATERFJeQpuXVXMBvOgMW4iIiKi4NY1hRugZk+TFjeNcRMREREFt66oZrf/ntubCs0qFRERkYCCW1cUs2tCeU09ZpCbEUpumURERCTpFNy6ovoq/z0jl701fteEtDRLbplEREQk6RTcuqKGOv89PYuK2gYKtN2ViIiIoODWNYVr/fdQBlV1DeQquImIiAgKbl1TOGhxC2VRVRcmL1Pj20RERETBrWva11WaSVVdmBwFNxEREUHBrWva11Wa5btKM9VVKiIiIgpuXVO0xS2kFjcRERFppODWFYUbu0qrNcZNREREAgpuXVFMV2llrbpKRURExFNw64pi1nGrrldXqYiIiHgKbl1R0FVa50LUh526SkVERARQcOuagq7S6ojvIs1RV6mIiIig4NY1BV2lVWG/P2muWtxEREQEBbeuKVzrlwKpjwAKbiIiIuIpuHVF4XoIZVFdFwbQrFIREREBFNy6poZaSM+ksrYBUIubiIiIeApuXVG41m93Ve9b3LQciIiIiICCW9cUrodQRkxXqYKbiIiIKLh1TQ21kJ61r6s0T2PcREREBAW3rilc5ycnqKtUREREYii4dUXB5IQqdZWKiIhIDAW3rihc59dxqwtjBtnpCm4iIiKi4NY1RYNbbQM5GSHS0izZJRIREZEuQMGtKwomJ1TVh9VNKiIiIvsouHVFQYtbdV1YExNERERkHwW3rigIbpW1DVoKRERERPZRcOuKGuog3S8HohY3ERERiVJw64rCtftmlWqMm4iIiEQpuHVFMV2lueoqFRERkYCCW1cU01WqFjcRERGJUnDritRVKiIiIq1QcOtqIhGINDQuB5KhrlIRERHxFNy6mnAdAC6USWVdA3lZanETERERT8GtqwnXAtCQloFzaDkQERER2UfBratp8C1udS4DgNwMBTcRERHxFNy6mqDFrdb5wKblQERERCRKwa2rCca41RK0uGmMm4iIiAQU3LqaoKu01vmWNi0HIiIiIlEKbl1N0FVaE/GBTcuBiIiISJSCW1cTrgegOghuWg5EREREohTcupoG3+JWHVFXqYiIiDSl4NbVhKPBLegq1axSERERCSi4dTXB5ITKBv/UaB03ERERiVJw62qC5UCqol2lGuMmIiIiAQW3riYIbpXhNEJpRmZIT5GIiIh4GkDV1QSTE8rrQ+RmGGaW5AKJiIhIV6Hg1tWEG8e45WYptImIiEijhPbDmdlZZrbUzFaY2U2tXD/MzGaa2UIzm2VmpTGXzzezBWa22MyujbnNVDNbFNznbdbTmqSC4FbekKZ9SkVERKSJhAU3MwsBdwBnA+OBy81sfLPDfgHc45ybBNwC3Bpcvgk4xjk3BTgKuMnMBgXX3Ql8HhgTfJ2VqDokxb6u0jRyNKNUREREYiSyxW06sMI5t8o5Vwc8AFzQ7JjxwIvBzy9Fr3fO1TnnaoPLs6LlNLOBQKFz7i3nnAPuAS5MYB06X7CO2576NC2+KyIiIk0ksi9uMLA+5vcyfOtZrHeBi4DfAh8FCsysj3Nuh5kNAZ4ERgM3OOc2mtm04H5i73Nwaw9uZtcA1wCUlJQwa9asD1+jdlRUVMTlMYavXs5wYOOOcnIz0xJe7niJV/27q1SufyrXHVR/1T9165/KdYfk1T/Zg6iuB243s6uBV4ANQBjAObcemBR0kT5qZg8fyB075+4C7gKYNm2amzFjRhyL3dKsWbOIy2PUvwRlmaTn5FHaN58ZM6Z++PvsBHGrfzeVyvVP5bqD6q/6p279U7nukLz6JzK4bQCGxPxeGly2j3NuI77FDTPLBy52zu1ufoyZvQecALwe3E+b99nthesglEVlbVhdpSIiItJEIse4zQHGmNkIM8sELgMejz3AzPqaWbQMNwN/DS4vNbOc4OdewPHAUufcJmCvmR0dzCb9FPBYAuvQ+RpqIZRBdX2YHAU3ERERiZGw4OacawCuA54FPgAedM4tNrNbzOz84LAZwFIzWwaUAD8KLj8UmG1m7wIvA79wzi0KrvsS8GdgBbASeDpRdUiKcB2kZ1FV10BeVrJ7skVERKQrSWgycM49BTzV7LLvxfz8MNBi7Jpz7nlgUhv3OReYGN+SdiHhOlwok5r6iJYDERERkSa0EWZX01CLC2UCaIybiIiINKHg1tWE6wmnZQCQq65SERERiaHg1tWEa4lY0OKmrlIRERGJoeDW1TTU0hC0uOVlKbiJiIhIIwW3riZcRz0+uBXmZCS5MCIiItKVKLh1NeE66oPJvkUKbiIiIhJDwa2raaij1vngVpit4CYiIiKNFNy6mnDtvuBWlKvgJiIiIo32G9zM7LyYbakk0cJ11ERCpBnkZ2o5EBEREWnUkUD2cWC5mf3MzMYlukApr6GOapdOQXYGaWmW7NKIiIhIF7Lf4Oac+yRwOH5f0LvN7E0zu8bMChJeulQUrqUqHNLEBBEREWmhQ12gzrm9+D1FHwAGAh8F5pvZVxJYttTUUKfgJiIiIq3qyBi3883sP8AsIAOY7pw7G5gM/E9ii5eCwnVUhtMozNH4NhEREWmqI+ngYuDXzrlXYi90zlWZ2WcTU6wUFYlApJ6KBrW4iYiISEsdCW7fBzZFfzGzHKDEObfGOTczUQVLSeE6AMoV3ERERKQVHRnj9hAQifk9HFwm8RauBaC8Pk2L74qIiEgLHQlu6c65uugvwc+ZiStSCgvXA1AdSdM+pSIiItJCR4LbNjM7P/qLmV0AbE9ckVJYg29xqyNDXaUiIiLSQkfGuF0L/NPMbgcMWA98KqGlSlVBV2mdS1eLm4iIiLSw3+DmnFsJHG1m+cHvFQkvVaoKukrrSVeLm4iIiLTQocXCzOwjwAQg28xvw+ScuyWB5UpN6ioVERGRdnRkAd4/4Pcr/Qq+q/RjwLAElys1BcuB1JJOYbYW4BUREZGmOjI54Vjn3KeAXc65/wOOAcYmtlgpSi1uIiIi0o6OBLea4HuVmQ0C6vH7lUq8BS1u9ZqcICIiIq3oSH/cf82sGPg5MB9wwJ8SWaiUFQS3UEYWGaGOZGoRERFJJe0GNzNLA2Y653YDj5jZE0C2c25PZxQu5QRdpRlZ2UkuiIiIiHRF7TbrOOciwB0xv9cqtCVQ0OKWlZ2T5IKIiIhIV9SR/riZZnaxRdcBkcQJglu2gpuIiIi0oiPB7Qv4TeVrzWyvmZWb2d4Elys1BV2lCm4iIiLSmo7snFDQGQUR9rW45ebkJrkgIiIi0hXtN7iZ2YmtXe6ceyX+xUlx0eCWq+AmIiIiLXVkOZAbYn7OBqYD84BTElKiFBauryEE5OWqq1RERERa6khX6Xmxv5vZEOA3iSpQKqurqSEHyFeLm4iIiLTiYDbELAMOjXdBBGprq0lz6RTlZia7KCIiItIFdWSM2+/wuyWAn4U6Bb+DgsRZfW0N6aRTmK3trkRERKSljrS4zY35uQG43zn3eoLKk9Lq62oIkU5RroKbiIiItNSR4PYwUOOcCwOYWcjMcp1zVYktWuqpr6shjQyKtMG8iIiItKJDOycAsdMcc4AXElOc1Baur6XOqatUREREWteR4JbtnKuI/hL8rGmPCRCpr6WedLW4iYiISKs60lVaaWZHOOfmA5jZVKA6scVKIeVb4NFroXQ62dWbqbAMsjM6kqdFREQk1XQkuH0deMjMNgIGDAA+nshCpZSyt2Hli7DyRUqB92w0ZpbsUomIiEgX1JEFeOeY2TjgkOCipc65+sQWK4VU7fTfP/sCDz/2H+ZU9uWnyS2RiIiIdFEdWcfty8A/nXPvBb/3MrPLnXO/T3jpUkHVDv+9ZAL/zgpTkxZObnlERESky+rIYKrPO+d2R39xzu0CPp+wEqWa6p2QngOZuWzaU8PAIu1TKiIiIq3rSHALWcygKzMLAdqTKV6qdkJub5xzbNxdzcCi7GSXSERERLqojkxOeAb4l5n9Mfj9C8DTiStSiqnaCTm92V1VT21DhIHFanETERGR1nUkuN0IXANcG/y+ED+zVOKhagfk9mbjHr/CyiC1uImIiEgb9ttV6pyLALOBNcB04BTgg8QWK4VU+67STbtrABig4CYiIiJtaLPFzczGApcHX9uBfwE4507unKKliKodkNuHTdEWN3WVioiISBva6ypdArwKnOucWwFgZt/olFKlikgYqndDTm827qkhPc3om5+V7FKJiIhIF9VeV+lFwCbgJTP7k5mdit85QeKlejfgfIvb7mpKCrMJpelPLCIiIq1rM7g55x51zl0GjANewm991d/M7jSzMzqpfD1bdbBrQm5vNu2pYVCxxreJiIhI2zoyOaHSOXefc+48oBR4Bz/TVD6s6K4JQXAboMV3RUREpB0dWYB3H+fcLufcXc65UxNVoJQS7FMaye7N5j01WgpERERE2nVAwU3iLGhx20UBdeGIdk0QERGRdim4JVMwxm1Tne8i1a4JIiIi0h4Ft2Sq2gGhTMoqQwAM0hg3ERERaYeCWzIF+5Ru3ut3TRioWaUiIiLSDgW3ZKraGeyaUENmKI3euZnJLpGIiIh0YQpuyRTsU7pxTw0DirJJ0+K7IiIi0g4Ft2Sq2hFsMF+tGaUiIiKyXwpuyVS1A3KiuyZoYoKIiIi0T8EtWSIRqN5FJKcPm/fWqMVNRERE9kvBLVlqdoOLUBkqIBxxWsNNRERE9iuhwc3MzjKzpWa2wsxuauX6YWY208wWmtksMysNLp9iZm+a2eLguo/H3OZuM1ttZguCrymJrEPCVO8CYIcrAGBgoVrcREREpH0JC25mFgLuAM4GxgOXm9n4Zof9ArjHOTcJuAW4Nbi8CviUc24CcBbwGzMrjrndDc65KcHXgkTVIaGC7a7WVmUBMLJfXjJLIyIiIt1AIlvcpgMrnHOrnHN1wAPABc2OGQ+8GPz8UvR659wy59zy4OeNwFagXwLL2vmCDeYX7UqnKCeDEX0V3ERERKR95pxLzB2bXQKc5Zz7XPD7lcBRzrnrYo65D5jtnPutmV0EPAL0dc7tiDlmOvB3YIJzLmJmdwPHALXATOAm51xtK49/DXANQElJydQHHnggIfWMqqioID8/v8PHD9g0k3FLb+PS0G+oyhnI9dO6d1fpgda/p0nl+qdy3UH1V/1Tt/6pXHdIbP1PPvnkec65aa1dl56QR+y464Hbzexq4BVgAxCOXmlmA4F/AFc55yLBxTcDm4FM4C7gRnw3axPOubuC65k2bZqbMWNGwioBMGvWLA7oMd5YBEthaVU+Vx09khkzxiasbJ3hgOvfw6Ry/VO57qD6q/6pW/9Urjskr/6JDG4bgCExv5cGl+0TdINeBGBm+cDFzrndwe+FwJPAt51zb8XcZlPwY62Z/Q0f/rqfqh1ELJ09LofDhxQnuzQiIiLSDSRyjNscYIyZjTCzTOAy4PHYA8ysr5lFy3Az8Nfg8kzgP/iJCw83u83A4LsBFwLvJbAOiVO1k5r0IsCYrOAmIiIiHZCw4OacawCuA54FPgAedM4tNrNbzOz84LAZwFIzWwaUAD8KLr8UOBG4upVlP/5pZouARUBf4IeJqkNCVe1gN/kM65NL7zxtLi8iIiL7l9Axbs65p4Cnml32vZifHwYebuV29wL3tnGfp8S5mJ1n5yp49jtQMAA2L2JzQx5TRhUnu1QiIiLSTSR7ckJqWfMaLH0SMgugrpzlDTOYom5SERER6SAFt85UX+O/f20BL3ywlW89vIKHFdxERESkg7RXaWdqqPbf07OZs9UIhTIYP6gwuWUSERGRbkPBrTNFW9wycliwfjeHDiokKz2U3DKJiIhIt6Hg1pkaqiEtA9JCrN9ZxSjtTyoiIiIHQMGtM9XXQEYOzjm2VdTSv6B7b3MlIiIinUvBrTM1VEN6Nruq6qkPO/oXZCW7RCIiItKNKLh1pvoayMhma7kf69a/UMFNREREOk7BrTM1VEN6Dlv31gKoq1REREQOiIJbZ9rX4hYNbmpxExERkY5TcOtM0RY3dZWKiIjIQVBw60xBi9u28lrys9LJzdTGFSIiItJxCm6daV+LW626SUVEROSAKbh1pmiL295a+im4iYiIyAFScOtMDTX7xrj1L9SMUhERETkwCm6dqb5q36zSfvlqcRMREZEDo+DWmeprqLMsqurCmlEqIiIiB0zBrbM4Bw3VVEb8TFJNThAREZEDpeDWWcL14CJUhDMA7ZogIiIiB07BrbM0VAOwpyEIbuoqFRERkQOk4NZZ6v1uCXvq/Z9cXaUiIiJyoBTcOkvQ4rarPkRmehpFORlJLpCIiIh0NwpunSVocdtZG6JffhZmluQCiYiISHej4NZZgha37TVpGt8mIiIiB0XBrbMELW5bqzW+TURERA6OgltnCVrcNleb9ikVERGRg6Lg1lmCFrftNWlaw01EREQOioJbZwla3GrIVFepiIiIHBQFt84StLjVkKnJCSIiInJQFNw6S9DiVusy1VUqIiIiB0XBrbPEtLj1ystMcmFERESkO1Jw6ywxY9wKstOTXBgRERHpjhTcOkt9DRHSqCdEXqaCm4iIiBw4BbfOUl9NQ1oWuZnphNK03ZWIiIgcOAW3ztJQTZ1lkpel1jYRERE5OApunaW+hjrLokDBTURERA6SgltnaaimlkzyNTFBREREDpKCW2epr6GWTE1MEBERkYOm4NZZGqqpdhlqcRMREZGDpuDWWeprqHIZ5GuMm4iIiBwkBbfO0lBNVUTBTURERA6egltnqa+hMpKh5UBERETkoCm4dRJXX02l03ZXIiIicvAU3DqJq6+m1mWqq1REREQOmoJbZ2mooQbtnCAiIiIHT8GtswTBTS1uIiIicrAU3DpDJExapJ4adZWKiIjIh6Dg1hnqqwGoQQvwioiIyMFTcOsMDTUAQVdpKMmFERERke5Kwa0z7GtxyyQ/KyPJhREREZHuSsGtM0Rb3FymukpFRETkoCm4dYagxa2WTHIz1FUqIiIiB0fBrTMEwY2MHNLSLLllERERkW5Lwa0zNPjgZhnZSS6IiIiIdGcKbp2h3o9xS8vMSXJBREREpDtTcOsMQYtbemZukgsiIiIi3ZmCW2cIWtzSs9XiJiIiIgdPwa0zBC1uGVlqcRMREZGDp+DWGYIWt4zsvCQXRERERLozBbfOELS4ZSm4iYiIyIeg4NYJXH00uKmrVERERA6e9l/qBOG6ahpcBvk52qdUREREDp6CWyeor6milkzys/TnFhERkYOX0K5SMzvLzJaa2Qozu6mV64eZ2UwzW2hms8ysNLh8ipm9aWaLg+s+HnObEWY2O7jPf5lZZiLrEA8NtVXUKLiJiIjIh5Sw4GZmIeAO4GxgPHC5mY1vdtgvgHucc5OAW4Bbg8urgE855yYAZwG/MbPi4LqfAr92zo0GdgGfTVQd4iVcV02NU3ATERGRDyeRLW7TgRXOuVXOuTrgAeCCZseMB14Mfn4per1zbplzbnnw80ZgK9DPzAw4BXg4uM3fgQsTWIe4iNRVU60WNxEREfmQEpkkBgPrY34vA45qdsy7wEXAb4GPAgVm1sc5tyN6gJlNBzKBlUAfYLdzriHmPge39uBmdg1wDUBJSQmzZs36sPVpV0VFRZuPMXznVmrJZOnid6krCyW0HMnSXv1TQSrXP5XrDqq/6p+69U/lukPy6p/sJqDrgdvN7GrgFWADEI5eaWYDgX8AVznnIr7BrWOcc3cBdwFMmzbNzZgxI36lbsWsWbNo6zG2L0pnc3kmJx57FKP65Se0HMnSXv1TQSrXP5XrDqq/6p+69U/lukPy6p/I4LYBGBLze2lw2T5BN+hFAGaWD1zsnNsd/F4IPAl82zn3VnCTHUCxmaUHrW4t7rNLaqihxmVSoK5SERER+RASOcZtDjAmmAWaCVwGPB57gJn1NbNoGW4G/hpcngn8Bz9xITqeDeecw4+FuyS46CrgsQTWIS6socbPKs1WcBMREZGDl7DgFrSIXQc8C3wAPOicW2xmt5jZ+cFhM4ClZrYMKAF+FFx+KXAicLWZLQi+pgTX3Qh808xW4Me8/SVRdYiXUEM1tWSQk9Ezx7eJiIhI50hoE5Bz7ingqWaXfS/m54dpnCEae8y9wL1t3Ocq/IzV7qGhjoxwJQ2hbA5kjJ6IiIhIc9qrNJG2r4C/nkFew26Wpo9LdmlERESkm1NwS5TVr8AfT4Bda/jjgO/zUu5ZyS6RiIiIdHMKbongHDz7LcjvD198g9cyjiVPM0pFRETkQ1JwS4SlT8PmRXDSTVA4iPKaBgo0o1REREQ+JAW3eHMOXv4p9BoOh30MgMraBm13JSIiIh+aglu8LX8eNi2AE66HkA9rFbUN6ioVERGRD03BLd5e/ikUD4XJlwGweOMeNu2p6bFbXYmIiEjnUXCLp9oK2DAXDv8UhDIAuP3FFRRkpfOJo4YmuXAiIiLS3Sm4xVPVdv+9cBAAy7aU8/R7m7n6uOEU5WQksWAiIiLSEyi4xVNlENzy+gK+tS0vM8RnjhuRxEKJiIhIT6HgFk8xwW3VtgqeWLiRTx4zjF55mcktl4iIiPQICm7xVLnNf8/ty9PvbSbi4HPHj0xumURERKTHUHCLp6rGFrcte2soysmgX0FWcsskIiIiPYaCWzxVboeMXMjMY+veWvortImIiEgcKbjFU+X2fRMTtlXUqrVNRERE4krBLZ4qt0GuD25by2sU3ERERCSuFNziqWo75PXDOce2cnWVioiISHwpuMVT0FVaUdtATX1ELW4iIiISVwpu8eLcvuC2tbwWQMFNRERE4krBLU5C4WoI10JuX7YFwa1/QXaSSyUiIiI9iYJbnGTU7/E/5PXbF9zU4iYiIiLxpOAWJ5l10eAW01War+AmIiIi8aPgFif7Wtxy+7CtvJaMkFGcm5HcQomIiEiPouAWJ40tbr6rtF9+FmaW3EKJiIhIj6LgFicZ9Xv9D3l9tfiuiIiIJISCW5xk1O+GzHzIyPEtbppRKiIiInGm4BYnmXV7IbcPQBDc1OImIiIi8aXgFicZ9Xsgrx/14Qg7q+q03ZWIiIjEnYJbnPjg1pedlXU4pzXcREREJP4U3OIks84Ht617tfiuiIiIJIaCWzw452eV5vZlW0UNgLpKRUREJO4U3OKhZg9prkHbXYmIiEhCKbjFQ9UO/z2mq7SvtrsSERGROFNwi4fKbf57Xl+2VdRSlJNBdkYouWUSERGRHkfBLR4qt/vvub7FTd2kIiIikggKbvHQrMWtn7pJRUREJAEU3OKhqrHFbVt5Lf0LFdxEREQk/hTc4qFyOw2hHFx6lt9gXi1uIiIikgDpyS5AjzD9GhZXD2RcOEJNfYTi3Ixkl0hERER6ILW4xUOfUezqPYW6hggAmen6s4qIiEj8KWHEUTS4ZaVrKRARERGJPwW3OKoLq8VNREREEkcJI472dZWG9GcVERGR+FPCiCONcRMREZFEUsKIo1oFNxEREUkgJYw4UnATERGRRFLCiKN9s0o1xk1EREQSQAkjjjSrVERERBJJCSOONDlBREREEkkJI44U3ERERCSRlDDiqC4cBrRzgoiIiCSGglscqcVNREREEkkJI460c4KIiIgkkhJGHGkdNxEREUkkJYw4ii4HkqXgJiIiIgmghBFHtfXqKhUREZHEUcKIo7pwhPQ0Iy3Nkl0UERER6YEU3OKoriGi8W0iIiKSMEoZcaTgJiIiIomklBFHdQ0RjW8TERGRhFHKiKO6cISsDP1JRUREJDGUMuJILW4iIiKSSEoZcVTbECFT+5SKiIhIgii4xVFdWJMTREREJHESmjLM7CwzW2pmK8zsplauH2ZmM81soZnNMrPSmOueMbPdZvZEs9vcbWarzWxB8DUlkXU4EHUNYbLUVSoiIiIJkrCUYWYh4A7gbGA8cLmZjW922C+Ae5xzk4BbgFtjrvs5cGUbd3+Dc25K8LUgviU/eLVaDkREREQSKJEpYzqwwjm3yjlXBzwAXNDsmPHAi8HPL8Ve75ybCZQnsHxxp3XcREREJJHMOZeYOza7BDjLOfe54PcrgaOcc9fFHHMfMNs591szuwh4BOjrnNsRXD8DuN45d27Mbe4GjgFqgZnATc652lYe/xrgGoCSkpKpDzzwQCKquU9FRQU/XpDGwLw0vnJ4dkIfqyuqqKggPz8/2cVImlSufyrXHVR/1T9165/KdYfE1v/kk0+e55yb1tp16Ql5xI67HrjdzK4GXgE2AOH93OZmYDOQCdwF3IjvZm3COXdXcD3Tpk1zM2bMiFuhWzNr1iwyshyDBxQzY8bhCX2srmjWrFkk+m/claVy/VO57qD6q/6pW/9Urjskr/6JDG4bgCExv5cGl+3jnNsIXARgZvnAxc653e3dqXNuU/BjrZn9DR/+ugR1lYqIiEgiJTJlzAHGmNkIM8sELgMejz3AzPqaWbQMNwN/3d+dmtnA4LsBFwLvxbPQH0ZdQ4QsBTcRERFJkISlDOdcA3Ad8CzwAfCgc26xmd1iZucHh80AlprZMqAE+FH09mb2KvAQcKqZlZnZmcFV/zSzRcAioC/ww0TV4UCpxU1EREQSKaFj3JxzTwFPNbvsezE/Pww83MZtT2jj8lPiWcZ4qtUCvCIiIpJAShlx4pzzXaVagFdEREQSRCkjTsLBqipqcRMREZFEUcqIk/qI/67gJiIiIomilBEn+4KbukpFREQkQZQy4qQh4vtKM9NDSS6JiIiI9FQKbnHSoK5SERERSTCljDjRGDcRERFJNKWMOIl2lWrnBBEREUkUpYw4UYubiIiIJJpSRpxEx7hpAV4RERFJFKWMOGmcVao/qYiIiCSGUkacqKtUREREEk0pI060HIiIiIgkmlJGnGjnBBEREUk0pYw4qdcYNxEREUkwpYw4UVepiIiIJJpSRpw0LgeivUpFREQkMRTc4iTaVZqVoT+piIiIJIZSRpw0aHKCiIiIJJhSRpw0RCA9zUhLs2QXRURERHooBbc4qY84TUwQERGRhFLSiJOGiGaUioiISGIpacRJfUTj20RERCSxlDTiRC1uIiIikmhKGnGiMW4iIiKSaEoacdKgrlIRERFJMCWNOKmPQJZa3ERERCSBlDTipCHiyErXdlciIiKSOApucaLJCSIiIpJoShpxUq/gJiIiIgmmpBEnDRGnyQkiIiKSUEoacaKuUhEREUk0JY04UVepiIiIJJqSRpw0aAFeERERSTAljTjRXqUiIiKSaEoacaIFeEVERCTRlDTiwDmnyQkiIiKScEoacVAfdoC6SkVERCSxlDTioC4cASArQ39OERERSRwljTioa/DBTS1uIiIikkhKGnGwL7hpk3kRERFJIAW3OGgMbvpzioiISOIoacRBXTgMKLiJiIhIYilpxEGtxriJiIhIJ1DSiINoV6kW4BUREZFEUtKIg1qNcRMREZFOoKQRB5qcICIiIp1BSSMOtI6biIiIdAYljTjQzgkiIiLSGZQ04kAtbiIiItIZlDTiQGPcREREpDMoacRBbVjBTURERBJPSSMO9q3jFtJepSIiIpI4Cm5xoK5SERER6QxKGnGg4CYiIiKdQUkjDurCYdIMQmmW7KKIiIhID6bgFge19RHU2CYiIiKJprgRB73yMhmcpz+liIiIJFZ6sgvQE3z55NFMsLJkF0NERER6ODUTiYiIiHQTCm4iIiIi3YSCm4iIiEg3oeAmIiIi0k0ouImIiIh0EwkNbmZ2lpktNbMVZnZTK9cPM7OZZrbQzGaZWWnMdc+Y2W4ze6LZbUaY2ezgPv9lZpmJrIOIiIhIV5Gw4GZmIeAO4GxgPHC5mY1vdtgvgHucc5OAW4BbY677OXBlK3f9U+DXzrnRwC7gs/Euu4iIiEhXlMgWt+nACufcKudcHfAAcEGzY8YDLwY/vxR7vXNuJlAee7CZGXAK8HBw0d+BC+NechEREZEuyJxzibljs0uAs5xznwt+vxI4yjl3Xcwx9wGznXO/NbOLgEeAvs65HcH1M4DrnXPnBr/3Bd4KWtswsyHA0865ia08/jXANQAlJSVTH3jggYTUM6qiooL8/PyEPkZXpvqnbv1Tue6g+qv+qVv/VK47JLb+J5988jzn3LTWrkv2zgnXA7eb2dXAK8AGIByPO3bO3QXcBTBt2jQ3Y8aMeNxtm2bNmkWiH6MrU/1Tt/6pXHdQ/VX/1K1/Ktcdklf/RAa3DcCQmN9Lg8v2cc5tBC4CMLN84GLn3O527nMHUGxm6c65htbuU0RERKSnSuQYtznAmGAWaCZwGfB47AFm1tfMomW4Gfhre3fofL/uS8AlwUVXAY/FtdQiIiIiXVTCglvQInYd8CzwAfCgc26xmd1iZucHh80AlprZMqAE+FH09mb2KvAQcKqZlZnZmcFVNwLfNLMVQB/gL4mqg4iIiEhXktAxbs65p4Cnml32vZifH6Zxhmjz257QxuWr8DNWRURERFKKdk4QERER6SYU3ERERES6CQU3ERERkW5CwU1ERESkm1BwExEREekmFNxEREREugkFNxEREZFuQsFNREREpJtQcBMRERHpJsxv/9mzmdk2YG2CH6YvsD3Bj9GVqf6pW/9Urjuo/qp/6tY/lesOia3/MOdcv9auSIng1hnMbK5zblqyy5Esqn/q1j+V6w6qv+qfuvVP5bpD8uqvrlIRERGRbkLBTURERKSbUHCLn7uSXYAkU/1TVyrXHVR/1T91pXLdIUn11xg3ERERkW5CLW4iIiIi3YSCm4iIiEg3oeAWB2Z2lpktNbMVZnZTssuTSGY2xMxeMrP3zWyxmX0tuPz7ZrbBzBYEX+cku6yJYmZrzGxRUM+5wWW9zex5M1sefO+V7HImgpkdEvMcLzCzvWb29Z78/JvZX81sq5m9F3NZq8+3ebcF7wULzeyI5JX8w2uj7j83syVB/f5jZsXB5cPNrDrmNfCHpBU8Ttqof5uvdTO7OXjul5rZmckpdfy0Uf9/xdR9jZktCC7vUc9/O+e6pP/va4zbh2RmIWAZcDpQBswBLnfOvZ/UgiWImQ0EBjrn5ptZATAPuBC4FKhwzv0imeXrDGa2BpjmnNsec9nPgJ3OuZ8E4b2Xc+7GZJWxMwSv/Q3AUcCn6aHPv5mdCFQA9zjnJgaXtfp8ByfxrwDn4P8uv3XOHZWssn9YbdT9DOBF51yDmf0UIKj7cOCJ6HE9QRv1/z6tvNbNbDxwPzAdGAS8AIx1zoU7tdBx1Fr9m13/S2CPc+6Wnvb8t3Ouu5ok/++rxe3Dmw6scM6tcs7VAQ8AFyS5TAnjnNvknJsf/FwOfAAMTm6puoQLgL8HP/8d/w/e050KrHTOJXpXkqRyzr0C7Gx2cVvP9wX4k5xzzr0FFAcngG6ptbo7555zzjUEv74FlHZ6wTpJG899Wy4AHnDO1TrnVgMr8OeHbqu9+puZ4T+w39+pheok7Zzrkv6/r+D24Q0G1sf8XkaKBJngE9bhwOzgouuCJuK/9tSuwoADnjOzeWZ2TXBZiXNuU/DzZqAkOUXrVJfR9E07VZ5/aPv5TrX3g88AT8f8PsLM3jGzl83shGQVqhO09lpPtef+BGCLc255zGU98vlvdq5L+v++gpscFDPLBx4Bvu6c2wvcCYwCpgCbgF8mr3QJd7xz7gjgbODLQXfCPs6PP+jRYxDMLBM4H3gouCiVnv8mUuH5bo2ZfRtoAP4ZXLQJGOqcOxz4JnCfmRUmq3wJlLKv9WYup+kHtx75/LdyrtsnWf/7Cm4f3gZgSMzvpcFlPZaZZeBfyP90zv0bwDm3xTkXds5FgD/RzbsI2uOc2xB83wr8B1/XLdFm8eD71uSVsFOcDcx3zm2B1Hr+A2093ynxfmBmVwPnAlcEJy+CLsIdwc/zgJXA2KQVMkHaea2nxHMPYGbpwEXAv6KX9cTnv7VzHV3gf1/B7cObA4wxsxFBK8RlwONJLlPCBOMa/gJ84Jz7VczlsX35HwXea37bnsDM8oKBqphZHnAGvq6PA1cFh10FPJacEnaaJp+2U+X5j9HW8/048KlghtnR+IHbm1q7g+7KzM4C/hc43zlXFXN5v2DCCmY2EhgDrEpOKROnndf648BlZpZlZiPw9X+7s8vXSU4DljjnyqIX9LTnv61zHV3hf985p68P+YWfRbIM/wnj28kuT4Lrejy+aXghsCD4Ogf4B7AouPxx/GycpJc3AfUfCbwbfC2OPt9AH2AmsBw/m6x3ssuawL9BHrADKIq5rMc+//iAugmox49b+WxbzzdgwB3Be8Ei/OzjpNchznVfgR/LE/3//0Nw7MXB/8QCYD5wXrLLn6D6t/laB74dPPdLgbOTXf5E1D+4/G7g2mbH9qjnv51zXdL/97UciIiIiEg3oa5SERERkW5CwU1ERESkm1BwExEREekmFNxEREREugkFNxEREZFuQsFNRFKSmYXNbEHM101xvO/hZtbT17ITkSRIT3YBRESSpNo5NyXZhRARORBqcRMRiWFma8zsZ2a2yMzeNrPRweXDzezFYHPxmWY2NLi8xMz+Y2bvBl/HBncVMrM/mdliM3vOzHKC479qZu8H9/NAkqopIt2UgpuIpKqcZl2lH4+5bo9z7jDgduA3wWW/A/7unJuE31j9tuDy24CXnXOTgSPwq8eD3/LnDufcBGA3fmV5gJuAw4P7uTYxVRORnko7J4hISjKzCudcfiuXrwFOcc6tCjaZ3uyc62Nm2/HbG9UHl29yzvU1s21AqXOuNuY+hgPPO+fGBL/fCGQ4535oZs8AFcCjwKPOuYoEV1VEehC1uImItOTa+PlA1Mb8HKZxTPFH8HsaHgHMMTONNRaRDlNwExFp6eMx398Mfn4DuCz4+Qrg1eDnmcAXAcwsZGZFbd2pmaUBQ5xzLwE3AkVAi1Y/EZG26JOeiKSqHDNbEPP7M8656JIgvcxsIb7V7PLgsq8AfzOzG4BtwKeDy78G3GVmn8W3rH0R2NTGY4aAe4NwZ8BtzrndcaqPiKQAjXETEYkRjHGb5pzbnuyyiIg0p65SERERkW5CLW4iIiIi3YRa3ERERES6CQU3ERERkW5CwU1ERESkm1BwExEREekmFNxEREREuon/DzNgNG1Q7/+HAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Depth 3 Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_d3_v3-10k.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/200\n",
      "6400/6400 [==============================] - 0s 53us/step - loss: 0.6532 - accuracy: 0.7058 - val_loss: 0.6188 - val_accuracy: 0.7075\n",
      "Epoch 2/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.5550 - accuracy: 0.7632 - val_loss: 0.5814 - val_accuracy: 0.7261\n",
      "Epoch 3/200\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.5345 - accuracy: 0.7657 - val_loss: 0.5769 - val_accuracy: 0.7261\n",
      "Epoch 4/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5322 - accuracy: 0.7657 - val_loss: 0.5760 - val_accuracy: 0.7261\n",
      "Epoch 5/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5307 - accuracy: 0.7657 - val_loss: 0.5741 - val_accuracy: 0.7261\n",
      "Epoch 6/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.5294 - accuracy: 0.7657 - val_loss: 0.5737 - val_accuracy: 0.7261\n",
      "Epoch 7/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5282 - accuracy: 0.7657 - val_loss: 0.5720 - val_accuracy: 0.7261\n",
      "Epoch 8/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5270 - accuracy: 0.7657 - val_loss: 0.5709 - val_accuracy: 0.7261\n",
      "Epoch 9/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.5258 - accuracy: 0.7657 - val_loss: 0.5693 - val_accuracy: 0.7261\n",
      "Epoch 10/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.5245 - accuracy: 0.7657 - val_loss: 0.5685 - val_accuracy: 0.7261\n",
      "Epoch 11/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.5232 - accuracy: 0.7657 - val_loss: 0.5683 - val_accuracy: 0.7261\n",
      "Epoch 12/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5220 - accuracy: 0.7657 - val_loss: 0.5665 - val_accuracy: 0.7261\n",
      "Epoch 13/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5209 - accuracy: 0.7658 - val_loss: 0.5657 - val_accuracy: 0.7263\n",
      "Epoch 14/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5199 - accuracy: 0.7657 - val_loss: 0.5654 - val_accuracy: 0.7263\n",
      "Epoch 15/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5189 - accuracy: 0.7658 - val_loss: 0.5647 - val_accuracy: 0.7261\n",
      "Epoch 16/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5180 - accuracy: 0.7656 - val_loss: 0.5640 - val_accuracy: 0.7263\n",
      "Epoch 17/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5171 - accuracy: 0.7656 - val_loss: 0.5627 - val_accuracy: 0.7264\n",
      "Epoch 18/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5162 - accuracy: 0.7656 - val_loss: 0.5624 - val_accuracy: 0.7264\n",
      "Epoch 19/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5153 - accuracy: 0.7658 - val_loss: 0.5617 - val_accuracy: 0.7262\n",
      "Epoch 20/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.5143 - accuracy: 0.7656 - val_loss: 0.5607 - val_accuracy: 0.7258\n",
      "Epoch 21/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.5133 - accuracy: 0.7658 - val_loss: 0.5595 - val_accuracy: 0.7262\n",
      "Epoch 22/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5121 - accuracy: 0.7656 - val_loss: 0.5580 - val_accuracy: 0.7261\n",
      "Epoch 23/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.5108 - accuracy: 0.7657 - val_loss: 0.5572 - val_accuracy: 0.7263\n",
      "Epoch 24/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5095 - accuracy: 0.7657 - val_loss: 0.5566 - val_accuracy: 0.7262\n",
      "Epoch 25/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5081 - accuracy: 0.7656 - val_loss: 0.5560 - val_accuracy: 0.7262\n",
      "Epoch 26/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5069 - accuracy: 0.7659 - val_loss: 0.5549 - val_accuracy: 0.7259\n",
      "Epoch 27/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5058 - accuracy: 0.7654 - val_loss: 0.5550 - val_accuracy: 0.7255\n",
      "Epoch 28/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5051 - accuracy: 0.7654 - val_loss: 0.5539 - val_accuracy: 0.7259\n",
      "Epoch 29/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5043 - accuracy: 0.7653 - val_loss: 0.5538 - val_accuracy: 0.7259\n",
      "Epoch 30/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5038 - accuracy: 0.7655 - val_loss: 0.5532 - val_accuracy: 0.7258\n",
      "Epoch 31/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5033 - accuracy: 0.7653 - val_loss: 0.5531 - val_accuracy: 0.7263\n",
      "Epoch 32/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5028 - accuracy: 0.7652 - val_loss: 0.5540 - val_accuracy: 0.7261\n",
      "Epoch 33/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5023 - accuracy: 0.7654 - val_loss: 0.5524 - val_accuracy: 0.7260\n",
      "Epoch 34/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.5019 - accuracy: 0.7655 - val_loss: 0.5525 - val_accuracy: 0.7256\n",
      "Epoch 35/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.5014 - accuracy: 0.7653 - val_loss: 0.5515 - val_accuracy: 0.7257\n",
      "Epoch 36/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.5009 - accuracy: 0.7656 - val_loss: 0.5515 - val_accuracy: 0.7252\n",
      "Epoch 37/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.5003 - accuracy: 0.7653 - val_loss: 0.5507 - val_accuracy: 0.7256\n",
      "Epoch 38/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4998 - accuracy: 0.7653 - val_loss: 0.5499 - val_accuracy: 0.7254\n",
      "Epoch 39/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4992 - accuracy: 0.7657 - val_loss: 0.5499 - val_accuracy: 0.7252\n",
      "Epoch 40/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4986 - accuracy: 0.7656 - val_loss: 0.5496 - val_accuracy: 0.7253\n",
      "Epoch 41/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4979 - accuracy: 0.7656 - val_loss: 0.5500 - val_accuracy: 0.7252\n",
      "Epoch 42/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4973 - accuracy: 0.7651 - val_loss: 0.5488 - val_accuracy: 0.7259\n",
      "Epoch 43/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4968 - accuracy: 0.7655 - val_loss: 0.5486 - val_accuracy: 0.7251\n",
      "Epoch 44/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4963 - accuracy: 0.7651 - val_loss: 0.5477 - val_accuracy: 0.7254\n",
      "Epoch 45/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4958 - accuracy: 0.7651 - val_loss: 0.5484 - val_accuracy: 0.7252\n",
      "Epoch 46/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4954 - accuracy: 0.7652 - val_loss: 0.5470 - val_accuracy: 0.7254\n",
      "Epoch 47/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4950 - accuracy: 0.7653 - val_loss: 0.5480 - val_accuracy: 0.7255\n",
      "Epoch 48/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4947 - accuracy: 0.7650 - val_loss: 0.5474 - val_accuracy: 0.7257\n",
      "Epoch 49/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4945 - accuracy: 0.7655 - val_loss: 0.5476 - val_accuracy: 0.7259\n",
      "Epoch 50/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4942 - accuracy: 0.7657 - val_loss: 0.5481 - val_accuracy: 0.7256\n",
      "Epoch 51/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4941 - accuracy: 0.7653 - val_loss: 0.5471 - val_accuracy: 0.7262\n",
      "Epoch 52/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4939 - accuracy: 0.7652 - val_loss: 0.5466 - val_accuracy: 0.7252\n",
      "Epoch 53/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4938 - accuracy: 0.7654 - val_loss: 0.5476 - val_accuracy: 0.7262\n",
      "Epoch 54/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4937 - accuracy: 0.7656 - val_loss: 0.5470 - val_accuracy: 0.7262\n",
      "Epoch 55/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4935 - accuracy: 0.7659 - val_loss: 0.5463 - val_accuracy: 0.7262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4934 - accuracy: 0.7658 - val_loss: 0.5470 - val_accuracy: 0.7266\n",
      "Epoch 57/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4935 - accuracy: 0.7654 - val_loss: 0.5480 - val_accuracy: 0.7265\n",
      "Epoch 58/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4933 - accuracy: 0.7657 - val_loss: 0.5477 - val_accuracy: 0.7257\n",
      "Epoch 59/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4933 - accuracy: 0.7658 - val_loss: 0.5460 - val_accuracy: 0.7261\n",
      "Epoch 60/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4932 - accuracy: 0.7655 - val_loss: 0.5462 - val_accuracy: 0.7268\n",
      "Epoch 61/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4932 - accuracy: 0.7661 - val_loss: 0.5476 - val_accuracy: 0.7260\n",
      "Epoch 62/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4931 - accuracy: 0.7658 - val_loss: 0.5474 - val_accuracy: 0.7267\n",
      "Epoch 63/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4930 - accuracy: 0.7657 - val_loss: 0.5475 - val_accuracy: 0.7268\n",
      "Epoch 64/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4929 - accuracy: 0.7655 - val_loss: 0.5473 - val_accuracy: 0.7266\n",
      "Epoch 65/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4930 - accuracy: 0.7661 - val_loss: 0.5480 - val_accuracy: 0.7265\n",
      "Epoch 66/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4928 - accuracy: 0.7660 - val_loss: 0.5459 - val_accuracy: 0.7270\n",
      "Epoch 67/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4928 - accuracy: 0.7662 - val_loss: 0.5469 - val_accuracy: 0.7270\n",
      "Epoch 68/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4928 - accuracy: 0.7659 - val_loss: 0.5473 - val_accuracy: 0.7268\n",
      "Epoch 69/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4927 - accuracy: 0.7665 - val_loss: 0.5469 - val_accuracy: 0.7273\n",
      "Epoch 70/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4927 - accuracy: 0.7661 - val_loss: 0.5464 - val_accuracy: 0.7273\n",
      "Epoch 71/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4927 - accuracy: 0.7660 - val_loss: 0.5462 - val_accuracy: 0.7265\n",
      "Epoch 72/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4926 - accuracy: 0.7665 - val_loss: 0.5458 - val_accuracy: 0.7275\n",
      "Epoch 73/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4926 - accuracy: 0.7660 - val_loss: 0.5470 - val_accuracy: 0.7259\n",
      "Epoch 74/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4926 - accuracy: 0.7665 - val_loss: 0.5459 - val_accuracy: 0.7260\n",
      "Epoch 75/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4925 - accuracy: 0.7665 - val_loss: 0.5477 - val_accuracy: 0.7273\n",
      "Epoch 76/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4925 - accuracy: 0.7664 - val_loss: 0.5475 - val_accuracy: 0.7262\n",
      "Epoch 77/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4924 - accuracy: 0.7661 - val_loss: 0.5473 - val_accuracy: 0.7266\n",
      "Epoch 78/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4924 - accuracy: 0.7658 - val_loss: 0.5463 - val_accuracy: 0.7264\n",
      "Epoch 79/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4924 - accuracy: 0.7662 - val_loss: 0.5458 - val_accuracy: 0.7269\n",
      "Epoch 80/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4923 - accuracy: 0.7665 - val_loss: 0.5465 - val_accuracy: 0.7267\n",
      "Epoch 81/200\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4922 - accuracy: 0.7666 - val_loss: 0.5473 - val_accuracy: 0.7268\n",
      "Epoch 82/200\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4923 - accuracy: 0.7661 - val_loss: 0.5467 - val_accuracy: 0.7260\n",
      "Epoch 83/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4922 - accuracy: 0.7666 - val_loss: 0.5469 - val_accuracy: 0.7273\n",
      "Epoch 84/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4922 - accuracy: 0.7664 - val_loss: 0.5461 - val_accuracy: 0.7264\n",
      "Epoch 85/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4921 - accuracy: 0.7664 - val_loss: 0.5474 - val_accuracy: 0.7258\n",
      "Epoch 86/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4921 - accuracy: 0.7663 - val_loss: 0.5468 - val_accuracy: 0.7266\n",
      "Epoch 87/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4921 - accuracy: 0.7669 - val_loss: 0.5464 - val_accuracy: 0.7275\n",
      "Epoch 88/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4921 - accuracy: 0.7665 - val_loss: 0.5460 - val_accuracy: 0.7268\n",
      "Epoch 89/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4920 - accuracy: 0.7662 - val_loss: 0.5461 - val_accuracy: 0.7272\n",
      "Epoch 90/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4920 - accuracy: 0.7662 - val_loss: 0.5476 - val_accuracy: 0.7262\n",
      "Epoch 91/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4919 - accuracy: 0.7665 - val_loss: 0.5470 - val_accuracy: 0.7267\n",
      "Epoch 92/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4919 - accuracy: 0.7663 - val_loss: 0.5456 - val_accuracy: 0.7275\n",
      "Epoch 93/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4919 - accuracy: 0.7667 - val_loss: 0.5479 - val_accuracy: 0.7254\n",
      "Epoch 94/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4920 - accuracy: 0.7663 - val_loss: 0.5471 - val_accuracy: 0.7251\n",
      "Epoch 95/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4919 - accuracy: 0.7667 - val_loss: 0.5471 - val_accuracy: 0.7265\n",
      "Epoch 96/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4918 - accuracy: 0.7665 - val_loss: 0.5462 - val_accuracy: 0.7271\n",
      "Epoch 97/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4918 - accuracy: 0.7664 - val_loss: 0.5465 - val_accuracy: 0.7261\n",
      "Epoch 98/200\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4918 - accuracy: 0.7665 - val_loss: 0.5467 - val_accuracy: 0.7276\n",
      "Epoch 99/200\n",
      "6400/6400 [==============================] - 0s 38us/step - loss: 0.4917 - accuracy: 0.7666 - val_loss: 0.5486 - val_accuracy: 0.7258\n",
      "Epoch 100/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4917 - accuracy: 0.7662 - val_loss: 0.5468 - val_accuracy: 0.7271\n",
      "Epoch 101/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4917 - accuracy: 0.7666 - val_loss: 0.5468 - val_accuracy: 0.7281\n",
      "Epoch 102/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4917 - accuracy: 0.7668 - val_loss: 0.5466 - val_accuracy: 0.7257\n",
      "Epoch 103/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4917 - accuracy: 0.7665 - val_loss: 0.5462 - val_accuracy: 0.7267\n",
      "Epoch 104/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4916 - accuracy: 0.7662 - val_loss: 0.5463 - val_accuracy: 0.7268\n",
      "Epoch 105/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4916 - accuracy: 0.7662 - val_loss: 0.5475 - val_accuracy: 0.7265\n",
      "Epoch 106/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4916 - accuracy: 0.7666 - val_loss: 0.5469 - val_accuracy: 0.7264\n",
      "Epoch 107/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4916 - accuracy: 0.7667 - val_loss: 0.5464 - val_accuracy: 0.7267\n",
      "Epoch 108/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4915 - accuracy: 0.7665 - val_loss: 0.5460 - val_accuracy: 0.7275\n",
      "Epoch 109/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4915 - accuracy: 0.7666 - val_loss: 0.5467 - val_accuracy: 0.7265\n",
      "Epoch 110/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4916 - accuracy: 0.7667 - val_loss: 0.5462 - val_accuracy: 0.7266\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4915 - accuracy: 0.7665 - val_loss: 0.5472 - val_accuracy: 0.7272\n",
      "Epoch 112/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4915 - accuracy: 0.7668 - val_loss: 0.5466 - val_accuracy: 0.7276\n",
      "Epoch 113/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4914 - accuracy: 0.7668 - val_loss: 0.5472 - val_accuracy: 0.7264\n",
      "Epoch 114/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4914 - accuracy: 0.7668 - val_loss: 0.5469 - val_accuracy: 0.7263\n",
      "Epoch 115/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4914 - accuracy: 0.7665 - val_loss: 0.5472 - val_accuracy: 0.7258\n",
      "Epoch 116/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4913 - accuracy: 0.7666 - val_loss: 0.5466 - val_accuracy: 0.7264\n",
      "Epoch 117/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4913 - accuracy: 0.7669 - val_loss: 0.5472 - val_accuracy: 0.7269\n",
      "Epoch 118/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4914 - accuracy: 0.7667 - val_loss: 0.5473 - val_accuracy: 0.7251\n",
      "Epoch 119/200\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4913 - accuracy: 0.7667 - val_loss: 0.5465 - val_accuracy: 0.7271\n",
      "Epoch 120/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4913 - accuracy: 0.7663 - val_loss: 0.5472 - val_accuracy: 0.7263\n",
      "Epoch 121/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4913 - accuracy: 0.7669 - val_loss: 0.5461 - val_accuracy: 0.7274\n",
      "Epoch 122/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4912 - accuracy: 0.7668 - val_loss: 0.5480 - val_accuracy: 0.7259\n",
      "Epoch 123/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4913 - accuracy: 0.7664 - val_loss: 0.5459 - val_accuracy: 0.7268\n",
      "Epoch 124/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4911 - accuracy: 0.7667 - val_loss: 0.5474 - val_accuracy: 0.7253\n",
      "Epoch 125/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4912 - accuracy: 0.7668 - val_loss: 0.5469 - val_accuracy: 0.7264\n",
      "Epoch 126/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4912 - accuracy: 0.7662 - val_loss: 0.5467 - val_accuracy: 0.7267\n",
      "Epoch 127/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4912 - accuracy: 0.7669 - val_loss: 0.5469 - val_accuracy: 0.7259\n",
      "Epoch 128/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4911 - accuracy: 0.7670 - val_loss: 0.5476 - val_accuracy: 0.7258\n",
      "Epoch 129/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4911 - accuracy: 0.7666 - val_loss: 0.5472 - val_accuracy: 0.7253\n",
      "Epoch 130/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4911 - accuracy: 0.7665 - val_loss: 0.5465 - val_accuracy: 0.7261\n",
      "Epoch 131/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4910 - accuracy: 0.7671 - val_loss: 0.5470 - val_accuracy: 0.7269\n",
      "Epoch 132/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4911 - accuracy: 0.7670 - val_loss: 0.5473 - val_accuracy: 0.7265\n",
      "Epoch 133/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4911 - accuracy: 0.7668 - val_loss: 0.5477 - val_accuracy: 0.7264\n",
      "Epoch 134/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4910 - accuracy: 0.7670 - val_loss: 0.5461 - val_accuracy: 0.7260\n",
      "Epoch 135/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4911 - accuracy: 0.7669 - val_loss: 0.5464 - val_accuracy: 0.7270\n",
      "Epoch 136/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4910 - accuracy: 0.7670 - val_loss: 0.5472 - val_accuracy: 0.7268\n",
      "Epoch 137/200\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4911 - accuracy: 0.7669 - val_loss: 0.5469 - val_accuracy: 0.7262\n",
      "Epoch 138/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4909 - accuracy: 0.7669 - val_loss: 0.5462 - val_accuracy: 0.7268\n",
      "Epoch 139/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4910 - accuracy: 0.7667 - val_loss: 0.5466 - val_accuracy: 0.7258\n",
      "Epoch 140/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4910 - accuracy: 0.7668 - val_loss: 0.5472 - val_accuracy: 0.7260\n",
      "Epoch 141/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4910 - accuracy: 0.7668 - val_loss: 0.5479 - val_accuracy: 0.7251\n",
      "Epoch 142/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4908 - accuracy: 0.7672 - val_loss: 0.5472 - val_accuracy: 0.7270\n",
      "Epoch 143/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4909 - accuracy: 0.7673 - val_loss: 0.5476 - val_accuracy: 0.7266\n",
      "Epoch 144/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4909 - accuracy: 0.7671 - val_loss: 0.5467 - val_accuracy: 0.7263\n",
      "Epoch 145/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4909 - accuracy: 0.7677 - val_loss: 0.5474 - val_accuracy: 0.7258\n",
      "Epoch 146/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4909 - accuracy: 0.7668 - val_loss: 0.5466 - val_accuracy: 0.7262\n",
      "Epoch 147/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4909 - accuracy: 0.7673 - val_loss: 0.5467 - val_accuracy: 0.7261\n",
      "Epoch 148/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4909 - accuracy: 0.7673 - val_loss: 0.5469 - val_accuracy: 0.7262\n",
      "Epoch 149/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4908 - accuracy: 0.7673 - val_loss: 0.5470 - val_accuracy: 0.7263\n",
      "Epoch 150/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4908 - accuracy: 0.7671 - val_loss: 0.5468 - val_accuracy: 0.7266\n",
      "Epoch 151/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4908 - accuracy: 0.7668 - val_loss: 0.5475 - val_accuracy: 0.7264\n",
      "Epoch 152/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4908 - accuracy: 0.7676 - val_loss: 0.5468 - val_accuracy: 0.7264\n",
      "Epoch 153/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4908 - accuracy: 0.7672 - val_loss: 0.5474 - val_accuracy: 0.7255\n",
      "Epoch 154/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4908 - accuracy: 0.7667 - val_loss: 0.5477 - val_accuracy: 0.7253\n",
      "Epoch 155/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4908 - accuracy: 0.7673 - val_loss: 0.5473 - val_accuracy: 0.7261\n",
      "Epoch 156/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4907 - accuracy: 0.7667 - val_loss: 0.5473 - val_accuracy: 0.7268\n",
      "Epoch 157/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4908 - accuracy: 0.7668 - val_loss: 0.5475 - val_accuracy: 0.7261\n",
      "Epoch 158/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4907 - accuracy: 0.7673 - val_loss: 0.5474 - val_accuracy: 0.7256\n",
      "Epoch 159/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4908 - accuracy: 0.7672 - val_loss: 0.5471 - val_accuracy: 0.7265\n",
      "Epoch 160/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4907 - accuracy: 0.7673 - val_loss: 0.5485 - val_accuracy: 0.7253\n",
      "Epoch 161/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4906 - accuracy: 0.7669 - val_loss: 0.5470 - val_accuracy: 0.7258\n",
      "Epoch 162/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4907 - accuracy: 0.7671 - val_loss: 0.5471 - val_accuracy: 0.7257\n",
      "Epoch 163/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4906 - accuracy: 0.7675 - val_loss: 0.5483 - val_accuracy: 0.7254\n",
      "Epoch 164/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4907 - accuracy: 0.7669 - val_loss: 0.5484 - val_accuracy: 0.7255\n",
      "Epoch 165/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4907 - accuracy: 0.7672 - val_loss: 0.5480 - val_accuracy: 0.7268\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4907 - accuracy: 0.7671 - val_loss: 0.5470 - val_accuracy: 0.7260\n",
      "Epoch 167/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4906 - accuracy: 0.7672 - val_loss: 0.5469 - val_accuracy: 0.7265\n",
      "Epoch 168/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4906 - accuracy: 0.7673 - val_loss: 0.5473 - val_accuracy: 0.7257\n",
      "Epoch 169/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4906 - accuracy: 0.7672 - val_loss: 0.5470 - val_accuracy: 0.7259\n",
      "Epoch 170/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4906 - accuracy: 0.7672 - val_loss: 0.5475 - val_accuracy: 0.7263\n",
      "Epoch 171/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4906 - accuracy: 0.7669 - val_loss: 0.5469 - val_accuracy: 0.7265\n",
      "Epoch 172/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4906 - accuracy: 0.7674 - val_loss: 0.5475 - val_accuracy: 0.7265\n",
      "Epoch 173/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4906 - accuracy: 0.7676 - val_loss: 0.5471 - val_accuracy: 0.7263\n",
      "Epoch 174/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4905 - accuracy: 0.7677 - val_loss: 0.5479 - val_accuracy: 0.7247\n",
      "Epoch 175/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4906 - accuracy: 0.7673 - val_loss: 0.5486 - val_accuracy: 0.7262\n",
      "Epoch 176/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4905 - accuracy: 0.7674 - val_loss: 0.5471 - val_accuracy: 0.7258\n",
      "Epoch 177/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4905 - accuracy: 0.7674 - val_loss: 0.5471 - val_accuracy: 0.7265\n",
      "Epoch 178/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4905 - accuracy: 0.7673 - val_loss: 0.5466 - val_accuracy: 0.7262\n",
      "Epoch 179/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4905 - accuracy: 0.7671 - val_loss: 0.5467 - val_accuracy: 0.7266\n",
      "Epoch 180/200\n",
      "6400/6400 [==============================] - 0s 57us/step - loss: 0.4905 - accuracy: 0.7674 - val_loss: 0.5479 - val_accuracy: 0.7257\n",
      "Epoch 181/200\n",
      "6400/6400 [==============================] - 0s 58us/step - loss: 0.4905 - accuracy: 0.7671 - val_loss: 0.5477 - val_accuracy: 0.7257\n",
      "Epoch 182/200\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4905 - accuracy: 0.7671 - val_loss: 0.5469 - val_accuracy: 0.7256\n",
      "Epoch 183/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4905 - accuracy: 0.7671 - val_loss: 0.5475 - val_accuracy: 0.7259\n",
      "Epoch 184/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4905 - accuracy: 0.7671 - val_loss: 0.5471 - val_accuracy: 0.7260\n",
      "Epoch 185/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4904 - accuracy: 0.7670 - val_loss: 0.5472 - val_accuracy: 0.7254\n",
      "Epoch 186/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4904 - accuracy: 0.7669 - val_loss: 0.5476 - val_accuracy: 0.7257\n",
      "Epoch 187/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4905 - accuracy: 0.7677 - val_loss: 0.5466 - val_accuracy: 0.7269\n",
      "Epoch 188/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4903 - accuracy: 0.7672 - val_loss: 0.5476 - val_accuracy: 0.7253\n",
      "Epoch 189/200\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4904 - accuracy: 0.7672 - val_loss: 0.5468 - val_accuracy: 0.7260\n",
      "Epoch 190/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4904 - accuracy: 0.7673 - val_loss: 0.5482 - val_accuracy: 0.7262\n",
      "Epoch 191/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4903 - accuracy: 0.7673 - val_loss: 0.5486 - val_accuracy: 0.7247\n",
      "Epoch 192/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4904 - accuracy: 0.7670 - val_loss: 0.5475 - val_accuracy: 0.7261\n",
      "Epoch 193/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4904 - accuracy: 0.7672 - val_loss: 0.5479 - val_accuracy: 0.7254\n",
      "Epoch 194/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4904 - accuracy: 0.7673 - val_loss: 0.5488 - val_accuracy: 0.7266\n",
      "Epoch 195/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4904 - accuracy: 0.7673 - val_loss: 0.5466 - val_accuracy: 0.7261\n",
      "Epoch 196/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4904 - accuracy: 0.7670 - val_loss: 0.5473 - val_accuracy: 0.7263\n",
      "Epoch 197/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4903 - accuracy: 0.7678 - val_loss: 0.5478 - val_accuracy: 0.7255\n",
      "Epoch 198/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4903 - accuracy: 0.7672 - val_loss: 0.5474 - val_accuracy: 0.7266\n",
      "Epoch 199/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4903 - accuracy: 0.7672 - val_loss: 0.5487 - val_accuracy: 0.7258\n",
      "Epoch 200/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4903 - accuracy: 0.7674 - val_loss: 0.5482 - val_accuracy: 0.7259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:127: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Train on 6400 samples, validate on 1601 samples\n",
      "Epoch 1/200\n",
      "6400/6400 [==============================] - 0s 48us/step - loss: 0.6158 - accuracy: 0.7052 - val_loss: 0.5877 - val_accuracy: 0.7261\n",
      "Epoch 2/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.5381 - accuracy: 0.7661 - val_loss: 0.5801 - val_accuracy: 0.7261\n",
      "Epoch 3/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5331 - accuracy: 0.7661 - val_loss: 0.5780 - val_accuracy: 0.7261\n",
      "Epoch 4/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5316 - accuracy: 0.7661 - val_loss: 0.5776 - val_accuracy: 0.7261\n",
      "Epoch 5/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5307 - accuracy: 0.7661 - val_loss: 0.5765 - val_accuracy: 0.7261\n",
      "Epoch 6/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5300 - accuracy: 0.7661 - val_loss: 0.5759 - val_accuracy: 0.7261\n",
      "Epoch 7/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5294 - accuracy: 0.7661 - val_loss: 0.5751 - val_accuracy: 0.7261\n",
      "Epoch 8/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5289 - accuracy: 0.7661 - val_loss: 0.5740 - val_accuracy: 0.7261\n",
      "Epoch 9/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5284 - accuracy: 0.7661 - val_loss: 0.5741 - val_accuracy: 0.7261\n",
      "Epoch 10/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5279 - accuracy: 0.7661 - val_loss: 0.5738 - val_accuracy: 0.7261\n",
      "Epoch 11/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5274 - accuracy: 0.7661 - val_loss: 0.5730 - val_accuracy: 0.7261\n",
      "Epoch 12/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5267 - accuracy: 0.7661 - val_loss: 0.5733 - val_accuracy: 0.7261\n",
      "Epoch 13/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5261 - accuracy: 0.7661 - val_loss: 0.5719 - val_accuracy: 0.7261\n",
      "Epoch 14/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5253 - accuracy: 0.7661 - val_loss: 0.5717 - val_accuracy: 0.7261\n",
      "Epoch 15/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5244 - accuracy: 0.7661 - val_loss: 0.5710 - val_accuracy: 0.7261\n",
      "Epoch 16/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5235 - accuracy: 0.7661 - val_loss: 0.5712 - val_accuracy: 0.7261\n",
      "Epoch 17/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5223 - accuracy: 0.7661 - val_loss: 0.5691 - val_accuracy: 0.7261\n",
      "Epoch 18/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5212 - accuracy: 0.7660 - val_loss: 0.5686 - val_accuracy: 0.7263\n",
      "Epoch 19/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5199 - accuracy: 0.7661 - val_loss: 0.5684 - val_accuracy: 0.7265\n",
      "Epoch 20/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5187 - accuracy: 0.7661 - val_loss: 0.5664 - val_accuracy: 0.7265\n",
      "Epoch 21/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.5175 - accuracy: 0.7663 - val_loss: 0.5662 - val_accuracy: 0.7265\n",
      "Epoch 22/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5164 - accuracy: 0.7663 - val_loss: 0.5650 - val_accuracy: 0.7264\n",
      "Epoch 23/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5151 - accuracy: 0.7661 - val_loss: 0.5642 - val_accuracy: 0.7262\n",
      "Epoch 24/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5140 - accuracy: 0.7661 - val_loss: 0.5642 - val_accuracy: 0.7265\n",
      "Epoch 25/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5127 - accuracy: 0.7660 - val_loss: 0.5631 - val_accuracy: 0.7259\n",
      "Epoch 26/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5115 - accuracy: 0.7658 - val_loss: 0.5620 - val_accuracy: 0.7256\n",
      "Epoch 27/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5102 - accuracy: 0.7658 - val_loss: 0.5614 - val_accuracy: 0.7260\n",
      "Epoch 28/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.5087 - accuracy: 0.7663 - val_loss: 0.5606 - val_accuracy: 0.7262\n",
      "Epoch 29/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.5073 - accuracy: 0.7665 - val_loss: 0.5584 - val_accuracy: 0.7260\n",
      "Epoch 30/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5057 - accuracy: 0.7664 - val_loss: 0.5579 - val_accuracy: 0.7255\n",
      "Epoch 31/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5041 - accuracy: 0.7665 - val_loss: 0.5560 - val_accuracy: 0.7254\n",
      "Epoch 32/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.5026 - accuracy: 0.7663 - val_loss: 0.5558 - val_accuracy: 0.7255\n",
      "Epoch 33/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5012 - accuracy: 0.7667 - val_loss: 0.5546 - val_accuracy: 0.7257\n",
      "Epoch 34/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4998 - accuracy: 0.7664 - val_loss: 0.5524 - val_accuracy: 0.7253\n",
      "Epoch 35/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4988 - accuracy: 0.7664 - val_loss: 0.5536 - val_accuracy: 0.7259\n",
      "Epoch 36/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4978 - accuracy: 0.7662 - val_loss: 0.5540 - val_accuracy: 0.7258\n",
      "Epoch 37/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4972 - accuracy: 0.7661 - val_loss: 0.5516 - val_accuracy: 0.7258\n",
      "Epoch 38/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4965 - accuracy: 0.7663 - val_loss: 0.5517 - val_accuracy: 0.7262\n",
      "Epoch 39/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4960 - accuracy: 0.7662 - val_loss: 0.5509 - val_accuracy: 0.7262\n",
      "Epoch 40/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4956 - accuracy: 0.7660 - val_loss: 0.5517 - val_accuracy: 0.7264\n",
      "Epoch 41/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4953 - accuracy: 0.7661 - val_loss: 0.5511 - val_accuracy: 0.7270\n",
      "Epoch 42/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4951 - accuracy: 0.7661 - val_loss: 0.5501 - val_accuracy: 0.7257\n",
      "Epoch 43/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4947 - accuracy: 0.7662 - val_loss: 0.5508 - val_accuracy: 0.7254\n",
      "Epoch 44/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4947 - accuracy: 0.7663 - val_loss: 0.5505 - val_accuracy: 0.7265\n",
      "Epoch 45/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4944 - accuracy: 0.7661 - val_loss: 0.5512 - val_accuracy: 0.7260\n",
      "Epoch 46/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4944 - accuracy: 0.7662 - val_loss: 0.5510 - val_accuracy: 0.7252\n",
      "Epoch 47/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4943 - accuracy: 0.7658 - val_loss: 0.5513 - val_accuracy: 0.7263\n",
      "Epoch 48/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4942 - accuracy: 0.7656 - val_loss: 0.5500 - val_accuracy: 0.7255\n",
      "Epoch 49/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4941 - accuracy: 0.7660 - val_loss: 0.5496 - val_accuracy: 0.7262\n",
      "Epoch 50/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4940 - accuracy: 0.7658 - val_loss: 0.5499 - val_accuracy: 0.7259\n",
      "Epoch 51/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4940 - accuracy: 0.7659 - val_loss: 0.5502 - val_accuracy: 0.7262\n",
      "Epoch 52/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4940 - accuracy: 0.7660 - val_loss: 0.5501 - val_accuracy: 0.7254\n",
      "Epoch 53/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4938 - accuracy: 0.7663 - val_loss: 0.5502 - val_accuracy: 0.7256\n",
      "Epoch 54/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4939 - accuracy: 0.7658 - val_loss: 0.5501 - val_accuracy: 0.7258\n",
      "Epoch 55/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4938 - accuracy: 0.7661 - val_loss: 0.5495 - val_accuracy: 0.7266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4938 - accuracy: 0.7659 - val_loss: 0.5492 - val_accuracy: 0.7251\n",
      "Epoch 57/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4936 - accuracy: 0.7659 - val_loss: 0.5499 - val_accuracy: 0.7257\n",
      "Epoch 58/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4937 - accuracy: 0.7661 - val_loss: 0.5505 - val_accuracy: 0.7252\n",
      "Epoch 59/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4937 - accuracy: 0.7657 - val_loss: 0.5500 - val_accuracy: 0.7258\n",
      "Epoch 60/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4937 - accuracy: 0.7660 - val_loss: 0.5502 - val_accuracy: 0.7253\n",
      "Epoch 61/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4936 - accuracy: 0.7660 - val_loss: 0.5492 - val_accuracy: 0.7266\n",
      "Epoch 62/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4935 - accuracy: 0.7666 - val_loss: 0.5505 - val_accuracy: 0.7253\n",
      "Epoch 63/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4935 - accuracy: 0.7663 - val_loss: 0.5500 - val_accuracy: 0.7258\n",
      "Epoch 64/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4934 - accuracy: 0.7662 - val_loss: 0.5500 - val_accuracy: 0.7261\n",
      "Epoch 65/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4934 - accuracy: 0.7666 - val_loss: 0.5503 - val_accuracy: 0.7264\n",
      "Epoch 66/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4934 - accuracy: 0.7660 - val_loss: 0.5500 - val_accuracy: 0.7264\n",
      "Epoch 67/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4933 - accuracy: 0.7666 - val_loss: 0.5500 - val_accuracy: 0.7248\n",
      "Epoch 68/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4933 - accuracy: 0.7663 - val_loss: 0.5502 - val_accuracy: 0.7258\n",
      "Epoch 69/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4933 - accuracy: 0.7664 - val_loss: 0.5506 - val_accuracy: 0.7255\n",
      "Epoch 70/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4933 - accuracy: 0.7663 - val_loss: 0.5506 - val_accuracy: 0.7259\n",
      "Epoch 71/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4932 - accuracy: 0.7671 - val_loss: 0.5506 - val_accuracy: 0.7260\n",
      "Epoch 72/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4931 - accuracy: 0.7668 - val_loss: 0.5497 - val_accuracy: 0.7258\n",
      "Epoch 73/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4931 - accuracy: 0.7665 - val_loss: 0.5504 - val_accuracy: 0.7265\n",
      "Epoch 74/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4932 - accuracy: 0.7664 - val_loss: 0.5494 - val_accuracy: 0.7264\n",
      "Epoch 75/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4931 - accuracy: 0.7666 - val_loss: 0.5505 - val_accuracy: 0.7264\n",
      "Epoch 76/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4931 - accuracy: 0.7664 - val_loss: 0.5500 - val_accuracy: 0.7260\n",
      "Epoch 77/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4931 - accuracy: 0.7668 - val_loss: 0.5508 - val_accuracy: 0.7259\n",
      "Epoch 78/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4930 - accuracy: 0.7668 - val_loss: 0.5503 - val_accuracy: 0.7260\n",
      "Epoch 79/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4930 - accuracy: 0.7667 - val_loss: 0.5507 - val_accuracy: 0.7254\n",
      "Epoch 80/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4929 - accuracy: 0.7671 - val_loss: 0.5493 - val_accuracy: 0.7258\n",
      "Epoch 81/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4930 - accuracy: 0.7668 - val_loss: 0.5501 - val_accuracy: 0.7263\n",
      "Epoch 82/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4929 - accuracy: 0.7672 - val_loss: 0.5503 - val_accuracy: 0.7262\n",
      "Epoch 83/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4930 - accuracy: 0.7669 - val_loss: 0.5493 - val_accuracy: 0.7258\n",
      "Epoch 84/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4929 - accuracy: 0.7666 - val_loss: 0.5502 - val_accuracy: 0.7268\n",
      "Epoch 85/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4929 - accuracy: 0.7668 - val_loss: 0.5495 - val_accuracy: 0.7255\n",
      "Epoch 86/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4929 - accuracy: 0.7666 - val_loss: 0.5496 - val_accuracy: 0.7266\n",
      "Epoch 87/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4928 - accuracy: 0.7669 - val_loss: 0.5506 - val_accuracy: 0.7249\n",
      "Epoch 88/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4927 - accuracy: 0.7671 - val_loss: 0.5508 - val_accuracy: 0.7248\n",
      "Epoch 89/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4927 - accuracy: 0.7674 - val_loss: 0.5506 - val_accuracy: 0.7254\n",
      "Epoch 90/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4928 - accuracy: 0.7670 - val_loss: 0.5506 - val_accuracy: 0.7258\n",
      "Epoch 91/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4927 - accuracy: 0.7672 - val_loss: 0.5490 - val_accuracy: 0.7254\n",
      "Epoch 92/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4927 - accuracy: 0.7671 - val_loss: 0.5492 - val_accuracy: 0.7262\n",
      "Epoch 93/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4927 - accuracy: 0.7675 - val_loss: 0.5500 - val_accuracy: 0.7266\n",
      "Epoch 94/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4926 - accuracy: 0.7671 - val_loss: 0.5502 - val_accuracy: 0.7262\n",
      "Epoch 95/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4927 - accuracy: 0.7671 - val_loss: 0.5498 - val_accuracy: 0.7254\n",
      "Epoch 96/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4926 - accuracy: 0.7671 - val_loss: 0.5498 - val_accuracy: 0.7257\n",
      "Epoch 97/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4925 - accuracy: 0.7677 - val_loss: 0.5505 - val_accuracy: 0.7257\n",
      "Epoch 98/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4926 - accuracy: 0.7678 - val_loss: 0.5499 - val_accuracy: 0.7254\n",
      "Epoch 99/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4926 - accuracy: 0.7675 - val_loss: 0.5497 - val_accuracy: 0.7261\n",
      "Epoch 100/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4925 - accuracy: 0.7675 - val_loss: 0.5491 - val_accuracy: 0.7250\n",
      "Epoch 101/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4925 - accuracy: 0.7671 - val_loss: 0.5497 - val_accuracy: 0.7252\n",
      "Epoch 102/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4925 - accuracy: 0.7678 - val_loss: 0.5495 - val_accuracy: 0.7257\n",
      "Epoch 103/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4925 - accuracy: 0.7673 - val_loss: 0.5496 - val_accuracy: 0.7258\n",
      "Epoch 104/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4924 - accuracy: 0.7674 - val_loss: 0.5510 - val_accuracy: 0.7262\n",
      "Epoch 105/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4924 - accuracy: 0.7679 - val_loss: 0.5512 - val_accuracy: 0.7250\n",
      "Epoch 106/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4924 - accuracy: 0.7675 - val_loss: 0.5506 - val_accuracy: 0.7264\n",
      "Epoch 107/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4924 - accuracy: 0.7680 - val_loss: 0.5509 - val_accuracy: 0.7255\n",
      "Epoch 108/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4923 - accuracy: 0.7677 - val_loss: 0.5496 - val_accuracy: 0.7257\n",
      "Epoch 109/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4923 - accuracy: 0.7675 - val_loss: 0.5509 - val_accuracy: 0.7267\n",
      "Epoch 110/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4923 - accuracy: 0.7680 - val_loss: 0.5507 - val_accuracy: 0.7270\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4923 - accuracy: 0.7672 - val_loss: 0.5495 - val_accuracy: 0.7253\n",
      "Epoch 112/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4923 - accuracy: 0.7679 - val_loss: 0.5507 - val_accuracy: 0.7264\n",
      "Epoch 113/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4922 - accuracy: 0.7676 - val_loss: 0.5514 - val_accuracy: 0.7253\n",
      "Epoch 114/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4922 - accuracy: 0.7677 - val_loss: 0.5503 - val_accuracy: 0.7262\n",
      "Epoch 115/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4922 - accuracy: 0.7678 - val_loss: 0.5509 - val_accuracy: 0.7254\n",
      "Epoch 116/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4922 - accuracy: 0.7680 - val_loss: 0.5501 - val_accuracy: 0.7261\n",
      "Epoch 117/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4921 - accuracy: 0.7678 - val_loss: 0.5506 - val_accuracy: 0.7258\n",
      "Epoch 118/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4921 - accuracy: 0.7677 - val_loss: 0.5503 - val_accuracy: 0.7264\n",
      "Epoch 119/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4922 - accuracy: 0.7678 - val_loss: 0.5495 - val_accuracy: 0.7258\n",
      "Epoch 120/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4921 - accuracy: 0.7681 - val_loss: 0.5519 - val_accuracy: 0.7250\n",
      "Epoch 121/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4921 - accuracy: 0.7676 - val_loss: 0.5497 - val_accuracy: 0.7257\n",
      "Epoch 122/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4921 - accuracy: 0.7680 - val_loss: 0.5495 - val_accuracy: 0.7256\n",
      "Epoch 123/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4921 - accuracy: 0.7679 - val_loss: 0.5508 - val_accuracy: 0.7253\n",
      "Epoch 124/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4921 - accuracy: 0.7683 - val_loss: 0.5508 - val_accuracy: 0.7259\n",
      "Epoch 125/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4921 - accuracy: 0.7680 - val_loss: 0.5512 - val_accuracy: 0.7256\n",
      "Epoch 126/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4920 - accuracy: 0.7682 - val_loss: 0.5510 - val_accuracy: 0.7256\n",
      "Epoch 127/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4920 - accuracy: 0.7683 - val_loss: 0.5500 - val_accuracy: 0.7261\n",
      "Epoch 128/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4919 - accuracy: 0.7684 - val_loss: 0.5500 - val_accuracy: 0.7254\n",
      "Epoch 129/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4920 - accuracy: 0.7684 - val_loss: 0.5504 - val_accuracy: 0.7265\n",
      "Epoch 130/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4920 - accuracy: 0.7688 - val_loss: 0.5509 - val_accuracy: 0.7262\n",
      "Epoch 131/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4920 - accuracy: 0.7679 - val_loss: 0.5499 - val_accuracy: 0.7257\n",
      "Epoch 132/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4920 - accuracy: 0.7687 - val_loss: 0.5515 - val_accuracy: 0.7255\n",
      "Epoch 133/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4919 - accuracy: 0.7682 - val_loss: 0.5499 - val_accuracy: 0.7255\n",
      "Epoch 134/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4919 - accuracy: 0.7684 - val_loss: 0.5508 - val_accuracy: 0.7259\n",
      "Epoch 135/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4919 - accuracy: 0.7686 - val_loss: 0.5498 - val_accuracy: 0.7262\n",
      "Epoch 136/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4919 - accuracy: 0.7685 - val_loss: 0.5496 - val_accuracy: 0.7252\n",
      "Epoch 137/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4919 - accuracy: 0.7678 - val_loss: 0.5496 - val_accuracy: 0.7265\n",
      "Epoch 138/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4918 - accuracy: 0.7680 - val_loss: 0.5504 - val_accuracy: 0.7249\n",
      "Epoch 139/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4918 - accuracy: 0.7681 - val_loss: 0.5488 - val_accuracy: 0.7258\n",
      "Epoch 140/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4919 - accuracy: 0.7685 - val_loss: 0.5505 - val_accuracy: 0.7266\n",
      "Epoch 141/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4919 - accuracy: 0.7685 - val_loss: 0.5513 - val_accuracy: 0.7260\n",
      "Epoch 142/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4918 - accuracy: 0.7688 - val_loss: 0.5505 - val_accuracy: 0.7250\n",
      "Epoch 143/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4918 - accuracy: 0.7684 - val_loss: 0.5499 - val_accuracy: 0.7244\n",
      "Epoch 144/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4917 - accuracy: 0.7683 - val_loss: 0.5507 - val_accuracy: 0.7247\n",
      "Epoch 145/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4918 - accuracy: 0.7685 - val_loss: 0.5508 - val_accuracy: 0.7247\n",
      "Epoch 146/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4918 - accuracy: 0.7682 - val_loss: 0.5504 - val_accuracy: 0.7260\n",
      "Epoch 147/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4917 - accuracy: 0.7682 - val_loss: 0.5501 - val_accuracy: 0.7251\n",
      "Epoch 148/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4918 - accuracy: 0.7685 - val_loss: 0.5496 - val_accuracy: 0.7260\n",
      "Epoch 149/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4917 - accuracy: 0.7690 - val_loss: 0.5501 - val_accuracy: 0.7243\n",
      "Epoch 150/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4918 - accuracy: 0.7682 - val_loss: 0.5502 - val_accuracy: 0.7250\n",
      "Epoch 151/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4917 - accuracy: 0.7687 - val_loss: 0.5519 - val_accuracy: 0.7252\n",
      "Epoch 152/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4917 - accuracy: 0.7684 - val_loss: 0.5510 - val_accuracy: 0.7250\n",
      "Epoch 153/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4917 - accuracy: 0.7687 - val_loss: 0.5503 - val_accuracy: 0.7254\n",
      "Epoch 154/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4917 - accuracy: 0.7689 - val_loss: 0.5493 - val_accuracy: 0.7242\n",
      "Epoch 155/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4916 - accuracy: 0.7682 - val_loss: 0.5500 - val_accuracy: 0.7252\n",
      "Epoch 156/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4917 - accuracy: 0.7683 - val_loss: 0.5508 - val_accuracy: 0.7248\n",
      "Epoch 157/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4916 - accuracy: 0.7677 - val_loss: 0.5496 - val_accuracy: 0.7243\n",
      "Epoch 158/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4917 - accuracy: 0.7688 - val_loss: 0.5504 - val_accuracy: 0.7259\n",
      "Epoch 159/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4916 - accuracy: 0.7684 - val_loss: 0.5492 - val_accuracy: 0.7255\n",
      "Epoch 160/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4916 - accuracy: 0.7687 - val_loss: 0.5504 - val_accuracy: 0.7261\n",
      "Epoch 161/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4916 - accuracy: 0.7685 - val_loss: 0.5499 - val_accuracy: 0.7248\n",
      "Epoch 162/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4916 - accuracy: 0.7683 - val_loss: 0.5504 - val_accuracy: 0.7262\n",
      "Epoch 163/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4916 - accuracy: 0.7686 - val_loss: 0.5505 - val_accuracy: 0.7250\n",
      "Epoch 164/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4915 - accuracy: 0.7682 - val_loss: 0.5501 - val_accuracy: 0.7265\n",
      "Epoch 165/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4916 - accuracy: 0.7687 - val_loss: 0.5506 - val_accuracy: 0.7259\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7687 - val_loss: 0.5494 - val_accuracy: 0.7241\n",
      "Epoch 167/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7685 - val_loss: 0.5500 - val_accuracy: 0.7246\n",
      "Epoch 168/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7686 - val_loss: 0.5498 - val_accuracy: 0.7255\n",
      "Epoch 169/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4916 - accuracy: 0.7681 - val_loss: 0.5506 - val_accuracy: 0.7255\n",
      "Epoch 170/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7689 - val_loss: 0.5500 - val_accuracy: 0.7243\n",
      "Epoch 171/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4915 - accuracy: 0.7690 - val_loss: 0.5509 - val_accuracy: 0.7240\n",
      "Epoch 172/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4916 - accuracy: 0.7692 - val_loss: 0.5497 - val_accuracy: 0.7261\n",
      "Epoch 173/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7682 - val_loss: 0.5500 - val_accuracy: 0.7243\n",
      "Epoch 174/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7682 - val_loss: 0.5508 - val_accuracy: 0.7251\n",
      "Epoch 175/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7681 - val_loss: 0.5504 - val_accuracy: 0.7249\n",
      "Epoch 176/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7687 - val_loss: 0.5504 - val_accuracy: 0.7248\n",
      "Epoch 177/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7689 - val_loss: 0.5500 - val_accuracy: 0.7255\n",
      "Epoch 178/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7687 - val_loss: 0.5517 - val_accuracy: 0.7249\n",
      "Epoch 179/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7688 - val_loss: 0.5499 - val_accuracy: 0.7257\n",
      "Epoch 180/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7685 - val_loss: 0.5508 - val_accuracy: 0.7260\n",
      "Epoch 181/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7690 - val_loss: 0.5504 - val_accuracy: 0.7263\n",
      "Epoch 182/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7687 - val_loss: 0.5500 - val_accuracy: 0.7264\n",
      "Epoch 183/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4914 - accuracy: 0.7686 - val_loss: 0.5509 - val_accuracy: 0.7252\n",
      "Epoch 184/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7682 - val_loss: 0.5509 - val_accuracy: 0.7248\n",
      "Epoch 185/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7691 - val_loss: 0.5498 - val_accuracy: 0.7243\n",
      "Epoch 186/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7689 - val_loss: 0.5501 - val_accuracy: 0.7261\n",
      "Epoch 187/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7693 - val_loss: 0.5504 - val_accuracy: 0.7250\n",
      "Epoch 188/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7684 - val_loss: 0.5497 - val_accuracy: 0.7254\n",
      "Epoch 189/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7687 - val_loss: 0.5499 - val_accuracy: 0.7252\n",
      "Epoch 190/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7686 - val_loss: 0.5509 - val_accuracy: 0.7245\n",
      "Epoch 191/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7687 - val_loss: 0.5508 - val_accuracy: 0.7258\n",
      "Epoch 192/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4913 - accuracy: 0.7685 - val_loss: 0.5512 - val_accuracy: 0.7259\n",
      "Epoch 193/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4913 - accuracy: 0.7687 - val_loss: 0.5497 - val_accuracy: 0.7248\n",
      "Epoch 194/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4913 - accuracy: 0.7687 - val_loss: 0.5506 - val_accuracy: 0.7242\n",
      "Epoch 195/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4913 - accuracy: 0.7687 - val_loss: 0.5496 - val_accuracy: 0.7251\n",
      "Epoch 196/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4913 - accuracy: 0.7689 - val_loss: 0.5507 - val_accuracy: 0.7240\n",
      "Epoch 197/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4912 - accuracy: 0.7688 - val_loss: 0.5505 - val_accuracy: 0.7244\n",
      "Epoch 198/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4913 - accuracy: 0.7684 - val_loss: 0.5506 - val_accuracy: 0.7254\n",
      "Epoch 199/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4913 - accuracy: 0.7683 - val_loss: 0.5508 - val_accuracy: 0.7247\n",
      "Epoch 200/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4913 - accuracy: 0.7689 - val_loss: 0.5498 - val_accuracy: 0.7249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:127: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Train on 6400 samples, validate on 1601 samples\n",
      "Epoch 1/200\n",
      "6400/6400 [==============================] - 0s 49us/step - loss: 0.6478 - accuracy: 0.6674 - val_loss: 0.6129 - val_accuracy: 0.7206\n",
      "Epoch 2/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5536 - accuracy: 0.7659 - val_loss: 0.5834 - val_accuracy: 0.7257\n",
      "Epoch 3/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5365 - accuracy: 0.7660 - val_loss: 0.5788 - val_accuracy: 0.7257\n",
      "Epoch 4/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5337 - accuracy: 0.7660 - val_loss: 0.5778 - val_accuracy: 0.7257\n",
      "Epoch 5/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5320 - accuracy: 0.7660 - val_loss: 0.5760 - val_accuracy: 0.7257\n",
      "Epoch 6/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5307 - accuracy: 0.7660 - val_loss: 0.5747 - val_accuracy: 0.7257\n",
      "Epoch 7/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5296 - accuracy: 0.7660 - val_loss: 0.5748 - val_accuracy: 0.7257\n",
      "Epoch 8/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5286 - accuracy: 0.7660 - val_loss: 0.5736 - val_accuracy: 0.7257\n",
      "Epoch 9/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5274 - accuracy: 0.7660 - val_loss: 0.5725 - val_accuracy: 0.7257\n",
      "Epoch 10/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5263 - accuracy: 0.7660 - val_loss: 0.5713 - val_accuracy: 0.7257\n",
      "Epoch 11/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5251 - accuracy: 0.7660 - val_loss: 0.5714 - val_accuracy: 0.7257\n",
      "Epoch 12/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5238 - accuracy: 0.7660 - val_loss: 0.5695 - val_accuracy: 0.7257\n",
      "Epoch 13/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5222 - accuracy: 0.7660 - val_loss: 0.5682 - val_accuracy: 0.7257\n",
      "Epoch 14/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5205 - accuracy: 0.7660 - val_loss: 0.5658 - val_accuracy: 0.7257\n",
      "Epoch 15/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5188 - accuracy: 0.7660 - val_loss: 0.5653 - val_accuracy: 0.7256\n",
      "Epoch 16/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5169 - accuracy: 0.7659 - val_loss: 0.5647 - val_accuracy: 0.7258\n",
      "Epoch 17/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5152 - accuracy: 0.7660 - val_loss: 0.5629 - val_accuracy: 0.7254\n",
      "Epoch 18/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5136 - accuracy: 0.7660 - val_loss: 0.5613 - val_accuracy: 0.7258\n",
      "Epoch 19/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5122 - accuracy: 0.7659 - val_loss: 0.5616 - val_accuracy: 0.7259\n",
      "Epoch 20/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5110 - accuracy: 0.7659 - val_loss: 0.5611 - val_accuracy: 0.7262\n",
      "Epoch 21/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5098 - accuracy: 0.7660 - val_loss: 0.5598 - val_accuracy: 0.7258\n",
      "Epoch 22/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5086 - accuracy: 0.7657 - val_loss: 0.5596 - val_accuracy: 0.7259\n",
      "Epoch 23/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5075 - accuracy: 0.7657 - val_loss: 0.5579 - val_accuracy: 0.7257\n",
      "Epoch 24/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5065 - accuracy: 0.7659 - val_loss: 0.5576 - val_accuracy: 0.7251\n",
      "Epoch 25/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5057 - accuracy: 0.7657 - val_loss: 0.5564 - val_accuracy: 0.7259\n",
      "Epoch 26/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5049 - accuracy: 0.7657 - val_loss: 0.5574 - val_accuracy: 0.7260\n",
      "Epoch 27/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5043 - accuracy: 0.7654 - val_loss: 0.5561 - val_accuracy: 0.7259\n",
      "Epoch 28/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5038 - accuracy: 0.7658 - val_loss: 0.5565 - val_accuracy: 0.7252\n",
      "Epoch 29/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5034 - accuracy: 0.7655 - val_loss: 0.5562 - val_accuracy: 0.7258\n",
      "Epoch 30/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5031 - accuracy: 0.7657 - val_loss: 0.5561 - val_accuracy: 0.7252\n",
      "Epoch 31/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5028 - accuracy: 0.7655 - val_loss: 0.5564 - val_accuracy: 0.7257\n",
      "Epoch 32/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5025 - accuracy: 0.7656 - val_loss: 0.5552 - val_accuracy: 0.7249\n",
      "Epoch 33/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5023 - accuracy: 0.7658 - val_loss: 0.5547 - val_accuracy: 0.7249\n",
      "Epoch 34/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5020 - accuracy: 0.7653 - val_loss: 0.5557 - val_accuracy: 0.7254\n",
      "Epoch 35/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5018 - accuracy: 0.7654 - val_loss: 0.5546 - val_accuracy: 0.7248\n",
      "Epoch 36/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5016 - accuracy: 0.7652 - val_loss: 0.5548 - val_accuracy: 0.7250\n",
      "Epoch 37/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5013 - accuracy: 0.7655 - val_loss: 0.5535 - val_accuracy: 0.7249\n",
      "Epoch 38/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5011 - accuracy: 0.7655 - val_loss: 0.5552 - val_accuracy: 0.7252\n",
      "Epoch 39/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5008 - accuracy: 0.7656 - val_loss: 0.5539 - val_accuracy: 0.7254\n",
      "Epoch 40/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5005 - accuracy: 0.7657 - val_loss: 0.5538 - val_accuracy: 0.7250\n",
      "Epoch 41/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5001 - accuracy: 0.7652 - val_loss: 0.5543 - val_accuracy: 0.7250\n",
      "Epoch 42/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4998 - accuracy: 0.7654 - val_loss: 0.5532 - val_accuracy: 0.7255\n",
      "Epoch 43/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4994 - accuracy: 0.7654 - val_loss: 0.5526 - val_accuracy: 0.7253\n",
      "Epoch 44/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4990 - accuracy: 0.7656 - val_loss: 0.5525 - val_accuracy: 0.7262\n",
      "Epoch 45/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4983 - accuracy: 0.7658 - val_loss: 0.5525 - val_accuracy: 0.7252\n",
      "Epoch 46/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4978 - accuracy: 0.7656 - val_loss: 0.5513 - val_accuracy: 0.7257\n",
      "Epoch 47/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4973 - accuracy: 0.7656 - val_loss: 0.5505 - val_accuracy: 0.7251\n",
      "Epoch 48/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4967 - accuracy: 0.7654 - val_loss: 0.5505 - val_accuracy: 0.7258\n",
      "Epoch 49/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4962 - accuracy: 0.7653 - val_loss: 0.5492 - val_accuracy: 0.7255\n",
      "Epoch 50/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4957 - accuracy: 0.7657 - val_loss: 0.5512 - val_accuracy: 0.7253\n",
      "Epoch 51/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4954 - accuracy: 0.7659 - val_loss: 0.5498 - val_accuracy: 0.7250\n",
      "Epoch 52/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4951 - accuracy: 0.7655 - val_loss: 0.5496 - val_accuracy: 0.7259\n",
      "Epoch 53/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4947 - accuracy: 0.7655 - val_loss: 0.5497 - val_accuracy: 0.7250\n",
      "Epoch 54/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4944 - accuracy: 0.7658 - val_loss: 0.5494 - val_accuracy: 0.7243\n",
      "Epoch 55/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4942 - accuracy: 0.7654 - val_loss: 0.5495 - val_accuracy: 0.7252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4940 - accuracy: 0.7654 - val_loss: 0.5488 - val_accuracy: 0.7254\n",
      "Epoch 57/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4937 - accuracy: 0.7658 - val_loss: 0.5483 - val_accuracy: 0.7237\n",
      "Epoch 58/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4936 - accuracy: 0.7659 - val_loss: 0.5490 - val_accuracy: 0.7244\n",
      "Epoch 59/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4934 - accuracy: 0.7650 - val_loss: 0.5499 - val_accuracy: 0.7255\n",
      "Epoch 60/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4935 - accuracy: 0.7658 - val_loss: 0.5493 - val_accuracy: 0.7263\n",
      "Epoch 61/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4932 - accuracy: 0.7652 - val_loss: 0.5486 - val_accuracy: 0.7242\n",
      "Epoch 62/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4932 - accuracy: 0.7659 - val_loss: 0.5493 - val_accuracy: 0.7247\n",
      "Epoch 63/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4931 - accuracy: 0.7656 - val_loss: 0.5486 - val_accuracy: 0.7257\n",
      "Epoch 64/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4931 - accuracy: 0.7656 - val_loss: 0.5481 - val_accuracy: 0.7242\n",
      "Epoch 65/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4930 - accuracy: 0.7663 - val_loss: 0.5488 - val_accuracy: 0.7248\n",
      "Epoch 66/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4929 - accuracy: 0.7662 - val_loss: 0.5503 - val_accuracy: 0.7258\n",
      "Epoch 67/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4929 - accuracy: 0.7658 - val_loss: 0.5494 - val_accuracy: 0.7250\n",
      "Epoch 68/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4928 - accuracy: 0.7659 - val_loss: 0.5495 - val_accuracy: 0.7244\n",
      "Epoch 69/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4927 - accuracy: 0.7666 - val_loss: 0.5498 - val_accuracy: 0.7240\n",
      "Epoch 70/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4926 - accuracy: 0.7667 - val_loss: 0.5488 - val_accuracy: 0.7255\n",
      "Epoch 71/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4926 - accuracy: 0.7659 - val_loss: 0.5491 - val_accuracy: 0.7248\n",
      "Epoch 72/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4926 - accuracy: 0.7663 - val_loss: 0.5495 - val_accuracy: 0.7248\n",
      "Epoch 73/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4925 - accuracy: 0.7659 - val_loss: 0.5498 - val_accuracy: 0.7247\n",
      "Epoch 74/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4924 - accuracy: 0.7662 - val_loss: 0.5501 - val_accuracy: 0.7256\n",
      "Epoch 75/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4924 - accuracy: 0.7666 - val_loss: 0.5491 - val_accuracy: 0.7251\n",
      "Epoch 76/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4924 - accuracy: 0.7661 - val_loss: 0.5487 - val_accuracy: 0.7253\n",
      "Epoch 77/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4923 - accuracy: 0.7662 - val_loss: 0.5491 - val_accuracy: 0.7244\n",
      "Epoch 78/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4923 - accuracy: 0.7666 - val_loss: 0.5488 - val_accuracy: 0.7256\n",
      "Epoch 79/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4922 - accuracy: 0.7663 - val_loss: 0.5491 - val_accuracy: 0.7255\n",
      "Epoch 80/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4922 - accuracy: 0.7662 - val_loss: 0.5491 - val_accuracy: 0.7256\n",
      "Epoch 81/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4921 - accuracy: 0.7666 - val_loss: 0.5493 - val_accuracy: 0.7251\n",
      "Epoch 82/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4921 - accuracy: 0.7668 - val_loss: 0.5492 - val_accuracy: 0.7263\n",
      "Epoch 83/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4921 - accuracy: 0.7665 - val_loss: 0.5486 - val_accuracy: 0.7250\n",
      "Epoch 84/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4920 - accuracy: 0.7670 - val_loss: 0.5489 - val_accuracy: 0.7259\n",
      "Epoch 85/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4919 - accuracy: 0.7662 - val_loss: 0.5497 - val_accuracy: 0.7250\n",
      "Epoch 86/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4919 - accuracy: 0.7667 - val_loss: 0.5499 - val_accuracy: 0.7254\n",
      "Epoch 87/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4919 - accuracy: 0.7664 - val_loss: 0.5493 - val_accuracy: 0.7240\n",
      "Epoch 88/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4919 - accuracy: 0.7670 - val_loss: 0.5498 - val_accuracy: 0.7254\n",
      "Epoch 89/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4918 - accuracy: 0.7667 - val_loss: 0.5500 - val_accuracy: 0.7254\n",
      "Epoch 90/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4918 - accuracy: 0.7668 - val_loss: 0.5498 - val_accuracy: 0.7259\n",
      "Epoch 91/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4916 - accuracy: 0.7669 - val_loss: 0.5492 - val_accuracy: 0.7260\n",
      "Epoch 92/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4916 - accuracy: 0.7670 - val_loss: 0.5498 - val_accuracy: 0.7258\n",
      "Epoch 93/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4917 - accuracy: 0.7672 - val_loss: 0.5492 - val_accuracy: 0.7247\n",
      "Epoch 94/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4916 - accuracy: 0.7668 - val_loss: 0.5498 - val_accuracy: 0.7257\n",
      "Epoch 95/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7673 - val_loss: 0.5496 - val_accuracy: 0.7250\n",
      "Epoch 96/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4917 - accuracy: 0.7678 - val_loss: 0.5486 - val_accuracy: 0.7263\n",
      "Epoch 97/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4916 - accuracy: 0.7670 - val_loss: 0.5505 - val_accuracy: 0.7263\n",
      "Epoch 98/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7671 - val_loss: 0.5499 - val_accuracy: 0.7259\n",
      "Epoch 99/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7674 - val_loss: 0.5490 - val_accuracy: 0.7264\n",
      "Epoch 100/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7671 - val_loss: 0.5499 - val_accuracy: 0.7251\n",
      "Epoch 101/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7673 - val_loss: 0.5508 - val_accuracy: 0.7249\n",
      "Epoch 102/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7670 - val_loss: 0.5494 - val_accuracy: 0.7241\n",
      "Epoch 103/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4913 - accuracy: 0.7674 - val_loss: 0.5496 - val_accuracy: 0.7256\n",
      "Epoch 104/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4914 - accuracy: 0.7676 - val_loss: 0.5503 - val_accuracy: 0.7256\n",
      "Epoch 105/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4914 - accuracy: 0.7677 - val_loss: 0.5496 - val_accuracy: 0.7257\n",
      "Epoch 106/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4913 - accuracy: 0.7674 - val_loss: 0.5498 - val_accuracy: 0.7252\n",
      "Epoch 107/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4913 - accuracy: 0.7672 - val_loss: 0.5504 - val_accuracy: 0.7264\n",
      "Epoch 108/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4912 - accuracy: 0.7680 - val_loss: 0.5497 - val_accuracy: 0.7265\n",
      "Epoch 109/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4912 - accuracy: 0.7669 - val_loss: 0.5492 - val_accuracy: 0.7247\n",
      "Epoch 110/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4912 - accuracy: 0.7680 - val_loss: 0.5489 - val_accuracy: 0.7250\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4912 - accuracy: 0.7672 - val_loss: 0.5496 - val_accuracy: 0.7247\n",
      "Epoch 112/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4911 - accuracy: 0.7679 - val_loss: 0.5494 - val_accuracy: 0.7251\n",
      "Epoch 113/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4910 - accuracy: 0.7676 - val_loss: 0.5492 - val_accuracy: 0.7258\n",
      "Epoch 114/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4911 - accuracy: 0.7676 - val_loss: 0.5492 - val_accuracy: 0.7250\n",
      "Epoch 115/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4910 - accuracy: 0.7681 - val_loss: 0.5496 - val_accuracy: 0.7250\n",
      "Epoch 116/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4909 - accuracy: 0.7681 - val_loss: 0.5486 - val_accuracy: 0.7259\n",
      "Epoch 117/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4911 - accuracy: 0.7677 - val_loss: 0.5491 - val_accuracy: 0.7255\n",
      "Epoch 118/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4909 - accuracy: 0.7679 - val_loss: 0.5494 - val_accuracy: 0.7259\n",
      "Epoch 119/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4910 - accuracy: 0.7677 - val_loss: 0.5506 - val_accuracy: 0.7267\n",
      "Epoch 120/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4909 - accuracy: 0.7677 - val_loss: 0.5501 - val_accuracy: 0.7263\n",
      "Epoch 121/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4910 - accuracy: 0.7679 - val_loss: 0.5499 - val_accuracy: 0.7254\n",
      "Epoch 122/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4908 - accuracy: 0.7679 - val_loss: 0.5497 - val_accuracy: 0.7261\n",
      "Epoch 123/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4908 - accuracy: 0.7682 - val_loss: 0.5500 - val_accuracy: 0.7261\n",
      "Epoch 124/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4908 - accuracy: 0.7683 - val_loss: 0.5504 - val_accuracy: 0.7253\n",
      "Epoch 125/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4908 - accuracy: 0.7681 - val_loss: 0.5489 - val_accuracy: 0.7262\n",
      "Epoch 126/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4908 - accuracy: 0.7681 - val_loss: 0.5490 - val_accuracy: 0.7254\n",
      "Epoch 127/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4908 - accuracy: 0.7677 - val_loss: 0.5496 - val_accuracy: 0.7262\n",
      "Epoch 128/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4907 - accuracy: 0.7681 - val_loss: 0.5507 - val_accuracy: 0.7258\n",
      "Epoch 129/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4908 - accuracy: 0.7684 - val_loss: 0.5500 - val_accuracy: 0.7264\n",
      "Epoch 130/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4907 - accuracy: 0.7679 - val_loss: 0.5507 - val_accuracy: 0.7254\n",
      "Epoch 131/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4906 - accuracy: 0.7678 - val_loss: 0.5492 - val_accuracy: 0.7262\n",
      "Epoch 132/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4907 - accuracy: 0.7683 - val_loss: 0.5496 - val_accuracy: 0.7263\n",
      "Epoch 133/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4906 - accuracy: 0.7683 - val_loss: 0.5500 - val_accuracy: 0.7262\n",
      "Epoch 134/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4905 - accuracy: 0.7678 - val_loss: 0.5511 - val_accuracy: 0.7268\n",
      "Epoch 135/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4906 - accuracy: 0.7687 - val_loss: 0.5502 - val_accuracy: 0.7262\n",
      "Epoch 136/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4905 - accuracy: 0.7682 - val_loss: 0.5508 - val_accuracy: 0.7259\n",
      "Epoch 137/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4906 - accuracy: 0.7685 - val_loss: 0.5497 - val_accuracy: 0.7253\n",
      "Epoch 138/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4905 - accuracy: 0.7683 - val_loss: 0.5503 - val_accuracy: 0.7267\n",
      "Epoch 139/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4905 - accuracy: 0.7687 - val_loss: 0.5504 - val_accuracy: 0.7258\n",
      "Epoch 140/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4905 - accuracy: 0.7683 - val_loss: 0.5512 - val_accuracy: 0.7254\n",
      "Epoch 141/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4905 - accuracy: 0.7683 - val_loss: 0.5498 - val_accuracy: 0.7256\n",
      "Epoch 142/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4905 - accuracy: 0.7685 - val_loss: 0.5505 - val_accuracy: 0.7257\n",
      "Epoch 143/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4904 - accuracy: 0.7684 - val_loss: 0.5514 - val_accuracy: 0.7256\n",
      "Epoch 144/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4904 - accuracy: 0.7687 - val_loss: 0.5499 - val_accuracy: 0.7256\n",
      "Epoch 145/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4904 - accuracy: 0.7684 - val_loss: 0.5501 - val_accuracy: 0.7255\n",
      "Epoch 146/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4904 - accuracy: 0.7684 - val_loss: 0.5499 - val_accuracy: 0.7250\n",
      "Epoch 147/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4904 - accuracy: 0.7683 - val_loss: 0.5497 - val_accuracy: 0.7269\n",
      "Epoch 148/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4904 - accuracy: 0.7687 - val_loss: 0.5493 - val_accuracy: 0.7259\n",
      "Epoch 149/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4903 - accuracy: 0.7682 - val_loss: 0.5495 - val_accuracy: 0.7256\n",
      "Epoch 150/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4903 - accuracy: 0.7686 - val_loss: 0.5516 - val_accuracy: 0.7259\n",
      "Epoch 151/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4903 - accuracy: 0.7687 - val_loss: 0.5501 - val_accuracy: 0.7256\n",
      "Epoch 152/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4903 - accuracy: 0.7684 - val_loss: 0.5490 - val_accuracy: 0.7256\n",
      "Epoch 153/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4902 - accuracy: 0.7681 - val_loss: 0.5502 - val_accuracy: 0.7255\n",
      "Epoch 154/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4902 - accuracy: 0.7686 - val_loss: 0.5500 - val_accuracy: 0.7249\n",
      "Epoch 155/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4902 - accuracy: 0.7687 - val_loss: 0.5495 - val_accuracy: 0.7263\n",
      "Epoch 156/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4902 - accuracy: 0.7683 - val_loss: 0.5498 - val_accuracy: 0.7265\n",
      "Epoch 157/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4902 - accuracy: 0.7690 - val_loss: 0.5496 - val_accuracy: 0.7260\n",
      "Epoch 158/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4902 - accuracy: 0.7686 - val_loss: 0.5501 - val_accuracy: 0.7257\n",
      "Epoch 159/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4902 - accuracy: 0.7688 - val_loss: 0.5502 - val_accuracy: 0.7258\n",
      "Epoch 160/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4902 - accuracy: 0.7688 - val_loss: 0.5495 - val_accuracy: 0.7257\n",
      "Epoch 161/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4902 - accuracy: 0.7687 - val_loss: 0.5512 - val_accuracy: 0.7256\n",
      "Epoch 162/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4902 - accuracy: 0.7689 - val_loss: 0.5502 - val_accuracy: 0.7254\n",
      "Epoch 163/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4901 - accuracy: 0.7687 - val_loss: 0.5498 - val_accuracy: 0.7258\n",
      "Epoch 164/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4901 - accuracy: 0.7684 - val_loss: 0.5506 - val_accuracy: 0.7259\n",
      "Epoch 165/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4901 - accuracy: 0.7693 - val_loss: 0.5503 - val_accuracy: 0.7261\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4900 - accuracy: 0.7692 - val_loss: 0.5499 - val_accuracy: 0.7254\n",
      "Epoch 167/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4900 - accuracy: 0.7691 - val_loss: 0.5498 - val_accuracy: 0.7255\n",
      "Epoch 168/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4900 - accuracy: 0.7690 - val_loss: 0.5499 - val_accuracy: 0.7254\n",
      "Epoch 169/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4900 - accuracy: 0.7688 - val_loss: 0.5501 - val_accuracy: 0.7258\n",
      "Epoch 170/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4900 - accuracy: 0.7692 - val_loss: 0.5503 - val_accuracy: 0.7267\n",
      "Epoch 171/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4900 - accuracy: 0.7690 - val_loss: 0.5508 - val_accuracy: 0.7256\n",
      "Epoch 172/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4900 - accuracy: 0.7681 - val_loss: 0.5496 - val_accuracy: 0.7262\n",
      "Epoch 173/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4901 - accuracy: 0.7689 - val_loss: 0.5503 - val_accuracy: 0.7260\n",
      "Epoch 174/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7693 - val_loss: 0.5494 - val_accuracy: 0.7263\n",
      "Epoch 175/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4900 - accuracy: 0.7687 - val_loss: 0.5502 - val_accuracy: 0.7264\n",
      "Epoch 176/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4900 - accuracy: 0.7689 - val_loss: 0.5498 - val_accuracy: 0.7262\n",
      "Epoch 177/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7690 - val_loss: 0.5493 - val_accuracy: 0.7262\n",
      "Epoch 178/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7694 - val_loss: 0.5508 - val_accuracy: 0.7262\n",
      "Epoch 179/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7692 - val_loss: 0.5499 - val_accuracy: 0.7263\n",
      "Epoch 180/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7686 - val_loss: 0.5502 - val_accuracy: 0.7265\n",
      "Epoch 181/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7692 - val_loss: 0.5489 - val_accuracy: 0.7267\n",
      "Epoch 182/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7690 - val_loss: 0.5501 - val_accuracy: 0.7266\n",
      "Epoch 183/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7689 - val_loss: 0.5492 - val_accuracy: 0.7265\n",
      "Epoch 184/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7691 - val_loss: 0.5504 - val_accuracy: 0.7263\n",
      "Epoch 185/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7688 - val_loss: 0.5506 - val_accuracy: 0.7261\n",
      "Epoch 186/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7688 - val_loss: 0.5504 - val_accuracy: 0.7260\n",
      "Epoch 187/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7690 - val_loss: 0.5485 - val_accuracy: 0.7270\n",
      "Epoch 188/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7686 - val_loss: 0.5505 - val_accuracy: 0.7264\n",
      "Epoch 189/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4897 - accuracy: 0.7686 - val_loss: 0.5497 - val_accuracy: 0.7265\n",
      "Epoch 190/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7688 - val_loss: 0.5510 - val_accuracy: 0.7258\n",
      "Epoch 191/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7689 - val_loss: 0.5503 - val_accuracy: 0.7267\n",
      "Epoch 192/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7693 - val_loss: 0.5502 - val_accuracy: 0.7261\n",
      "Epoch 193/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7687 - val_loss: 0.5502 - val_accuracy: 0.7267\n",
      "Epoch 194/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7693 - val_loss: 0.5497 - val_accuracy: 0.7255\n",
      "Epoch 195/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7690 - val_loss: 0.5516 - val_accuracy: 0.7255\n",
      "Epoch 196/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7693 - val_loss: 0.5500 - val_accuracy: 0.7265\n",
      "Epoch 197/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4897 - accuracy: 0.7690 - val_loss: 0.5493 - val_accuracy: 0.7264\n",
      "Epoch 198/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4897 - accuracy: 0.7697 - val_loss: 0.5508 - val_accuracy: 0.7259\n",
      "Epoch 199/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4898 - accuracy: 0.7687 - val_loss: 0.5498 - val_accuracy: 0.7272\n",
      "Epoch 200/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4897 - accuracy: 0.7693 - val_loss: 0.5508 - val_accuracy: 0.7272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:127: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Train on 6400 samples, validate on 1601 samples\n",
      "Epoch 1/200\n",
      "6400/6400 [==============================] - 0s 48us/step - loss: 0.6204 - accuracy: 0.6986 - val_loss: 0.5931 - val_accuracy: 0.7258\n",
      "Epoch 2/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5394 - accuracy: 0.7665 - val_loss: 0.5806 - val_accuracy: 0.7258\n",
      "Epoch 3/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5320 - accuracy: 0.7665 - val_loss: 0.5772 - val_accuracy: 0.7258\n",
      "Epoch 4/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5299 - accuracy: 0.7665 - val_loss: 0.5758 - val_accuracy: 0.7258\n",
      "Epoch 5/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5284 - accuracy: 0.7665 - val_loss: 0.5750 - val_accuracy: 0.7258\n",
      "Epoch 6/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5269 - accuracy: 0.7665 - val_loss: 0.5724 - val_accuracy: 0.7258\n",
      "Epoch 7/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5255 - accuracy: 0.7665 - val_loss: 0.5725 - val_accuracy: 0.7258\n",
      "Epoch 8/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5241 - accuracy: 0.7665 - val_loss: 0.5703 - val_accuracy: 0.7258\n",
      "Epoch 9/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5225 - accuracy: 0.7665 - val_loss: 0.5691 - val_accuracy: 0.7258\n",
      "Epoch 10/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5209 - accuracy: 0.7665 - val_loss: 0.5673 - val_accuracy: 0.7258\n",
      "Epoch 11/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5190 - accuracy: 0.7665 - val_loss: 0.5663 - val_accuracy: 0.7258\n",
      "Epoch 12/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5170 - accuracy: 0.7665 - val_loss: 0.5643 - val_accuracy: 0.7258\n",
      "Epoch 13/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5147 - accuracy: 0.7665 - val_loss: 0.5625 - val_accuracy: 0.7258\n",
      "Epoch 14/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5125 - accuracy: 0.7665 - val_loss: 0.5602 - val_accuracy: 0.7259\n",
      "Epoch 15/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5101 - accuracy: 0.7666 - val_loss: 0.5589 - val_accuracy: 0.7257\n",
      "Epoch 16/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5079 - accuracy: 0.7665 - val_loss: 0.5569 - val_accuracy: 0.7256\n",
      "Epoch 17/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5058 - accuracy: 0.7666 - val_loss: 0.5556 - val_accuracy: 0.7256\n",
      "Epoch 18/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5038 - accuracy: 0.7667 - val_loss: 0.5544 - val_accuracy: 0.7257\n",
      "Epoch 19/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5022 - accuracy: 0.7666 - val_loss: 0.5540 - val_accuracy: 0.7264\n",
      "Epoch 20/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5006 - accuracy: 0.7664 - val_loss: 0.5536 - val_accuracy: 0.7266\n",
      "Epoch 21/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4994 - accuracy: 0.7666 - val_loss: 0.5524 - val_accuracy: 0.7265\n",
      "Epoch 22/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4983 - accuracy: 0.7664 - val_loss: 0.5507 - val_accuracy: 0.7263\n",
      "Epoch 23/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4974 - accuracy: 0.7665 - val_loss: 0.5510 - val_accuracy: 0.7263\n",
      "Epoch 24/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4967 - accuracy: 0.7666 - val_loss: 0.5506 - val_accuracy: 0.7259\n",
      "Epoch 25/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4960 - accuracy: 0.7666 - val_loss: 0.5504 - val_accuracy: 0.7262\n",
      "Epoch 26/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4955 - accuracy: 0.7664 - val_loss: 0.5507 - val_accuracy: 0.7253\n",
      "Epoch 27/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4950 - accuracy: 0.7665 - val_loss: 0.5504 - val_accuracy: 0.7252\n",
      "Epoch 28/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4946 - accuracy: 0.7664 - val_loss: 0.5495 - val_accuracy: 0.7249\n",
      "Epoch 29/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4942 - accuracy: 0.7664 - val_loss: 0.5496 - val_accuracy: 0.7255\n",
      "Epoch 30/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4939 - accuracy: 0.7662 - val_loss: 0.5491 - val_accuracy: 0.7254\n",
      "Epoch 31/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4937 - accuracy: 0.7663 - val_loss: 0.5503 - val_accuracy: 0.7250\n",
      "Epoch 32/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4934 - accuracy: 0.7669 - val_loss: 0.5495 - val_accuracy: 0.7244\n",
      "Epoch 33/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4932 - accuracy: 0.7668 - val_loss: 0.5487 - val_accuracy: 0.7249\n",
      "Epoch 34/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4930 - accuracy: 0.7671 - val_loss: 0.5495 - val_accuracy: 0.7243\n",
      "Epoch 35/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4928 - accuracy: 0.7667 - val_loss: 0.5496 - val_accuracy: 0.7250\n",
      "Epoch 36/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4928 - accuracy: 0.7666 - val_loss: 0.5491 - val_accuracy: 0.7254\n",
      "Epoch 37/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4927 - accuracy: 0.7667 - val_loss: 0.5488 - val_accuracy: 0.7250\n",
      "Epoch 38/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4926 - accuracy: 0.7667 - val_loss: 0.5499 - val_accuracy: 0.7250\n",
      "Epoch 39/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4925 - accuracy: 0.7660 - val_loss: 0.5496 - val_accuracy: 0.7238\n",
      "Epoch 40/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4923 - accuracy: 0.7668 - val_loss: 0.5504 - val_accuracy: 0.7253\n",
      "Epoch 41/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4922 - accuracy: 0.7667 - val_loss: 0.5500 - val_accuracy: 0.7251\n",
      "Epoch 42/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4922 - accuracy: 0.7667 - val_loss: 0.5496 - val_accuracy: 0.7255\n",
      "Epoch 43/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4921 - accuracy: 0.7661 - val_loss: 0.5483 - val_accuracy: 0.7260\n",
      "Epoch 44/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4920 - accuracy: 0.7665 - val_loss: 0.5502 - val_accuracy: 0.7253\n",
      "Epoch 45/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4919 - accuracy: 0.7662 - val_loss: 0.5487 - val_accuracy: 0.7260\n",
      "Epoch 46/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4919 - accuracy: 0.7666 - val_loss: 0.5491 - val_accuracy: 0.7248\n",
      "Epoch 47/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4919 - accuracy: 0.7664 - val_loss: 0.5497 - val_accuracy: 0.7246\n",
      "Epoch 48/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4918 - accuracy: 0.7662 - val_loss: 0.5491 - val_accuracy: 0.7254\n",
      "Epoch 49/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4917 - accuracy: 0.7668 - val_loss: 0.5495 - val_accuracy: 0.7256\n",
      "Epoch 50/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4917 - accuracy: 0.7664 - val_loss: 0.5485 - val_accuracy: 0.7249\n",
      "Epoch 51/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4916 - accuracy: 0.7663 - val_loss: 0.5482 - val_accuracy: 0.7254\n",
      "Epoch 52/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7668 - val_loss: 0.5502 - val_accuracy: 0.7258\n",
      "Epoch 53/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7670 - val_loss: 0.5497 - val_accuracy: 0.7254\n",
      "Epoch 54/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7672 - val_loss: 0.5479 - val_accuracy: 0.7264\n",
      "Epoch 55/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7672 - val_loss: 0.5490 - val_accuracy: 0.7253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7664 - val_loss: 0.5484 - val_accuracy: 0.7259\n",
      "Epoch 57/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4913 - accuracy: 0.7664 - val_loss: 0.5483 - val_accuracy: 0.7261\n",
      "Epoch 58/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4912 - accuracy: 0.7669 - val_loss: 0.5485 - val_accuracy: 0.7250\n",
      "Epoch 59/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4912 - accuracy: 0.7665 - val_loss: 0.5484 - val_accuracy: 0.7251\n",
      "Epoch 60/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4912 - accuracy: 0.7668 - val_loss: 0.5488 - val_accuracy: 0.7263\n",
      "Epoch 61/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4911 - accuracy: 0.7669 - val_loss: 0.5495 - val_accuracy: 0.7251\n",
      "Epoch 62/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4911 - accuracy: 0.7670 - val_loss: 0.5488 - val_accuracy: 0.7265\n",
      "Epoch 63/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4911 - accuracy: 0.7673 - val_loss: 0.5491 - val_accuracy: 0.7242\n",
      "Epoch 64/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4910 - accuracy: 0.7667 - val_loss: 0.5490 - val_accuracy: 0.7251\n",
      "Epoch 65/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4909 - accuracy: 0.7673 - val_loss: 0.5492 - val_accuracy: 0.7253\n",
      "Epoch 66/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4910 - accuracy: 0.7673 - val_loss: 0.5485 - val_accuracy: 0.7253\n",
      "Epoch 67/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4908 - accuracy: 0.7671 - val_loss: 0.5490 - val_accuracy: 0.7253\n",
      "Epoch 68/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4909 - accuracy: 0.7670 - val_loss: 0.5493 - val_accuracy: 0.7255\n",
      "Epoch 69/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4908 - accuracy: 0.7675 - val_loss: 0.5493 - val_accuracy: 0.7253\n",
      "Epoch 70/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4908 - accuracy: 0.7670 - val_loss: 0.5487 - val_accuracy: 0.7245\n",
      "Epoch 71/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4908 - accuracy: 0.7672 - val_loss: 0.5482 - val_accuracy: 0.7250\n",
      "Epoch 72/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4908 - accuracy: 0.7672 - val_loss: 0.5494 - val_accuracy: 0.7259\n",
      "Epoch 73/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4907 - accuracy: 0.7671 - val_loss: 0.5493 - val_accuracy: 0.7252\n",
      "Epoch 74/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4906 - accuracy: 0.7674 - val_loss: 0.5498 - val_accuracy: 0.7243\n",
      "Epoch 75/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4907 - accuracy: 0.7672 - val_loss: 0.5495 - val_accuracy: 0.7252\n",
      "Epoch 76/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4906 - accuracy: 0.7677 - val_loss: 0.5489 - val_accuracy: 0.7254\n",
      "Epoch 77/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4906 - accuracy: 0.7677 - val_loss: 0.5488 - val_accuracy: 0.7255\n",
      "Epoch 78/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4905 - accuracy: 0.7675 - val_loss: 0.5482 - val_accuracy: 0.7249\n",
      "Epoch 79/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4905 - accuracy: 0.7677 - val_loss: 0.5510 - val_accuracy: 0.7263\n",
      "Epoch 80/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4905 - accuracy: 0.7679 - val_loss: 0.5499 - val_accuracy: 0.7245\n",
      "Epoch 81/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4904 - accuracy: 0.7675 - val_loss: 0.5491 - val_accuracy: 0.7243\n",
      "Epoch 82/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4904 - accuracy: 0.7675 - val_loss: 0.5496 - val_accuracy: 0.7247\n",
      "Epoch 83/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4905 - accuracy: 0.7679 - val_loss: 0.5499 - val_accuracy: 0.7244\n",
      "Epoch 84/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4904 - accuracy: 0.7680 - val_loss: 0.5497 - val_accuracy: 0.7243\n",
      "Epoch 85/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4904 - accuracy: 0.7676 - val_loss: 0.5489 - val_accuracy: 0.7252\n",
      "Epoch 86/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4904 - accuracy: 0.7679 - val_loss: 0.5481 - val_accuracy: 0.7250\n",
      "Epoch 87/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4903 - accuracy: 0.7678 - val_loss: 0.5498 - val_accuracy: 0.7253\n",
      "Epoch 88/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4903 - accuracy: 0.7676 - val_loss: 0.5494 - val_accuracy: 0.7240\n",
      "Epoch 89/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4903 - accuracy: 0.7679 - val_loss: 0.5490 - val_accuracy: 0.7245\n",
      "Epoch 90/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4902 - accuracy: 0.7678 - val_loss: 0.5489 - val_accuracy: 0.7247\n",
      "Epoch 91/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4902 - accuracy: 0.7686 - val_loss: 0.5497 - val_accuracy: 0.7252\n",
      "Epoch 92/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4902 - accuracy: 0.7682 - val_loss: 0.5496 - val_accuracy: 0.7249\n",
      "Epoch 93/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4902 - accuracy: 0.7684 - val_loss: 0.5501 - val_accuracy: 0.7249\n",
      "Epoch 94/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4901 - accuracy: 0.7675 - val_loss: 0.5496 - val_accuracy: 0.7247\n",
      "Epoch 95/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4901 - accuracy: 0.7685 - val_loss: 0.5488 - val_accuracy: 0.7250\n",
      "Epoch 96/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4901 - accuracy: 0.7682 - val_loss: 0.5494 - val_accuracy: 0.7247\n",
      "Epoch 97/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4901 - accuracy: 0.7683 - val_loss: 0.5491 - val_accuracy: 0.7248\n",
      "Epoch 98/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4901 - accuracy: 0.7684 - val_loss: 0.5491 - val_accuracy: 0.7245\n",
      "Epoch 99/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4901 - accuracy: 0.7681 - val_loss: 0.5481 - val_accuracy: 0.7242\n",
      "Epoch 100/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4900 - accuracy: 0.7683 - val_loss: 0.5492 - val_accuracy: 0.7244\n",
      "Epoch 101/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4900 - accuracy: 0.7682 - val_loss: 0.5491 - val_accuracy: 0.7253\n",
      "Epoch 102/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7677 - val_loss: 0.5498 - val_accuracy: 0.7251\n",
      "Epoch 103/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7680 - val_loss: 0.5496 - val_accuracy: 0.7247\n",
      "Epoch 104/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7680 - val_loss: 0.5499 - val_accuracy: 0.7251\n",
      "Epoch 105/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7686 - val_loss: 0.5496 - val_accuracy: 0.7250\n",
      "Epoch 106/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7683 - val_loss: 0.5480 - val_accuracy: 0.7246\n",
      "Epoch 107/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7684 - val_loss: 0.5489 - val_accuracy: 0.7243\n",
      "Epoch 108/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7688 - val_loss: 0.5494 - val_accuracy: 0.7260\n",
      "Epoch 109/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4897 - accuracy: 0.7682 - val_loss: 0.5493 - val_accuracy: 0.7254\n",
      "Epoch 110/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7690 - val_loss: 0.5509 - val_accuracy: 0.7253\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7691 - val_loss: 0.5498 - val_accuracy: 0.7255\n",
      "Epoch 112/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4898 - accuracy: 0.7689 - val_loss: 0.5502 - val_accuracy: 0.7249\n",
      "Epoch 113/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7683 - val_loss: 0.5506 - val_accuracy: 0.7254\n",
      "Epoch 114/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7689 - val_loss: 0.5495 - val_accuracy: 0.7248\n",
      "Epoch 115/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4897 - accuracy: 0.7686 - val_loss: 0.5490 - val_accuracy: 0.7246\n",
      "Epoch 116/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4897 - accuracy: 0.7689 - val_loss: 0.5489 - val_accuracy: 0.7250\n",
      "Epoch 117/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7686 - val_loss: 0.5494 - val_accuracy: 0.7253\n",
      "Epoch 118/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4897 - accuracy: 0.7686 - val_loss: 0.5508 - val_accuracy: 0.7257\n",
      "Epoch 119/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4897 - accuracy: 0.7687 - val_loss: 0.5500 - val_accuracy: 0.7250\n",
      "Epoch 120/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4897 - accuracy: 0.7690 - val_loss: 0.5495 - val_accuracy: 0.7249\n",
      "Epoch 121/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4896 - accuracy: 0.7684 - val_loss: 0.5494 - val_accuracy: 0.7241\n",
      "Epoch 122/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4896 - accuracy: 0.7685 - val_loss: 0.5497 - val_accuracy: 0.7258\n",
      "Epoch 123/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4896 - accuracy: 0.7692 - val_loss: 0.5501 - val_accuracy: 0.7250\n",
      "Epoch 124/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4896 - accuracy: 0.7688 - val_loss: 0.5496 - val_accuracy: 0.7257\n",
      "Epoch 125/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4896 - accuracy: 0.7686 - val_loss: 0.5490 - val_accuracy: 0.7243\n",
      "Epoch 126/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4896 - accuracy: 0.7686 - val_loss: 0.5500 - val_accuracy: 0.7247\n",
      "Epoch 127/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4896 - accuracy: 0.7689 - val_loss: 0.5494 - val_accuracy: 0.7248\n",
      "Epoch 128/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4896 - accuracy: 0.7695 - val_loss: 0.5487 - val_accuracy: 0.7247\n",
      "Epoch 129/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4895 - accuracy: 0.7693 - val_loss: 0.5486 - val_accuracy: 0.7252\n",
      "Epoch 130/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4895 - accuracy: 0.7692 - val_loss: 0.5496 - val_accuracy: 0.7252\n",
      "Epoch 131/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4895 - accuracy: 0.7692 - val_loss: 0.5505 - val_accuracy: 0.7241\n",
      "Epoch 132/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4895 - accuracy: 0.7691 - val_loss: 0.5496 - val_accuracy: 0.7259\n",
      "Epoch 133/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4895 - accuracy: 0.7688 - val_loss: 0.5492 - val_accuracy: 0.7252\n",
      "Epoch 134/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4894 - accuracy: 0.7694 - val_loss: 0.5489 - val_accuracy: 0.7242\n",
      "Epoch 135/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4894 - accuracy: 0.7689 - val_loss: 0.5490 - val_accuracy: 0.7251\n",
      "Epoch 136/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4894 - accuracy: 0.7688 - val_loss: 0.5482 - val_accuracy: 0.7249\n",
      "Epoch 137/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4894 - accuracy: 0.7691 - val_loss: 0.5498 - val_accuracy: 0.7259\n",
      "Epoch 138/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4894 - accuracy: 0.7691 - val_loss: 0.5485 - val_accuracy: 0.7256\n",
      "Epoch 139/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4893 - accuracy: 0.7693 - val_loss: 0.5483 - val_accuracy: 0.7257\n",
      "Epoch 140/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4893 - accuracy: 0.7692 - val_loss: 0.5496 - val_accuracy: 0.7255\n",
      "Epoch 141/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4894 - accuracy: 0.7691 - val_loss: 0.5495 - val_accuracy: 0.7260\n",
      "Epoch 142/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4892 - accuracy: 0.7694 - val_loss: 0.5489 - val_accuracy: 0.7257\n",
      "Epoch 143/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4893 - accuracy: 0.7687 - val_loss: 0.5500 - val_accuracy: 0.7251\n",
      "Epoch 144/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4893 - accuracy: 0.7691 - val_loss: 0.5491 - val_accuracy: 0.7252\n",
      "Epoch 145/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4892 - accuracy: 0.7693 - val_loss: 0.5501 - val_accuracy: 0.7255\n",
      "Epoch 146/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4893 - accuracy: 0.7690 - val_loss: 0.5489 - val_accuracy: 0.7252\n",
      "Epoch 147/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4893 - accuracy: 0.7694 - val_loss: 0.5485 - val_accuracy: 0.7254\n",
      "Epoch 148/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4893 - accuracy: 0.7692 - val_loss: 0.5500 - val_accuracy: 0.7250\n",
      "Epoch 149/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4892 - accuracy: 0.7694 - val_loss: 0.5480 - val_accuracy: 0.7253\n",
      "Epoch 150/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4892 - accuracy: 0.7692 - val_loss: 0.5484 - val_accuracy: 0.7251\n",
      "Epoch 151/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4892 - accuracy: 0.7697 - val_loss: 0.5489 - val_accuracy: 0.7247\n",
      "Epoch 152/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4891 - accuracy: 0.7692 - val_loss: 0.5488 - val_accuracy: 0.7256\n",
      "Epoch 153/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4891 - accuracy: 0.7692 - val_loss: 0.5499 - val_accuracy: 0.7245\n",
      "Epoch 154/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4891 - accuracy: 0.7692 - val_loss: 0.5499 - val_accuracy: 0.7248\n",
      "Epoch 155/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4891 - accuracy: 0.7692 - val_loss: 0.5494 - val_accuracy: 0.7249\n",
      "Epoch 156/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4892 - accuracy: 0.7691 - val_loss: 0.5493 - val_accuracy: 0.7251\n",
      "Epoch 157/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4890 - accuracy: 0.7693 - val_loss: 0.5514 - val_accuracy: 0.7251\n",
      "Epoch 158/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4891 - accuracy: 0.7690 - val_loss: 0.5495 - val_accuracy: 0.7240\n",
      "Epoch 159/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4891 - accuracy: 0.7694 - val_loss: 0.5494 - val_accuracy: 0.7255\n",
      "Epoch 160/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4890 - accuracy: 0.7694 - val_loss: 0.5484 - val_accuracy: 0.7255\n",
      "Epoch 161/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4891 - accuracy: 0.7693 - val_loss: 0.5500 - val_accuracy: 0.7246\n",
      "Epoch 162/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4890 - accuracy: 0.7694 - val_loss: 0.5495 - val_accuracy: 0.7248\n",
      "Epoch 163/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4890 - accuracy: 0.7694 - val_loss: 0.5494 - val_accuracy: 0.7252\n",
      "Epoch 164/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4890 - accuracy: 0.7699 - val_loss: 0.5496 - val_accuracy: 0.7252\n",
      "Epoch 165/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4891 - accuracy: 0.7698 - val_loss: 0.5492 - val_accuracy: 0.7248\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4890 - accuracy: 0.7697 - val_loss: 0.5486 - val_accuracy: 0.7250\n",
      "Epoch 167/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4890 - accuracy: 0.7694 - val_loss: 0.5498 - val_accuracy: 0.7246\n",
      "Epoch 168/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4889 - accuracy: 0.7696 - val_loss: 0.5499 - val_accuracy: 0.7247\n",
      "Epoch 169/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4890 - accuracy: 0.7697 - val_loss: 0.5491 - val_accuracy: 0.7253\n",
      "Epoch 170/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4890 - accuracy: 0.7695 - val_loss: 0.5494 - val_accuracy: 0.7249\n",
      "Epoch 171/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4889 - accuracy: 0.7697 - val_loss: 0.5494 - val_accuracy: 0.7249\n",
      "Epoch 172/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4889 - accuracy: 0.7694 - val_loss: 0.5491 - val_accuracy: 0.7244\n",
      "Epoch 173/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4889 - accuracy: 0.7695 - val_loss: 0.5482 - val_accuracy: 0.7251\n",
      "Epoch 174/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4889 - accuracy: 0.7699 - val_loss: 0.5493 - val_accuracy: 0.7246\n",
      "Epoch 175/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4889 - accuracy: 0.7693 - val_loss: 0.5496 - val_accuracy: 0.7242\n",
      "Epoch 176/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4889 - accuracy: 0.7696 - val_loss: 0.5494 - val_accuracy: 0.7252\n",
      "Epoch 177/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4888 - accuracy: 0.7691 - val_loss: 0.5494 - val_accuracy: 0.7253\n",
      "Epoch 178/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4889 - accuracy: 0.7699 - val_loss: 0.5500 - val_accuracy: 0.7250\n",
      "Epoch 179/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4889 - accuracy: 0.7696 - val_loss: 0.5478 - val_accuracy: 0.7250\n",
      "Epoch 180/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4889 - accuracy: 0.7692 - val_loss: 0.5510 - val_accuracy: 0.7256\n",
      "Epoch 181/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4888 - accuracy: 0.7696 - val_loss: 0.5486 - val_accuracy: 0.7247\n",
      "Epoch 182/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4888 - accuracy: 0.7699 - val_loss: 0.5494 - val_accuracy: 0.7248\n",
      "Epoch 183/200\n",
      "6400/6400 [==============================] - 0s 29us/step - loss: 0.4888 - accuracy: 0.7699 - val_loss: 0.5494 - val_accuracy: 0.7251\n",
      "Epoch 184/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4888 - accuracy: 0.7697 - val_loss: 0.5502 - val_accuracy: 0.7246\n",
      "Epoch 185/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4888 - accuracy: 0.7697 - val_loss: 0.5502 - val_accuracy: 0.7244\n",
      "Epoch 186/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4888 - accuracy: 0.7694 - val_loss: 0.5499 - val_accuracy: 0.7251\n",
      "Epoch 187/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4888 - accuracy: 0.7696 - val_loss: 0.5488 - val_accuracy: 0.7256\n",
      "Epoch 188/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4887 - accuracy: 0.7700 - val_loss: 0.5492 - val_accuracy: 0.7256\n",
      "Epoch 189/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4888 - accuracy: 0.7693 - val_loss: 0.5497 - val_accuracy: 0.7251\n",
      "Epoch 190/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4887 - accuracy: 0.7689 - val_loss: 0.5491 - val_accuracy: 0.7239\n",
      "Epoch 191/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4887 - accuracy: 0.7695 - val_loss: 0.5501 - val_accuracy: 0.7251\n",
      "Epoch 192/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4887 - accuracy: 0.7696 - val_loss: 0.5499 - val_accuracy: 0.7254\n",
      "Epoch 193/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4887 - accuracy: 0.7699 - val_loss: 0.5497 - val_accuracy: 0.7253\n",
      "Epoch 194/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4887 - accuracy: 0.7696 - val_loss: 0.5483 - val_accuracy: 0.7258\n",
      "Epoch 195/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4886 - accuracy: 0.7699 - val_loss: 0.5511 - val_accuracy: 0.7240\n",
      "Epoch 196/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4888 - accuracy: 0.7698 - val_loss: 0.5504 - val_accuracy: 0.7252\n",
      "Epoch 197/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4887 - accuracy: 0.7698 - val_loss: 0.5496 - val_accuracy: 0.7242\n",
      "Epoch 198/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4886 - accuracy: 0.7694 - val_loss: 0.5495 - val_accuracy: 0.7260\n",
      "Epoch 199/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4887 - accuracy: 0.7700 - val_loss: 0.5492 - val_accuracy: 0.7253\n",
      "Epoch 200/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4886 - accuracy: 0.7695 - val_loss: 0.5503 - val_accuracy: 0.7259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:127: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Train on 6400 samples, validate on 1601 samples\n",
      "Epoch 1/200\n",
      "6400/6400 [==============================] - 0s 50us/step - loss: 0.6674 - accuracy: 0.7027 - val_loss: 0.6514 - val_accuracy: 0.7127\n",
      "Epoch 2/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.6130 - accuracy: 0.7523 - val_loss: 0.6061 - val_accuracy: 0.7159\n",
      "Epoch 3/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.5553 - accuracy: 0.7648 - val_loss: 0.5848 - val_accuracy: 0.7257\n",
      "Epoch 4/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5352 - accuracy: 0.7666 - val_loss: 0.5794 - val_accuracy: 0.7257\n",
      "Epoch 5/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.5303 - accuracy: 0.7666 - val_loss: 0.5759 - val_accuracy: 0.7257\n",
      "Epoch 6/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5277 - accuracy: 0.7666 - val_loss: 0.5740 - val_accuracy: 0.7257\n",
      "Epoch 7/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5256 - accuracy: 0.7666 - val_loss: 0.5722 - val_accuracy: 0.7257\n",
      "Epoch 8/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5236 - accuracy: 0.7666 - val_loss: 0.5705 - val_accuracy: 0.7257\n",
      "Epoch 9/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5216 - accuracy: 0.7666 - val_loss: 0.5687 - val_accuracy: 0.7257\n",
      "Epoch 10/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5196 - accuracy: 0.7666 - val_loss: 0.5673 - val_accuracy: 0.7257\n",
      "Epoch 11/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5177 - accuracy: 0.7666 - val_loss: 0.5660 - val_accuracy: 0.7257\n",
      "Epoch 12/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.5159 - accuracy: 0.7666 - val_loss: 0.5641 - val_accuracy: 0.7254\n",
      "Epoch 13/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5144 - accuracy: 0.7667 - val_loss: 0.5636 - val_accuracy: 0.7253\n",
      "Epoch 14/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5131 - accuracy: 0.7669 - val_loss: 0.5623 - val_accuracy: 0.7253\n",
      "Epoch 15/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5120 - accuracy: 0.7667 - val_loss: 0.5620 - val_accuracy: 0.7257\n",
      "Epoch 16/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5110 - accuracy: 0.7668 - val_loss: 0.5612 - val_accuracy: 0.7260\n",
      "Epoch 17/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5102 - accuracy: 0.7666 - val_loss: 0.5610 - val_accuracy: 0.7263\n",
      "Epoch 18/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5095 - accuracy: 0.7667 - val_loss: 0.5606 - val_accuracy: 0.7260\n",
      "Epoch 19/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5089 - accuracy: 0.7670 - val_loss: 0.5604 - val_accuracy: 0.7258\n",
      "Epoch 20/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5085 - accuracy: 0.7664 - val_loss: 0.5598 - val_accuracy: 0.7261\n",
      "Epoch 21/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5081 - accuracy: 0.7667 - val_loss: 0.5598 - val_accuracy: 0.7257\n",
      "Epoch 22/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5077 - accuracy: 0.7665 - val_loss: 0.5599 - val_accuracy: 0.7254\n",
      "Epoch 23/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5075 - accuracy: 0.7666 - val_loss: 0.5597 - val_accuracy: 0.7259\n",
      "Epoch 24/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5072 - accuracy: 0.7666 - val_loss: 0.5599 - val_accuracy: 0.7257\n",
      "Epoch 25/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5070 - accuracy: 0.7665 - val_loss: 0.5592 - val_accuracy: 0.7260\n",
      "Epoch 26/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5069 - accuracy: 0.7666 - val_loss: 0.5595 - val_accuracy: 0.7260\n",
      "Epoch 27/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.5067 - accuracy: 0.7665 - val_loss: 0.5594 - val_accuracy: 0.7256\n",
      "Epoch 28/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.5065 - accuracy: 0.7668 - val_loss: 0.5597 - val_accuracy: 0.7254\n",
      "Epoch 29/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5064 - accuracy: 0.7667 - val_loss: 0.5596 - val_accuracy: 0.7262\n",
      "Epoch 30/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5063 - accuracy: 0.7667 - val_loss: 0.5600 - val_accuracy: 0.7259\n",
      "Epoch 31/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5062 - accuracy: 0.7667 - val_loss: 0.5591 - val_accuracy: 0.7255\n",
      "Epoch 32/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5061 - accuracy: 0.7668 - val_loss: 0.5587 - val_accuracy: 0.7255\n",
      "Epoch 33/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5060 - accuracy: 0.7665 - val_loss: 0.5588 - val_accuracy: 0.7254\n",
      "Epoch 34/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5059 - accuracy: 0.7666 - val_loss: 0.5592 - val_accuracy: 0.7257\n",
      "Epoch 35/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5058 - accuracy: 0.7668 - val_loss: 0.5586 - val_accuracy: 0.7260\n",
      "Epoch 36/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5058 - accuracy: 0.7666 - val_loss: 0.5584 - val_accuracy: 0.7257\n",
      "Epoch 37/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.5057 - accuracy: 0.7665 - val_loss: 0.5591 - val_accuracy: 0.7259\n",
      "Epoch 38/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5056 - accuracy: 0.7664 - val_loss: 0.5588 - val_accuracy: 0.7253\n",
      "Epoch 39/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5055 - accuracy: 0.7665 - val_loss: 0.5589 - val_accuracy: 0.7252\n",
      "Epoch 40/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5055 - accuracy: 0.7666 - val_loss: 0.5590 - val_accuracy: 0.7254\n",
      "Epoch 41/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5054 - accuracy: 0.7664 - val_loss: 0.5588 - val_accuracy: 0.7253\n",
      "Epoch 42/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5054 - accuracy: 0.7667 - val_loss: 0.5589 - val_accuracy: 0.7249\n",
      "Epoch 43/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.5053 - accuracy: 0.7667 - val_loss: 0.5583 - val_accuracy: 0.7256\n",
      "Epoch 44/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5053 - accuracy: 0.7665 - val_loss: 0.5589 - val_accuracy: 0.7246\n",
      "Epoch 45/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5052 - accuracy: 0.7666 - val_loss: 0.5582 - val_accuracy: 0.7245\n",
      "Epoch 46/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5051 - accuracy: 0.7668 - val_loss: 0.5581 - val_accuracy: 0.7256\n",
      "Epoch 47/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5051 - accuracy: 0.7665 - val_loss: 0.5585 - val_accuracy: 0.7244\n",
      "Epoch 48/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5050 - accuracy: 0.7666 - val_loss: 0.5585 - val_accuracy: 0.7248\n",
      "Epoch 49/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5049 - accuracy: 0.7666 - val_loss: 0.5581 - val_accuracy: 0.7248\n",
      "Epoch 50/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5047 - accuracy: 0.7668 - val_loss: 0.5588 - val_accuracy: 0.7249\n",
      "Epoch 51/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5047 - accuracy: 0.7666 - val_loss: 0.5585 - val_accuracy: 0.7251\n",
      "Epoch 52/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5046 - accuracy: 0.7665 - val_loss: 0.5574 - val_accuracy: 0.7252\n",
      "Epoch 53/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5045 - accuracy: 0.7664 - val_loss: 0.5580 - val_accuracy: 0.7249\n",
      "Epoch 54/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.5044 - accuracy: 0.7666 - val_loss: 0.5581 - val_accuracy: 0.7248\n",
      "Epoch 55/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5042 - accuracy: 0.7667 - val_loss: 0.5578 - val_accuracy: 0.7252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5041 - accuracy: 0.7665 - val_loss: 0.5574 - val_accuracy: 0.7255\n",
      "Epoch 57/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5040 - accuracy: 0.7668 - val_loss: 0.5571 - val_accuracy: 0.7252\n",
      "Epoch 58/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.5039 - accuracy: 0.7667 - val_loss: 0.5580 - val_accuracy: 0.7250\n",
      "Epoch 59/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.5037 - accuracy: 0.7665 - val_loss: 0.5577 - val_accuracy: 0.7251\n",
      "Epoch 60/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5035 - accuracy: 0.7668 - val_loss: 0.5571 - val_accuracy: 0.7248\n",
      "Epoch 61/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5033 - accuracy: 0.7669 - val_loss: 0.5575 - val_accuracy: 0.7251\n",
      "Epoch 62/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5031 - accuracy: 0.7668 - val_loss: 0.5571 - val_accuracy: 0.7255\n",
      "Epoch 63/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5027 - accuracy: 0.7668 - val_loss: 0.5563 - val_accuracy: 0.7251\n",
      "Epoch 64/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5025 - accuracy: 0.7668 - val_loss: 0.5572 - val_accuracy: 0.7256\n",
      "Epoch 65/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.5021 - accuracy: 0.7669 - val_loss: 0.5560 - val_accuracy: 0.7252\n",
      "Epoch 66/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.5018 - accuracy: 0.7667 - val_loss: 0.5555 - val_accuracy: 0.7248\n",
      "Epoch 67/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.5014 - accuracy: 0.7666 - val_loss: 0.5561 - val_accuracy: 0.7250\n",
      "Epoch 68/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5009 - accuracy: 0.7666 - val_loss: 0.5555 - val_accuracy: 0.7244\n",
      "Epoch 69/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5004 - accuracy: 0.7664 - val_loss: 0.5554 - val_accuracy: 0.7244\n",
      "Epoch 70/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.5000 - accuracy: 0.7666 - val_loss: 0.5552 - val_accuracy: 0.7248\n",
      "Epoch 71/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4994 - accuracy: 0.7667 - val_loss: 0.5542 - val_accuracy: 0.7250\n",
      "Epoch 72/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4986 - accuracy: 0.7666 - val_loss: 0.5534 - val_accuracy: 0.7247\n",
      "Epoch 73/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4980 - accuracy: 0.7667 - val_loss: 0.5532 - val_accuracy: 0.7248\n",
      "Epoch 74/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4973 - accuracy: 0.7664 - val_loss: 0.5532 - val_accuracy: 0.7261\n",
      "Epoch 75/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4968 - accuracy: 0.7666 - val_loss: 0.5522 - val_accuracy: 0.7262\n",
      "Epoch 76/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4962 - accuracy: 0.7670 - val_loss: 0.5521 - val_accuracy: 0.7253\n",
      "Epoch 77/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4958 - accuracy: 0.7669 - val_loss: 0.5520 - val_accuracy: 0.7249\n",
      "Epoch 78/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4954 - accuracy: 0.7663 - val_loss: 0.5515 - val_accuracy: 0.7249\n",
      "Epoch 79/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4950 - accuracy: 0.7670 - val_loss: 0.5513 - val_accuracy: 0.7244\n",
      "Epoch 80/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4946 - accuracy: 0.7668 - val_loss: 0.5510 - val_accuracy: 0.7252\n",
      "Epoch 81/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4944 - accuracy: 0.7668 - val_loss: 0.5506 - val_accuracy: 0.7260\n",
      "Epoch 82/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4942 - accuracy: 0.7669 - val_loss: 0.5502 - val_accuracy: 0.7244\n",
      "Epoch 83/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4940 - accuracy: 0.7663 - val_loss: 0.5508 - val_accuracy: 0.7248\n",
      "Epoch 84/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4938 - accuracy: 0.7672 - val_loss: 0.5501 - val_accuracy: 0.7254\n",
      "Epoch 85/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4937 - accuracy: 0.7664 - val_loss: 0.5504 - val_accuracy: 0.7259\n",
      "Epoch 86/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4935 - accuracy: 0.7673 - val_loss: 0.5505 - val_accuracy: 0.7246\n",
      "Epoch 87/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4933 - accuracy: 0.7668 - val_loss: 0.5507 - val_accuracy: 0.7250\n",
      "Epoch 88/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4932 - accuracy: 0.7667 - val_loss: 0.5494 - val_accuracy: 0.7251\n",
      "Epoch 89/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4932 - accuracy: 0.7669 - val_loss: 0.5498 - val_accuracy: 0.7252\n",
      "Epoch 90/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4930 - accuracy: 0.7669 - val_loss: 0.5497 - val_accuracy: 0.7247\n",
      "Epoch 91/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4930 - accuracy: 0.7665 - val_loss: 0.5502 - val_accuracy: 0.7250\n",
      "Epoch 92/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4929 - accuracy: 0.7666 - val_loss: 0.5504 - val_accuracy: 0.7250\n",
      "Epoch 93/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4928 - accuracy: 0.7661 - val_loss: 0.5503 - val_accuracy: 0.7246\n",
      "Epoch 94/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4927 - accuracy: 0.7670 - val_loss: 0.5491 - val_accuracy: 0.7250\n",
      "Epoch 95/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4927 - accuracy: 0.7661 - val_loss: 0.5492 - val_accuracy: 0.7254\n",
      "Epoch 96/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4926 - accuracy: 0.7664 - val_loss: 0.5502 - val_accuracy: 0.7252\n",
      "Epoch 97/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4926 - accuracy: 0.7662 - val_loss: 0.5498 - val_accuracy: 0.7240\n",
      "Epoch 98/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4925 - accuracy: 0.7670 - val_loss: 0.5495 - val_accuracy: 0.7245\n",
      "Epoch 99/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4925 - accuracy: 0.7672 - val_loss: 0.5494 - val_accuracy: 0.7247\n",
      "Epoch 100/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4924 - accuracy: 0.7667 - val_loss: 0.5496 - val_accuracy: 0.7243\n",
      "Epoch 101/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4923 - accuracy: 0.7671 - val_loss: 0.5493 - val_accuracy: 0.7248\n",
      "Epoch 102/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4923 - accuracy: 0.7668 - val_loss: 0.5491 - val_accuracy: 0.7250\n",
      "Epoch 103/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4924 - accuracy: 0.7666 - val_loss: 0.5495 - val_accuracy: 0.7246\n",
      "Epoch 104/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4923 - accuracy: 0.7670 - val_loss: 0.5501 - val_accuracy: 0.7241\n",
      "Epoch 105/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4922 - accuracy: 0.7667 - val_loss: 0.5497 - val_accuracy: 0.7247\n",
      "Epoch 106/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4922 - accuracy: 0.7670 - val_loss: 0.5495 - val_accuracy: 0.7243\n",
      "Epoch 107/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4921 - accuracy: 0.7671 - val_loss: 0.5488 - val_accuracy: 0.7243\n",
      "Epoch 108/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4921 - accuracy: 0.7666 - val_loss: 0.5490 - val_accuracy: 0.7238\n",
      "Epoch 109/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4921 - accuracy: 0.7667 - val_loss: 0.5493 - val_accuracy: 0.7245\n",
      "Epoch 110/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4921 - accuracy: 0.7668 - val_loss: 0.5491 - val_accuracy: 0.7242\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4920 - accuracy: 0.7673 - val_loss: 0.5485 - val_accuracy: 0.7236\n",
      "Epoch 112/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4919 - accuracy: 0.7669 - val_loss: 0.5492 - val_accuracy: 0.7245\n",
      "Epoch 113/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4920 - accuracy: 0.7672 - val_loss: 0.5499 - val_accuracy: 0.7243\n",
      "Epoch 114/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4919 - accuracy: 0.7673 - val_loss: 0.5488 - val_accuracy: 0.7237\n",
      "Epoch 115/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4918 - accuracy: 0.7673 - val_loss: 0.5503 - val_accuracy: 0.7237\n",
      "Epoch 116/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4919 - accuracy: 0.7667 - val_loss: 0.5496 - val_accuracy: 0.7244\n",
      "Epoch 117/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4919 - accuracy: 0.7674 - val_loss: 0.5495 - val_accuracy: 0.7245\n",
      "Epoch 118/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4918 - accuracy: 0.7669 - val_loss: 0.5481 - val_accuracy: 0.7235\n",
      "Epoch 119/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4918 - accuracy: 0.7675 - val_loss: 0.5502 - val_accuracy: 0.7239\n",
      "Epoch 120/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4917 - accuracy: 0.7670 - val_loss: 0.5489 - val_accuracy: 0.7240\n",
      "Epoch 121/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4917 - accuracy: 0.7670 - val_loss: 0.5496 - val_accuracy: 0.7234\n",
      "Epoch 122/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4917 - accuracy: 0.7673 - val_loss: 0.5494 - val_accuracy: 0.7240\n",
      "Epoch 123/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4916 - accuracy: 0.7675 - val_loss: 0.5495 - val_accuracy: 0.7247\n",
      "Epoch 124/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4916 - accuracy: 0.7671 - val_loss: 0.5500 - val_accuracy: 0.7235\n",
      "Epoch 125/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7676 - val_loss: 0.5492 - val_accuracy: 0.7241\n",
      "Epoch 126/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4916 - accuracy: 0.7675 - val_loss: 0.5482 - val_accuracy: 0.7237\n",
      "Epoch 127/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7671 - val_loss: 0.5492 - val_accuracy: 0.7236\n",
      "Epoch 128/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4915 - accuracy: 0.7673 - val_loss: 0.5494 - val_accuracy: 0.7242\n",
      "Epoch 129/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7672 - val_loss: 0.5490 - val_accuracy: 0.7234\n",
      "Epoch 130/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7673 - val_loss: 0.5490 - val_accuracy: 0.7239\n",
      "Epoch 131/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7677 - val_loss: 0.5488 - val_accuracy: 0.7244\n",
      "Epoch 132/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4914 - accuracy: 0.7669 - val_loss: 0.5496 - val_accuracy: 0.7239\n",
      "Epoch 133/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4913 - accuracy: 0.7675 - val_loss: 0.5489 - val_accuracy: 0.7237\n",
      "Epoch 134/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4913 - accuracy: 0.7673 - val_loss: 0.5495 - val_accuracy: 0.7238\n",
      "Epoch 135/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4912 - accuracy: 0.7675 - val_loss: 0.5494 - val_accuracy: 0.7237\n",
      "Epoch 136/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4912 - accuracy: 0.7673 - val_loss: 0.5486 - val_accuracy: 0.7234\n",
      "Epoch 137/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4912 - accuracy: 0.7680 - val_loss: 0.5492 - val_accuracy: 0.7242\n",
      "Epoch 138/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4912 - accuracy: 0.7675 - val_loss: 0.5497 - val_accuracy: 0.7242\n",
      "Epoch 139/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4911 - accuracy: 0.7675 - val_loss: 0.5494 - val_accuracy: 0.7233\n",
      "Epoch 140/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4911 - accuracy: 0.7675 - val_loss: 0.5495 - val_accuracy: 0.7241\n",
      "Epoch 141/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4910 - accuracy: 0.7677 - val_loss: 0.5491 - val_accuracy: 0.7233\n",
      "Epoch 142/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4910 - accuracy: 0.7679 - val_loss: 0.5497 - val_accuracy: 0.7243\n",
      "Epoch 143/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4910 - accuracy: 0.7674 - val_loss: 0.5491 - val_accuracy: 0.7245\n",
      "Epoch 144/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4910 - accuracy: 0.7678 - val_loss: 0.5494 - val_accuracy: 0.7232\n",
      "Epoch 145/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4910 - accuracy: 0.7677 - val_loss: 0.5500 - val_accuracy: 0.7230\n",
      "Epoch 146/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4909 - accuracy: 0.7678 - val_loss: 0.5490 - val_accuracy: 0.7232\n",
      "Epoch 147/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4909 - accuracy: 0.7676 - val_loss: 0.5498 - val_accuracy: 0.7230\n",
      "Epoch 148/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4909 - accuracy: 0.7677 - val_loss: 0.5489 - val_accuracy: 0.7230\n",
      "Epoch 149/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4909 - accuracy: 0.7677 - val_loss: 0.5494 - val_accuracy: 0.7232\n",
      "Epoch 150/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4908 - accuracy: 0.7672 - val_loss: 0.5498 - val_accuracy: 0.7234\n",
      "Epoch 151/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4908 - accuracy: 0.7679 - val_loss: 0.5504 - val_accuracy: 0.7229\n",
      "Epoch 152/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4908 - accuracy: 0.7675 - val_loss: 0.5493 - val_accuracy: 0.7242\n",
      "Epoch 153/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4907 - accuracy: 0.7677 - val_loss: 0.5493 - val_accuracy: 0.7242\n",
      "Epoch 154/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4907 - accuracy: 0.7684 - val_loss: 0.5490 - val_accuracy: 0.7233\n",
      "Epoch 155/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4907 - accuracy: 0.7677 - val_loss: 0.5495 - val_accuracy: 0.7233\n",
      "Epoch 156/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4906 - accuracy: 0.7683 - val_loss: 0.5491 - val_accuracy: 0.7232\n",
      "Epoch 157/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4906 - accuracy: 0.7679 - val_loss: 0.5494 - val_accuracy: 0.7240\n",
      "Epoch 158/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4906 - accuracy: 0.7681 - val_loss: 0.5492 - val_accuracy: 0.7240\n",
      "Epoch 159/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4906 - accuracy: 0.7684 - val_loss: 0.5506 - val_accuracy: 0.7234\n",
      "Epoch 160/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4905 - accuracy: 0.7679 - val_loss: 0.5490 - val_accuracy: 0.7235\n",
      "Epoch 161/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4905 - accuracy: 0.7681 - val_loss: 0.5490 - val_accuracy: 0.7243\n",
      "Epoch 162/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4904 - accuracy: 0.7678 - val_loss: 0.5502 - val_accuracy: 0.7240\n",
      "Epoch 163/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4904 - accuracy: 0.7682 - val_loss: 0.5498 - val_accuracy: 0.7241\n",
      "Epoch 164/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4904 - accuracy: 0.7681 - val_loss: 0.5498 - val_accuracy: 0.7240\n",
      "Epoch 165/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4904 - accuracy: 0.7690 - val_loss: 0.5501 - val_accuracy: 0.7238\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4904 - accuracy: 0.7683 - val_loss: 0.5503 - val_accuracy: 0.7243\n",
      "Epoch 167/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4903 - accuracy: 0.7682 - val_loss: 0.5496 - val_accuracy: 0.7236\n",
      "Epoch 168/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4903 - accuracy: 0.7686 - val_loss: 0.5499 - val_accuracy: 0.7237\n",
      "Epoch 169/200\n",
      "6400/6400 [==============================] - 0s 36us/step - loss: 0.4903 - accuracy: 0.7682 - val_loss: 0.5491 - val_accuracy: 0.7244\n",
      "Epoch 170/200\n",
      "6400/6400 [==============================] - 0s 34us/step - loss: 0.4903 - accuracy: 0.7684 - val_loss: 0.5500 - val_accuracy: 0.7242\n",
      "Epoch 171/200\n",
      "6400/6400 [==============================] - 0s 35us/step - loss: 0.4902 - accuracy: 0.7685 - val_loss: 0.5498 - val_accuracy: 0.7241\n",
      "Epoch 172/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4902 - accuracy: 0.7687 - val_loss: 0.5501 - val_accuracy: 0.7249\n",
      "Epoch 173/200\n",
      "6400/6400 [==============================] - 0s 32us/step - loss: 0.4902 - accuracy: 0.7679 - val_loss: 0.5501 - val_accuracy: 0.7241\n",
      "Epoch 174/200\n",
      "6400/6400 [==============================] - 0s 33us/step - loss: 0.4901 - accuracy: 0.7682 - val_loss: 0.5504 - val_accuracy: 0.7230\n",
      "Epoch 175/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4901 - accuracy: 0.7688 - val_loss: 0.5496 - val_accuracy: 0.7242\n",
      "Epoch 176/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4901 - accuracy: 0.7684 - val_loss: 0.5500 - val_accuracy: 0.7237\n",
      "Epoch 177/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4900 - accuracy: 0.7687 - val_loss: 0.5499 - val_accuracy: 0.7249\n",
      "Epoch 178/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4900 - accuracy: 0.7686 - val_loss: 0.5508 - val_accuracy: 0.7251\n",
      "Epoch 179/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4900 - accuracy: 0.7683 - val_loss: 0.5491 - val_accuracy: 0.7239\n",
      "Epoch 180/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4900 - accuracy: 0.7681 - val_loss: 0.5497 - val_accuracy: 0.7243\n",
      "Epoch 181/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4900 - accuracy: 0.7684 - val_loss: 0.5494 - val_accuracy: 0.7237\n",
      "Epoch 182/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4900 - accuracy: 0.7685 - val_loss: 0.5503 - val_accuracy: 0.7227\n",
      "Epoch 183/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7679 - val_loss: 0.5497 - val_accuracy: 0.7240\n",
      "Epoch 184/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7688 - val_loss: 0.5504 - val_accuracy: 0.7241\n",
      "Epoch 185/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7686 - val_loss: 0.5500 - val_accuracy: 0.7241\n",
      "Epoch 186/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4899 - accuracy: 0.7691 - val_loss: 0.5501 - val_accuracy: 0.7234\n",
      "Epoch 187/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7687 - val_loss: 0.5495 - val_accuracy: 0.7247\n",
      "Epoch 188/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7686 - val_loss: 0.5507 - val_accuracy: 0.7248\n",
      "Epoch 189/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7685 - val_loss: 0.5499 - val_accuracy: 0.7235\n",
      "Epoch 190/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7690 - val_loss: 0.5491 - val_accuracy: 0.7240\n",
      "Epoch 191/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4898 - accuracy: 0.7687 - val_loss: 0.5501 - val_accuracy: 0.7245\n",
      "Epoch 192/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4897 - accuracy: 0.7687 - val_loss: 0.5500 - val_accuracy: 0.7243\n",
      "Epoch 193/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4897 - accuracy: 0.7687 - val_loss: 0.5502 - val_accuracy: 0.7255\n",
      "Epoch 194/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4896 - accuracy: 0.7686 - val_loss: 0.5501 - val_accuracy: 0.7227\n",
      "Epoch 195/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4897 - accuracy: 0.7690 - val_loss: 0.5497 - val_accuracy: 0.7236\n",
      "Epoch 196/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4896 - accuracy: 0.7689 - val_loss: 0.5499 - val_accuracy: 0.7247\n",
      "Epoch 197/200\n",
      "6400/6400 [==============================] - 0s 31us/step - loss: 0.4896 - accuracy: 0.7685 - val_loss: 0.5501 - val_accuracy: 0.7239\n",
      "Epoch 198/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4896 - accuracy: 0.7692 - val_loss: 0.5501 - val_accuracy: 0.7240\n",
      "Epoch 199/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4896 - accuracy: 0.7690 - val_loss: 0.5501 - val_accuracy: 0.7232\n",
      "Epoch 200/200\n",
      "6400/6400 [==============================] - 0s 30us/step - loss: 0.4895 - accuracy: 0.7686 - val_loss: 0.5513 - val_accuracy: 0.7244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:127: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[1977, 23]\n",
      "[0, 0]\n",
      "[189, 310]\n",
      "[1285, 216]\n",
      "[21, 478]\n",
      "[1431, 70]\n",
      "[209, 320]\n",
      "[1258, 213]\n",
      "[22, 507]\n",
      "[1377, 94]\n",
      "[98, 408]\n",
      "[1302, 192]\n",
      "[61, 445]\n",
      "[1349, 145]\n",
      "[59, 465]\n",
      "[1355, 121]\n",
      "[53, 471]\n",
      "[1317, 159]\n",
      "[189, 341]\n",
      "[1116, 354]\n",
      "[121, 409]\n",
      "[1176, 294]\n",
      "[0, 532]\n",
      "[1468, 0]\n",
      "[95, 437]\n",
      "[1250, 218]\n",
      "[0, 517]\n",
      "[1483, 0]\n",
      "[67, 450]\n",
      "[1304, 179]\n",
      "[1009, 209]\n",
      "[469, 313]\n",
      "[985, 233]\n",
      "[516, 266]\n",
      "[827, 299]\n",
      "[663, 211]\n",
      "[887, 239]\n",
      "[617, 257]\n",
      "[91, 434]\n",
      "[1272, 203]\n",
      "[95, 430]\n",
      "[1246, 229]\n",
      "[0, 509]\n",
      "[1491, 0]\n",
      "[75, 434]\n",
      "[1290, 201]\n",
      "[813, 280]\n",
      "[721, 186]\n",
      "[851, 242]\n",
      "[674, 233]\n",
      "[866, 247]\n",
      "[630, 257]\n",
      "[899, 214]\n",
      "[626, 261]\n",
      "[186, 326]\n",
      "[1158, 330]\n",
      "[89, 423]\n",
      "[1281, 207]\n",
      "[830, 201]\n",
      "[693, 276]\n",
      "[768, 263]\n",
      "[741, 228]\n",
      "[933, 242]\n",
      "[574, 251]\n",
      "[931, 244]\n",
      "[596, 229]\n",
      "[64, 456]\n",
      "[1372, 108]\n",
      "[92, 428]\n",
      "[1268, 212]\n",
      "[0, 480]\n",
      "[1520, 0]\n",
      "[37, 443]\n",
      "[1408, 112]\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds of MWPM:\n",
      "> Accuracy: 0.7383103974328693 (+- 0.0025068088308236977)\n",
      "> F1: 0.31232225216200904(+- 0.006437269309019919)\n",
      "> Time: 20.203409720000028 (+- 0.3403304777569674)\n",
      "#####################################################################################\n",
      "Average scores for all folds of PLUT:\n",
      "> Accuracy: 0.7256586654041463 (+- 0.002205906005546041)\n",
      "> F1: 0.2798443583016767(+- 0.005772189824591114)\n",
      "> Time: 0.03980876 (+- 0.0007486148024184389)\n",
      "#####################################################################################\n",
      "Average scores for all folds of NN:\n",
      "> Accuracy: 0.6860450198223721 (+- 0.14645826461373013)\n",
      "> F1: 0.4331179468750834(+- 0.0022467376287528457)\n",
      "> Time: 0.05581206000000001 (+- 0.0004004801847782237)\n",
      "#####################################################################################\n",
      "> AUC for class : 0.10830415207603805 (+- 0.0)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 21.043478260869566\n",
      "> AUC for class X00: 0.5465926251355747 (+- 0.00713783253229283)\n",
      "X^2 for MWPM and NN: 597.2263322884013\n",
      "X^2 for PLUT and NN: 476.7501309586171\n",
      "> AUC for class X01: 0.559275195281024 (+- 0.014945302220298403)\n",
      "X^2 for MWPM and NN: 558.7585551330799\n",
      "X^2 for PLUT and NN: 402.67569002123145\n",
      "> AUC for class X02: 0.5620379189552028 (+- 0.005380767151682319)\n",
      "X^2 for MWPM and NN: 468.4356725146199\n",
      "X^2 for PLUT and NN: 456.5356744704571\n",
      "> AUC for class X10: 0.5722313410697322 (+- 0.015208120669716347)\n",
      "X^2 for MWPM and NN: 436.19835164835166\n",
      "X^2 for PLUT and NN: 401.2354586129754\n",
      "> AUC for class X11: 0.5767079632361318 (+- 0.014207433350199231)\n",
      "X^2 for MWPM and NN: 413.29855868222376\n",
      "X^2 for PLUT and NN: 372.1287066246057\n",
      "> AUC for class X12: 0.5644636011477161 (+- 0.006518675851465145)\n",
      "X^2 for MWPM and NN: 438.9845\n",
      "X^2 for PLUT and NN: 392.7658565500889\n",
      "> AUC for class X20: 0.580949849443303 (+- 0.01616501254234275)\n",
      "X^2 for MWPM and NN: 467.5445\n",
      "X^2 for PLUT and NN: 416.7759407069555\n",
      "> AUC for class X21: 0.7662420468543532 (+- 0.009404622980681954)\n",
      "X^2 for MWPM and NN: 100.47345132743362\n",
      "X^2 for PLUT and NN: 107.6849132176235\n",
      "> AUC for class X22: 0.7631842406957376 (+- 0.01270634965669573)\n",
      "X^2 for MWPM and NN: 138.487525987526\n",
      "X^2 for PLUT and NN: 167.80490654205607\n",
      "> AUC for class Z00: 0.5707091610149863 (+- 0.019937712876647994)\n",
      "X^2 for MWPM and NN: 412.61488862837047\n",
      "X^2 for PLUT and NN: 398.2631264916468\n",
      "> AUC for class Z01: 0.5720292065926204 (+- 0.005650566592619272)\n",
      "X^2 for MWPM and NN: 483.1445\n",
      "X^2 for PLUT and NN: 426.01450116009283\n",
      "> AUC for class Z02: 0.76733673490731 (+- 0.006213908862514872)\n",
      "X^2 for MWPM and NN: 195.16883116883116\n",
      "X^2 for PLUT and NN: 204.68231441048036\n",
      "> AUC for class Z10: 0.7731471305045882 (+- 0.0069769466798570755)\n",
      "X^2 for MWPM and NN: 168.13683010262258\n",
      "X^2 for PLUT and NN: 203.05833333333334\n",
      "> AUC for class Z11: 0.5841999290998235 (+- 0.01599323047214338)\n",
      "X^2 for MWPM and NN: 467.5801886792453\n",
      "X^2 for PLUT and NN: 433.0287558685446\n",
      "> AUC for class Z12: 0.7741968301987215 (+- 0.005621834833660305)\n",
      "X^2 for MWPM and NN: 271.8668903803132\n",
      "X^2 for PLUT and NN: 228.52689243027888\n",
      "> AUC for class Z20: 0.7715984657015087 (+- 0.009546843965655185)\n",
      "X^2 for MWPM and NN: 135.8933823529412\n",
      "X^2 for PLUT and NN: 148.34404761904761\n",
      "> AUC for class Z21: 0.5573273747487745 (+- 0.013577915161184432)\n",
      "X^2 for MWPM and NN: 460.00492341356676\n",
      "X^2 for PLUT and NN: 417.02889150943395\n",
      "> AUC for class Z22: 0.5501885037242273 (+- 0.013868643338159134)\n",
      "X^2 for MWPM and NN: 541.8405\n",
      "X^2 for PLUT and NN: 504.13614262560776\n",
      "###################################################################################\n",
      "TOTAL F1 NN: [0.4293158022887753, 0.4355446153846154, 0.4318964464525583, 0.4345387453874539, 0.4342941248620141]\n",
      "TOTAL F1 PLUT: [0.28346785416086834, 0.26867119301648884, 0.2798370953268448, 0.28343861576489976, 0.2838070332392816]\n",
      "TOTAL F1 MWPM: [0.3095700416088765, 0.30332342983486493, 0.31616832779623477, 0.3102496896123603, 0.3222997719577086]\n",
      "TOTAL ACC NN: [0.7601988315582275, 0.7591843605041504, 0.7595788240432739, 0.7581315040588379, 0.3931315789473708]\n",
      "TOTAL ACC PLUT: [0.7291354322838636, 0.7222105263157961, 0.7254473684210582, 0.725368421052639, 0.7261315789473746]\n",
      "TOTAL ACC MWPM: [0.7381309345327397, 0.7346578947368495, 0.7400000000000074, 0.7368421052631634, 0.7419210526315866]\n",
      "TOTAL TIME NN: [0.0550111, 0.0560126, 0.0560128, 0.0560121, 0.0560117]\n",
      "TOTAL TIME PLUT: [0.041009, 0.0390084, 0.0400092, 0.0400089, 0.0390083]\n",
      "TOTAL TIME MWPM: [20.814489900000037, 20.27706590000007, 20.088461300000045, 20.029731000000005, 19.80730049999998]\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "inputs = x_d3.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = y_d3.copy()\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "n_classes = 19\n",
    "\n",
    "acc_per_fold = []\n",
    "f1_per_fold = []\n",
    "time_per_fold = []\n",
    "\n",
    "\n",
    "acc_per_fold_plut = []\n",
    "f1_per_fold_plut = []\n",
    "time_per_fold_plut = []\n",
    "\n",
    "acc_per_fold_mwpm = []\n",
    "f1_per_fold_mwpm = []\n",
    "time_per_fold_mwpm = []\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "aucs_classes = {}\n",
    "for i in mlb_d3.classes_:\n",
    "    aucs_classes[i] = []\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for i, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "    \n",
    "    i_train = inputs[train].copy()\n",
    "    i_test = inputs[test].copy()\n",
    "    x_test_d3 = i_test[:,:2]\n",
    "    inputs_train = i_train[:,3:]\n",
    "    inputs_test = i_test[:,3:]\n",
    "    \n",
    "    ####################################################################################################\n",
    "    #test MWPM decoder for this fold\n",
    "    \n",
    "    decoding_d3, time_mwpm = do_new_decoding(x_test_d3, 3, .03)\n",
    "    decoding_d3['combine'] = decoding_d3[[0, 1]].values.tolist()\n",
    "    decoding_d3['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "    decoding_d3 = np.array(decoding_d3[0])\n",
    "\n",
    "    time_per_fold_mwpm.append(time_mwpm)\n",
    "\n",
    "    pred_mwpm = mlb_d3.transform(decoding_d3)\n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_mwpm)\n",
    "    else:\n",
    "        acc, contingency_mwpm = partial_accuracy_and_contingency(targets[test], pred_mwpm, mlb_d3)\n",
    "        \n",
    "    acc_per_fold_mwpm.append(acc)\n",
    "    f1_per_fold_mwpm.append(f1_score(targets[test], pred_mwpm, average='micro'))\n",
    "\n",
    "\n",
    "    #####################################################################################################\n",
    "    #test the plut decoder for this fold\n",
    "\n",
    "    lookup_d3 = lookup_decoder(3)\n",
    "\n",
    "    lookup_d3 = train_plut(lookup_d3, inputs_train, targets[train])\n",
    "\n",
    "    start = time.time_ns()\n",
    "    pred_plut_d3 = test_plut(lookup_d3, inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_plut_d3)\n",
    "    else:\n",
    "        acc, contingency_plut = partial_accuracy_and_contingency(targets[test], pred_plut_d3, mlb_d3)\n",
    "\n",
    "    acc_per_fold_plut.append(acc)\n",
    "    f1_per_fold_plut.append(f1_score(targets[test], pred_plut_d3, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #Test the NN decoder for this fold\n",
    "\n",
    "    model = compile_FFNN_cv_model_DepthThree(3)\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "\n",
    "    history = model.fit(\n",
    "        inputs_train, targets[train],\n",
    "        validation_split=.2,\n",
    "        epochs=200,\n",
    "        verbose=1)\n",
    "\n",
    "   # Generate generalization metrics\n",
    "    scores = model.evaluate(inputs_test, targets[test], verbose=0)\n",
    "\n",
    "    #get the time to predicting test\n",
    "    start = time.time_ns()\n",
    "    predictions_d3 = model.predict(inputs_test) #change here\n",
    "    end = time.time_ns()\n",
    "    time_per_fold.append((end - start)/ (10 ** 9))\n",
    "\n",
    "    #threshold based on previous tests with train_test_split in hyperparameter tuning\n",
    "    pred=predictions_d3.copy() #change here\n",
    "    pred[pred>=.1]=1 \n",
    "    pred[pred<.1]=0\n",
    "    \n",
    "    if fold_no <5:\n",
    "        acc = scores[1]\n",
    "    else:\n",
    "        acc, contingency_nn = partial_accuracy_and_contingency(targets[test], pred, mlb_d3)\n",
    "\n",
    "    acc_per_fold.append(acc)\n",
    "    f1_per_fold.append(f1_score(targets[test], pred, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #comput ROC AUC for classes and the mircoaverage\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d3.ravel())\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    #get the AUCs of each class, used to get average AUC of each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d3[:, i]) #change here\n",
    "        aucs_classes[mlb_d3.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "        \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "        \n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb_d3.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "    \n",
    "############print mean and stdev of AUC of each class#####################      \n",
    "    \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print(\"#####################################################################################\")\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print(\"#####################################################################################\")\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "print(\"#####################################################################################\")\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 3 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D5 Training, Testing, and Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data sets from CSV\n",
    "\n",
    "#### Data sets for D5:\n",
    "* Original:\n",
    "    - \"depth5_all_combos.csv\"\n",
    "* Randomly-sampled, with replacement (version 2):\n",
    "    - \"v2samples-d5-1000.csv\"\n",
    "    - \"v2samples-d5-10000.csv\"\n",
    "    - \"v2samples-d5-100000.csv\"\n",
    "* Randomly-sampled, without replacement (version 3):\n",
    "    - \"v3samples-d5-1000.csv\"\n",
    "    - \"v3samples-d5-10000.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported and formatted in 40.07048797607422 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "trainData_d5 = pd.read_csv(\"SAMPLES/v3samples-d5-10000.csv\")\n",
    "\n",
    "trainData_d5 = trainData_d5.applymap(lambda x: add_noise(x,.01)) #was .05\n",
    "\n",
    "#These four lines remove duplicates\n",
    "trainData_d5['Labels'] = trainData_d5['Labels'].map(lambda x: create_list_from_string(x))\n",
    "trainData_d5['Labels'] = trainData_d5['Labels'].astype(str)\n",
    "trainData_d5 = trainData_d5.drop_duplicates('Labels', keep='first', ignore_index=True)\n",
    "trainData_d5['Labels'] = trainData_d5['Labels'].map(lambda x: create_list_from_string(x))\n",
    "\n",
    "testData_d5_MWPM = graph_with_errs_d5(trainData_d5)\n",
    "\n",
    "#transforms the data to encoding for ML\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(trainData_d5['Labels'])\n",
    "df = pd.DataFrame(mlb.transform(trainData_d5['Labels']))\n",
    "df['Labels']= df.values.tolist()\n",
    "trainData_d5 = trainData_d5.drop(['Labels'], axis=1)\n",
    "trainData_d5 = pd.concat([df[\"Labels\"], testData_d5_MWPM, trainData_d5], axis=1, ignore_index=True)\n",
    "trainData_d5.columns = [\"Labels\",\"XSyn\", \"ZSyn\",\"X0\",\"Z1\",\"X2\",\"X3\",\"Z4\",\"X5\",\"Z6\",\"Z7\",\"X8\",\"Z9\",\"X10\",\"Z11\",\"Z12\",\"X13\",\"Z14\",\"X15\",\"Z16\",\"Z17\",\"X18\",\"X19\",\"Z20\",\"X21\",\"X22\",\"Z23\"]\n",
    "\n",
    "y_d5 = trainData_d5[\"Labels\"] \n",
    "x_d5 = trainData_d5.drop([\"Labels\"], axis=1) \n",
    "\n",
    "x_d5 = x_d5.replace([-1], 0)\n",
    "print(\"Data imported and formatted in %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Train on 5625 samples, validate on 1875 samples\n",
      "Epoch 1/500\n",
      "5625/5625 [==============================] - 1s 97us/step - loss: 0.4833 - accuracy: 0.8327 - val_loss: 0.2564 - val_accuracy: 0.9288\n",
      "Epoch 2/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.2542 - accuracy: 0.9290 - val_loss: 0.2540 - val_accuracy: 0.9288\n",
      "Epoch 3/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2533 - accuracy: 0.9290 - val_loss: 0.2536 - val_accuracy: 0.9288\n",
      "Epoch 4/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2529 - accuracy: 0.9290 - val_loss: 0.2534 - val_accuracy: 0.9288\n",
      "Epoch 5/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2527 - accuracy: 0.9290 - val_loss: 0.2529 - val_accuracy: 0.9288\n",
      "Epoch 6/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2523 - accuracy: 0.9290 - val_loss: 0.2526 - val_accuracy: 0.9288\n",
      "Epoch 7/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2520 - accuracy: 0.9290 - val_loss: 0.2523 - val_accuracy: 0.9288\n",
      "Epoch 8/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2517 - accuracy: 0.9290 - val_loss: 0.2521 - val_accuracy: 0.9288\n",
      "Epoch 9/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2514 - accuracy: 0.9290 - val_loss: 0.2519 - val_accuracy: 0.9288\n",
      "Epoch 10/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2511 - accuracy: 0.9290 - val_loss: 0.2516 - val_accuracy: 0.9288\n",
      "Epoch 11/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.2508 - accuracy: 0.9290 - val_loss: 0.2512 - val_accuracy: 0.9288\n",
      "Epoch 12/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2504 - accuracy: 0.9290 - val_loss: 0.2507 - val_accuracy: 0.9288\n",
      "Epoch 13/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.2500 - accuracy: 0.9290 - val_loss: 0.2504 - val_accuracy: 0.9288\n",
      "Epoch 14/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.2496 - accuracy: 0.9290 - val_loss: 0.2500 - val_accuracy: 0.9288\n",
      "Epoch 15/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2491 - accuracy: 0.9290 - val_loss: 0.2495 - val_accuracy: 0.9288\n",
      "Epoch 16/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2486 - accuracy: 0.9290 - val_loss: 0.2491 - val_accuracy: 0.9288\n",
      "Epoch 17/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2481 - accuracy: 0.9290 - val_loss: 0.2484 - val_accuracy: 0.9288\n",
      "Epoch 18/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2475 - accuracy: 0.9290 - val_loss: 0.2477 - val_accuracy: 0.9288\n",
      "Epoch 19/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2468 - accuracy: 0.9290 - val_loss: 0.2471 - val_accuracy: 0.9288\n",
      "Epoch 20/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2460 - accuracy: 0.9290 - val_loss: 0.2463 - val_accuracy: 0.9288\n",
      "Epoch 21/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.2452 - accuracy: 0.9290 - val_loss: 0.2454 - val_accuracy: 0.9288\n",
      "Epoch 22/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.2442 - accuracy: 0.9290 - val_loss: 0.2445 - val_accuracy: 0.9288\n",
      "Epoch 23/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.2431 - accuracy: 0.9290 - val_loss: 0.2433 - val_accuracy: 0.9288\n",
      "Epoch 24/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2420 - accuracy: 0.9290 - val_loss: 0.2421 - val_accuracy: 0.9288\n",
      "Epoch 25/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.2407 - accuracy: 0.9290 - val_loss: 0.2409 - val_accuracy: 0.9288\n",
      "Epoch 26/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2395 - accuracy: 0.9290 - val_loss: 0.2397 - val_accuracy: 0.9288\n",
      "Epoch 27/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2382 - accuracy: 0.9290 - val_loss: 0.2384 - val_accuracy: 0.9288\n",
      "Epoch 28/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2369 - accuracy: 0.9290 - val_loss: 0.2371 - val_accuracy: 0.9288\n",
      "Epoch 29/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.2356 - accuracy: 0.9291 - val_loss: 0.2359 - val_accuracy: 0.9288\n",
      "Epoch 30/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2343 - accuracy: 0.9291 - val_loss: 0.2347 - val_accuracy: 0.9288\n",
      "Epoch 31/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2330 - accuracy: 0.9291 - val_loss: 0.2333 - val_accuracy: 0.9288\n",
      "Epoch 32/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2317 - accuracy: 0.9292 - val_loss: 0.2321 - val_accuracy: 0.9289\n",
      "Epoch 33/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.2304 - accuracy: 0.9292 - val_loss: 0.2310 - val_accuracy: 0.9290\n",
      "Epoch 34/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2292 - accuracy: 0.9292 - val_loss: 0.2298 - val_accuracy: 0.9289\n",
      "Epoch 35/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2279 - accuracy: 0.9292 - val_loss: 0.2287 - val_accuracy: 0.9290\n",
      "Epoch 36/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2266 - accuracy: 0.9294 - val_loss: 0.2276 - val_accuracy: 0.9290\n",
      "Epoch 37/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2253 - accuracy: 0.9294 - val_loss: 0.2262 - val_accuracy: 0.9290\n",
      "Epoch 38/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2240 - accuracy: 0.9294 - val_loss: 0.2249 - val_accuracy: 0.9290\n",
      "Epoch 39/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2228 - accuracy: 0.9294 - val_loss: 0.2236 - val_accuracy: 0.9291\n",
      "Epoch 40/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2214 - accuracy: 0.9294 - val_loss: 0.2224 - val_accuracy: 0.9292\n",
      "Epoch 41/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2202 - accuracy: 0.9295 - val_loss: 0.2215 - val_accuracy: 0.9295\n",
      "Epoch 42/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.2190 - accuracy: 0.9295 - val_loss: 0.2201 - val_accuracy: 0.9294\n",
      "Epoch 43/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.2177 - accuracy: 0.9295 - val_loss: 0.2189 - val_accuracy: 0.9294\n",
      "Epoch 44/500\n",
      "5625/5625 [==============================] - 0s 77us/step - loss: 0.2166 - accuracy: 0.9296 - val_loss: 0.2177 - val_accuracy: 0.9295\n",
      "Epoch 45/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.2155 - accuracy: 0.9296 - val_loss: 0.2168 - val_accuracy: 0.9295\n",
      "Epoch 46/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2143 - accuracy: 0.9296 - val_loss: 0.2158 - val_accuracy: 0.9294\n",
      "Epoch 47/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.2132 - accuracy: 0.9296 - val_loss: 0.2151 - val_accuracy: 0.9295\n",
      "Epoch 48/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2122 - accuracy: 0.9297 - val_loss: 0.2136 - val_accuracy: 0.9296\n",
      "Epoch 49/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2112 - accuracy: 0.9297 - val_loss: 0.2128 - val_accuracy: 0.9295\n",
      "Epoch 50/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.2102 - accuracy: 0.9297 - val_loss: 0.2119 - val_accuracy: 0.9296\n",
      "Epoch 51/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2093 - accuracy: 0.9298 - val_loss: 0.2113 - val_accuracy: 0.9295\n",
      "Epoch 52/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2084 - accuracy: 0.9298 - val_loss: 0.2103 - val_accuracy: 0.9300\n",
      "Epoch 53/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.2076 - accuracy: 0.9299 - val_loss: 0.2096 - val_accuracy: 0.9297\n",
      "Epoch 54/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2068 - accuracy: 0.9299 - val_loss: 0.2089 - val_accuracy: 0.9297\n",
      "Epoch 55/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2060 - accuracy: 0.9299 - val_loss: 0.2081 - val_accuracy: 0.9299\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2052 - accuracy: 0.9300 - val_loss: 0.2074 - val_accuracy: 0.9299\n",
      "Epoch 57/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2045 - accuracy: 0.9301 - val_loss: 0.2067 - val_accuracy: 0.9299\n",
      "Epoch 58/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.2038 - accuracy: 0.9302 - val_loss: 0.2060 - val_accuracy: 0.9301\n",
      "Epoch 59/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2031 - accuracy: 0.9302 - val_loss: 0.2053 - val_accuracy: 0.9300\n",
      "Epoch 60/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2025 - accuracy: 0.9303 - val_loss: 0.2047 - val_accuracy: 0.9300\n",
      "Epoch 61/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2018 - accuracy: 0.9303 - val_loss: 0.2044 - val_accuracy: 0.9303\n",
      "Epoch 62/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.2011 - accuracy: 0.9304 - val_loss: 0.2040 - val_accuracy: 0.9301\n",
      "Epoch 63/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.2004 - accuracy: 0.9306 - val_loss: 0.2032 - val_accuracy: 0.9307\n",
      "Epoch 64/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1999 - accuracy: 0.9306 - val_loss: 0.2025 - val_accuracy: 0.9305\n",
      "Epoch 65/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1993 - accuracy: 0.9306 - val_loss: 0.2022 - val_accuracy: 0.9307\n",
      "Epoch 66/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1987 - accuracy: 0.9306 - val_loss: 0.2015 - val_accuracy: 0.9306\n",
      "Epoch 67/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1982 - accuracy: 0.9306 - val_loss: 0.2009 - val_accuracy: 0.9308\n",
      "Epoch 68/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1976 - accuracy: 0.9307 - val_loss: 0.2004 - val_accuracy: 0.9310\n",
      "Epoch 69/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1970 - accuracy: 0.9309 - val_loss: 0.1997 - val_accuracy: 0.9308\n",
      "Epoch 70/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1965 - accuracy: 0.9309 - val_loss: 0.1995 - val_accuracy: 0.9310\n",
      "Epoch 71/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1959 - accuracy: 0.9310 - val_loss: 0.1988 - val_accuracy: 0.9312\n",
      "Epoch 72/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1953 - accuracy: 0.9311 - val_loss: 0.1982 - val_accuracy: 0.9313\n",
      "Epoch 73/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1947 - accuracy: 0.9311 - val_loss: 0.1977 - val_accuracy: 0.9312\n",
      "Epoch 74/500\n",
      "5625/5625 [==============================] - 0s 78us/step - loss: 0.1940 - accuracy: 0.9312 - val_loss: 0.1971 - val_accuracy: 0.9314\n",
      "Epoch 75/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1935 - accuracy: 0.9313 - val_loss: 0.1966 - val_accuracy: 0.9316\n",
      "Epoch 76/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1929 - accuracy: 0.9316 - val_loss: 0.1962 - val_accuracy: 0.9317\n",
      "Epoch 77/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1923 - accuracy: 0.9315 - val_loss: 0.1954 - val_accuracy: 0.9317\n",
      "Epoch 78/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1917 - accuracy: 0.9316 - val_loss: 0.1950 - val_accuracy: 0.9319\n",
      "Epoch 79/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1911 - accuracy: 0.9318 - val_loss: 0.1945 - val_accuracy: 0.9320\n",
      "Epoch 80/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1905 - accuracy: 0.9320 - val_loss: 0.1940 - val_accuracy: 0.9321\n",
      "Epoch 81/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1900 - accuracy: 0.9321 - val_loss: 0.1935 - val_accuracy: 0.9322\n",
      "Epoch 82/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1894 - accuracy: 0.9321 - val_loss: 0.1931 - val_accuracy: 0.9324\n",
      "Epoch 83/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1889 - accuracy: 0.9324 - val_loss: 0.1928 - val_accuracy: 0.9323\n",
      "Epoch 84/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1884 - accuracy: 0.9325 - val_loss: 0.1921 - val_accuracy: 0.9325\n",
      "Epoch 85/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1879 - accuracy: 0.9326 - val_loss: 0.1916 - val_accuracy: 0.9325\n",
      "Epoch 86/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1874 - accuracy: 0.9327 - val_loss: 0.1910 - val_accuracy: 0.9327\n",
      "Epoch 87/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1868 - accuracy: 0.9328 - val_loss: 0.1908 - val_accuracy: 0.9330\n",
      "Epoch 88/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1863 - accuracy: 0.9330 - val_loss: 0.1901 - val_accuracy: 0.9331\n",
      "Epoch 89/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1858 - accuracy: 0.9330 - val_loss: 0.1900 - val_accuracy: 0.9332\n",
      "Epoch 90/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1853 - accuracy: 0.9333 - val_loss: 0.1893 - val_accuracy: 0.9332\n",
      "Epoch 91/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1848 - accuracy: 0.9334 - val_loss: 0.1887 - val_accuracy: 0.9334\n",
      "Epoch 92/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1843 - accuracy: 0.9336 - val_loss: 0.1884 - val_accuracy: 0.9334\n",
      "Epoch 93/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1837 - accuracy: 0.9337 - val_loss: 0.1877 - val_accuracy: 0.9338\n",
      "Epoch 94/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1833 - accuracy: 0.9337 - val_loss: 0.1873 - val_accuracy: 0.9338\n",
      "Epoch 95/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1828 - accuracy: 0.9340 - val_loss: 0.1866 - val_accuracy: 0.9340\n",
      "Epoch 96/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1823 - accuracy: 0.9343 - val_loss: 0.1865 - val_accuracy: 0.9340\n",
      "Epoch 97/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1818 - accuracy: 0.9342 - val_loss: 0.1862 - val_accuracy: 0.9342\n",
      "Epoch 98/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1813 - accuracy: 0.9344 - val_loss: 0.1855 - val_accuracy: 0.9341\n",
      "Epoch 99/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1809 - accuracy: 0.9345 - val_loss: 0.1852 - val_accuracy: 0.9343\n",
      "Epoch 100/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1804 - accuracy: 0.9346 - val_loss: 0.1845 - val_accuracy: 0.9341\n",
      "Epoch 101/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1800 - accuracy: 0.9347 - val_loss: 0.1841 - val_accuracy: 0.9342\n",
      "Epoch 102/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1795 - accuracy: 0.9348 - val_loss: 0.1837 - val_accuracy: 0.9347\n",
      "Epoch 103/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1791 - accuracy: 0.9349 - val_loss: 0.1836 - val_accuracy: 0.9348\n",
      "Epoch 104/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1786 - accuracy: 0.9353 - val_loss: 0.1833 - val_accuracy: 0.9349\n",
      "Epoch 105/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1782 - accuracy: 0.9354 - val_loss: 0.1826 - val_accuracy: 0.9349\n",
      "Epoch 106/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1777 - accuracy: 0.9354 - val_loss: 0.1820 - val_accuracy: 0.9350\n",
      "Epoch 107/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1772 - accuracy: 0.9355 - val_loss: 0.1818 - val_accuracy: 0.9348\n",
      "Epoch 108/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1767 - accuracy: 0.9357 - val_loss: 0.1812 - val_accuracy: 0.9350\n",
      "Epoch 109/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1763 - accuracy: 0.9358 - val_loss: 0.1807 - val_accuracy: 0.9350\n",
      "Epoch 110/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1758 - accuracy: 0.9357 - val_loss: 0.1803 - val_accuracy: 0.9354\n",
      "Epoch 111/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1754 - accuracy: 0.9358 - val_loss: 0.1798 - val_accuracy: 0.9357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1750 - accuracy: 0.9361 - val_loss: 0.1795 - val_accuracy: 0.9354\n",
      "Epoch 113/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1745 - accuracy: 0.9363 - val_loss: 0.1791 - val_accuracy: 0.9356\n",
      "Epoch 114/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1741 - accuracy: 0.9362 - val_loss: 0.1787 - val_accuracy: 0.9360\n",
      "Epoch 115/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1736 - accuracy: 0.9365 - val_loss: 0.1782 - val_accuracy: 0.9361\n",
      "Epoch 116/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1731 - accuracy: 0.9367 - val_loss: 0.1786 - val_accuracy: 0.9357\n",
      "Epoch 117/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1728 - accuracy: 0.9367 - val_loss: 0.1773 - val_accuracy: 0.9363\n",
      "Epoch 118/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1722 - accuracy: 0.9369 - val_loss: 0.1774 - val_accuracy: 0.9359\n",
      "Epoch 119/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1719 - accuracy: 0.9370 - val_loss: 0.1766 - val_accuracy: 0.9364\n",
      "Epoch 120/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1715 - accuracy: 0.9371 - val_loss: 0.1763 - val_accuracy: 0.9364\n",
      "Epoch 121/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1710 - accuracy: 0.9372 - val_loss: 0.1760 - val_accuracy: 0.9366\n",
      "Epoch 122/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1707 - accuracy: 0.9373 - val_loss: 0.1756 - val_accuracy: 0.9368\n",
      "Epoch 123/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1702 - accuracy: 0.9376 - val_loss: 0.1749 - val_accuracy: 0.9369\n",
      "Epoch 124/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1698 - accuracy: 0.9376 - val_loss: 0.1748 - val_accuracy: 0.9368\n",
      "Epoch 125/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1694 - accuracy: 0.9377 - val_loss: 0.1743 - val_accuracy: 0.9374\n",
      "Epoch 126/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1690 - accuracy: 0.9380 - val_loss: 0.1742 - val_accuracy: 0.9372\n",
      "Epoch 127/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1687 - accuracy: 0.9380 - val_loss: 0.1738 - val_accuracy: 0.9374\n",
      "Epoch 128/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1683 - accuracy: 0.9381 - val_loss: 0.1733 - val_accuracy: 0.9373\n",
      "Epoch 129/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1679 - accuracy: 0.9382 - val_loss: 0.1730 - val_accuracy: 0.9373\n",
      "Epoch 130/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1675 - accuracy: 0.9383 - val_loss: 0.1729 - val_accuracy: 0.9378\n",
      "Epoch 131/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1672 - accuracy: 0.9384 - val_loss: 0.1725 - val_accuracy: 0.9375\n",
      "Epoch 132/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1668 - accuracy: 0.9385 - val_loss: 0.1719 - val_accuracy: 0.9383\n",
      "Epoch 133/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1665 - accuracy: 0.9387 - val_loss: 0.1721 - val_accuracy: 0.9379\n",
      "Epoch 134/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1661 - accuracy: 0.9389 - val_loss: 0.1713 - val_accuracy: 0.9383\n",
      "Epoch 135/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1658 - accuracy: 0.9390 - val_loss: 0.1715 - val_accuracy: 0.9382\n",
      "Epoch 136/500\n",
      "5625/5625 [==============================] - 0s 81us/step - loss: 0.1654 - accuracy: 0.9391 - val_loss: 0.1708 - val_accuracy: 0.9384\n",
      "Epoch 137/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1651 - accuracy: 0.9392 - val_loss: 0.1703 - val_accuracy: 0.9386\n",
      "Epoch 138/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1648 - accuracy: 0.9392 - val_loss: 0.1703 - val_accuracy: 0.9387\n",
      "Epoch 139/500\n",
      "5625/5625 [==============================] - 0s 77us/step - loss: 0.1645 - accuracy: 0.9394 - val_loss: 0.1697 - val_accuracy: 0.9388\n",
      "Epoch 140/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1641 - accuracy: 0.9393 - val_loss: 0.1696 - val_accuracy: 0.9389\n",
      "Epoch 141/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1639 - accuracy: 0.9395 - val_loss: 0.1697 - val_accuracy: 0.9389\n",
      "Epoch 142/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1636 - accuracy: 0.9397 - val_loss: 0.1690 - val_accuracy: 0.9390\n",
      "Epoch 143/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1633 - accuracy: 0.9399 - val_loss: 0.1691 - val_accuracy: 0.9389\n",
      "Epoch 144/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1631 - accuracy: 0.9398 - val_loss: 0.1685 - val_accuracy: 0.9393\n",
      "Epoch 145/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1628 - accuracy: 0.9399 - val_loss: 0.1686 - val_accuracy: 0.9390\n",
      "Epoch 146/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1626 - accuracy: 0.9400 - val_loss: 0.1683 - val_accuracy: 0.9394\n",
      "Epoch 147/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1623 - accuracy: 0.9401 - val_loss: 0.1680 - val_accuracy: 0.9391\n",
      "Epoch 148/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1621 - accuracy: 0.9401 - val_loss: 0.1680 - val_accuracy: 0.9394\n",
      "Epoch 149/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1619 - accuracy: 0.9401 - val_loss: 0.1676 - val_accuracy: 0.9392\n",
      "Epoch 150/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1616 - accuracy: 0.9403 - val_loss: 0.1680 - val_accuracy: 0.9394\n",
      "Epoch 151/500\n",
      "5625/5625 [==============================] - 0s 81us/step - loss: 0.1615 - accuracy: 0.9403 - val_loss: 0.1671 - val_accuracy: 0.9399\n",
      "Epoch 152/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1612 - accuracy: 0.9403 - val_loss: 0.1673 - val_accuracy: 0.9395\n",
      "Epoch 153/500\n",
      "5625/5625 [==============================] - 0s 78us/step - loss: 0.1610 - accuracy: 0.9405 - val_loss: 0.1671 - val_accuracy: 0.9395\n",
      "Epoch 154/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1608 - accuracy: 0.9407 - val_loss: 0.1667 - val_accuracy: 0.9398\n",
      "Epoch 155/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1606 - accuracy: 0.9408 - val_loss: 0.1665 - val_accuracy: 0.9397\n",
      "Epoch 156/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1603 - accuracy: 0.9407 - val_loss: 0.1669 - val_accuracy: 0.9399\n",
      "Epoch 157/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1602 - accuracy: 0.9409 - val_loss: 0.1664 - val_accuracy: 0.9398\n",
      "Epoch 158/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1599 - accuracy: 0.9410 - val_loss: 0.1660 - val_accuracy: 0.9402\n",
      "Epoch 159/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1598 - accuracy: 0.9409 - val_loss: 0.1657 - val_accuracy: 0.9402\n",
      "Epoch 160/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1596 - accuracy: 0.9409 - val_loss: 0.1654 - val_accuracy: 0.9403\n",
      "Epoch 161/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1593 - accuracy: 0.9410 - val_loss: 0.1657 - val_accuracy: 0.9402\n",
      "Epoch 162/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1592 - accuracy: 0.9412 - val_loss: 0.1654 - val_accuracy: 0.9401\n",
      "Epoch 163/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1590 - accuracy: 0.9412 - val_loss: 0.1652 - val_accuracy: 0.9405\n",
      "Epoch 164/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1588 - accuracy: 0.9413 - val_loss: 0.1647 - val_accuracy: 0.9408\n",
      "Epoch 165/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1586 - accuracy: 0.9414 - val_loss: 0.1653 - val_accuracy: 0.9408\n",
      "Epoch 166/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1583 - accuracy: 0.9414 - val_loss: 0.1649 - val_accuracy: 0.9406\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1582 - accuracy: 0.9415 - val_loss: 0.1644 - val_accuracy: 0.9405\n",
      "Epoch 168/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1579 - accuracy: 0.9416 - val_loss: 0.1647 - val_accuracy: 0.9405\n",
      "Epoch 169/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1578 - accuracy: 0.9416 - val_loss: 0.1646 - val_accuracy: 0.9405\n",
      "Epoch 170/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1575 - accuracy: 0.9416 - val_loss: 0.1639 - val_accuracy: 0.9405\n",
      "Epoch 171/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1574 - accuracy: 0.9417 - val_loss: 0.1640 - val_accuracy: 0.9407\n",
      "Epoch 172/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1572 - accuracy: 0.9420 - val_loss: 0.1640 - val_accuracy: 0.9403\n",
      "Epoch 173/500\n",
      "5625/5625 [==============================] - 1s 91us/step - loss: 0.1570 - accuracy: 0.9419 - val_loss: 0.1641 - val_accuracy: 0.9408\n",
      "Epoch 174/500\n",
      "5625/5625 [==============================] - 0s 84us/step - loss: 0.1569 - accuracy: 0.9417 - val_loss: 0.1633 - val_accuracy: 0.9407\n",
      "Epoch 175/500\n",
      "5625/5625 [==============================] - 0s 85us/step - loss: 0.1567 - accuracy: 0.9419 - val_loss: 0.1634 - val_accuracy: 0.9411\n",
      "Epoch 176/500\n",
      "5625/5625 [==============================] - 0s 80us/step - loss: 0.1565 - accuracy: 0.9420 - val_loss: 0.1636 - val_accuracy: 0.9411\n",
      "Epoch 177/500\n",
      "5625/5625 [==============================] - 0s 85us/step - loss: 0.1563 - accuracy: 0.9420 - val_loss: 0.1632 - val_accuracy: 0.9410\n",
      "Epoch 178/500\n",
      "5625/5625 [==============================] - 0s 78us/step - loss: 0.1560 - accuracy: 0.9420 - val_loss: 0.1631 - val_accuracy: 0.9410\n",
      "Epoch 179/500\n",
      "5625/5625 [==============================] - 1s 89us/step - loss: 0.1559 - accuracy: 0.9421 - val_loss: 0.1628 - val_accuracy: 0.9408\n",
      "Epoch 180/500\n",
      "5625/5625 [==============================] - 0s 82us/step - loss: 0.1556 - accuracy: 0.9423 - val_loss: 0.1630 - val_accuracy: 0.9414\n",
      "Epoch 181/500\n",
      "5625/5625 [==============================] - 0s 81us/step - loss: 0.1555 - accuracy: 0.9424 - val_loss: 0.1628 - val_accuracy: 0.9416\n",
      "Epoch 182/500\n",
      "5625/5625 [==============================] - 0s 81us/step - loss: 0.1553 - accuracy: 0.9425 - val_loss: 0.1623 - val_accuracy: 0.9414\n",
      "Epoch 183/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1551 - accuracy: 0.9425 - val_loss: 0.1621 - val_accuracy: 0.9412\n",
      "Epoch 184/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1549 - accuracy: 0.9425 - val_loss: 0.1621 - val_accuracy: 0.9417\n",
      "Epoch 185/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1547 - accuracy: 0.9426 - val_loss: 0.1618 - val_accuracy: 0.9414\n",
      "Epoch 186/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1545 - accuracy: 0.9427 - val_loss: 0.1620 - val_accuracy: 0.9415\n",
      "Epoch 187/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1543 - accuracy: 0.9427 - val_loss: 0.1617 - val_accuracy: 0.9415\n",
      "Epoch 188/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1542 - accuracy: 0.9427 - val_loss: 0.1615 - val_accuracy: 0.9415\n",
      "Epoch 189/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1539 - accuracy: 0.9428 - val_loss: 0.1612 - val_accuracy: 0.9412\n",
      "Epoch 190/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1537 - accuracy: 0.9427 - val_loss: 0.1610 - val_accuracy: 0.9419\n",
      "Epoch 191/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1535 - accuracy: 0.9429 - val_loss: 0.1610 - val_accuracy: 0.9411\n",
      "Epoch 192/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1533 - accuracy: 0.9429 - val_loss: 0.1605 - val_accuracy: 0.9418\n",
      "Epoch 193/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1531 - accuracy: 0.9429 - val_loss: 0.1612 - val_accuracy: 0.9414\n",
      "Epoch 194/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1529 - accuracy: 0.9430 - val_loss: 0.1603 - val_accuracy: 0.9418\n",
      "Epoch 195/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1527 - accuracy: 0.9432 - val_loss: 0.1603 - val_accuracy: 0.9418\n",
      "Epoch 196/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1525 - accuracy: 0.9433 - val_loss: 0.1603 - val_accuracy: 0.9420\n",
      "Epoch 197/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1523 - accuracy: 0.9431 - val_loss: 0.1600 - val_accuracy: 0.9417\n",
      "Epoch 198/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1520 - accuracy: 0.9433 - val_loss: 0.1600 - val_accuracy: 0.9420\n",
      "Epoch 199/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1519 - accuracy: 0.9434 - val_loss: 0.1596 - val_accuracy: 0.9421\n",
      "Epoch 200/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1517 - accuracy: 0.9436 - val_loss: 0.1599 - val_accuracy: 0.9421\n",
      "Epoch 201/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1515 - accuracy: 0.9437 - val_loss: 0.1595 - val_accuracy: 0.9419\n",
      "Epoch 202/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1513 - accuracy: 0.9437 - val_loss: 0.1591 - val_accuracy: 0.9424\n",
      "Epoch 203/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1510 - accuracy: 0.9439 - val_loss: 0.1589 - val_accuracy: 0.9424\n",
      "Epoch 204/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1508 - accuracy: 0.9436 - val_loss: 0.1588 - val_accuracy: 0.9425\n",
      "Epoch 205/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1506 - accuracy: 0.9438 - val_loss: 0.1588 - val_accuracy: 0.9424\n",
      "Epoch 206/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1504 - accuracy: 0.9439 - val_loss: 0.1586 - val_accuracy: 0.9424\n",
      "Epoch 207/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1502 - accuracy: 0.9439 - val_loss: 0.1582 - val_accuracy: 0.9423\n",
      "Epoch 208/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1501 - accuracy: 0.9441 - val_loss: 0.1581 - val_accuracy: 0.9426\n",
      "Epoch 209/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1498 - accuracy: 0.9441 - val_loss: 0.1578 - val_accuracy: 0.9426\n",
      "Epoch 210/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1495 - accuracy: 0.9442 - val_loss: 0.1576 - val_accuracy: 0.9427\n",
      "Epoch 211/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1494 - accuracy: 0.9443 - val_loss: 0.1580 - val_accuracy: 0.9427\n",
      "Epoch 212/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1491 - accuracy: 0.9444 - val_loss: 0.1576 - val_accuracy: 0.9427\n",
      "Epoch 213/500\n",
      "5625/5625 [==============================] - 0s 77us/step - loss: 0.1490 - accuracy: 0.9443 - val_loss: 0.1573 - val_accuracy: 0.9430\n",
      "Epoch 214/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1488 - accuracy: 0.9444 - val_loss: 0.1573 - val_accuracy: 0.9428\n",
      "Epoch 215/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1485 - accuracy: 0.9444 - val_loss: 0.1576 - val_accuracy: 0.9435\n",
      "Epoch 216/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1484 - accuracy: 0.9447 - val_loss: 0.1568 - val_accuracy: 0.9432\n",
      "Epoch 217/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1481 - accuracy: 0.9447 - val_loss: 0.1566 - val_accuracy: 0.9427\n",
      "Epoch 218/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1480 - accuracy: 0.9448 - val_loss: 0.1565 - val_accuracy: 0.9435\n",
      "Epoch 219/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1478 - accuracy: 0.9448 - val_loss: 0.1563 - val_accuracy: 0.9428\n",
      "Epoch 220/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1476 - accuracy: 0.9447 - val_loss: 0.1565 - val_accuracy: 0.9433\n",
      "Epoch 221/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1473 - accuracy: 0.9449 - val_loss: 0.1561 - val_accuracy: 0.9434\n",
      "Epoch 222/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1471 - accuracy: 0.9450 - val_loss: 0.1559 - val_accuracy: 0.9434\n",
      "Epoch 223/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1470 - accuracy: 0.9452 - val_loss: 0.1558 - val_accuracy: 0.9438\n",
      "Epoch 224/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1468 - accuracy: 0.9451 - val_loss: 0.1558 - val_accuracy: 0.9432\n",
      "Epoch 225/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1466 - accuracy: 0.9451 - val_loss: 0.1557 - val_accuracy: 0.9437\n",
      "Epoch 226/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1464 - accuracy: 0.9453 - val_loss: 0.1557 - val_accuracy: 0.9435\n",
      "Epoch 227/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1462 - accuracy: 0.9452 - val_loss: 0.1552 - val_accuracy: 0.9435\n",
      "Epoch 228/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1460 - accuracy: 0.9454 - val_loss: 0.1550 - val_accuracy: 0.9444\n",
      "Epoch 229/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1460 - accuracy: 0.9455 - val_loss: 0.1553 - val_accuracy: 0.9434\n",
      "Epoch 230/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1457 - accuracy: 0.9453 - val_loss: 0.1551 - val_accuracy: 0.9439\n",
      "Epoch 231/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1455 - accuracy: 0.9456 - val_loss: 0.1552 - val_accuracy: 0.9439\n",
      "Epoch 232/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1454 - accuracy: 0.9458 - val_loss: 0.1545 - val_accuracy: 0.9437\n",
      "Epoch 233/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1452 - accuracy: 0.9456 - val_loss: 0.1545 - val_accuracy: 0.9441\n",
      "Epoch 234/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1450 - accuracy: 0.9457 - val_loss: 0.1541 - val_accuracy: 0.9439\n",
      "Epoch 235/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1448 - accuracy: 0.9458 - val_loss: 0.1545 - val_accuracy: 0.9439\n",
      "Epoch 236/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1447 - accuracy: 0.9458 - val_loss: 0.1544 - val_accuracy: 0.9441\n",
      "Epoch 237/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1445 - accuracy: 0.9459 - val_loss: 0.1544 - val_accuracy: 0.9438\n",
      "Epoch 238/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1443 - accuracy: 0.9459 - val_loss: 0.1538 - val_accuracy: 0.9440\n",
      "Epoch 239/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1441 - accuracy: 0.9460 - val_loss: 0.1542 - val_accuracy: 0.9437\n",
      "Epoch 240/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1440 - accuracy: 0.9460 - val_loss: 0.1537 - val_accuracy: 0.9442\n",
      "Epoch 241/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1438 - accuracy: 0.9463 - val_loss: 0.1539 - val_accuracy: 0.9441\n",
      "Epoch 242/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1437 - accuracy: 0.9462 - val_loss: 0.1537 - val_accuracy: 0.9445\n",
      "Epoch 243/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1435 - accuracy: 0.9462 - val_loss: 0.1536 - val_accuracy: 0.9444\n",
      "Epoch 244/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1434 - accuracy: 0.9463 - val_loss: 0.1531 - val_accuracy: 0.9444\n",
      "Epoch 245/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1431 - accuracy: 0.9464 - val_loss: 0.1530 - val_accuracy: 0.9445\n",
      "Epoch 246/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1429 - accuracy: 0.9466 - val_loss: 0.1529 - val_accuracy: 0.9447\n",
      "Epoch 247/500\n",
      "5625/5625 [==============================] - 0s 77us/step - loss: 0.1428 - accuracy: 0.9464 - val_loss: 0.1532 - val_accuracy: 0.9444\n",
      "Epoch 248/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1426 - accuracy: 0.9467 - val_loss: 0.1530 - val_accuracy: 0.9444\n",
      "Epoch 249/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1426 - accuracy: 0.9466 - val_loss: 0.1527 - val_accuracy: 0.9446\n",
      "Epoch 250/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1423 - accuracy: 0.9465 - val_loss: 0.1526 - val_accuracy: 0.9448\n",
      "Epoch 251/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1421 - accuracy: 0.9465 - val_loss: 0.1527 - val_accuracy: 0.9449\n",
      "Epoch 252/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1420 - accuracy: 0.9468 - val_loss: 0.1525 - val_accuracy: 0.9449\n",
      "Epoch 253/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1419 - accuracy: 0.9466 - val_loss: 0.1527 - val_accuracy: 0.9444\n",
      "Epoch 254/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1417 - accuracy: 0.9465 - val_loss: 0.1522 - val_accuracy: 0.9444\n",
      "Epoch 255/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1415 - accuracy: 0.9470 - val_loss: 0.1523 - val_accuracy: 0.9445\n",
      "Epoch 256/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1414 - accuracy: 0.9469 - val_loss: 0.1519 - val_accuracy: 0.9454\n",
      "Epoch 257/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1412 - accuracy: 0.9470 - val_loss: 0.1516 - val_accuracy: 0.9449\n",
      "Epoch 258/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1411 - accuracy: 0.9470 - val_loss: 0.1518 - val_accuracy: 0.9446\n",
      "Epoch 259/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1409 - accuracy: 0.9469 - val_loss: 0.1517 - val_accuracy: 0.9449\n",
      "Epoch 260/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1407 - accuracy: 0.9472 - val_loss: 0.1519 - val_accuracy: 0.9452\n",
      "Epoch 261/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1406 - accuracy: 0.9472 - val_loss: 0.1520 - val_accuracy: 0.9448\n",
      "Epoch 262/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1405 - accuracy: 0.9472 - val_loss: 0.1513 - val_accuracy: 0.9450\n",
      "Epoch 263/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1403 - accuracy: 0.9472 - val_loss: 0.1514 - val_accuracy: 0.9451\n",
      "Epoch 264/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1402 - accuracy: 0.9473 - val_loss: 0.1513 - val_accuracy: 0.9451\n",
      "Epoch 265/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1400 - accuracy: 0.9474 - val_loss: 0.1510 - val_accuracy: 0.9450\n",
      "Epoch 266/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1398 - accuracy: 0.9474 - val_loss: 0.1507 - val_accuracy: 0.9455\n",
      "Epoch 267/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1397 - accuracy: 0.9474 - val_loss: 0.1509 - val_accuracy: 0.9455\n",
      "Epoch 268/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1396 - accuracy: 0.9475 - val_loss: 0.1513 - val_accuracy: 0.9450\n",
      "Epoch 269/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1394 - accuracy: 0.9473 - val_loss: 0.1508 - val_accuracy: 0.9454\n",
      "Epoch 270/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1393 - accuracy: 0.9476 - val_loss: 0.1503 - val_accuracy: 0.9457\n",
      "Epoch 271/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1391 - accuracy: 0.9478 - val_loss: 0.1507 - val_accuracy: 0.9455\n",
      "Epoch 272/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1390 - accuracy: 0.9477 - val_loss: 0.1510 - val_accuracy: 0.9452\n",
      "Epoch 273/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1388 - accuracy: 0.9476 - val_loss: 0.1506 - val_accuracy: 0.9449\n",
      "Epoch 274/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1386 - accuracy: 0.9477 - val_loss: 0.1510 - val_accuracy: 0.9456\n",
      "Epoch 275/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1385 - accuracy: 0.9479 - val_loss: 0.1506 - val_accuracy: 0.9454\n",
      "Epoch 276/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1383 - accuracy: 0.9479 - val_loss: 0.1500 - val_accuracy: 0.9458\n",
      "Epoch 277/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1382 - accuracy: 0.9479 - val_loss: 0.1500 - val_accuracy: 0.9454\n",
      "Epoch 278/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1381 - accuracy: 0.9479 - val_loss: 0.1501 - val_accuracy: 0.9456\n",
      "Epoch 279/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1379 - accuracy: 0.9478 - val_loss: 0.1503 - val_accuracy: 0.9454\n",
      "Epoch 280/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1378 - accuracy: 0.9479 - val_loss: 0.1499 - val_accuracy: 0.9456\n",
      "Epoch 281/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1376 - accuracy: 0.9478 - val_loss: 0.1501 - val_accuracy: 0.9453\n",
      "Epoch 282/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1375 - accuracy: 0.9479 - val_loss: 0.1497 - val_accuracy: 0.9456\n",
      "Epoch 283/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1374 - accuracy: 0.9481 - val_loss: 0.1495 - val_accuracy: 0.9459\n",
      "Epoch 284/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1373 - accuracy: 0.9483 - val_loss: 0.1499 - val_accuracy: 0.9458\n",
      "Epoch 285/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1371 - accuracy: 0.9481 - val_loss: 0.1494 - val_accuracy: 0.9458\n",
      "Epoch 286/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1370 - accuracy: 0.9482 - val_loss: 0.1493 - val_accuracy: 0.9454\n",
      "Epoch 287/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1368 - accuracy: 0.9483 - val_loss: 0.1492 - val_accuracy: 0.9458\n",
      "Epoch 288/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1367 - accuracy: 0.9483 - val_loss: 0.1497 - val_accuracy: 0.9451\n",
      "Epoch 289/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1365 - accuracy: 0.9484 - val_loss: 0.1497 - val_accuracy: 0.9456\n",
      "Epoch 290/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1364 - accuracy: 0.9482 - val_loss: 0.1490 - val_accuracy: 0.9456\n",
      "Epoch 291/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1362 - accuracy: 0.9487 - val_loss: 0.1494 - val_accuracy: 0.9454\n",
      "Epoch 292/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1361 - accuracy: 0.9485 - val_loss: 0.1489 - val_accuracy: 0.9460\n",
      "Epoch 293/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1360 - accuracy: 0.9486 - val_loss: 0.1493 - val_accuracy: 0.9458\n",
      "Epoch 294/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1358 - accuracy: 0.9484 - val_loss: 0.1493 - val_accuracy: 0.9457\n",
      "Epoch 295/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1359 - accuracy: 0.9485 - val_loss: 0.1494 - val_accuracy: 0.9461\n",
      "Epoch 296/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1356 - accuracy: 0.9489 - val_loss: 0.1487 - val_accuracy: 0.9459\n",
      "Epoch 297/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1354 - accuracy: 0.9486 - val_loss: 0.1490 - val_accuracy: 0.9461\n",
      "Epoch 298/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1355 - accuracy: 0.9486 - val_loss: 0.1485 - val_accuracy: 0.9461\n",
      "Epoch 299/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1352 - accuracy: 0.9488 - val_loss: 0.1487 - val_accuracy: 0.9462\n",
      "Epoch 300/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1352 - accuracy: 0.9488 - val_loss: 0.1486 - val_accuracy: 0.9458\n",
      "Epoch 301/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1350 - accuracy: 0.9486 - val_loss: 0.1483 - val_accuracy: 0.9463\n",
      "Epoch 302/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1349 - accuracy: 0.9492 - val_loss: 0.1482 - val_accuracy: 0.9461\n",
      "Epoch 303/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1348 - accuracy: 0.9489 - val_loss: 0.1486 - val_accuracy: 0.9461\n",
      "Epoch 304/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1346 - accuracy: 0.9490 - val_loss: 0.1485 - val_accuracy: 0.9457\n",
      "Epoch 305/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1345 - accuracy: 0.9491 - val_loss: 0.1481 - val_accuracy: 0.9462\n",
      "Epoch 306/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1343 - accuracy: 0.9489 - val_loss: 0.1479 - val_accuracy: 0.9464\n",
      "Epoch 307/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1342 - accuracy: 0.9492 - val_loss: 0.1480 - val_accuracy: 0.9463\n",
      "Epoch 308/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1341 - accuracy: 0.9492 - val_loss: 0.1478 - val_accuracy: 0.9463\n",
      "Epoch 309/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1340 - accuracy: 0.9492 - val_loss: 0.1476 - val_accuracy: 0.9465\n",
      "Epoch 310/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1338 - accuracy: 0.9491 - val_loss: 0.1478 - val_accuracy: 0.9460\n",
      "Epoch 311/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1338 - accuracy: 0.9491 - val_loss: 0.1475 - val_accuracy: 0.9464\n",
      "Epoch 312/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1336 - accuracy: 0.9490 - val_loss: 0.1475 - val_accuracy: 0.9463\n",
      "Epoch 313/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1336 - accuracy: 0.9493 - val_loss: 0.1475 - val_accuracy: 0.9466\n",
      "Epoch 314/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1334 - accuracy: 0.9492 - val_loss: 0.1481 - val_accuracy: 0.9460\n",
      "Epoch 315/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1333 - accuracy: 0.9494 - val_loss: 0.1476 - val_accuracy: 0.9465\n",
      "Epoch 316/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1332 - accuracy: 0.9492 - val_loss: 0.1473 - val_accuracy: 0.9464\n",
      "Epoch 317/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1331 - accuracy: 0.9496 - val_loss: 0.1474 - val_accuracy: 0.9463\n",
      "Epoch 318/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1329 - accuracy: 0.9493 - val_loss: 0.1472 - val_accuracy: 0.9468\n",
      "Epoch 319/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1328 - accuracy: 0.9495 - val_loss: 0.1475 - val_accuracy: 0.9462\n",
      "Epoch 320/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1327 - accuracy: 0.9496 - val_loss: 0.1471 - val_accuracy: 0.9469\n",
      "Epoch 321/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1326 - accuracy: 0.9495 - val_loss: 0.1473 - val_accuracy: 0.9463\n",
      "Epoch 322/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1325 - accuracy: 0.9495 - val_loss: 0.1471 - val_accuracy: 0.9467\n",
      "Epoch 323/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1324 - accuracy: 0.9497 - val_loss: 0.1472 - val_accuracy: 0.9467\n",
      "Epoch 324/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1322 - accuracy: 0.9497 - val_loss: 0.1469 - val_accuracy: 0.9466\n",
      "Epoch 325/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1321 - accuracy: 0.9496 - val_loss: 0.1477 - val_accuracy: 0.9460\n",
      "Epoch 326/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1320 - accuracy: 0.9496 - val_loss: 0.1468 - val_accuracy: 0.9466\n",
      "Epoch 327/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1319 - accuracy: 0.9500 - val_loss: 0.1468 - val_accuracy: 0.9460\n",
      "Epoch 328/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1318 - accuracy: 0.9496 - val_loss: 0.1468 - val_accuracy: 0.9466\n",
      "Epoch 329/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1317 - accuracy: 0.9497 - val_loss: 0.1469 - val_accuracy: 0.9465\n",
      "Epoch 330/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1316 - accuracy: 0.9500 - val_loss: 0.1469 - val_accuracy: 0.9468\n",
      "Epoch 331/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1315 - accuracy: 0.9498 - val_loss: 0.1470 - val_accuracy: 0.9466\n",
      "Epoch 332/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1313 - accuracy: 0.9499 - val_loss: 0.1469 - val_accuracy: 0.9467\n",
      "Epoch 333/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1312 - accuracy: 0.9497 - val_loss: 0.1465 - val_accuracy: 0.9466\n",
      "Epoch 334/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1310 - accuracy: 0.9499 - val_loss: 0.1472 - val_accuracy: 0.9464\n",
      "Epoch 335/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1310 - accuracy: 0.9499 - val_loss: 0.1463 - val_accuracy: 0.9471\n",
      "Epoch 336/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1309 - accuracy: 0.9500 - val_loss: 0.1465 - val_accuracy: 0.9464\n",
      "Epoch 337/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1308 - accuracy: 0.9501 - val_loss: 0.1463 - val_accuracy: 0.9467\n",
      "Epoch 338/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1307 - accuracy: 0.9499 - val_loss: 0.1466 - val_accuracy: 0.9465\n",
      "Epoch 339/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1306 - accuracy: 0.9501 - val_loss: 0.1466 - val_accuracy: 0.9462\n",
      "Epoch 340/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1305 - accuracy: 0.9502 - val_loss: 0.1461 - val_accuracy: 0.9471\n",
      "Epoch 341/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1303 - accuracy: 0.9501 - val_loss: 0.1459 - val_accuracy: 0.9469\n",
      "Epoch 342/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1302 - accuracy: 0.9503 - val_loss: 0.1466 - val_accuracy: 0.9464\n",
      "Epoch 343/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1302 - accuracy: 0.9503 - val_loss: 0.1469 - val_accuracy: 0.9469\n",
      "Epoch 344/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1301 - accuracy: 0.9505 - val_loss: 0.1461 - val_accuracy: 0.9471\n",
      "Epoch 345/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1300 - accuracy: 0.9502 - val_loss: 0.1461 - val_accuracy: 0.9462\n",
      "Epoch 346/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1298 - accuracy: 0.9503 - val_loss: 0.1457 - val_accuracy: 0.9468\n",
      "Epoch 347/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1296 - accuracy: 0.9503 - val_loss: 0.1461 - val_accuracy: 0.9466\n",
      "Epoch 348/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1296 - accuracy: 0.9504 - val_loss: 0.1458 - val_accuracy: 0.9469\n",
      "Epoch 349/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1296 - accuracy: 0.9502 - val_loss: 0.1458 - val_accuracy: 0.9467\n",
      "Epoch 350/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1294 - accuracy: 0.9503 - val_loss: 0.1464 - val_accuracy: 0.9466\n",
      "Epoch 351/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1292 - accuracy: 0.9505 - val_loss: 0.1457 - val_accuracy: 0.9470\n",
      "Epoch 352/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1292 - accuracy: 0.9504 - val_loss: 0.1460 - val_accuracy: 0.9470\n",
      "Epoch 353/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1292 - accuracy: 0.9505 - val_loss: 0.1455 - val_accuracy: 0.9465\n",
      "Epoch 354/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1290 - accuracy: 0.9507 - val_loss: 0.1459 - val_accuracy: 0.9467\n",
      "Epoch 355/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1289 - accuracy: 0.9507 - val_loss: 0.1458 - val_accuracy: 0.9469\n",
      "Epoch 356/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1287 - accuracy: 0.9508 - val_loss: 0.1456 - val_accuracy: 0.9469\n",
      "Epoch 357/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1288 - accuracy: 0.9505 - val_loss: 0.1456 - val_accuracy: 0.9470\n",
      "Epoch 358/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1286 - accuracy: 0.9506 - val_loss: 0.1457 - val_accuracy: 0.9467\n",
      "Epoch 359/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1286 - accuracy: 0.9508 - val_loss: 0.1459 - val_accuracy: 0.9469\n",
      "Epoch 360/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1284 - accuracy: 0.9507 - val_loss: 0.1452 - val_accuracy: 0.9471\n",
      "Epoch 361/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1284 - accuracy: 0.9509 - val_loss: 0.1453 - val_accuracy: 0.9471\n",
      "Epoch 362/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1283 - accuracy: 0.9508 - val_loss: 0.1451 - val_accuracy: 0.9472\n",
      "Epoch 363/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1282 - accuracy: 0.9508 - val_loss: 0.1452 - val_accuracy: 0.9468\n",
      "Epoch 364/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1281 - accuracy: 0.9510 - val_loss: 0.1452 - val_accuracy: 0.9472\n",
      "Epoch 365/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1279 - accuracy: 0.9508 - val_loss: 0.1455 - val_accuracy: 0.9466\n",
      "Epoch 366/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1279 - accuracy: 0.9511 - val_loss: 0.1448 - val_accuracy: 0.9474\n",
      "Epoch 367/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1277 - accuracy: 0.9511 - val_loss: 0.1457 - val_accuracy: 0.9470\n",
      "Epoch 368/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1275 - accuracy: 0.9510 - val_loss: 0.1452 - val_accuracy: 0.9470\n",
      "Epoch 369/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1276 - accuracy: 0.9510 - val_loss: 0.1450 - val_accuracy: 0.9472\n",
      "Epoch 370/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1274 - accuracy: 0.9512 - val_loss: 0.1454 - val_accuracy: 0.9470\n",
      "Epoch 371/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1274 - accuracy: 0.9510 - val_loss: 0.1450 - val_accuracy: 0.9473\n",
      "Epoch 372/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1272 - accuracy: 0.9512 - val_loss: 0.1452 - val_accuracy: 0.9473\n",
      "Epoch 373/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1271 - accuracy: 0.9512 - val_loss: 0.1449 - val_accuracy: 0.9475\n",
      "Epoch 374/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1270 - accuracy: 0.9512 - val_loss: 0.1449 - val_accuracy: 0.9473\n",
      "Epoch 375/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1270 - accuracy: 0.9511 - val_loss: 0.1451 - val_accuracy: 0.9472\n",
      "Epoch 376/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1268 - accuracy: 0.9511 - val_loss: 0.1449 - val_accuracy: 0.9470\n",
      "Epoch 377/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1267 - accuracy: 0.9513 - val_loss: 0.1447 - val_accuracy: 0.9471\n",
      "Epoch 378/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1266 - accuracy: 0.9513 - val_loss: 0.1449 - val_accuracy: 0.9473\n",
      "Epoch 379/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1265 - accuracy: 0.9513 - val_loss: 0.1450 - val_accuracy: 0.9474\n",
      "Epoch 380/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1265 - accuracy: 0.9513 - val_loss: 0.1448 - val_accuracy: 0.9474\n",
      "Epoch 381/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1264 - accuracy: 0.9512 - val_loss: 0.1455 - val_accuracy: 0.9471\n",
      "Epoch 382/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1263 - accuracy: 0.9514 - val_loss: 0.1453 - val_accuracy: 0.9466\n",
      "Epoch 383/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1262 - accuracy: 0.9515 - val_loss: 0.1449 - val_accuracy: 0.9471\n",
      "Epoch 384/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1262 - accuracy: 0.9516 - val_loss: 0.1456 - val_accuracy: 0.9467\n",
      "Epoch 385/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1260 - accuracy: 0.9515 - val_loss: 0.1451 - val_accuracy: 0.9471\n",
      "Epoch 386/500\n",
      "5625/5625 [==============================] - 0s 77us/step - loss: 0.1259 - accuracy: 0.9517 - val_loss: 0.1450 - val_accuracy: 0.9469\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1259 - accuracy: 0.9514 - val_loss: 0.1446 - val_accuracy: 0.9473\n",
      "Epoch 388/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1257 - accuracy: 0.9516 - val_loss: 0.1445 - val_accuracy: 0.9470\n",
      "Epoch 389/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1256 - accuracy: 0.9514 - val_loss: 0.1447 - val_accuracy: 0.9472\n",
      "Epoch 390/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1256 - accuracy: 0.9514 - val_loss: 0.1446 - val_accuracy: 0.9469\n",
      "Epoch 391/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1254 - accuracy: 0.9515 - val_loss: 0.1447 - val_accuracy: 0.9469\n",
      "Epoch 392/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1254 - accuracy: 0.9517 - val_loss: 0.1452 - val_accuracy: 0.9469\n",
      "Epoch 393/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1254 - accuracy: 0.9517 - val_loss: 0.1445 - val_accuracy: 0.9467\n",
      "Epoch 394/500\n",
      "5625/5625 [==============================] - 0s 70us/step - loss: 0.1253 - accuracy: 0.9518 - val_loss: 0.1449 - val_accuracy: 0.9465\n",
      "Epoch 395/500\n",
      "5625/5625 [==============================] - 0s 72us/step - loss: 0.1251 - accuracy: 0.9518 - val_loss: 0.1454 - val_accuracy: 0.9466\n",
      "Epoch 396/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1250 - accuracy: 0.9519 - val_loss: 0.1441 - val_accuracy: 0.9473\n",
      "Epoch 397/500\n",
      "5625/5625 [==============================] - 0s 78us/step - loss: 0.1249 - accuracy: 0.9520 - val_loss: 0.1451 - val_accuracy: 0.9472\n",
      "Epoch 398/500\n",
      "5625/5625 [==============================] - 1s 116us/step - loss: 0.1249 - accuracy: 0.9519 - val_loss: 0.1448 - val_accuracy: 0.9472\n",
      "Epoch 399/500\n",
      "5625/5625 [==============================] - 0s 83us/step - loss: 0.1248 - accuracy: 0.9520 - val_loss: 0.1448 - val_accuracy: 0.9471\n",
      "Epoch 400/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1246 - accuracy: 0.9519 - val_loss: 0.1448 - val_accuracy: 0.9469\n",
      "Epoch 401/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1246 - accuracy: 0.9519 - val_loss: 0.1444 - val_accuracy: 0.9474\n",
      "Epoch 402/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1245 - accuracy: 0.9522 - val_loss: 0.1441 - val_accuracy: 0.9472\n",
      "Epoch 403/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1245 - accuracy: 0.9518 - val_loss: 0.1442 - val_accuracy: 0.9474\n",
      "Epoch 404/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1243 - accuracy: 0.9519 - val_loss: 0.1441 - val_accuracy: 0.9469\n",
      "Epoch 405/500\n",
      "5625/5625 [==============================] - 0s 80us/step - loss: 0.1243 - accuracy: 0.9520 - val_loss: 0.1448 - val_accuracy: 0.9467\n",
      "Epoch 406/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1242 - accuracy: 0.9519 - val_loss: 0.1440 - val_accuracy: 0.9471\n",
      "Epoch 407/500\n",
      "5625/5625 [==============================] - 0s 77us/step - loss: 0.1241 - accuracy: 0.9521 - val_loss: 0.1444 - val_accuracy: 0.9473\n",
      "Epoch 408/500\n",
      "5625/5625 [==============================] - 0s 77us/step - loss: 0.1239 - accuracy: 0.9522 - val_loss: 0.1446 - val_accuracy: 0.9470\n",
      "Epoch 409/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1240 - accuracy: 0.9519 - val_loss: 0.1449 - val_accuracy: 0.9467\n",
      "Epoch 410/500\n",
      "5625/5625 [==============================] - 0s 77us/step - loss: 0.1238 - accuracy: 0.9522 - val_loss: 0.1444 - val_accuracy: 0.9468\n",
      "Epoch 411/500\n",
      "5625/5625 [==============================] - 0s 78us/step - loss: 0.1237 - accuracy: 0.9521 - val_loss: 0.1444 - val_accuracy: 0.9468\n",
      "Epoch 412/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1236 - accuracy: 0.9522 - val_loss: 0.1441 - val_accuracy: 0.9475\n",
      "Epoch 413/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1235 - accuracy: 0.9524 - val_loss: 0.1442 - val_accuracy: 0.9471\n",
      "Epoch 414/500\n",
      "5625/5625 [==============================] - 0s 74us/step - loss: 0.1234 - accuracy: 0.9522 - val_loss: 0.1442 - val_accuracy: 0.9472\n",
      "Epoch 415/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1233 - accuracy: 0.9526 - val_loss: 0.1448 - val_accuracy: 0.9469\n",
      "Epoch 416/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1233 - accuracy: 0.9524 - val_loss: 0.1442 - val_accuracy: 0.9471\n",
      "Epoch 417/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1233 - accuracy: 0.9522 - val_loss: 0.1442 - val_accuracy: 0.9470\n",
      "Epoch 418/500\n",
      "5625/5625 [==============================] - 0s 78us/step - loss: 0.1231 - accuracy: 0.9523 - val_loss: 0.1441 - val_accuracy: 0.9473\n",
      "Epoch 419/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1231 - accuracy: 0.9525 - val_loss: 0.1439 - val_accuracy: 0.9473\n",
      "Epoch 420/500\n",
      "5625/5625 [==============================] - 0s 77us/step - loss: 0.1230 - accuracy: 0.9525 - val_loss: 0.1439 - val_accuracy: 0.9472\n",
      "Epoch 421/500\n",
      "5625/5625 [==============================] - 0s 71us/step - loss: 0.1227 - accuracy: 0.9526 - val_loss: 0.1447 - val_accuracy: 0.9467\n",
      "Epoch 422/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1227 - accuracy: 0.9524 - val_loss: 0.1444 - val_accuracy: 0.9471\n",
      "Epoch 423/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1228 - accuracy: 0.9526 - val_loss: 0.1441 - val_accuracy: 0.9467\n",
      "Epoch 424/500\n",
      "5625/5625 [==============================] - 0s 78us/step - loss: 0.1226 - accuracy: 0.9527 - val_loss: 0.1442 - val_accuracy: 0.9475\n",
      "Epoch 425/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1226 - accuracy: 0.9525 - val_loss: 0.1448 - val_accuracy: 0.9470\n",
      "Epoch 426/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1224 - accuracy: 0.9526 - val_loss: 0.1441 - val_accuracy: 0.9472\n",
      "Epoch 427/500\n",
      "5625/5625 [==============================] - 0s 76us/step - loss: 0.1224 - accuracy: 0.9525 - val_loss: 0.1441 - val_accuracy: 0.9469\n",
      "Epoch 428/500\n",
      "5625/5625 [==============================] - 0s 75us/step - loss: 0.1223 - accuracy: 0.9528 - val_loss: 0.1440 - val_accuracy: 0.9475\n",
      "Epoch 429/500\n",
      "5625/5625 [==============================] - 0s 80us/step - loss: 0.1222 - accuracy: 0.9527 - val_loss: 0.1443 - val_accuracy: 0.9472\n",
      "Epoch 430/500\n",
      "5625/5625 [==============================] - 0s 69us/step - loss: 0.1221 - accuracy: 0.9527 - val_loss: 0.1444 - val_accuracy: 0.9463\n",
      "Epoch 431/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1221 - accuracy: 0.9529 - val_loss: 0.1441 - val_accuracy: 0.9471\n",
      "Epoch 432/500\n",
      "5625/5625 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.95 - 0s 70us/step - loss: 0.1219 - accuracy: 0.9531 - val_loss: 0.1444 - val_accuracy: 0.9472\n",
      "Epoch 433/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1220 - accuracy: 0.9528 - val_loss: 0.1441 - val_accuracy: 0.9470\n",
      "Epoch 434/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1218 - accuracy: 0.9527 - val_loss: 0.1436 - val_accuracy: 0.9473\n",
      "Epoch 435/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1216 - accuracy: 0.9530 - val_loss: 0.1439 - val_accuracy: 0.9469\n",
      "Epoch 436/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1218 - accuracy: 0.9528 - val_loss: 0.1441 - val_accuracy: 0.9469\n",
      "Epoch 437/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1216 - accuracy: 0.9529 - val_loss: 0.1439 - val_accuracy: 0.9469\n",
      "Epoch 438/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1215 - accuracy: 0.9527 - val_loss: 0.1441 - val_accuracy: 0.9470\n",
      "Epoch 439/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1214 - accuracy: 0.9530 - val_loss: 0.1440 - val_accuracy: 0.9470\n",
      "Epoch 440/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1213 - accuracy: 0.9530 - val_loss: 0.1439 - val_accuracy: 0.9470\n",
      "Epoch 441/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1212 - accuracy: 0.9531 - val_loss: 0.1446 - val_accuracy: 0.9468\n",
      "Epoch 442/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1212 - accuracy: 0.9531 - val_loss: 0.1442 - val_accuracy: 0.9468\n",
      "Epoch 443/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1211 - accuracy: 0.9530 - val_loss: 0.1442 - val_accuracy: 0.9471\n",
      "Epoch 444/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1210 - accuracy: 0.9531 - val_loss: 0.1441 - val_accuracy: 0.9475\n",
      "Epoch 445/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1208 - accuracy: 0.9530 - val_loss: 0.1437 - val_accuracy: 0.9475\n",
      "Epoch 446/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1208 - accuracy: 0.9532 - val_loss: 0.1438 - val_accuracy: 0.9476\n",
      "Epoch 447/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1207 - accuracy: 0.9529 - val_loss: 0.1438 - val_accuracy: 0.9473\n",
      "Epoch 448/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1207 - accuracy: 0.9532 - val_loss: 0.1441 - val_accuracy: 0.9471\n",
      "Epoch 449/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1206 - accuracy: 0.9531 - val_loss: 0.1443 - val_accuracy: 0.9471\n",
      "Epoch 450/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1204 - accuracy: 0.9532 - val_loss: 0.1445 - val_accuracy: 0.9472\n",
      "Epoch 451/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1204 - accuracy: 0.9534 - val_loss: 0.1446 - val_accuracy: 0.9472\n",
      "Epoch 452/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1203 - accuracy: 0.9533 - val_loss: 0.1446 - val_accuracy: 0.9471\n",
      "Epoch 453/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1203 - accuracy: 0.9532 - val_loss: 0.1436 - val_accuracy: 0.9472\n",
      "Epoch 454/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1202 - accuracy: 0.9534 - val_loss: 0.1437 - val_accuracy: 0.9474\n",
      "Epoch 455/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1201 - accuracy: 0.9536 - val_loss: 0.1442 - val_accuracy: 0.9471\n",
      "Epoch 456/500\n",
      "5625/5625 [==============================] - 0s 69us/step - loss: 0.1200 - accuracy: 0.9535 - val_loss: 0.1442 - val_accuracy: 0.9469\n",
      "Epoch 457/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1200 - accuracy: 0.9533 - val_loss: 0.1441 - val_accuracy: 0.9471\n",
      "Epoch 458/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1199 - accuracy: 0.9534 - val_loss: 0.1437 - val_accuracy: 0.9472\n",
      "Epoch 459/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1198 - accuracy: 0.9535 - val_loss: 0.1438 - val_accuracy: 0.9475\n",
      "Epoch 460/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1198 - accuracy: 0.9534 - val_loss: 0.1437 - val_accuracy: 0.9474\n",
      "Epoch 461/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1196 - accuracy: 0.9535 - val_loss: 0.1436 - val_accuracy: 0.9474\n",
      "Epoch 462/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1196 - accuracy: 0.9535 - val_loss: 0.1441 - val_accuracy: 0.9469\n",
      "Epoch 463/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1195 - accuracy: 0.9534 - val_loss: 0.1439 - val_accuracy: 0.9471\n",
      "Epoch 464/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1194 - accuracy: 0.9535 - val_loss: 0.1445 - val_accuracy: 0.9471\n",
      "Epoch 465/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1194 - accuracy: 0.9537 - val_loss: 0.1443 - val_accuracy: 0.9472\n",
      "Epoch 466/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1194 - accuracy: 0.9537 - val_loss: 0.1436 - val_accuracy: 0.9471\n",
      "Epoch 467/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1191 - accuracy: 0.9536 - val_loss: 0.1451 - val_accuracy: 0.9466\n",
      "Epoch 468/500\n",
      "5625/5625 [==============================] - 0s 69us/step - loss: 0.1192 - accuracy: 0.9538 - val_loss: 0.1440 - val_accuracy: 0.9471\n",
      "Epoch 469/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1190 - accuracy: 0.9536 - val_loss: 0.1441 - val_accuracy: 0.9466\n",
      "Epoch 470/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1189 - accuracy: 0.9539 - val_loss: 0.1442 - val_accuracy: 0.9470\n",
      "Epoch 471/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1189 - accuracy: 0.9537 - val_loss: 0.1447 - val_accuracy: 0.9466\n",
      "Epoch 472/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1188 - accuracy: 0.9538 - val_loss: 0.1440 - val_accuracy: 0.9468\n",
      "Epoch 473/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1186 - accuracy: 0.9538 - val_loss: 0.1438 - val_accuracy: 0.9468\n",
      "Epoch 474/500\n",
      "5625/5625 [==============================] - 0s 73us/step - loss: 0.1186 - accuracy: 0.9540 - val_loss: 0.1450 - val_accuracy: 0.9472\n",
      "Epoch 475/500\n",
      "5625/5625 [==============================] - 0s 69us/step - loss: 0.1185 - accuracy: 0.9538 - val_loss: 0.1440 - val_accuracy: 0.9469\n",
      "Epoch 476/500\n",
      "5625/5625 [==============================] - 0s 69us/step - loss: 0.1184 - accuracy: 0.9541 - val_loss: 0.1445 - val_accuracy: 0.9473\n",
      "Epoch 477/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1185 - accuracy: 0.9538 - val_loss: 0.1440 - val_accuracy: 0.9478\n",
      "Epoch 478/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1183 - accuracy: 0.9539 - val_loss: 0.1438 - val_accuracy: 0.9474\n",
      "Epoch 479/500\n",
      "5625/5625 [==============================] - 0s 69us/step - loss: 0.1183 - accuracy: 0.9538 - val_loss: 0.1440 - val_accuracy: 0.9470\n",
      "Epoch 480/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1181 - accuracy: 0.9540 - val_loss: 0.1445 - val_accuracy: 0.9470\n",
      "Epoch 481/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1181 - accuracy: 0.9540 - val_loss: 0.1439 - val_accuracy: 0.9469\n",
      "Epoch 482/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1180 - accuracy: 0.9539 - val_loss: 0.1442 - val_accuracy: 0.9466\n",
      "Epoch 483/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1181 - accuracy: 0.9539 - val_loss: 0.1436 - val_accuracy: 0.9474\n",
      "Epoch 484/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1179 - accuracy: 0.9543 - val_loss: 0.1438 - val_accuracy: 0.9472\n",
      "Epoch 485/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1178 - accuracy: 0.9540 - val_loss: 0.1447 - val_accuracy: 0.9469\n",
      "Epoch 486/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1177 - accuracy: 0.9539 - val_loss: 0.1437 - val_accuracy: 0.9473\n",
      "Epoch 487/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1177 - accuracy: 0.9542 - val_loss: 0.1442 - val_accuracy: 0.9468\n",
      "Epoch 488/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1175 - accuracy: 0.9542 - val_loss: 0.1456 - val_accuracy: 0.9468\n",
      "Epoch 489/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1174 - accuracy: 0.9542 - val_loss: 0.1440 - val_accuracy: 0.9470\n",
      "Epoch 490/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1173 - accuracy: 0.9543 - val_loss: 0.1446 - val_accuracy: 0.9473\n",
      "Epoch 491/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1173 - accuracy: 0.9541 - val_loss: 0.1443 - val_accuracy: 0.9472\n",
      "Epoch 492/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1172 - accuracy: 0.9542 - val_loss: 0.1440 - val_accuracy: 0.9471\n",
      "Epoch 493/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1171 - accuracy: 0.9541 - val_loss: 0.1445 - val_accuracy: 0.9471\n",
      "Epoch 494/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1171 - accuracy: 0.9542 - val_loss: 0.1438 - val_accuracy: 0.9473\n",
      "Epoch 495/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1170 - accuracy: 0.9545 - val_loss: 0.1439 - val_accuracy: 0.9471\n",
      "Epoch 496/500\n",
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1169 - accuracy: 0.9544 - val_loss: 0.1440 - val_accuracy: 0.9467\n",
      "Epoch 497/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 0s 68us/step - loss: 0.1169 - accuracy: 0.9545 - val_loss: 0.1442 - val_accuracy: 0.9466\n",
      "Epoch 498/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1168 - accuracy: 0.9543 - val_loss: 0.1447 - val_accuracy: 0.9471\n",
      "Epoch 499/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1166 - accuracy: 0.9545 - val_loss: 0.1437 - val_accuracy: 0.9472\n",
      "Epoch 500/500\n",
      "5625/5625 [==============================] - 0s 67us/step - loss: 0.1166 - accuracy: 0.9546 - val_loss: 0.1449 - val_accuracy: 0.9467\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_367 (Dense)            (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_368 (Dense)            (None, 240)               6000      \n",
      "_________________________________________________________________\n",
      "dense_369 (Dense)            (None, 240)               57840     \n",
      "_________________________________________________________________\n",
      "dense_370 (Dense)            (None, 240)               57840     \n",
      "_________________________________________________________________\n",
      "dense_371 (Dense)            (None, 240)               57840     \n",
      "_________________________________________________________________\n",
      "dense_372 (Dense)            (None, 51)                12291     \n",
      "=================================================================\n",
      "Total params: 192,411\n",
      "Trainable params: 192,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model trained in 205.47789454460144 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "inputs = x_d5.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = y_d5.copy()\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "train_input_d5 = inputs[:,2:]\n",
    "train_output_d5 = targets\n",
    "\n",
    "x_train_d5, x_test_d5, Y_train_d5, Y_test_d5 = train_test_split(train_input_d5, train_output_d5, train_size=0.75, shuffle=True)\n",
    "\n",
    "model_d5 = compile_FFNN_cv_model_DepthFive(5)\n",
    "print(\"Fit model on training data\")\n",
    "history = model_d5.fit(\n",
    "    x=x_train_d5,\n",
    "    y=Y_train_d5,\n",
    "    validation_split=.25,\n",
    "    epochs=500\n",
    ")\n",
    "model_d5.summary()\n",
    "print(\"Model trained in %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive:   4065\n",
      "False positive:  1702\n",
      "True negative:   114457\n",
      "False negative:  4776\n"
     ]
    }
   ],
   "source": [
    "predictions_d5 = model_d5.predict(x_test_d5)\n",
    "\n",
    "y_pred = predictions_d5\n",
    "y_test = Y_test_d5\n",
    "\n",
    "y_pred[y_pred>=.5]=1 \n",
    "y_pred[y_pred<.5]=0\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(len(y_pred)-1):\n",
    "    for j in range(len(y_test[0])-1):\n",
    "        if y_test[i][j] == y_pred[i][j] and y_test[i][j] == 1:\n",
    "            TP += 1\n",
    "        if y_pred[i][j] == 1 and y_test[i][j] != y_pred[i][j]:\n",
    "            FP += 1\n",
    "        if y_test[i][j] == y_pred[i][j] and y_test[i][j] == 0:\n",
    "            TN += 1\n",
    "        if y_pred[i][j] == 0 and y_test[i][j] != y_pred[i][j]:\n",
    "            FN += 1\n",
    "            \n",
    "print(\"True positive:   \" + str(TP) + \"\\nFalse positive:  \" + str(FP) + \"\\nTrue negative:   \" + str(TN) + \"\\nFalse negative:  \" + str(FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Epoch vs. Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss (MSE)')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Depth 5 Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Epoch vs. Accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Depth 5 Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d5.save(\"model_d5_v3-10k.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Train on 6000 samples, validate on 2000 samples\n",
      "Epoch 1/800\n",
      "6000/6000 [==============================] - 1s 91us/step - loss: 0.4216 - accuracy: 0.8535 - val_loss: 0.2670 - val_accuracy: 0.9246\n",
      "Epoch 2/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2494 - accuracy: 0.9307 - val_loss: 0.2655 - val_accuracy: 0.9246\n",
      "Epoch 3/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2488 - accuracy: 0.9307 - val_loss: 0.2651 - val_accuracy: 0.9246\n",
      "Epoch 4/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2485 - accuracy: 0.9307 - val_loss: 0.2649 - val_accuracy: 0.9246\n",
      "Epoch 5/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.2481 - accuracy: 0.9307 - val_loss: 0.2643 - val_accuracy: 0.9246\n",
      "Epoch 6/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2478 - accuracy: 0.9307 - val_loss: 0.2641 - val_accuracy: 0.9246\n",
      "Epoch 7/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2474 - accuracy: 0.9307 - val_loss: 0.2636 - val_accuracy: 0.9246\n",
      "Epoch 8/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2470 - accuracy: 0.9307 - val_loss: 0.2632 - val_accuracy: 0.9246\n",
      "Epoch 9/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.2467 - accuracy: 0.9307 - val_loss: 0.2628 - val_accuracy: 0.9246\n",
      "Epoch 10/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2463 - accuracy: 0.9307 - val_loss: 0.2625 - val_accuracy: 0.9246\n",
      "Epoch 11/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2458 - accuracy: 0.9307 - val_loss: 0.2619 - val_accuracy: 0.9246\n",
      "Epoch 12/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2453 - accuracy: 0.9307 - val_loss: 0.2614 - val_accuracy: 0.9246\n",
      "Epoch 13/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2448 - accuracy: 0.9307 - val_loss: 0.2610 - val_accuracy: 0.9246\n",
      "Epoch 14/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2442 - accuracy: 0.9307 - val_loss: 0.2603 - val_accuracy: 0.9246\n",
      "Epoch 15/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2436 - accuracy: 0.9307 - val_loss: 0.2598 - val_accuracy: 0.9246\n",
      "Epoch 16/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2429 - accuracy: 0.9307 - val_loss: 0.2589 - val_accuracy: 0.9246\n",
      "Epoch 17/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.2421 - accuracy: 0.9307 - val_loss: 0.2581 - val_accuracy: 0.9246\n",
      "Epoch 18/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2413 - accuracy: 0.9307 - val_loss: 0.2571 - val_accuracy: 0.9246\n",
      "Epoch 19/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2403 - accuracy: 0.9307 - val_loss: 0.2560 - val_accuracy: 0.9246\n",
      "Epoch 20/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2392 - accuracy: 0.9307 - val_loss: 0.2550 - val_accuracy: 0.9246\n",
      "Epoch 21/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2380 - accuracy: 0.9307 - val_loss: 0.2536 - val_accuracy: 0.9246\n",
      "Epoch 22/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2368 - accuracy: 0.9307 - val_loss: 0.2522 - val_accuracy: 0.9246\n",
      "Epoch 23/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2355 - accuracy: 0.9307 - val_loss: 0.2511 - val_accuracy: 0.9246\n",
      "Epoch 24/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2341 - accuracy: 0.9307 - val_loss: 0.2496 - val_accuracy: 0.9246\n",
      "Epoch 25/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.2327 - accuracy: 0.9307 - val_loss: 0.2484 - val_accuracy: 0.9246\n",
      "Epoch 26/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.2313 - accuracy: 0.9307 - val_loss: 0.2469 - val_accuracy: 0.9246\n",
      "Epoch 27/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2299 - accuracy: 0.9307 - val_loss: 0.2454 - val_accuracy: 0.9246\n",
      "Epoch 28/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2284 - accuracy: 0.9307 - val_loss: 0.2440 - val_accuracy: 0.9246\n",
      "Epoch 29/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2269 - accuracy: 0.9307 - val_loss: 0.2426 - val_accuracy: 0.9246\n",
      "Epoch 30/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2253 - accuracy: 0.9307 - val_loss: 0.2410 - val_accuracy: 0.9246\n",
      "Epoch 31/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2238 - accuracy: 0.9307 - val_loss: 0.2395 - val_accuracy: 0.9245\n",
      "Epoch 32/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2222 - accuracy: 0.9307 - val_loss: 0.2379 - val_accuracy: 0.9245\n",
      "Epoch 33/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2206 - accuracy: 0.9308 - val_loss: 0.2367 - val_accuracy: 0.9246\n",
      "Epoch 34/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2190 - accuracy: 0.9307 - val_loss: 0.2350 - val_accuracy: 0.9247\n",
      "Epoch 35/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2174 - accuracy: 0.9309 - val_loss: 0.2336 - val_accuracy: 0.9247\n",
      "Epoch 36/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2158 - accuracy: 0.9309 - val_loss: 0.2320 - val_accuracy: 0.9248\n",
      "Epoch 37/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2142 - accuracy: 0.9310 - val_loss: 0.2303 - val_accuracy: 0.9247\n",
      "Epoch 38/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2126 - accuracy: 0.9310 - val_loss: 0.2288 - val_accuracy: 0.9249\n",
      "Epoch 39/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2108 - accuracy: 0.9311 - val_loss: 0.2272 - val_accuracy: 0.9248\n",
      "Epoch 40/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2092 - accuracy: 0.9312 - val_loss: 0.2256 - val_accuracy: 0.9250\n",
      "Epoch 41/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2076 - accuracy: 0.9312 - val_loss: 0.2240 - val_accuracy: 0.9251\n",
      "Epoch 42/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2059 - accuracy: 0.9314 - val_loss: 0.2223 - val_accuracy: 0.9252\n",
      "Epoch 43/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.2042 - accuracy: 0.9315 - val_loss: 0.2208 - val_accuracy: 0.9253\n",
      "Epoch 44/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2026 - accuracy: 0.9316 - val_loss: 0.2195 - val_accuracy: 0.9254\n",
      "Epoch 45/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2010 - accuracy: 0.9317 - val_loss: 0.2179 - val_accuracy: 0.9255\n",
      "Epoch 46/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1994 - accuracy: 0.9318 - val_loss: 0.2160 - val_accuracy: 0.9256\n",
      "Epoch 47/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1978 - accuracy: 0.9320 - val_loss: 0.2155 - val_accuracy: 0.9261\n",
      "Epoch 48/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1963 - accuracy: 0.9321 - val_loss: 0.2136 - val_accuracy: 0.9258\n",
      "Epoch 49/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1949 - accuracy: 0.9324 - val_loss: 0.2124 - val_accuracy: 0.9256\n",
      "Epoch 50/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1935 - accuracy: 0.9327 - val_loss: 0.2108 - val_accuracy: 0.9266\n",
      "Epoch 51/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1921 - accuracy: 0.9330 - val_loss: 0.2095 - val_accuracy: 0.9266\n",
      "Epoch 52/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1908 - accuracy: 0.9332 - val_loss: 0.2084 - val_accuracy: 0.9268\n",
      "Epoch 53/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1896 - accuracy: 0.9336 - val_loss: 0.2070 - val_accuracy: 0.9274\n",
      "Epoch 54/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1884 - accuracy: 0.9338 - val_loss: 0.2065 - val_accuracy: 0.9274\n",
      "Epoch 55/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1873 - accuracy: 0.9342 - val_loss: 0.2052 - val_accuracy: 0.9272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1863 - accuracy: 0.9345 - val_loss: 0.2042 - val_accuracy: 0.9274\n",
      "Epoch 57/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1853 - accuracy: 0.9347 - val_loss: 0.2034 - val_accuracy: 0.9277\n",
      "Epoch 58/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1843 - accuracy: 0.9348 - val_loss: 0.2023 - val_accuracy: 0.9280\n",
      "Epoch 59/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1834 - accuracy: 0.9350 - val_loss: 0.2017 - val_accuracy: 0.9277\n",
      "Epoch 60/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1825 - accuracy: 0.9353 - val_loss: 0.2008 - val_accuracy: 0.9282\n",
      "Epoch 61/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1815 - accuracy: 0.9355 - val_loss: 0.2002 - val_accuracy: 0.9286\n",
      "Epoch 62/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1807 - accuracy: 0.9355 - val_loss: 0.1991 - val_accuracy: 0.9288\n",
      "Epoch 63/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1799 - accuracy: 0.9360 - val_loss: 0.1983 - val_accuracy: 0.9288\n",
      "Epoch 64/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1791 - accuracy: 0.9361 - val_loss: 0.1976 - val_accuracy: 0.9287\n",
      "Epoch 65/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1784 - accuracy: 0.9362 - val_loss: 0.1973 - val_accuracy: 0.9287\n",
      "Epoch 66/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1777 - accuracy: 0.9365 - val_loss: 0.1963 - val_accuracy: 0.9292\n",
      "Epoch 67/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1770 - accuracy: 0.9366 - val_loss: 0.1962 - val_accuracy: 0.9290\n",
      "Epoch 68/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1765 - accuracy: 0.9367 - val_loss: 0.1952 - val_accuracy: 0.9291\n",
      "Epoch 69/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1759 - accuracy: 0.9368 - val_loss: 0.1947 - val_accuracy: 0.9292\n",
      "Epoch 70/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1753 - accuracy: 0.9371 - val_loss: 0.1944 - val_accuracy: 0.9295\n",
      "Epoch 71/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1747 - accuracy: 0.9372 - val_loss: 0.1939 - val_accuracy: 0.9297\n",
      "Epoch 72/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1742 - accuracy: 0.9375 - val_loss: 0.1936 - val_accuracy: 0.9296\n",
      "Epoch 73/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1737 - accuracy: 0.9375 - val_loss: 0.1936 - val_accuracy: 0.9296\n",
      "Epoch 74/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1733 - accuracy: 0.9376 - val_loss: 0.1928 - val_accuracy: 0.9301\n",
      "Epoch 75/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1728 - accuracy: 0.9378 - val_loss: 0.1923 - val_accuracy: 0.9300\n",
      "Epoch 76/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1725 - accuracy: 0.9379 - val_loss: 0.1922 - val_accuracy: 0.9301\n",
      "Epoch 77/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1720 - accuracy: 0.9381 - val_loss: 0.1916 - val_accuracy: 0.9304\n",
      "Epoch 78/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1715 - accuracy: 0.9381 - val_loss: 0.1910 - val_accuracy: 0.9301\n",
      "Epoch 79/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1712 - accuracy: 0.9383 - val_loss: 0.1906 - val_accuracy: 0.9303\n",
      "Epoch 80/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1707 - accuracy: 0.9384 - val_loss: 0.1907 - val_accuracy: 0.9302\n",
      "Epoch 81/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1703 - accuracy: 0.9385 - val_loss: 0.1903 - val_accuracy: 0.9305\n",
      "Epoch 82/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1700 - accuracy: 0.9386 - val_loss: 0.1899 - val_accuracy: 0.9306\n",
      "Epoch 83/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1696 - accuracy: 0.9389 - val_loss: 0.1899 - val_accuracy: 0.9302\n",
      "Epoch 84/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1692 - accuracy: 0.9387 - val_loss: 0.1888 - val_accuracy: 0.9309\n",
      "Epoch 85/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1688 - accuracy: 0.9388 - val_loss: 0.1889 - val_accuracy: 0.9305\n",
      "Epoch 86/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1684 - accuracy: 0.9390 - val_loss: 0.1885 - val_accuracy: 0.9309\n",
      "Epoch 87/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1680 - accuracy: 0.9391 - val_loss: 0.1880 - val_accuracy: 0.9305\n",
      "Epoch 88/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1676 - accuracy: 0.9392 - val_loss: 0.1878 - val_accuracy: 0.9307\n",
      "Epoch 89/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1672 - accuracy: 0.9394 - val_loss: 0.1879 - val_accuracy: 0.9309\n",
      "Epoch 90/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1668 - accuracy: 0.9395 - val_loss: 0.1876 - val_accuracy: 0.9310\n",
      "Epoch 91/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1664 - accuracy: 0.9397 - val_loss: 0.1866 - val_accuracy: 0.9311\n",
      "Epoch 92/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1660 - accuracy: 0.9399 - val_loss: 0.1863 - val_accuracy: 0.9310\n",
      "Epoch 93/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1656 - accuracy: 0.9399 - val_loss: 0.1861 - val_accuracy: 0.9314\n",
      "Epoch 94/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1652 - accuracy: 0.9401 - val_loss: 0.1852 - val_accuracy: 0.9319\n",
      "Epoch 95/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1649 - accuracy: 0.9401 - val_loss: 0.1851 - val_accuracy: 0.9318\n",
      "Epoch 96/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1645 - accuracy: 0.9403 - val_loss: 0.1848 - val_accuracy: 0.9316\n",
      "Epoch 97/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1640 - accuracy: 0.9403 - val_loss: 0.1844 - val_accuracy: 0.9320\n",
      "Epoch 98/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1636 - accuracy: 0.9405 - val_loss: 0.1840 - val_accuracy: 0.9322\n",
      "Epoch 99/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1633 - accuracy: 0.9406 - val_loss: 0.1839 - val_accuracy: 0.9321\n",
      "Epoch 100/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1629 - accuracy: 0.9406 - val_loss: 0.1835 - val_accuracy: 0.9320\n",
      "Epoch 101/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1625 - accuracy: 0.9410 - val_loss: 0.1834 - val_accuracy: 0.9317\n",
      "Epoch 102/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1621 - accuracy: 0.9411 - val_loss: 0.1826 - val_accuracy: 0.9326\n",
      "Epoch 103/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1618 - accuracy: 0.9412 - val_loss: 0.1825 - val_accuracy: 0.9325\n",
      "Epoch 104/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1614 - accuracy: 0.9413 - val_loss: 0.1823 - val_accuracy: 0.9324\n",
      "Epoch 105/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1611 - accuracy: 0.9416 - val_loss: 0.1817 - val_accuracy: 0.9327\n",
      "Epoch 106/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1607 - accuracy: 0.9415 - val_loss: 0.1817 - val_accuracy: 0.9326\n",
      "Epoch 107/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1603 - accuracy: 0.9418 - val_loss: 0.1816 - val_accuracy: 0.9328\n",
      "Epoch 108/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1601 - accuracy: 0.9419 - val_loss: 0.1805 - val_accuracy: 0.9328\n",
      "Epoch 109/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1596 - accuracy: 0.9419 - val_loss: 0.1806 - val_accuracy: 0.9335\n",
      "Epoch 110/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1592 - accuracy: 0.9420 - val_loss: 0.1803 - val_accuracy: 0.9330\n",
      "Epoch 111/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1588 - accuracy: 0.9421 - val_loss: 0.1799 - val_accuracy: 0.9335\n",
      "Epoch 112/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1585 - accuracy: 0.9422 - val_loss: 0.1800 - val_accuracy: 0.9335\n",
      "Epoch 113/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1581 - accuracy: 0.9425 - val_loss: 0.1797 - val_accuracy: 0.9336\n",
      "Epoch 114/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1578 - accuracy: 0.9425 - val_loss: 0.1788 - val_accuracy: 0.9342\n",
      "Epoch 115/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1575 - accuracy: 0.9425 - val_loss: 0.1788 - val_accuracy: 0.9343\n",
      "Epoch 116/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1571 - accuracy: 0.9428 - val_loss: 0.1784 - val_accuracy: 0.9342\n",
      "Epoch 117/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1567 - accuracy: 0.9428 - val_loss: 0.1781 - val_accuracy: 0.9343\n",
      "Epoch 118/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1564 - accuracy: 0.9429 - val_loss: 0.1779 - val_accuracy: 0.9343\n",
      "Epoch 119/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1562 - accuracy: 0.9430 - val_loss: 0.1776 - val_accuracy: 0.9351\n",
      "Epoch 120/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1558 - accuracy: 0.9433 - val_loss: 0.1776 - val_accuracy: 0.9346\n",
      "Epoch 121/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1556 - accuracy: 0.9433 - val_loss: 0.1771 - val_accuracy: 0.9352\n",
      "Epoch 122/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1551 - accuracy: 0.9436 - val_loss: 0.1771 - val_accuracy: 0.9351\n",
      "Epoch 123/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1549 - accuracy: 0.9435 - val_loss: 0.1764 - val_accuracy: 0.9349\n",
      "Epoch 124/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1547 - accuracy: 0.9436 - val_loss: 0.1763 - val_accuracy: 0.9349\n",
      "Epoch 125/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1544 - accuracy: 0.9436 - val_loss: 0.1766 - val_accuracy: 0.9350\n",
      "Epoch 126/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1541 - accuracy: 0.9440 - val_loss: 0.1758 - val_accuracy: 0.9350\n",
      "Epoch 127/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1539 - accuracy: 0.9439 - val_loss: 0.1756 - val_accuracy: 0.9354\n",
      "Epoch 128/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1536 - accuracy: 0.9440 - val_loss: 0.1755 - val_accuracy: 0.9357\n",
      "Epoch 129/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1534 - accuracy: 0.9441 - val_loss: 0.1756 - val_accuracy: 0.9355\n",
      "Epoch 130/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1531 - accuracy: 0.9441 - val_loss: 0.1751 - val_accuracy: 0.9358\n",
      "Epoch 131/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1528 - accuracy: 0.9442 - val_loss: 0.1750 - val_accuracy: 0.9358\n",
      "Epoch 132/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1525 - accuracy: 0.9442 - val_loss: 0.1745 - val_accuracy: 0.9358\n",
      "Epoch 133/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1523 - accuracy: 0.9444 - val_loss: 0.1744 - val_accuracy: 0.9360\n",
      "Epoch 134/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1521 - accuracy: 0.9444 - val_loss: 0.1742 - val_accuracy: 0.9357\n",
      "Epoch 135/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1518 - accuracy: 0.9444 - val_loss: 0.1741 - val_accuracy: 0.9362\n",
      "Epoch 136/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1516 - accuracy: 0.9447 - val_loss: 0.1736 - val_accuracy: 0.9357\n",
      "Epoch 137/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1514 - accuracy: 0.9448 - val_loss: 0.1735 - val_accuracy: 0.9357\n",
      "Epoch 138/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1512 - accuracy: 0.9449 - val_loss: 0.1733 - val_accuracy: 0.9361\n",
      "Epoch 139/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1510 - accuracy: 0.9450 - val_loss: 0.1728 - val_accuracy: 0.9364\n",
      "Epoch 140/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1507 - accuracy: 0.9451 - val_loss: 0.1729 - val_accuracy: 0.9362\n",
      "Epoch 141/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1504 - accuracy: 0.9449 - val_loss: 0.1730 - val_accuracy: 0.9367\n",
      "Epoch 142/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1502 - accuracy: 0.9453 - val_loss: 0.1726 - val_accuracy: 0.9361\n",
      "Epoch 143/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1500 - accuracy: 0.9453 - val_loss: 0.1719 - val_accuracy: 0.9368\n",
      "Epoch 144/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1498 - accuracy: 0.9453 - val_loss: 0.1724 - val_accuracy: 0.9364\n",
      "Epoch 145/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1496 - accuracy: 0.9453 - val_loss: 0.1719 - val_accuracy: 0.9369\n",
      "Epoch 146/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1493 - accuracy: 0.9455 - val_loss: 0.1718 - val_accuracy: 0.9370\n",
      "Epoch 147/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1491 - accuracy: 0.9455 - val_loss: 0.1710 - val_accuracy: 0.9372\n",
      "Epoch 148/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1489 - accuracy: 0.9457 - val_loss: 0.1716 - val_accuracy: 0.9374\n",
      "Epoch 149/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1487 - accuracy: 0.9456 - val_loss: 0.1713 - val_accuracy: 0.9368\n",
      "Epoch 150/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1485 - accuracy: 0.9456 - val_loss: 0.1710 - val_accuracy: 0.9374\n",
      "Epoch 151/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1483 - accuracy: 0.9458 - val_loss: 0.1706 - val_accuracy: 0.9372\n",
      "Epoch 152/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1481 - accuracy: 0.9460 - val_loss: 0.1711 - val_accuracy: 0.9374\n",
      "Epoch 153/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1480 - accuracy: 0.9459 - val_loss: 0.1700 - val_accuracy: 0.9373\n",
      "Epoch 154/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1477 - accuracy: 0.9459 - val_loss: 0.1710 - val_accuracy: 0.9372\n",
      "Epoch 155/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1475 - accuracy: 0.9462 - val_loss: 0.1701 - val_accuracy: 0.9374\n",
      "Epoch 156/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1473 - accuracy: 0.9461 - val_loss: 0.1702 - val_accuracy: 0.9373\n",
      "Epoch 157/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1471 - accuracy: 0.9461 - val_loss: 0.1696 - val_accuracy: 0.9376\n",
      "Epoch 158/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1469 - accuracy: 0.9463 - val_loss: 0.1700 - val_accuracy: 0.9375\n",
      "Epoch 159/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1467 - accuracy: 0.9464 - val_loss: 0.1693 - val_accuracy: 0.9375\n",
      "Epoch 160/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1466 - accuracy: 0.9465 - val_loss: 0.1690 - val_accuracy: 0.9376\n",
      "Epoch 161/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1464 - accuracy: 0.9465 - val_loss: 0.1696 - val_accuracy: 0.9375\n",
      "Epoch 162/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1462 - accuracy: 0.9464 - val_loss: 0.1691 - val_accuracy: 0.9380\n",
      "Epoch 163/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1460 - accuracy: 0.9466 - val_loss: 0.1689 - val_accuracy: 0.9377\n",
      "Epoch 164/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1458 - accuracy: 0.9466 - val_loss: 0.1685 - val_accuracy: 0.9379\n",
      "Epoch 165/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1456 - accuracy: 0.9469 - val_loss: 0.1689 - val_accuracy: 0.9376\n",
      "Epoch 166/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1455 - accuracy: 0.9467 - val_loss: 0.1681 - val_accuracy: 0.9376\n",
      "Epoch 167/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1452 - accuracy: 0.9469 - val_loss: 0.1684 - val_accuracy: 0.9377\n",
      "Epoch 168/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1451 - accuracy: 0.9470 - val_loss: 0.1685 - val_accuracy: 0.9381\n",
      "Epoch 169/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1448 - accuracy: 0.9469 - val_loss: 0.1685 - val_accuracy: 0.9380\n",
      "Epoch 170/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1447 - accuracy: 0.9470 - val_loss: 0.1678 - val_accuracy: 0.9381\n",
      "Epoch 171/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1445 - accuracy: 0.9470 - val_loss: 0.1677 - val_accuracy: 0.9377\n",
      "Epoch 172/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1444 - accuracy: 0.9471 - val_loss: 0.1677 - val_accuracy: 0.9380\n",
      "Epoch 173/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1442 - accuracy: 0.9472 - val_loss: 0.1669 - val_accuracy: 0.9387\n",
      "Epoch 174/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1440 - accuracy: 0.9472 - val_loss: 0.1671 - val_accuracy: 0.9383\n",
      "Epoch 175/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1438 - accuracy: 0.9474 - val_loss: 0.1669 - val_accuracy: 0.9384\n",
      "Epoch 176/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1437 - accuracy: 0.9473 - val_loss: 0.1669 - val_accuracy: 0.9382\n",
      "Epoch 177/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1435 - accuracy: 0.9473 - val_loss: 0.1670 - val_accuracy: 0.9384\n",
      "Epoch 178/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1434 - accuracy: 0.9472 - val_loss: 0.1668 - val_accuracy: 0.9383\n",
      "Epoch 179/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1432 - accuracy: 0.9476 - val_loss: 0.1664 - val_accuracy: 0.9381\n",
      "Epoch 180/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1430 - accuracy: 0.9474 - val_loss: 0.1660 - val_accuracy: 0.9385\n",
      "Epoch 181/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1428 - accuracy: 0.9476 - val_loss: 0.1661 - val_accuracy: 0.9390\n",
      "Epoch 182/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1426 - accuracy: 0.9476 - val_loss: 0.1657 - val_accuracy: 0.9389\n",
      "Epoch 183/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1425 - accuracy: 0.9476 - val_loss: 0.1659 - val_accuracy: 0.9387\n",
      "Epoch 184/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1423 - accuracy: 0.9478 - val_loss: 0.1661 - val_accuracy: 0.9389\n",
      "Epoch 185/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1422 - accuracy: 0.9479 - val_loss: 0.1654 - val_accuracy: 0.9392\n",
      "Epoch 186/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1420 - accuracy: 0.9478 - val_loss: 0.1654 - val_accuracy: 0.9385\n",
      "Epoch 187/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1419 - accuracy: 0.9480 - val_loss: 0.1658 - val_accuracy: 0.9389\n",
      "Epoch 188/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1416 - accuracy: 0.9480 - val_loss: 0.1653 - val_accuracy: 0.9392\n",
      "Epoch 189/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1415 - accuracy: 0.9481 - val_loss: 0.1648 - val_accuracy: 0.9393\n",
      "Epoch 190/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1413 - accuracy: 0.9480 - val_loss: 0.1651 - val_accuracy: 0.9390\n",
      "Epoch 191/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1412 - accuracy: 0.9481 - val_loss: 0.1649 - val_accuracy: 0.9388\n",
      "Epoch 192/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1410 - accuracy: 0.9481 - val_loss: 0.1644 - val_accuracy: 0.9390\n",
      "Epoch 193/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1408 - accuracy: 0.9483 - val_loss: 0.1643 - val_accuracy: 0.9393\n",
      "Epoch 194/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1406 - accuracy: 0.9483 - val_loss: 0.1642 - val_accuracy: 0.9395\n",
      "Epoch 195/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1405 - accuracy: 0.9485 - val_loss: 0.1644 - val_accuracy: 0.9396\n",
      "Epoch 196/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1403 - accuracy: 0.9484 - val_loss: 0.1643 - val_accuracy: 0.9389\n",
      "Epoch 197/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1402 - accuracy: 0.9485 - val_loss: 0.1640 - val_accuracy: 0.9395\n",
      "Epoch 198/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1401 - accuracy: 0.9484 - val_loss: 0.1638 - val_accuracy: 0.9394\n",
      "Epoch 199/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1398 - accuracy: 0.9485 - val_loss: 0.1641 - val_accuracy: 0.9399\n",
      "Epoch 200/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1397 - accuracy: 0.9487 - val_loss: 0.1635 - val_accuracy: 0.9398\n",
      "Epoch 201/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1395 - accuracy: 0.9487 - val_loss: 0.1634 - val_accuracy: 0.9397\n",
      "Epoch 202/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1394 - accuracy: 0.9487 - val_loss: 0.1630 - val_accuracy: 0.9402\n",
      "Epoch 203/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1392 - accuracy: 0.9488 - val_loss: 0.1632 - val_accuracy: 0.9398\n",
      "Epoch 204/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1391 - accuracy: 0.9488 - val_loss: 0.1631 - val_accuracy: 0.9400\n",
      "Epoch 205/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1389 - accuracy: 0.9489 - val_loss: 0.1629 - val_accuracy: 0.9400\n",
      "Epoch 206/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1387 - accuracy: 0.9489 - val_loss: 0.1635 - val_accuracy: 0.9400\n",
      "Epoch 207/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1386 - accuracy: 0.9490 - val_loss: 0.1626 - val_accuracy: 0.9402\n",
      "Epoch 208/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1385 - accuracy: 0.9489 - val_loss: 0.1628 - val_accuracy: 0.9400\n",
      "Epoch 209/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1383 - accuracy: 0.9492 - val_loss: 0.1627 - val_accuracy: 0.9400\n",
      "Epoch 210/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1382 - accuracy: 0.9491 - val_loss: 0.1627 - val_accuracy: 0.9400\n",
      "Epoch 211/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1380 - accuracy: 0.9492 - val_loss: 0.1627 - val_accuracy: 0.9398\n",
      "Epoch 212/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1378 - accuracy: 0.9492 - val_loss: 0.1623 - val_accuracy: 0.9404\n",
      "Epoch 213/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1377 - accuracy: 0.9492 - val_loss: 0.1630 - val_accuracy: 0.9401\n",
      "Epoch 214/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1376 - accuracy: 0.9493 - val_loss: 0.1620 - val_accuracy: 0.9404\n",
      "Epoch 215/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1374 - accuracy: 0.9493 - val_loss: 0.1624 - val_accuracy: 0.9400\n",
      "Epoch 216/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1373 - accuracy: 0.9493 - val_loss: 0.1614 - val_accuracy: 0.9407\n",
      "Epoch 217/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1371 - accuracy: 0.9495 - val_loss: 0.1616 - val_accuracy: 0.9404\n",
      "Epoch 218/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1370 - accuracy: 0.9493 - val_loss: 0.1612 - val_accuracy: 0.9410\n",
      "Epoch 219/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1369 - accuracy: 0.9496 - val_loss: 0.1615 - val_accuracy: 0.9405\n",
      "Epoch 220/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1367 - accuracy: 0.9495 - val_loss: 0.1619 - val_accuracy: 0.9408\n",
      "Epoch 221/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1365 - accuracy: 0.9495 - val_loss: 0.1615 - val_accuracy: 0.9410\n",
      "Epoch 222/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1364 - accuracy: 0.9496 - val_loss: 0.1610 - val_accuracy: 0.9407\n",
      "Epoch 223/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1363 - accuracy: 0.9497 - val_loss: 0.1608 - val_accuracy: 0.9411\n",
      "Epoch 224/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1361 - accuracy: 0.9497 - val_loss: 0.1608 - val_accuracy: 0.9407\n",
      "Epoch 225/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1360 - accuracy: 0.9497 - val_loss: 0.1610 - val_accuracy: 0.9409\n",
      "Epoch 226/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1358 - accuracy: 0.9497 - val_loss: 0.1603 - val_accuracy: 0.9410\n",
      "Epoch 227/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1357 - accuracy: 0.9499 - val_loss: 0.1606 - val_accuracy: 0.9411\n",
      "Epoch 228/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1356 - accuracy: 0.9497 - val_loss: 0.1611 - val_accuracy: 0.9406\n",
      "Epoch 229/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1355 - accuracy: 0.9499 - val_loss: 0.1604 - val_accuracy: 0.9406\n",
      "Epoch 230/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1353 - accuracy: 0.9500 - val_loss: 0.1604 - val_accuracy: 0.9413\n",
      "Epoch 231/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1352 - accuracy: 0.9500 - val_loss: 0.1601 - val_accuracy: 0.9409\n",
      "Epoch 232/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1350 - accuracy: 0.9499 - val_loss: 0.1603 - val_accuracy: 0.9414\n",
      "Epoch 233/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1349 - accuracy: 0.9500 - val_loss: 0.1594 - val_accuracy: 0.9410\n",
      "Epoch 234/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1347 - accuracy: 0.9500 - val_loss: 0.1596 - val_accuracy: 0.9408\n",
      "Epoch 235/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1346 - accuracy: 0.9501 - val_loss: 0.1593 - val_accuracy: 0.9412\n",
      "Epoch 236/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1345 - accuracy: 0.9501 - val_loss: 0.1595 - val_accuracy: 0.9411\n",
      "Epoch 237/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1343 - accuracy: 0.9502 - val_loss: 0.1594 - val_accuracy: 0.9413\n",
      "Epoch 238/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1342 - accuracy: 0.9502 - val_loss: 0.1593 - val_accuracy: 0.9419\n",
      "Epoch 239/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1341 - accuracy: 0.9501 - val_loss: 0.1601 - val_accuracy: 0.9410\n",
      "Epoch 240/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1340 - accuracy: 0.9501 - val_loss: 0.1597 - val_accuracy: 0.9413\n",
      "Epoch 241/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1339 - accuracy: 0.9503 - val_loss: 0.1598 - val_accuracy: 0.9413\n",
      "Epoch 242/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1338 - accuracy: 0.9502 - val_loss: 0.1592 - val_accuracy: 0.9417\n",
      "Epoch 243/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1336 - accuracy: 0.9504 - val_loss: 0.1585 - val_accuracy: 0.9419\n",
      "Epoch 244/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1334 - accuracy: 0.9503 - val_loss: 0.1590 - val_accuracy: 0.9413\n",
      "Epoch 245/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1333 - accuracy: 0.9505 - val_loss: 0.1593 - val_accuracy: 0.9416\n",
      "Epoch 246/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1333 - accuracy: 0.9504 - val_loss: 0.1589 - val_accuracy: 0.9414\n",
      "Epoch 247/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1330 - accuracy: 0.9505 - val_loss: 0.1593 - val_accuracy: 0.9409\n",
      "Epoch 248/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1330 - accuracy: 0.9506 - val_loss: 0.1584 - val_accuracy: 0.9416\n",
      "Epoch 249/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1328 - accuracy: 0.9505 - val_loss: 0.1586 - val_accuracy: 0.9414\n",
      "Epoch 250/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1327 - accuracy: 0.9504 - val_loss: 0.1586 - val_accuracy: 0.9417\n",
      "Epoch 251/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1325 - accuracy: 0.9506 - val_loss: 0.1580 - val_accuracy: 0.9420\n",
      "Epoch 252/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1324 - accuracy: 0.9507 - val_loss: 0.1586 - val_accuracy: 0.9420\n",
      "Epoch 253/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1323 - accuracy: 0.9506 - val_loss: 0.1583 - val_accuracy: 0.9414\n",
      "Epoch 254/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1323 - accuracy: 0.9505 - val_loss: 0.1585 - val_accuracy: 0.9413\n",
      "Epoch 255/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1321 - accuracy: 0.9507 - val_loss: 0.1584 - val_accuracy: 0.9418\n",
      "Epoch 256/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1320 - accuracy: 0.9506 - val_loss: 0.1585 - val_accuracy: 0.9413\n",
      "Epoch 257/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1319 - accuracy: 0.9508 - val_loss: 0.1582 - val_accuracy: 0.9415\n",
      "Epoch 258/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1317 - accuracy: 0.9505 - val_loss: 0.1577 - val_accuracy: 0.9418\n",
      "Epoch 259/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1316 - accuracy: 0.9506 - val_loss: 0.1577 - val_accuracy: 0.9417\n",
      "Epoch 260/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1315 - accuracy: 0.9507 - val_loss: 0.1572 - val_accuracy: 0.9416\n",
      "Epoch 261/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1314 - accuracy: 0.9507 - val_loss: 0.1579 - val_accuracy: 0.9422\n",
      "Epoch 262/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1313 - accuracy: 0.9509 - val_loss: 0.1575 - val_accuracy: 0.9416\n",
      "Epoch 263/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1312 - accuracy: 0.9509 - val_loss: 0.1580 - val_accuracy: 0.9417\n",
      "Epoch 264/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1311 - accuracy: 0.9510 - val_loss: 0.1577 - val_accuracy: 0.9416\n",
      "Epoch 265/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1309 - accuracy: 0.9511 - val_loss: 0.1577 - val_accuracy: 0.9417\n",
      "Epoch 266/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1308 - accuracy: 0.9509 - val_loss: 0.1582 - val_accuracy: 0.9413\n",
      "Epoch 267/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1307 - accuracy: 0.9511 - val_loss: 0.1570 - val_accuracy: 0.9419\n",
      "Epoch 268/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1305 - accuracy: 0.9510 - val_loss: 0.1574 - val_accuracy: 0.9417\n",
      "Epoch 269/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1305 - accuracy: 0.9511 - val_loss: 0.1569 - val_accuracy: 0.9416\n",
      "Epoch 270/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1305 - accuracy: 0.9509 - val_loss: 0.1568 - val_accuracy: 0.9420\n",
      "Epoch 271/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1303 - accuracy: 0.9509 - val_loss: 0.1568 - val_accuracy: 0.9423\n",
      "Epoch 272/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1302 - accuracy: 0.9512 - val_loss: 0.1573 - val_accuracy: 0.9418\n",
      "Epoch 273/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1301 - accuracy: 0.9510 - val_loss: 0.1567 - val_accuracy: 0.9421\n",
      "Epoch 274/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1299 - accuracy: 0.9512 - val_loss: 0.1571 - val_accuracy: 0.9420\n",
      "Epoch 275/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1298 - accuracy: 0.9511 - val_loss: 0.1569 - val_accuracy: 0.9422\n",
      "Epoch 276/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1297 - accuracy: 0.9511 - val_loss: 0.1571 - val_accuracy: 0.9417\n",
      "Epoch 277/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1296 - accuracy: 0.9514 - val_loss: 0.1563 - val_accuracy: 0.9411\n",
      "Epoch 278/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1295 - accuracy: 0.9514 - val_loss: 0.1570 - val_accuracy: 0.9421\n",
      "Epoch 279/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1294 - accuracy: 0.9516 - val_loss: 0.1569 - val_accuracy: 0.9416\n",
      "Epoch 280/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1293 - accuracy: 0.9513 - val_loss: 0.1563 - val_accuracy: 0.9418\n",
      "Epoch 281/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1291 - accuracy: 0.9513 - val_loss: 0.1569 - val_accuracy: 0.9418\n",
      "Epoch 282/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1291 - accuracy: 0.9513 - val_loss: 0.1564 - val_accuracy: 0.9418\n",
      "Epoch 283/800\n",
      "6000/6000 [==============================] - 1s 94us/step - loss: 0.1289 - accuracy: 0.9514 - val_loss: 0.1564 - val_accuracy: 0.9417\n",
      "Epoch 284/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1288 - accuracy: 0.9513 - val_loss: 0.1563 - val_accuracy: 0.9416\n",
      "Epoch 285/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1287 - accuracy: 0.9516 - val_loss: 0.1562 - val_accuracy: 0.9419\n",
      "Epoch 286/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1286 - accuracy: 0.9514 - val_loss: 0.1564 - val_accuracy: 0.9423\n",
      "Epoch 287/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.1287 - accuracy: 0.9514 - val_loss: 0.1561 - val_accuracy: 0.9421\n",
      "Epoch 288/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1284 - accuracy: 0.9517 - val_loss: 0.1564 - val_accuracy: 0.9420\n",
      "Epoch 289/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1283 - accuracy: 0.9517 - val_loss: 0.1555 - val_accuracy: 0.9419\n",
      "Epoch 290/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1282 - accuracy: 0.9513 - val_loss: 0.1554 - val_accuracy: 0.9421\n",
      "Epoch 291/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1282 - accuracy: 0.9517 - val_loss: 0.1556 - val_accuracy: 0.9424\n",
      "Epoch 292/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1280 - accuracy: 0.9517 - val_loss: 0.1562 - val_accuracy: 0.9423\n",
      "Epoch 293/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1279 - accuracy: 0.9516 - val_loss: 0.1560 - val_accuracy: 0.9421\n",
      "Epoch 294/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1278 - accuracy: 0.9517 - val_loss: 0.1563 - val_accuracy: 0.9420\n",
      "Epoch 295/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1277 - accuracy: 0.9519 - val_loss: 0.1558 - val_accuracy: 0.9416\n",
      "Epoch 296/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1276 - accuracy: 0.9516 - val_loss: 0.1565 - val_accuracy: 0.9419\n",
      "Epoch 297/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1275 - accuracy: 0.9517 - val_loss: 0.1553 - val_accuracy: 0.9420\n",
      "Epoch 298/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1274 - accuracy: 0.9520 - val_loss: 0.1559 - val_accuracy: 0.9420\n",
      "Epoch 299/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1273 - accuracy: 0.9520 - val_loss: 0.1561 - val_accuracy: 0.9419\n",
      "Epoch 300/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1272 - accuracy: 0.9518 - val_loss: 0.1557 - val_accuracy: 0.9421\n",
      "Epoch 301/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1271 - accuracy: 0.9519 - val_loss: 0.1556 - val_accuracy: 0.9422\n",
      "Epoch 302/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1270 - accuracy: 0.9517 - val_loss: 0.1557 - val_accuracy: 0.9416\n",
      "Epoch 303/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1269 - accuracy: 0.9518 - val_loss: 0.1552 - val_accuracy: 0.9418\n",
      "Epoch 304/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1269 - accuracy: 0.9519 - val_loss: 0.1548 - val_accuracy: 0.9418\n",
      "Epoch 305/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1268 - accuracy: 0.9520 - val_loss: 0.1553 - val_accuracy: 0.9423\n",
      "Epoch 306/800\n",
      "6000/6000 [==============================] - 1s 87us/step - loss: 0.1265 - accuracy: 0.9522 - val_loss: 0.1555 - val_accuracy: 0.9420\n",
      "Epoch 307/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1265 - accuracy: 0.9522 - val_loss: 0.1552 - val_accuracy: 0.9424\n",
      "Epoch 308/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1265 - accuracy: 0.9520 - val_loss: 0.1552 - val_accuracy: 0.9420\n",
      "Epoch 309/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1263 - accuracy: 0.9520 - val_loss: 0.1548 - val_accuracy: 0.9414\n",
      "Epoch 310/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1263 - accuracy: 0.9521 - val_loss: 0.1559 - val_accuracy: 0.9424\n",
      "Epoch 311/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1262 - accuracy: 0.9520 - val_loss: 0.1549 - val_accuracy: 0.9423\n",
      "Epoch 312/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1260 - accuracy: 0.9520 - val_loss: 0.1556 - val_accuracy: 0.9420\n",
      "Epoch 313/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1260 - accuracy: 0.9520 - val_loss: 0.1545 - val_accuracy: 0.9423\n",
      "Epoch 314/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1257 - accuracy: 0.9522 - val_loss: 0.1558 - val_accuracy: 0.9411\n",
      "Epoch 315/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1258 - accuracy: 0.9521 - val_loss: 0.1551 - val_accuracy: 0.9420\n",
      "Epoch 316/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1256 - accuracy: 0.9521 - val_loss: 0.1560 - val_accuracy: 0.9417\n",
      "Epoch 317/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1256 - accuracy: 0.9523 - val_loss: 0.1557 - val_accuracy: 0.9412\n",
      "Epoch 318/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1255 - accuracy: 0.9521 - val_loss: 0.1544 - val_accuracy: 0.9420\n",
      "Epoch 319/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1255 - accuracy: 0.9522 - val_loss: 0.1549 - val_accuracy: 0.9423\n",
      "Epoch 320/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1253 - accuracy: 0.9522 - val_loss: 0.1555 - val_accuracy: 0.9417\n",
      "Epoch 321/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1252 - accuracy: 0.9523 - val_loss: 0.1549 - val_accuracy: 0.9424\n",
      "Epoch 322/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1252 - accuracy: 0.9522 - val_loss: 0.1546 - val_accuracy: 0.9420\n",
      "Epoch 323/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1249 - accuracy: 0.9524 - val_loss: 0.1544 - val_accuracy: 0.9428\n",
      "Epoch 324/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1250 - accuracy: 0.9522 - val_loss: 0.1545 - val_accuracy: 0.9422\n",
      "Epoch 325/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1248 - accuracy: 0.9525 - val_loss: 0.1548 - val_accuracy: 0.9425\n",
      "Epoch 326/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1248 - accuracy: 0.9523 - val_loss: 0.1543 - val_accuracy: 0.9420\n",
      "Epoch 327/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1247 - accuracy: 0.9524 - val_loss: 0.1540 - val_accuracy: 0.9420\n",
      "Epoch 328/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1246 - accuracy: 0.9522 - val_loss: 0.1546 - val_accuracy: 0.9428\n",
      "Epoch 329/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1244 - accuracy: 0.9527 - val_loss: 0.1538 - val_accuracy: 0.9426\n",
      "Epoch 330/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1243 - accuracy: 0.9525 - val_loss: 0.1546 - val_accuracy: 0.9420\n",
      "Epoch 331/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1243 - accuracy: 0.9524 - val_loss: 0.1546 - val_accuracy: 0.9418\n",
      "Epoch 332/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1242 - accuracy: 0.9525 - val_loss: 0.1545 - val_accuracy: 0.9428\n",
      "Epoch 333/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1240 - accuracy: 0.9525 - val_loss: 0.1548 - val_accuracy: 0.9418\n",
      "Epoch 334/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1241 - accuracy: 0.9525 - val_loss: 0.1538 - val_accuracy: 0.9425\n",
      "Epoch 335/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1239 - accuracy: 0.9528 - val_loss: 0.1545 - val_accuracy: 0.9427\n",
      "Epoch 336/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1238 - accuracy: 0.9527 - val_loss: 0.1539 - val_accuracy: 0.9418\n",
      "Epoch 337/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1237 - accuracy: 0.9527 - val_loss: 0.1541 - val_accuracy: 0.9425\n",
      "Epoch 338/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1237 - accuracy: 0.9526 - val_loss: 0.1538 - val_accuracy: 0.9429\n",
      "Epoch 339/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1236 - accuracy: 0.9528 - val_loss: 0.1544 - val_accuracy: 0.9426\n",
      "Epoch 340/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1235 - accuracy: 0.9526 - val_loss: 0.1538 - val_accuracy: 0.9420\n",
      "Epoch 341/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1235 - accuracy: 0.9527 - val_loss: 0.1537 - val_accuracy: 0.9425\n",
      "Epoch 342/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1234 - accuracy: 0.9528 - val_loss: 0.1541 - val_accuracy: 0.9423\n",
      "Epoch 343/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1233 - accuracy: 0.9528 - val_loss: 0.1540 - val_accuracy: 0.9425\n",
      "Epoch 344/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1231 - accuracy: 0.9530 - val_loss: 0.1539 - val_accuracy: 0.9423\n",
      "Epoch 345/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1231 - accuracy: 0.9529 - val_loss: 0.1541 - val_accuracy: 0.9420\n",
      "Epoch 346/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1230 - accuracy: 0.9528 - val_loss: 0.1535 - val_accuracy: 0.9424\n",
      "Epoch 347/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1229 - accuracy: 0.9529 - val_loss: 0.1556 - val_accuracy: 0.9411\n",
      "Epoch 348/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1228 - accuracy: 0.9530 - val_loss: 0.1535 - val_accuracy: 0.9430\n",
      "Epoch 349/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1227 - accuracy: 0.9530 - val_loss: 0.1534 - val_accuracy: 0.9426\n",
      "Epoch 350/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1227 - accuracy: 0.9529 - val_loss: 0.1544 - val_accuracy: 0.9424\n",
      "Epoch 351/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1226 - accuracy: 0.9530 - val_loss: 0.1540 - val_accuracy: 0.9423\n",
      "Epoch 352/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1225 - accuracy: 0.9527 - val_loss: 0.1540 - val_accuracy: 0.9424\n",
      "Epoch 353/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1225 - accuracy: 0.9529 - val_loss: 0.1539 - val_accuracy: 0.9422\n",
      "Epoch 354/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1223 - accuracy: 0.9530 - val_loss: 0.1534 - val_accuracy: 0.9425\n",
      "Epoch 355/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1222 - accuracy: 0.9531 - val_loss: 0.1540 - val_accuracy: 0.9424\n",
      "Epoch 356/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1221 - accuracy: 0.9531 - val_loss: 0.1540 - val_accuracy: 0.9424\n",
      "Epoch 357/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1221 - accuracy: 0.9532 - val_loss: 0.1536 - val_accuracy: 0.9423\n",
      "Epoch 358/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1219 - accuracy: 0.9531 - val_loss: 0.1539 - val_accuracy: 0.9424\n",
      "Epoch 359/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1219 - accuracy: 0.9532 - val_loss: 0.1534 - val_accuracy: 0.9427\n",
      "Epoch 360/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1218 - accuracy: 0.9532 - val_loss: 0.1535 - val_accuracy: 0.9424\n",
      "Epoch 361/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1217 - accuracy: 0.9530 - val_loss: 0.1535 - val_accuracy: 0.9423\n",
      "Epoch 362/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1216 - accuracy: 0.9530 - val_loss: 0.1537 - val_accuracy: 0.9420\n",
      "Epoch 363/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1215 - accuracy: 0.9533 - val_loss: 0.1535 - val_accuracy: 0.9415\n",
      "Epoch 364/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1215 - accuracy: 0.9530 - val_loss: 0.1545 - val_accuracy: 0.9424\n",
      "Epoch 365/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1215 - accuracy: 0.9533 - val_loss: 0.1537 - val_accuracy: 0.9420\n",
      "Epoch 366/800\n",
      "6000/6000 [==============================] - 0s 67us/step - loss: 0.1213 - accuracy: 0.9534 - val_loss: 0.1532 - val_accuracy: 0.9425\n",
      "Epoch 367/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1213 - accuracy: 0.9534 - val_loss: 0.1536 - val_accuracy: 0.9416\n",
      "Epoch 368/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1211 - accuracy: 0.9533 - val_loss: 0.1536 - val_accuracy: 0.9426\n",
      "Epoch 369/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1211 - accuracy: 0.9532 - val_loss: 0.1533 - val_accuracy: 0.9428\n",
      "Epoch 370/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1210 - accuracy: 0.9533 - val_loss: 0.1543 - val_accuracy: 0.9419\n",
      "Epoch 371/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1209 - accuracy: 0.9536 - val_loss: 0.1533 - val_accuracy: 0.9421\n",
      "Epoch 372/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1208 - accuracy: 0.9535 - val_loss: 0.1533 - val_accuracy: 0.9424\n",
      "Epoch 373/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1207 - accuracy: 0.9534 - val_loss: 0.1529 - val_accuracy: 0.9424\n",
      "Epoch 374/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1207 - accuracy: 0.9534 - val_loss: 0.1532 - val_accuracy: 0.9428\n",
      "Epoch 375/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1206 - accuracy: 0.9534 - val_loss: 0.1534 - val_accuracy: 0.9423\n",
      "Epoch 376/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1206 - accuracy: 0.9534 - val_loss: 0.1532 - val_accuracy: 0.9424\n",
      "Epoch 377/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1205 - accuracy: 0.9536 - val_loss: 0.1533 - val_accuracy: 0.9417\n",
      "Epoch 378/800\n",
      "6000/6000 [==============================] - 0s 67us/step - loss: 0.1204 - accuracy: 0.9534 - val_loss: 0.1531 - val_accuracy: 0.9429\n",
      "Epoch 379/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1204 - accuracy: 0.9535 - val_loss: 0.1529 - val_accuracy: 0.9427\n",
      "Epoch 380/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1203 - accuracy: 0.9538 - val_loss: 0.1532 - val_accuracy: 0.9427\n",
      "Epoch 381/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1202 - accuracy: 0.9533 - val_loss: 0.1527 - val_accuracy: 0.9425\n",
      "Epoch 382/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1201 - accuracy: 0.9534 - val_loss: 0.1534 - val_accuracy: 0.9421\n",
      "Epoch 383/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1200 - accuracy: 0.9535 - val_loss: 0.1539 - val_accuracy: 0.9431\n",
      "Epoch 384/800\n",
      "6000/6000 [==============================] - 0s 67us/step - loss: 0.1199 - accuracy: 0.9538 - val_loss: 0.1526 - val_accuracy: 0.9430\n",
      "Epoch 385/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1198 - accuracy: 0.9536 - val_loss: 0.1531 - val_accuracy: 0.9418\n",
      "Epoch 386/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1197 - accuracy: 0.9539 - val_loss: 0.1535 - val_accuracy: 0.9424\n",
      "Epoch 387/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1197 - accuracy: 0.9536 - val_loss: 0.1534 - val_accuracy: 0.9421\n",
      "Epoch 388/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1197 - accuracy: 0.9538 - val_loss: 0.1531 - val_accuracy: 0.9421\n",
      "Epoch 389/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1194 - accuracy: 0.9535 - val_loss: 0.1532 - val_accuracy: 0.9424\n",
      "Epoch 390/800\n",
      "6000/6000 [==============================] - 0s 67us/step - loss: 0.1195 - accuracy: 0.9538 - val_loss: 0.1527 - val_accuracy: 0.9425\n",
      "Epoch 391/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1194 - accuracy: 0.9539 - val_loss: 0.1530 - val_accuracy: 0.9428\n",
      "Epoch 392/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1193 - accuracy: 0.9537 - val_loss: 0.1538 - val_accuracy: 0.9429\n",
      "Epoch 393/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1192 - accuracy: 0.9537 - val_loss: 0.1529 - val_accuracy: 0.9419\n",
      "Epoch 394/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1192 - accuracy: 0.9536 - val_loss: 0.1535 - val_accuracy: 0.9420\n",
      "Epoch 395/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1191 - accuracy: 0.9539 - val_loss: 0.1531 - val_accuracy: 0.9426\n",
      "Epoch 396/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1191 - accuracy: 0.9539 - val_loss: 0.1524 - val_accuracy: 0.9423\n",
      "Epoch 397/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1190 - accuracy: 0.9541 - val_loss: 0.1528 - val_accuracy: 0.9428\n",
      "Epoch 398/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1189 - accuracy: 0.9539 - val_loss: 0.1531 - val_accuracy: 0.9422\n",
      "Epoch 399/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1188 - accuracy: 0.9540 - val_loss: 0.1534 - val_accuracy: 0.9420\n",
      "Epoch 400/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1188 - accuracy: 0.9539 - val_loss: 0.1530 - val_accuracy: 0.9424\n",
      "Epoch 401/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1187 - accuracy: 0.9541 - val_loss: 0.1529 - val_accuracy: 0.9425\n",
      "Epoch 402/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1186 - accuracy: 0.9543 - val_loss: 0.1531 - val_accuracy: 0.9425\n",
      "Epoch 403/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1185 - accuracy: 0.9540 - val_loss: 0.1528 - val_accuracy: 0.9426\n",
      "Epoch 404/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1185 - accuracy: 0.9540 - val_loss: 0.1525 - val_accuracy: 0.9422\n",
      "Epoch 405/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1184 - accuracy: 0.9541 - val_loss: 0.1539 - val_accuracy: 0.9422\n",
      "Epoch 406/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1183 - accuracy: 0.9543 - val_loss: 0.1535 - val_accuracy: 0.9424\n",
      "Epoch 407/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1182 - accuracy: 0.9541 - val_loss: 0.1527 - val_accuracy: 0.9428\n",
      "Epoch 408/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1182 - accuracy: 0.9542 - val_loss: 0.1533 - val_accuracy: 0.9422\n",
      "Epoch 409/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1181 - accuracy: 0.9541 - val_loss: 0.1529 - val_accuracy: 0.9430\n",
      "Epoch 410/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1180 - accuracy: 0.9542 - val_loss: 0.1531 - val_accuracy: 0.9421\n",
      "Epoch 411/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1178 - accuracy: 0.9544 - val_loss: 0.1542 - val_accuracy: 0.9422\n",
      "Epoch 412/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1179 - accuracy: 0.9543 - val_loss: 0.1534 - val_accuracy: 0.9422\n",
      "Epoch 413/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1178 - accuracy: 0.9544 - val_loss: 0.1532 - val_accuracy: 0.9423\n",
      "Epoch 414/800\n",
      "6000/6000 [==============================] - 0s 67us/step - loss: 0.1178 - accuracy: 0.9542 - val_loss: 0.1532 - val_accuracy: 0.9425\n",
      "Epoch 415/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1176 - accuracy: 0.9544 - val_loss: 0.1534 - val_accuracy: 0.9422\n",
      "Epoch 416/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1176 - accuracy: 0.9543 - val_loss: 0.1529 - val_accuracy: 0.9419\n",
      "Epoch 417/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1175 - accuracy: 0.9545 - val_loss: 0.1526 - val_accuracy: 0.9422\n",
      "Epoch 418/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1175 - accuracy: 0.9542 - val_loss: 0.1530 - val_accuracy: 0.9424\n",
      "Epoch 419/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1174 - accuracy: 0.9546 - val_loss: 0.1542 - val_accuracy: 0.9425\n",
      "Epoch 420/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1175 - accuracy: 0.9545 - val_loss: 0.1531 - val_accuracy: 0.9423\n",
      "Epoch 421/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1173 - accuracy: 0.9543 - val_loss: 0.1532 - val_accuracy: 0.9425\n",
      "Epoch 422/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1172 - accuracy: 0.9543 - val_loss: 0.1535 - val_accuracy: 0.9419\n",
      "Epoch 423/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1172 - accuracy: 0.9545 - val_loss: 0.1532 - val_accuracy: 0.9419\n",
      "Epoch 424/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1170 - accuracy: 0.9544 - val_loss: 0.1536 - val_accuracy: 0.9424\n",
      "Epoch 425/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1169 - accuracy: 0.9546 - val_loss: 0.1529 - val_accuracy: 0.9419\n",
      "Epoch 426/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1169 - accuracy: 0.9546 - val_loss: 0.1531 - val_accuracy: 0.9421\n",
      "Epoch 427/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1169 - accuracy: 0.9546 - val_loss: 0.1530 - val_accuracy: 0.9421\n",
      "Epoch 428/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1167 - accuracy: 0.9546 - val_loss: 0.1532 - val_accuracy: 0.9425\n",
      "Epoch 429/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1166 - accuracy: 0.9547 - val_loss: 0.1538 - val_accuracy: 0.9426\n",
      "Epoch 430/800\n",
      "6000/6000 [==============================] - 0s 67us/step - loss: 0.1166 - accuracy: 0.9546 - val_loss: 0.1538 - val_accuracy: 0.9420\n",
      "Epoch 431/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1167 - accuracy: 0.9549 - val_loss: 0.1528 - val_accuracy: 0.9423\n",
      "Epoch 432/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1165 - accuracy: 0.9549 - val_loss: 0.1538 - val_accuracy: 0.9421\n",
      "Epoch 433/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1164 - accuracy: 0.9547 - val_loss: 0.1529 - val_accuracy: 0.9426\n",
      "Epoch 434/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1163 - accuracy: 0.9547 - val_loss: 0.1540 - val_accuracy: 0.9417\n",
      "Epoch 435/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1162 - accuracy: 0.9548 - val_loss: 0.1530 - val_accuracy: 0.9428\n",
      "Epoch 436/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1162 - accuracy: 0.9548 - val_loss: 0.1536 - val_accuracy: 0.9426\n",
      "Epoch 437/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1161 - accuracy: 0.9548 - val_loss: 0.1535 - val_accuracy: 0.9428\n",
      "Epoch 438/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1160 - accuracy: 0.9549 - val_loss: 0.1535 - val_accuracy: 0.9424\n",
      "Epoch 439/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1160 - accuracy: 0.9547 - val_loss: 0.1536 - val_accuracy: 0.9423\n",
      "Epoch 440/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1161 - accuracy: 0.9546 - val_loss: 0.1538 - val_accuracy: 0.9423\n",
      "Epoch 441/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1159 - accuracy: 0.9548 - val_loss: 0.1538 - val_accuracy: 0.9420\n",
      "Epoch 442/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1158 - accuracy: 0.9551 - val_loss: 0.1535 - val_accuracy: 0.9424\n",
      "Epoch 443/800\n",
      "6000/6000 [==============================] - 0s 67us/step - loss: 0.1157 - accuracy: 0.9550 - val_loss: 0.1539 - val_accuracy: 0.9425\n",
      "Epoch 444/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1157 - accuracy: 0.9551 - val_loss: 0.1532 - val_accuracy: 0.9422\n",
      "Epoch 445/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1157 - accuracy: 0.9549 - val_loss: 0.1532 - val_accuracy: 0.9413\n",
      "Epoch 446/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1156 - accuracy: 0.9548 - val_loss: 0.1538 - val_accuracy: 0.9426\n",
      "Epoch 447/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1155 - accuracy: 0.9550 - val_loss: 0.1531 - val_accuracy: 0.9421\n",
      "Epoch 448/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1155 - accuracy: 0.9549 - val_loss: 0.1537 - val_accuracy: 0.9422\n",
      "Epoch 449/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1154 - accuracy: 0.9552 - val_loss: 0.1539 - val_accuracy: 0.9417\n",
      "Epoch 450/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1153 - accuracy: 0.9550 - val_loss: 0.1532 - val_accuracy: 0.9420\n",
      "Epoch 451/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1152 - accuracy: 0.9552 - val_loss: 0.1530 - val_accuracy: 0.9415\n",
      "Epoch 452/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1152 - accuracy: 0.9552 - val_loss: 0.1560 - val_accuracy: 0.9412\n",
      "Epoch 453/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1151 - accuracy: 0.9549 - val_loss: 0.1539 - val_accuracy: 0.9416\n",
      "Epoch 454/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1150 - accuracy: 0.9552 - val_loss: 0.1537 - val_accuracy: 0.9417\n",
      "Epoch 455/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1150 - accuracy: 0.9552 - val_loss: 0.1537 - val_accuracy: 0.9416\n",
      "Epoch 456/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1149 - accuracy: 0.9553 - val_loss: 0.1533 - val_accuracy: 0.9412\n",
      "Epoch 457/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1149 - accuracy: 0.9552 - val_loss: 0.1532 - val_accuracy: 0.9423\n",
      "Epoch 458/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1149 - accuracy: 0.9551 - val_loss: 0.1539 - val_accuracy: 0.9411\n",
      "Epoch 459/800\n",
      "6000/6000 [==============================] - 0s 67us/step - loss: 0.1147 - accuracy: 0.9553 - val_loss: 0.1536 - val_accuracy: 0.9422\n",
      "Epoch 460/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1147 - accuracy: 0.9552 - val_loss: 0.1539 - val_accuracy: 0.9415\n",
      "Epoch 461/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1146 - accuracy: 0.9556 - val_loss: 0.1539 - val_accuracy: 0.9420\n",
      "Epoch 462/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1145 - accuracy: 0.9554 - val_loss: 0.1539 - val_accuracy: 0.9412\n",
      "Epoch 463/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1145 - accuracy: 0.9553 - val_loss: 0.1537 - val_accuracy: 0.9423\n",
      "Epoch 464/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1144 - accuracy: 0.9554 - val_loss: 0.1541 - val_accuracy: 0.9419\n",
      "Epoch 465/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1143 - accuracy: 0.9554 - val_loss: 0.1538 - val_accuracy: 0.9417\n",
      "Epoch 466/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1143 - accuracy: 0.9556 - val_loss: 0.1539 - val_accuracy: 0.9423\n",
      "Epoch 467/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1142 - accuracy: 0.9555 - val_loss: 0.1540 - val_accuracy: 0.9419\n",
      "Epoch 468/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1141 - accuracy: 0.9556 - val_loss: 0.1532 - val_accuracy: 0.9420\n",
      "Epoch 469/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1140 - accuracy: 0.9553 - val_loss: 0.1536 - val_accuracy: 0.9419\n",
      "Epoch 470/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1140 - accuracy: 0.9555 - val_loss: 0.1539 - val_accuracy: 0.9425\n",
      "Epoch 471/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1139 - accuracy: 0.9554 - val_loss: 0.1539 - val_accuracy: 0.9421\n",
      "Epoch 472/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1138 - accuracy: 0.9556 - val_loss: 0.1532 - val_accuracy: 0.9421\n",
      "Epoch 473/800\n",
      "6000/6000 [==============================] - 0s 67us/step - loss: 0.1138 - accuracy: 0.9558 - val_loss: 0.1536 - val_accuracy: 0.9423\n",
      "Epoch 474/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1137 - accuracy: 0.9557 - val_loss: 0.1539 - val_accuracy: 0.9420\n",
      "Epoch 475/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1136 - accuracy: 0.9556 - val_loss: 0.1539 - val_accuracy: 0.9425\n",
      "Epoch 476/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1136 - accuracy: 0.9556 - val_loss: 0.1549 - val_accuracy: 0.9404\n",
      "Epoch 477/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1135 - accuracy: 0.9556 - val_loss: 0.1542 - val_accuracy: 0.9418\n",
      "Epoch 478/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1134 - accuracy: 0.9556 - val_loss: 0.1551 - val_accuracy: 0.9412\n",
      "Epoch 479/800\n",
      "6000/6000 [==============================] - 0s 67us/step - loss: 0.1135 - accuracy: 0.9556 - val_loss: 0.1543 - val_accuracy: 0.9417\n",
      "Epoch 480/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1134 - accuracy: 0.9557 - val_loss: 0.1545 - val_accuracy: 0.9421\n",
      "Epoch 481/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1133 - accuracy: 0.9559 - val_loss: 0.1537 - val_accuracy: 0.9411\n",
      "Epoch 482/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1131 - accuracy: 0.9559 - val_loss: 0.1548 - val_accuracy: 0.9414\n",
      "Epoch 483/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1133 - accuracy: 0.9558 - val_loss: 0.1538 - val_accuracy: 0.9419\n",
      "Epoch 484/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1131 - accuracy: 0.9560 - val_loss: 0.1543 - val_accuracy: 0.9418\n",
      "Epoch 485/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1130 - accuracy: 0.9558 - val_loss: 0.1543 - val_accuracy: 0.9417\n",
      "Epoch 486/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1130 - accuracy: 0.9559 - val_loss: 0.1536 - val_accuracy: 0.9420\n",
      "Epoch 487/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1129 - accuracy: 0.9558 - val_loss: 0.1544 - val_accuracy: 0.9417\n",
      "Epoch 488/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1128 - accuracy: 0.9559 - val_loss: 0.1542 - val_accuracy: 0.9423\n",
      "Epoch 489/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1129 - accuracy: 0.9560 - val_loss: 0.1541 - val_accuracy: 0.9422\n",
      "Epoch 490/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1128 - accuracy: 0.9558 - val_loss: 0.1544 - val_accuracy: 0.9405\n",
      "Epoch 491/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1127 - accuracy: 0.9562 - val_loss: 0.1544 - val_accuracy: 0.9413\n",
      "Epoch 492/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1127 - accuracy: 0.9561 - val_loss: 0.1542 - val_accuracy: 0.9420\n",
      "Epoch 493/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1125 - accuracy: 0.9562 - val_loss: 0.1542 - val_accuracy: 0.9418\n",
      "Epoch 494/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1124 - accuracy: 0.9563 - val_loss: 0.1533 - val_accuracy: 0.9418\n",
      "Epoch 495/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1124 - accuracy: 0.9563 - val_loss: 0.1541 - val_accuracy: 0.9419\n",
      "Epoch 496/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1123 - accuracy: 0.9563 - val_loss: 0.1553 - val_accuracy: 0.9416\n",
      "Epoch 497/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1122 - accuracy: 0.9564 - val_loss: 0.1554 - val_accuracy: 0.9415\n",
      "Epoch 498/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1123 - accuracy: 0.9564 - val_loss: 0.1544 - val_accuracy: 0.9411\n",
      "Epoch 499/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1122 - accuracy: 0.9562 - val_loss: 0.1542 - val_accuracy: 0.9418\n",
      "Epoch 500/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1121 - accuracy: 0.9563 - val_loss: 0.1543 - val_accuracy: 0.9415\n",
      "Epoch 501/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1120 - accuracy: 0.9563 - val_loss: 0.1546 - val_accuracy: 0.9414\n",
      "Epoch 502/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1119 - accuracy: 0.9566 - val_loss: 0.1542 - val_accuracy: 0.9414\n",
      "Epoch 503/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1118 - accuracy: 0.9564 - val_loss: 0.1560 - val_accuracy: 0.9408\n",
      "Epoch 504/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1118 - accuracy: 0.9564 - val_loss: 0.1548 - val_accuracy: 0.9415\n",
      "Epoch 505/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1117 - accuracy: 0.9565 - val_loss: 0.1548 - val_accuracy: 0.9415\n",
      "Epoch 506/800\n",
      "6000/6000 [==============================] - 0s 67us/step - loss: 0.1117 - accuracy: 0.9566 - val_loss: 0.1554 - val_accuracy: 0.9405\n",
      "Epoch 507/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1117 - accuracy: 0.9564 - val_loss: 0.1546 - val_accuracy: 0.9420\n",
      "Epoch 508/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1116 - accuracy: 0.9564 - val_loss: 0.1547 - val_accuracy: 0.9414\n",
      "Epoch 509/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1116 - accuracy: 0.9563 - val_loss: 0.1540 - val_accuracy: 0.9420\n",
      "Epoch 510/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1114 - accuracy: 0.9566 - val_loss: 0.1555 - val_accuracy: 0.9407\n",
      "Epoch 511/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1114 - accuracy: 0.9565 - val_loss: 0.1547 - val_accuracy: 0.9418\n",
      "Epoch 512/800\n",
      "6000/6000 [==============================] - 1s 92us/step - loss: 0.1114 - accuracy: 0.9565 - val_loss: 0.1546 - val_accuracy: 0.9413\n",
      "Epoch 513/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1112 - accuracy: 0.9567 - val_loss: 0.1549 - val_accuracy: 0.9412\n",
      "Epoch 514/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1112 - accuracy: 0.9564 - val_loss: 0.1563 - val_accuracy: 0.9406\n",
      "Epoch 515/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1112 - accuracy: 0.9567 - val_loss: 0.1556 - val_accuracy: 0.9402\n",
      "Epoch 516/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1111 - accuracy: 0.9564 - val_loss: 0.1547 - val_accuracy: 0.9418\n",
      "Epoch 517/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1110 - accuracy: 0.9565 - val_loss: 0.1547 - val_accuracy: 0.9416\n",
      "Epoch 518/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1109 - accuracy: 0.9567 - val_loss: 0.1549 - val_accuracy: 0.9409\n",
      "Epoch 519/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1109 - accuracy: 0.9568 - val_loss: 0.1552 - val_accuracy: 0.9417\n",
      "Epoch 520/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1108 - accuracy: 0.9569 - val_loss: 0.1558 - val_accuracy: 0.9411\n",
      "Epoch 521/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1108 - accuracy: 0.9566 - val_loss: 0.1549 - val_accuracy: 0.9414\n",
      "Epoch 522/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1106 - accuracy: 0.9570 - val_loss: 0.1551 - val_accuracy: 0.9415\n",
      "Epoch 523/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1106 - accuracy: 0.9569 - val_loss: 0.1556 - val_accuracy: 0.9417\n",
      "Epoch 524/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1105 - accuracy: 0.9568 - val_loss: 0.1549 - val_accuracy: 0.9412\n",
      "Epoch 525/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1106 - accuracy: 0.9567 - val_loss: 0.1552 - val_accuracy: 0.9417\n",
      "Epoch 526/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1105 - accuracy: 0.9570 - val_loss: 0.1550 - val_accuracy: 0.9414\n",
      "Epoch 527/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1104 - accuracy: 0.9565 - val_loss: 0.1555 - val_accuracy: 0.9411\n",
      "Epoch 528/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1103 - accuracy: 0.9569 - val_loss: 0.1554 - val_accuracy: 0.9408\n",
      "Epoch 529/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1102 - accuracy: 0.9571 - val_loss: 0.1564 - val_accuracy: 0.9411\n",
      "Epoch 530/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1102 - accuracy: 0.9569 - val_loss: 0.1543 - val_accuracy: 0.9412\n",
      "Epoch 531/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1101 - accuracy: 0.9570 - val_loss: 0.1556 - val_accuracy: 0.9415\n",
      "Epoch 532/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1101 - accuracy: 0.9569 - val_loss: 0.1553 - val_accuracy: 0.9414\n",
      "Epoch 533/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1100 - accuracy: 0.9568 - val_loss: 0.1567 - val_accuracy: 0.9416\n",
      "Epoch 534/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1099 - accuracy: 0.9571 - val_loss: 0.1554 - val_accuracy: 0.9413\n",
      "Epoch 535/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1099 - accuracy: 0.9569 - val_loss: 0.1556 - val_accuracy: 0.9414\n",
      "Epoch 536/800\n",
      "6000/6000 [==============================] - 0s 67us/step - loss: 0.1098 - accuracy: 0.9572 - val_loss: 0.1556 - val_accuracy: 0.9413\n",
      "Epoch 537/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1098 - accuracy: 0.9571 - val_loss: 0.1552 - val_accuracy: 0.9417\n",
      "Epoch 538/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1096 - accuracy: 0.9572 - val_loss: 0.1566 - val_accuracy: 0.9405\n",
      "Epoch 539/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1096 - accuracy: 0.9573 - val_loss: 0.1557 - val_accuracy: 0.9410\n",
      "Epoch 540/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1095 - accuracy: 0.9572 - val_loss: 0.1560 - val_accuracy: 0.9413\n",
      "Epoch 541/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1095 - accuracy: 0.9572 - val_loss: 0.1553 - val_accuracy: 0.9405\n",
      "Epoch 542/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1094 - accuracy: 0.9572 - val_loss: 0.1559 - val_accuracy: 0.9416\n",
      "Epoch 543/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1094 - accuracy: 0.9572 - val_loss: 0.1565 - val_accuracy: 0.9413\n",
      "Epoch 544/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1093 - accuracy: 0.9573 - val_loss: 0.1563 - val_accuracy: 0.9410\n",
      "Epoch 545/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1092 - accuracy: 0.9576 - val_loss: 0.1562 - val_accuracy: 0.9418\n",
      "Epoch 546/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1093 - accuracy: 0.9574 - val_loss: 0.1550 - val_accuracy: 0.9413\n",
      "Epoch 547/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1091 - accuracy: 0.9573 - val_loss: 0.1554 - val_accuracy: 0.9420\n",
      "Epoch 548/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1091 - accuracy: 0.9571 - val_loss: 0.1554 - val_accuracy: 0.9406\n",
      "Epoch 549/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1091 - accuracy: 0.9573 - val_loss: 0.1565 - val_accuracy: 0.9408\n",
      "Epoch 550/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1090 - accuracy: 0.9574 - val_loss: 0.1568 - val_accuracy: 0.9400\n",
      "Epoch 551/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1089 - accuracy: 0.9574 - val_loss: 0.1560 - val_accuracy: 0.9415\n",
      "Epoch 552/800\n",
      "6000/6000 [==============================] - 0s 67us/step - loss: 0.1089 - accuracy: 0.9574 - val_loss: 0.1554 - val_accuracy: 0.9413\n",
      "Epoch 553/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1087 - accuracy: 0.9575 - val_loss: 0.1559 - val_accuracy: 0.9409\n",
      "Epoch 554/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1087 - accuracy: 0.9574 - val_loss: 0.1561 - val_accuracy: 0.9407\n",
      "Epoch 555/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1086 - accuracy: 0.9578 - val_loss: 0.1560 - val_accuracy: 0.9400\n",
      "Epoch 556/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1085 - accuracy: 0.9576 - val_loss: 0.1562 - val_accuracy: 0.9409\n",
      "Epoch 557/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1085 - accuracy: 0.9575 - val_loss: 0.1560 - val_accuracy: 0.9414\n",
      "Epoch 558/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1084 - accuracy: 0.9575 - val_loss: 0.1558 - val_accuracy: 0.9404\n",
      "Epoch 559/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1083 - accuracy: 0.9575 - val_loss: 0.1572 - val_accuracy: 0.9406\n",
      "Epoch 560/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1082 - accuracy: 0.9575 - val_loss: 0.1562 - val_accuracy: 0.9408\n",
      "Epoch 561/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1082 - accuracy: 0.9577 - val_loss: 0.1579 - val_accuracy: 0.9406\n",
      "Epoch 562/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1082 - accuracy: 0.9576 - val_loss: 0.1560 - val_accuracy: 0.9413\n",
      "Epoch 563/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1081 - accuracy: 0.9577 - val_loss: 0.1563 - val_accuracy: 0.9409\n",
      "Epoch 564/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1082 - accuracy: 0.9578 - val_loss: 0.1559 - val_accuracy: 0.9416\n",
      "Epoch 565/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1079 - accuracy: 0.9578 - val_loss: 0.1563 - val_accuracy: 0.9415\n",
      "Epoch 566/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1079 - accuracy: 0.9579 - val_loss: 0.1560 - val_accuracy: 0.9412\n",
      "Epoch 567/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1079 - accuracy: 0.9578 - val_loss: 0.1564 - val_accuracy: 0.9405\n",
      "Epoch 568/800\n",
      "6000/6000 [==============================] - 0s 67us/step - loss: 0.1078 - accuracy: 0.9577 - val_loss: 0.1564 - val_accuracy: 0.9412\n",
      "Epoch 569/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1078 - accuracy: 0.9578 - val_loss: 0.1568 - val_accuracy: 0.9406\n",
      "Epoch 570/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1077 - accuracy: 0.9579 - val_loss: 0.1570 - val_accuracy: 0.9404\n",
      "Epoch 571/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1076 - accuracy: 0.9579 - val_loss: 0.1562 - val_accuracy: 0.9413\n",
      "Epoch 572/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1075 - accuracy: 0.9579 - val_loss: 0.1564 - val_accuracy: 0.9410\n",
      "Epoch 573/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1075 - accuracy: 0.9580 - val_loss: 0.1564 - val_accuracy: 0.9412\n",
      "Epoch 574/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1075 - accuracy: 0.9578 - val_loss: 0.1571 - val_accuracy: 0.9405\n",
      "Epoch 575/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1074 - accuracy: 0.9580 - val_loss: 0.1564 - val_accuracy: 0.9412\n",
      "Epoch 576/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1073 - accuracy: 0.9579 - val_loss: 0.1567 - val_accuracy: 0.9404\n",
      "Epoch 577/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1072 - accuracy: 0.9581 - val_loss: 0.1565 - val_accuracy: 0.9409\n",
      "Epoch 578/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1072 - accuracy: 0.9580 - val_loss: 0.1572 - val_accuracy: 0.9415\n",
      "Epoch 579/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1071 - accuracy: 0.9583 - val_loss: 0.1573 - val_accuracy: 0.9407\n",
      "Epoch 580/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1070 - accuracy: 0.9581 - val_loss: 0.1574 - val_accuracy: 0.9408\n",
      "Epoch 581/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1071 - accuracy: 0.9581 - val_loss: 0.1575 - val_accuracy: 0.9406\n",
      "Epoch 582/800\n",
      "6000/6000 [==============================] - 0s 67us/step - loss: 0.1070 - accuracy: 0.9579 - val_loss: 0.1574 - val_accuracy: 0.9408\n",
      "Epoch 583/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1067 - accuracy: 0.9584 - val_loss: 0.1566 - val_accuracy: 0.9408\n",
      "Epoch 584/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1067 - accuracy: 0.9582 - val_loss: 0.1573 - val_accuracy: 0.9409\n",
      "Epoch 585/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1068 - accuracy: 0.9581 - val_loss: 0.1580 - val_accuracy: 0.9399\n",
      "Epoch 586/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1066 - accuracy: 0.9584 - val_loss: 0.1580 - val_accuracy: 0.9404\n",
      "Epoch 587/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1067 - accuracy: 0.9584 - val_loss: 0.1570 - val_accuracy: 0.9410\n",
      "Epoch 588/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1065 - accuracy: 0.9583 - val_loss: 0.1569 - val_accuracy: 0.9404\n",
      "Epoch 589/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1065 - accuracy: 0.9585 - val_loss: 0.1572 - val_accuracy: 0.9407\n",
      "Epoch 590/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1064 - accuracy: 0.9584 - val_loss: 0.1575 - val_accuracy: 0.9415\n",
      "Epoch 591/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1064 - accuracy: 0.9583 - val_loss: 0.1583 - val_accuracy: 0.9405\n",
      "Epoch 592/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1062 - accuracy: 0.9584 - val_loss: 0.1579 - val_accuracy: 0.9402\n",
      "Epoch 593/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1061 - accuracy: 0.9584 - val_loss: 0.1584 - val_accuracy: 0.9399\n",
      "Epoch 594/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1062 - accuracy: 0.9581 - val_loss: 0.1589 - val_accuracy: 0.9404\n",
      "Epoch 595/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1060 - accuracy: 0.9583 - val_loss: 0.1590 - val_accuracy: 0.9413\n",
      "Epoch 596/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1061 - accuracy: 0.9584 - val_loss: 0.1578 - val_accuracy: 0.9404\n",
      "Epoch 597/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1060 - accuracy: 0.9585 - val_loss: 0.1578 - val_accuracy: 0.9398\n",
      "Epoch 598/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1058 - accuracy: 0.9585 - val_loss: 0.1588 - val_accuracy: 0.9408\n",
      "Epoch 599/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1058 - accuracy: 0.9589 - val_loss: 0.1578 - val_accuracy: 0.9397\n",
      "Epoch 600/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1057 - accuracy: 0.9586 - val_loss: 0.1574 - val_accuracy: 0.9411\n",
      "Epoch 601/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1057 - accuracy: 0.9585 - val_loss: 0.1580 - val_accuracy: 0.9411\n",
      "Epoch 602/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1058 - accuracy: 0.9586 - val_loss: 0.1586 - val_accuracy: 0.9399\n",
      "Epoch 603/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1055 - accuracy: 0.9587 - val_loss: 0.1575 - val_accuracy: 0.9408\n",
      "Epoch 604/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1054 - accuracy: 0.9587 - val_loss: 0.1575 - val_accuracy: 0.9404\n",
      "Epoch 605/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1056 - accuracy: 0.9587 - val_loss: 0.1579 - val_accuracy: 0.9398\n",
      "Epoch 606/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1053 - accuracy: 0.9585 - val_loss: 0.1579 - val_accuracy: 0.9406\n",
      "Epoch 607/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1053 - accuracy: 0.9587 - val_loss: 0.1584 - val_accuracy: 0.9405\n",
      "Epoch 608/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1052 - accuracy: 0.9587 - val_loss: 0.1575 - val_accuracy: 0.9402\n",
      "Epoch 609/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1052 - accuracy: 0.9589 - val_loss: 0.1585 - val_accuracy: 0.9399\n",
      "Epoch 610/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1051 - accuracy: 0.9588 - val_loss: 0.1590 - val_accuracy: 0.9403\n",
      "Epoch 611/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1051 - accuracy: 0.9589 - val_loss: 0.1591 - val_accuracy: 0.9402\n",
      "Epoch 612/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1049 - accuracy: 0.9590 - val_loss: 0.1584 - val_accuracy: 0.9407\n",
      "Epoch 613/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1049 - accuracy: 0.9585 - val_loss: 0.1590 - val_accuracy: 0.9393\n",
      "Epoch 614/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1048 - accuracy: 0.9590 - val_loss: 0.1582 - val_accuracy: 0.9410\n",
      "Epoch 615/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1047 - accuracy: 0.9589 - val_loss: 0.1593 - val_accuracy: 0.9411\n",
      "Epoch 616/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1047 - accuracy: 0.9589 - val_loss: 0.1586 - val_accuracy: 0.9406\n",
      "Epoch 617/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1046 - accuracy: 0.9591 - val_loss: 0.1608 - val_accuracy: 0.9402\n",
      "Epoch 618/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1046 - accuracy: 0.9588 - val_loss: 0.1589 - val_accuracy: 0.9404\n",
      "Epoch 619/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1046 - accuracy: 0.9591 - val_loss: 0.1602 - val_accuracy: 0.9402\n",
      "Epoch 620/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1045 - accuracy: 0.9588 - val_loss: 0.1603 - val_accuracy: 0.9402\n",
      "Epoch 621/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1045 - accuracy: 0.9591 - val_loss: 0.1585 - val_accuracy: 0.9409\n",
      "Epoch 622/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1042 - accuracy: 0.9593 - val_loss: 0.1588 - val_accuracy: 0.9410\n",
      "Epoch 623/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1043 - accuracy: 0.9590 - val_loss: 0.1592 - val_accuracy: 0.9405\n",
      "Epoch 624/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1042 - accuracy: 0.9590 - val_loss: 0.1595 - val_accuracy: 0.9407\n",
      "Epoch 625/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1040 - accuracy: 0.9592 - val_loss: 0.1587 - val_accuracy: 0.9405\n",
      "Epoch 626/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1042 - accuracy: 0.9592 - val_loss: 0.1592 - val_accuracy: 0.9404\n",
      "Epoch 627/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1040 - accuracy: 0.9593 - val_loss: 0.1598 - val_accuracy: 0.9406\n",
      "Epoch 628/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1040 - accuracy: 0.9596 - val_loss: 0.1591 - val_accuracy: 0.9399\n",
      "Epoch 629/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1039 - accuracy: 0.9590 - val_loss: 0.1587 - val_accuracy: 0.9409\n",
      "Epoch 630/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1038 - accuracy: 0.9592 - val_loss: 0.1595 - val_accuracy: 0.9405\n",
      "Epoch 631/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1038 - accuracy: 0.9595 - val_loss: 0.1590 - val_accuracy: 0.9404\n",
      "Epoch 632/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1037 - accuracy: 0.9594 - val_loss: 0.1590 - val_accuracy: 0.9410\n",
      "Epoch 633/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1036 - accuracy: 0.9592 - val_loss: 0.1586 - val_accuracy: 0.9404\n",
      "Epoch 634/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1036 - accuracy: 0.9594 - val_loss: 0.1593 - val_accuracy: 0.9407\n",
      "Epoch 635/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1035 - accuracy: 0.9595 - val_loss: 0.1594 - val_accuracy: 0.9402\n",
      "Epoch 636/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1034 - accuracy: 0.9593 - val_loss: 0.1589 - val_accuracy: 0.9402\n",
      "Epoch 637/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1035 - accuracy: 0.9592 - val_loss: 0.1601 - val_accuracy: 0.9404\n",
      "Epoch 638/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1033 - accuracy: 0.9595 - val_loss: 0.1609 - val_accuracy: 0.9393\n",
      "Epoch 639/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1033 - accuracy: 0.9595 - val_loss: 0.1591 - val_accuracy: 0.9408\n",
      "Epoch 640/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1032 - accuracy: 0.9597 - val_loss: 0.1597 - val_accuracy: 0.9406\n",
      "Epoch 641/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1031 - accuracy: 0.9594 - val_loss: 0.1600 - val_accuracy: 0.9402\n",
      "Epoch 642/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1031 - accuracy: 0.9595 - val_loss: 0.1592 - val_accuracy: 0.9406\n",
      "Epoch 643/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1030 - accuracy: 0.9595 - val_loss: 0.1599 - val_accuracy: 0.9397\n",
      "Epoch 644/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1030 - accuracy: 0.9596 - val_loss: 0.1606 - val_accuracy: 0.9397\n",
      "Epoch 645/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1029 - accuracy: 0.9597 - val_loss: 0.1600 - val_accuracy: 0.9400\n",
      "Epoch 646/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1028 - accuracy: 0.9600 - val_loss: 0.1605 - val_accuracy: 0.9402\n",
      "Epoch 647/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1028 - accuracy: 0.9596 - val_loss: 0.1597 - val_accuracy: 0.9398\n",
      "Epoch 648/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1026 - accuracy: 0.9598 - val_loss: 0.1609 - val_accuracy: 0.9400\n",
      "Epoch 649/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1026 - accuracy: 0.9596 - val_loss: 0.1599 - val_accuracy: 0.9405\n",
      "Epoch 650/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1025 - accuracy: 0.9598 - val_loss: 0.1606 - val_accuracy: 0.9398\n",
      "Epoch 651/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1025 - accuracy: 0.9599 - val_loss: 0.1619 - val_accuracy: 0.9402\n",
      "Epoch 652/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1023 - accuracy: 0.9599 - val_loss: 0.1603 - val_accuracy: 0.9405\n",
      "Epoch 653/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1023 - accuracy: 0.9598 - val_loss: 0.1611 - val_accuracy: 0.9396\n",
      "Epoch 654/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1023 - accuracy: 0.9600 - val_loss: 0.1602 - val_accuracy: 0.9400\n",
      "Epoch 655/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1022 - accuracy: 0.9600 - val_loss: 0.1605 - val_accuracy: 0.9403\n",
      "Epoch 656/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1021 - accuracy: 0.9600 - val_loss: 0.1607 - val_accuracy: 0.9405\n",
      "Epoch 657/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1022 - accuracy: 0.9600 - val_loss: 0.1599 - val_accuracy: 0.9401\n",
      "Epoch 658/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1020 - accuracy: 0.9601 - val_loss: 0.1616 - val_accuracy: 0.9395\n",
      "Epoch 659/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1019 - accuracy: 0.9600 - val_loss: 0.1619 - val_accuracy: 0.9396\n",
      "Epoch 660/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1020 - accuracy: 0.9600 - val_loss: 0.1609 - val_accuracy: 0.9404\n",
      "Epoch 661/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1018 - accuracy: 0.9600 - val_loss: 0.1611 - val_accuracy: 0.9405\n",
      "Epoch 662/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1017 - accuracy: 0.9602 - val_loss: 0.1607 - val_accuracy: 0.9404\n",
      "Epoch 663/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1018 - accuracy: 0.9601 - val_loss: 0.1606 - val_accuracy: 0.9406\n",
      "Epoch 664/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1017 - accuracy: 0.9599 - val_loss: 0.1607 - val_accuracy: 0.9398\n",
      "Epoch 665/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1015 - accuracy: 0.9602 - val_loss: 0.1612 - val_accuracy: 0.9398\n",
      "Epoch 666/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1014 - accuracy: 0.9602 - val_loss: 0.1620 - val_accuracy: 0.9399\n",
      "Epoch 667/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1014 - accuracy: 0.9602 - val_loss: 0.1602 - val_accuracy: 0.9394\n",
      "Epoch 668/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1014 - accuracy: 0.9603 - val_loss: 0.1613 - val_accuracy: 0.9395\n",
      "Epoch 669/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1013 - accuracy: 0.9603 - val_loss: 0.1619 - val_accuracy: 0.9401\n",
      "Epoch 670/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1014 - accuracy: 0.9604 - val_loss: 0.1620 - val_accuracy: 0.9406\n",
      "Epoch 671/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1011 - accuracy: 0.9607 - val_loss: 0.1618 - val_accuracy: 0.9390\n",
      "Epoch 672/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1011 - accuracy: 0.9603 - val_loss: 0.1614 - val_accuracy: 0.9399\n",
      "Epoch 673/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1010 - accuracy: 0.9606 - val_loss: 0.1628 - val_accuracy: 0.9397\n",
      "Epoch 674/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1010 - accuracy: 0.9601 - val_loss: 0.1619 - val_accuracy: 0.9402\n",
      "Epoch 675/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1009 - accuracy: 0.9604 - val_loss: 0.1607 - val_accuracy: 0.9404\n",
      "Epoch 676/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1009 - accuracy: 0.9605 - val_loss: 0.1619 - val_accuracy: 0.9397\n",
      "Epoch 677/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1008 - accuracy: 0.9603 - val_loss: 0.1617 - val_accuracy: 0.9402\n",
      "Epoch 678/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1007 - accuracy: 0.9606 - val_loss: 0.1634 - val_accuracy: 0.9391\n",
      "Epoch 679/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1006 - accuracy: 0.9607 - val_loss: 0.1624 - val_accuracy: 0.9403\n",
      "Epoch 680/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1005 - accuracy: 0.9605 - val_loss: 0.1618 - val_accuracy: 0.9395\n",
      "Epoch 681/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1004 - accuracy: 0.9605 - val_loss: 0.1622 - val_accuracy: 0.9404\n",
      "Epoch 682/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1004 - accuracy: 0.9607 - val_loss: 0.1632 - val_accuracy: 0.9405\n",
      "Epoch 683/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1004 - accuracy: 0.9607 - val_loss: 0.1635 - val_accuracy: 0.9394\n",
      "Epoch 684/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1003 - accuracy: 0.9607 - val_loss: 0.1623 - val_accuracy: 0.9403\n",
      "Epoch 685/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1002 - accuracy: 0.9608 - val_loss: 0.1625 - val_accuracy: 0.9399\n",
      "Epoch 686/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1002 - accuracy: 0.9608 - val_loss: 0.1634 - val_accuracy: 0.9398\n",
      "Epoch 687/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1001 - accuracy: 0.9607 - val_loss: 0.1634 - val_accuracy: 0.9394\n",
      "Epoch 688/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.1001 - accuracy: 0.9607 - val_loss: 0.1628 - val_accuracy: 0.9397\n",
      "Epoch 689/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1000 - accuracy: 0.9608 - val_loss: 0.1616 - val_accuracy: 0.9398\n",
      "Epoch 690/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.1000 - accuracy: 0.9608 - val_loss: 0.1618 - val_accuracy: 0.9402\n",
      "Epoch 691/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.0999 - accuracy: 0.9607 - val_loss: 0.1619 - val_accuracy: 0.9397\n",
      "Epoch 692/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.0997 - accuracy: 0.9609 - val_loss: 0.1631 - val_accuracy: 0.9403\n",
      "Epoch 693/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.0997 - accuracy: 0.9609 - val_loss: 0.1632 - val_accuracy: 0.9392\n",
      "Epoch 694/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0998 - accuracy: 0.9609 - val_loss: 0.1627 - val_accuracy: 0.9394\n",
      "Epoch 695/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.0996 - accuracy: 0.9608 - val_loss: 0.1625 - val_accuracy: 0.9395\n",
      "Epoch 696/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0994 - accuracy: 0.9611 - val_loss: 0.1644 - val_accuracy: 0.9388\n",
      "Epoch 697/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0995 - accuracy: 0.9609 - val_loss: 0.1644 - val_accuracy: 0.9389\n",
      "Epoch 698/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0994 - accuracy: 0.9610 - val_loss: 0.1636 - val_accuracy: 0.9390\n",
      "Epoch 699/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.0992 - accuracy: 0.9610 - val_loss: 0.1633 - val_accuracy: 0.9396\n",
      "Epoch 700/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0992 - accuracy: 0.9610 - val_loss: 0.1647 - val_accuracy: 0.9393\n",
      "Epoch 701/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.0993 - accuracy: 0.9611 - val_loss: 0.1653 - val_accuracy: 0.9393\n",
      "Epoch 702/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0992 - accuracy: 0.9609 - val_loss: 0.1640 - val_accuracy: 0.9398\n",
      "Epoch 703/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0991 - accuracy: 0.9611 - val_loss: 0.1646 - val_accuracy: 0.9392\n",
      "Epoch 704/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.0991 - accuracy: 0.9612 - val_loss: 0.1645 - val_accuracy: 0.9397\n",
      "Epoch 705/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.0988 - accuracy: 0.9612 - val_loss: 0.1651 - val_accuracy: 0.9397\n",
      "Epoch 706/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0989 - accuracy: 0.9611 - val_loss: 0.1646 - val_accuracy: 0.9401\n",
      "Epoch 707/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0988 - accuracy: 0.9615 - val_loss: 0.1642 - val_accuracy: 0.9384\n",
      "Epoch 708/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0987 - accuracy: 0.9614 - val_loss: 0.1642 - val_accuracy: 0.9394\n",
      "Epoch 709/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.0988 - accuracy: 0.9611 - val_loss: 0.1650 - val_accuracy: 0.9398\n",
      "Epoch 710/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.0985 - accuracy: 0.9614 - val_loss: 0.1637 - val_accuracy: 0.9396\n",
      "Epoch 711/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.0986 - accuracy: 0.9612 - val_loss: 0.1636 - val_accuracy: 0.9402\n",
      "Epoch 712/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0985 - accuracy: 0.9614 - val_loss: 0.1645 - val_accuracy: 0.9394\n",
      "Epoch 713/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0984 - accuracy: 0.9614 - val_loss: 0.1642 - val_accuracy: 0.9390\n",
      "Epoch 714/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0983 - accuracy: 0.9616 - val_loss: 0.1649 - val_accuracy: 0.9399\n",
      "Epoch 715/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.0984 - accuracy: 0.9613 - val_loss: 0.1651 - val_accuracy: 0.9393\n",
      "Epoch 716/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.0982 - accuracy: 0.9616 - val_loss: 0.1639 - val_accuracy: 0.9393\n",
      "Epoch 717/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.0982 - accuracy: 0.9614 - val_loss: 0.1653 - val_accuracy: 0.9383\n",
      "Epoch 718/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.0980 - accuracy: 0.9616 - val_loss: 0.1647 - val_accuracy: 0.9390\n",
      "Epoch 719/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0980 - accuracy: 0.9615 - val_loss: 0.1652 - val_accuracy: 0.9395\n",
      "Epoch 720/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.0980 - accuracy: 0.9616 - val_loss: 0.1645 - val_accuracy: 0.9398\n",
      "Epoch 721/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.0978 - accuracy: 0.9614 - val_loss: 0.1650 - val_accuracy: 0.9398\n",
      "Epoch 722/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.0977 - accuracy: 0.9616 - val_loss: 0.1665 - val_accuracy: 0.9385\n",
      "Epoch 723/800\n",
      "6000/6000 [==============================] - 0s 68us/step - loss: 0.0977 - accuracy: 0.9618 - val_loss: 0.1663 - val_accuracy: 0.9394\n",
      "Epoch 724/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.0975 - accuracy: 0.9617 - val_loss: 0.1649 - val_accuracy: 0.9393\n",
      "Epoch 725/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.0974 - accuracy: 0.9617 - val_loss: 0.1651 - val_accuracy: 0.9391\n",
      "Epoch 726/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.0974 - accuracy: 0.9618 - val_loss: 0.1667 - val_accuracy: 0.9405\n",
      "Epoch 727/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.0975 - accuracy: 0.9615 - val_loss: 0.1657 - val_accuracy: 0.9390\n",
      "Epoch 728/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.0975 - accuracy: 0.9617 - val_loss: 0.1652 - val_accuracy: 0.9397\n",
      "Epoch 729/800\n",
      "6000/6000 [==============================] - 0s 69us/step - loss: 0.0974 - accuracy: 0.9618 - val_loss: 0.1668 - val_accuracy: 0.9393\n",
      "Epoch 730/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0974 - accuracy: 0.9617 - val_loss: 0.1657 - val_accuracy: 0.9395\n",
      "Epoch 731/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.0972 - accuracy: 0.9619 - val_loss: 0.1676 - val_accuracy: 0.9384\n",
      "Epoch 732/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0971 - accuracy: 0.9620 - val_loss: 0.1660 - val_accuracy: 0.9398\n",
      "Epoch 733/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0970 - accuracy: 0.9622 - val_loss: 0.1663 - val_accuracy: 0.9390\n",
      "Epoch 734/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.0970 - accuracy: 0.9619 - val_loss: 0.1678 - val_accuracy: 0.9395\n",
      "Epoch 735/800\n",
      "6000/6000 [==============================] - 1s 92us/step - loss: 0.0969 - accuracy: 0.9620 - val_loss: 0.1656 - val_accuracy: 0.9392\n",
      "Epoch 736/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.0970 - accuracy: 0.9619 - val_loss: 0.1659 - val_accuracy: 0.9391\n",
      "Epoch 737/800\n",
      "6000/6000 [==============================] - 1s 87us/step - loss: 0.0969 - accuracy: 0.9618 - val_loss: 0.1678 - val_accuracy: 0.9395\n",
      "Epoch 738/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.0967 - accuracy: 0.9621 - val_loss: 0.1678 - val_accuracy: 0.9376\n",
      "Epoch 739/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0966 - accuracy: 0.9620 - val_loss: 0.1664 - val_accuracy: 0.9392\n",
      "Epoch 740/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.0966 - accuracy: 0.9621 - val_loss: 0.1670 - val_accuracy: 0.9388\n",
      "Epoch 741/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.0966 - accuracy: 0.9618 - val_loss: 0.1690 - val_accuracy: 0.9377\n",
      "Epoch 742/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.0964 - accuracy: 0.9624 - val_loss: 0.1664 - val_accuracy: 0.9398\n",
      "Epoch 743/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.0964 - accuracy: 0.9623 - val_loss: 0.1688 - val_accuracy: 0.9376\n",
      "Epoch 744/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0963 - accuracy: 0.9621 - val_loss: 0.1665 - val_accuracy: 0.9392\n",
      "Epoch 745/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.0961 - accuracy: 0.9623 - val_loss: 0.1670 - val_accuracy: 0.9390\n",
      "Epoch 746/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.0961 - accuracy: 0.9624 - val_loss: 0.1677 - val_accuracy: 0.9387\n",
      "Epoch 747/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0960 - accuracy: 0.9623 - val_loss: 0.1669 - val_accuracy: 0.9391\n",
      "Epoch 748/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.0959 - accuracy: 0.9623 - val_loss: 0.1671 - val_accuracy: 0.9389\n",
      "Epoch 749/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.0959 - accuracy: 0.9627 - val_loss: 0.1677 - val_accuracy: 0.9395\n",
      "Epoch 750/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.0959 - accuracy: 0.9626 - val_loss: 0.1693 - val_accuracy: 0.9386\n",
      "Epoch 751/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.0960 - accuracy: 0.9623 - val_loss: 0.1685 - val_accuracy: 0.9392\n",
      "Epoch 752/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.0957 - accuracy: 0.9625 - val_loss: 0.1673 - val_accuracy: 0.9391\n",
      "Epoch 753/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.0955 - accuracy: 0.9625 - val_loss: 0.1672 - val_accuracy: 0.9397\n",
      "Epoch 754/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.0957 - accuracy: 0.9624 - val_loss: 0.1680 - val_accuracy: 0.9391\n",
      "Epoch 755/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.0955 - accuracy: 0.9626 - val_loss: 0.1723 - val_accuracy: 0.9380\n",
      "Epoch 756/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0954 - accuracy: 0.9626 - val_loss: 0.1680 - val_accuracy: 0.9386\n",
      "Epoch 757/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.0952 - accuracy: 0.9627 - val_loss: 0.1694 - val_accuracy: 0.9384\n",
      "Epoch 758/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.0953 - accuracy: 0.9626 - val_loss: 0.1688 - val_accuracy: 0.9390\n",
      "Epoch 759/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.0954 - accuracy: 0.9625 - val_loss: 0.1679 - val_accuracy: 0.9388\n",
      "Epoch 760/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.0951 - accuracy: 0.9624 - val_loss: 0.1693 - val_accuracy: 0.9391\n",
      "Epoch 761/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.0952 - accuracy: 0.9626 - val_loss: 0.1683 - val_accuracy: 0.9389\n",
      "Epoch 762/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.0950 - accuracy: 0.9630 - val_loss: 0.1702 - val_accuracy: 0.9387\n",
      "Epoch 763/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0951 - accuracy: 0.9627 - val_loss: 0.1688 - val_accuracy: 0.9383\n",
      "Epoch 764/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.0949 - accuracy: 0.9627 - val_loss: 0.1684 - val_accuracy: 0.9381\n",
      "Epoch 765/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0947 - accuracy: 0.9625 - val_loss: 0.1677 - val_accuracy: 0.9395\n",
      "Epoch 766/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0949 - accuracy: 0.9628 - val_loss: 0.1685 - val_accuracy: 0.9399\n",
      "Epoch 767/800\n",
      "6000/6000 [==============================] - 1s 94us/step - loss: 0.0947 - accuracy: 0.9628 - val_loss: 0.1699 - val_accuracy: 0.9393\n",
      "Epoch 768/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.0946 - accuracy: 0.9631 - val_loss: 0.1698 - val_accuracy: 0.9371\n",
      "Epoch 769/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.0944 - accuracy: 0.9630 - val_loss: 0.1678 - val_accuracy: 0.9385\n",
      "Epoch 770/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.0946 - accuracy: 0.9630 - val_loss: 0.1700 - val_accuracy: 0.9382\n",
      "Epoch 771/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.0945 - accuracy: 0.9628 - val_loss: 0.1708 - val_accuracy: 0.9391\n",
      "Epoch 772/800\n",
      "6000/6000 [==============================] - 1s 87us/step - loss: 0.0944 - accuracy: 0.9632 - val_loss: 0.1683 - val_accuracy: 0.9385\n",
      "Epoch 773/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.0944 - accuracy: 0.9630 - val_loss: 0.1687 - val_accuracy: 0.9393\n",
      "Epoch 774/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.0941 - accuracy: 0.9630 - val_loss: 0.1694 - val_accuracy: 0.9374\n",
      "Epoch 775/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.0943 - accuracy: 0.9630 - val_loss: 0.1688 - val_accuracy: 0.9399\n",
      "Epoch 776/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0941 - accuracy: 0.9629 - val_loss: 0.1709 - val_accuracy: 0.9377\n",
      "Epoch 777/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0940 - accuracy: 0.9633 - val_loss: 0.1706 - val_accuracy: 0.9378\n",
      "Epoch 778/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0939 - accuracy: 0.9633 - val_loss: 0.1703 - val_accuracy: 0.9386\n",
      "Epoch 779/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0939 - accuracy: 0.9628 - val_loss: 0.1685 - val_accuracy: 0.9387\n",
      "Epoch 780/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0937 - accuracy: 0.9630 - val_loss: 0.1711 - val_accuracy: 0.9383\n",
      "Epoch 781/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0937 - accuracy: 0.9632 - val_loss: 0.1699 - val_accuracy: 0.9387\n",
      "Epoch 782/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0937 - accuracy: 0.9632 - val_loss: 0.1700 - val_accuracy: 0.9389\n",
      "Epoch 783/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0934 - accuracy: 0.9634 - val_loss: 0.1707 - val_accuracy: 0.9379\n",
      "Epoch 784/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0934 - accuracy: 0.9634 - val_loss: 0.1698 - val_accuracy: 0.9388\n",
      "Epoch 785/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0934 - accuracy: 0.9633 - val_loss: 0.1711 - val_accuracy: 0.9388\n",
      "Epoch 786/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0933 - accuracy: 0.9633 - val_loss: 0.1696 - val_accuracy: 0.9388\n",
      "Epoch 787/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0933 - accuracy: 0.9636 - val_loss: 0.1719 - val_accuracy: 0.9386\n",
      "Epoch 788/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0933 - accuracy: 0.9634 - val_loss: 0.1724 - val_accuracy: 0.9381\n",
      "Epoch 789/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0932 - accuracy: 0.9635 - val_loss: 0.1715 - val_accuracy: 0.9374\n",
      "Epoch 790/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0931 - accuracy: 0.9635 - val_loss: 0.1716 - val_accuracy: 0.9391\n",
      "Epoch 791/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0931 - accuracy: 0.9633 - val_loss: 0.1717 - val_accuracy: 0.9382\n",
      "Epoch 792/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0930 - accuracy: 0.9633 - val_loss: 0.1716 - val_accuracy: 0.9379\n",
      "Epoch 793/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0928 - accuracy: 0.9636 - val_loss: 0.1739 - val_accuracy: 0.9371\n",
      "Epoch 794/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0928 - accuracy: 0.9634 - val_loss: 0.1711 - val_accuracy: 0.9390\n",
      "Epoch 795/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0927 - accuracy: 0.9635 - val_loss: 0.1710 - val_accuracy: 0.9388\n",
      "Epoch 796/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0926 - accuracy: 0.9637 - val_loss: 0.1717 - val_accuracy: 0.9377\n",
      "Epoch 797/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0925 - accuracy: 0.9638 - val_loss: 0.1716 - val_accuracy: 0.9385\n",
      "Epoch 798/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0926 - accuracy: 0.9638 - val_loss: 0.1715 - val_accuracy: 0.9387\n",
      "Epoch 799/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0925 - accuracy: 0.9636 - val_loss: 0.1720 - val_accuracy: 0.9383\n",
      "Epoch 800/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0924 - accuracy: 0.9638 - val_loss: 0.1714 - val_accuracy: 0.9385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:122: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Train on 6000 samples, validate on 2001 samples\n",
      "Epoch 1/800\n",
      "6000/6000 [==============================] - 1s 91us/step - loss: 0.4401 - accuracy: 0.8509 - val_loss: 0.2687 - val_accuracy: 0.9250\n",
      "Epoch 2/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2520 - accuracy: 0.9304 - val_loss: 0.2667 - val_accuracy: 0.9250\n",
      "Epoch 3/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2510 - accuracy: 0.9304 - val_loss: 0.2660 - val_accuracy: 0.9250\n",
      "Epoch 4/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2504 - accuracy: 0.9304 - val_loss: 0.2653 - val_accuracy: 0.9250\n",
      "Epoch 5/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2499 - accuracy: 0.9304 - val_loss: 0.2648 - val_accuracy: 0.9250\n",
      "Epoch 6/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2494 - accuracy: 0.9304 - val_loss: 0.2644 - val_accuracy: 0.9250\n",
      "Epoch 7/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2490 - accuracy: 0.9304 - val_loss: 0.2637 - val_accuracy: 0.9250\n",
      "Epoch 8/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2486 - accuracy: 0.9304 - val_loss: 0.2635 - val_accuracy: 0.9250\n",
      "Epoch 9/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2482 - accuracy: 0.9304 - val_loss: 0.2631 - val_accuracy: 0.9250\n",
      "Epoch 10/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2478 - accuracy: 0.9304 - val_loss: 0.2628 - val_accuracy: 0.9250\n",
      "Epoch 11/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2474 - accuracy: 0.9304 - val_loss: 0.2623 - val_accuracy: 0.9250\n",
      "Epoch 12/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2470 - accuracy: 0.9304 - val_loss: 0.2616 - val_accuracy: 0.9250\n",
      "Epoch 13/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2465 - accuracy: 0.9304 - val_loss: 0.2611 - val_accuracy: 0.9250\n",
      "Epoch 14/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2461 - accuracy: 0.9304 - val_loss: 0.2606 - val_accuracy: 0.9250\n",
      "Epoch 15/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2455 - accuracy: 0.9304 - val_loss: 0.2600 - val_accuracy: 0.9250\n",
      "Epoch 16/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2449 - accuracy: 0.9304 - val_loss: 0.2596 - val_accuracy: 0.9250\n",
      "Epoch 17/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2444 - accuracy: 0.9304 - val_loss: 0.2590 - val_accuracy: 0.9250\n",
      "Epoch 18/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2437 - accuracy: 0.9304 - val_loss: 0.2581 - val_accuracy: 0.9250\n",
      "Epoch 19/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2429 - accuracy: 0.9304 - val_loss: 0.2572 - val_accuracy: 0.9250\n",
      "Epoch 20/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2420 - accuracy: 0.9304 - val_loss: 0.2563 - val_accuracy: 0.9250\n",
      "Epoch 21/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.2411 - accuracy: 0.9304 - val_loss: 0.2553 - val_accuracy: 0.9250\n",
      "Epoch 22/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.2400 - accuracy: 0.9304 - val_loss: 0.2541 - val_accuracy: 0.9250\n",
      "Epoch 23/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2389 - accuracy: 0.9304 - val_loss: 0.2530 - val_accuracy: 0.9250\n",
      "Epoch 24/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.2376 - accuracy: 0.9304 - val_loss: 0.2515 - val_accuracy: 0.9250\n",
      "Epoch 25/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.2362 - accuracy: 0.9304 - val_loss: 0.2500 - val_accuracy: 0.9250\n",
      "Epoch 26/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2347 - accuracy: 0.9304 - val_loss: 0.2484 - val_accuracy: 0.9250\n",
      "Epoch 27/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2331 - accuracy: 0.9304 - val_loss: 0.2467 - val_accuracy: 0.9250\n",
      "Epoch 28/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2313 - accuracy: 0.9304 - val_loss: 0.2449 - val_accuracy: 0.9250\n",
      "Epoch 29/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2294 - accuracy: 0.9304 - val_loss: 0.2430 - val_accuracy: 0.9250\n",
      "Epoch 30/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2275 - accuracy: 0.9304 - val_loss: 0.2412 - val_accuracy: 0.9250\n",
      "Epoch 31/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2256 - accuracy: 0.9304 - val_loss: 0.2392 - val_accuracy: 0.9250\n",
      "Epoch 32/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2236 - accuracy: 0.9304 - val_loss: 0.2370 - val_accuracy: 0.9250\n",
      "Epoch 33/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2217 - accuracy: 0.9305 - val_loss: 0.2352 - val_accuracy: 0.9250\n",
      "Epoch 34/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2198 - accuracy: 0.9306 - val_loss: 0.2333 - val_accuracy: 0.9252\n",
      "Epoch 35/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2180 - accuracy: 0.9307 - val_loss: 0.2316 - val_accuracy: 0.9252\n",
      "Epoch 36/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.2162 - accuracy: 0.9307 - val_loss: 0.2298 - val_accuracy: 0.9252\n",
      "Epoch 37/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.2145 - accuracy: 0.9308 - val_loss: 0.2284 - val_accuracy: 0.9254\n",
      "Epoch 38/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.2128 - accuracy: 0.9309 - val_loss: 0.2265 - val_accuracy: 0.9254\n",
      "Epoch 39/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.2111 - accuracy: 0.9309 - val_loss: 0.2251 - val_accuracy: 0.9257\n",
      "Epoch 40/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.2096 - accuracy: 0.9311 - val_loss: 0.2236 - val_accuracy: 0.9258\n",
      "Epoch 41/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.2081 - accuracy: 0.9312 - val_loss: 0.2223 - val_accuracy: 0.9258\n",
      "Epoch 42/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.2066 - accuracy: 0.9313 - val_loss: 0.2207 - val_accuracy: 0.9261\n",
      "Epoch 43/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.2051 - accuracy: 0.9314 - val_loss: 0.2193 - val_accuracy: 0.9261\n",
      "Epoch 44/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.2037 - accuracy: 0.9314 - val_loss: 0.2184 - val_accuracy: 0.9260\n",
      "Epoch 45/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.2023 - accuracy: 0.9316 - val_loss: 0.2170 - val_accuracy: 0.9266\n",
      "Epoch 46/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.2010 - accuracy: 0.9318 - val_loss: 0.2159 - val_accuracy: 0.9268\n",
      "Epoch 47/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1997 - accuracy: 0.9318 - val_loss: 0.2145 - val_accuracy: 0.9267\n",
      "Epoch 48/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1985 - accuracy: 0.9319 - val_loss: 0.2132 - val_accuracy: 0.9270\n",
      "Epoch 49/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1973 - accuracy: 0.9321 - val_loss: 0.2124 - val_accuracy: 0.9269\n",
      "Epoch 50/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1961 - accuracy: 0.9324 - val_loss: 0.2113 - val_accuracy: 0.9273\n",
      "Epoch 51/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1950 - accuracy: 0.9325 - val_loss: 0.2104 - val_accuracy: 0.9274\n",
      "Epoch 52/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1940 - accuracy: 0.9327 - val_loss: 0.2097 - val_accuracy: 0.9276\n",
      "Epoch 53/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1930 - accuracy: 0.9329 - val_loss: 0.2084 - val_accuracy: 0.9272\n",
      "Epoch 54/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1920 - accuracy: 0.9329 - val_loss: 0.2076 - val_accuracy: 0.9277\n",
      "Epoch 55/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1910 - accuracy: 0.9333 - val_loss: 0.2073 - val_accuracy: 0.9283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1901 - accuracy: 0.9335 - val_loss: 0.2062 - val_accuracy: 0.9279\n",
      "Epoch 57/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1892 - accuracy: 0.9336 - val_loss: 0.2051 - val_accuracy: 0.9283\n",
      "Epoch 58/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1883 - accuracy: 0.9338 - val_loss: 0.2047 - val_accuracy: 0.9286\n",
      "Epoch 59/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1874 - accuracy: 0.9340 - val_loss: 0.2039 - val_accuracy: 0.9289\n",
      "Epoch 60/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1865 - accuracy: 0.9343 - val_loss: 0.2032 - val_accuracy: 0.9287\n",
      "Epoch 61/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1857 - accuracy: 0.9345 - val_loss: 0.2023 - val_accuracy: 0.9286\n",
      "Epoch 62/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1849 - accuracy: 0.9345 - val_loss: 0.2013 - val_accuracy: 0.9291\n",
      "Epoch 63/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1840 - accuracy: 0.9348 - val_loss: 0.2010 - val_accuracy: 0.9291\n",
      "Epoch 64/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1833 - accuracy: 0.9350 - val_loss: 0.2000 - val_accuracy: 0.9290\n",
      "Epoch 65/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1824 - accuracy: 0.9352 - val_loss: 0.1996 - val_accuracy: 0.9293\n",
      "Epoch 66/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1817 - accuracy: 0.9354 - val_loss: 0.1984 - val_accuracy: 0.9295\n",
      "Epoch 67/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1809 - accuracy: 0.9356 - val_loss: 0.1977 - val_accuracy: 0.9293\n",
      "Epoch 68/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1802 - accuracy: 0.9358 - val_loss: 0.1972 - val_accuracy: 0.9294\n",
      "Epoch 69/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1794 - accuracy: 0.9358 - val_loss: 0.1963 - val_accuracy: 0.9299\n",
      "Epoch 70/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1787 - accuracy: 0.9361 - val_loss: 0.1959 - val_accuracy: 0.9300\n",
      "Epoch 71/800\n",
      "6000/6000 [==============================] - 1s 83us/step - loss: 0.1780 - accuracy: 0.9364 - val_loss: 0.1954 - val_accuracy: 0.9300\n",
      "Epoch 72/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1773 - accuracy: 0.9366 - val_loss: 0.1948 - val_accuracy: 0.9303\n",
      "Epoch 73/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1766 - accuracy: 0.9368 - val_loss: 0.1941 - val_accuracy: 0.9304\n",
      "Epoch 74/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1760 - accuracy: 0.9369 - val_loss: 0.1935 - val_accuracy: 0.9305\n",
      "Epoch 75/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1753 - accuracy: 0.9369 - val_loss: 0.1929 - val_accuracy: 0.9313\n",
      "Epoch 76/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1746 - accuracy: 0.9372 - val_loss: 0.1922 - val_accuracy: 0.9309\n",
      "Epoch 77/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1740 - accuracy: 0.9376 - val_loss: 0.1918 - val_accuracy: 0.9312\n",
      "Epoch 78/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1734 - accuracy: 0.9375 - val_loss: 0.1913 - val_accuracy: 0.9313\n",
      "Epoch 79/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1727 - accuracy: 0.9380 - val_loss: 0.1905 - val_accuracy: 0.9316\n",
      "Epoch 80/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1722 - accuracy: 0.9382 - val_loss: 0.1901 - val_accuracy: 0.9318\n",
      "Epoch 81/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1716 - accuracy: 0.9382 - val_loss: 0.1897 - val_accuracy: 0.9323\n",
      "Epoch 82/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1710 - accuracy: 0.9385 - val_loss: 0.1888 - val_accuracy: 0.9320\n",
      "Epoch 83/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1705 - accuracy: 0.9388 - val_loss: 0.1884 - val_accuracy: 0.9330\n",
      "Epoch 84/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1699 - accuracy: 0.9390 - val_loss: 0.1880 - val_accuracy: 0.9321\n",
      "Epoch 85/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1694 - accuracy: 0.9390 - val_loss: 0.1873 - val_accuracy: 0.9325\n",
      "Epoch 86/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1688 - accuracy: 0.9392 - val_loss: 0.1875 - val_accuracy: 0.9330\n",
      "Epoch 87/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1683 - accuracy: 0.9392 - val_loss: 0.1861 - val_accuracy: 0.9330\n",
      "Epoch 88/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1679 - accuracy: 0.9394 - val_loss: 0.1861 - val_accuracy: 0.9329\n",
      "Epoch 89/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1673 - accuracy: 0.9396 - val_loss: 0.1853 - val_accuracy: 0.9332\n",
      "Epoch 90/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1669 - accuracy: 0.9398 - val_loss: 0.1857 - val_accuracy: 0.9334\n",
      "Epoch 91/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1664 - accuracy: 0.9400 - val_loss: 0.1851 - val_accuracy: 0.9336\n",
      "Epoch 92/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1660 - accuracy: 0.9400 - val_loss: 0.1843 - val_accuracy: 0.9339\n",
      "Epoch 93/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1655 - accuracy: 0.9403 - val_loss: 0.1835 - val_accuracy: 0.9339\n",
      "Epoch 94/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1651 - accuracy: 0.9402 - val_loss: 0.1833 - val_accuracy: 0.9341\n",
      "Epoch 95/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1646 - accuracy: 0.9404 - val_loss: 0.1830 - val_accuracy: 0.9341\n",
      "Epoch 96/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1642 - accuracy: 0.9406 - val_loss: 0.1827 - val_accuracy: 0.9344\n",
      "Epoch 97/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1639 - accuracy: 0.9406 - val_loss: 0.1825 - val_accuracy: 0.9340\n",
      "Epoch 98/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1635 - accuracy: 0.9408 - val_loss: 0.1818 - val_accuracy: 0.9344\n",
      "Epoch 99/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1631 - accuracy: 0.9410 - val_loss: 0.1814 - val_accuracy: 0.9343\n",
      "Epoch 100/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1627 - accuracy: 0.9410 - val_loss: 0.1813 - val_accuracy: 0.9345\n",
      "Epoch 101/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1623 - accuracy: 0.9410 - val_loss: 0.1807 - val_accuracy: 0.9351\n",
      "Epoch 102/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1620 - accuracy: 0.9412 - val_loss: 0.1804 - val_accuracy: 0.9347\n",
      "Epoch 103/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1616 - accuracy: 0.9414 - val_loss: 0.1802 - val_accuracy: 0.9349\n",
      "Epoch 104/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1612 - accuracy: 0.9416 - val_loss: 0.1796 - val_accuracy: 0.9351\n",
      "Epoch 105/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1609 - accuracy: 0.9415 - val_loss: 0.1794 - val_accuracy: 0.9348\n",
      "Epoch 106/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1606 - accuracy: 0.9417 - val_loss: 0.1789 - val_accuracy: 0.9354\n",
      "Epoch 107/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1603 - accuracy: 0.9418 - val_loss: 0.1790 - val_accuracy: 0.9348\n",
      "Epoch 108/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1599 - accuracy: 0.9418 - val_loss: 0.1788 - val_accuracy: 0.9350\n",
      "Epoch 109/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1595 - accuracy: 0.9422 - val_loss: 0.1782 - val_accuracy: 0.9354\n",
      "Epoch 110/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1592 - accuracy: 0.9422 - val_loss: 0.1783 - val_accuracy: 0.9353\n",
      "Epoch 111/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1590 - accuracy: 0.9422 - val_loss: 0.1777 - val_accuracy: 0.9357\n",
      "Epoch 112/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1586 - accuracy: 0.9424 - val_loss: 0.1775 - val_accuracy: 0.9353\n",
      "Epoch 113/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1584 - accuracy: 0.9424 - val_loss: 0.1772 - val_accuracy: 0.9361\n",
      "Epoch 114/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1581 - accuracy: 0.9425 - val_loss: 0.1775 - val_accuracy: 0.9355\n",
      "Epoch 115/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1578 - accuracy: 0.9426 - val_loss: 0.1766 - val_accuracy: 0.9362\n",
      "Epoch 116/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1575 - accuracy: 0.9428 - val_loss: 0.1762 - val_accuracy: 0.9362\n",
      "Epoch 117/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1573 - accuracy: 0.9426 - val_loss: 0.1768 - val_accuracy: 0.9356\n",
      "Epoch 118/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1571 - accuracy: 0.9429 - val_loss: 0.1762 - val_accuracy: 0.9360\n",
      "Epoch 119/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1567 - accuracy: 0.9431 - val_loss: 0.1771 - val_accuracy: 0.9360\n",
      "Epoch 120/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1565 - accuracy: 0.9430 - val_loss: 0.1756 - val_accuracy: 0.9361\n",
      "Epoch 121/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1562 - accuracy: 0.9431 - val_loss: 0.1755 - val_accuracy: 0.9359\n",
      "Epoch 122/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1560 - accuracy: 0.9431 - val_loss: 0.1753 - val_accuracy: 0.9363\n",
      "Epoch 123/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1558 - accuracy: 0.9434 - val_loss: 0.1748 - val_accuracy: 0.9362\n",
      "Epoch 124/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1556 - accuracy: 0.9434 - val_loss: 0.1747 - val_accuracy: 0.9366\n",
      "Epoch 125/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1553 - accuracy: 0.9434 - val_loss: 0.1748 - val_accuracy: 0.9366\n",
      "Epoch 126/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1551 - accuracy: 0.9436 - val_loss: 0.1750 - val_accuracy: 0.9362\n",
      "Epoch 127/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1549 - accuracy: 0.9437 - val_loss: 0.1748 - val_accuracy: 0.9370\n",
      "Epoch 128/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1546 - accuracy: 0.9436 - val_loss: 0.1740 - val_accuracy: 0.9366\n",
      "Epoch 129/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1545 - accuracy: 0.9438 - val_loss: 0.1742 - val_accuracy: 0.9367\n",
      "Epoch 130/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1542 - accuracy: 0.9439 - val_loss: 0.1735 - val_accuracy: 0.9365\n",
      "Epoch 131/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1540 - accuracy: 0.9439 - val_loss: 0.1733 - val_accuracy: 0.9368\n",
      "Epoch 132/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1538 - accuracy: 0.9441 - val_loss: 0.1733 - val_accuracy: 0.9371\n",
      "Epoch 133/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1536 - accuracy: 0.9442 - val_loss: 0.1733 - val_accuracy: 0.9368\n",
      "Epoch 134/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1534 - accuracy: 0.9440 - val_loss: 0.1732 - val_accuracy: 0.9370\n",
      "Epoch 135/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1533 - accuracy: 0.9441 - val_loss: 0.1729 - val_accuracy: 0.9371\n",
      "Epoch 136/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1530 - accuracy: 0.9443 - val_loss: 0.1725 - val_accuracy: 0.9370\n",
      "Epoch 137/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1529 - accuracy: 0.9443 - val_loss: 0.1724 - val_accuracy: 0.9370\n",
      "Epoch 138/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1526 - accuracy: 0.9445 - val_loss: 0.1724 - val_accuracy: 0.9372\n",
      "Epoch 139/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1525 - accuracy: 0.9445 - val_loss: 0.1723 - val_accuracy: 0.9374\n",
      "Epoch 140/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1523 - accuracy: 0.9446 - val_loss: 0.1719 - val_accuracy: 0.9374\n",
      "Epoch 141/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1521 - accuracy: 0.9446 - val_loss: 0.1726 - val_accuracy: 0.9372\n",
      "Epoch 142/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1519 - accuracy: 0.9445 - val_loss: 0.1728 - val_accuracy: 0.9372\n",
      "Epoch 143/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1517 - accuracy: 0.9446 - val_loss: 0.1722 - val_accuracy: 0.9374\n",
      "Epoch 144/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1516 - accuracy: 0.9447 - val_loss: 0.1723 - val_accuracy: 0.9373\n",
      "Epoch 145/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1513 - accuracy: 0.9448 - val_loss: 0.1716 - val_accuracy: 0.9375\n",
      "Epoch 146/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1512 - accuracy: 0.9450 - val_loss: 0.1714 - val_accuracy: 0.9378\n",
      "Epoch 147/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1510 - accuracy: 0.9449 - val_loss: 0.1709 - val_accuracy: 0.9371\n",
      "Epoch 148/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1509 - accuracy: 0.9449 - val_loss: 0.1713 - val_accuracy: 0.9374\n",
      "Epoch 149/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1507 - accuracy: 0.9451 - val_loss: 0.1710 - val_accuracy: 0.9379\n",
      "Epoch 150/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1506 - accuracy: 0.9451 - val_loss: 0.1707 - val_accuracy: 0.9378\n",
      "Epoch 151/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1503 - accuracy: 0.9451 - val_loss: 0.1707 - val_accuracy: 0.9376\n",
      "Epoch 152/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1501 - accuracy: 0.9452 - val_loss: 0.1715 - val_accuracy: 0.9379\n",
      "Epoch 153/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1501 - accuracy: 0.9453 - val_loss: 0.1707 - val_accuracy: 0.9375\n",
      "Epoch 154/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1499 - accuracy: 0.9452 - val_loss: 0.1700 - val_accuracy: 0.9378\n",
      "Epoch 155/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1498 - accuracy: 0.9453 - val_loss: 0.1701 - val_accuracy: 0.9379\n",
      "Epoch 156/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1495 - accuracy: 0.9453 - val_loss: 0.1701 - val_accuracy: 0.9381\n",
      "Epoch 157/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1494 - accuracy: 0.9455 - val_loss: 0.1703 - val_accuracy: 0.9382\n",
      "Epoch 158/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1491 - accuracy: 0.9455 - val_loss: 0.1703 - val_accuracy: 0.9381\n",
      "Epoch 159/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1490 - accuracy: 0.9456 - val_loss: 0.1696 - val_accuracy: 0.9382\n",
      "Epoch 160/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1488 - accuracy: 0.9458 - val_loss: 0.1697 - val_accuracy: 0.9380\n",
      "Epoch 161/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1487 - accuracy: 0.9457 - val_loss: 0.1690 - val_accuracy: 0.9385\n",
      "Epoch 162/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1486 - accuracy: 0.9458 - val_loss: 0.1693 - val_accuracy: 0.9383\n",
      "Epoch 163/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1483 - accuracy: 0.9458 - val_loss: 0.1694 - val_accuracy: 0.9380\n",
      "Epoch 164/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1482 - accuracy: 0.9458 - val_loss: 0.1690 - val_accuracy: 0.9382\n",
      "Epoch 165/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1481 - accuracy: 0.9457 - val_loss: 0.1687 - val_accuracy: 0.9383\n",
      "Epoch 166/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1479 - accuracy: 0.9462 - val_loss: 0.1682 - val_accuracy: 0.9384\n",
      "Epoch 167/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1478 - accuracy: 0.9459 - val_loss: 0.1689 - val_accuracy: 0.9383\n",
      "Epoch 168/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1476 - accuracy: 0.9460 - val_loss: 0.1681 - val_accuracy: 0.9386\n",
      "Epoch 169/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1474 - accuracy: 0.9461 - val_loss: 0.1679 - val_accuracy: 0.9386\n",
      "Epoch 170/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1473 - accuracy: 0.9462 - val_loss: 0.1681 - val_accuracy: 0.9382\n",
      "Epoch 171/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1471 - accuracy: 0.9461 - val_loss: 0.1680 - val_accuracy: 0.9382\n",
      "Epoch 172/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1469 - accuracy: 0.9462 - val_loss: 0.1678 - val_accuracy: 0.9385\n",
      "Epoch 173/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1467 - accuracy: 0.9463 - val_loss: 0.1682 - val_accuracy: 0.9386\n",
      "Epoch 174/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1466 - accuracy: 0.9464 - val_loss: 0.1683 - val_accuracy: 0.9385\n",
      "Epoch 175/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1464 - accuracy: 0.9463 - val_loss: 0.1678 - val_accuracy: 0.9384\n",
      "Epoch 176/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1463 - accuracy: 0.9466 - val_loss: 0.1675 - val_accuracy: 0.9385\n",
      "Epoch 177/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1462 - accuracy: 0.9464 - val_loss: 0.1671 - val_accuracy: 0.9386\n",
      "Epoch 178/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1460 - accuracy: 0.9465 - val_loss: 0.1675 - val_accuracy: 0.9388\n",
      "Epoch 179/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1459 - accuracy: 0.9464 - val_loss: 0.1669 - val_accuracy: 0.9391\n",
      "Epoch 180/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1456 - accuracy: 0.9468 - val_loss: 0.1671 - val_accuracy: 0.9384\n",
      "Epoch 181/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1455 - accuracy: 0.9467 - val_loss: 0.1666 - val_accuracy: 0.9389\n",
      "Epoch 182/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1453 - accuracy: 0.9465 - val_loss: 0.1666 - val_accuracy: 0.9391\n",
      "Epoch 183/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1452 - accuracy: 0.9467 - val_loss: 0.1666 - val_accuracy: 0.9389\n",
      "Epoch 184/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1450 - accuracy: 0.9469 - val_loss: 0.1668 - val_accuracy: 0.9387\n",
      "Epoch 185/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1449 - accuracy: 0.9468 - val_loss: 0.1660 - val_accuracy: 0.9392\n",
      "Epoch 186/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1447 - accuracy: 0.9469 - val_loss: 0.1655 - val_accuracy: 0.9392\n",
      "Epoch 187/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1445 - accuracy: 0.9471 - val_loss: 0.1661 - val_accuracy: 0.9393\n",
      "Epoch 188/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1444 - accuracy: 0.9470 - val_loss: 0.1657 - val_accuracy: 0.9395\n",
      "Epoch 189/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1443 - accuracy: 0.9471 - val_loss: 0.1653 - val_accuracy: 0.9393\n",
      "Epoch 190/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1440 - accuracy: 0.9473 - val_loss: 0.1663 - val_accuracy: 0.9394\n",
      "Epoch 191/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1439 - accuracy: 0.9471 - val_loss: 0.1657 - val_accuracy: 0.9392\n",
      "Epoch 192/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1437 - accuracy: 0.9472 - val_loss: 0.1653 - val_accuracy: 0.9393\n",
      "Epoch 193/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1436 - accuracy: 0.9471 - val_loss: 0.1651 - val_accuracy: 0.9393\n",
      "Epoch 194/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1434 - accuracy: 0.9474 - val_loss: 0.1652 - val_accuracy: 0.9391\n",
      "Epoch 195/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1432 - accuracy: 0.9474 - val_loss: 0.1655 - val_accuracy: 0.9395\n",
      "Epoch 196/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1431 - accuracy: 0.9475 - val_loss: 0.1645 - val_accuracy: 0.9394\n",
      "Epoch 197/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1429 - accuracy: 0.9475 - val_loss: 0.1646 - val_accuracy: 0.9393\n",
      "Epoch 198/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1427 - accuracy: 0.9476 - val_loss: 0.1650 - val_accuracy: 0.9398\n",
      "Epoch 199/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1425 - accuracy: 0.9475 - val_loss: 0.1644 - val_accuracy: 0.9394\n",
      "Epoch 200/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1424 - accuracy: 0.9477 - val_loss: 0.1640 - val_accuracy: 0.9396\n",
      "Epoch 201/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1422 - accuracy: 0.9477 - val_loss: 0.1640 - val_accuracy: 0.9398\n",
      "Epoch 202/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1421 - accuracy: 0.9477 - val_loss: 0.1646 - val_accuracy: 0.9398\n",
      "Epoch 203/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1419 - accuracy: 0.9477 - val_loss: 0.1637 - val_accuracy: 0.9398\n",
      "Epoch 204/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1417 - accuracy: 0.9477 - val_loss: 0.1638 - val_accuracy: 0.9399\n",
      "Epoch 205/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1416 - accuracy: 0.9478 - val_loss: 0.1634 - val_accuracy: 0.9403\n",
      "Epoch 206/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1414 - accuracy: 0.9479 - val_loss: 0.1633 - val_accuracy: 0.9399\n",
      "Epoch 207/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1412 - accuracy: 0.9480 - val_loss: 0.1638 - val_accuracy: 0.9398\n",
      "Epoch 208/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1411 - accuracy: 0.9480 - val_loss: 0.1635 - val_accuracy: 0.9397\n",
      "Epoch 209/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1409 - accuracy: 0.9479 - val_loss: 0.1635 - val_accuracy: 0.9400\n",
      "Epoch 210/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1406 - accuracy: 0.9482 - val_loss: 0.1624 - val_accuracy: 0.9401\n",
      "Epoch 211/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1406 - accuracy: 0.9482 - val_loss: 0.1624 - val_accuracy: 0.9400\n",
      "Epoch 212/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1404 - accuracy: 0.9482 - val_loss: 0.1624 - val_accuracy: 0.9398\n",
      "Epoch 213/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1402 - accuracy: 0.9483 - val_loss: 0.1629 - val_accuracy: 0.9403\n",
      "Epoch 214/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1401 - accuracy: 0.9484 - val_loss: 0.1621 - val_accuracy: 0.9405\n",
      "Epoch 215/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1399 - accuracy: 0.9486 - val_loss: 0.1624 - val_accuracy: 0.9398\n",
      "Epoch 216/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1397 - accuracy: 0.9484 - val_loss: 0.1621 - val_accuracy: 0.9407\n",
      "Epoch 217/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1396 - accuracy: 0.9487 - val_loss: 0.1615 - val_accuracy: 0.9403\n",
      "Epoch 218/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1394 - accuracy: 0.9486 - val_loss: 0.1616 - val_accuracy: 0.9405\n",
      "Epoch 219/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1391 - accuracy: 0.9486 - val_loss: 0.1616 - val_accuracy: 0.9403\n",
      "Epoch 220/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1391 - accuracy: 0.9487 - val_loss: 0.1614 - val_accuracy: 0.9405\n",
      "Epoch 221/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1389 - accuracy: 0.9488 - val_loss: 0.1613 - val_accuracy: 0.9405\n",
      "Epoch 222/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1387 - accuracy: 0.9489 - val_loss: 0.1617 - val_accuracy: 0.9405\n",
      "Epoch 223/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1386 - accuracy: 0.9488 - val_loss: 0.1611 - val_accuracy: 0.9409\n",
      "Epoch 224/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1384 - accuracy: 0.9489 - val_loss: 0.1610 - val_accuracy: 0.9406\n",
      "Epoch 225/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1382 - accuracy: 0.9491 - val_loss: 0.1614 - val_accuracy: 0.9406\n",
      "Epoch 226/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1381 - accuracy: 0.9490 - val_loss: 0.1606 - val_accuracy: 0.9406\n",
      "Epoch 227/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1379 - accuracy: 0.9489 - val_loss: 0.1610 - val_accuracy: 0.9408\n",
      "Epoch 228/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1378 - accuracy: 0.9491 - val_loss: 0.1607 - val_accuracy: 0.9406\n",
      "Epoch 229/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1377 - accuracy: 0.9492 - val_loss: 0.1604 - val_accuracy: 0.9410\n",
      "Epoch 230/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1374 - accuracy: 0.9493 - val_loss: 0.1600 - val_accuracy: 0.9408\n",
      "Epoch 231/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1373 - accuracy: 0.9493 - val_loss: 0.1597 - val_accuracy: 0.9413\n",
      "Epoch 232/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1370 - accuracy: 0.9494 - val_loss: 0.1601 - val_accuracy: 0.9407\n",
      "Epoch 233/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1369 - accuracy: 0.9493 - val_loss: 0.1599 - val_accuracy: 0.9406\n",
      "Epoch 234/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1368 - accuracy: 0.9493 - val_loss: 0.1603 - val_accuracy: 0.9409\n",
      "Epoch 235/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1366 - accuracy: 0.9493 - val_loss: 0.1597 - val_accuracy: 0.9414\n",
      "Epoch 236/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1364 - accuracy: 0.9497 - val_loss: 0.1600 - val_accuracy: 0.9410\n",
      "Epoch 237/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1364 - accuracy: 0.9497 - val_loss: 0.1596 - val_accuracy: 0.9412\n",
      "Epoch 238/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1363 - accuracy: 0.9497 - val_loss: 0.1597 - val_accuracy: 0.9411\n",
      "Epoch 239/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1360 - accuracy: 0.9496 - val_loss: 0.1594 - val_accuracy: 0.9410\n",
      "Epoch 240/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1359 - accuracy: 0.9496 - val_loss: 0.1591 - val_accuracy: 0.9414\n",
      "Epoch 241/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1358 - accuracy: 0.9496 - val_loss: 0.1592 - val_accuracy: 0.9413\n",
      "Epoch 242/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1356 - accuracy: 0.9496 - val_loss: 0.1588 - val_accuracy: 0.9411\n",
      "Epoch 243/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1355 - accuracy: 0.9496 - val_loss: 0.1590 - val_accuracy: 0.9413\n",
      "Epoch 244/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1353 - accuracy: 0.9499 - val_loss: 0.1595 - val_accuracy: 0.9408\n",
      "Epoch 245/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1352 - accuracy: 0.9497 - val_loss: 0.1588 - val_accuracy: 0.9415\n",
      "Epoch 246/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1351 - accuracy: 0.9501 - val_loss: 0.1582 - val_accuracy: 0.9415\n",
      "Epoch 247/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1348 - accuracy: 0.9501 - val_loss: 0.1584 - val_accuracy: 0.9413\n",
      "Epoch 248/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1348 - accuracy: 0.9497 - val_loss: 0.1585 - val_accuracy: 0.9410\n",
      "Epoch 249/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1346 - accuracy: 0.9501 - val_loss: 0.1584 - val_accuracy: 0.9413\n",
      "Epoch 250/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1345 - accuracy: 0.9499 - val_loss: 0.1578 - val_accuracy: 0.9413\n",
      "Epoch 251/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1343 - accuracy: 0.9501 - val_loss: 0.1583 - val_accuracy: 0.9413\n",
      "Epoch 252/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1342 - accuracy: 0.9499 - val_loss: 0.1579 - val_accuracy: 0.9417\n",
      "Epoch 253/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1341 - accuracy: 0.9502 - val_loss: 0.1588 - val_accuracy: 0.9413\n",
      "Epoch 254/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1340 - accuracy: 0.9503 - val_loss: 0.1577 - val_accuracy: 0.9413\n",
      "Epoch 255/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1338 - accuracy: 0.9502 - val_loss: 0.1575 - val_accuracy: 0.9420\n",
      "Epoch 256/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1336 - accuracy: 0.9502 - val_loss: 0.1578 - val_accuracy: 0.9416\n",
      "Epoch 257/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1335 - accuracy: 0.9502 - val_loss: 0.1577 - val_accuracy: 0.9418\n",
      "Epoch 258/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1334 - accuracy: 0.9503 - val_loss: 0.1570 - val_accuracy: 0.9416\n",
      "Epoch 259/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1332 - accuracy: 0.9503 - val_loss: 0.1574 - val_accuracy: 0.9423\n",
      "Epoch 260/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1331 - accuracy: 0.9504 - val_loss: 0.1569 - val_accuracy: 0.9416\n",
      "Epoch 261/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1331 - accuracy: 0.9503 - val_loss: 0.1570 - val_accuracy: 0.9419\n",
      "Epoch 262/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1329 - accuracy: 0.9503 - val_loss: 0.1569 - val_accuracy: 0.9417\n",
      "Epoch 263/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1328 - accuracy: 0.9504 - val_loss: 0.1566 - val_accuracy: 0.9418\n",
      "Epoch 264/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1326 - accuracy: 0.9504 - val_loss: 0.1570 - val_accuracy: 0.9415\n",
      "Epoch 265/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1324 - accuracy: 0.9504 - val_loss: 0.1571 - val_accuracy: 0.9419\n",
      "Epoch 266/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1323 - accuracy: 0.9506 - val_loss: 0.1568 - val_accuracy: 0.9418\n",
      "Epoch 267/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1323 - accuracy: 0.9504 - val_loss: 0.1567 - val_accuracy: 0.9417\n",
      "Epoch 268/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1322 - accuracy: 0.9506 - val_loss: 0.1566 - val_accuracy: 0.9420\n",
      "Epoch 269/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1320 - accuracy: 0.9507 - val_loss: 0.1564 - val_accuracy: 0.9420\n",
      "Epoch 270/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1320 - accuracy: 0.9503 - val_loss: 0.1567 - val_accuracy: 0.9416\n",
      "Epoch 271/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1318 - accuracy: 0.9506 - val_loss: 0.1568 - val_accuracy: 0.9416\n",
      "Epoch 272/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1317 - accuracy: 0.9508 - val_loss: 0.1563 - val_accuracy: 0.9418\n",
      "Epoch 273/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1316 - accuracy: 0.9508 - val_loss: 0.1562 - val_accuracy: 0.9422\n",
      "Epoch 274/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1314 - accuracy: 0.9507 - val_loss: 0.1563 - val_accuracy: 0.9422\n",
      "Epoch 275/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1313 - accuracy: 0.9507 - val_loss: 0.1564 - val_accuracy: 0.9422\n",
      "Epoch 276/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1312 - accuracy: 0.9509 - val_loss: 0.1562 - val_accuracy: 0.9419\n",
      "Epoch 277/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1311 - accuracy: 0.9510 - val_loss: 0.1562 - val_accuracy: 0.9415\n",
      "Epoch 278/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1310 - accuracy: 0.9509 - val_loss: 0.1567 - val_accuracy: 0.9417\n",
      "Epoch 279/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1309 - accuracy: 0.9509 - val_loss: 0.1562 - val_accuracy: 0.9420\n",
      "Epoch 280/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1308 - accuracy: 0.9510 - val_loss: 0.1555 - val_accuracy: 0.9422\n",
      "Epoch 281/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1306 - accuracy: 0.9509 - val_loss: 0.1561 - val_accuracy: 0.9418\n",
      "Epoch 282/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1305 - accuracy: 0.9511 - val_loss: 0.1552 - val_accuracy: 0.9422\n",
      "Epoch 283/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1304 - accuracy: 0.9509 - val_loss: 0.1554 - val_accuracy: 0.9424\n",
      "Epoch 284/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1304 - accuracy: 0.9511 - val_loss: 0.1557 - val_accuracy: 0.9422\n",
      "Epoch 285/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1302 - accuracy: 0.9510 - val_loss: 0.1560 - val_accuracy: 0.9423\n",
      "Epoch 286/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1301 - accuracy: 0.9511 - val_loss: 0.1556 - val_accuracy: 0.9421\n",
      "Epoch 287/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1299 - accuracy: 0.9511 - val_loss: 0.1561 - val_accuracy: 0.9422\n",
      "Epoch 288/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1298 - accuracy: 0.9512 - val_loss: 0.1555 - val_accuracy: 0.9423\n",
      "Epoch 289/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1298 - accuracy: 0.9511 - val_loss: 0.1554 - val_accuracy: 0.9420\n",
      "Epoch 290/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1297 - accuracy: 0.9513 - val_loss: 0.1552 - val_accuracy: 0.9424\n",
      "Epoch 291/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1296 - accuracy: 0.9514 - val_loss: 0.1553 - val_accuracy: 0.9423\n",
      "Epoch 292/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1294 - accuracy: 0.9514 - val_loss: 0.1551 - val_accuracy: 0.9422\n",
      "Epoch 293/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1294 - accuracy: 0.9513 - val_loss: 0.1555 - val_accuracy: 0.9421\n",
      "Epoch 294/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1293 - accuracy: 0.9513 - val_loss: 0.1556 - val_accuracy: 0.9421\n",
      "Epoch 295/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1292 - accuracy: 0.9514 - val_loss: 0.1552 - val_accuracy: 0.9422\n",
      "Epoch 296/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1290 - accuracy: 0.9514 - val_loss: 0.1546 - val_accuracy: 0.9423\n",
      "Epoch 297/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1290 - accuracy: 0.9515 - val_loss: 0.1553 - val_accuracy: 0.9421\n",
      "Epoch 298/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1288 - accuracy: 0.9516 - val_loss: 0.1548 - val_accuracy: 0.9422\n",
      "Epoch 299/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1287 - accuracy: 0.9514 - val_loss: 0.1547 - val_accuracy: 0.9426\n",
      "Epoch 300/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1287 - accuracy: 0.9515 - val_loss: 0.1552 - val_accuracy: 0.9428\n",
      "Epoch 301/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1284 - accuracy: 0.9517 - val_loss: 0.1545 - val_accuracy: 0.9420\n",
      "Epoch 302/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1283 - accuracy: 0.9517 - val_loss: 0.1552 - val_accuracy: 0.9425\n",
      "Epoch 303/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1283 - accuracy: 0.9518 - val_loss: 0.1550 - val_accuracy: 0.9427\n",
      "Epoch 304/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1282 - accuracy: 0.9517 - val_loss: 0.1548 - val_accuracy: 0.9422\n",
      "Epoch 305/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1281 - accuracy: 0.9518 - val_loss: 0.1548 - val_accuracy: 0.9427\n",
      "Epoch 306/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1281 - accuracy: 0.9516 - val_loss: 0.1547 - val_accuracy: 0.9425\n",
      "Epoch 307/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1279 - accuracy: 0.9519 - val_loss: 0.1541 - val_accuracy: 0.9426\n",
      "Epoch 308/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1279 - accuracy: 0.9518 - val_loss: 0.1543 - val_accuracy: 0.9423\n",
      "Epoch 309/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1277 - accuracy: 0.9519 - val_loss: 0.1553 - val_accuracy: 0.9424\n",
      "Epoch 310/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1276 - accuracy: 0.9517 - val_loss: 0.1545 - val_accuracy: 0.9425\n",
      "Epoch 311/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1276 - accuracy: 0.9518 - val_loss: 0.1544 - val_accuracy: 0.9424\n",
      "Epoch 312/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1275 - accuracy: 0.9517 - val_loss: 0.1548 - val_accuracy: 0.9423\n",
      "Epoch 313/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1274 - accuracy: 0.9519 - val_loss: 0.1541 - val_accuracy: 0.9425\n",
      "Epoch 314/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1273 - accuracy: 0.9519 - val_loss: 0.1540 - val_accuracy: 0.9425\n",
      "Epoch 315/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1272 - accuracy: 0.9518 - val_loss: 0.1542 - val_accuracy: 0.9424\n",
      "Epoch 316/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1271 - accuracy: 0.9520 - val_loss: 0.1562 - val_accuracy: 0.9421\n",
      "Epoch 317/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1270 - accuracy: 0.9519 - val_loss: 0.1551 - val_accuracy: 0.9420\n",
      "Epoch 318/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1268 - accuracy: 0.9521 - val_loss: 0.1544 - val_accuracy: 0.9420\n",
      "Epoch 319/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1269 - accuracy: 0.9519 - val_loss: 0.1542 - val_accuracy: 0.9425\n",
      "Epoch 320/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1267 - accuracy: 0.9520 - val_loss: 0.1543 - val_accuracy: 0.9427\n",
      "Epoch 321/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1266 - accuracy: 0.9521 - val_loss: 0.1543 - val_accuracy: 0.9426\n",
      "Epoch 322/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1266 - accuracy: 0.9522 - val_loss: 0.1539 - val_accuracy: 0.9427\n",
      "Epoch 323/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1264 - accuracy: 0.9521 - val_loss: 0.1538 - val_accuracy: 0.9428\n",
      "Epoch 324/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1263 - accuracy: 0.9524 - val_loss: 0.1542 - val_accuracy: 0.9426\n",
      "Epoch 325/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1262 - accuracy: 0.9521 - val_loss: 0.1539 - val_accuracy: 0.9429\n",
      "Epoch 326/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1261 - accuracy: 0.9522 - val_loss: 0.1542 - val_accuracy: 0.9424\n",
      "Epoch 327/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1261 - accuracy: 0.9520 - val_loss: 0.1538 - val_accuracy: 0.9424\n",
      "Epoch 328/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1260 - accuracy: 0.9522 - val_loss: 0.1537 - val_accuracy: 0.9426\n",
      "Epoch 329/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1259 - accuracy: 0.9523 - val_loss: 0.1539 - val_accuracy: 0.9429\n",
      "Epoch 330/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1258 - accuracy: 0.9521 - val_loss: 0.1542 - val_accuracy: 0.9429\n",
      "Epoch 331/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1257 - accuracy: 0.9524 - val_loss: 0.1535 - val_accuracy: 0.9426\n",
      "Epoch 332/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1255 - accuracy: 0.9525 - val_loss: 0.1545 - val_accuracy: 0.9427\n",
      "Epoch 333/800\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 0.95 - 0s 72us/step - loss: 0.1256 - accuracy: 0.9523 - val_loss: 0.1545 - val_accuracy: 0.9426\n",
      "Epoch 334/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1255 - accuracy: 0.9524 - val_loss: 0.1539 - val_accuracy: 0.9430\n",
      "Epoch 335/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1255 - accuracy: 0.9524 - val_loss: 0.1535 - val_accuracy: 0.9423\n",
      "Epoch 336/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1252 - accuracy: 0.9522 - val_loss: 0.1539 - val_accuracy: 0.9427\n",
      "Epoch 337/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1252 - accuracy: 0.9524 - val_loss: 0.1536 - val_accuracy: 0.9427\n",
      "Epoch 338/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1251 - accuracy: 0.9523 - val_loss: 0.1542 - val_accuracy: 0.9432\n",
      "Epoch 339/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1250 - accuracy: 0.9525 - val_loss: 0.1537 - val_accuracy: 0.9427\n",
      "Epoch 340/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1250 - accuracy: 0.9525 - val_loss: 0.1535 - val_accuracy: 0.9427\n",
      "Epoch 341/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1248 - accuracy: 0.9525 - val_loss: 0.1544 - val_accuracy: 0.9420\n",
      "Epoch 342/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1248 - accuracy: 0.9526 - val_loss: 0.1538 - val_accuracy: 0.9426\n",
      "Epoch 343/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1246 - accuracy: 0.9525 - val_loss: 0.1530 - val_accuracy: 0.9429\n",
      "Epoch 344/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1246 - accuracy: 0.9524 - val_loss: 0.1535 - val_accuracy: 0.9429\n",
      "Epoch 345/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1246 - accuracy: 0.9527 - val_loss: 0.1534 - val_accuracy: 0.9425\n",
      "Epoch 346/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1244 - accuracy: 0.9528 - val_loss: 0.1538 - val_accuracy: 0.9425\n",
      "Epoch 347/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1244 - accuracy: 0.9527 - val_loss: 0.1533 - val_accuracy: 0.9423\n",
      "Epoch 348/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1242 - accuracy: 0.9526 - val_loss: 0.1539 - val_accuracy: 0.9431\n",
      "Epoch 349/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1241 - accuracy: 0.9527 - val_loss: 0.1536 - val_accuracy: 0.9429\n",
      "Epoch 350/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1241 - accuracy: 0.9527 - val_loss: 0.1532 - val_accuracy: 0.9430\n",
      "Epoch 351/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1240 - accuracy: 0.9527 - val_loss: 0.1538 - val_accuracy: 0.9431\n",
      "Epoch 352/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1239 - accuracy: 0.9527 - val_loss: 0.1537 - val_accuracy: 0.9420\n",
      "Epoch 353/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1238 - accuracy: 0.9528 - val_loss: 0.1532 - val_accuracy: 0.9427\n",
      "Epoch 354/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1238 - accuracy: 0.9529 - val_loss: 0.1538 - val_accuracy: 0.9431\n",
      "Epoch 355/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1237 - accuracy: 0.9529 - val_loss: 0.1531 - val_accuracy: 0.9426\n",
      "Epoch 356/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1235 - accuracy: 0.9530 - val_loss: 0.1538 - val_accuracy: 0.9431\n",
      "Epoch 357/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1235 - accuracy: 0.9529 - val_loss: 0.1535 - val_accuracy: 0.9427\n",
      "Epoch 358/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1234 - accuracy: 0.9529 - val_loss: 0.1534 - val_accuracy: 0.9425\n",
      "Epoch 359/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1233 - accuracy: 0.9531 - val_loss: 0.1535 - val_accuracy: 0.9428\n",
      "Epoch 360/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1233 - accuracy: 0.9532 - val_loss: 0.1528 - val_accuracy: 0.9428\n",
      "Epoch 361/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1232 - accuracy: 0.9530 - val_loss: 0.1532 - val_accuracy: 0.9429\n",
      "Epoch 362/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1231 - accuracy: 0.9529 - val_loss: 0.1529 - val_accuracy: 0.9430\n",
      "Epoch 363/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1230 - accuracy: 0.9531 - val_loss: 0.1532 - val_accuracy: 0.9424\n",
      "Epoch 364/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1230 - accuracy: 0.9530 - val_loss: 0.1528 - val_accuracy: 0.9428\n",
      "Epoch 365/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1229 - accuracy: 0.9530 - val_loss: 0.1534 - val_accuracy: 0.9424\n",
      "Epoch 366/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1227 - accuracy: 0.9531 - val_loss: 0.1532 - val_accuracy: 0.9426\n",
      "Epoch 367/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1227 - accuracy: 0.9530 - val_loss: 0.1527 - val_accuracy: 0.9426\n",
      "Epoch 368/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1227 - accuracy: 0.9531 - val_loss: 0.1525 - val_accuracy: 0.9426\n",
      "Epoch 369/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1225 - accuracy: 0.9531 - val_loss: 0.1535 - val_accuracy: 0.9423\n",
      "Epoch 370/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1225 - accuracy: 0.9531 - val_loss: 0.1526 - val_accuracy: 0.9427\n",
      "Epoch 371/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1224 - accuracy: 0.9532 - val_loss: 0.1525 - val_accuracy: 0.9431\n",
      "Epoch 372/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1223 - accuracy: 0.9532 - val_loss: 0.1530 - val_accuracy: 0.9425\n",
      "Epoch 373/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1222 - accuracy: 0.9533 - val_loss: 0.1527 - val_accuracy: 0.9427\n",
      "Epoch 374/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1221 - accuracy: 0.9531 - val_loss: 0.1532 - val_accuracy: 0.9423\n",
      "Epoch 375/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1220 - accuracy: 0.9533 - val_loss: 0.1527 - val_accuracy: 0.9431\n",
      "Epoch 376/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1220 - accuracy: 0.9533 - val_loss: 0.1528 - val_accuracy: 0.9428\n",
      "Epoch 377/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1219 - accuracy: 0.9535 - val_loss: 0.1529 - val_accuracy: 0.9428\n",
      "Epoch 378/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1219 - accuracy: 0.9533 - val_loss: 0.1537 - val_accuracy: 0.9431\n",
      "Epoch 379/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1218 - accuracy: 0.9534 - val_loss: 0.1528 - val_accuracy: 0.9425\n",
      "Epoch 380/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1217 - accuracy: 0.9533 - val_loss: 0.1527 - val_accuracy: 0.9425\n",
      "Epoch 381/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1216 - accuracy: 0.9533 - val_loss: 0.1529 - val_accuracy: 0.9430\n",
      "Epoch 382/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1216 - accuracy: 0.9534 - val_loss: 0.1526 - val_accuracy: 0.9426\n",
      "Epoch 383/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1214 - accuracy: 0.9534 - val_loss: 0.1536 - val_accuracy: 0.9428\n",
      "Epoch 384/800\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.95 - 0s 72us/step - loss: 0.1215 - accuracy: 0.9533 - val_loss: 0.1533 - val_accuracy: 0.9428\n",
      "Epoch 385/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1213 - accuracy: 0.9535 - val_loss: 0.1538 - val_accuracy: 0.9420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1212 - accuracy: 0.9534 - val_loss: 0.1526 - val_accuracy: 0.9423\n",
      "Epoch 387/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1212 - accuracy: 0.9535 - val_loss: 0.1529 - val_accuracy: 0.9428\n",
      "Epoch 388/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1210 - accuracy: 0.9536 - val_loss: 0.1525 - val_accuracy: 0.9432\n",
      "Epoch 389/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1210 - accuracy: 0.9538 - val_loss: 0.1532 - val_accuracy: 0.9432\n",
      "Epoch 390/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1209 - accuracy: 0.9536 - val_loss: 0.1528 - val_accuracy: 0.9426\n",
      "Epoch 391/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1208 - accuracy: 0.9536 - val_loss: 0.1533 - val_accuracy: 0.9424\n",
      "Epoch 392/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1208 - accuracy: 0.9536 - val_loss: 0.1530 - val_accuracy: 0.9430\n",
      "Epoch 393/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1206 - accuracy: 0.9538 - val_loss: 0.1531 - val_accuracy: 0.9424\n",
      "Epoch 394/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1206 - accuracy: 0.9538 - val_loss: 0.1531 - val_accuracy: 0.9424\n",
      "Epoch 395/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1205 - accuracy: 0.9535 - val_loss: 0.1526 - val_accuracy: 0.9425\n",
      "Epoch 396/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1204 - accuracy: 0.9536 - val_loss: 0.1530 - val_accuracy: 0.9427\n",
      "Epoch 397/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1205 - accuracy: 0.9536 - val_loss: 0.1528 - val_accuracy: 0.9423\n",
      "Epoch 398/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1203 - accuracy: 0.9539 - val_loss: 0.1524 - val_accuracy: 0.9426\n",
      "Epoch 399/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1203 - accuracy: 0.9536 - val_loss: 0.1525 - val_accuracy: 0.9424\n",
      "Epoch 400/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1202 - accuracy: 0.9538 - val_loss: 0.1529 - val_accuracy: 0.9428\n",
      "Epoch 401/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1201 - accuracy: 0.9537 - val_loss: 0.1529 - val_accuracy: 0.9424\n",
      "Epoch 402/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1200 - accuracy: 0.9540 - val_loss: 0.1526 - val_accuracy: 0.9423\n",
      "Epoch 403/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1199 - accuracy: 0.9539 - val_loss: 0.1532 - val_accuracy: 0.9430\n",
      "Epoch 404/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1199 - accuracy: 0.9538 - val_loss: 0.1527 - val_accuracy: 0.9428\n",
      "Epoch 405/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1197 - accuracy: 0.9538 - val_loss: 0.1529 - val_accuracy: 0.9428\n",
      "Epoch 406/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1198 - accuracy: 0.9538 - val_loss: 0.1525 - val_accuracy: 0.9427\n",
      "Epoch 407/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1197 - accuracy: 0.9540 - val_loss: 0.1529 - val_accuracy: 0.9426\n",
      "Epoch 408/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1197 - accuracy: 0.9538 - val_loss: 0.1526 - val_accuracy: 0.9423\n",
      "Epoch 409/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1195 - accuracy: 0.9539 - val_loss: 0.1526 - val_accuracy: 0.9430\n",
      "Epoch 410/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1194 - accuracy: 0.9542 - val_loss: 0.1534 - val_accuracy: 0.9426\n",
      "Epoch 411/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1194 - accuracy: 0.9542 - val_loss: 0.1526 - val_accuracy: 0.9427\n",
      "Epoch 412/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1194 - accuracy: 0.9542 - val_loss: 0.1532 - val_accuracy: 0.9431\n",
      "Epoch 413/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1192 - accuracy: 0.9541 - val_loss: 0.1528 - val_accuracy: 0.9425\n",
      "Epoch 414/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1192 - accuracy: 0.9542 - val_loss: 0.1528 - val_accuracy: 0.9427\n",
      "Epoch 415/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1191 - accuracy: 0.9540 - val_loss: 0.1530 - val_accuracy: 0.9422\n",
      "Epoch 416/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1191 - accuracy: 0.9540 - val_loss: 0.1529 - val_accuracy: 0.9425\n",
      "Epoch 417/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1190 - accuracy: 0.9541 - val_loss: 0.1527 - val_accuracy: 0.9426\n",
      "Epoch 418/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1189 - accuracy: 0.9543 - val_loss: 0.1522 - val_accuracy: 0.9429\n",
      "Epoch 419/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1189 - accuracy: 0.9541 - val_loss: 0.1526 - val_accuracy: 0.9429\n",
      "Epoch 420/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1188 - accuracy: 0.9544 - val_loss: 0.1527 - val_accuracy: 0.9426\n",
      "Epoch 421/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1188 - accuracy: 0.9542 - val_loss: 0.1528 - val_accuracy: 0.9423\n",
      "Epoch 422/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1186 - accuracy: 0.9543 - val_loss: 0.1530 - val_accuracy: 0.9428\n",
      "Epoch 423/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1184 - accuracy: 0.9543 - val_loss: 0.1525 - val_accuracy: 0.9425\n",
      "Epoch 424/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1184 - accuracy: 0.9544 - val_loss: 0.1526 - val_accuracy: 0.9419\n",
      "Epoch 425/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1185 - accuracy: 0.9544 - val_loss: 0.1528 - val_accuracy: 0.9428\n",
      "Epoch 426/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1184 - accuracy: 0.9543 - val_loss: 0.1528 - val_accuracy: 0.9423\n",
      "Epoch 427/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1182 - accuracy: 0.9544 - val_loss: 0.1527 - val_accuracy: 0.9429\n",
      "Epoch 428/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1182 - accuracy: 0.9544 - val_loss: 0.1535 - val_accuracy: 0.9425\n",
      "Epoch 429/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1182 - accuracy: 0.9543 - val_loss: 0.1531 - val_accuracy: 0.9427\n",
      "Epoch 430/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1181 - accuracy: 0.9544 - val_loss: 0.1528 - val_accuracy: 0.9421\n",
      "Epoch 431/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1180 - accuracy: 0.9547 - val_loss: 0.1534 - val_accuracy: 0.9428\n",
      "Epoch 432/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1179 - accuracy: 0.9544 - val_loss: 0.1529 - val_accuracy: 0.9424\n",
      "Epoch 433/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1178 - accuracy: 0.9543 - val_loss: 0.1526 - val_accuracy: 0.9432\n",
      "Epoch 434/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1178 - accuracy: 0.9546 - val_loss: 0.1529 - val_accuracy: 0.9428\n",
      "Epoch 435/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1178 - accuracy: 0.9546 - val_loss: 0.1527 - val_accuracy: 0.9424\n",
      "Epoch 436/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1177 - accuracy: 0.9545 - val_loss: 0.1527 - val_accuracy: 0.9423\n",
      "Epoch 437/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1176 - accuracy: 0.9543 - val_loss: 0.1525 - val_accuracy: 0.9427\n",
      "Epoch 438/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1174 - accuracy: 0.9547 - val_loss: 0.1534 - val_accuracy: 0.9425\n",
      "Epoch 439/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1175 - accuracy: 0.9547 - val_loss: 0.1527 - val_accuracy: 0.9431\n",
      "Epoch 440/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1174 - accuracy: 0.9546 - val_loss: 0.1527 - val_accuracy: 0.9428\n",
      "Epoch 441/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1174 - accuracy: 0.9546 - val_loss: 0.1524 - val_accuracy: 0.9426\n",
      "Epoch 442/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1172 - accuracy: 0.9546 - val_loss: 0.1530 - val_accuracy: 0.9424\n",
      "Epoch 443/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1172 - accuracy: 0.9547 - val_loss: 0.1532 - val_accuracy: 0.9420\n",
      "Epoch 444/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1171 - accuracy: 0.9548 - val_loss: 0.1529 - val_accuracy: 0.9424\n",
      "Epoch 445/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1170 - accuracy: 0.9547 - val_loss: 0.1535 - val_accuracy: 0.9424\n",
      "Epoch 446/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1170 - accuracy: 0.9548 - val_loss: 0.1525 - val_accuracy: 0.9423\n",
      "Epoch 447/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1170 - accuracy: 0.9547 - val_loss: 0.1535 - val_accuracy: 0.9419\n",
      "Epoch 448/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1169 - accuracy: 0.9547 - val_loss: 0.1529 - val_accuracy: 0.9427\n",
      "Epoch 449/800\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.1165 - accuracy: 0.95 - 0s 74us/step - loss: 0.1167 - accuracy: 0.9549 - val_loss: 0.1532 - val_accuracy: 0.9424\n",
      "Epoch 450/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1167 - accuracy: 0.9550 - val_loss: 0.1532 - val_accuracy: 0.9422\n",
      "Epoch 451/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1167 - accuracy: 0.9550 - val_loss: 0.1532 - val_accuracy: 0.9424\n",
      "Epoch 452/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1166 - accuracy: 0.9550 - val_loss: 0.1527 - val_accuracy: 0.9426\n",
      "Epoch 453/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1164 - accuracy: 0.9548 - val_loss: 0.1532 - val_accuracy: 0.9422\n",
      "Epoch 454/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1165 - accuracy: 0.9551 - val_loss: 0.1530 - val_accuracy: 0.9425\n",
      "Epoch 455/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1163 - accuracy: 0.9549 - val_loss: 0.1522 - val_accuracy: 0.9422\n",
      "Epoch 456/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1163 - accuracy: 0.9549 - val_loss: 0.1528 - val_accuracy: 0.9425\n",
      "Epoch 457/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1163 - accuracy: 0.9550 - val_loss: 0.1528 - val_accuracy: 0.9422\n",
      "Epoch 458/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1162 - accuracy: 0.9550 - val_loss: 0.1533 - val_accuracy: 0.9426\n",
      "Epoch 459/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1161 - accuracy: 0.9550 - val_loss: 0.1531 - val_accuracy: 0.9429\n",
      "Epoch 460/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1160 - accuracy: 0.9549 - val_loss: 0.1534 - val_accuracy: 0.9427\n",
      "Epoch 461/800\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.95 - 0s 73us/step - loss: 0.1160 - accuracy: 0.9549 - val_loss: 0.1534 - val_accuracy: 0.9426\n",
      "Epoch 462/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1159 - accuracy: 0.9553 - val_loss: 0.1533 - val_accuracy: 0.9416\n",
      "Epoch 463/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1159 - accuracy: 0.9551 - val_loss: 0.1531 - val_accuracy: 0.9421\n",
      "Epoch 464/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1158 - accuracy: 0.9552 - val_loss: 0.1529 - val_accuracy: 0.9422\n",
      "Epoch 465/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1158 - accuracy: 0.9551 - val_loss: 0.1528 - val_accuracy: 0.9428\n",
      "Epoch 466/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1157 - accuracy: 0.9550 - val_loss: 0.1534 - val_accuracy: 0.9422\n",
      "Epoch 467/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1156 - accuracy: 0.9553 - val_loss: 0.1538 - val_accuracy: 0.9421\n",
      "Epoch 468/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1156 - accuracy: 0.9555 - val_loss: 0.1529 - val_accuracy: 0.9426\n",
      "Epoch 469/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1155 - accuracy: 0.9553 - val_loss: 0.1532 - val_accuracy: 0.9429\n",
      "Epoch 470/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1154 - accuracy: 0.9551 - val_loss: 0.1527 - val_accuracy: 0.9426\n",
      "Epoch 471/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1154 - accuracy: 0.9553 - val_loss: 0.1532 - val_accuracy: 0.9425\n",
      "Epoch 472/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1153 - accuracy: 0.9554 - val_loss: 0.1536 - val_accuracy: 0.9426\n",
      "Epoch 473/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1151 - accuracy: 0.9554 - val_loss: 0.1531 - val_accuracy: 0.9419\n",
      "Epoch 474/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1151 - accuracy: 0.9552 - val_loss: 0.1528 - val_accuracy: 0.9425\n",
      "Epoch 475/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1150 - accuracy: 0.9557 - val_loss: 0.1537 - val_accuracy: 0.9418\n",
      "Epoch 476/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1150 - accuracy: 0.9554 - val_loss: 0.1540 - val_accuracy: 0.9422\n",
      "Epoch 477/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1150 - accuracy: 0.9552 - val_loss: 0.1534 - val_accuracy: 0.9422\n",
      "Epoch 478/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1150 - accuracy: 0.9555 - val_loss: 0.1529 - val_accuracy: 0.9427\n",
      "Epoch 479/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1148 - accuracy: 0.9555 - val_loss: 0.1529 - val_accuracy: 0.9424\n",
      "Epoch 480/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1148 - accuracy: 0.9554 - val_loss: 0.1528 - val_accuracy: 0.9422\n",
      "Epoch 481/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1147 - accuracy: 0.9553 - val_loss: 0.1530 - val_accuracy: 0.9425\n",
      "Epoch 482/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1146 - accuracy: 0.9555 - val_loss: 0.1535 - val_accuracy: 0.9430\n",
      "Epoch 483/800\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.95 - 0s 73us/step - loss: 0.1146 - accuracy: 0.9554 - val_loss: 0.1528 - val_accuracy: 0.9425\n",
      "Epoch 484/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1146 - accuracy: 0.9556 - val_loss: 0.1534 - val_accuracy: 0.9425\n",
      "Epoch 485/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1144 - accuracy: 0.9557 - val_loss: 0.1533 - val_accuracy: 0.9426\n",
      "Epoch 486/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1142 - accuracy: 0.9558 - val_loss: 0.1535 - val_accuracy: 0.9427\n",
      "Epoch 487/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1142 - accuracy: 0.9555 - val_loss: 0.1532 - val_accuracy: 0.9421\n",
      "Epoch 488/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1142 - accuracy: 0.9557 - val_loss: 0.1533 - val_accuracy: 0.9422\n",
      "Epoch 489/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1141 - accuracy: 0.9558 - val_loss: 0.1533 - val_accuracy: 0.9426\n",
      "Epoch 490/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1140 - accuracy: 0.9558 - val_loss: 0.1534 - val_accuracy: 0.9421\n",
      "Epoch 491/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1141 - accuracy: 0.9556 - val_loss: 0.1537 - val_accuracy: 0.9422\n",
      "Epoch 492/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1140 - accuracy: 0.9559 - val_loss: 0.1544 - val_accuracy: 0.9422\n",
      "Epoch 493/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1139 - accuracy: 0.9560 - val_loss: 0.1530 - val_accuracy: 0.9421\n",
      "Epoch 494/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1139 - accuracy: 0.9558 - val_loss: 0.1534 - val_accuracy: 0.9430\n",
      "Epoch 495/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1138 - accuracy: 0.9558 - val_loss: 0.1535 - val_accuracy: 0.9418\n",
      "Epoch 496/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1138 - accuracy: 0.9558 - val_loss: 0.1537 - val_accuracy: 0.9428\n",
      "Epoch 497/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1137 - accuracy: 0.9560 - val_loss: 0.1533 - val_accuracy: 0.9423\n",
      "Epoch 498/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1136 - accuracy: 0.9558 - val_loss: 0.1536 - val_accuracy: 0.9425\n",
      "Epoch 499/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1135 - accuracy: 0.9560 - val_loss: 0.1535 - val_accuracy: 0.9419\n",
      "Epoch 500/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1135 - accuracy: 0.9560 - val_loss: 0.1535 - val_accuracy: 0.9421\n",
      "Epoch 501/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1135 - accuracy: 0.9557 - val_loss: 0.1537 - val_accuracy: 0.9427\n",
      "Epoch 502/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1134 - accuracy: 0.9560 - val_loss: 0.1534 - val_accuracy: 0.9422\n",
      "Epoch 503/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1133 - accuracy: 0.9560 - val_loss: 0.1539 - val_accuracy: 0.9421\n",
      "Epoch 504/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1132 - accuracy: 0.9559 - val_loss: 0.1556 - val_accuracy: 0.9412\n",
      "Epoch 505/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1132 - accuracy: 0.9559 - val_loss: 0.1536 - val_accuracy: 0.9420\n",
      "Epoch 506/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1130 - accuracy: 0.9562 - val_loss: 0.1536 - val_accuracy: 0.9414\n",
      "Epoch 507/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1130 - accuracy: 0.9560 - val_loss: 0.1541 - val_accuracy: 0.9424\n",
      "Epoch 508/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1131 - accuracy: 0.9561 - val_loss: 0.1548 - val_accuracy: 0.9415\n",
      "Epoch 509/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1129 - accuracy: 0.9560 - val_loss: 0.1533 - val_accuracy: 0.9417\n",
      "Epoch 510/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1129 - accuracy: 0.9561 - val_loss: 0.1536 - val_accuracy: 0.9418\n",
      "Epoch 511/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1128 - accuracy: 0.9561 - val_loss: 0.1535 - val_accuracy: 0.9420\n",
      "Epoch 512/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1128 - accuracy: 0.9561 - val_loss: 0.1536 - val_accuracy: 0.9427\n",
      "Epoch 513/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1128 - accuracy: 0.9560 - val_loss: 0.1535 - val_accuracy: 0.9419\n",
      "Epoch 514/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1126 - accuracy: 0.9563 - val_loss: 0.1543 - val_accuracy: 0.9419\n",
      "Epoch 515/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1126 - accuracy: 0.9562 - val_loss: 0.1537 - val_accuracy: 0.9421\n",
      "Epoch 516/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1126 - accuracy: 0.9561 - val_loss: 0.1537 - val_accuracy: 0.9427\n",
      "Epoch 517/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1124 - accuracy: 0.9564 - val_loss: 0.1537 - val_accuracy: 0.9423\n",
      "Epoch 518/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1124 - accuracy: 0.9564 - val_loss: 0.1542 - val_accuracy: 0.9416\n",
      "Epoch 519/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1123 - accuracy: 0.9563 - val_loss: 0.1542 - val_accuracy: 0.9417\n",
      "Epoch 520/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1122 - accuracy: 0.9564 - val_loss: 0.1534 - val_accuracy: 0.9418\n",
      "Epoch 521/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1122 - accuracy: 0.9562 - val_loss: 0.1538 - val_accuracy: 0.9420\n",
      "Epoch 522/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1121 - accuracy: 0.9564 - val_loss: 0.1535 - val_accuracy: 0.9419\n",
      "Epoch 523/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1121 - accuracy: 0.9564 - val_loss: 0.1534 - val_accuracy: 0.9425\n",
      "Epoch 524/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1121 - accuracy: 0.9563 - val_loss: 0.1544 - val_accuracy: 0.9420\n",
      "Epoch 525/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1119 - accuracy: 0.9562 - val_loss: 0.1541 - val_accuracy: 0.9418\n",
      "Epoch 526/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1119 - accuracy: 0.9565 - val_loss: 0.1541 - val_accuracy: 0.9417\n",
      "Epoch 527/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1118 - accuracy: 0.9565 - val_loss: 0.1541 - val_accuracy: 0.9416\n",
      "Epoch 528/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1119 - accuracy: 0.9565 - val_loss: 0.1544 - val_accuracy: 0.9423\n",
      "Epoch 529/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1116 - accuracy: 0.9564 - val_loss: 0.1544 - val_accuracy: 0.9423\n",
      "Epoch 530/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1116 - accuracy: 0.9565 - val_loss: 0.1539 - val_accuracy: 0.9424\n",
      "Epoch 531/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1115 - accuracy: 0.9565 - val_loss: 0.1547 - val_accuracy: 0.9417\n",
      "Epoch 532/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1115 - accuracy: 0.9564 - val_loss: 0.1547 - val_accuracy: 0.9409\n",
      "Epoch 533/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1115 - accuracy: 0.9568 - val_loss: 0.1538 - val_accuracy: 0.9422\n",
      "Epoch 534/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1113 - accuracy: 0.9567 - val_loss: 0.1545 - val_accuracy: 0.9421\n",
      "Epoch 535/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1113 - accuracy: 0.9567 - val_loss: 0.1540 - val_accuracy: 0.9420\n",
      "Epoch 536/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1112 - accuracy: 0.9568 - val_loss: 0.1550 - val_accuracy: 0.9417\n",
      "Epoch 537/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1112 - accuracy: 0.9568 - val_loss: 0.1544 - val_accuracy: 0.9419\n",
      "Epoch 538/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1111 - accuracy: 0.9567 - val_loss: 0.1540 - val_accuracy: 0.9419\n",
      "Epoch 539/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1112 - accuracy: 0.9567 - val_loss: 0.1538 - val_accuracy: 0.9423\n",
      "Epoch 540/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1110 - accuracy: 0.9569 - val_loss: 0.1550 - val_accuracy: 0.9424\n",
      "Epoch 541/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1110 - accuracy: 0.9568 - val_loss: 0.1542 - val_accuracy: 0.9412\n",
      "Epoch 542/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1109 - accuracy: 0.9566 - val_loss: 0.1545 - val_accuracy: 0.9417\n",
      "Epoch 543/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1107 - accuracy: 0.9568 - val_loss: 0.1547 - val_accuracy: 0.9416\n",
      "Epoch 544/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1107 - accuracy: 0.9567 - val_loss: 0.1546 - val_accuracy: 0.9418\n",
      "Epoch 545/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1106 - accuracy: 0.9570 - val_loss: 0.1556 - val_accuracy: 0.9416\n",
      "Epoch 546/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1106 - accuracy: 0.9568 - val_loss: 0.1540 - val_accuracy: 0.9422\n",
      "Epoch 547/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1105 - accuracy: 0.9570 - val_loss: 0.1539 - val_accuracy: 0.9427\n",
      "Epoch 548/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1105 - accuracy: 0.9569 - val_loss: 0.1545 - val_accuracy: 0.9420\n",
      "Epoch 549/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1103 - accuracy: 0.9570 - val_loss: 0.1543 - val_accuracy: 0.9422\n",
      "Epoch 550/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1104 - accuracy: 0.9570 - val_loss: 0.1549 - val_accuracy: 0.9417\n",
      "Epoch 551/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1102 - accuracy: 0.9570 - val_loss: 0.1548 - val_accuracy: 0.9418\n",
      "Epoch 552/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1103 - accuracy: 0.9569 - val_loss: 0.1550 - val_accuracy: 0.9412\n",
      "Epoch 553/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1102 - accuracy: 0.9571 - val_loss: 0.1550 - val_accuracy: 0.9420\n",
      "Epoch 554/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1101 - accuracy: 0.9572 - val_loss: 0.1543 - val_accuracy: 0.9422\n",
      "Epoch 555/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1101 - accuracy: 0.9571 - val_loss: 0.1545 - val_accuracy: 0.9421\n",
      "Epoch 556/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1100 - accuracy: 0.9570 - val_loss: 0.1545 - val_accuracy: 0.9421\n",
      "Epoch 557/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1098 - accuracy: 0.9571 - val_loss: 0.1545 - val_accuracy: 0.9413\n",
      "Epoch 558/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1099 - accuracy: 0.9570 - val_loss: 0.1545 - val_accuracy: 0.9419\n",
      "Epoch 559/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1097 - accuracy: 0.9573 - val_loss: 0.1550 - val_accuracy: 0.9418\n",
      "Epoch 560/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1097 - accuracy: 0.9572 - val_loss: 0.1555 - val_accuracy: 0.9419\n",
      "Epoch 561/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1097 - accuracy: 0.9572 - val_loss: 0.1559 - val_accuracy: 0.9417\n",
      "Epoch 562/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1095 - accuracy: 0.9572 - val_loss: 0.1544 - val_accuracy: 0.9421\n",
      "Epoch 563/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1095 - accuracy: 0.9574 - val_loss: 0.1559 - val_accuracy: 0.9417\n",
      "Epoch 564/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1094 - accuracy: 0.9572 - val_loss: 0.1547 - val_accuracy: 0.9414\n",
      "Epoch 565/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1094 - accuracy: 0.9573 - val_loss: 0.1550 - val_accuracy: 0.9416\n",
      "Epoch 566/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1094 - accuracy: 0.9572 - val_loss: 0.1545 - val_accuracy: 0.9420\n",
      "Epoch 567/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1093 - accuracy: 0.9575 - val_loss: 0.1556 - val_accuracy: 0.9416\n",
      "Epoch 568/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1093 - accuracy: 0.9575 - val_loss: 0.1555 - val_accuracy: 0.9417\n",
      "Epoch 569/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1091 - accuracy: 0.9575 - val_loss: 0.1557 - val_accuracy: 0.9417\n",
      "Epoch 570/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1089 - accuracy: 0.9573 - val_loss: 0.1558 - val_accuracy: 0.9409\n",
      "Epoch 571/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1090 - accuracy: 0.9573 - val_loss: 0.1551 - val_accuracy: 0.9423\n",
      "Epoch 572/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1089 - accuracy: 0.9574 - val_loss: 0.1562 - val_accuracy: 0.9423\n",
      "Epoch 573/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1089 - accuracy: 0.9576 - val_loss: 0.1551 - val_accuracy: 0.9417\n",
      "Epoch 574/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1089 - accuracy: 0.9577 - val_loss: 0.1549 - val_accuracy: 0.9418\n",
      "Epoch 575/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1088 - accuracy: 0.9577 - val_loss: 0.1553 - val_accuracy: 0.9416\n",
      "Epoch 576/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1087 - accuracy: 0.9574 - val_loss: 0.1559 - val_accuracy: 0.9420\n",
      "Epoch 577/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1087 - accuracy: 0.9576 - val_loss: 0.1561 - val_accuracy: 0.9420\n",
      "Epoch 578/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1085 - accuracy: 0.9578 - val_loss: 0.1557 - val_accuracy: 0.9418\n",
      "Epoch 579/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1085 - accuracy: 0.9577 - val_loss: 0.1551 - val_accuracy: 0.9418\n",
      "Epoch 580/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1084 - accuracy: 0.9577 - val_loss: 0.1571 - val_accuracy: 0.9415\n",
      "Epoch 581/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1085 - accuracy: 0.9575 - val_loss: 0.1560 - val_accuracy: 0.9421\n",
      "Epoch 582/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1083 - accuracy: 0.9576 - val_loss: 0.1549 - val_accuracy: 0.9417\n",
      "Epoch 583/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1083 - accuracy: 0.9577 - val_loss: 0.1555 - val_accuracy: 0.9406\n",
      "Epoch 584/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1082 - accuracy: 0.9576 - val_loss: 0.1567 - val_accuracy: 0.9410\n",
      "Epoch 585/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1082 - accuracy: 0.9577 - val_loss: 0.1562 - val_accuracy: 0.9413\n",
      "Epoch 586/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1081 - accuracy: 0.9578 - val_loss: 0.1570 - val_accuracy: 0.9408\n",
      "Epoch 587/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1080 - accuracy: 0.9579 - val_loss: 0.1552 - val_accuracy: 0.9418\n",
      "Epoch 588/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1079 - accuracy: 0.9579 - val_loss: 0.1552 - val_accuracy: 0.9418\n",
      "Epoch 589/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1078 - accuracy: 0.9579 - val_loss: 0.1566 - val_accuracy: 0.9412\n",
      "Epoch 590/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1078 - accuracy: 0.9579 - val_loss: 0.1576 - val_accuracy: 0.9406\n",
      "Epoch 591/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1077 - accuracy: 0.9580 - val_loss: 0.1559 - val_accuracy: 0.9421\n",
      "Epoch 592/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1078 - accuracy: 0.9578 - val_loss: 0.1561 - val_accuracy: 0.9411\n",
      "Epoch 593/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1076 - accuracy: 0.9581 - val_loss: 0.1560 - val_accuracy: 0.9413\n",
      "Epoch 594/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1076 - accuracy: 0.9577 - val_loss: 0.1562 - val_accuracy: 0.9418\n",
      "Epoch 595/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1075 - accuracy: 0.9581 - val_loss: 0.1567 - val_accuracy: 0.9419\n",
      "Epoch 596/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1073 - accuracy: 0.9580 - val_loss: 0.1569 - val_accuracy: 0.9410\n",
      "Epoch 597/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1075 - accuracy: 0.9583 - val_loss: 0.1561 - val_accuracy: 0.9411\n",
      "Epoch 598/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1073 - accuracy: 0.9582 - val_loss: 0.1559 - val_accuracy: 0.9413\n",
      "Epoch 599/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1073 - accuracy: 0.9582 - val_loss: 0.1556 - val_accuracy: 0.9413\n",
      "Epoch 600/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1072 - accuracy: 0.9582 - val_loss: 0.1575 - val_accuracy: 0.9412\n",
      "Epoch 601/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1072 - accuracy: 0.9582 - val_loss: 0.1564 - val_accuracy: 0.9417\n",
      "Epoch 602/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1070 - accuracy: 0.9581 - val_loss: 0.1557 - val_accuracy: 0.9409\n",
      "Epoch 603/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1069 - accuracy: 0.9583 - val_loss: 0.1564 - val_accuracy: 0.9421\n",
      "Epoch 604/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1069 - accuracy: 0.9584 - val_loss: 0.1566 - val_accuracy: 0.9407\n",
      "Epoch 605/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1068 - accuracy: 0.9582 - val_loss: 0.1560 - val_accuracy: 0.9415\n",
      "Epoch 606/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1068 - accuracy: 0.9581 - val_loss: 0.1559 - val_accuracy: 0.9413\n",
      "Epoch 607/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1067 - accuracy: 0.9583 - val_loss: 0.1574 - val_accuracy: 0.9420\n",
      "Epoch 608/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1067 - accuracy: 0.9582 - val_loss: 0.1573 - val_accuracy: 0.9410\n",
      "Epoch 609/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1067 - accuracy: 0.9582 - val_loss: 0.1565 - val_accuracy: 0.9411\n",
      "Epoch 610/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1066 - accuracy: 0.9582 - val_loss: 0.1559 - val_accuracy: 0.9414\n",
      "Epoch 611/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1065 - accuracy: 0.9582 - val_loss: 0.1569 - val_accuracy: 0.9411\n",
      "Epoch 612/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1063 - accuracy: 0.9583 - val_loss: 0.1591 - val_accuracy: 0.9414\n",
      "Epoch 613/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1062 - accuracy: 0.9584 - val_loss: 0.1567 - val_accuracy: 0.9412\n",
      "Epoch 614/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1064 - accuracy: 0.9584 - val_loss: 0.1566 - val_accuracy: 0.9411\n",
      "Epoch 615/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1063 - accuracy: 0.9585 - val_loss: 0.1563 - val_accuracy: 0.9416\n",
      "Epoch 616/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1062 - accuracy: 0.9585 - val_loss: 0.1571 - val_accuracy: 0.9407\n",
      "Epoch 617/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1062 - accuracy: 0.9584 - val_loss: 0.1569 - val_accuracy: 0.9410\n",
      "Epoch 618/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1059 - accuracy: 0.9586 - val_loss: 0.1576 - val_accuracy: 0.9414\n",
      "Epoch 619/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1060 - accuracy: 0.9587 - val_loss: 0.1573 - val_accuracy: 0.9407\n",
      "Epoch 620/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1058 - accuracy: 0.9588 - val_loss: 0.1574 - val_accuracy: 0.9407\n",
      "Epoch 621/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1059 - accuracy: 0.9585 - val_loss: 0.1567 - val_accuracy: 0.9416\n",
      "Epoch 622/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1059 - accuracy: 0.9589 - val_loss: 0.1566 - val_accuracy: 0.9413\n",
      "Epoch 623/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1056 - accuracy: 0.9587 - val_loss: 0.1577 - val_accuracy: 0.9410\n",
      "Epoch 624/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1057 - accuracy: 0.9586 - val_loss: 0.1573 - val_accuracy: 0.9411\n",
      "Epoch 625/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1056 - accuracy: 0.9586 - val_loss: 0.1575 - val_accuracy: 0.9410\n",
      "Epoch 626/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1055 - accuracy: 0.9589 - val_loss: 0.1577 - val_accuracy: 0.9409\n",
      "Epoch 627/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1056 - accuracy: 0.9589 - val_loss: 0.1570 - val_accuracy: 0.9414\n",
      "Epoch 628/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1054 - accuracy: 0.9586 - val_loss: 0.1576 - val_accuracy: 0.9412\n",
      "Epoch 629/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1053 - accuracy: 0.9588 - val_loss: 0.1578 - val_accuracy: 0.9407\n",
      "Epoch 630/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1054 - accuracy: 0.9587 - val_loss: 0.1573 - val_accuracy: 0.9410\n",
      "Epoch 631/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1052 - accuracy: 0.9590 - val_loss: 0.1573 - val_accuracy: 0.9412\n",
      "Epoch 632/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1052 - accuracy: 0.9588 - val_loss: 0.1579 - val_accuracy: 0.9415\n",
      "Epoch 633/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1050 - accuracy: 0.9591 - val_loss: 0.1577 - val_accuracy: 0.9414\n",
      "Epoch 634/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1051 - accuracy: 0.9589 - val_loss: 0.1572 - val_accuracy: 0.9415\n",
      "Epoch 635/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1049 - accuracy: 0.9592 - val_loss: 0.1585 - val_accuracy: 0.9408\n",
      "Epoch 636/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1050 - accuracy: 0.9589 - val_loss: 0.1590 - val_accuracy: 0.9420\n",
      "Epoch 637/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1049 - accuracy: 0.9590 - val_loss: 0.1570 - val_accuracy: 0.9410\n",
      "Epoch 638/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1046 - accuracy: 0.9591 - val_loss: 0.1586 - val_accuracy: 0.9408\n",
      "Epoch 639/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1048 - accuracy: 0.9588 - val_loss: 0.1574 - val_accuracy: 0.9415\n",
      "Epoch 640/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1046 - accuracy: 0.9590 - val_loss: 0.1578 - val_accuracy: 0.9406\n",
      "Epoch 641/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1047 - accuracy: 0.9590 - val_loss: 0.1585 - val_accuracy: 0.9410\n",
      "Epoch 642/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1045 - accuracy: 0.9591 - val_loss: 0.1583 - val_accuracy: 0.9410\n",
      "Epoch 643/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1044 - accuracy: 0.9591 - val_loss: 0.1583 - val_accuracy: 0.9408\n",
      "Epoch 644/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1044 - accuracy: 0.9592 - val_loss: 0.1581 - val_accuracy: 0.9406\n",
      "Epoch 645/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1044 - accuracy: 0.9591 - val_loss: 0.1584 - val_accuracy: 0.9413\n",
      "Epoch 646/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1043 - accuracy: 0.9592 - val_loss: 0.1590 - val_accuracy: 0.9412\n",
      "Epoch 647/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1043 - accuracy: 0.9592 - val_loss: 0.1590 - val_accuracy: 0.9406\n",
      "Epoch 648/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1042 - accuracy: 0.9592 - val_loss: 0.1588 - val_accuracy: 0.9419\n",
      "Epoch 649/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1040 - accuracy: 0.9593 - val_loss: 0.1584 - val_accuracy: 0.9407\n",
      "Epoch 650/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1039 - accuracy: 0.9592 - val_loss: 0.1581 - val_accuracy: 0.9408\n",
      "Epoch 651/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1040 - accuracy: 0.9594 - val_loss: 0.1584 - val_accuracy: 0.9413\n",
      "Epoch 652/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1039 - accuracy: 0.9595 - val_loss: 0.1588 - val_accuracy: 0.9413\n",
      "Epoch 653/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1039 - accuracy: 0.9595 - val_loss: 0.1595 - val_accuracy: 0.9405\n",
      "Epoch 654/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1038 - accuracy: 0.9592 - val_loss: 0.1585 - val_accuracy: 0.9410\n",
      "Epoch 655/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1036 - accuracy: 0.9597 - val_loss: 0.1592 - val_accuracy: 0.9411\n",
      "Epoch 656/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1036 - accuracy: 0.9594 - val_loss: 0.1583 - val_accuracy: 0.9413\n",
      "Epoch 657/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1035 - accuracy: 0.9595 - val_loss: 0.1594 - val_accuracy: 0.9404\n",
      "Epoch 658/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1034 - accuracy: 0.9593 - val_loss: 0.1590 - val_accuracy: 0.9407\n",
      "Epoch 659/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1035 - accuracy: 0.9596 - val_loss: 0.1580 - val_accuracy: 0.9415\n",
      "Epoch 660/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1033 - accuracy: 0.9594 - val_loss: 0.1592 - val_accuracy: 0.9405\n",
      "Epoch 661/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1032 - accuracy: 0.9598 - val_loss: 0.1587 - val_accuracy: 0.9415\n",
      "Epoch 662/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1032 - accuracy: 0.9594 - val_loss: 0.1599 - val_accuracy: 0.9408\n",
      "Epoch 663/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1031 - accuracy: 0.9596 - val_loss: 0.1590 - val_accuracy: 0.9419\n",
      "Epoch 664/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1030 - accuracy: 0.9598 - val_loss: 0.1597 - val_accuracy: 0.9396\n",
      "Epoch 665/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1031 - accuracy: 0.9594 - val_loss: 0.1599 - val_accuracy: 0.9407\n",
      "Epoch 666/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1029 - accuracy: 0.9598 - val_loss: 0.1609 - val_accuracy: 0.9405\n",
      "Epoch 667/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1030 - accuracy: 0.9597 - val_loss: 0.1590 - val_accuracy: 0.9411\n",
      "Epoch 668/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1028 - accuracy: 0.9598 - val_loss: 0.1603 - val_accuracy: 0.9411\n",
      "Epoch 669/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1028 - accuracy: 0.9600 - val_loss: 0.1596 - val_accuracy: 0.9406\n",
      "Epoch 670/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1027 - accuracy: 0.9598 - val_loss: 0.1596 - val_accuracy: 0.9403\n",
      "Epoch 671/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1026 - accuracy: 0.9598 - val_loss: 0.1596 - val_accuracy: 0.9402\n",
      "Epoch 672/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1026 - accuracy: 0.9601 - val_loss: 0.1586 - val_accuracy: 0.9408\n",
      "Epoch 673/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1025 - accuracy: 0.9598 - val_loss: 0.1591 - val_accuracy: 0.9406\n",
      "Epoch 674/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1026 - accuracy: 0.9597 - val_loss: 0.1593 - val_accuracy: 0.9402\n",
      "Epoch 675/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1023 - accuracy: 0.9599 - val_loss: 0.1600 - val_accuracy: 0.9407\n",
      "Epoch 676/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1024 - accuracy: 0.9598 - val_loss: 0.1594 - val_accuracy: 0.9405\n",
      "Epoch 677/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1023 - accuracy: 0.9600 - val_loss: 0.1593 - val_accuracy: 0.9411\n",
      "Epoch 678/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1022 - accuracy: 0.9600 - val_loss: 0.1610 - val_accuracy: 0.9409\n",
      "Epoch 679/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1020 - accuracy: 0.9600 - val_loss: 0.1595 - val_accuracy: 0.9405\n",
      "Epoch 680/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1020 - accuracy: 0.9600 - val_loss: 0.1597 - val_accuracy: 0.9409\n",
      "Epoch 681/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1021 - accuracy: 0.9599 - val_loss: 0.1595 - val_accuracy: 0.9411\n",
      "Epoch 682/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1019 - accuracy: 0.9601 - val_loss: 0.1600 - val_accuracy: 0.9412\n",
      "Epoch 683/800\n",
      "6000/6000 [==============================] - 1s 95us/step - loss: 0.1018 - accuracy: 0.9599 - val_loss: 0.1601 - val_accuracy: 0.9394\n",
      "Epoch 684/800\n",
      "6000/6000 [==============================] - 1s 91us/step - loss: 0.1018 - accuracy: 0.9601 - val_loss: 0.1600 - val_accuracy: 0.9399\n",
      "Epoch 685/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1018 - accuracy: 0.9602 - val_loss: 0.1600 - val_accuracy: 0.9409\n",
      "Epoch 686/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1016 - accuracy: 0.9603 - val_loss: 0.1609 - val_accuracy: 0.9400\n",
      "Epoch 687/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1014 - accuracy: 0.9603 - val_loss: 0.1605 - val_accuracy: 0.9395\n",
      "Epoch 688/800\n",
      "6000/6000 [==============================] - 1s 87us/step - loss: 0.1015 - accuracy: 0.9603 - val_loss: 0.1603 - val_accuracy: 0.9416\n",
      "Epoch 689/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1015 - accuracy: 0.9604 - val_loss: 0.1611 - val_accuracy: 0.9405\n",
      "Epoch 690/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1014 - accuracy: 0.9601 - val_loss: 0.1617 - val_accuracy: 0.9400\n",
      "Epoch 691/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1012 - accuracy: 0.9603 - val_loss: 0.1618 - val_accuracy: 0.9410\n",
      "Epoch 692/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1012 - accuracy: 0.9605 - val_loss: 0.1602 - val_accuracy: 0.9406\n",
      "Epoch 693/800\n",
      "6000/6000 [==============================] - 1s 83us/step - loss: 0.1012 - accuracy: 0.9604 - val_loss: 0.1609 - val_accuracy: 0.9406\n",
      "Epoch 694/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1011 - accuracy: 0.9603 - val_loss: 0.1603 - val_accuracy: 0.9402\n",
      "Epoch 695/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1009 - accuracy: 0.9607 - val_loss: 0.1604 - val_accuracy: 0.9413\n",
      "Epoch 696/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1009 - accuracy: 0.9608 - val_loss: 0.1612 - val_accuracy: 0.9416\n",
      "Epoch 697/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1009 - accuracy: 0.9605 - val_loss: 0.1611 - val_accuracy: 0.9387\n",
      "Epoch 698/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1008 - accuracy: 0.9604 - val_loss: 0.1620 - val_accuracy: 0.9401\n",
      "Epoch 699/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1008 - accuracy: 0.9604 - val_loss: 0.1625 - val_accuracy: 0.9401\n",
      "Epoch 700/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1006 - accuracy: 0.9606 - val_loss: 0.1610 - val_accuracy: 0.9406\n",
      "Epoch 701/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1006 - accuracy: 0.9605 - val_loss: 0.1622 - val_accuracy: 0.9402\n",
      "Epoch 702/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1006 - accuracy: 0.9609 - val_loss: 0.1612 - val_accuracy: 0.9406\n",
      "Epoch 703/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1005 - accuracy: 0.9607 - val_loss: 0.1603 - val_accuracy: 0.9404\n",
      "Epoch 704/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1005 - accuracy: 0.9608 - val_loss: 0.1619 - val_accuracy: 0.9400\n",
      "Epoch 705/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1004 - accuracy: 0.9607 - val_loss: 0.1614 - val_accuracy: 0.9398\n",
      "Epoch 706/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1003 - accuracy: 0.9606 - val_loss: 0.1610 - val_accuracy: 0.9403\n",
      "Epoch 707/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1003 - accuracy: 0.9606 - val_loss: 0.1625 - val_accuracy: 0.9404\n",
      "Epoch 708/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1003 - accuracy: 0.9607 - val_loss: 0.1623 - val_accuracy: 0.9415\n",
      "Epoch 709/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1001 - accuracy: 0.9610 - val_loss: 0.1617 - val_accuracy: 0.9404\n",
      "Epoch 710/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1001 - accuracy: 0.9608 - val_loss: 0.1618 - val_accuracy: 0.9402\n",
      "Epoch 711/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0999 - accuracy: 0.9609 - val_loss: 0.1629 - val_accuracy: 0.9402\n",
      "Epoch 712/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0999 - accuracy: 0.9610 - val_loss: 0.1616 - val_accuracy: 0.9407\n",
      "Epoch 713/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0998 - accuracy: 0.9609 - val_loss: 0.1625 - val_accuracy: 0.9403\n",
      "Epoch 714/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0998 - accuracy: 0.9609 - val_loss: 0.1625 - val_accuracy: 0.9404\n",
      "Epoch 715/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0997 - accuracy: 0.9609 - val_loss: 0.1622 - val_accuracy: 0.9402\n",
      "Epoch 716/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0997 - accuracy: 0.9610 - val_loss: 0.1619 - val_accuracy: 0.9410\n",
      "Epoch 717/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0995 - accuracy: 0.9611 - val_loss: 0.1619 - val_accuracy: 0.9395\n",
      "Epoch 718/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0996 - accuracy: 0.9609 - val_loss: 0.1628 - val_accuracy: 0.9406\n",
      "Epoch 719/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0995 - accuracy: 0.9614 - val_loss: 0.1626 - val_accuracy: 0.9410\n",
      "Epoch 720/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0994 - accuracy: 0.9612 - val_loss: 0.1621 - val_accuracy: 0.9396\n",
      "Epoch 721/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0992 - accuracy: 0.9613 - val_loss: 0.1633 - val_accuracy: 0.9408\n",
      "Epoch 722/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0994 - accuracy: 0.9610 - val_loss: 0.1622 - val_accuracy: 0.9404\n",
      "Epoch 723/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0993 - accuracy: 0.9614 - val_loss: 0.1628 - val_accuracy: 0.9400\n",
      "Epoch 724/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0990 - accuracy: 0.9612 - val_loss: 0.1626 - val_accuracy: 0.9410\n",
      "Epoch 725/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0990 - accuracy: 0.9611 - val_loss: 0.1640 - val_accuracy: 0.9406\n",
      "Epoch 726/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0990 - accuracy: 0.9613 - val_loss: 0.1640 - val_accuracy: 0.9400\n",
      "Epoch 727/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0988 - accuracy: 0.9612 - val_loss: 0.1638 - val_accuracy: 0.9400\n",
      "Epoch 728/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0989 - accuracy: 0.9611 - val_loss: 0.1642 - val_accuracy: 0.9403\n",
      "Epoch 729/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0989 - accuracy: 0.9614 - val_loss: 0.1637 - val_accuracy: 0.9405\n",
      "Epoch 730/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0989 - accuracy: 0.9611 - val_loss: 0.1641 - val_accuracy: 0.9401\n",
      "Epoch 731/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0986 - accuracy: 0.9614 - val_loss: 0.1636 - val_accuracy: 0.9394\n",
      "Epoch 732/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0985 - accuracy: 0.9615 - val_loss: 0.1641 - val_accuracy: 0.9396\n",
      "Epoch 733/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0983 - accuracy: 0.9617 - val_loss: 0.1642 - val_accuracy: 0.9401\n",
      "Epoch 734/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0985 - accuracy: 0.9613 - val_loss: 0.1632 - val_accuracy: 0.9401\n",
      "Epoch 735/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0984 - accuracy: 0.9616 - val_loss: 0.1646 - val_accuracy: 0.9405\n",
      "Epoch 736/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0983 - accuracy: 0.9616 - val_loss: 0.1632 - val_accuracy: 0.9405\n",
      "Epoch 737/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0981 - accuracy: 0.9615 - val_loss: 0.1650 - val_accuracy: 0.9401\n",
      "Epoch 738/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0981 - accuracy: 0.9617 - val_loss: 0.1631 - val_accuracy: 0.9407\n",
      "Epoch 739/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0982 - accuracy: 0.9618 - val_loss: 0.1646 - val_accuracy: 0.9388\n",
      "Epoch 740/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0981 - accuracy: 0.9618 - val_loss: 0.1641 - val_accuracy: 0.9406\n",
      "Epoch 741/800\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.96 - 0s 74us/step - loss: 0.0981 - accuracy: 0.9615 - val_loss: 0.1638 - val_accuracy: 0.9402\n",
      "Epoch 742/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0978 - accuracy: 0.9620 - val_loss: 0.1645 - val_accuracy: 0.9385\n",
      "Epoch 743/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0979 - accuracy: 0.9617 - val_loss: 0.1656 - val_accuracy: 0.9387\n",
      "Epoch 744/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0976 - accuracy: 0.9619 - val_loss: 0.1659 - val_accuracy: 0.9389\n",
      "Epoch 745/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0977 - accuracy: 0.9618 - val_loss: 0.1638 - val_accuracy: 0.9395\n",
      "Epoch 746/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0976 - accuracy: 0.9621 - val_loss: 0.1648 - val_accuracy: 0.9400\n",
      "Epoch 747/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0975 - accuracy: 0.9618 - val_loss: 0.1649 - val_accuracy: 0.9406\n",
      "Epoch 748/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0974 - accuracy: 0.9618 - val_loss: 0.1646 - val_accuracy: 0.9397\n",
      "Epoch 749/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0974 - accuracy: 0.9620 - val_loss: 0.1641 - val_accuracy: 0.9407\n",
      "Epoch 750/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0972 - accuracy: 0.9620 - val_loss: 0.1652 - val_accuracy: 0.9395\n",
      "Epoch 751/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0973 - accuracy: 0.9619 - val_loss: 0.1641 - val_accuracy: 0.9405\n",
      "Epoch 752/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0972 - accuracy: 0.9618 - val_loss: 0.1649 - val_accuracy: 0.9398\n",
      "Epoch 753/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0972 - accuracy: 0.9623 - val_loss: 0.1641 - val_accuracy: 0.9397\n",
      "Epoch 754/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0971 - accuracy: 0.9618 - val_loss: 0.1648 - val_accuracy: 0.9399\n",
      "Epoch 755/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0969 - accuracy: 0.9621 - val_loss: 0.1645 - val_accuracy: 0.9401\n",
      "Epoch 756/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0970 - accuracy: 0.9622 - val_loss: 0.1645 - val_accuracy: 0.9405\n",
      "Epoch 757/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0969 - accuracy: 0.9623 - val_loss: 0.1645 - val_accuracy: 0.9402\n",
      "Epoch 758/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0968 - accuracy: 0.9620 - val_loss: 0.1654 - val_accuracy: 0.9394\n",
      "Epoch 759/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0968 - accuracy: 0.9623 - val_loss: 0.1669 - val_accuracy: 0.9386\n",
      "Epoch 760/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0966 - accuracy: 0.9621 - val_loss: 0.1655 - val_accuracy: 0.9395\n",
      "Epoch 761/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0966 - accuracy: 0.9623 - val_loss: 0.1652 - val_accuracy: 0.9399\n",
      "Epoch 762/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0965 - accuracy: 0.9621 - val_loss: 0.1653 - val_accuracy: 0.9398\n",
      "Epoch 763/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0964 - accuracy: 0.9623 - val_loss: 0.1653 - val_accuracy: 0.9399\n",
      "Epoch 764/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0965 - accuracy: 0.9625 - val_loss: 0.1652 - val_accuracy: 0.9396\n",
      "Epoch 765/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.0964 - accuracy: 0.9624 - val_loss: 0.1658 - val_accuracy: 0.9390\n",
      "Epoch 766/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.0963 - accuracy: 0.9625 - val_loss: 0.1675 - val_accuracy: 0.9395\n",
      "Epoch 767/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0961 - accuracy: 0.9626 - val_loss: 0.1671 - val_accuracy: 0.9386\n",
      "Epoch 768/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0961 - accuracy: 0.9624 - val_loss: 0.1655 - val_accuracy: 0.9392\n",
      "Epoch 769/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0960 - accuracy: 0.9625 - val_loss: 0.1658 - val_accuracy: 0.9394\n",
      "Epoch 770/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0961 - accuracy: 0.9625 - val_loss: 0.1660 - val_accuracy: 0.9396\n",
      "Epoch 771/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0958 - accuracy: 0.9625 - val_loss: 0.1659 - val_accuracy: 0.9403\n",
      "Epoch 772/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0957 - accuracy: 0.9629 - val_loss: 0.1669 - val_accuracy: 0.9391\n",
      "Epoch 773/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0959 - accuracy: 0.9625 - val_loss: 0.1666 - val_accuracy: 0.9392\n",
      "Epoch 774/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0955 - accuracy: 0.9630 - val_loss: 0.1660 - val_accuracy: 0.9399\n",
      "Epoch 775/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0956 - accuracy: 0.9626 - val_loss: 0.1669 - val_accuracy: 0.9398\n",
      "Epoch 776/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0956 - accuracy: 0.9628 - val_loss: 0.1668 - val_accuracy: 0.9397\n",
      "Epoch 777/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.0954 - accuracy: 0.9627 - val_loss: 0.1665 - val_accuracy: 0.9403\n",
      "Epoch 778/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0953 - accuracy: 0.9629 - val_loss: 0.1668 - val_accuracy: 0.9407\n",
      "Epoch 779/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0952 - accuracy: 0.9628 - val_loss: 0.1670 - val_accuracy: 0.9399\n",
      "Epoch 780/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0953 - accuracy: 0.9628 - val_loss: 0.1656 - val_accuracy: 0.9399\n",
      "Epoch 781/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0951 - accuracy: 0.9629 - val_loss: 0.1670 - val_accuracy: 0.9387\n",
      "Epoch 782/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0951 - accuracy: 0.9628 - val_loss: 0.1685 - val_accuracy: 0.9390\n",
      "Epoch 783/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0950 - accuracy: 0.9632 - val_loss: 0.1661 - val_accuracy: 0.9402\n",
      "Epoch 784/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0950 - accuracy: 0.9630 - val_loss: 0.1664 - val_accuracy: 0.9397\n",
      "Epoch 785/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0950 - accuracy: 0.9628 - val_loss: 0.1674 - val_accuracy: 0.9389\n",
      "Epoch 786/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0947 - accuracy: 0.9629 - val_loss: 0.1667 - val_accuracy: 0.9392\n",
      "Epoch 787/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0946 - accuracy: 0.9632 - val_loss: 0.1680 - val_accuracy: 0.9403\n",
      "Epoch 788/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0948 - accuracy: 0.9631 - val_loss: 0.1679 - val_accuracy: 0.9389\n",
      "Epoch 789/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0946 - accuracy: 0.9631 - val_loss: 0.1677 - val_accuracy: 0.9400\n",
      "Epoch 790/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0945 - accuracy: 0.9633 - val_loss: 0.1691 - val_accuracy: 0.9394\n",
      "Epoch 791/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0946 - accuracy: 0.9632 - val_loss: 0.1676 - val_accuracy: 0.9397\n",
      "Epoch 792/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0943 - accuracy: 0.9633 - val_loss: 0.1691 - val_accuracy: 0.9402\n",
      "Epoch 793/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0944 - accuracy: 0.9632 - val_loss: 0.1690 - val_accuracy: 0.9382\n",
      "Epoch 794/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0941 - accuracy: 0.9633 - val_loss: 0.1701 - val_accuracy: 0.9389\n",
      "Epoch 795/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0940 - accuracy: 0.9633 - val_loss: 0.1680 - val_accuracy: 0.9391\n",
      "Epoch 796/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0940 - accuracy: 0.9633 - val_loss: 0.1681 - val_accuracy: 0.9391\n",
      "Epoch 797/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0939 - accuracy: 0.9636 - val_loss: 0.1709 - val_accuracy: 0.9391\n",
      "Epoch 798/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0940 - accuracy: 0.9632 - val_loss: 0.1676 - val_accuracy: 0.9391\n",
      "Epoch 799/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.0938 - accuracy: 0.9635 - val_loss: 0.1676 - val_accuracy: 0.9396\n",
      "Epoch 800/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0937 - accuracy: 0.9634 - val_loss: 0.1711 - val_accuracy: 0.9382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:122: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Train on 6000 samples, validate on 2001 samples\n",
      "Epoch 1/800\n",
      "6000/6000 [==============================] - 1s 92us/step - loss: 0.4272 - accuracy: 0.8553 - val_loss: 0.2680 - val_accuracy: 0.9248\n",
      "Epoch 2/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.2517 - accuracy: 0.9302 - val_loss: 0.2664 - val_accuracy: 0.9248\n",
      "Epoch 3/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2510 - accuracy: 0.9302 - val_loss: 0.2658 - val_accuracy: 0.9248\n",
      "Epoch 4/800\n",
      "6000/6000 [==============================] - 1s 94us/step - loss: 0.2505 - accuracy: 0.9302 - val_loss: 0.2655 - val_accuracy: 0.9248\n",
      "Epoch 5/800\n",
      "6000/6000 [==============================] - 1s 87us/step - loss: 0.2501 - accuracy: 0.9302 - val_loss: 0.2649 - val_accuracy: 0.9248\n",
      "Epoch 6/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.2497 - accuracy: 0.9302 - val_loss: 0.2644 - val_accuracy: 0.9248\n",
      "Epoch 7/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.2493 - accuracy: 0.9302 - val_loss: 0.2641 - val_accuracy: 0.9248\n",
      "Epoch 8/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.2489 - accuracy: 0.9302 - val_loss: 0.2638 - val_accuracy: 0.9248\n",
      "Epoch 9/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.2486 - accuracy: 0.9302 - val_loss: 0.2634 - val_accuracy: 0.9248\n",
      "Epoch 10/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.2482 - accuracy: 0.9302 - val_loss: 0.2630 - val_accuracy: 0.9248\n",
      "Epoch 11/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.2478 - accuracy: 0.9302 - val_loss: 0.2626 - val_accuracy: 0.9248\n",
      "Epoch 12/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.2474 - accuracy: 0.9302 - val_loss: 0.2623 - val_accuracy: 0.9248\n",
      "Epoch 13/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.2470 - accuracy: 0.9302 - val_loss: 0.2615 - val_accuracy: 0.9248\n",
      "Epoch 14/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.2465 - accuracy: 0.9302 - val_loss: 0.2612 - val_accuracy: 0.9248\n",
      "Epoch 15/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.2459 - accuracy: 0.9302 - val_loss: 0.2606 - val_accuracy: 0.9248\n",
      "Epoch 16/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.2454 - accuracy: 0.9302 - val_loss: 0.2600 - val_accuracy: 0.9248\n",
      "Epoch 17/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.2447 - accuracy: 0.9302 - val_loss: 0.2593 - val_accuracy: 0.9248\n",
      "Epoch 18/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.2441 - accuracy: 0.9302 - val_loss: 0.2585 - val_accuracy: 0.9248\n",
      "Epoch 19/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.2433 - accuracy: 0.9302 - val_loss: 0.2579 - val_accuracy: 0.9248\n",
      "Epoch 20/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.2425 - accuracy: 0.9302 - val_loss: 0.2570 - val_accuracy: 0.9248\n",
      "Epoch 21/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.2415 - accuracy: 0.9302 - val_loss: 0.2558 - val_accuracy: 0.9248\n",
      "Epoch 22/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.2405 - accuracy: 0.9302 - val_loss: 0.2548 - val_accuracy: 0.9248\n",
      "Epoch 23/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.2393 - accuracy: 0.9302 - val_loss: 0.2537 - val_accuracy: 0.9248\n",
      "Epoch 24/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2381 - accuracy: 0.9302 - val_loss: 0.2525 - val_accuracy: 0.9248\n",
      "Epoch 25/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2367 - accuracy: 0.9302 - val_loss: 0.2511 - val_accuracy: 0.9248\n",
      "Epoch 26/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2352 - accuracy: 0.9302 - val_loss: 0.2495 - val_accuracy: 0.9248\n",
      "Epoch 27/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2337 - accuracy: 0.9302 - val_loss: 0.2479 - val_accuracy: 0.9248\n",
      "Epoch 28/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.2322 - accuracy: 0.9302 - val_loss: 0.2466 - val_accuracy: 0.9248\n",
      "Epoch 29/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2306 - accuracy: 0.9303 - val_loss: 0.2450 - val_accuracy: 0.9248\n",
      "Epoch 30/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2290 - accuracy: 0.9303 - val_loss: 0.2434 - val_accuracy: 0.9249\n",
      "Epoch 31/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.2274 - accuracy: 0.9304 - val_loss: 0.2418 - val_accuracy: 0.9250\n",
      "Epoch 32/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2259 - accuracy: 0.9304 - val_loss: 0.2402 - val_accuracy: 0.9250\n",
      "Epoch 33/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2244 - accuracy: 0.9305 - val_loss: 0.2386 - val_accuracy: 0.9250\n",
      "Epoch 34/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2229 - accuracy: 0.9306 - val_loss: 0.2372 - val_accuracy: 0.9250\n",
      "Epoch 35/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2214 - accuracy: 0.9307 - val_loss: 0.2358 - val_accuracy: 0.9251\n",
      "Epoch 36/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2200 - accuracy: 0.9308 - val_loss: 0.2341 - val_accuracy: 0.9252\n",
      "Epoch 37/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2185 - accuracy: 0.9308 - val_loss: 0.2329 - val_accuracy: 0.9252\n",
      "Epoch 38/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2170 - accuracy: 0.9309 - val_loss: 0.2314 - val_accuracy: 0.9254\n",
      "Epoch 39/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2156 - accuracy: 0.9309 - val_loss: 0.2300 - val_accuracy: 0.9254\n",
      "Epoch 40/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.2141 - accuracy: 0.9310 - val_loss: 0.2284 - val_accuracy: 0.9254\n",
      "Epoch 41/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2126 - accuracy: 0.9311 - val_loss: 0.2270 - val_accuracy: 0.9254\n",
      "Epoch 42/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.2111 - accuracy: 0.9311 - val_loss: 0.2252 - val_accuracy: 0.9254\n",
      "Epoch 43/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2096 - accuracy: 0.9313 - val_loss: 0.2239 - val_accuracy: 0.9256\n",
      "Epoch 44/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.2081 - accuracy: 0.9313 - val_loss: 0.2224 - val_accuracy: 0.9257\n",
      "Epoch 45/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2066 - accuracy: 0.9314 - val_loss: 0.2209 - val_accuracy: 0.9256\n",
      "Epoch 46/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2052 - accuracy: 0.9316 - val_loss: 0.2193 - val_accuracy: 0.9259\n",
      "Epoch 47/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2037 - accuracy: 0.9318 - val_loss: 0.2179 - val_accuracy: 0.9260\n",
      "Epoch 48/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2023 - accuracy: 0.9318 - val_loss: 0.2167 - val_accuracy: 0.9263\n",
      "Epoch 49/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2008 - accuracy: 0.9319 - val_loss: 0.2149 - val_accuracy: 0.9264\n",
      "Epoch 50/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1993 - accuracy: 0.9320 - val_loss: 0.2135 - val_accuracy: 0.9266\n",
      "Epoch 51/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1979 - accuracy: 0.9322 - val_loss: 0.2123 - val_accuracy: 0.9265\n",
      "Epoch 52/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1965 - accuracy: 0.9323 - val_loss: 0.2105 - val_accuracy: 0.9268\n",
      "Epoch 53/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1951 - accuracy: 0.9324 - val_loss: 0.2096 - val_accuracy: 0.9266\n",
      "Epoch 54/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1938 - accuracy: 0.9325 - val_loss: 0.2083 - val_accuracy: 0.9269\n",
      "Epoch 55/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1926 - accuracy: 0.9326 - val_loss: 0.2068 - val_accuracy: 0.9269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1913 - accuracy: 0.9328 - val_loss: 0.2061 - val_accuracy: 0.9272\n",
      "Epoch 57/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1902 - accuracy: 0.9331 - val_loss: 0.2048 - val_accuracy: 0.9269\n",
      "Epoch 58/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1891 - accuracy: 0.9332 - val_loss: 0.2037 - val_accuracy: 0.9271\n",
      "Epoch 59/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1880 - accuracy: 0.9333 - val_loss: 0.2026 - val_accuracy: 0.9274\n",
      "Epoch 60/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1870 - accuracy: 0.9335 - val_loss: 0.2016 - val_accuracy: 0.9276\n",
      "Epoch 61/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1860 - accuracy: 0.9337 - val_loss: 0.2010 - val_accuracy: 0.9274\n",
      "Epoch 62/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1851 - accuracy: 0.9338 - val_loss: 0.2000 - val_accuracy: 0.9276\n",
      "Epoch 63/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1841 - accuracy: 0.9341 - val_loss: 0.1993 - val_accuracy: 0.9280\n",
      "Epoch 64/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1833 - accuracy: 0.9342 - val_loss: 0.1984 - val_accuracy: 0.9283\n",
      "Epoch 65/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1824 - accuracy: 0.9345 - val_loss: 0.1979 - val_accuracy: 0.9283\n",
      "Epoch 66/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1816 - accuracy: 0.9347 - val_loss: 0.1966 - val_accuracy: 0.9288\n",
      "Epoch 67/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1808 - accuracy: 0.9350 - val_loss: 0.1962 - val_accuracy: 0.9289\n",
      "Epoch 68/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1801 - accuracy: 0.9351 - val_loss: 0.1956 - val_accuracy: 0.9291\n",
      "Epoch 69/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1794 - accuracy: 0.9353 - val_loss: 0.1952 - val_accuracy: 0.9293\n",
      "Epoch 70/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1787 - accuracy: 0.9355 - val_loss: 0.1945 - val_accuracy: 0.9296\n",
      "Epoch 71/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1782 - accuracy: 0.9357 - val_loss: 0.1936 - val_accuracy: 0.9298\n",
      "Epoch 72/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1774 - accuracy: 0.9360 - val_loss: 0.1934 - val_accuracy: 0.9301\n",
      "Epoch 73/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1768 - accuracy: 0.9362 - val_loss: 0.1932 - val_accuracy: 0.9300\n",
      "Epoch 74/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1763 - accuracy: 0.9364 - val_loss: 0.1923 - val_accuracy: 0.9304\n",
      "Epoch 75/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1757 - accuracy: 0.9366 - val_loss: 0.1920 - val_accuracy: 0.9311\n",
      "Epoch 76/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1752 - accuracy: 0.9369 - val_loss: 0.1912 - val_accuracy: 0.9308\n",
      "Epoch 77/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1746 - accuracy: 0.9369 - val_loss: 0.1912 - val_accuracy: 0.9308\n",
      "Epoch 78/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1741 - accuracy: 0.9371 - val_loss: 0.1902 - val_accuracy: 0.9311\n",
      "Epoch 79/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1736 - accuracy: 0.9372 - val_loss: 0.1900 - val_accuracy: 0.9310\n",
      "Epoch 80/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1731 - accuracy: 0.9374 - val_loss: 0.1894 - val_accuracy: 0.9313\n",
      "Epoch 81/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1726 - accuracy: 0.9377 - val_loss: 0.1892 - val_accuracy: 0.9315\n",
      "Epoch 82/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1721 - accuracy: 0.9378 - val_loss: 0.1885 - val_accuracy: 0.9316\n",
      "Epoch 83/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1716 - accuracy: 0.9381 - val_loss: 0.1882 - val_accuracy: 0.9317\n",
      "Epoch 84/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1712 - accuracy: 0.9380 - val_loss: 0.1876 - val_accuracy: 0.9321\n",
      "Epoch 85/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1707 - accuracy: 0.9382 - val_loss: 0.1874 - val_accuracy: 0.9319\n",
      "Epoch 86/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1702 - accuracy: 0.9384 - val_loss: 0.1873 - val_accuracy: 0.9323\n",
      "Epoch 87/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1698 - accuracy: 0.9386 - val_loss: 0.1864 - val_accuracy: 0.9325\n",
      "Epoch 88/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1693 - accuracy: 0.9389 - val_loss: 0.1866 - val_accuracy: 0.9324\n",
      "Epoch 89/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1689 - accuracy: 0.9388 - val_loss: 0.1854 - val_accuracy: 0.9326\n",
      "Epoch 90/800\n",
      "6000/6000 [==============================] - 1s 92us/step - loss: 0.1684 - accuracy: 0.9391 - val_loss: 0.1854 - val_accuracy: 0.9328\n",
      "Epoch 91/800\n",
      "6000/6000 [==============================] - 1s 92us/step - loss: 0.1680 - accuracy: 0.9391 - val_loss: 0.1848 - val_accuracy: 0.9328\n",
      "Epoch 92/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1675 - accuracy: 0.9394 - val_loss: 0.1842 - val_accuracy: 0.9332\n",
      "Epoch 93/800\n",
      "6000/6000 [==============================] - 1s 92us/step - loss: 0.1670 - accuracy: 0.9394 - val_loss: 0.1838 - val_accuracy: 0.9334\n",
      "Epoch 94/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1666 - accuracy: 0.9399 - val_loss: 0.1834 - val_accuracy: 0.9334\n",
      "Epoch 95/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1662 - accuracy: 0.9398 - val_loss: 0.1829 - val_accuracy: 0.9334\n",
      "Epoch 96/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1657 - accuracy: 0.9399 - val_loss: 0.1828 - val_accuracy: 0.9336\n",
      "Epoch 97/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1652 - accuracy: 0.9402 - val_loss: 0.1824 - val_accuracy: 0.9336\n",
      "Epoch 98/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1647 - accuracy: 0.9404 - val_loss: 0.1819 - val_accuracy: 0.9340\n",
      "Epoch 99/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1644 - accuracy: 0.9403 - val_loss: 0.1816 - val_accuracy: 0.9338\n",
      "Epoch 100/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1639 - accuracy: 0.9405 - val_loss: 0.1811 - val_accuracy: 0.9343\n",
      "Epoch 101/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1635 - accuracy: 0.9406 - val_loss: 0.1811 - val_accuracy: 0.9345\n",
      "Epoch 102/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1631 - accuracy: 0.9407 - val_loss: 0.1805 - val_accuracy: 0.9345\n",
      "Epoch 103/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1626 - accuracy: 0.9409 - val_loss: 0.1799 - val_accuracy: 0.9347\n",
      "Epoch 104/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1623 - accuracy: 0.9410 - val_loss: 0.1798 - val_accuracy: 0.9342\n",
      "Epoch 105/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1618 - accuracy: 0.9409 - val_loss: 0.1792 - val_accuracy: 0.9347\n",
      "Epoch 106/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1615 - accuracy: 0.9413 - val_loss: 0.1788 - val_accuracy: 0.9348\n",
      "Epoch 107/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1611 - accuracy: 0.9413 - val_loss: 0.1786 - val_accuracy: 0.9350\n",
      "Epoch 108/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1607 - accuracy: 0.9416 - val_loss: 0.1786 - val_accuracy: 0.9351\n",
      "Epoch 109/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1604 - accuracy: 0.9417 - val_loss: 0.1777 - val_accuracy: 0.9351\n",
      "Epoch 110/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1600 - accuracy: 0.9417 - val_loss: 0.1776 - val_accuracy: 0.9354\n",
      "Epoch 111/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1596 - accuracy: 0.9418 - val_loss: 0.1777 - val_accuracy: 0.9352\n",
      "Epoch 112/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1593 - accuracy: 0.9419 - val_loss: 0.1772 - val_accuracy: 0.9352\n",
      "Epoch 113/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1589 - accuracy: 0.9422 - val_loss: 0.1769 - val_accuracy: 0.9353\n",
      "Epoch 114/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1586 - accuracy: 0.9422 - val_loss: 0.1764 - val_accuracy: 0.9356\n",
      "Epoch 115/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1584 - accuracy: 0.9425 - val_loss: 0.1762 - val_accuracy: 0.9355\n",
      "Epoch 116/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1580 - accuracy: 0.9425 - val_loss: 0.1758 - val_accuracy: 0.9357\n",
      "Epoch 117/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1576 - accuracy: 0.9425 - val_loss: 0.1759 - val_accuracy: 0.9358\n",
      "Epoch 118/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1573 - accuracy: 0.9426 - val_loss: 0.1755 - val_accuracy: 0.9358\n",
      "Epoch 119/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1570 - accuracy: 0.9427 - val_loss: 0.1749 - val_accuracy: 0.9362\n",
      "Epoch 120/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1567 - accuracy: 0.9429 - val_loss: 0.1746 - val_accuracy: 0.9362\n",
      "Epoch 121/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1564 - accuracy: 0.9430 - val_loss: 0.1746 - val_accuracy: 0.9365\n",
      "Epoch 122/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1561 - accuracy: 0.9431 - val_loss: 0.1743 - val_accuracy: 0.9367\n",
      "Epoch 123/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1558 - accuracy: 0.9433 - val_loss: 0.1740 - val_accuracy: 0.9364\n",
      "Epoch 124/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1555 - accuracy: 0.9434 - val_loss: 0.1736 - val_accuracy: 0.9366\n",
      "Epoch 125/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1553 - accuracy: 0.9435 - val_loss: 0.1739 - val_accuracy: 0.9362\n",
      "Epoch 126/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1550 - accuracy: 0.9434 - val_loss: 0.1732 - val_accuracy: 0.9366\n",
      "Epoch 127/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1547 - accuracy: 0.9435 - val_loss: 0.1729 - val_accuracy: 0.9368\n",
      "Epoch 128/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1545 - accuracy: 0.9437 - val_loss: 0.1724 - val_accuracy: 0.9371\n",
      "Epoch 129/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1542 - accuracy: 0.9438 - val_loss: 0.1722 - val_accuracy: 0.9369\n",
      "Epoch 130/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1539 - accuracy: 0.9438 - val_loss: 0.1728 - val_accuracy: 0.9367\n",
      "Epoch 131/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1537 - accuracy: 0.9438 - val_loss: 0.1723 - val_accuracy: 0.9371\n",
      "Epoch 132/800\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.1536 - accuracy: 0.94 - 0s 74us/step - loss: 0.1534 - accuracy: 0.9440 - val_loss: 0.1717 - val_accuracy: 0.9368\n",
      "Epoch 133/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1532 - accuracy: 0.9441 - val_loss: 0.1714 - val_accuracy: 0.9371\n",
      "Epoch 134/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1529 - accuracy: 0.9443 - val_loss: 0.1714 - val_accuracy: 0.9371\n",
      "Epoch 135/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1526 - accuracy: 0.9442 - val_loss: 0.1714 - val_accuracy: 0.9374\n",
      "Epoch 136/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1525 - accuracy: 0.9443 - val_loss: 0.1715 - val_accuracy: 0.9378\n",
      "Epoch 137/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1522 - accuracy: 0.9445 - val_loss: 0.1711 - val_accuracy: 0.9374\n",
      "Epoch 138/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1520 - accuracy: 0.9444 - val_loss: 0.1707 - val_accuracy: 0.9378\n",
      "Epoch 139/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1518 - accuracy: 0.9444 - val_loss: 0.1701 - val_accuracy: 0.9380\n",
      "Epoch 140/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1516 - accuracy: 0.9446 - val_loss: 0.1703 - val_accuracy: 0.9379\n",
      "Epoch 141/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1513 - accuracy: 0.9448 - val_loss: 0.1701 - val_accuracy: 0.9375\n",
      "Epoch 142/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1511 - accuracy: 0.9446 - val_loss: 0.1697 - val_accuracy: 0.9381\n",
      "Epoch 143/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1508 - accuracy: 0.9447 - val_loss: 0.1704 - val_accuracy: 0.9378\n",
      "Epoch 144/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1507 - accuracy: 0.9449 - val_loss: 0.1696 - val_accuracy: 0.9381\n",
      "Epoch 145/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1504 - accuracy: 0.9449 - val_loss: 0.1697 - val_accuracy: 0.9381\n",
      "Epoch 146/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1502 - accuracy: 0.9451 - val_loss: 0.1692 - val_accuracy: 0.9381\n",
      "Epoch 147/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1500 - accuracy: 0.9452 - val_loss: 0.1692 - val_accuracy: 0.9381\n",
      "Epoch 148/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1498 - accuracy: 0.9450 - val_loss: 0.1686 - val_accuracy: 0.9383\n",
      "Epoch 149/800\n",
      "6000/6000 [==============================] - 0s 70us/step - loss: 0.1496 - accuracy: 0.9452 - val_loss: 0.1694 - val_accuracy: 0.9379\n",
      "Epoch 150/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1494 - accuracy: 0.9453 - val_loss: 0.1689 - val_accuracy: 0.9385\n",
      "Epoch 151/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1492 - accuracy: 0.9453 - val_loss: 0.1683 - val_accuracy: 0.9383\n",
      "Epoch 152/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1490 - accuracy: 0.9454 - val_loss: 0.1684 - val_accuracy: 0.9382\n",
      "Epoch 153/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1488 - accuracy: 0.9454 - val_loss: 0.1683 - val_accuracy: 0.9389\n",
      "Epoch 154/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1486 - accuracy: 0.9454 - val_loss: 0.1680 - val_accuracy: 0.9381\n",
      "Epoch 155/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1483 - accuracy: 0.9456 - val_loss: 0.1678 - val_accuracy: 0.9387\n",
      "Epoch 156/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1483 - accuracy: 0.9455 - val_loss: 0.1678 - val_accuracy: 0.9388\n",
      "Epoch 157/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1480 - accuracy: 0.9457 - val_loss: 0.1680 - val_accuracy: 0.9382\n",
      "Epoch 158/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1478 - accuracy: 0.9458 - val_loss: 0.1674 - val_accuracy: 0.9391\n",
      "Epoch 159/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1477 - accuracy: 0.9459 - val_loss: 0.1672 - val_accuracy: 0.9384\n",
      "Epoch 160/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1475 - accuracy: 0.9459 - val_loss: 0.1671 - val_accuracy: 0.9389\n",
      "Epoch 161/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1473 - accuracy: 0.9459 - val_loss: 0.1668 - val_accuracy: 0.9393\n",
      "Epoch 162/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1471 - accuracy: 0.9460 - val_loss: 0.1668 - val_accuracy: 0.9389\n",
      "Epoch 163/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1469 - accuracy: 0.9460 - val_loss: 0.1664 - val_accuracy: 0.9391\n",
      "Epoch 164/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1466 - accuracy: 0.9461 - val_loss: 0.1666 - val_accuracy: 0.9391\n",
      "Epoch 165/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1465 - accuracy: 0.9461 - val_loss: 0.1666 - val_accuracy: 0.9391\n",
      "Epoch 166/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1463 - accuracy: 0.9462 - val_loss: 0.1672 - val_accuracy: 0.9387\n",
      "Epoch 167/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1461 - accuracy: 0.9463 - val_loss: 0.1661 - val_accuracy: 0.9395\n",
      "Epoch 168/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1459 - accuracy: 0.9463 - val_loss: 0.1661 - val_accuracy: 0.9392\n",
      "Epoch 169/800\n",
      "6000/6000 [==============================] - 1s 101us/step - loss: 0.1458 - accuracy: 0.9463 - val_loss: 0.1661 - val_accuracy: 0.9392\n",
      "Epoch 170/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1456 - accuracy: 0.9464 - val_loss: 0.1659 - val_accuracy: 0.9393\n",
      "Epoch 171/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1454 - accuracy: 0.9465 - val_loss: 0.1654 - val_accuracy: 0.9394\n",
      "Epoch 172/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1452 - accuracy: 0.9465 - val_loss: 0.1653 - val_accuracy: 0.9396\n",
      "Epoch 173/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1450 - accuracy: 0.9468 - val_loss: 0.1655 - val_accuracy: 0.9395\n",
      "Epoch 174/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1448 - accuracy: 0.9467 - val_loss: 0.1649 - val_accuracy: 0.9394\n",
      "Epoch 175/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1446 - accuracy: 0.9468 - val_loss: 0.1650 - val_accuracy: 0.9395\n",
      "Epoch 176/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1445 - accuracy: 0.9469 - val_loss: 0.1648 - val_accuracy: 0.9397\n",
      "Epoch 177/800\n",
      "6000/6000 [==============================] - 1s 87us/step - loss: 0.1443 - accuracy: 0.9468 - val_loss: 0.1646 - val_accuracy: 0.9397\n",
      "Epoch 178/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1441 - accuracy: 0.9471 - val_loss: 0.1645 - val_accuracy: 0.9398\n",
      "Epoch 179/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1440 - accuracy: 0.9469 - val_loss: 0.1648 - val_accuracy: 0.9396\n",
      "Epoch 180/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1438 - accuracy: 0.9469 - val_loss: 0.1643 - val_accuracy: 0.9401\n",
      "Epoch 181/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1436 - accuracy: 0.9470 - val_loss: 0.1654 - val_accuracy: 0.9394\n",
      "Epoch 182/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1435 - accuracy: 0.9470 - val_loss: 0.1642 - val_accuracy: 0.9394\n",
      "Epoch 183/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1434 - accuracy: 0.9470 - val_loss: 0.1644 - val_accuracy: 0.9400\n",
      "Epoch 184/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1432 - accuracy: 0.9473 - val_loss: 0.1639 - val_accuracy: 0.9398\n",
      "Epoch 185/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1430 - accuracy: 0.9472 - val_loss: 0.1639 - val_accuracy: 0.9395\n",
      "Epoch 186/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1429 - accuracy: 0.9474 - val_loss: 0.1637 - val_accuracy: 0.9400\n",
      "Epoch 187/800\n",
      "6000/6000 [==============================] - 1s 87us/step - loss: 0.1426 - accuracy: 0.9473 - val_loss: 0.1635 - val_accuracy: 0.9401\n",
      "Epoch 188/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1425 - accuracy: 0.9474 - val_loss: 0.1631 - val_accuracy: 0.9404\n",
      "Epoch 189/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1423 - accuracy: 0.9475 - val_loss: 0.1638 - val_accuracy: 0.9401\n",
      "Epoch 190/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1422 - accuracy: 0.9475 - val_loss: 0.1632 - val_accuracy: 0.9401\n",
      "Epoch 191/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1420 - accuracy: 0.9474 - val_loss: 0.1633 - val_accuracy: 0.9398\n",
      "Epoch 192/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1419 - accuracy: 0.9477 - val_loss: 0.1632 - val_accuracy: 0.9403\n",
      "Epoch 193/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1418 - accuracy: 0.9476 - val_loss: 0.1629 - val_accuracy: 0.9403\n",
      "Epoch 194/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1415 - accuracy: 0.9477 - val_loss: 0.1627 - val_accuracy: 0.9405\n",
      "Epoch 195/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1415 - accuracy: 0.9476 - val_loss: 0.1626 - val_accuracy: 0.9403\n",
      "Epoch 196/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1413 - accuracy: 0.9478 - val_loss: 0.1627 - val_accuracy: 0.9405\n",
      "Epoch 197/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1411 - accuracy: 0.9479 - val_loss: 0.1623 - val_accuracy: 0.9404\n",
      "Epoch 198/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1409 - accuracy: 0.9478 - val_loss: 0.1623 - val_accuracy: 0.9406\n",
      "Epoch 199/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1408 - accuracy: 0.9477 - val_loss: 0.1623 - val_accuracy: 0.9405\n",
      "Epoch 200/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1406 - accuracy: 0.9479 - val_loss: 0.1620 - val_accuracy: 0.9404\n",
      "Epoch 201/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1405 - accuracy: 0.9479 - val_loss: 0.1619 - val_accuracy: 0.9407\n",
      "Epoch 202/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1404 - accuracy: 0.9481 - val_loss: 0.1620 - val_accuracy: 0.9406\n",
      "Epoch 203/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1402 - accuracy: 0.9480 - val_loss: 0.1618 - val_accuracy: 0.9410\n",
      "Epoch 204/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1401 - accuracy: 0.9481 - val_loss: 0.1619 - val_accuracy: 0.9405\n",
      "Epoch 205/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1399 - accuracy: 0.9480 - val_loss: 0.1618 - val_accuracy: 0.9410\n",
      "Epoch 206/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1398 - accuracy: 0.9482 - val_loss: 0.1611 - val_accuracy: 0.9407\n",
      "Epoch 207/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1395 - accuracy: 0.9481 - val_loss: 0.1617 - val_accuracy: 0.9406\n",
      "Epoch 208/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1395 - accuracy: 0.9483 - val_loss: 0.1609 - val_accuracy: 0.9408\n",
      "Epoch 209/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1393 - accuracy: 0.9484 - val_loss: 0.1618 - val_accuracy: 0.9403\n",
      "Epoch 210/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1391 - accuracy: 0.9483 - val_loss: 0.1615 - val_accuracy: 0.9407\n",
      "Epoch 211/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1390 - accuracy: 0.9484 - val_loss: 0.1610 - val_accuracy: 0.9408\n",
      "Epoch 212/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1390 - accuracy: 0.9485 - val_loss: 0.1609 - val_accuracy: 0.9410\n",
      "Epoch 213/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1388 - accuracy: 0.9484 - val_loss: 0.1609 - val_accuracy: 0.9408\n",
      "Epoch 214/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1386 - accuracy: 0.9485 - val_loss: 0.1610 - val_accuracy: 0.9407\n",
      "Epoch 215/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1386 - accuracy: 0.9485 - val_loss: 0.1603 - val_accuracy: 0.9410\n",
      "Epoch 216/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1384 - accuracy: 0.9485 - val_loss: 0.1604 - val_accuracy: 0.9403\n",
      "Epoch 217/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1382 - accuracy: 0.9486 - val_loss: 0.1607 - val_accuracy: 0.9411\n",
      "Epoch 218/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1380 - accuracy: 0.9487 - val_loss: 0.1607 - val_accuracy: 0.9410\n",
      "Epoch 219/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1379 - accuracy: 0.9488 - val_loss: 0.1605 - val_accuracy: 0.9412\n",
      "Epoch 220/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1379 - accuracy: 0.9488 - val_loss: 0.1599 - val_accuracy: 0.9412\n",
      "Epoch 221/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1377 - accuracy: 0.9488 - val_loss: 0.1607 - val_accuracy: 0.9409\n",
      "Epoch 222/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1377 - accuracy: 0.9488 - val_loss: 0.1601 - val_accuracy: 0.9414\n",
      "Epoch 223/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1374 - accuracy: 0.9489 - val_loss: 0.1598 - val_accuracy: 0.9414\n",
      "Epoch 224/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1372 - accuracy: 0.9489 - val_loss: 0.1595 - val_accuracy: 0.9413\n",
      "Epoch 225/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1371 - accuracy: 0.9489 - val_loss: 0.1604 - val_accuracy: 0.9414\n",
      "Epoch 226/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1370 - accuracy: 0.9490 - val_loss: 0.1596 - val_accuracy: 0.9413\n",
      "Epoch 227/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1369 - accuracy: 0.9490 - val_loss: 0.1596 - val_accuracy: 0.9414\n",
      "Epoch 228/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1368 - accuracy: 0.9490 - val_loss: 0.1596 - val_accuracy: 0.9412\n",
      "Epoch 229/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1366 - accuracy: 0.9491 - val_loss: 0.1594 - val_accuracy: 0.9415\n",
      "Epoch 230/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1365 - accuracy: 0.9489 - val_loss: 0.1594 - val_accuracy: 0.9414\n",
      "Epoch 231/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1364 - accuracy: 0.9493 - val_loss: 0.1593 - val_accuracy: 0.9416\n",
      "Epoch 232/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1362 - accuracy: 0.9492 - val_loss: 0.1588 - val_accuracy: 0.9416\n",
      "Epoch 233/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1361 - accuracy: 0.9492 - val_loss: 0.1588 - val_accuracy: 0.9415\n",
      "Epoch 234/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1360 - accuracy: 0.9491 - val_loss: 0.1588 - val_accuracy: 0.9414\n",
      "Epoch 235/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1358 - accuracy: 0.9492 - val_loss: 0.1586 - val_accuracy: 0.9419\n",
      "Epoch 236/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1357 - accuracy: 0.9492 - val_loss: 0.1584 - val_accuracy: 0.9416\n",
      "Epoch 237/800\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.1354 - accuracy: 0.94 - 0s 72us/step - loss: 0.1355 - accuracy: 0.9492 - val_loss: 0.1587 - val_accuracy: 0.9420\n",
      "Epoch 238/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1354 - accuracy: 0.9494 - val_loss: 0.1586 - val_accuracy: 0.9417\n",
      "Epoch 239/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1353 - accuracy: 0.9493 - val_loss: 0.1586 - val_accuracy: 0.9418\n",
      "Epoch 240/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1352 - accuracy: 0.9494 - val_loss: 0.1584 - val_accuracy: 0.9416\n",
      "Epoch 241/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1350 - accuracy: 0.9495 - val_loss: 0.1581 - val_accuracy: 0.9417\n",
      "Epoch 242/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1349 - accuracy: 0.9495 - val_loss: 0.1590 - val_accuracy: 0.9415\n",
      "Epoch 243/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1348 - accuracy: 0.9495 - val_loss: 0.1587 - val_accuracy: 0.9417\n",
      "Epoch 244/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1347 - accuracy: 0.9497 - val_loss: 0.1584 - val_accuracy: 0.9412\n",
      "Epoch 245/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1346 - accuracy: 0.9496 - val_loss: 0.1579 - val_accuracy: 0.9418\n",
      "Epoch 246/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1345 - accuracy: 0.9497 - val_loss: 0.1581 - val_accuracy: 0.9420\n",
      "Epoch 247/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1343 - accuracy: 0.9495 - val_loss: 0.1589 - val_accuracy: 0.9418\n",
      "Epoch 248/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1343 - accuracy: 0.9498 - val_loss: 0.1580 - val_accuracy: 0.9417\n",
      "Epoch 249/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1341 - accuracy: 0.9497 - val_loss: 0.1583 - val_accuracy: 0.9415\n",
      "Epoch 250/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1340 - accuracy: 0.9499 - val_loss: 0.1575 - val_accuracy: 0.9421\n",
      "Epoch 251/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1339 - accuracy: 0.9498 - val_loss: 0.1578 - val_accuracy: 0.9416\n",
      "Epoch 252/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1338 - accuracy: 0.9499 - val_loss: 0.1574 - val_accuracy: 0.9421\n",
      "Epoch 253/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1337 - accuracy: 0.9499 - val_loss: 0.1579 - val_accuracy: 0.9414\n",
      "Epoch 254/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1335 - accuracy: 0.9498 - val_loss: 0.1579 - val_accuracy: 0.9420\n",
      "Epoch 255/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1334 - accuracy: 0.9498 - val_loss: 0.1584 - val_accuracy: 0.9418\n",
      "Epoch 256/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1332 - accuracy: 0.9499 - val_loss: 0.1575 - val_accuracy: 0.9416\n",
      "Epoch 257/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1332 - accuracy: 0.9499 - val_loss: 0.1575 - val_accuracy: 0.9418\n",
      "Epoch 258/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1331 - accuracy: 0.9500 - val_loss: 0.1572 - val_accuracy: 0.9423\n",
      "Epoch 259/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1329 - accuracy: 0.9499 - val_loss: 0.1570 - val_accuracy: 0.9420\n",
      "Epoch 260/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1329 - accuracy: 0.9500 - val_loss: 0.1571 - val_accuracy: 0.9422\n",
      "Epoch 261/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1328 - accuracy: 0.9501 - val_loss: 0.1574 - val_accuracy: 0.9420\n",
      "Epoch 262/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1327 - accuracy: 0.9501 - val_loss: 0.1570 - val_accuracy: 0.9419\n",
      "Epoch 263/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1326 - accuracy: 0.9501 - val_loss: 0.1568 - val_accuracy: 0.9422\n",
      "Epoch 264/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1325 - accuracy: 0.9501 - val_loss: 0.1570 - val_accuracy: 0.9424\n",
      "Epoch 265/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1324 - accuracy: 0.9501 - val_loss: 0.1571 - val_accuracy: 0.9425\n",
      "Epoch 266/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1323 - accuracy: 0.9503 - val_loss: 0.1573 - val_accuracy: 0.9420\n",
      "Epoch 267/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1321 - accuracy: 0.9503 - val_loss: 0.1567 - val_accuracy: 0.9424\n",
      "Epoch 268/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1321 - accuracy: 0.9502 - val_loss: 0.1578 - val_accuracy: 0.9417\n",
      "Epoch 269/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1320 - accuracy: 0.9503 - val_loss: 0.1569 - val_accuracy: 0.9422\n",
      "Epoch 270/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1318 - accuracy: 0.9504 - val_loss: 0.1565 - val_accuracy: 0.9426\n",
      "Epoch 271/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1317 - accuracy: 0.9502 - val_loss: 0.1570 - val_accuracy: 0.9421\n",
      "Epoch 272/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1316 - accuracy: 0.9504 - val_loss: 0.1567 - val_accuracy: 0.9425\n",
      "Epoch 273/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1315 - accuracy: 0.9502 - val_loss: 0.1566 - val_accuracy: 0.9420\n",
      "Epoch 274/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1314 - accuracy: 0.9503 - val_loss: 0.1567 - val_accuracy: 0.9423\n",
      "Epoch 275/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1314 - accuracy: 0.9504 - val_loss: 0.1565 - val_accuracy: 0.9424\n",
      "Epoch 276/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1312 - accuracy: 0.9504 - val_loss: 0.1561 - val_accuracy: 0.9424\n",
      "Epoch 277/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1311 - accuracy: 0.9506 - val_loss: 0.1560 - val_accuracy: 0.9422\n",
      "Epoch 278/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1311 - accuracy: 0.9503 - val_loss: 0.1560 - val_accuracy: 0.9426\n",
      "Epoch 279/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1309 - accuracy: 0.9504 - val_loss: 0.1563 - val_accuracy: 0.9424\n",
      "Epoch 280/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1308 - accuracy: 0.9505 - val_loss: 0.1565 - val_accuracy: 0.9428\n",
      "Epoch 281/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1307 - accuracy: 0.9507 - val_loss: 0.1565 - val_accuracy: 0.9420\n",
      "Epoch 282/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1307 - accuracy: 0.9505 - val_loss: 0.1563 - val_accuracy: 0.9420\n",
      "Epoch 283/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1306 - accuracy: 0.9506 - val_loss: 0.1559 - val_accuracy: 0.9421\n",
      "Epoch 284/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1305 - accuracy: 0.9506 - val_loss: 0.1556 - val_accuracy: 0.9421\n",
      "Epoch 285/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1304 - accuracy: 0.9506 - val_loss: 0.1561 - val_accuracy: 0.9424\n",
      "Epoch 286/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1303 - accuracy: 0.9507 - val_loss: 0.1559 - val_accuracy: 0.9424\n",
      "Epoch 287/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1302 - accuracy: 0.9508 - val_loss: 0.1558 - val_accuracy: 0.9421\n",
      "Epoch 288/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1301 - accuracy: 0.9507 - val_loss: 0.1565 - val_accuracy: 0.9423\n",
      "Epoch 289/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1301 - accuracy: 0.9506 - val_loss: 0.1555 - val_accuracy: 0.9423\n",
      "Epoch 290/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1299 - accuracy: 0.9507 - val_loss: 0.1561 - val_accuracy: 0.9427\n",
      "Epoch 291/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1299 - accuracy: 0.9508 - val_loss: 0.1556 - val_accuracy: 0.9423\n",
      "Epoch 292/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1298 - accuracy: 0.9507 - val_loss: 0.1556 - val_accuracy: 0.9420\n",
      "Epoch 293/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1297 - accuracy: 0.9509 - val_loss: 0.1558 - val_accuracy: 0.9427\n",
      "Epoch 294/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1297 - accuracy: 0.9508 - val_loss: 0.1556 - val_accuracy: 0.9421\n",
      "Epoch 295/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1295 - accuracy: 0.9509 - val_loss: 0.1558 - val_accuracy: 0.9423\n",
      "Epoch 296/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1294 - accuracy: 0.9509 - val_loss: 0.1554 - val_accuracy: 0.9418\n",
      "Epoch 297/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1293 - accuracy: 0.9510 - val_loss: 0.1555 - val_accuracy: 0.9421\n",
      "Epoch 298/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1292 - accuracy: 0.9508 - val_loss: 0.1549 - val_accuracy: 0.9425\n",
      "Epoch 299/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1291 - accuracy: 0.9509 - val_loss: 0.1554 - val_accuracy: 0.9420\n",
      "Epoch 300/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1291 - accuracy: 0.9509 - val_loss: 0.1556 - val_accuracy: 0.9423\n",
      "Epoch 301/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1290 - accuracy: 0.9511 - val_loss: 0.1555 - val_accuracy: 0.9423\n",
      "Epoch 302/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1289 - accuracy: 0.9511 - val_loss: 0.1557 - val_accuracy: 0.9418\n",
      "Epoch 303/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1288 - accuracy: 0.9512 - val_loss: 0.1556 - val_accuracy: 0.9419\n",
      "Epoch 304/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1286 - accuracy: 0.9512 - val_loss: 0.1555 - val_accuracy: 0.9430\n",
      "Epoch 305/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1286 - accuracy: 0.9511 - val_loss: 0.1550 - val_accuracy: 0.9424\n",
      "Epoch 306/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1284 - accuracy: 0.9513 - val_loss: 0.1560 - val_accuracy: 0.9421\n",
      "Epoch 307/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1284 - accuracy: 0.9512 - val_loss: 0.1552 - val_accuracy: 0.9422\n",
      "Epoch 308/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1284 - accuracy: 0.9512 - val_loss: 0.1552 - val_accuracy: 0.9427\n",
      "Epoch 309/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1283 - accuracy: 0.9513 - val_loss: 0.1555 - val_accuracy: 0.9426\n",
      "Epoch 310/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1282 - accuracy: 0.9512 - val_loss: 0.1553 - val_accuracy: 0.9425\n",
      "Epoch 311/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1282 - accuracy: 0.9512 - val_loss: 0.1554 - val_accuracy: 0.9425\n",
      "Epoch 312/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1281 - accuracy: 0.9511 - val_loss: 0.1558 - val_accuracy: 0.9424\n",
      "Epoch 313/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1279 - accuracy: 0.9512 - val_loss: 0.1555 - val_accuracy: 0.9423\n",
      "Epoch 314/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1277 - accuracy: 0.9514 - val_loss: 0.1552 - val_accuracy: 0.9426\n",
      "Epoch 315/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1278 - accuracy: 0.9512 - val_loss: 0.1549 - val_accuracy: 0.9428\n",
      "Epoch 316/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1276 - accuracy: 0.9514 - val_loss: 0.1552 - val_accuracy: 0.9425\n",
      "Epoch 317/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1276 - accuracy: 0.9514 - val_loss: 0.1557 - val_accuracy: 0.9423\n",
      "Epoch 318/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1275 - accuracy: 0.9514 - val_loss: 0.1551 - val_accuracy: 0.9422\n",
      "Epoch 319/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1274 - accuracy: 0.9514 - val_loss: 0.1548 - val_accuracy: 0.9422\n",
      "Epoch 320/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1273 - accuracy: 0.9514 - val_loss: 0.1563 - val_accuracy: 0.9423\n",
      "Epoch 321/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1273 - accuracy: 0.9515 - val_loss: 0.1554 - val_accuracy: 0.9424\n",
      "Epoch 322/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1271 - accuracy: 0.9515 - val_loss: 0.1557 - val_accuracy: 0.9423\n",
      "Epoch 323/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1271 - accuracy: 0.9513 - val_loss: 0.1546 - val_accuracy: 0.9420\n",
      "Epoch 324/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1271 - accuracy: 0.9516 - val_loss: 0.1550 - val_accuracy: 0.9424\n",
      "Epoch 325/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1269 - accuracy: 0.9517 - val_loss: 0.1550 - val_accuracy: 0.9421\n",
      "Epoch 326/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1269 - accuracy: 0.9517 - val_loss: 0.1549 - val_accuracy: 0.9425\n",
      "Epoch 327/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1268 - accuracy: 0.9517 - val_loss: 0.1553 - val_accuracy: 0.9423\n",
      "Epoch 328/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1267 - accuracy: 0.9516 - val_loss: 0.1548 - val_accuracy: 0.9424\n",
      "Epoch 329/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1266 - accuracy: 0.9516 - val_loss: 0.1548 - val_accuracy: 0.9420\n",
      "Epoch 330/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1265 - accuracy: 0.9517 - val_loss: 0.1550 - val_accuracy: 0.9420\n",
      "Epoch 331/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1264 - accuracy: 0.9517 - val_loss: 0.1548 - val_accuracy: 0.9426\n",
      "Epoch 332/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1263 - accuracy: 0.9519 - val_loss: 0.1556 - val_accuracy: 0.9422\n",
      "Epoch 333/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1263 - accuracy: 0.9518 - val_loss: 0.1553 - val_accuracy: 0.9420\n",
      "Epoch 334/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1263 - accuracy: 0.9521 - val_loss: 0.1550 - val_accuracy: 0.9418\n",
      "Epoch 335/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1261 - accuracy: 0.9517 - val_loss: 0.1549 - val_accuracy: 0.9429\n",
      "Epoch 336/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1260 - accuracy: 0.9519 - val_loss: 0.1546 - val_accuracy: 0.9421\n",
      "Epoch 337/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1259 - accuracy: 0.9518 - val_loss: 0.1552 - val_accuracy: 0.9423\n",
      "Epoch 338/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1259 - accuracy: 0.9519 - val_loss: 0.1542 - val_accuracy: 0.9425\n",
      "Epoch 339/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1258 - accuracy: 0.9519 - val_loss: 0.1551 - val_accuracy: 0.9426\n",
      "Epoch 340/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1256 - accuracy: 0.9522 - val_loss: 0.1546 - val_accuracy: 0.9421\n",
      "Epoch 341/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1255 - accuracy: 0.9520 - val_loss: 0.1549 - val_accuracy: 0.9412\n",
      "Epoch 342/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1256 - accuracy: 0.9520 - val_loss: 0.1546 - val_accuracy: 0.9422\n",
      "Epoch 343/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1255 - accuracy: 0.9521 - val_loss: 0.1544 - val_accuracy: 0.9426\n",
      "Epoch 344/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1254 - accuracy: 0.9520 - val_loss: 0.1549 - val_accuracy: 0.9422\n",
      "Epoch 345/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1254 - accuracy: 0.9520 - val_loss: 0.1549 - val_accuracy: 0.9419\n",
      "Epoch 346/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1253 - accuracy: 0.9520 - val_loss: 0.1549 - val_accuracy: 0.9420\n",
      "Epoch 347/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1251 - accuracy: 0.9522 - val_loss: 0.1546 - val_accuracy: 0.9420\n",
      "Epoch 348/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1251 - accuracy: 0.9523 - val_loss: 0.1546 - val_accuracy: 0.9423\n",
      "Epoch 349/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1251 - accuracy: 0.9522 - val_loss: 0.1543 - val_accuracy: 0.9421\n",
      "Epoch 350/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1249 - accuracy: 0.9521 - val_loss: 0.1549 - val_accuracy: 0.9421\n",
      "Epoch 351/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1248 - accuracy: 0.9523 - val_loss: 0.1547 - val_accuracy: 0.9424\n",
      "Epoch 352/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1247 - accuracy: 0.9523 - val_loss: 0.1544 - val_accuracy: 0.9428\n",
      "Epoch 353/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1247 - accuracy: 0.9523 - val_loss: 0.1543 - val_accuracy: 0.9417\n",
      "Epoch 354/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1246 - accuracy: 0.9522 - val_loss: 0.1547 - val_accuracy: 0.9420\n",
      "Epoch 355/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1246 - accuracy: 0.9524 - val_loss: 0.1542 - val_accuracy: 0.9425\n",
      "Epoch 356/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1244 - accuracy: 0.9523 - val_loss: 0.1539 - val_accuracy: 0.9420\n",
      "Epoch 357/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1244 - accuracy: 0.9527 - val_loss: 0.1546 - val_accuracy: 0.9424\n",
      "Epoch 358/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1243 - accuracy: 0.9522 - val_loss: 0.1541 - val_accuracy: 0.9423\n",
      "Epoch 359/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1242 - accuracy: 0.9525 - val_loss: 0.1540 - val_accuracy: 0.9423\n",
      "Epoch 360/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1241 - accuracy: 0.9526 - val_loss: 0.1541 - val_accuracy: 0.9425\n",
      "Epoch 361/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1241 - accuracy: 0.9524 - val_loss: 0.1547 - val_accuracy: 0.9422\n",
      "Epoch 362/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1241 - accuracy: 0.9526 - val_loss: 0.1539 - val_accuracy: 0.9426\n",
      "Epoch 363/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1240 - accuracy: 0.9524 - val_loss: 0.1539 - val_accuracy: 0.9420\n",
      "Epoch 364/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1239 - accuracy: 0.9525 - val_loss: 0.1542 - val_accuracy: 0.9425\n",
      "Epoch 365/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1239 - accuracy: 0.9526 - val_loss: 0.1547 - val_accuracy: 0.9422\n",
      "Epoch 366/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1238 - accuracy: 0.9525 - val_loss: 0.1544 - val_accuracy: 0.9424\n",
      "Epoch 367/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1236 - accuracy: 0.9525 - val_loss: 0.1541 - val_accuracy: 0.9426\n",
      "Epoch 368/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1235 - accuracy: 0.9526 - val_loss: 0.1535 - val_accuracy: 0.9419\n",
      "Epoch 369/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1235 - accuracy: 0.9528 - val_loss: 0.1539 - val_accuracy: 0.9424\n",
      "Epoch 370/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1234 - accuracy: 0.9528 - val_loss: 0.1544 - val_accuracy: 0.9429\n",
      "Epoch 371/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1234 - accuracy: 0.9527 - val_loss: 0.1540 - val_accuracy: 0.9425\n",
      "Epoch 372/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1232 - accuracy: 0.9529 - val_loss: 0.1542 - val_accuracy: 0.9422\n",
      "Epoch 373/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1231 - accuracy: 0.9527 - val_loss: 0.1543 - val_accuracy: 0.9424\n",
      "Epoch 374/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1231 - accuracy: 0.9528 - val_loss: 0.1541 - val_accuracy: 0.9422\n",
      "Epoch 375/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1230 - accuracy: 0.9529 - val_loss: 0.1540 - val_accuracy: 0.9426\n",
      "Epoch 376/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1229 - accuracy: 0.9526 - val_loss: 0.1541 - val_accuracy: 0.9423\n",
      "Epoch 377/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1228 - accuracy: 0.9528 - val_loss: 0.1544 - val_accuracy: 0.9423\n",
      "Epoch 378/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1228 - accuracy: 0.9526 - val_loss: 0.1541 - val_accuracy: 0.9423\n",
      "Epoch 379/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1227 - accuracy: 0.9529 - val_loss: 0.1542 - val_accuracy: 0.9422\n",
      "Epoch 380/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1226 - accuracy: 0.9530 - val_loss: 0.1544 - val_accuracy: 0.9423\n",
      "Epoch 381/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1226 - accuracy: 0.9530 - val_loss: 0.1539 - val_accuracy: 0.9420\n",
      "Epoch 382/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1225 - accuracy: 0.9531 - val_loss: 0.1542 - val_accuracy: 0.9423\n",
      "Epoch 383/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1224 - accuracy: 0.9531 - val_loss: 0.1538 - val_accuracy: 0.9421\n",
      "Epoch 384/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1223 - accuracy: 0.9531 - val_loss: 0.1538 - val_accuracy: 0.9424\n",
      "Epoch 385/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1223 - accuracy: 0.9529 - val_loss: 0.1538 - val_accuracy: 0.9425\n",
      "Epoch 386/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1222 - accuracy: 0.9531 - val_loss: 0.1539 - val_accuracy: 0.9413\n",
      "Epoch 387/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1221 - accuracy: 0.9530 - val_loss: 0.1544 - val_accuracy: 0.9425\n",
      "Epoch 388/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1221 - accuracy: 0.9530 - val_loss: 0.1543 - val_accuracy: 0.9422\n",
      "Epoch 389/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1220 - accuracy: 0.9530 - val_loss: 0.1540 - val_accuracy: 0.9418\n",
      "Epoch 390/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1218 - accuracy: 0.9532 - val_loss: 0.1544 - val_accuracy: 0.9419\n",
      "Epoch 391/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1217 - accuracy: 0.9533 - val_loss: 0.1543 - val_accuracy: 0.9422\n",
      "Epoch 392/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1217 - accuracy: 0.9532 - val_loss: 0.1538 - val_accuracy: 0.9424\n",
      "Epoch 393/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1216 - accuracy: 0.9533 - val_loss: 0.1544 - val_accuracy: 0.9417\n",
      "Epoch 394/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1216 - accuracy: 0.9534 - val_loss: 0.1549 - val_accuracy: 0.9419\n",
      "Epoch 395/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1216 - accuracy: 0.9534 - val_loss: 0.1538 - val_accuracy: 0.9427\n",
      "Epoch 396/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1214 - accuracy: 0.9533 - val_loss: 0.1541 - val_accuracy: 0.9420\n",
      "Epoch 397/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1214 - accuracy: 0.9532 - val_loss: 0.1539 - val_accuracy: 0.9425\n",
      "Epoch 398/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1213 - accuracy: 0.9536 - val_loss: 0.1542 - val_accuracy: 0.9421\n",
      "Epoch 399/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1213 - accuracy: 0.9534 - val_loss: 0.1537 - val_accuracy: 0.9418\n",
      "Epoch 400/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1212 - accuracy: 0.9534 - val_loss: 0.1545 - val_accuracy: 0.9419\n",
      "Epoch 401/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1211 - accuracy: 0.9533 - val_loss: 0.1543 - val_accuracy: 0.9422\n",
      "Epoch 402/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1210 - accuracy: 0.9534 - val_loss: 0.1554 - val_accuracy: 0.9422\n",
      "Epoch 403/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1209 - accuracy: 0.9535 - val_loss: 0.1540 - val_accuracy: 0.9427\n",
      "Epoch 404/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1209 - accuracy: 0.9534 - val_loss: 0.1535 - val_accuracy: 0.9425\n",
      "Epoch 405/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1207 - accuracy: 0.9535 - val_loss: 0.1539 - val_accuracy: 0.9421\n",
      "Epoch 406/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1206 - accuracy: 0.9537 - val_loss: 0.1549 - val_accuracy: 0.9417\n",
      "Epoch 407/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1207 - accuracy: 0.9535 - val_loss: 0.1540 - val_accuracy: 0.9423\n",
      "Epoch 408/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1205 - accuracy: 0.9535 - val_loss: 0.1542 - val_accuracy: 0.9424\n",
      "Epoch 409/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1205 - accuracy: 0.9535 - val_loss: 0.1539 - val_accuracy: 0.9430\n",
      "Epoch 410/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1204 - accuracy: 0.9535 - val_loss: 0.1540 - val_accuracy: 0.9424\n",
      "Epoch 411/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1203 - accuracy: 0.9539 - val_loss: 0.1543 - val_accuracy: 0.9415\n",
      "Epoch 412/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1203 - accuracy: 0.9536 - val_loss: 0.1538 - val_accuracy: 0.9426\n",
      "Epoch 413/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1202 - accuracy: 0.9539 - val_loss: 0.1541 - val_accuracy: 0.9416\n",
      "Epoch 414/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1201 - accuracy: 0.9537 - val_loss: 0.1536 - val_accuracy: 0.9418\n",
      "Epoch 415/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1201 - accuracy: 0.9536 - val_loss: 0.1542 - val_accuracy: 0.9421\n",
      "Epoch 416/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1201 - accuracy: 0.9536 - val_loss: 0.1539 - val_accuracy: 0.9418\n",
      "Epoch 417/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1199 - accuracy: 0.9538 - val_loss: 0.1539 - val_accuracy: 0.9421\n",
      "Epoch 418/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1198 - accuracy: 0.9538 - val_loss: 0.1535 - val_accuracy: 0.9424\n",
      "Epoch 419/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1198 - accuracy: 0.9538 - val_loss: 0.1543 - val_accuracy: 0.9423\n",
      "Epoch 420/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1198 - accuracy: 0.9538 - val_loss: 0.1545 - val_accuracy: 0.9421\n",
      "Epoch 421/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1196 - accuracy: 0.9539 - val_loss: 0.1546 - val_accuracy: 0.9420\n",
      "Epoch 422/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1196 - accuracy: 0.9540 - val_loss: 0.1539 - val_accuracy: 0.9420\n",
      "Epoch 423/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1195 - accuracy: 0.9540 - val_loss: 0.1537 - val_accuracy: 0.9422\n",
      "Epoch 424/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1194 - accuracy: 0.9539 - val_loss: 0.1544 - val_accuracy: 0.9420\n",
      "Epoch 425/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1193 - accuracy: 0.9540 - val_loss: 0.1541 - val_accuracy: 0.9427\n",
      "Epoch 426/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1193 - accuracy: 0.9539 - val_loss: 0.1545 - val_accuracy: 0.9422\n",
      "Epoch 427/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1192 - accuracy: 0.9542 - val_loss: 0.1534 - val_accuracy: 0.9418\n",
      "Epoch 428/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1190 - accuracy: 0.9540 - val_loss: 0.1538 - val_accuracy: 0.9423\n",
      "Epoch 429/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1190 - accuracy: 0.9539 - val_loss: 0.1538 - val_accuracy: 0.9418\n",
      "Epoch 430/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1190 - accuracy: 0.9542 - val_loss: 0.1546 - val_accuracy: 0.9419\n",
      "Epoch 431/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1188 - accuracy: 0.9542 - val_loss: 0.1551 - val_accuracy: 0.9419\n",
      "Epoch 432/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1188 - accuracy: 0.9541 - val_loss: 0.1544 - val_accuracy: 0.9418\n",
      "Epoch 433/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1188 - accuracy: 0.9540 - val_loss: 0.1537 - val_accuracy: 0.9416\n",
      "Epoch 434/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1188 - accuracy: 0.9540 - val_loss: 0.1541 - val_accuracy: 0.9418\n",
      "Epoch 435/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1187 - accuracy: 0.9539 - val_loss: 0.1543 - val_accuracy: 0.9418\n",
      "Epoch 436/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1186 - accuracy: 0.9541 - val_loss: 0.1540 - val_accuracy: 0.9421\n",
      "Epoch 437/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1186 - accuracy: 0.9541 - val_loss: 0.1539 - val_accuracy: 0.9421\n",
      "Epoch 438/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1185 - accuracy: 0.9541 - val_loss: 0.1535 - val_accuracy: 0.9417\n",
      "Epoch 439/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1183 - accuracy: 0.9542 - val_loss: 0.1547 - val_accuracy: 0.9419\n",
      "Epoch 440/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1183 - accuracy: 0.9545 - val_loss: 0.1537 - val_accuracy: 0.9419\n",
      "Epoch 441/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1183 - accuracy: 0.9545 - val_loss: 0.1543 - val_accuracy: 0.9419\n",
      "Epoch 442/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1181 - accuracy: 0.9543 - val_loss: 0.1542 - val_accuracy: 0.9422\n",
      "Epoch 443/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1181 - accuracy: 0.9543 - val_loss: 0.1543 - val_accuracy: 0.9420\n",
      "Epoch 444/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1180 - accuracy: 0.9544 - val_loss: 0.1547 - val_accuracy: 0.9423\n",
      "Epoch 445/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1179 - accuracy: 0.9543 - val_loss: 0.1545 - val_accuracy: 0.9419\n",
      "Epoch 446/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1179 - accuracy: 0.9544 - val_loss: 0.1549 - val_accuracy: 0.9417\n",
      "Epoch 447/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1179 - accuracy: 0.9543 - val_loss: 0.1542 - val_accuracy: 0.9422\n",
      "Epoch 448/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1177 - accuracy: 0.9544 - val_loss: 0.1540 - val_accuracy: 0.9418\n",
      "Epoch 449/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1177 - accuracy: 0.9545 - val_loss: 0.1543 - val_accuracy: 0.9417\n",
      "Epoch 450/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1176 - accuracy: 0.9546 - val_loss: 0.1551 - val_accuracy: 0.9409\n",
      "Epoch 451/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1176 - accuracy: 0.9546 - val_loss: 0.1547 - val_accuracy: 0.9420\n",
      "Epoch 452/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1175 - accuracy: 0.9546 - val_loss: 0.1537 - val_accuracy: 0.9417\n",
      "Epoch 453/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1174 - accuracy: 0.9545 - val_loss: 0.1547 - val_accuracy: 0.9421\n",
      "Epoch 454/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1173 - accuracy: 0.9544 - val_loss: 0.1543 - val_accuracy: 0.9415\n",
      "Epoch 455/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1173 - accuracy: 0.9546 - val_loss: 0.1540 - val_accuracy: 0.9411\n",
      "Epoch 456/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1171 - accuracy: 0.9548 - val_loss: 0.1546 - val_accuracy: 0.9424\n",
      "Epoch 457/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1171 - accuracy: 0.9544 - val_loss: 0.1552 - val_accuracy: 0.9414\n",
      "Epoch 458/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1170 - accuracy: 0.9545 - val_loss: 0.1543 - val_accuracy: 0.9419\n",
      "Epoch 459/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1170 - accuracy: 0.9547 - val_loss: 0.1547 - val_accuracy: 0.9420\n",
      "Epoch 460/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1168 - accuracy: 0.9546 - val_loss: 0.1543 - val_accuracy: 0.9418\n",
      "Epoch 461/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1169 - accuracy: 0.9547 - val_loss: 0.1548 - val_accuracy: 0.9418\n",
      "Epoch 462/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1168 - accuracy: 0.9547 - val_loss: 0.1553 - val_accuracy: 0.9411\n",
      "Epoch 463/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1167 - accuracy: 0.9548 - val_loss: 0.1544 - val_accuracy: 0.9419\n",
      "Epoch 464/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1166 - accuracy: 0.9548 - val_loss: 0.1538 - val_accuracy: 0.9419\n",
      "Epoch 465/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1164 - accuracy: 0.9549 - val_loss: 0.1549 - val_accuracy: 0.9423\n",
      "Epoch 466/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1164 - accuracy: 0.9549 - val_loss: 0.1553 - val_accuracy: 0.9420\n",
      "Epoch 467/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1164 - accuracy: 0.9548 - val_loss: 0.1545 - val_accuracy: 0.9419\n",
      "Epoch 468/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1163 - accuracy: 0.9548 - val_loss: 0.1543 - val_accuracy: 0.9414\n",
      "Epoch 469/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1163 - accuracy: 0.9551 - val_loss: 0.1538 - val_accuracy: 0.9424\n",
      "Epoch 470/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1161 - accuracy: 0.9548 - val_loss: 0.1546 - val_accuracy: 0.9413\n",
      "Epoch 471/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1161 - accuracy: 0.9550 - val_loss: 0.1544 - val_accuracy: 0.9417\n",
      "Epoch 472/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1160 - accuracy: 0.9549 - val_loss: 0.1557 - val_accuracy: 0.9412\n",
      "Epoch 473/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1160 - accuracy: 0.9550 - val_loss: 0.1547 - val_accuracy: 0.9421\n",
      "Epoch 474/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1159 - accuracy: 0.9549 - val_loss: 0.1547 - val_accuracy: 0.9420\n",
      "Epoch 475/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1158 - accuracy: 0.9551 - val_loss: 0.1552 - val_accuracy: 0.9420\n",
      "Epoch 476/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1159 - accuracy: 0.9550 - val_loss: 0.1540 - val_accuracy: 0.9419\n",
      "Epoch 477/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1157 - accuracy: 0.9549 - val_loss: 0.1554 - val_accuracy: 0.9417\n",
      "Epoch 478/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1156 - accuracy: 0.9553 - val_loss: 0.1557 - val_accuracy: 0.9418\n",
      "Epoch 479/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1155 - accuracy: 0.9552 - val_loss: 0.1547 - val_accuracy: 0.9420\n",
      "Epoch 480/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1155 - accuracy: 0.9553 - val_loss: 0.1554 - val_accuracy: 0.9415\n",
      "Epoch 481/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1154 - accuracy: 0.9552 - val_loss: 0.1559 - val_accuracy: 0.9408\n",
      "Epoch 482/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1153 - accuracy: 0.9551 - val_loss: 0.1549 - val_accuracy: 0.9419\n",
      "Epoch 483/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1153 - accuracy: 0.9552 - val_loss: 0.1552 - val_accuracy: 0.9414\n",
      "Epoch 484/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1152 - accuracy: 0.9551 - val_loss: 0.1549 - val_accuracy: 0.9421\n",
      "Epoch 485/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1150 - accuracy: 0.9553 - val_loss: 0.1547 - val_accuracy: 0.9415\n",
      "Epoch 486/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1152 - accuracy: 0.9553 - val_loss: 0.1545 - val_accuracy: 0.9412\n",
      "Epoch 487/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1150 - accuracy: 0.9554 - val_loss: 0.1565 - val_accuracy: 0.9408\n",
      "Epoch 488/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1150 - accuracy: 0.9554 - val_loss: 0.1552 - val_accuracy: 0.9414\n",
      "Epoch 489/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1149 - accuracy: 0.9551 - val_loss: 0.1552 - val_accuracy: 0.9417\n",
      "Epoch 490/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1148 - accuracy: 0.9555 - val_loss: 0.1553 - val_accuracy: 0.9411\n",
      "Epoch 491/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1148 - accuracy: 0.9553 - val_loss: 0.1554 - val_accuracy: 0.9413\n",
      "Epoch 492/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1147 - accuracy: 0.9555 - val_loss: 0.1550 - val_accuracy: 0.9409\n",
      "Epoch 493/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1147 - accuracy: 0.9554 - val_loss: 0.1557 - val_accuracy: 0.9418\n",
      "Epoch 494/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1146 - accuracy: 0.9556 - val_loss: 0.1548 - val_accuracy: 0.9419\n",
      "Epoch 495/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1144 - accuracy: 0.9558 - val_loss: 0.1563 - val_accuracy: 0.9411\n",
      "Epoch 496/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1145 - accuracy: 0.9556 - val_loss: 0.1552 - val_accuracy: 0.9420\n",
      "Epoch 497/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1143 - accuracy: 0.9556 - val_loss: 0.1550 - val_accuracy: 0.9423\n",
      "Epoch 498/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1143 - accuracy: 0.9556 - val_loss: 0.1551 - val_accuracy: 0.9411\n",
      "Epoch 499/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1142 - accuracy: 0.9556 - val_loss: 0.1550 - val_accuracy: 0.9420\n",
      "Epoch 500/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1141 - accuracy: 0.9555 - val_loss: 0.1547 - val_accuracy: 0.9418\n",
      "Epoch 501/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1142 - accuracy: 0.9555 - val_loss: 0.1551 - val_accuracy: 0.9420\n",
      "Epoch 502/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1139 - accuracy: 0.9557 - val_loss: 0.1554 - val_accuracy: 0.9410\n",
      "Epoch 503/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1139 - accuracy: 0.9557 - val_loss: 0.1545 - val_accuracy: 0.9421\n",
      "Epoch 504/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1138 - accuracy: 0.9557 - val_loss: 0.1557 - val_accuracy: 0.9413\n",
      "Epoch 505/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1138 - accuracy: 0.9557 - val_loss: 0.1556 - val_accuracy: 0.9421\n",
      "Epoch 506/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1138 - accuracy: 0.9559 - val_loss: 0.1553 - val_accuracy: 0.9417\n",
      "Epoch 507/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1136 - accuracy: 0.9558 - val_loss: 0.1557 - val_accuracy: 0.9420\n",
      "Epoch 508/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1136 - accuracy: 0.9557 - val_loss: 0.1555 - val_accuracy: 0.9420\n",
      "Epoch 509/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1136 - accuracy: 0.9557 - val_loss: 0.1554 - val_accuracy: 0.9417\n",
      "Epoch 510/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1134 - accuracy: 0.9559 - val_loss: 0.1556 - val_accuracy: 0.9412\n",
      "Epoch 511/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1133 - accuracy: 0.9559 - val_loss: 0.1552 - val_accuracy: 0.9418\n",
      "Epoch 512/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1134 - accuracy: 0.9559 - val_loss: 0.1557 - val_accuracy: 0.9413\n",
      "Epoch 513/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1133 - accuracy: 0.9562 - val_loss: 0.1559 - val_accuracy: 0.9411\n",
      "Epoch 514/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1132 - accuracy: 0.9561 - val_loss: 0.1553 - val_accuracy: 0.9417\n",
      "Epoch 515/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1131 - accuracy: 0.9560 - val_loss: 0.1559 - val_accuracy: 0.9413\n",
      "Epoch 516/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1131 - accuracy: 0.9560 - val_loss: 0.1547 - val_accuracy: 0.9413\n",
      "Epoch 517/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1129 - accuracy: 0.9563 - val_loss: 0.1561 - val_accuracy: 0.9415\n",
      "Epoch 518/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1129 - accuracy: 0.9560 - val_loss: 0.1567 - val_accuracy: 0.9415\n",
      "Epoch 519/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1129 - accuracy: 0.9560 - val_loss: 0.1556 - val_accuracy: 0.9414\n",
      "Epoch 520/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1128 - accuracy: 0.9560 - val_loss: 0.1555 - val_accuracy: 0.9413\n",
      "Epoch 521/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1127 - accuracy: 0.9560 - val_loss: 0.1560 - val_accuracy: 0.9410\n",
      "Epoch 522/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1126 - accuracy: 0.9561 - val_loss: 0.1553 - val_accuracy: 0.9414\n",
      "Epoch 523/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1126 - accuracy: 0.9560 - val_loss: 0.1570 - val_accuracy: 0.9419\n",
      "Epoch 524/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1124 - accuracy: 0.9562 - val_loss: 0.1557 - val_accuracy: 0.9416\n",
      "Epoch 525/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1124 - accuracy: 0.9562 - val_loss: 0.1562 - val_accuracy: 0.9412\n",
      "Epoch 526/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1125 - accuracy: 0.9561 - val_loss: 0.1569 - val_accuracy: 0.9413\n",
      "Epoch 527/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1123 - accuracy: 0.9563 - val_loss: 0.1557 - val_accuracy: 0.9415\n",
      "Epoch 528/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1123 - accuracy: 0.9563 - val_loss: 0.1554 - val_accuracy: 0.9414\n",
      "Epoch 529/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1121 - accuracy: 0.9564 - val_loss: 0.1554 - val_accuracy: 0.9416\n",
      "Epoch 530/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1120 - accuracy: 0.9562 - val_loss: 0.1566 - val_accuracy: 0.9418\n",
      "Epoch 531/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1120 - accuracy: 0.9565 - val_loss: 0.1563 - val_accuracy: 0.9413\n",
      "Epoch 532/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1120 - accuracy: 0.9565 - val_loss: 0.1566 - val_accuracy: 0.9411\n",
      "Epoch 533/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1118 - accuracy: 0.9567 - val_loss: 0.1559 - val_accuracy: 0.9413\n",
      "Epoch 534/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1119 - accuracy: 0.9565 - val_loss: 0.1560 - val_accuracy: 0.9415\n",
      "Epoch 535/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1117 - accuracy: 0.9566 - val_loss: 0.1566 - val_accuracy: 0.9415\n",
      "Epoch 536/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1117 - accuracy: 0.9568 - val_loss: 0.1565 - val_accuracy: 0.9410\n",
      "Epoch 537/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1117 - accuracy: 0.9564 - val_loss: 0.1562 - val_accuracy: 0.9413\n",
      "Epoch 538/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1116 - accuracy: 0.9566 - val_loss: 0.1582 - val_accuracy: 0.9406\n",
      "Epoch 539/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1115 - accuracy: 0.9565 - val_loss: 0.1578 - val_accuracy: 0.9410\n",
      "Epoch 540/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1114 - accuracy: 0.9564 - val_loss: 0.1565 - val_accuracy: 0.9412\n",
      "Epoch 541/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1113 - accuracy: 0.9568 - val_loss: 0.1565 - val_accuracy: 0.9412\n",
      "Epoch 542/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1113 - accuracy: 0.9568 - val_loss: 0.1570 - val_accuracy: 0.9410\n",
      "Epoch 543/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1112 - accuracy: 0.9565 - val_loss: 0.1563 - val_accuracy: 0.9408\n",
      "Epoch 544/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1112 - accuracy: 0.9567 - val_loss: 0.1560 - val_accuracy: 0.9409\n",
      "Epoch 545/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1110 - accuracy: 0.9568 - val_loss: 0.1567 - val_accuracy: 0.9409\n",
      "Epoch 546/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1111 - accuracy: 0.9568 - val_loss: 0.1563 - val_accuracy: 0.9409\n",
      "Epoch 547/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1110 - accuracy: 0.9568 - val_loss: 0.1561 - val_accuracy: 0.9418\n",
      "Epoch 548/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1108 - accuracy: 0.9568 - val_loss: 0.1561 - val_accuracy: 0.9417\n",
      "Epoch 549/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1108 - accuracy: 0.9569 - val_loss: 0.1580 - val_accuracy: 0.9408\n",
      "Epoch 550/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1108 - accuracy: 0.9568 - val_loss: 0.1567 - val_accuracy: 0.9416\n",
      "Epoch 551/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1108 - accuracy: 0.9568 - val_loss: 0.1569 - val_accuracy: 0.9409\n",
      "Epoch 552/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1106 - accuracy: 0.9568 - val_loss: 0.1575 - val_accuracy: 0.9409\n",
      "Epoch 553/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1106 - accuracy: 0.9567 - val_loss: 0.1575 - val_accuracy: 0.9413\n",
      "Epoch 554/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1106 - accuracy: 0.9569 - val_loss: 0.1567 - val_accuracy: 0.9414\n",
      "Epoch 555/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1105 - accuracy: 0.9569 - val_loss: 0.1573 - val_accuracy: 0.9409\n",
      "Epoch 556/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1105 - accuracy: 0.9569 - val_loss: 0.1572 - val_accuracy: 0.9415\n",
      "Epoch 557/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1103 - accuracy: 0.9572 - val_loss: 0.1574 - val_accuracy: 0.9416\n",
      "Epoch 558/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1102 - accuracy: 0.9569 - val_loss: 0.1568 - val_accuracy: 0.9414\n",
      "Epoch 559/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1101 - accuracy: 0.9571 - val_loss: 0.1568 - val_accuracy: 0.9415\n",
      "Epoch 560/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1101 - accuracy: 0.9570 - val_loss: 0.1565 - val_accuracy: 0.9410\n",
      "Epoch 561/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1099 - accuracy: 0.9571 - val_loss: 0.1567 - val_accuracy: 0.9407\n",
      "Epoch 562/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1100 - accuracy: 0.9571 - val_loss: 0.1574 - val_accuracy: 0.9411\n",
      "Epoch 563/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1100 - accuracy: 0.9573 - val_loss: 0.1570 - val_accuracy: 0.9411\n",
      "Epoch 564/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1098 - accuracy: 0.9570 - val_loss: 0.1574 - val_accuracy: 0.9413\n",
      "Epoch 565/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1097 - accuracy: 0.9572 - val_loss: 0.1569 - val_accuracy: 0.9407\n",
      "Epoch 566/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1097 - accuracy: 0.9572 - val_loss: 0.1575 - val_accuracy: 0.9409\n",
      "Epoch 567/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1096 - accuracy: 0.9573 - val_loss: 0.1573 - val_accuracy: 0.9411\n",
      "Epoch 568/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1095 - accuracy: 0.9571 - val_loss: 0.1566 - val_accuracy: 0.9412\n",
      "Epoch 569/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1096 - accuracy: 0.9573 - val_loss: 0.1575 - val_accuracy: 0.9412\n",
      "Epoch 570/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1094 - accuracy: 0.9571 - val_loss: 0.1580 - val_accuracy: 0.9407\n",
      "Epoch 571/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1094 - accuracy: 0.9573 - val_loss: 0.1577 - val_accuracy: 0.9411\n",
      "Epoch 572/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1093 - accuracy: 0.9575 - val_loss: 0.1581 - val_accuracy: 0.9414\n",
      "Epoch 573/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1092 - accuracy: 0.9573 - val_loss: 0.1575 - val_accuracy: 0.9413\n",
      "Epoch 574/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1092 - accuracy: 0.9574 - val_loss: 0.1575 - val_accuracy: 0.9413\n",
      "Epoch 575/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1090 - accuracy: 0.9575 - val_loss: 0.1575 - val_accuracy: 0.9411\n",
      "Epoch 576/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1089 - accuracy: 0.9577 - val_loss: 0.1580 - val_accuracy: 0.9416\n",
      "Epoch 577/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1090 - accuracy: 0.9574 - val_loss: 0.1581 - val_accuracy: 0.9404\n",
      "Epoch 578/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1089 - accuracy: 0.9574 - val_loss: 0.1575 - val_accuracy: 0.9415\n",
      "Epoch 579/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1088 - accuracy: 0.9574 - val_loss: 0.1592 - val_accuracy: 0.9408\n",
      "Epoch 580/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1088 - accuracy: 0.9577 - val_loss: 0.1587 - val_accuracy: 0.9410\n",
      "Epoch 581/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1087 - accuracy: 0.9576 - val_loss: 0.1578 - val_accuracy: 0.9412\n",
      "Epoch 582/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1086 - accuracy: 0.9576 - val_loss: 0.1573 - val_accuracy: 0.9405\n",
      "Epoch 583/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1085 - accuracy: 0.9577 - val_loss: 0.1586 - val_accuracy: 0.9410\n",
      "Epoch 584/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1085 - accuracy: 0.9578 - val_loss: 0.1584 - val_accuracy: 0.9404\n",
      "Epoch 585/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1083 - accuracy: 0.9578 - val_loss: 0.1576 - val_accuracy: 0.9407\n",
      "Epoch 586/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1084 - accuracy: 0.9577 - val_loss: 0.1582 - val_accuracy: 0.9420\n",
      "Epoch 587/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1082 - accuracy: 0.9580 - val_loss: 0.1581 - val_accuracy: 0.9411\n",
      "Epoch 588/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1083 - accuracy: 0.9577 - val_loss: 0.1577 - val_accuracy: 0.9408\n",
      "Epoch 589/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1081 - accuracy: 0.9581 - val_loss: 0.1582 - val_accuracy: 0.9412\n",
      "Epoch 590/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1080 - accuracy: 0.9578 - val_loss: 0.1590 - val_accuracy: 0.9406\n",
      "Epoch 591/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1081 - accuracy: 0.9580 - val_loss: 0.1595 - val_accuracy: 0.9405\n",
      "Epoch 592/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1080 - accuracy: 0.9579 - val_loss: 0.1588 - val_accuracy: 0.9410\n",
      "Epoch 593/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1078 - accuracy: 0.9581 - val_loss: 0.1580 - val_accuracy: 0.9406\n",
      "Epoch 594/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1079 - accuracy: 0.9578 - val_loss: 0.1581 - val_accuracy: 0.9402\n",
      "Epoch 595/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1077 - accuracy: 0.9579 - val_loss: 0.1584 - val_accuracy: 0.9407\n",
      "Epoch 596/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1077 - accuracy: 0.9580 - val_loss: 0.1596 - val_accuracy: 0.9405\n",
      "Epoch 597/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1077 - accuracy: 0.9582 - val_loss: 0.1577 - val_accuracy: 0.9414\n",
      "Epoch 598/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1075 - accuracy: 0.9582 - val_loss: 0.1582 - val_accuracy: 0.9408\n",
      "Epoch 599/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1074 - accuracy: 0.9581 - val_loss: 0.1586 - val_accuracy: 0.9403\n",
      "Epoch 600/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1074 - accuracy: 0.9580 - val_loss: 0.1587 - val_accuracy: 0.9413\n",
      "Epoch 601/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1074 - accuracy: 0.9581 - val_loss: 0.1595 - val_accuracy: 0.9404\n",
      "Epoch 602/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1074 - accuracy: 0.9581 - val_loss: 0.1582 - val_accuracy: 0.9411\n",
      "Epoch 603/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1074 - accuracy: 0.9580 - val_loss: 0.1591 - val_accuracy: 0.9408\n",
      "Epoch 604/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1071 - accuracy: 0.9584 - val_loss: 0.1590 - val_accuracy: 0.9404\n",
      "Epoch 605/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1070 - accuracy: 0.9582 - val_loss: 0.1595 - val_accuracy: 0.9403\n",
      "Epoch 606/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1071 - accuracy: 0.9581 - val_loss: 0.1583 - val_accuracy: 0.9407\n",
      "Epoch 607/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1069 - accuracy: 0.9584 - val_loss: 0.1586 - val_accuracy: 0.9416\n",
      "Epoch 608/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1070 - accuracy: 0.9583 - val_loss: 0.1583 - val_accuracy: 0.9407\n",
      "Epoch 609/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1067 - accuracy: 0.9583 - val_loss: 0.1592 - val_accuracy: 0.9406\n",
      "Epoch 610/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1067 - accuracy: 0.9583 - val_loss: 0.1599 - val_accuracy: 0.9408\n",
      "Epoch 611/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1067 - accuracy: 0.9583 - val_loss: 0.1591 - val_accuracy: 0.9410\n",
      "Epoch 612/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1066 - accuracy: 0.9582 - val_loss: 0.1609 - val_accuracy: 0.9400\n",
      "Epoch 613/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1066 - accuracy: 0.9583 - val_loss: 0.1598 - val_accuracy: 0.9400\n",
      "Epoch 614/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1066 - accuracy: 0.9583 - val_loss: 0.1594 - val_accuracy: 0.9403\n",
      "Epoch 615/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1065 - accuracy: 0.9584 - val_loss: 0.1589 - val_accuracy: 0.9404\n",
      "Epoch 616/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1064 - accuracy: 0.9584 - val_loss: 0.1591 - val_accuracy: 0.9409\n",
      "Epoch 617/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1064 - accuracy: 0.9585 - val_loss: 0.1598 - val_accuracy: 0.9410\n",
      "Epoch 618/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1063 - accuracy: 0.9585 - val_loss: 0.1609 - val_accuracy: 0.9403\n",
      "Epoch 619/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1062 - accuracy: 0.9583 - val_loss: 0.1588 - val_accuracy: 0.9408\n",
      "Epoch 620/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1061 - accuracy: 0.9586 - val_loss: 0.1597 - val_accuracy: 0.9405\n",
      "Epoch 621/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1059 - accuracy: 0.9585 - val_loss: 0.1597 - val_accuracy: 0.9412\n",
      "Epoch 622/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1059 - accuracy: 0.9589 - val_loss: 0.1608 - val_accuracy: 0.9400\n",
      "Epoch 623/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1059 - accuracy: 0.9588 - val_loss: 0.1597 - val_accuracy: 0.9408\n",
      "Epoch 624/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1058 - accuracy: 0.9587 - val_loss: 0.1602 - val_accuracy: 0.9399\n",
      "Epoch 625/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1058 - accuracy: 0.9584 - val_loss: 0.1604 - val_accuracy: 0.9403\n",
      "Epoch 626/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1057 - accuracy: 0.9587 - val_loss: 0.1600 - val_accuracy: 0.9409\n",
      "Epoch 627/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1056 - accuracy: 0.9587 - val_loss: 0.1604 - val_accuracy: 0.9395\n",
      "Epoch 628/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1057 - accuracy: 0.9590 - val_loss: 0.1602 - val_accuracy: 0.9407\n",
      "Epoch 629/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1054 - accuracy: 0.9589 - val_loss: 0.1602 - val_accuracy: 0.9403\n",
      "Epoch 630/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1054 - accuracy: 0.9587 - val_loss: 0.1606 - val_accuracy: 0.9412\n",
      "Epoch 631/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1054 - accuracy: 0.9589 - val_loss: 0.1600 - val_accuracy: 0.9402\n",
      "Epoch 632/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1052 - accuracy: 0.9591 - val_loss: 0.1599 - val_accuracy: 0.9410\n",
      "Epoch 633/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1052 - accuracy: 0.9592 - val_loss: 0.1604 - val_accuracy: 0.9405\n",
      "Epoch 634/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1052 - accuracy: 0.9589 - val_loss: 0.1613 - val_accuracy: 0.9400\n",
      "Epoch 635/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1051 - accuracy: 0.9588 - val_loss: 0.1619 - val_accuracy: 0.9405\n",
      "Epoch 636/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1050 - accuracy: 0.9590 - val_loss: 0.1601 - val_accuracy: 0.9414\n",
      "Epoch 637/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1050 - accuracy: 0.9591 - val_loss: 0.1602 - val_accuracy: 0.9404\n",
      "Epoch 638/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1047 - accuracy: 0.9590 - val_loss: 0.1604 - val_accuracy: 0.9404\n",
      "Epoch 639/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1048 - accuracy: 0.9590 - val_loss: 0.1609 - val_accuracy: 0.9405\n",
      "Epoch 640/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1048 - accuracy: 0.9590 - val_loss: 0.1604 - val_accuracy: 0.9405\n",
      "Epoch 641/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1048 - accuracy: 0.9589 - val_loss: 0.1603 - val_accuracy: 0.9410\n",
      "Epoch 642/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1046 - accuracy: 0.9592 - val_loss: 0.1621 - val_accuracy: 0.9406\n",
      "Epoch 643/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1045 - accuracy: 0.9590 - val_loss: 0.1615 - val_accuracy: 0.9401\n",
      "Epoch 644/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1046 - accuracy: 0.9590 - val_loss: 0.1609 - val_accuracy: 0.9407\n",
      "Epoch 645/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1044 - accuracy: 0.9595 - val_loss: 0.1614 - val_accuracy: 0.9400\n",
      "Epoch 646/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1044 - accuracy: 0.9593 - val_loss: 0.1614 - val_accuracy: 0.9396\n",
      "Epoch 647/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1042 - accuracy: 0.9593 - val_loss: 0.1608 - val_accuracy: 0.9401\n",
      "Epoch 648/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1043 - accuracy: 0.9594 - val_loss: 0.1606 - val_accuracy: 0.9402\n",
      "Epoch 649/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1041 - accuracy: 0.9593 - val_loss: 0.1614 - val_accuracy: 0.9410\n",
      "Epoch 650/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1042 - accuracy: 0.9594 - val_loss: 0.1618 - val_accuracy: 0.9399\n",
      "Epoch 651/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1041 - accuracy: 0.9592 - val_loss: 0.1617 - val_accuracy: 0.9408\n",
      "Epoch 652/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1039 - accuracy: 0.9593 - val_loss: 0.1611 - val_accuracy: 0.9408\n",
      "Epoch 653/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1039 - accuracy: 0.9593 - val_loss: 0.1605 - val_accuracy: 0.9407\n",
      "Epoch 654/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1038 - accuracy: 0.9595 - val_loss: 0.1623 - val_accuracy: 0.9405\n",
      "Epoch 655/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1038 - accuracy: 0.9595 - val_loss: 0.1605 - val_accuracy: 0.9404\n",
      "Epoch 656/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1037 - accuracy: 0.9596 - val_loss: 0.1624 - val_accuracy: 0.9404\n",
      "Epoch 657/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1036 - accuracy: 0.9594 - val_loss: 0.1626 - val_accuracy: 0.9399\n",
      "Epoch 658/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1036 - accuracy: 0.9593 - val_loss: 0.1606 - val_accuracy: 0.9402\n",
      "Epoch 659/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1035 - accuracy: 0.9597 - val_loss: 0.1634 - val_accuracy: 0.9406\n",
      "Epoch 660/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1034 - accuracy: 0.9597 - val_loss: 0.1621 - val_accuracy: 0.9399\n",
      "Epoch 661/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1034 - accuracy: 0.9595 - val_loss: 0.1624 - val_accuracy: 0.9401\n",
      "Epoch 662/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1034 - accuracy: 0.9596 - val_loss: 0.1625 - val_accuracy: 0.9399\n",
      "Epoch 663/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1032 - accuracy: 0.9599 - val_loss: 0.1619 - val_accuracy: 0.9399\n",
      "Epoch 664/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1030 - accuracy: 0.9595 - val_loss: 0.1616 - val_accuracy: 0.9403\n",
      "Epoch 665/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1030 - accuracy: 0.9599 - val_loss: 0.1618 - val_accuracy: 0.9400\n",
      "Epoch 666/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1030 - accuracy: 0.9596 - val_loss: 0.1631 - val_accuracy: 0.9400\n",
      "Epoch 667/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1029 - accuracy: 0.9599 - val_loss: 0.1622 - val_accuracy: 0.9401\n",
      "Epoch 668/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1029 - accuracy: 0.9596 - val_loss: 0.1624 - val_accuracy: 0.9402\n",
      "Epoch 669/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1027 - accuracy: 0.9598 - val_loss: 0.1632 - val_accuracy: 0.9403\n",
      "Epoch 670/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1026 - accuracy: 0.9600 - val_loss: 0.1624 - val_accuracy: 0.9408\n",
      "Epoch 671/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1027 - accuracy: 0.9598 - val_loss: 0.1622 - val_accuracy: 0.9401\n",
      "Epoch 672/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1026 - accuracy: 0.9600 - val_loss: 0.1634 - val_accuracy: 0.9397\n",
      "Epoch 673/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1025 - accuracy: 0.9601 - val_loss: 0.1629 - val_accuracy: 0.9400\n",
      "Epoch 674/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1024 - accuracy: 0.9598 - val_loss: 0.1630 - val_accuracy: 0.9390\n",
      "Epoch 675/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1025 - accuracy: 0.9598 - val_loss: 0.1627 - val_accuracy: 0.9401\n",
      "Epoch 676/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1022 - accuracy: 0.9603 - val_loss: 0.1633 - val_accuracy: 0.9403\n",
      "Epoch 677/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1023 - accuracy: 0.9600 - val_loss: 0.1638 - val_accuracy: 0.9407\n",
      "Epoch 678/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1021 - accuracy: 0.9600 - val_loss: 0.1637 - val_accuracy: 0.9387\n",
      "Epoch 679/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1021 - accuracy: 0.9598 - val_loss: 0.1637 - val_accuracy: 0.9397\n",
      "Epoch 680/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1021 - accuracy: 0.9601 - val_loss: 0.1635 - val_accuracy: 0.9394\n",
      "Epoch 681/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1019 - accuracy: 0.9601 - val_loss: 0.1625 - val_accuracy: 0.9403\n",
      "Epoch 682/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1019 - accuracy: 0.9602 - val_loss: 0.1627 - val_accuracy: 0.9396\n",
      "Epoch 683/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1019 - accuracy: 0.9600 - val_loss: 0.1630 - val_accuracy: 0.9396\n",
      "Epoch 684/800\n",
      "6000/6000 [==============================] - 1s 92us/step - loss: 0.1017 - accuracy: 0.9601 - val_loss: 0.1632 - val_accuracy: 0.9400\n",
      "Epoch 685/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1017 - accuracy: 0.9603 - val_loss: 0.1638 - val_accuracy: 0.9402\n",
      "Epoch 686/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1016 - accuracy: 0.9603 - val_loss: 0.1651 - val_accuracy: 0.9402\n",
      "Epoch 687/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1015 - accuracy: 0.9604 - val_loss: 0.1642 - val_accuracy: 0.9395\n",
      "Epoch 688/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1015 - accuracy: 0.9603 - val_loss: 0.1641 - val_accuracy: 0.9399\n",
      "Epoch 689/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1014 - accuracy: 0.9603 - val_loss: 0.1648 - val_accuracy: 0.9398\n",
      "Epoch 690/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1012 - accuracy: 0.9606 - val_loss: 0.1639 - val_accuracy: 0.9402\n",
      "Epoch 691/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1013 - accuracy: 0.9603 - val_loss: 0.1649 - val_accuracy: 0.9395\n",
      "Epoch 692/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1012 - accuracy: 0.9604 - val_loss: 0.1653 - val_accuracy: 0.9398\n",
      "Epoch 693/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1012 - accuracy: 0.9605 - val_loss: 0.1642 - val_accuracy: 0.9398\n",
      "Epoch 694/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1010 - accuracy: 0.9608 - val_loss: 0.1643 - val_accuracy: 0.9404\n",
      "Epoch 695/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1010 - accuracy: 0.9605 - val_loss: 0.1644 - val_accuracy: 0.9394\n",
      "Epoch 696/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1010 - accuracy: 0.9603 - val_loss: 0.1637 - val_accuracy: 0.9404\n",
      "Epoch 697/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1010 - accuracy: 0.9603 - val_loss: 0.1640 - val_accuracy: 0.9396\n",
      "Epoch 698/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1009 - accuracy: 0.9606 - val_loss: 0.1644 - val_accuracy: 0.9402\n",
      "Epoch 699/800\n",
      "6000/6000 [==============================] - 1s 87us/step - loss: 0.1006 - accuracy: 0.9607 - val_loss: 0.1641 - val_accuracy: 0.9396\n",
      "Epoch 700/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1007 - accuracy: 0.9605 - val_loss: 0.1643 - val_accuracy: 0.9403\n",
      "Epoch 701/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1006 - accuracy: 0.9608 - val_loss: 0.1651 - val_accuracy: 0.9393\n",
      "Epoch 702/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1004 - accuracy: 0.9603 - val_loss: 0.1659 - val_accuracy: 0.9396\n",
      "Epoch 703/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1004 - accuracy: 0.9610 - val_loss: 0.1647 - val_accuracy: 0.9400\n",
      "Epoch 704/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1004 - accuracy: 0.9606 - val_loss: 0.1657 - val_accuracy: 0.9404\n",
      "Epoch 705/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1003 - accuracy: 0.9609 - val_loss: 0.1647 - val_accuracy: 0.9396\n",
      "Epoch 706/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1002 - accuracy: 0.9605 - val_loss: 0.1655 - val_accuracy: 0.9396\n",
      "Epoch 707/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1001 - accuracy: 0.9608 - val_loss: 0.1684 - val_accuracy: 0.9384\n",
      "Epoch 708/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1001 - accuracy: 0.9609 - val_loss: 0.1648 - val_accuracy: 0.9395\n",
      "Epoch 709/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1001 - accuracy: 0.9607 - val_loss: 0.1652 - val_accuracy: 0.9392\n",
      "Epoch 710/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0998 - accuracy: 0.9613 - val_loss: 0.1648 - val_accuracy: 0.9394\n",
      "Epoch 711/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0998 - accuracy: 0.9611 - val_loss: 0.1659 - val_accuracy: 0.9393\n",
      "Epoch 712/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0998 - accuracy: 0.9607 - val_loss: 0.1649 - val_accuracy: 0.9399\n",
      "Epoch 713/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0997 - accuracy: 0.9609 - val_loss: 0.1670 - val_accuracy: 0.9382\n",
      "Epoch 714/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0997 - accuracy: 0.9610 - val_loss: 0.1659 - val_accuracy: 0.9396\n",
      "Epoch 715/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0997 - accuracy: 0.9611 - val_loss: 0.1651 - val_accuracy: 0.9404\n",
      "Epoch 716/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0994 - accuracy: 0.9613 - val_loss: 0.1651 - val_accuracy: 0.9399\n",
      "Epoch 717/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0994 - accuracy: 0.9611 - val_loss: 0.1655 - val_accuracy: 0.9399\n",
      "Epoch 718/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0993 - accuracy: 0.9612 - val_loss: 0.1659 - val_accuracy: 0.9400\n",
      "Epoch 719/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0993 - accuracy: 0.9612 - val_loss: 0.1660 - val_accuracy: 0.9398\n",
      "Epoch 720/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0992 - accuracy: 0.9614 - val_loss: 0.1664 - val_accuracy: 0.9396\n",
      "Epoch 721/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0991 - accuracy: 0.9612 - val_loss: 0.1680 - val_accuracy: 0.9389\n",
      "Epoch 722/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0990 - accuracy: 0.9613 - val_loss: 0.1672 - val_accuracy: 0.9400\n",
      "Epoch 723/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0988 - accuracy: 0.9614 - val_loss: 0.1692 - val_accuracy: 0.9394\n",
      "Epoch 724/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0991 - accuracy: 0.9613 - val_loss: 0.1657 - val_accuracy: 0.9396\n",
      "Epoch 725/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0989 - accuracy: 0.9613 - val_loss: 0.1658 - val_accuracy: 0.9395\n",
      "Epoch 726/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0988 - accuracy: 0.9612 - val_loss: 0.1663 - val_accuracy: 0.9399\n",
      "Epoch 727/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0988 - accuracy: 0.9612 - val_loss: 0.1666 - val_accuracy: 0.9396\n",
      "Epoch 728/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0986 - accuracy: 0.9614 - val_loss: 0.1655 - val_accuracy: 0.9400\n",
      "Epoch 729/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0987 - accuracy: 0.9614 - val_loss: 0.1672 - val_accuracy: 0.9391\n",
      "Epoch 730/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0986 - accuracy: 0.9612 - val_loss: 0.1674 - val_accuracy: 0.9398\n",
      "Epoch 731/800\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.96 - 0s 72us/step - loss: 0.0984 - accuracy: 0.9615 - val_loss: 0.1675 - val_accuracy: 0.9393\n",
      "Epoch 732/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0983 - accuracy: 0.9616 - val_loss: 0.1677 - val_accuracy: 0.9396\n",
      "Epoch 733/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0983 - accuracy: 0.9616 - val_loss: 0.1659 - val_accuracy: 0.9395\n",
      "Epoch 734/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0982 - accuracy: 0.9616 - val_loss: 0.1672 - val_accuracy: 0.9391\n",
      "Epoch 735/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0982 - accuracy: 0.9617 - val_loss: 0.1705 - val_accuracy: 0.9376\n",
      "Epoch 736/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0981 - accuracy: 0.9615 - val_loss: 0.1684 - val_accuracy: 0.9384\n",
      "Epoch 737/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0979 - accuracy: 0.9615 - val_loss: 0.1675 - val_accuracy: 0.9386\n",
      "Epoch 738/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0980 - accuracy: 0.9615 - val_loss: 0.1683 - val_accuracy: 0.9390\n",
      "Epoch 739/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0979 - accuracy: 0.9616 - val_loss: 0.1672 - val_accuracy: 0.9393\n",
      "Epoch 740/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0978 - accuracy: 0.9617 - val_loss: 0.1678 - val_accuracy: 0.9394\n",
      "Epoch 741/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0976 - accuracy: 0.9617 - val_loss: 0.1670 - val_accuracy: 0.9395\n",
      "Epoch 742/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0977 - accuracy: 0.9617 - val_loss: 0.1697 - val_accuracy: 0.9377\n",
      "Epoch 743/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0975 - accuracy: 0.9619 - val_loss: 0.1708 - val_accuracy: 0.9381\n",
      "Epoch 744/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0975 - accuracy: 0.9620 - val_loss: 0.1692 - val_accuracy: 0.9396\n",
      "Epoch 745/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0974 - accuracy: 0.9618 - val_loss: 0.1689 - val_accuracy: 0.9388\n",
      "Epoch 746/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.0974 - accuracy: 0.9619 - val_loss: 0.1679 - val_accuracy: 0.9392\n",
      "Epoch 747/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0972 - accuracy: 0.9619 - val_loss: 0.1692 - val_accuracy: 0.9395\n",
      "Epoch 748/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0972 - accuracy: 0.9618 - val_loss: 0.1688 - val_accuracy: 0.9388\n",
      "Epoch 749/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0972 - accuracy: 0.9621 - val_loss: 0.1695 - val_accuracy: 0.9386\n",
      "Epoch 750/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0970 - accuracy: 0.9621 - val_loss: 0.1718 - val_accuracy: 0.9386\n",
      "Epoch 751/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0971 - accuracy: 0.9621 - val_loss: 0.1696 - val_accuracy: 0.9391\n",
      "Epoch 752/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0969 - accuracy: 0.9621 - val_loss: 0.1685 - val_accuracy: 0.9397\n",
      "Epoch 753/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0968 - accuracy: 0.9625 - val_loss: 0.1707 - val_accuracy: 0.9375\n",
      "Epoch 754/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0968 - accuracy: 0.9621 - val_loss: 0.1695 - val_accuracy: 0.9398\n",
      "Epoch 755/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0968 - accuracy: 0.9623 - val_loss: 0.1701 - val_accuracy: 0.9385\n",
      "Epoch 756/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0965 - accuracy: 0.9623 - val_loss: 0.1707 - val_accuracy: 0.9392\n",
      "Epoch 757/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0967 - accuracy: 0.9622 - val_loss: 0.1702 - val_accuracy: 0.9384\n",
      "Epoch 758/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0964 - accuracy: 0.9626 - val_loss: 0.1684 - val_accuracy: 0.9392\n",
      "Epoch 759/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0964 - accuracy: 0.9623 - val_loss: 0.1683 - val_accuracy: 0.9389\n",
      "Epoch 760/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0964 - accuracy: 0.9625 - val_loss: 0.1706 - val_accuracy: 0.9391\n",
      "Epoch 761/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0962 - accuracy: 0.9625 - val_loss: 0.1697 - val_accuracy: 0.9386\n",
      "Epoch 762/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0961 - accuracy: 0.9623 - val_loss: 0.1695 - val_accuracy: 0.9392\n",
      "Epoch 763/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0962 - accuracy: 0.9623 - val_loss: 0.1697 - val_accuracy: 0.9389\n",
      "Epoch 764/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0960 - accuracy: 0.9625 - val_loss: 0.1728 - val_accuracy: 0.9375\n",
      "Epoch 765/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0961 - accuracy: 0.9625 - val_loss: 0.1707 - val_accuracy: 0.9389\n",
      "Epoch 766/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0959 - accuracy: 0.9626 - val_loss: 0.1702 - val_accuracy: 0.9386\n",
      "Epoch 767/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0959 - accuracy: 0.9626 - val_loss: 0.1717 - val_accuracy: 0.9377\n",
      "Epoch 768/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0959 - accuracy: 0.9626 - val_loss: 0.1698 - val_accuracy: 0.9386\n",
      "Epoch 769/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0956 - accuracy: 0.9625 - val_loss: 0.1704 - val_accuracy: 0.9388\n",
      "Epoch 770/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0955 - accuracy: 0.9625 - val_loss: 0.1699 - val_accuracy: 0.9397\n",
      "Epoch 771/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0956 - accuracy: 0.9627 - val_loss: 0.1713 - val_accuracy: 0.9395\n",
      "Epoch 772/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0954 - accuracy: 0.9627 - val_loss: 0.1715 - val_accuracy: 0.9394\n",
      "Epoch 773/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0955 - accuracy: 0.9626 - val_loss: 0.1713 - val_accuracy: 0.9396\n",
      "Epoch 774/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0954 - accuracy: 0.9627 - val_loss: 0.1704 - val_accuracy: 0.9383\n",
      "Epoch 775/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0953 - accuracy: 0.9629 - val_loss: 0.1704 - val_accuracy: 0.9382\n",
      "Epoch 776/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0950 - accuracy: 0.9628 - val_loss: 0.1713 - val_accuracy: 0.9384\n",
      "Epoch 777/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0950 - accuracy: 0.9628 - val_loss: 0.1718 - val_accuracy: 0.9388\n",
      "Epoch 778/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0950 - accuracy: 0.9627 - val_loss: 0.1716 - val_accuracy: 0.9381\n",
      "Epoch 779/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0950 - accuracy: 0.9629 - val_loss: 0.1712 - val_accuracy: 0.9395\n",
      "Epoch 780/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0949 - accuracy: 0.9629 - val_loss: 0.1713 - val_accuracy: 0.9395\n",
      "Epoch 781/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0948 - accuracy: 0.9627 - val_loss: 0.1732 - val_accuracy: 0.9384\n",
      "Epoch 782/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0947 - accuracy: 0.9630 - val_loss: 0.1715 - val_accuracy: 0.9389\n",
      "Epoch 783/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0946 - accuracy: 0.9630 - val_loss: 0.1724 - val_accuracy: 0.9383\n",
      "Epoch 784/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0947 - accuracy: 0.9629 - val_loss: 0.1715 - val_accuracy: 0.9383\n",
      "Epoch 785/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0946 - accuracy: 0.9628 - val_loss: 0.1719 - val_accuracy: 0.9383\n",
      "Epoch 786/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0945 - accuracy: 0.9629 - val_loss: 0.1717 - val_accuracy: 0.9393\n",
      "Epoch 787/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0943 - accuracy: 0.9632 - val_loss: 0.1723 - val_accuracy: 0.9387\n",
      "Epoch 788/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0943 - accuracy: 0.9632 - val_loss: 0.1731 - val_accuracy: 0.9384\n",
      "Epoch 789/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0941 - accuracy: 0.9632 - val_loss: 0.1721 - val_accuracy: 0.9385\n",
      "Epoch 790/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0943 - accuracy: 0.9634 - val_loss: 0.1729 - val_accuracy: 0.9384\n",
      "Epoch 791/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0941 - accuracy: 0.9633 - val_loss: 0.1714 - val_accuracy: 0.9385\n",
      "Epoch 792/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.0941 - accuracy: 0.9630 - val_loss: 0.1723 - val_accuracy: 0.9385\n",
      "Epoch 793/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.0939 - accuracy: 0.9632 - val_loss: 0.1723 - val_accuracy: 0.9385\n",
      "Epoch 794/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0938 - accuracy: 0.9633 - val_loss: 0.1749 - val_accuracy: 0.9364\n",
      "Epoch 795/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0939 - accuracy: 0.9632 - val_loss: 0.1749 - val_accuracy: 0.9375\n",
      "Epoch 796/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0936 - accuracy: 0.9635 - val_loss: 0.1733 - val_accuracy: 0.9389\n",
      "Epoch 797/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0937 - accuracy: 0.9632 - val_loss: 0.1726 - val_accuracy: 0.9387\n",
      "Epoch 798/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0936 - accuracy: 0.9636 - val_loss: 0.1719 - val_accuracy: 0.9390\n",
      "Epoch 799/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0935 - accuracy: 0.9634 - val_loss: 0.1725 - val_accuracy: 0.9387\n",
      "Epoch 800/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0934 - accuracy: 0.9634 - val_loss: 0.1720 - val_accuracy: 0.9385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:122: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Train on 6000 samples, validate on 2001 samples\n",
      "Epoch 1/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.3886 - accuracy: 0.8688 - val_loss: 0.2650 - val_accuracy: 0.9250\n",
      "Epoch 2/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2491 - accuracy: 0.9306 - val_loss: 0.2642 - val_accuracy: 0.9250\n",
      "Epoch 3/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2486 - accuracy: 0.9306 - val_loss: 0.2638 - val_accuracy: 0.9250\n",
      "Epoch 4/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2483 - accuracy: 0.9306 - val_loss: 0.2634 - val_accuracy: 0.9250\n",
      "Epoch 5/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2480 - accuracy: 0.9306 - val_loss: 0.2631 - val_accuracy: 0.9250\n",
      "Epoch 6/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2477 - accuracy: 0.9306 - val_loss: 0.2629 - val_accuracy: 0.9250\n",
      "Epoch 7/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.2474 - accuracy: 0.9306 - val_loss: 0.2624 - val_accuracy: 0.9250\n",
      "Epoch 8/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2470 - accuracy: 0.9306 - val_loss: 0.2621 - val_accuracy: 0.9250\n",
      "Epoch 9/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2467 - accuracy: 0.9306 - val_loss: 0.2619 - val_accuracy: 0.9250\n",
      "Epoch 10/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2463 - accuracy: 0.9306 - val_loss: 0.2614 - val_accuracy: 0.9250\n",
      "Epoch 11/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2459 - accuracy: 0.9306 - val_loss: 0.2610 - val_accuracy: 0.9250\n",
      "Epoch 12/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.2455 - accuracy: 0.9306 - val_loss: 0.2607 - val_accuracy: 0.9250\n",
      "Epoch 13/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2450 - accuracy: 0.9306 - val_loss: 0.2599 - val_accuracy: 0.9250\n",
      "Epoch 14/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2444 - accuracy: 0.9306 - val_loss: 0.2592 - val_accuracy: 0.9250\n",
      "Epoch 15/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2438 - accuracy: 0.9306 - val_loss: 0.2587 - val_accuracy: 0.9250\n",
      "Epoch 16/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2431 - accuracy: 0.9306 - val_loss: 0.2579 - val_accuracy: 0.9250\n",
      "Epoch 17/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2424 - accuracy: 0.9306 - val_loss: 0.2571 - val_accuracy: 0.9250\n",
      "Epoch 18/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.2416 - accuracy: 0.9306 - val_loss: 0.2562 - val_accuracy: 0.9250\n",
      "Epoch 19/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.2406 - accuracy: 0.9306 - val_loss: 0.2551 - val_accuracy: 0.9250\n",
      "Epoch 20/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.2396 - accuracy: 0.9306 - val_loss: 0.2540 - val_accuracy: 0.9250\n",
      "Epoch 21/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.2384 - accuracy: 0.9306 - val_loss: 0.2530 - val_accuracy: 0.9250\n",
      "Epoch 22/800\n",
      "6000/6000 [==============================] - 1s 87us/step - loss: 0.2372 - accuracy: 0.9306 - val_loss: 0.2516 - val_accuracy: 0.9250\n",
      "Epoch 23/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.2359 - accuracy: 0.9306 - val_loss: 0.2502 - val_accuracy: 0.9250\n",
      "Epoch 24/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.2345 - accuracy: 0.9306 - val_loss: 0.2488 - val_accuracy: 0.9250\n",
      "Epoch 25/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.2330 - accuracy: 0.9306 - val_loss: 0.2472 - val_accuracy: 0.9250\n",
      "Epoch 26/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.2315 - accuracy: 0.9306 - val_loss: 0.2457 - val_accuracy: 0.9250\n",
      "Epoch 27/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.2299 - accuracy: 0.9306 - val_loss: 0.2440 - val_accuracy: 0.9250\n",
      "Epoch 28/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.2282 - accuracy: 0.9307 - val_loss: 0.2423 - val_accuracy: 0.9251\n",
      "Epoch 29/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.2266 - accuracy: 0.9307 - val_loss: 0.2404 - val_accuracy: 0.9252\n",
      "Epoch 30/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.2248 - accuracy: 0.9307 - val_loss: 0.2388 - val_accuracy: 0.9252\n",
      "Epoch 31/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2231 - accuracy: 0.9308 - val_loss: 0.2372 - val_accuracy: 0.9252\n",
      "Epoch 32/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2215 - accuracy: 0.9308 - val_loss: 0.2354 - val_accuracy: 0.9253\n",
      "Epoch 33/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2198 - accuracy: 0.9308 - val_loss: 0.2338 - val_accuracy: 0.9253\n",
      "Epoch 34/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2181 - accuracy: 0.9309 - val_loss: 0.2322 - val_accuracy: 0.9253\n",
      "Epoch 35/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2165 - accuracy: 0.9309 - val_loss: 0.2304 - val_accuracy: 0.9254\n",
      "Epoch 36/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2149 - accuracy: 0.9309 - val_loss: 0.2289 - val_accuracy: 0.9255\n",
      "Epoch 37/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2134 - accuracy: 0.9310 - val_loss: 0.2273 - val_accuracy: 0.9255\n",
      "Epoch 38/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2117 - accuracy: 0.9309 - val_loss: 0.2260 - val_accuracy: 0.9257\n",
      "Epoch 39/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2102 - accuracy: 0.9310 - val_loss: 0.2245 - val_accuracy: 0.9258\n",
      "Epoch 40/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2087 - accuracy: 0.9311 - val_loss: 0.2229 - val_accuracy: 0.9257\n",
      "Epoch 41/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2072 - accuracy: 0.9312 - val_loss: 0.2216 - val_accuracy: 0.9258\n",
      "Epoch 42/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2058 - accuracy: 0.9313 - val_loss: 0.2204 - val_accuracy: 0.9260\n",
      "Epoch 43/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.2044 - accuracy: 0.9313 - val_loss: 0.2189 - val_accuracy: 0.9260\n",
      "Epoch 44/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2029 - accuracy: 0.9313 - val_loss: 0.2175 - val_accuracy: 0.9262\n",
      "Epoch 45/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2016 - accuracy: 0.9315 - val_loss: 0.2162 - val_accuracy: 0.9265\n",
      "Epoch 46/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2002 - accuracy: 0.9316 - val_loss: 0.2151 - val_accuracy: 0.9263\n",
      "Epoch 47/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1988 - accuracy: 0.9316 - val_loss: 0.2136 - val_accuracy: 0.9265\n",
      "Epoch 48/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1974 - accuracy: 0.9317 - val_loss: 0.2126 - val_accuracy: 0.9267\n",
      "Epoch 49/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1961 - accuracy: 0.9318 - val_loss: 0.2111 - val_accuracy: 0.9266\n",
      "Epoch 50/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1947 - accuracy: 0.9321 - val_loss: 0.2098 - val_accuracy: 0.9268\n",
      "Epoch 51/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1934 - accuracy: 0.9321 - val_loss: 0.2089 - val_accuracy: 0.9267\n",
      "Epoch 52/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1921 - accuracy: 0.9323 - val_loss: 0.2072 - val_accuracy: 0.9268\n",
      "Epoch 53/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1907 - accuracy: 0.9325 - val_loss: 0.2060 - val_accuracy: 0.9268\n",
      "Epoch 54/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1894 - accuracy: 0.9328 - val_loss: 0.2048 - val_accuracy: 0.9270\n",
      "Epoch 55/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1882 - accuracy: 0.9330 - val_loss: 0.2038 - val_accuracy: 0.9272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1870 - accuracy: 0.9333 - val_loss: 0.2025 - val_accuracy: 0.9273\n",
      "Epoch 57/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1858 - accuracy: 0.9335 - val_loss: 0.2016 - val_accuracy: 0.9277\n",
      "Epoch 58/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1848 - accuracy: 0.9338 - val_loss: 0.2008 - val_accuracy: 0.9276\n",
      "Epoch 59/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1838 - accuracy: 0.9341 - val_loss: 0.2001 - val_accuracy: 0.9280\n",
      "Epoch 60/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1828 - accuracy: 0.9342 - val_loss: 0.1989 - val_accuracy: 0.9280\n",
      "Epoch 61/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1819 - accuracy: 0.9344 - val_loss: 0.1982 - val_accuracy: 0.9282\n",
      "Epoch 62/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1811 - accuracy: 0.9347 - val_loss: 0.1978 - val_accuracy: 0.9281\n",
      "Epoch 63/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1802 - accuracy: 0.9348 - val_loss: 0.1968 - val_accuracy: 0.9283\n",
      "Epoch 64/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1795 - accuracy: 0.9350 - val_loss: 0.1962 - val_accuracy: 0.9290\n",
      "Epoch 65/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1787 - accuracy: 0.9352 - val_loss: 0.1954 - val_accuracy: 0.9286\n",
      "Epoch 66/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1779 - accuracy: 0.9354 - val_loss: 0.1953 - val_accuracy: 0.9287\n",
      "Epoch 67/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1773 - accuracy: 0.9356 - val_loss: 0.1942 - val_accuracy: 0.9292\n",
      "Epoch 68/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1766 - accuracy: 0.9356 - val_loss: 0.1932 - val_accuracy: 0.9293\n",
      "Epoch 69/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1759 - accuracy: 0.9360 - val_loss: 0.1929 - val_accuracy: 0.9295\n",
      "Epoch 70/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1753 - accuracy: 0.9361 - val_loss: 0.1923 - val_accuracy: 0.9293\n",
      "Epoch 71/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1747 - accuracy: 0.9363 - val_loss: 0.1918 - val_accuracy: 0.9297\n",
      "Epoch 72/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1742 - accuracy: 0.9364 - val_loss: 0.1913 - val_accuracy: 0.9301\n",
      "Epoch 73/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1736 - accuracy: 0.9368 - val_loss: 0.1908 - val_accuracy: 0.9300\n",
      "Epoch 74/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1730 - accuracy: 0.9369 - val_loss: 0.1904 - val_accuracy: 0.9300\n",
      "Epoch 75/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1726 - accuracy: 0.9370 - val_loss: 0.1898 - val_accuracy: 0.9300\n",
      "Epoch 76/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1720 - accuracy: 0.9372 - val_loss: 0.1894 - val_accuracy: 0.9301\n",
      "Epoch 77/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1715 - accuracy: 0.9374 - val_loss: 0.1891 - val_accuracy: 0.9304\n",
      "Epoch 78/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1710 - accuracy: 0.9376 - val_loss: 0.1886 - val_accuracy: 0.9303\n",
      "Epoch 79/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1706 - accuracy: 0.9378 - val_loss: 0.1885 - val_accuracy: 0.9308\n",
      "Epoch 80/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1701 - accuracy: 0.9380 - val_loss: 0.1878 - val_accuracy: 0.9309\n",
      "Epoch 81/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1696 - accuracy: 0.9382 - val_loss: 0.1877 - val_accuracy: 0.9312\n",
      "Epoch 82/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1692 - accuracy: 0.9383 - val_loss: 0.1868 - val_accuracy: 0.9317\n",
      "Epoch 83/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1688 - accuracy: 0.9385 - val_loss: 0.1864 - val_accuracy: 0.9314\n",
      "Epoch 84/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1684 - accuracy: 0.9385 - val_loss: 0.1863 - val_accuracy: 0.9314\n",
      "Epoch 85/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1680 - accuracy: 0.9387 - val_loss: 0.1861 - val_accuracy: 0.9318\n",
      "Epoch 86/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1676 - accuracy: 0.9388 - val_loss: 0.1864 - val_accuracy: 0.9315\n",
      "Epoch 87/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1672 - accuracy: 0.9390 - val_loss: 0.1851 - val_accuracy: 0.9316\n",
      "Epoch 88/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1668 - accuracy: 0.9392 - val_loss: 0.1850 - val_accuracy: 0.9320\n",
      "Epoch 89/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1664 - accuracy: 0.9394 - val_loss: 0.1846 - val_accuracy: 0.9323\n",
      "Epoch 90/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1661 - accuracy: 0.9395 - val_loss: 0.1847 - val_accuracy: 0.9325\n",
      "Epoch 91/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1657 - accuracy: 0.9396 - val_loss: 0.1837 - val_accuracy: 0.9321\n",
      "Epoch 92/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1654 - accuracy: 0.9396 - val_loss: 0.1841 - val_accuracy: 0.9325\n",
      "Epoch 93/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1650 - accuracy: 0.9397 - val_loss: 0.1833 - val_accuracy: 0.9323\n",
      "Epoch 94/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1647 - accuracy: 0.9398 - val_loss: 0.1831 - val_accuracy: 0.9327\n",
      "Epoch 95/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1643 - accuracy: 0.9400 - val_loss: 0.1831 - val_accuracy: 0.9325\n",
      "Epoch 96/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1640 - accuracy: 0.9402 - val_loss: 0.1822 - val_accuracy: 0.9328\n",
      "Epoch 97/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1635 - accuracy: 0.9403 - val_loss: 0.1824 - val_accuracy: 0.9328\n",
      "Epoch 98/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1632 - accuracy: 0.9403 - val_loss: 0.1819 - val_accuracy: 0.9329\n",
      "Epoch 99/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1628 - accuracy: 0.9407 - val_loss: 0.1813 - val_accuracy: 0.9332\n",
      "Epoch 100/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1625 - accuracy: 0.9406 - val_loss: 0.1815 - val_accuracy: 0.9338\n",
      "Epoch 101/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1620 - accuracy: 0.9408 - val_loss: 0.1809 - val_accuracy: 0.9333\n",
      "Epoch 102/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1617 - accuracy: 0.9409 - val_loss: 0.1807 - val_accuracy: 0.9335\n",
      "Epoch 103/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1613 - accuracy: 0.9410 - val_loss: 0.1801 - val_accuracy: 0.9335\n",
      "Epoch 104/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1608 - accuracy: 0.9413 - val_loss: 0.1800 - val_accuracy: 0.9340\n",
      "Epoch 105/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1605 - accuracy: 0.9413 - val_loss: 0.1795 - val_accuracy: 0.9338\n",
      "Epoch 106/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1600 - accuracy: 0.9414 - val_loss: 0.1785 - val_accuracy: 0.9342\n",
      "Epoch 107/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1596 - accuracy: 0.9415 - val_loss: 0.1787 - val_accuracy: 0.9339\n",
      "Epoch 108/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1592 - accuracy: 0.9417 - val_loss: 0.1782 - val_accuracy: 0.9339\n",
      "Epoch 109/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1588 - accuracy: 0.9419 - val_loss: 0.1774 - val_accuracy: 0.9348\n",
      "Epoch 110/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1584 - accuracy: 0.9421 - val_loss: 0.1775 - val_accuracy: 0.9347\n",
      "Epoch 111/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1580 - accuracy: 0.9423 - val_loss: 0.1766 - val_accuracy: 0.9349\n",
      "Epoch 112/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1576 - accuracy: 0.9424 - val_loss: 0.1766 - val_accuracy: 0.9349\n",
      "Epoch 113/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1573 - accuracy: 0.9425 - val_loss: 0.1766 - val_accuracy: 0.9346\n",
      "Epoch 114/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1568 - accuracy: 0.9427 - val_loss: 0.1758 - val_accuracy: 0.9352\n",
      "Epoch 115/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1564 - accuracy: 0.9427 - val_loss: 0.1758 - val_accuracy: 0.9356\n",
      "Epoch 116/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1561 - accuracy: 0.9429 - val_loss: 0.1754 - val_accuracy: 0.9356\n",
      "Epoch 117/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1557 - accuracy: 0.9432 - val_loss: 0.1749 - val_accuracy: 0.9356\n",
      "Epoch 118/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1554 - accuracy: 0.9433 - val_loss: 0.1749 - val_accuracy: 0.9354\n",
      "Epoch 119/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1551 - accuracy: 0.9433 - val_loss: 0.1744 - val_accuracy: 0.9363\n",
      "Epoch 120/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1547 - accuracy: 0.9434 - val_loss: 0.1740 - val_accuracy: 0.9362\n",
      "Epoch 121/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1544 - accuracy: 0.9436 - val_loss: 0.1744 - val_accuracy: 0.9359\n",
      "Epoch 122/800\n",
      "6000/6000 [==============================] - 1s 83us/step - loss: 0.1541 - accuracy: 0.9439 - val_loss: 0.1738 - val_accuracy: 0.9361\n",
      "Epoch 123/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1538 - accuracy: 0.9438 - val_loss: 0.1738 - val_accuracy: 0.9364\n",
      "Epoch 124/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1534 - accuracy: 0.9439 - val_loss: 0.1729 - val_accuracy: 0.9364\n",
      "Epoch 125/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1532 - accuracy: 0.9442 - val_loss: 0.1729 - val_accuracy: 0.9365\n",
      "Epoch 126/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1530 - accuracy: 0.9442 - val_loss: 0.1726 - val_accuracy: 0.9369\n",
      "Epoch 127/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1526 - accuracy: 0.9444 - val_loss: 0.1726 - val_accuracy: 0.9370\n",
      "Epoch 128/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1524 - accuracy: 0.9445 - val_loss: 0.1732 - val_accuracy: 0.9365\n",
      "Epoch 129/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1522 - accuracy: 0.9443 - val_loss: 0.1720 - val_accuracy: 0.9369\n",
      "Epoch 130/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1519 - accuracy: 0.9445 - val_loss: 0.1718 - val_accuracy: 0.9368\n",
      "Epoch 131/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1517 - accuracy: 0.9446 - val_loss: 0.1717 - val_accuracy: 0.9370\n",
      "Epoch 132/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1515 - accuracy: 0.9449 - val_loss: 0.1714 - val_accuracy: 0.9371\n",
      "Epoch 133/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1513 - accuracy: 0.9449 - val_loss: 0.1715 - val_accuracy: 0.9372\n",
      "Epoch 134/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1510 - accuracy: 0.9450 - val_loss: 0.1711 - val_accuracy: 0.9371\n",
      "Epoch 135/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1508 - accuracy: 0.9452 - val_loss: 0.1711 - val_accuracy: 0.9372\n",
      "Epoch 136/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1507 - accuracy: 0.9452 - val_loss: 0.1711 - val_accuracy: 0.9373\n",
      "Epoch 137/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1504 - accuracy: 0.9453 - val_loss: 0.1711 - val_accuracy: 0.9368\n",
      "Epoch 138/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1502 - accuracy: 0.9450 - val_loss: 0.1705 - val_accuracy: 0.9373\n",
      "Epoch 139/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1500 - accuracy: 0.9455 - val_loss: 0.1704 - val_accuracy: 0.9376\n",
      "Epoch 140/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1498 - accuracy: 0.9455 - val_loss: 0.1701 - val_accuracy: 0.9377\n",
      "Epoch 141/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1497 - accuracy: 0.9455 - val_loss: 0.1708 - val_accuracy: 0.9374\n",
      "Epoch 142/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1495 - accuracy: 0.9456 - val_loss: 0.1703 - val_accuracy: 0.9379\n",
      "Epoch 143/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1493 - accuracy: 0.9458 - val_loss: 0.1708 - val_accuracy: 0.9375\n",
      "Epoch 144/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1490 - accuracy: 0.9457 - val_loss: 0.1699 - val_accuracy: 0.9374\n",
      "Epoch 145/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1490 - accuracy: 0.9460 - val_loss: 0.1698 - val_accuracy: 0.9383\n",
      "Epoch 146/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1487 - accuracy: 0.9459 - val_loss: 0.1700 - val_accuracy: 0.9378\n",
      "Epoch 147/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1485 - accuracy: 0.9458 - val_loss: 0.1702 - val_accuracy: 0.9378\n",
      "Epoch 148/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1484 - accuracy: 0.9462 - val_loss: 0.1696 - val_accuracy: 0.9377\n",
      "Epoch 149/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1483 - accuracy: 0.9460 - val_loss: 0.1697 - val_accuracy: 0.9377\n",
      "Epoch 150/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1480 - accuracy: 0.9459 - val_loss: 0.1692 - val_accuracy: 0.9379\n",
      "Epoch 151/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1478 - accuracy: 0.9462 - val_loss: 0.1688 - val_accuracy: 0.9379\n",
      "Epoch 152/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1477 - accuracy: 0.9462 - val_loss: 0.1692 - val_accuracy: 0.9382\n",
      "Epoch 153/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1475 - accuracy: 0.9462 - val_loss: 0.1689 - val_accuracy: 0.9384\n",
      "Epoch 154/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1474 - accuracy: 0.9463 - val_loss: 0.1689 - val_accuracy: 0.9383\n",
      "Epoch 155/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1472 - accuracy: 0.9464 - val_loss: 0.1684 - val_accuracy: 0.9382\n",
      "Epoch 156/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1471 - accuracy: 0.9464 - val_loss: 0.1680 - val_accuracy: 0.9384\n",
      "Epoch 157/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1468 - accuracy: 0.9466 - val_loss: 0.1680 - val_accuracy: 0.9383\n",
      "Epoch 158/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1467 - accuracy: 0.9466 - val_loss: 0.1678 - val_accuracy: 0.9388\n",
      "Epoch 159/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1466 - accuracy: 0.9467 - val_loss: 0.1677 - val_accuracy: 0.9382\n",
      "Epoch 160/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1463 - accuracy: 0.9466 - val_loss: 0.1682 - val_accuracy: 0.9384\n",
      "Epoch 161/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1461 - accuracy: 0.9466 - val_loss: 0.1679 - val_accuracy: 0.9385\n",
      "Epoch 162/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1461 - accuracy: 0.9467 - val_loss: 0.1677 - val_accuracy: 0.9385\n",
      "Epoch 163/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1459 - accuracy: 0.9469 - val_loss: 0.1676 - val_accuracy: 0.9384\n",
      "Epoch 164/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1457 - accuracy: 0.9466 - val_loss: 0.1676 - val_accuracy: 0.9383\n",
      "Epoch 165/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1455 - accuracy: 0.9468 - val_loss: 0.1670 - val_accuracy: 0.9386\n",
      "Epoch 166/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1453 - accuracy: 0.9470 - val_loss: 0.1675 - val_accuracy: 0.9385\n",
      "Epoch 167/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1452 - accuracy: 0.9469 - val_loss: 0.1669 - val_accuracy: 0.9389\n",
      "Epoch 168/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1450 - accuracy: 0.9470 - val_loss: 0.1672 - val_accuracy: 0.9390\n",
      "Epoch 169/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1448 - accuracy: 0.9470 - val_loss: 0.1664 - val_accuracy: 0.9389\n",
      "Epoch 170/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1446 - accuracy: 0.9473 - val_loss: 0.1665 - val_accuracy: 0.9385\n",
      "Epoch 171/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1445 - accuracy: 0.9473 - val_loss: 0.1662 - val_accuracy: 0.9387\n",
      "Epoch 172/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1443 - accuracy: 0.9473 - val_loss: 0.1663 - val_accuracy: 0.9391\n",
      "Epoch 173/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1441 - accuracy: 0.9472 - val_loss: 0.1666 - val_accuracy: 0.9389\n",
      "Epoch 174/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1440 - accuracy: 0.9473 - val_loss: 0.1660 - val_accuracy: 0.9392\n",
      "Epoch 175/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1438 - accuracy: 0.9475 - val_loss: 0.1666 - val_accuracy: 0.9389\n",
      "Epoch 176/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1437 - accuracy: 0.9474 - val_loss: 0.1659 - val_accuracy: 0.9389\n",
      "Epoch 177/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1435 - accuracy: 0.9474 - val_loss: 0.1660 - val_accuracy: 0.9389\n",
      "Epoch 178/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1433 - accuracy: 0.9474 - val_loss: 0.1658 - val_accuracy: 0.9388\n",
      "Epoch 179/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1431 - accuracy: 0.9474 - val_loss: 0.1655 - val_accuracy: 0.9392\n",
      "Epoch 180/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1430 - accuracy: 0.9475 - val_loss: 0.1655 - val_accuracy: 0.9390\n",
      "Epoch 181/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1428 - accuracy: 0.9477 - val_loss: 0.1652 - val_accuracy: 0.9389\n",
      "Epoch 182/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1427 - accuracy: 0.9476 - val_loss: 0.1653 - val_accuracy: 0.9388\n",
      "Epoch 183/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1425 - accuracy: 0.9477 - val_loss: 0.1649 - val_accuracy: 0.9391\n",
      "Epoch 184/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1423 - accuracy: 0.9477 - val_loss: 0.1647 - val_accuracy: 0.9392\n",
      "Epoch 185/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1421 - accuracy: 0.9479 - val_loss: 0.1649 - val_accuracy: 0.9396\n",
      "Epoch 186/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1420 - accuracy: 0.9480 - val_loss: 0.1650 - val_accuracy: 0.9392\n",
      "Epoch 187/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1417 - accuracy: 0.9480 - val_loss: 0.1646 - val_accuracy: 0.9393\n",
      "Epoch 188/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1416 - accuracy: 0.9480 - val_loss: 0.1645 - val_accuracy: 0.9389\n",
      "Epoch 189/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1415 - accuracy: 0.9482 - val_loss: 0.1646 - val_accuracy: 0.9390\n",
      "Epoch 190/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1413 - accuracy: 0.9481 - val_loss: 0.1643 - val_accuracy: 0.9393\n",
      "Epoch 191/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1411 - accuracy: 0.9481 - val_loss: 0.1645 - val_accuracy: 0.9391\n",
      "Epoch 192/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1410 - accuracy: 0.9484 - val_loss: 0.1641 - val_accuracy: 0.9394\n",
      "Epoch 193/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1408 - accuracy: 0.9480 - val_loss: 0.1635 - val_accuracy: 0.9398\n",
      "Epoch 194/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1406 - accuracy: 0.9484 - val_loss: 0.1639 - val_accuracy: 0.9393\n",
      "Epoch 195/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1406 - accuracy: 0.9483 - val_loss: 0.1638 - val_accuracy: 0.9398\n",
      "Epoch 196/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1404 - accuracy: 0.9484 - val_loss: 0.1631 - val_accuracy: 0.9392\n",
      "Epoch 197/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1401 - accuracy: 0.9483 - val_loss: 0.1631 - val_accuracy: 0.9402\n",
      "Epoch 198/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1400 - accuracy: 0.9485 - val_loss: 0.1637 - val_accuracy: 0.9395\n",
      "Epoch 199/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1398 - accuracy: 0.9485 - val_loss: 0.1629 - val_accuracy: 0.9393\n",
      "Epoch 200/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1397 - accuracy: 0.9485 - val_loss: 0.1630 - val_accuracy: 0.9395\n",
      "Epoch 201/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1395 - accuracy: 0.9486 - val_loss: 0.1633 - val_accuracy: 0.9400\n",
      "Epoch 202/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1394 - accuracy: 0.9484 - val_loss: 0.1628 - val_accuracy: 0.9404\n",
      "Epoch 203/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1392 - accuracy: 0.9487 - val_loss: 0.1632 - val_accuracy: 0.9397\n",
      "Epoch 204/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1390 - accuracy: 0.9488 - val_loss: 0.1626 - val_accuracy: 0.9399\n",
      "Epoch 205/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1389 - accuracy: 0.9488 - val_loss: 0.1626 - val_accuracy: 0.9400\n",
      "Epoch 206/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1387 - accuracy: 0.9489 - val_loss: 0.1626 - val_accuracy: 0.9398\n",
      "Epoch 207/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1386 - accuracy: 0.9488 - val_loss: 0.1620 - val_accuracy: 0.9399\n",
      "Epoch 208/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1384 - accuracy: 0.9489 - val_loss: 0.1625 - val_accuracy: 0.9397\n",
      "Epoch 209/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1382 - accuracy: 0.9490 - val_loss: 0.1623 - val_accuracy: 0.9401\n",
      "Epoch 210/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1381 - accuracy: 0.9490 - val_loss: 0.1619 - val_accuracy: 0.9398\n",
      "Epoch 211/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1379 - accuracy: 0.9491 - val_loss: 0.1620 - val_accuracy: 0.9404\n",
      "Epoch 212/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1378 - accuracy: 0.9489 - val_loss: 0.1621 - val_accuracy: 0.9401\n",
      "Epoch 213/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1377 - accuracy: 0.9491 - val_loss: 0.1617 - val_accuracy: 0.9402\n",
      "Epoch 214/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1376 - accuracy: 0.9491 - val_loss: 0.1618 - val_accuracy: 0.9402\n",
      "Epoch 215/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1374 - accuracy: 0.9492 - val_loss: 0.1616 - val_accuracy: 0.9400\n",
      "Epoch 216/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1372 - accuracy: 0.9492 - val_loss: 0.1612 - val_accuracy: 0.9399\n",
      "Epoch 217/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1370 - accuracy: 0.9494 - val_loss: 0.1611 - val_accuracy: 0.9405\n",
      "Epoch 218/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1369 - accuracy: 0.9495 - val_loss: 0.1607 - val_accuracy: 0.9400\n",
      "Epoch 219/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1368 - accuracy: 0.9492 - val_loss: 0.1614 - val_accuracy: 0.9400\n",
      "Epoch 220/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1366 - accuracy: 0.9494 - val_loss: 0.1610 - val_accuracy: 0.9407\n",
      "Epoch 221/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1365 - accuracy: 0.9492 - val_loss: 0.1611 - val_accuracy: 0.9404\n",
      "Epoch 222/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1363 - accuracy: 0.9493 - val_loss: 0.1609 - val_accuracy: 0.9407\n",
      "Epoch 223/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1362 - accuracy: 0.9496 - val_loss: 0.1608 - val_accuracy: 0.9406\n",
      "Epoch 224/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1361 - accuracy: 0.9496 - val_loss: 0.1612 - val_accuracy: 0.9404\n",
      "Epoch 225/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1359 - accuracy: 0.9495 - val_loss: 0.1605 - val_accuracy: 0.9406\n",
      "Epoch 226/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1358 - accuracy: 0.9497 - val_loss: 0.1604 - val_accuracy: 0.9404\n",
      "Epoch 227/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1357 - accuracy: 0.9495 - val_loss: 0.1606 - val_accuracy: 0.9404\n",
      "Epoch 228/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1355 - accuracy: 0.9496 - val_loss: 0.1605 - val_accuracy: 0.9402\n",
      "Epoch 229/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1353 - accuracy: 0.9497 - val_loss: 0.1603 - val_accuracy: 0.9404\n",
      "Epoch 230/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1353 - accuracy: 0.9495 - val_loss: 0.1603 - val_accuracy: 0.9405\n",
      "Epoch 231/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1351 - accuracy: 0.9497 - val_loss: 0.1601 - val_accuracy: 0.9400\n",
      "Epoch 232/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1350 - accuracy: 0.9496 - val_loss: 0.1598 - val_accuracy: 0.9410\n",
      "Epoch 233/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1348 - accuracy: 0.9499 - val_loss: 0.1602 - val_accuracy: 0.9411\n",
      "Epoch 234/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1347 - accuracy: 0.9497 - val_loss: 0.1598 - val_accuracy: 0.9409\n",
      "Epoch 235/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1345 - accuracy: 0.9500 - val_loss: 0.1601 - val_accuracy: 0.9401\n",
      "Epoch 236/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1344 - accuracy: 0.9501 - val_loss: 0.1598 - val_accuracy: 0.9405\n",
      "Epoch 237/800\n",
      "6000/6000 [==============================] - 1s 92us/step - loss: 0.1343 - accuracy: 0.9500 - val_loss: 0.1602 - val_accuracy: 0.9408\n",
      "Epoch 238/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1341 - accuracy: 0.9501 - val_loss: 0.1589 - val_accuracy: 0.9407\n",
      "Epoch 239/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1340 - accuracy: 0.9501 - val_loss: 0.1595 - val_accuracy: 0.9408\n",
      "Epoch 240/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1339 - accuracy: 0.9502 - val_loss: 0.1590 - val_accuracy: 0.9409\n",
      "Epoch 241/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1338 - accuracy: 0.9502 - val_loss: 0.1598 - val_accuracy: 0.9407\n",
      "Epoch 242/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1337 - accuracy: 0.9501 - val_loss: 0.1592 - val_accuracy: 0.9408\n",
      "Epoch 243/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1336 - accuracy: 0.9502 - val_loss: 0.1587 - val_accuracy: 0.9412\n",
      "Epoch 244/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1335 - accuracy: 0.9501 - val_loss: 0.1593 - val_accuracy: 0.9408\n",
      "Epoch 245/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1333 - accuracy: 0.9504 - val_loss: 0.1588 - val_accuracy: 0.9412\n",
      "Epoch 246/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1332 - accuracy: 0.9501 - val_loss: 0.1592 - val_accuracy: 0.9407\n",
      "Epoch 247/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1331 - accuracy: 0.9504 - val_loss: 0.1590 - val_accuracy: 0.9407\n",
      "Epoch 248/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1329 - accuracy: 0.9506 - val_loss: 0.1591 - val_accuracy: 0.9411\n",
      "Epoch 249/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1328 - accuracy: 0.9503 - val_loss: 0.1593 - val_accuracy: 0.9406\n",
      "Epoch 250/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1327 - accuracy: 0.9504 - val_loss: 0.1588 - val_accuracy: 0.9412\n",
      "Epoch 251/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1326 - accuracy: 0.9504 - val_loss: 0.1591 - val_accuracy: 0.9410\n",
      "Epoch 252/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1325 - accuracy: 0.9506 - val_loss: 0.1590 - val_accuracy: 0.9413\n",
      "Epoch 253/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1324 - accuracy: 0.9507 - val_loss: 0.1587 - val_accuracy: 0.9410\n",
      "Epoch 254/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1323 - accuracy: 0.9505 - val_loss: 0.1580 - val_accuracy: 0.9412\n",
      "Epoch 255/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1321 - accuracy: 0.9507 - val_loss: 0.1585 - val_accuracy: 0.9413\n",
      "Epoch 256/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1319 - accuracy: 0.9505 - val_loss: 0.1585 - val_accuracy: 0.9411\n",
      "Epoch 257/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1319 - accuracy: 0.9505 - val_loss: 0.1587 - val_accuracy: 0.9409\n",
      "Epoch 258/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1318 - accuracy: 0.9506 - val_loss: 0.1584 - val_accuracy: 0.9414\n",
      "Epoch 259/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1317 - accuracy: 0.9506 - val_loss: 0.1586 - val_accuracy: 0.9413\n",
      "Epoch 260/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1316 - accuracy: 0.9508 - val_loss: 0.1585 - val_accuracy: 0.9414\n",
      "Epoch 261/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1316 - accuracy: 0.9506 - val_loss: 0.1580 - val_accuracy: 0.9411\n",
      "Epoch 262/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1314 - accuracy: 0.9508 - val_loss: 0.1581 - val_accuracy: 0.9410\n",
      "Epoch 263/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1312 - accuracy: 0.9507 - val_loss: 0.1588 - val_accuracy: 0.9404\n",
      "Epoch 264/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1311 - accuracy: 0.9508 - val_loss: 0.1579 - val_accuracy: 0.9416\n",
      "Epoch 265/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1311 - accuracy: 0.9509 - val_loss: 0.1575 - val_accuracy: 0.9412\n",
      "Epoch 266/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1309 - accuracy: 0.9508 - val_loss: 0.1578 - val_accuracy: 0.9414\n",
      "Epoch 267/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1308 - accuracy: 0.9510 - val_loss: 0.1581 - val_accuracy: 0.9413\n",
      "Epoch 268/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1307 - accuracy: 0.9511 - val_loss: 0.1574 - val_accuracy: 0.9412\n",
      "Epoch 269/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1306 - accuracy: 0.9509 - val_loss: 0.1574 - val_accuracy: 0.9409\n",
      "Epoch 270/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1305 - accuracy: 0.9512 - val_loss: 0.1577 - val_accuracy: 0.9410\n",
      "Epoch 271/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1304 - accuracy: 0.9510 - val_loss: 0.1573 - val_accuracy: 0.9418\n",
      "Epoch 272/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1302 - accuracy: 0.9512 - val_loss: 0.1576 - val_accuracy: 0.9415\n",
      "Epoch 273/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1302 - accuracy: 0.9512 - val_loss: 0.1572 - val_accuracy: 0.9414\n",
      "Epoch 274/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1301 - accuracy: 0.9512 - val_loss: 0.1578 - val_accuracy: 0.9412\n",
      "Epoch 275/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1299 - accuracy: 0.9512 - val_loss: 0.1573 - val_accuracy: 0.9412\n",
      "Epoch 276/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1299 - accuracy: 0.9512 - val_loss: 0.1574 - val_accuracy: 0.9416\n",
      "Epoch 277/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1297 - accuracy: 0.9510 - val_loss: 0.1569 - val_accuracy: 0.9413\n",
      "Epoch 278/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1297 - accuracy: 0.9512 - val_loss: 0.1573 - val_accuracy: 0.9410\n",
      "Epoch 279/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1296 - accuracy: 0.9512 - val_loss: 0.1574 - val_accuracy: 0.9411\n",
      "Epoch 280/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1295 - accuracy: 0.9514 - val_loss: 0.1568 - val_accuracy: 0.9413\n",
      "Epoch 281/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1294 - accuracy: 0.9513 - val_loss: 0.1571 - val_accuracy: 0.9419\n",
      "Epoch 282/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1293 - accuracy: 0.9515 - val_loss: 0.1569 - val_accuracy: 0.9413\n",
      "Epoch 283/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1291 - accuracy: 0.9514 - val_loss: 0.1573 - val_accuracy: 0.9413\n",
      "Epoch 284/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1290 - accuracy: 0.9512 - val_loss: 0.1568 - val_accuracy: 0.9414\n",
      "Epoch 285/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1289 - accuracy: 0.9514 - val_loss: 0.1567 - val_accuracy: 0.9416\n",
      "Epoch 286/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1288 - accuracy: 0.9515 - val_loss: 0.1570 - val_accuracy: 0.9415\n",
      "Epoch 287/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1288 - accuracy: 0.9515 - val_loss: 0.1569 - val_accuracy: 0.9413\n",
      "Epoch 288/800\n",
      "6000/6000 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.95 - 0s 74us/step - loss: 0.1286 - accuracy: 0.9515 - val_loss: 0.1565 - val_accuracy: 0.9413\n",
      "Epoch 289/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1285 - accuracy: 0.9515 - val_loss: 0.1569 - val_accuracy: 0.9414\n",
      "Epoch 290/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1285 - accuracy: 0.9517 - val_loss: 0.1568 - val_accuracy: 0.9416\n",
      "Epoch 291/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1284 - accuracy: 0.9516 - val_loss: 0.1567 - val_accuracy: 0.9415\n",
      "Epoch 292/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1282 - accuracy: 0.9515 - val_loss: 0.1564 - val_accuracy: 0.9418\n",
      "Epoch 293/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1282 - accuracy: 0.9516 - val_loss: 0.1563 - val_accuracy: 0.9413\n",
      "Epoch 294/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1281 - accuracy: 0.9516 - val_loss: 0.1565 - val_accuracy: 0.9417\n",
      "Epoch 295/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1281 - accuracy: 0.9517 - val_loss: 0.1566 - val_accuracy: 0.9412\n",
      "Epoch 296/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1278 - accuracy: 0.9519 - val_loss: 0.1574 - val_accuracy: 0.9411\n",
      "Epoch 297/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1278 - accuracy: 0.9518 - val_loss: 0.1565 - val_accuracy: 0.9415\n",
      "Epoch 298/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1277 - accuracy: 0.9519 - val_loss: 0.1562 - val_accuracy: 0.9414\n",
      "Epoch 299/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1276 - accuracy: 0.9517 - val_loss: 0.1557 - val_accuracy: 0.9416\n",
      "Epoch 300/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1275 - accuracy: 0.9518 - val_loss: 0.1566 - val_accuracy: 0.9417\n",
      "Epoch 301/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1274 - accuracy: 0.9516 - val_loss: 0.1561 - val_accuracy: 0.9416\n",
      "Epoch 302/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1274 - accuracy: 0.9518 - val_loss: 0.1559 - val_accuracy: 0.9418\n",
      "Epoch 303/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1273 - accuracy: 0.9520 - val_loss: 0.1568 - val_accuracy: 0.9416\n",
      "Epoch 304/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1271 - accuracy: 0.9519 - val_loss: 0.1562 - val_accuracy: 0.9418\n",
      "Epoch 305/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1270 - accuracy: 0.9520 - val_loss: 0.1564 - val_accuracy: 0.9417\n",
      "Epoch 306/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1269 - accuracy: 0.9520 - val_loss: 0.1569 - val_accuracy: 0.9420\n",
      "Epoch 307/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1268 - accuracy: 0.9518 - val_loss: 0.1562 - val_accuracy: 0.9419\n",
      "Epoch 308/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1268 - accuracy: 0.9520 - val_loss: 0.1560 - val_accuracy: 0.9415\n",
      "Epoch 309/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1268 - accuracy: 0.9521 - val_loss: 0.1562 - val_accuracy: 0.9415\n",
      "Epoch 310/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1266 - accuracy: 0.9520 - val_loss: 0.1561 - val_accuracy: 0.9415\n",
      "Epoch 311/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1265 - accuracy: 0.9520 - val_loss: 0.1559 - val_accuracy: 0.9415\n",
      "Epoch 312/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1264 - accuracy: 0.9521 - val_loss: 0.1561 - val_accuracy: 0.9420\n",
      "Epoch 313/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1263 - accuracy: 0.9520 - val_loss: 0.1557 - val_accuracy: 0.9423\n",
      "Epoch 314/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1263 - accuracy: 0.9520 - val_loss: 0.1556 - val_accuracy: 0.9419\n",
      "Epoch 315/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1261 - accuracy: 0.9521 - val_loss: 0.1571 - val_accuracy: 0.9416\n",
      "Epoch 316/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1260 - accuracy: 0.9524 - val_loss: 0.1556 - val_accuracy: 0.9418\n",
      "Epoch 317/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1259 - accuracy: 0.9523 - val_loss: 0.1555 - val_accuracy: 0.9417\n",
      "Epoch 318/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1258 - accuracy: 0.9524 - val_loss: 0.1564 - val_accuracy: 0.9416\n",
      "Epoch 319/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1258 - accuracy: 0.9524 - val_loss: 0.1560 - val_accuracy: 0.9416\n",
      "Epoch 320/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1257 - accuracy: 0.9524 - val_loss: 0.1555 - val_accuracy: 0.9420\n",
      "Epoch 321/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1256 - accuracy: 0.9525 - val_loss: 0.1560 - val_accuracy: 0.9413\n",
      "Epoch 322/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1256 - accuracy: 0.9523 - val_loss: 0.1561 - val_accuracy: 0.9415\n",
      "Epoch 323/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1254 - accuracy: 0.9525 - val_loss: 0.1558 - val_accuracy: 0.9414\n",
      "Epoch 324/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1253 - accuracy: 0.9527 - val_loss: 0.1558 - val_accuracy: 0.9418\n",
      "Epoch 325/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1253 - accuracy: 0.9524 - val_loss: 0.1556 - val_accuracy: 0.9417\n",
      "Epoch 326/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1252 - accuracy: 0.9524 - val_loss: 0.1558 - val_accuracy: 0.9418\n",
      "Epoch 327/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1250 - accuracy: 0.9525 - val_loss: 0.1560 - val_accuracy: 0.9419\n",
      "Epoch 328/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1250 - accuracy: 0.9523 - val_loss: 0.1556 - val_accuracy: 0.9418\n",
      "Epoch 329/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1249 - accuracy: 0.9526 - val_loss: 0.1556 - val_accuracy: 0.9414\n",
      "Epoch 330/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1248 - accuracy: 0.9526 - val_loss: 0.1552 - val_accuracy: 0.9419\n",
      "Epoch 331/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1247 - accuracy: 0.9527 - val_loss: 0.1554 - val_accuracy: 0.9416\n",
      "Epoch 332/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1246 - accuracy: 0.9525 - val_loss: 0.1557 - val_accuracy: 0.9417\n",
      "Epoch 333/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1245 - accuracy: 0.9527 - val_loss: 0.1551 - val_accuracy: 0.9416\n",
      "Epoch 334/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1245 - accuracy: 0.9527 - val_loss: 0.1558 - val_accuracy: 0.9419\n",
      "Epoch 335/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1244 - accuracy: 0.9527 - val_loss: 0.1556 - val_accuracy: 0.9418\n",
      "Epoch 336/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1243 - accuracy: 0.9529 - val_loss: 0.1553 - val_accuracy: 0.9420\n",
      "Epoch 337/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1242 - accuracy: 0.9526 - val_loss: 0.1557 - val_accuracy: 0.9416\n",
      "Epoch 338/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1242 - accuracy: 0.9529 - val_loss: 0.1552 - val_accuracy: 0.9419\n",
      "Epoch 339/800\n",
      "6000/6000 [==============================] - 1s 101us/step - loss: 0.1242 - accuracy: 0.9528 - val_loss: 0.1557 - val_accuracy: 0.9419\n",
      "Epoch 340/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1240 - accuracy: 0.9529 - val_loss: 0.1558 - val_accuracy: 0.9416\n",
      "Epoch 341/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1239 - accuracy: 0.9527 - val_loss: 0.1557 - val_accuracy: 0.9418\n",
      "Epoch 342/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1238 - accuracy: 0.9529 - val_loss: 0.1563 - val_accuracy: 0.9413\n",
      "Epoch 343/800\n",
      "6000/6000 [==============================] - 1s 94us/step - loss: 0.1237 - accuracy: 0.9529 - val_loss: 0.1552 - val_accuracy: 0.9420\n",
      "Epoch 344/800\n",
      "6000/6000 [==============================] - 1s 100us/step - loss: 0.1237 - accuracy: 0.9528 - val_loss: 0.1549 - val_accuracy: 0.9419\n",
      "Epoch 345/800\n",
      "6000/6000 [==============================] - 1s 91us/step - loss: 0.1236 - accuracy: 0.9530 - val_loss: 0.1554 - val_accuracy: 0.9417\n",
      "Epoch 346/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.1234 - accuracy: 0.9529 - val_loss: 0.1555 - val_accuracy: 0.9423\n",
      "Epoch 347/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1235 - accuracy: 0.9527 - val_loss: 0.1551 - val_accuracy: 0.9416\n",
      "Epoch 348/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1234 - accuracy: 0.9531 - val_loss: 0.1561 - val_accuracy: 0.9415\n",
      "Epoch 349/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1233 - accuracy: 0.9529 - val_loss: 0.1552 - val_accuracy: 0.9420\n",
      "Epoch 350/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1231 - accuracy: 0.9529 - val_loss: 0.1550 - val_accuracy: 0.9417\n",
      "Epoch 351/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1232 - accuracy: 0.9531 - val_loss: 0.1551 - val_accuracy: 0.9417\n",
      "Epoch 352/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1231 - accuracy: 0.9531 - val_loss: 0.1549 - val_accuracy: 0.9419\n",
      "Epoch 353/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1230 - accuracy: 0.9532 - val_loss: 0.1554 - val_accuracy: 0.9419\n",
      "Epoch 354/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1229 - accuracy: 0.9532 - val_loss: 0.1552 - val_accuracy: 0.9417\n",
      "Epoch 355/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1228 - accuracy: 0.9532 - val_loss: 0.1553 - val_accuracy: 0.9416\n",
      "Epoch 356/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1226 - accuracy: 0.9530 - val_loss: 0.1561 - val_accuracy: 0.9414\n",
      "Epoch 357/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1227 - accuracy: 0.9532 - val_loss: 0.1551 - val_accuracy: 0.9415\n",
      "Epoch 358/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1226 - accuracy: 0.9529 - val_loss: 0.1551 - val_accuracy: 0.9413\n",
      "Epoch 359/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1224 - accuracy: 0.9532 - val_loss: 0.1553 - val_accuracy: 0.9414\n",
      "Epoch 360/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1224 - accuracy: 0.9533 - val_loss: 0.1555 - val_accuracy: 0.9420\n",
      "Epoch 361/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1223 - accuracy: 0.9531 - val_loss: 0.1558 - val_accuracy: 0.9413\n",
      "Epoch 362/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1222 - accuracy: 0.9534 - val_loss: 0.1550 - val_accuracy: 0.9417\n",
      "Epoch 363/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1221 - accuracy: 0.9532 - val_loss: 0.1554 - val_accuracy: 0.9421\n",
      "Epoch 364/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1220 - accuracy: 0.9535 - val_loss: 0.1548 - val_accuracy: 0.9418\n",
      "Epoch 365/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1220 - accuracy: 0.9532 - val_loss: 0.1549 - val_accuracy: 0.9421\n",
      "Epoch 366/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1219 - accuracy: 0.9534 - val_loss: 0.1547 - val_accuracy: 0.9419\n",
      "Epoch 367/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1219 - accuracy: 0.9533 - val_loss: 0.1548 - val_accuracy: 0.9415\n",
      "Epoch 368/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1217 - accuracy: 0.9534 - val_loss: 0.1553 - val_accuracy: 0.9417\n",
      "Epoch 369/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1217 - accuracy: 0.9535 - val_loss: 0.1559 - val_accuracy: 0.9418\n",
      "Epoch 370/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1217 - accuracy: 0.9537 - val_loss: 0.1555 - val_accuracy: 0.9416\n",
      "Epoch 371/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1215 - accuracy: 0.9534 - val_loss: 0.1554 - val_accuracy: 0.9419\n",
      "Epoch 372/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1215 - accuracy: 0.9535 - val_loss: 0.1555 - val_accuracy: 0.9415\n",
      "Epoch 373/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1214 - accuracy: 0.9537 - val_loss: 0.1548 - val_accuracy: 0.9417\n",
      "Epoch 374/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1212 - accuracy: 0.9534 - val_loss: 0.1548 - val_accuracy: 0.9420\n",
      "Epoch 375/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1212 - accuracy: 0.9536 - val_loss: 0.1558 - val_accuracy: 0.9411\n",
      "Epoch 376/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1211 - accuracy: 0.9534 - val_loss: 0.1553 - val_accuracy: 0.9420\n",
      "Epoch 377/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1211 - accuracy: 0.9536 - val_loss: 0.1553 - val_accuracy: 0.9414\n",
      "Epoch 378/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1210 - accuracy: 0.9536 - val_loss: 0.1551 - val_accuracy: 0.9419\n",
      "Epoch 379/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1210 - accuracy: 0.9535 - val_loss: 0.1548 - val_accuracy: 0.9422\n",
      "Epoch 380/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1208 - accuracy: 0.9536 - val_loss: 0.1554 - val_accuracy: 0.9413\n",
      "Epoch 381/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1208 - accuracy: 0.9539 - val_loss: 0.1551 - val_accuracy: 0.9422\n",
      "Epoch 382/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1207 - accuracy: 0.9536 - val_loss: 0.1555 - val_accuracy: 0.9417\n",
      "Epoch 383/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1206 - accuracy: 0.9536 - val_loss: 0.1551 - val_accuracy: 0.9417\n",
      "Epoch 384/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1205 - accuracy: 0.9538 - val_loss: 0.1551 - val_accuracy: 0.9422\n",
      "Epoch 385/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1205 - accuracy: 0.9538 - val_loss: 0.1552 - val_accuracy: 0.9419\n",
      "Epoch 386/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1204 - accuracy: 0.9539 - val_loss: 0.1547 - val_accuracy: 0.9415\n",
      "Epoch 387/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1203 - accuracy: 0.9538 - val_loss: 0.1546 - val_accuracy: 0.9414\n",
      "Epoch 388/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1203 - accuracy: 0.9537 - val_loss: 0.1552 - val_accuracy: 0.9411\n",
      "Epoch 389/800\n",
      "6000/6000 [==============================] - 1s 104us/step - loss: 0.1201 - accuracy: 0.9539 - val_loss: 0.1556 - val_accuracy: 0.9414\n",
      "Epoch 390/800\n",
      "6000/6000 [==============================] - 1s 102us/step - loss: 0.1201 - accuracy: 0.9538 - val_loss: 0.1555 - val_accuracy: 0.9420\n",
      "Epoch 391/800\n",
      "6000/6000 [==============================] - 1s 101us/step - loss: 0.1199 - accuracy: 0.9542 - val_loss: 0.1552 - val_accuracy: 0.9418\n",
      "Epoch 392/800\n",
      "6000/6000 [==============================] - 1s 102us/step - loss: 0.1200 - accuracy: 0.9539 - val_loss: 0.1548 - val_accuracy: 0.9420\n",
      "Epoch 393/800\n",
      "6000/6000 [==============================] - 1s 126us/step - loss: 0.1199 - accuracy: 0.9538 - val_loss: 0.1554 - val_accuracy: 0.9416\n",
      "Epoch 394/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.1198 - accuracy: 0.9540 - val_loss: 0.1552 - val_accuracy: 0.9419\n",
      "Epoch 395/800\n",
      "6000/6000 [==============================] - 1s 101us/step - loss: 0.1197 - accuracy: 0.9540 - val_loss: 0.1552 - val_accuracy: 0.9417\n",
      "Epoch 396/800\n",
      "6000/6000 [==============================] - 1s 95us/step - loss: 0.1197 - accuracy: 0.9539 - val_loss: 0.1551 - val_accuracy: 0.9417\n",
      "Epoch 397/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.1196 - accuracy: 0.9538 - val_loss: 0.1548 - val_accuracy: 0.9415\n",
      "Epoch 398/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1195 - accuracy: 0.9539 - val_loss: 0.1551 - val_accuracy: 0.9418\n",
      "Epoch 399/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.1195 - accuracy: 0.9542 - val_loss: 0.1546 - val_accuracy: 0.9420\n",
      "Epoch 400/800\n",
      "6000/6000 [==============================] - 1s 92us/step - loss: 0.1193 - accuracy: 0.9540 - val_loss: 0.1548 - val_accuracy: 0.9418\n",
      "Epoch 401/800\n",
      "6000/6000 [==============================] - 1s 97us/step - loss: 0.1193 - accuracy: 0.9542 - val_loss: 0.1545 - val_accuracy: 0.9421\n",
      "Epoch 402/800\n",
      "6000/6000 [==============================] - 1s 98us/step - loss: 0.1192 - accuracy: 0.9541 - val_loss: 0.1553 - val_accuracy: 0.9412\n",
      "Epoch 403/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1192 - accuracy: 0.9539 - val_loss: 0.1549 - val_accuracy: 0.9417\n",
      "Epoch 404/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1190 - accuracy: 0.9543 - val_loss: 0.1548 - val_accuracy: 0.9419\n",
      "Epoch 405/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1190 - accuracy: 0.9541 - val_loss: 0.1548 - val_accuracy: 0.9415\n",
      "Epoch 406/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1189 - accuracy: 0.9542 - val_loss: 0.1551 - val_accuracy: 0.9416\n",
      "Epoch 407/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1189 - accuracy: 0.9543 - val_loss: 0.1549 - val_accuracy: 0.9417\n",
      "Epoch 408/800\n",
      "6000/6000 [==============================] - 1s 87us/step - loss: 0.1188 - accuracy: 0.9544 - val_loss: 0.1549 - val_accuracy: 0.9421\n",
      "Epoch 409/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1188 - accuracy: 0.9542 - val_loss: 0.1552 - val_accuracy: 0.9418\n",
      "Epoch 410/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1186 - accuracy: 0.9545 - val_loss: 0.1560 - val_accuracy: 0.9411\n",
      "Epoch 411/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1185 - accuracy: 0.9544 - val_loss: 0.1555 - val_accuracy: 0.9413\n",
      "Epoch 412/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1185 - accuracy: 0.9544 - val_loss: 0.1552 - val_accuracy: 0.9413\n",
      "Epoch 413/800\n",
      "6000/6000 [==============================] - 1s 87us/step - loss: 0.1185 - accuracy: 0.9542 - val_loss: 0.1554 - val_accuracy: 0.9414\n",
      "Epoch 414/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1184 - accuracy: 0.9544 - val_loss: 0.1552 - val_accuracy: 0.9418\n",
      "Epoch 415/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1182 - accuracy: 0.9542 - val_loss: 0.1550 - val_accuracy: 0.9414\n",
      "Epoch 416/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1183 - accuracy: 0.9543 - val_loss: 0.1555 - val_accuracy: 0.9420\n",
      "Epoch 417/800\n",
      "6000/6000 [==============================] - 1s 87us/step - loss: 0.1181 - accuracy: 0.9547 - val_loss: 0.1559 - val_accuracy: 0.9418\n",
      "Epoch 418/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1180 - accuracy: 0.9545 - val_loss: 0.1552 - val_accuracy: 0.9418\n",
      "Epoch 419/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1180 - accuracy: 0.9544 - val_loss: 0.1553 - val_accuracy: 0.9415\n",
      "Epoch 420/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1180 - accuracy: 0.9543 - val_loss: 0.1546 - val_accuracy: 0.9419\n",
      "Epoch 421/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.1178 - accuracy: 0.9546 - val_loss: 0.1543 - val_accuracy: 0.9419\n",
      "Epoch 422/800\n",
      "6000/6000 [==============================] - 1s 92us/step - loss: 0.1177 - accuracy: 0.9546 - val_loss: 0.1548 - val_accuracy: 0.9420\n",
      "Epoch 423/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.1177 - accuracy: 0.9546 - val_loss: 0.1557 - val_accuracy: 0.9418\n",
      "Epoch 424/800\n",
      "6000/6000 [==============================] - 1s 96us/step - loss: 0.1176 - accuracy: 0.9545 - val_loss: 0.1548 - val_accuracy: 0.9416\n",
      "Epoch 425/800\n",
      "6000/6000 [==============================] - 1s 99us/step - loss: 0.1175 - accuracy: 0.9546 - val_loss: 0.1544 - val_accuracy: 0.9414\n",
      "Epoch 426/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.1175 - accuracy: 0.9547 - val_loss: 0.1550 - val_accuracy: 0.9418\n",
      "Epoch 427/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.1174 - accuracy: 0.9547 - val_loss: 0.1548 - val_accuracy: 0.9420\n",
      "Epoch 428/800\n",
      "6000/6000 [==============================] - 1s 94us/step - loss: 0.1174 - accuracy: 0.9548 - val_loss: 0.1548 - val_accuracy: 0.9419\n",
      "Epoch 429/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1173 - accuracy: 0.9548 - val_loss: 0.1553 - val_accuracy: 0.9414\n",
      "Epoch 430/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.1172 - accuracy: 0.9546 - val_loss: 0.1552 - val_accuracy: 0.9421\n",
      "Epoch 431/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1171 - accuracy: 0.9549 - val_loss: 0.1551 - val_accuracy: 0.9419\n",
      "Epoch 432/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.1171 - accuracy: 0.9549 - val_loss: 0.1553 - val_accuracy: 0.9420\n",
      "Epoch 433/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1170 - accuracy: 0.9549 - val_loss: 0.1552 - val_accuracy: 0.9416\n",
      "Epoch 434/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1169 - accuracy: 0.9552 - val_loss: 0.1548 - val_accuracy: 0.9420\n",
      "Epoch 435/800\n",
      "6000/6000 [==============================] - 1s 92us/step - loss: 0.1168 - accuracy: 0.9549 - val_loss: 0.1552 - val_accuracy: 0.9419\n",
      "Epoch 436/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1168 - accuracy: 0.9550 - val_loss: 0.1548 - val_accuracy: 0.9420\n",
      "Epoch 437/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1168 - accuracy: 0.9546 - val_loss: 0.1545 - val_accuracy: 0.9414\n",
      "Epoch 438/800\n",
      "6000/6000 [==============================] - 1s 94us/step - loss: 0.1166 - accuracy: 0.9549 - val_loss: 0.1549 - val_accuracy: 0.9418\n",
      "Epoch 439/800\n",
      "6000/6000 [==============================] - 1s 92us/step - loss: 0.1166 - accuracy: 0.9550 - val_loss: 0.1551 - val_accuracy: 0.9418\n",
      "Epoch 440/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1165 - accuracy: 0.9549 - val_loss: 0.1558 - val_accuracy: 0.9415\n",
      "Epoch 441/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1164 - accuracy: 0.9550 - val_loss: 0.1544 - val_accuracy: 0.9419\n",
      "Epoch 442/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1164 - accuracy: 0.9550 - val_loss: 0.1551 - val_accuracy: 0.9411\n",
      "Epoch 443/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1163 - accuracy: 0.9549 - val_loss: 0.1551 - val_accuracy: 0.9419\n",
      "Epoch 444/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1161 - accuracy: 0.9551 - val_loss: 0.1550 - val_accuracy: 0.9421\n",
      "Epoch 445/800\n",
      "6000/6000 [==============================] - 1s 91us/step - loss: 0.1162 - accuracy: 0.9552 - val_loss: 0.1552 - val_accuracy: 0.9417\n",
      "Epoch 446/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1160 - accuracy: 0.9551 - val_loss: 0.1557 - val_accuracy: 0.9414\n",
      "Epoch 447/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1160 - accuracy: 0.9552 - val_loss: 0.1552 - val_accuracy: 0.9418\n",
      "Epoch 448/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1160 - accuracy: 0.9552 - val_loss: 0.1560 - val_accuracy: 0.9413\n",
      "Epoch 449/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.1159 - accuracy: 0.9550 - val_loss: 0.1555 - val_accuracy: 0.9420\n",
      "Epoch 450/800\n",
      "6000/6000 [==============================] - 1s 94us/step - loss: 0.1158 - accuracy: 0.9552 - val_loss: 0.1551 - val_accuracy: 0.9416\n",
      "Epoch 451/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1158 - accuracy: 0.9551 - val_loss: 0.1559 - val_accuracy: 0.9416\n",
      "Epoch 452/800\n",
      "6000/6000 [==============================] - 1s 91us/step - loss: 0.1158 - accuracy: 0.9552 - val_loss: 0.1554 - val_accuracy: 0.9415\n",
      "Epoch 453/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1156 - accuracy: 0.9552 - val_loss: 0.1557 - val_accuracy: 0.9419\n",
      "Epoch 454/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1155 - accuracy: 0.9554 - val_loss: 0.1552 - val_accuracy: 0.9418\n",
      "Epoch 455/800\n",
      "6000/6000 [==============================] - 1s 91us/step - loss: 0.1156 - accuracy: 0.9551 - val_loss: 0.1550 - val_accuracy: 0.9422\n",
      "Epoch 456/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.1154 - accuracy: 0.9552 - val_loss: 0.1553 - val_accuracy: 0.9416\n",
      "Epoch 457/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1154 - accuracy: 0.9553 - val_loss: 0.1553 - val_accuracy: 0.9418\n",
      "Epoch 458/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1152 - accuracy: 0.9554 - val_loss: 0.1554 - val_accuracy: 0.9419\n",
      "Epoch 459/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1152 - accuracy: 0.9554 - val_loss: 0.1556 - val_accuracy: 0.9417\n",
      "Epoch 460/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1151 - accuracy: 0.9553 - val_loss: 0.1561 - val_accuracy: 0.9412\n",
      "Epoch 461/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1150 - accuracy: 0.9555 - val_loss: 0.1554 - val_accuracy: 0.9418\n",
      "Epoch 462/800\n",
      "6000/6000 [==============================] - 1s 91us/step - loss: 0.1150 - accuracy: 0.9555 - val_loss: 0.1558 - val_accuracy: 0.9420\n",
      "Epoch 463/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1149 - accuracy: 0.9555 - val_loss: 0.1551 - val_accuracy: 0.9413\n",
      "Epoch 464/800\n",
      "6000/6000 [==============================] - 1s 95us/step - loss: 0.1149 - accuracy: 0.9556 - val_loss: 0.1551 - val_accuracy: 0.9412\n",
      "Epoch 465/800\n",
      "6000/6000 [==============================] - 1s 91us/step - loss: 0.1148 - accuracy: 0.9556 - val_loss: 0.1557 - val_accuracy: 0.9419\n",
      "Epoch 466/800\n",
      "6000/6000 [==============================] - 1s 91us/step - loss: 0.1148 - accuracy: 0.9555 - val_loss: 0.1559 - val_accuracy: 0.9414\n",
      "Epoch 467/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1146 - accuracy: 0.9555 - val_loss: 0.1552 - val_accuracy: 0.9418\n",
      "Epoch 468/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1146 - accuracy: 0.9556 - val_loss: 0.1556 - val_accuracy: 0.9416\n",
      "Epoch 469/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1145 - accuracy: 0.9557 - val_loss: 0.1555 - val_accuracy: 0.9416\n",
      "Epoch 470/800\n",
      "6000/6000 [==============================] - 1s 87us/step - loss: 0.1144 - accuracy: 0.9556 - val_loss: 0.1556 - val_accuracy: 0.9420\n",
      "Epoch 471/800\n",
      "6000/6000 [==============================] - 1s 91us/step - loss: 0.1142 - accuracy: 0.9558 - val_loss: 0.1557 - val_accuracy: 0.9410\n",
      "Epoch 472/800\n",
      "6000/6000 [==============================] - 1s 91us/step - loss: 0.1143 - accuracy: 0.9558 - val_loss: 0.1562 - val_accuracy: 0.9409\n",
      "Epoch 473/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1143 - accuracy: 0.9557 - val_loss: 0.1553 - val_accuracy: 0.9414\n",
      "Epoch 474/800\n",
      "6000/6000 [==============================] - 1s 95us/step - loss: 0.1141 - accuracy: 0.9557 - val_loss: 0.1566 - val_accuracy: 0.9409\n",
      "Epoch 475/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.1140 - accuracy: 0.9558 - val_loss: 0.1570 - val_accuracy: 0.9410\n",
      "Epoch 476/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1140 - accuracy: 0.9558 - val_loss: 0.1555 - val_accuracy: 0.9415\n",
      "Epoch 477/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1139 - accuracy: 0.9559 - val_loss: 0.1558 - val_accuracy: 0.9419\n",
      "Epoch 478/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1139 - accuracy: 0.9558 - val_loss: 0.1553 - val_accuracy: 0.9414\n",
      "Epoch 479/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1138 - accuracy: 0.9558 - val_loss: 0.1552 - val_accuracy: 0.9420\n",
      "Epoch 480/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1138 - accuracy: 0.9559 - val_loss: 0.1552 - val_accuracy: 0.9421\n",
      "Epoch 481/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1136 - accuracy: 0.9558 - val_loss: 0.1555 - val_accuracy: 0.9421\n",
      "Epoch 482/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1135 - accuracy: 0.9559 - val_loss: 0.1561 - val_accuracy: 0.9415\n",
      "Epoch 483/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1135 - accuracy: 0.9559 - val_loss: 0.1557 - val_accuracy: 0.9415\n",
      "Epoch 484/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1135 - accuracy: 0.9557 - val_loss: 0.1554 - val_accuracy: 0.9413\n",
      "Epoch 485/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1135 - accuracy: 0.9560 - val_loss: 0.1556 - val_accuracy: 0.9419\n",
      "Epoch 486/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1132 - accuracy: 0.9561 - val_loss: 0.1560 - val_accuracy: 0.9420\n",
      "Epoch 487/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1132 - accuracy: 0.9561 - val_loss: 0.1555 - val_accuracy: 0.9411\n",
      "Epoch 488/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1132 - accuracy: 0.9561 - val_loss: 0.1560 - val_accuracy: 0.9415\n",
      "Epoch 489/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1132 - accuracy: 0.9562 - val_loss: 0.1562 - val_accuracy: 0.9409\n",
      "Epoch 490/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1131 - accuracy: 0.9558 - val_loss: 0.1560 - val_accuracy: 0.9415\n",
      "Epoch 491/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1130 - accuracy: 0.9561 - val_loss: 0.1559 - val_accuracy: 0.9415\n",
      "Epoch 492/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1129 - accuracy: 0.9561 - val_loss: 0.1565 - val_accuracy: 0.9414\n",
      "Epoch 493/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1129 - accuracy: 0.9562 - val_loss: 0.1557 - val_accuracy: 0.9419\n",
      "Epoch 494/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1128 - accuracy: 0.9561 - val_loss: 0.1556 - val_accuracy: 0.9416\n",
      "Epoch 495/800\n",
      "6000/6000 [==============================] - 1s 87us/step - loss: 0.1127 - accuracy: 0.9561 - val_loss: 0.1557 - val_accuracy: 0.9415\n",
      "Epoch 496/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1127 - accuracy: 0.9563 - val_loss: 0.1559 - val_accuracy: 0.9417\n",
      "Epoch 497/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1126 - accuracy: 0.9562 - val_loss: 0.1565 - val_accuracy: 0.9413\n",
      "Epoch 498/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1125 - accuracy: 0.9564 - val_loss: 0.1564 - val_accuracy: 0.9414\n",
      "Epoch 499/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1124 - accuracy: 0.9563 - val_loss: 0.1580 - val_accuracy: 0.9402\n",
      "Epoch 500/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1123 - accuracy: 0.9564 - val_loss: 0.1563 - val_accuracy: 0.9418\n",
      "Epoch 501/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1124 - accuracy: 0.9563 - val_loss: 0.1575 - val_accuracy: 0.9418\n",
      "Epoch 502/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1123 - accuracy: 0.9563 - val_loss: 0.1557 - val_accuracy: 0.9414\n",
      "Epoch 503/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1121 - accuracy: 0.9564 - val_loss: 0.1558 - val_accuracy: 0.9415\n",
      "Epoch 504/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1122 - accuracy: 0.9563 - val_loss: 0.1553 - val_accuracy: 0.9419\n",
      "Epoch 505/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1120 - accuracy: 0.9566 - val_loss: 0.1562 - val_accuracy: 0.9415\n",
      "Epoch 506/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1121 - accuracy: 0.9565 - val_loss: 0.1569 - val_accuracy: 0.9412\n",
      "Epoch 507/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1119 - accuracy: 0.9565 - val_loss: 0.1561 - val_accuracy: 0.9412\n",
      "Epoch 508/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1118 - accuracy: 0.9566 - val_loss: 0.1562 - val_accuracy: 0.9409\n",
      "Epoch 509/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1117 - accuracy: 0.9564 - val_loss: 0.1562 - val_accuracy: 0.9413\n",
      "Epoch 510/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1117 - accuracy: 0.9568 - val_loss: 0.1557 - val_accuracy: 0.9418\n",
      "Epoch 511/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1118 - accuracy: 0.9567 - val_loss: 0.1556 - val_accuracy: 0.9414\n",
      "Epoch 512/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1116 - accuracy: 0.9567 - val_loss: 0.1566 - val_accuracy: 0.9415\n",
      "Epoch 513/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1115 - accuracy: 0.9566 - val_loss: 0.1569 - val_accuracy: 0.9417\n",
      "Epoch 514/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1115 - accuracy: 0.9567 - val_loss: 0.1567 - val_accuracy: 0.9407\n",
      "Epoch 515/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1114 - accuracy: 0.9565 - val_loss: 0.1573 - val_accuracy: 0.9405\n",
      "Epoch 516/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1113 - accuracy: 0.9567 - val_loss: 0.1562 - val_accuracy: 0.9413\n",
      "Epoch 517/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1112 - accuracy: 0.9568 - val_loss: 0.1564 - val_accuracy: 0.9415\n",
      "Epoch 518/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1112 - accuracy: 0.9565 - val_loss: 0.1564 - val_accuracy: 0.9412\n",
      "Epoch 519/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1110 - accuracy: 0.9569 - val_loss: 0.1568 - val_accuracy: 0.9406\n",
      "Epoch 520/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1111 - accuracy: 0.9570 - val_loss: 0.1568 - val_accuracy: 0.9414\n",
      "Epoch 521/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1111 - accuracy: 0.9567 - val_loss: 0.1560 - val_accuracy: 0.9418\n",
      "Epoch 522/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1109 - accuracy: 0.9568 - val_loss: 0.1568 - val_accuracy: 0.9414\n",
      "Epoch 523/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1109 - accuracy: 0.9569 - val_loss: 0.1561 - val_accuracy: 0.9413\n",
      "Epoch 524/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1107 - accuracy: 0.9570 - val_loss: 0.1567 - val_accuracy: 0.9414\n",
      "Epoch 525/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1108 - accuracy: 0.9570 - val_loss: 0.1564 - val_accuracy: 0.9414\n",
      "Epoch 526/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1107 - accuracy: 0.9570 - val_loss: 0.1560 - val_accuracy: 0.9409\n",
      "Epoch 527/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1106 - accuracy: 0.9569 - val_loss: 0.1568 - val_accuracy: 0.9415\n",
      "Epoch 528/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1106 - accuracy: 0.9568 - val_loss: 0.1568 - val_accuracy: 0.9415\n",
      "Epoch 529/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1104 - accuracy: 0.9569 - val_loss: 0.1574 - val_accuracy: 0.9409\n",
      "Epoch 530/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1104 - accuracy: 0.9571 - val_loss: 0.1570 - val_accuracy: 0.9411\n",
      "Epoch 531/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1102 - accuracy: 0.9572 - val_loss: 0.1571 - val_accuracy: 0.9414\n",
      "Epoch 532/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1103 - accuracy: 0.9571 - val_loss: 0.1573 - val_accuracy: 0.9419\n",
      "Epoch 533/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1103 - accuracy: 0.9569 - val_loss: 0.1579 - val_accuracy: 0.9413\n",
      "Epoch 534/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1101 - accuracy: 0.9570 - val_loss: 0.1572 - val_accuracy: 0.9411\n",
      "Epoch 535/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1100 - accuracy: 0.9573 - val_loss: 0.1574 - val_accuracy: 0.9420\n",
      "Epoch 536/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1101 - accuracy: 0.9572 - val_loss: 0.1572 - val_accuracy: 0.9406\n",
      "Epoch 537/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1099 - accuracy: 0.9572 - val_loss: 0.1572 - val_accuracy: 0.9416\n",
      "Epoch 538/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1099 - accuracy: 0.9571 - val_loss: 0.1575 - val_accuracy: 0.9407\n",
      "Epoch 539/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1098 - accuracy: 0.9572 - val_loss: 0.1563 - val_accuracy: 0.9413\n",
      "Epoch 540/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1098 - accuracy: 0.9571 - val_loss: 0.1569 - val_accuracy: 0.9410\n",
      "Epoch 541/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1097 - accuracy: 0.9572 - val_loss: 0.1567 - val_accuracy: 0.9414\n",
      "Epoch 542/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1096 - accuracy: 0.9573 - val_loss: 0.1574 - val_accuracy: 0.9418\n",
      "Epoch 543/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1096 - accuracy: 0.9573 - val_loss: 0.1578 - val_accuracy: 0.9408\n",
      "Epoch 544/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1093 - accuracy: 0.9571 - val_loss: 0.1575 - val_accuracy: 0.9418\n",
      "Epoch 545/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1093 - accuracy: 0.9576 - val_loss: 0.1572 - val_accuracy: 0.9412\n",
      "Epoch 546/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1093 - accuracy: 0.9574 - val_loss: 0.1571 - val_accuracy: 0.9406\n",
      "Epoch 547/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1094 - accuracy: 0.9573 - val_loss: 0.1571 - val_accuracy: 0.9409\n",
      "Epoch 548/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1090 - accuracy: 0.9575 - val_loss: 0.1579 - val_accuracy: 0.9409\n",
      "Epoch 549/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1091 - accuracy: 0.9574 - val_loss: 0.1577 - val_accuracy: 0.9416\n",
      "Epoch 550/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1091 - accuracy: 0.9574 - val_loss: 0.1571 - val_accuracy: 0.9415\n",
      "Epoch 551/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1091 - accuracy: 0.9574 - val_loss: 0.1571 - val_accuracy: 0.9411\n",
      "Epoch 552/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1089 - accuracy: 0.9574 - val_loss: 0.1581 - val_accuracy: 0.9412\n",
      "Epoch 553/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1089 - accuracy: 0.9575 - val_loss: 0.1572 - val_accuracy: 0.9411\n",
      "Epoch 554/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1088 - accuracy: 0.9576 - val_loss: 0.1580 - val_accuracy: 0.9415\n",
      "Epoch 555/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1088 - accuracy: 0.9578 - val_loss: 0.1577 - val_accuracy: 0.9410\n",
      "Epoch 556/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1087 - accuracy: 0.9575 - val_loss: 0.1570 - val_accuracy: 0.9416\n",
      "Epoch 557/800\n",
      "6000/6000 [==============================] - 1s 87us/step - loss: 0.1085 - accuracy: 0.9577 - val_loss: 0.1575 - val_accuracy: 0.9412\n",
      "Epoch 558/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1086 - accuracy: 0.9577 - val_loss: 0.1585 - val_accuracy: 0.9412\n",
      "Epoch 559/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1085 - accuracy: 0.9576 - val_loss: 0.1586 - val_accuracy: 0.9409\n",
      "Epoch 560/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1085 - accuracy: 0.9578 - val_loss: 0.1576 - val_accuracy: 0.9410\n",
      "Epoch 561/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1083 - accuracy: 0.9578 - val_loss: 0.1578 - val_accuracy: 0.9410\n",
      "Epoch 562/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1082 - accuracy: 0.9578 - val_loss: 0.1579 - val_accuracy: 0.9408\n",
      "Epoch 563/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1080 - accuracy: 0.9580 - val_loss: 0.1578 - val_accuracy: 0.9413\n",
      "Epoch 564/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1082 - accuracy: 0.9580 - val_loss: 0.1580 - val_accuracy: 0.9409\n",
      "Epoch 565/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1081 - accuracy: 0.9579 - val_loss: 0.1578 - val_accuracy: 0.9410\n",
      "Epoch 566/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1080 - accuracy: 0.9578 - val_loss: 0.1585 - val_accuracy: 0.9407\n",
      "Epoch 567/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1078 - accuracy: 0.9579 - val_loss: 0.1587 - val_accuracy: 0.9401\n",
      "Epoch 568/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1079 - accuracy: 0.9580 - val_loss: 0.1584 - val_accuracy: 0.9418\n",
      "Epoch 569/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1078 - accuracy: 0.9582 - val_loss: 0.1584 - val_accuracy: 0.9414\n",
      "Epoch 570/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1078 - accuracy: 0.9582 - val_loss: 0.1580 - val_accuracy: 0.9411\n",
      "Epoch 571/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1077 - accuracy: 0.9581 - val_loss: 0.1578 - val_accuracy: 0.9417\n",
      "Epoch 572/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1077 - accuracy: 0.9580 - val_loss: 0.1580 - val_accuracy: 0.9412\n",
      "Epoch 573/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1076 - accuracy: 0.9580 - val_loss: 0.1583 - val_accuracy: 0.9411\n",
      "Epoch 574/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1075 - accuracy: 0.9582 - val_loss: 0.1590 - val_accuracy: 0.9414\n",
      "Epoch 575/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1073 - accuracy: 0.9583 - val_loss: 0.1583 - val_accuracy: 0.9415\n",
      "Epoch 576/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1073 - accuracy: 0.9581 - val_loss: 0.1586 - val_accuracy: 0.9409\n",
      "Epoch 577/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1073 - accuracy: 0.9581 - val_loss: 0.1593 - val_accuracy: 0.9404\n",
      "Epoch 578/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1073 - accuracy: 0.9581 - val_loss: 0.1585 - val_accuracy: 0.9406\n",
      "Epoch 579/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1071 - accuracy: 0.9581 - val_loss: 0.1591 - val_accuracy: 0.9409\n",
      "Epoch 580/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1071 - accuracy: 0.9580 - val_loss: 0.1592 - val_accuracy: 0.9404\n",
      "Epoch 581/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1071 - accuracy: 0.9582 - val_loss: 0.1580 - val_accuracy: 0.9411\n",
      "Epoch 582/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1070 - accuracy: 0.9581 - val_loss: 0.1581 - val_accuracy: 0.9409\n",
      "Epoch 583/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1069 - accuracy: 0.9583 - val_loss: 0.1590 - val_accuracy: 0.9410\n",
      "Epoch 584/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1068 - accuracy: 0.9585 - val_loss: 0.1583 - val_accuracy: 0.9405\n",
      "Epoch 585/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1067 - accuracy: 0.9583 - val_loss: 0.1595 - val_accuracy: 0.9406\n",
      "Epoch 586/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1066 - accuracy: 0.9585 - val_loss: 0.1587 - val_accuracy: 0.9405\n",
      "Epoch 587/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1066 - accuracy: 0.9583 - val_loss: 0.1593 - val_accuracy: 0.9407\n",
      "Epoch 588/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1065 - accuracy: 0.9583 - val_loss: 0.1582 - val_accuracy: 0.9406\n",
      "Epoch 589/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1064 - accuracy: 0.9585 - val_loss: 0.1596 - val_accuracy: 0.9402\n",
      "Epoch 590/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1063 - accuracy: 0.9586 - val_loss: 0.1591 - val_accuracy: 0.9412\n",
      "Epoch 591/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1064 - accuracy: 0.9584 - val_loss: 0.1598 - val_accuracy: 0.9406\n",
      "Epoch 592/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1063 - accuracy: 0.9585 - val_loss: 0.1597 - val_accuracy: 0.9408\n",
      "Epoch 593/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1062 - accuracy: 0.9585 - val_loss: 0.1595 - val_accuracy: 0.9407\n",
      "Epoch 594/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1062 - accuracy: 0.9585 - val_loss: 0.1596 - val_accuracy: 0.9406\n",
      "Epoch 595/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1061 - accuracy: 0.9584 - val_loss: 0.1592 - val_accuracy: 0.9411\n",
      "Epoch 596/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1061 - accuracy: 0.9586 - val_loss: 0.1591 - val_accuracy: 0.9411\n",
      "Epoch 597/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1059 - accuracy: 0.9587 - val_loss: 0.1592 - val_accuracy: 0.9412\n",
      "Epoch 598/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1058 - accuracy: 0.9585 - val_loss: 0.1601 - val_accuracy: 0.9411\n",
      "Epoch 599/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1058 - accuracy: 0.9587 - val_loss: 0.1597 - val_accuracy: 0.9410\n",
      "Epoch 600/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1058 - accuracy: 0.9586 - val_loss: 0.1597 - val_accuracy: 0.9408\n",
      "Epoch 601/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1058 - accuracy: 0.9587 - val_loss: 0.1599 - val_accuracy: 0.9411\n",
      "Epoch 602/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1056 - accuracy: 0.9588 - val_loss: 0.1599 - val_accuracy: 0.9403\n",
      "Epoch 603/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1055 - accuracy: 0.9585 - val_loss: 0.1592 - val_accuracy: 0.9415\n",
      "Epoch 604/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1055 - accuracy: 0.9587 - val_loss: 0.1599 - val_accuracy: 0.9406\n",
      "Epoch 605/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1054 - accuracy: 0.9587 - val_loss: 0.1601 - val_accuracy: 0.9414\n",
      "Epoch 606/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1054 - accuracy: 0.9588 - val_loss: 0.1598 - val_accuracy: 0.9406\n",
      "Epoch 607/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1052 - accuracy: 0.9588 - val_loss: 0.1598 - val_accuracy: 0.9412\n",
      "Epoch 608/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1052 - accuracy: 0.9589 - val_loss: 0.1606 - val_accuracy: 0.9411\n",
      "Epoch 609/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1051 - accuracy: 0.9589 - val_loss: 0.1608 - val_accuracy: 0.9411\n",
      "Epoch 610/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1050 - accuracy: 0.9591 - val_loss: 0.1618 - val_accuracy: 0.9411\n",
      "Epoch 611/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1050 - accuracy: 0.9591 - val_loss: 0.1602 - val_accuracy: 0.9405\n",
      "Epoch 612/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1050 - accuracy: 0.9591 - val_loss: 0.1600 - val_accuracy: 0.9412\n",
      "Epoch 613/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1049 - accuracy: 0.9591 - val_loss: 0.1618 - val_accuracy: 0.9404\n",
      "Epoch 614/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1048 - accuracy: 0.9592 - val_loss: 0.1600 - val_accuracy: 0.9406\n",
      "Epoch 615/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1049 - accuracy: 0.9589 - val_loss: 0.1592 - val_accuracy: 0.9410\n",
      "Epoch 616/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1047 - accuracy: 0.9591 - val_loss: 0.1598 - val_accuracy: 0.9410\n",
      "Epoch 617/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1047 - accuracy: 0.9589 - val_loss: 0.1610 - val_accuracy: 0.9405\n",
      "Epoch 618/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1044 - accuracy: 0.9591 - val_loss: 0.1626 - val_accuracy: 0.9404\n",
      "Epoch 619/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1045 - accuracy: 0.9593 - val_loss: 0.1607 - val_accuracy: 0.9406\n",
      "Epoch 620/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1044 - accuracy: 0.9592 - val_loss: 0.1611 - val_accuracy: 0.9406\n",
      "Epoch 621/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1044 - accuracy: 0.9592 - val_loss: 0.1617 - val_accuracy: 0.9404\n",
      "Epoch 622/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1043 - accuracy: 0.9594 - val_loss: 0.1612 - val_accuracy: 0.9402\n",
      "Epoch 623/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1043 - accuracy: 0.9593 - val_loss: 0.1601 - val_accuracy: 0.9409\n",
      "Epoch 624/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1042 - accuracy: 0.9593 - val_loss: 0.1620 - val_accuracy: 0.9403\n",
      "Epoch 625/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1040 - accuracy: 0.9594 - val_loss: 0.1603 - val_accuracy: 0.9409\n",
      "Epoch 626/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1041 - accuracy: 0.9592 - val_loss: 0.1610 - val_accuracy: 0.9404\n",
      "Epoch 627/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1040 - accuracy: 0.9593 - val_loss: 0.1608 - val_accuracy: 0.9405\n",
      "Epoch 628/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1039 - accuracy: 0.9593 - val_loss: 0.1610 - val_accuracy: 0.9408\n",
      "Epoch 629/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1038 - accuracy: 0.9594 - val_loss: 0.1624 - val_accuracy: 0.9404\n",
      "Epoch 630/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1038 - accuracy: 0.9594 - val_loss: 0.1608 - val_accuracy: 0.9411\n",
      "Epoch 631/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1038 - accuracy: 0.9595 - val_loss: 0.1610 - val_accuracy: 0.9410\n",
      "Epoch 632/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1037 - accuracy: 0.9594 - val_loss: 0.1605 - val_accuracy: 0.9408\n",
      "Epoch 633/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1035 - accuracy: 0.9596 - val_loss: 0.1615 - val_accuracy: 0.9411\n",
      "Epoch 634/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1035 - accuracy: 0.9597 - val_loss: 0.1615 - val_accuracy: 0.9398\n",
      "Epoch 635/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1034 - accuracy: 0.9596 - val_loss: 0.1611 - val_accuracy: 0.9405\n",
      "Epoch 636/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1033 - accuracy: 0.9597 - val_loss: 0.1618 - val_accuracy: 0.9407\n",
      "Epoch 637/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1032 - accuracy: 0.9597 - val_loss: 0.1623 - val_accuracy: 0.9403\n",
      "Epoch 638/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1032 - accuracy: 0.9598 - val_loss: 0.1610 - val_accuracy: 0.9408\n",
      "Epoch 639/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1031 - accuracy: 0.9597 - val_loss: 0.1611 - val_accuracy: 0.9413\n",
      "Epoch 640/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1030 - accuracy: 0.9596 - val_loss: 0.1625 - val_accuracy: 0.9401\n",
      "Epoch 641/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1030 - accuracy: 0.9596 - val_loss: 0.1625 - val_accuracy: 0.9406\n",
      "Epoch 642/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1030 - accuracy: 0.9598 - val_loss: 0.1616 - val_accuracy: 0.9408\n",
      "Epoch 643/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1028 - accuracy: 0.9598 - val_loss: 0.1614 - val_accuracy: 0.9405\n",
      "Epoch 644/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1027 - accuracy: 0.9600 - val_loss: 0.1623 - val_accuracy: 0.9399\n",
      "Epoch 645/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1028 - accuracy: 0.9600 - val_loss: 0.1614 - val_accuracy: 0.9406\n",
      "Epoch 646/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1027 - accuracy: 0.9598 - val_loss: 0.1617 - val_accuracy: 0.9403\n",
      "Epoch 647/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1027 - accuracy: 0.9598 - val_loss: 0.1624 - val_accuracy: 0.9400\n",
      "Epoch 648/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1025 - accuracy: 0.9599 - val_loss: 0.1624 - val_accuracy: 0.9409\n",
      "Epoch 649/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1027 - accuracy: 0.9597 - val_loss: 0.1625 - val_accuracy: 0.9404\n",
      "Epoch 650/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1024 - accuracy: 0.9600 - val_loss: 0.1611 - val_accuracy: 0.9405\n",
      "Epoch 651/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1024 - accuracy: 0.9599 - val_loss: 0.1626 - val_accuracy: 0.9400\n",
      "Epoch 652/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1023 - accuracy: 0.9602 - val_loss: 0.1619 - val_accuracy: 0.9413\n",
      "Epoch 653/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1022 - accuracy: 0.9600 - val_loss: 0.1620 - val_accuracy: 0.9407\n",
      "Epoch 654/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1021 - accuracy: 0.9601 - val_loss: 0.1647 - val_accuracy: 0.9389\n",
      "Epoch 655/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1021 - accuracy: 0.9601 - val_loss: 0.1632 - val_accuracy: 0.9411\n",
      "Epoch 656/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1020 - accuracy: 0.9601 - val_loss: 0.1640 - val_accuracy: 0.9399\n",
      "Epoch 657/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1019 - accuracy: 0.9600 - val_loss: 0.1636 - val_accuracy: 0.9402\n",
      "Epoch 658/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1018 - accuracy: 0.9602 - val_loss: 0.1627 - val_accuracy: 0.9407\n",
      "Epoch 659/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1018 - accuracy: 0.9601 - val_loss: 0.1631 - val_accuracy: 0.9406\n",
      "Epoch 660/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1018 - accuracy: 0.9602 - val_loss: 0.1625 - val_accuracy: 0.9402\n",
      "Epoch 661/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1016 - accuracy: 0.9603 - val_loss: 0.1636 - val_accuracy: 0.9397\n",
      "Epoch 662/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1017 - accuracy: 0.9604 - val_loss: 0.1634 - val_accuracy: 0.9408\n",
      "Epoch 663/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1016 - accuracy: 0.9603 - val_loss: 0.1629 - val_accuracy: 0.9403\n",
      "Epoch 664/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1015 - accuracy: 0.9605 - val_loss: 0.1626 - val_accuracy: 0.9402\n",
      "Epoch 665/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1014 - accuracy: 0.9606 - val_loss: 0.1637 - val_accuracy: 0.9401\n",
      "Epoch 666/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1015 - accuracy: 0.9604 - val_loss: 0.1635 - val_accuracy: 0.9402\n",
      "Epoch 667/800\n",
      "6000/6000 [==============================] - 1s 91us/step - loss: 0.1014 - accuracy: 0.9601 - val_loss: 0.1641 - val_accuracy: 0.9403\n",
      "Epoch 668/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1012 - accuracy: 0.9606 - val_loss: 0.1647 - val_accuracy: 0.9402\n",
      "Epoch 669/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1013 - accuracy: 0.9604 - val_loss: 0.1635 - val_accuracy: 0.9394\n",
      "Epoch 670/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1011 - accuracy: 0.9605 - val_loss: 0.1635 - val_accuracy: 0.9397\n",
      "Epoch 671/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1011 - accuracy: 0.9606 - val_loss: 0.1656 - val_accuracy: 0.9392\n",
      "Epoch 672/800\n",
      "6000/6000 [==============================] - 1s 83us/step - loss: 0.1009 - accuracy: 0.9607 - val_loss: 0.1640 - val_accuracy: 0.9404\n",
      "Epoch 673/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1009 - accuracy: 0.9606 - val_loss: 0.1637 - val_accuracy: 0.9406\n",
      "Epoch 674/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1008 - accuracy: 0.9606 - val_loss: 0.1643 - val_accuracy: 0.9406\n",
      "Epoch 675/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1007 - accuracy: 0.9606 - val_loss: 0.1640 - val_accuracy: 0.9397\n",
      "Epoch 676/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1007 - accuracy: 0.9608 - val_loss: 0.1647 - val_accuracy: 0.9394\n",
      "Epoch 677/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1008 - accuracy: 0.9606 - val_loss: 0.1638 - val_accuracy: 0.9406\n",
      "Epoch 678/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1006 - accuracy: 0.9606 - val_loss: 0.1638 - val_accuracy: 0.9404\n",
      "Epoch 679/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1004 - accuracy: 0.9606 - val_loss: 0.1638 - val_accuracy: 0.9402\n",
      "Epoch 680/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1004 - accuracy: 0.9608 - val_loss: 0.1652 - val_accuracy: 0.9396\n",
      "Epoch 681/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1005 - accuracy: 0.9608 - val_loss: 0.1640 - val_accuracy: 0.9405\n",
      "Epoch 682/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1003 - accuracy: 0.9609 - val_loss: 0.1637 - val_accuracy: 0.9406\n",
      "Epoch 683/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1001 - accuracy: 0.9608 - val_loss: 0.1648 - val_accuracy: 0.9400\n",
      "Epoch 684/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1001 - accuracy: 0.9608 - val_loss: 0.1644 - val_accuracy: 0.9401\n",
      "Epoch 685/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1001 - accuracy: 0.9608 - val_loss: 0.1635 - val_accuracy: 0.9405\n",
      "Epoch 686/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1001 - accuracy: 0.9609 - val_loss: 0.1639 - val_accuracy: 0.9401\n",
      "Epoch 687/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1000 - accuracy: 0.9609 - val_loss: 0.1641 - val_accuracy: 0.9405\n",
      "Epoch 688/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0999 - accuracy: 0.9610 - val_loss: 0.1643 - val_accuracy: 0.9400\n",
      "Epoch 689/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0998 - accuracy: 0.9608 - val_loss: 0.1642 - val_accuracy: 0.9401\n",
      "Epoch 690/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0997 - accuracy: 0.9610 - val_loss: 0.1652 - val_accuracy: 0.9400\n",
      "Epoch 691/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0996 - accuracy: 0.9611 - val_loss: 0.1661 - val_accuracy: 0.9393\n",
      "Epoch 692/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0996 - accuracy: 0.9609 - val_loss: 0.1643 - val_accuracy: 0.9397\n",
      "Epoch 693/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0996 - accuracy: 0.9610 - val_loss: 0.1662 - val_accuracy: 0.9399\n",
      "Epoch 694/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0994 - accuracy: 0.9609 - val_loss: 0.1651 - val_accuracy: 0.9402\n",
      "Epoch 695/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0993 - accuracy: 0.9612 - val_loss: 0.1650 - val_accuracy: 0.9398\n",
      "Epoch 696/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0993 - accuracy: 0.9609 - val_loss: 0.1651 - val_accuracy: 0.9403\n",
      "Epoch 697/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0992 - accuracy: 0.9612 - val_loss: 0.1643 - val_accuracy: 0.9400\n",
      "Epoch 698/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0992 - accuracy: 0.9614 - val_loss: 0.1654 - val_accuracy: 0.9398\n",
      "Epoch 699/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0991 - accuracy: 0.9613 - val_loss: 0.1669 - val_accuracy: 0.9396\n",
      "Epoch 700/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0990 - accuracy: 0.9613 - val_loss: 0.1662 - val_accuracy: 0.9407\n",
      "Epoch 701/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0989 - accuracy: 0.9615 - val_loss: 0.1660 - val_accuracy: 0.9400\n",
      "Epoch 702/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0990 - accuracy: 0.9613 - val_loss: 0.1660 - val_accuracy: 0.9399\n",
      "Epoch 703/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0988 - accuracy: 0.9614 - val_loss: 0.1668 - val_accuracy: 0.9399\n",
      "Epoch 704/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0988 - accuracy: 0.9615 - val_loss: 0.1665 - val_accuracy: 0.9403\n",
      "Epoch 705/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0987 - accuracy: 0.9614 - val_loss: 0.1658 - val_accuracy: 0.9395\n",
      "Epoch 706/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0987 - accuracy: 0.9613 - val_loss: 0.1658 - val_accuracy: 0.9401\n",
      "Epoch 707/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0985 - accuracy: 0.9615 - val_loss: 0.1674 - val_accuracy: 0.9390\n",
      "Epoch 708/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0985 - accuracy: 0.9617 - val_loss: 0.1661 - val_accuracy: 0.9406\n",
      "Epoch 709/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0984 - accuracy: 0.9616 - val_loss: 0.1665 - val_accuracy: 0.9404\n",
      "Epoch 710/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0984 - accuracy: 0.9615 - val_loss: 0.1666 - val_accuracy: 0.9402\n",
      "Epoch 711/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0983 - accuracy: 0.9616 - val_loss: 0.1669 - val_accuracy: 0.9397\n",
      "Epoch 712/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0982 - accuracy: 0.9616 - val_loss: 0.1668 - val_accuracy: 0.9398\n",
      "Epoch 713/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0981 - accuracy: 0.9617 - val_loss: 0.1671 - val_accuracy: 0.9394\n",
      "Epoch 714/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0981 - accuracy: 0.9619 - val_loss: 0.1669 - val_accuracy: 0.9395\n",
      "Epoch 715/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0981 - accuracy: 0.9615 - val_loss: 0.1662 - val_accuracy: 0.9400\n",
      "Epoch 716/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0980 - accuracy: 0.9615 - val_loss: 0.1664 - val_accuracy: 0.9398\n",
      "Epoch 717/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0979 - accuracy: 0.9618 - val_loss: 0.1668 - val_accuracy: 0.9398\n",
      "Epoch 718/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0979 - accuracy: 0.9616 - val_loss: 0.1666 - val_accuracy: 0.9398\n",
      "Epoch 719/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0978 - accuracy: 0.9619 - val_loss: 0.1655 - val_accuracy: 0.9401\n",
      "Epoch 720/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0977 - accuracy: 0.9618 - val_loss: 0.1676 - val_accuracy: 0.9394\n",
      "Epoch 721/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.0975 - accuracy: 0.9618 - val_loss: 0.1663 - val_accuracy: 0.9398\n",
      "Epoch 722/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0975 - accuracy: 0.9619 - val_loss: 0.1671 - val_accuracy: 0.9394\n",
      "Epoch 723/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0975 - accuracy: 0.9618 - val_loss: 0.1666 - val_accuracy: 0.9395\n",
      "Epoch 724/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0973 - accuracy: 0.9621 - val_loss: 0.1667 - val_accuracy: 0.9400\n",
      "Epoch 725/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0973 - accuracy: 0.9622 - val_loss: 0.1700 - val_accuracy: 0.9393\n",
      "Epoch 726/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0973 - accuracy: 0.9620 - val_loss: 0.1683 - val_accuracy: 0.9395\n",
      "Epoch 727/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0972 - accuracy: 0.9621 - val_loss: 0.1675 - val_accuracy: 0.9397\n",
      "Epoch 728/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0972 - accuracy: 0.9621 - val_loss: 0.1684 - val_accuracy: 0.9398\n",
      "Epoch 729/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0971 - accuracy: 0.9621 - val_loss: 0.1666 - val_accuracy: 0.9397\n",
      "Epoch 730/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0969 - accuracy: 0.9624 - val_loss: 0.1681 - val_accuracy: 0.9395\n",
      "Epoch 731/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0970 - accuracy: 0.9620 - val_loss: 0.1670 - val_accuracy: 0.9404\n",
      "Epoch 732/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0970 - accuracy: 0.9622 - val_loss: 0.1671 - val_accuracy: 0.9397\n",
      "Epoch 733/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0968 - accuracy: 0.9620 - val_loss: 0.1688 - val_accuracy: 0.9387\n",
      "Epoch 734/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0968 - accuracy: 0.9618 - val_loss: 0.1686 - val_accuracy: 0.9398\n",
      "Epoch 735/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0967 - accuracy: 0.9622 - val_loss: 0.1686 - val_accuracy: 0.9398\n",
      "Epoch 736/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0966 - accuracy: 0.9623 - val_loss: 0.1667 - val_accuracy: 0.9397\n",
      "Epoch 737/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0965 - accuracy: 0.9624 - val_loss: 0.1690 - val_accuracy: 0.9389\n",
      "Epoch 738/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0965 - accuracy: 0.9622 - val_loss: 0.1675 - val_accuracy: 0.9404\n",
      "Epoch 739/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0964 - accuracy: 0.9624 - val_loss: 0.1710 - val_accuracy: 0.9389\n",
      "Epoch 740/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0964 - accuracy: 0.9624 - val_loss: 0.1682 - val_accuracy: 0.9396\n",
      "Epoch 741/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0962 - accuracy: 0.9624 - val_loss: 0.1684 - val_accuracy: 0.9399\n",
      "Epoch 742/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0962 - accuracy: 0.9623 - val_loss: 0.1698 - val_accuracy: 0.9384\n",
      "Epoch 743/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0960 - accuracy: 0.9625 - val_loss: 0.1676 - val_accuracy: 0.9396\n",
      "Epoch 744/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0960 - accuracy: 0.9625 - val_loss: 0.1688 - val_accuracy: 0.9400\n",
      "Epoch 745/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0961 - accuracy: 0.9626 - val_loss: 0.1686 - val_accuracy: 0.9395\n",
      "Epoch 746/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0959 - accuracy: 0.9625 - val_loss: 0.1705 - val_accuracy: 0.9393\n",
      "Epoch 747/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0958 - accuracy: 0.9625 - val_loss: 0.1695 - val_accuracy: 0.9387\n",
      "Epoch 748/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0958 - accuracy: 0.9626 - val_loss: 0.1682 - val_accuracy: 0.9390\n",
      "Epoch 749/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0958 - accuracy: 0.9626 - val_loss: 0.1697 - val_accuracy: 0.9385\n",
      "Epoch 750/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0957 - accuracy: 0.9626 - val_loss: 0.1691 - val_accuracy: 0.9396\n",
      "Epoch 751/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0954 - accuracy: 0.9627 - val_loss: 0.1684 - val_accuracy: 0.9399\n",
      "Epoch 752/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0954 - accuracy: 0.9628 - val_loss: 0.1683 - val_accuracy: 0.9395\n",
      "Epoch 753/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0954 - accuracy: 0.9628 - val_loss: 0.1690 - val_accuracy: 0.9399\n",
      "Epoch 754/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0953 - accuracy: 0.9628 - val_loss: 0.1705 - val_accuracy: 0.9393\n",
      "Epoch 755/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.0953 - accuracy: 0.9630 - val_loss: 0.1696 - val_accuracy: 0.9397\n",
      "Epoch 756/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0951 - accuracy: 0.9630 - val_loss: 0.1697 - val_accuracy: 0.9400\n",
      "Epoch 757/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0951 - accuracy: 0.9629 - val_loss: 0.1690 - val_accuracy: 0.9389\n",
      "Epoch 758/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0951 - accuracy: 0.9629 - val_loss: 0.1710 - val_accuracy: 0.9384\n",
      "Epoch 759/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0950 - accuracy: 0.9630 - val_loss: 0.1704 - val_accuracy: 0.9394\n",
      "Epoch 760/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0950 - accuracy: 0.9629 - val_loss: 0.1702 - val_accuracy: 0.9389\n",
      "Epoch 761/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0950 - accuracy: 0.9628 - val_loss: 0.1700 - val_accuracy: 0.9391\n",
      "Epoch 762/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0949 - accuracy: 0.9631 - val_loss: 0.1703 - val_accuracy: 0.9394\n",
      "Epoch 763/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0946 - accuracy: 0.9631 - val_loss: 0.1717 - val_accuracy: 0.9391\n",
      "Epoch 764/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0947 - accuracy: 0.9632 - val_loss: 0.1704 - val_accuracy: 0.9399\n",
      "Epoch 765/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0946 - accuracy: 0.9632 - val_loss: 0.1712 - val_accuracy: 0.9398\n",
      "Epoch 766/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0944 - accuracy: 0.9633 - val_loss: 0.1730 - val_accuracy: 0.9383\n",
      "Epoch 767/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0945 - accuracy: 0.9631 - val_loss: 0.1701 - val_accuracy: 0.9396\n",
      "Epoch 768/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0942 - accuracy: 0.9633 - val_loss: 0.1717 - val_accuracy: 0.9389\n",
      "Epoch 769/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0942 - accuracy: 0.9631 - val_loss: 0.1716 - val_accuracy: 0.9390\n",
      "Epoch 770/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0942 - accuracy: 0.9631 - val_loss: 0.1709 - val_accuracy: 0.9394\n",
      "Epoch 771/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0943 - accuracy: 0.9632 - val_loss: 0.1710 - val_accuracy: 0.9389\n",
      "Epoch 772/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0941 - accuracy: 0.9635 - val_loss: 0.1712 - val_accuracy: 0.9390\n",
      "Epoch 773/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0941 - accuracy: 0.9633 - val_loss: 0.1698 - val_accuracy: 0.9400\n",
      "Epoch 774/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0939 - accuracy: 0.9633 - val_loss: 0.1703 - val_accuracy: 0.9396\n",
      "Epoch 775/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.0938 - accuracy: 0.9633 - val_loss: 0.1722 - val_accuracy: 0.9389\n",
      "Epoch 776/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0937 - accuracy: 0.9635 - val_loss: 0.1727 - val_accuracy: 0.9393\n",
      "Epoch 777/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0937 - accuracy: 0.9637 - val_loss: 0.1716 - val_accuracy: 0.9388\n",
      "Epoch 778/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0936 - accuracy: 0.9632 - val_loss: 0.1710 - val_accuracy: 0.9397\n",
      "Epoch 779/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0936 - accuracy: 0.9637 - val_loss: 0.1732 - val_accuracy: 0.9385\n",
      "Epoch 780/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0935 - accuracy: 0.9635 - val_loss: 0.1717 - val_accuracy: 0.9396\n",
      "Epoch 781/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0934 - accuracy: 0.9636 - val_loss: 0.1717 - val_accuracy: 0.9399\n",
      "Epoch 782/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0933 - accuracy: 0.9636 - val_loss: 0.1730 - val_accuracy: 0.9387\n",
      "Epoch 783/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0933 - accuracy: 0.9635 - val_loss: 0.1714 - val_accuracy: 0.9394\n",
      "Epoch 784/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0933 - accuracy: 0.9635 - val_loss: 0.1726 - val_accuracy: 0.9391\n",
      "Epoch 785/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0931 - accuracy: 0.9638 - val_loss: 0.1714 - val_accuracy: 0.9389\n",
      "Epoch 786/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0930 - accuracy: 0.9637 - val_loss: 0.1721 - val_accuracy: 0.9401\n",
      "Epoch 787/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0929 - accuracy: 0.9637 - val_loss: 0.1729 - val_accuracy: 0.9392\n",
      "Epoch 788/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0931 - accuracy: 0.9637 - val_loss: 0.1728 - val_accuracy: 0.9386\n",
      "Epoch 789/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0930 - accuracy: 0.9639 - val_loss: 0.1733 - val_accuracy: 0.9391\n",
      "Epoch 790/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0928 - accuracy: 0.9638 - val_loss: 0.1728 - val_accuracy: 0.9390\n",
      "Epoch 791/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0927 - accuracy: 0.9638 - val_loss: 0.1725 - val_accuracy: 0.9399\n",
      "Epoch 792/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0927 - accuracy: 0.9637 - val_loss: 0.1732 - val_accuracy: 0.9393\n",
      "Epoch 793/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0924 - accuracy: 0.9641 - val_loss: 0.1731 - val_accuracy: 0.9393\n",
      "Epoch 794/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0923 - accuracy: 0.9639 - val_loss: 0.1723 - val_accuracy: 0.9392\n",
      "Epoch 795/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0924 - accuracy: 0.9639 - val_loss: 0.1741 - val_accuracy: 0.9387\n",
      "Epoch 796/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0921 - accuracy: 0.9640 - val_loss: 0.1734 - val_accuracy: 0.9390\n",
      "Epoch 797/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0922 - accuracy: 0.9642 - val_loss: 0.1734 - val_accuracy: 0.9390\n",
      "Epoch 798/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0923 - accuracy: 0.9642 - val_loss: 0.1732 - val_accuracy: 0.9390\n",
      "Epoch 799/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.0920 - accuracy: 0.9640 - val_loss: 0.1746 - val_accuracy: 0.9377\n",
      "Epoch 800/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0920 - accuracy: 0.9640 - val_loss: 0.1735 - val_accuracy: 0.9390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:122: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Train on 6000 samples, validate on 2001 samples\n",
      "Epoch 1/800\n",
      "6000/6000 [==============================] - 1s 95us/step - loss: 0.3443 - accuracy: 0.8909 - val_loss: 0.2654 - val_accuracy: 0.9247\n",
      "Epoch 2/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.2496 - accuracy: 0.9304 - val_loss: 0.2647 - val_accuracy: 0.9247\n",
      "Epoch 3/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2491 - accuracy: 0.9304 - val_loss: 0.2643 - val_accuracy: 0.9247\n",
      "Epoch 4/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2487 - accuracy: 0.9304 - val_loss: 0.2641 - val_accuracy: 0.9247\n",
      "Epoch 5/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2484 - accuracy: 0.9304 - val_loss: 0.2636 - val_accuracy: 0.9247\n",
      "Epoch 6/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2481 - accuracy: 0.9304 - val_loss: 0.2633 - val_accuracy: 0.9247\n",
      "Epoch 7/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2478 - accuracy: 0.9304 - val_loss: 0.2629 - val_accuracy: 0.9247\n",
      "Epoch 8/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2474 - accuracy: 0.9304 - val_loss: 0.2627 - val_accuracy: 0.9247\n",
      "Epoch 9/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2470 - accuracy: 0.9304 - val_loss: 0.2623 - val_accuracy: 0.9247\n",
      "Epoch 10/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2466 - accuracy: 0.9304 - val_loss: 0.2617 - val_accuracy: 0.9247\n",
      "Epoch 11/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2462 - accuracy: 0.9304 - val_loss: 0.2613 - val_accuracy: 0.9247\n",
      "Epoch 12/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2457 - accuracy: 0.9304 - val_loss: 0.2609 - val_accuracy: 0.9247\n",
      "Epoch 13/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.2452 - accuracy: 0.9304 - val_loss: 0.2602 - val_accuracy: 0.9247\n",
      "Epoch 14/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2446 - accuracy: 0.9304 - val_loss: 0.2595 - val_accuracy: 0.9247\n",
      "Epoch 15/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2440 - accuracy: 0.9304 - val_loss: 0.2591 - val_accuracy: 0.9247\n",
      "Epoch 16/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2433 - accuracy: 0.9304 - val_loss: 0.2582 - val_accuracy: 0.9247\n",
      "Epoch 17/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2425 - accuracy: 0.9304 - val_loss: 0.2572 - val_accuracy: 0.9247\n",
      "Epoch 18/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2417 - accuracy: 0.9304 - val_loss: 0.2563 - val_accuracy: 0.9247\n",
      "Epoch 19/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2407 - accuracy: 0.9304 - val_loss: 0.2551 - val_accuracy: 0.9247\n",
      "Epoch 20/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.2397 - accuracy: 0.9304 - val_loss: 0.2543 - val_accuracy: 0.9247\n",
      "Epoch 21/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.2385 - accuracy: 0.9304 - val_loss: 0.2530 - val_accuracy: 0.9247\n",
      "Epoch 22/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2373 - accuracy: 0.9304 - val_loss: 0.2517 - val_accuracy: 0.9247\n",
      "Epoch 23/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2361 - accuracy: 0.9304 - val_loss: 0.2505 - val_accuracy: 0.9247\n",
      "Epoch 24/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2347 - accuracy: 0.9304 - val_loss: 0.2491 - val_accuracy: 0.9247\n",
      "Epoch 25/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2334 - accuracy: 0.9304 - val_loss: 0.2479 - val_accuracy: 0.9247\n",
      "Epoch 26/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2320 - accuracy: 0.9304 - val_loss: 0.2463 - val_accuracy: 0.9247\n",
      "Epoch 27/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2307 - accuracy: 0.9304 - val_loss: 0.2449 - val_accuracy: 0.9247\n",
      "Epoch 28/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2292 - accuracy: 0.9304 - val_loss: 0.2435 - val_accuracy: 0.9247\n",
      "Epoch 29/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2278 - accuracy: 0.9304 - val_loss: 0.2423 - val_accuracy: 0.9247\n",
      "Epoch 30/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2263 - accuracy: 0.9304 - val_loss: 0.2407 - val_accuracy: 0.9247\n",
      "Epoch 31/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2249 - accuracy: 0.9304 - val_loss: 0.2393 - val_accuracy: 0.9247\n",
      "Epoch 32/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2234 - accuracy: 0.9304 - val_loss: 0.2380 - val_accuracy: 0.9248\n",
      "Epoch 33/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2220 - accuracy: 0.9305 - val_loss: 0.2362 - val_accuracy: 0.9248\n",
      "Epoch 34/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2205 - accuracy: 0.9305 - val_loss: 0.2348 - val_accuracy: 0.9248\n",
      "Epoch 35/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2189 - accuracy: 0.9306 - val_loss: 0.2334 - val_accuracy: 0.9248\n",
      "Epoch 36/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.2174 - accuracy: 0.9307 - val_loss: 0.2317 - val_accuracy: 0.9249\n",
      "Epoch 37/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2158 - accuracy: 0.9308 - val_loss: 0.2302 - val_accuracy: 0.9250\n",
      "Epoch 38/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2143 - accuracy: 0.9309 - val_loss: 0.2288 - val_accuracy: 0.9250\n",
      "Epoch 39/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2127 - accuracy: 0.9310 - val_loss: 0.2272 - val_accuracy: 0.9252\n",
      "Epoch 40/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2112 - accuracy: 0.9311 - val_loss: 0.2259 - val_accuracy: 0.9253\n",
      "Epoch 41/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2097 - accuracy: 0.9312 - val_loss: 0.2245 - val_accuracy: 0.9255\n",
      "Epoch 42/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.2082 - accuracy: 0.9313 - val_loss: 0.2230 - val_accuracy: 0.9254\n",
      "Epoch 43/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.2068 - accuracy: 0.9315 - val_loss: 0.2216 - val_accuracy: 0.9258\n",
      "Epoch 44/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2054 - accuracy: 0.9316 - val_loss: 0.2204 - val_accuracy: 0.9258\n",
      "Epoch 45/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.2040 - accuracy: 0.9317 - val_loss: 0.2193 - val_accuracy: 0.9259\n",
      "Epoch 46/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.2026 - accuracy: 0.9317 - val_loss: 0.2181 - val_accuracy: 0.9258\n",
      "Epoch 47/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2013 - accuracy: 0.9319 - val_loss: 0.2171 - val_accuracy: 0.9262\n",
      "Epoch 48/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.2001 - accuracy: 0.9320 - val_loss: 0.2158 - val_accuracy: 0.9260\n",
      "Epoch 49/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1989 - accuracy: 0.9322 - val_loss: 0.2144 - val_accuracy: 0.9261\n",
      "Epoch 50/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1977 - accuracy: 0.9321 - val_loss: 0.2136 - val_accuracy: 0.9264\n",
      "Epoch 51/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1966 - accuracy: 0.9323 - val_loss: 0.2131 - val_accuracy: 0.9263\n",
      "Epoch 52/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1956 - accuracy: 0.9325 - val_loss: 0.2117 - val_accuracy: 0.9264\n",
      "Epoch 53/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1946 - accuracy: 0.9324 - val_loss: 0.2108 - val_accuracy: 0.9267\n",
      "Epoch 54/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1937 - accuracy: 0.9326 - val_loss: 0.2101 - val_accuracy: 0.9268\n",
      "Epoch 55/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1929 - accuracy: 0.9328 - val_loss: 0.2092 - val_accuracy: 0.9265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1921 - accuracy: 0.9328 - val_loss: 0.2088 - val_accuracy: 0.9270\n",
      "Epoch 57/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1914 - accuracy: 0.9328 - val_loss: 0.2084 - val_accuracy: 0.9268\n",
      "Epoch 58/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1907 - accuracy: 0.9331 - val_loss: 0.2077 - val_accuracy: 0.9270\n",
      "Epoch 59/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1901 - accuracy: 0.9331 - val_loss: 0.2069 - val_accuracy: 0.9273\n",
      "Epoch 60/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1894 - accuracy: 0.9332 - val_loss: 0.2066 - val_accuracy: 0.9271\n",
      "Epoch 61/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1888 - accuracy: 0.9334 - val_loss: 0.2059 - val_accuracy: 0.9273\n",
      "Epoch 62/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1882 - accuracy: 0.9333 - val_loss: 0.2055 - val_accuracy: 0.9276\n",
      "Epoch 63/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1876 - accuracy: 0.9336 - val_loss: 0.2048 - val_accuracy: 0.9273\n",
      "Epoch 64/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1871 - accuracy: 0.9335 - val_loss: 0.2045 - val_accuracy: 0.9273\n",
      "Epoch 65/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1864 - accuracy: 0.9336 - val_loss: 0.2040 - val_accuracy: 0.9277\n",
      "Epoch 66/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1858 - accuracy: 0.9339 - val_loss: 0.2033 - val_accuracy: 0.9274\n",
      "Epoch 67/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1852 - accuracy: 0.9340 - val_loss: 0.2030 - val_accuracy: 0.9276\n",
      "Epoch 68/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1846 - accuracy: 0.9340 - val_loss: 0.2022 - val_accuracy: 0.9278\n",
      "Epoch 69/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1840 - accuracy: 0.9342 - val_loss: 0.2019 - val_accuracy: 0.9279\n",
      "Epoch 70/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1833 - accuracy: 0.9343 - val_loss: 0.2018 - val_accuracy: 0.9275\n",
      "Epoch 71/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1827 - accuracy: 0.9346 - val_loss: 0.2006 - val_accuracy: 0.9285\n",
      "Epoch 72/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1821 - accuracy: 0.9346 - val_loss: 0.2003 - val_accuracy: 0.9280\n",
      "Epoch 73/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1815 - accuracy: 0.9347 - val_loss: 0.1995 - val_accuracy: 0.9280\n",
      "Epoch 74/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1809 - accuracy: 0.9348 - val_loss: 0.1990 - val_accuracy: 0.9285\n",
      "Epoch 75/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1803 - accuracy: 0.9352 - val_loss: 0.1983 - val_accuracy: 0.9287\n",
      "Epoch 76/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1799 - accuracy: 0.9352 - val_loss: 0.1984 - val_accuracy: 0.9285\n",
      "Epoch 77/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1793 - accuracy: 0.9353 - val_loss: 0.1980 - val_accuracy: 0.9284\n",
      "Epoch 78/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1789 - accuracy: 0.9355 - val_loss: 0.1972 - val_accuracy: 0.9284\n",
      "Epoch 79/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1784 - accuracy: 0.9356 - val_loss: 0.1967 - val_accuracy: 0.9292\n",
      "Epoch 80/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1780 - accuracy: 0.9358 - val_loss: 0.1963 - val_accuracy: 0.9290\n",
      "Epoch 81/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1776 - accuracy: 0.9360 - val_loss: 0.1961 - val_accuracy: 0.9289\n",
      "Epoch 82/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1772 - accuracy: 0.9358 - val_loss: 0.1960 - val_accuracy: 0.9288\n",
      "Epoch 83/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1768 - accuracy: 0.9361 - val_loss: 0.1954 - val_accuracy: 0.9293\n",
      "Epoch 84/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1764 - accuracy: 0.9361 - val_loss: 0.1953 - val_accuracy: 0.9294\n",
      "Epoch 85/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1761 - accuracy: 0.9363 - val_loss: 0.1949 - val_accuracy: 0.9293\n",
      "Epoch 86/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1757 - accuracy: 0.9363 - val_loss: 0.1946 - val_accuracy: 0.9294\n",
      "Epoch 87/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1754 - accuracy: 0.9367 - val_loss: 0.1941 - val_accuracy: 0.9295\n",
      "Epoch 88/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1750 - accuracy: 0.9368 - val_loss: 0.1938 - val_accuracy: 0.9299\n",
      "Epoch 89/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1746 - accuracy: 0.9369 - val_loss: 0.1935 - val_accuracy: 0.9298\n",
      "Epoch 90/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1742 - accuracy: 0.9369 - val_loss: 0.1932 - val_accuracy: 0.9299\n",
      "Epoch 91/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1739 - accuracy: 0.9370 - val_loss: 0.1927 - val_accuracy: 0.9298\n",
      "Epoch 92/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1735 - accuracy: 0.9372 - val_loss: 0.1926 - val_accuracy: 0.9304\n",
      "Epoch 93/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1732 - accuracy: 0.9372 - val_loss: 0.1922 - val_accuracy: 0.9302\n",
      "Epoch 94/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1728 - accuracy: 0.9373 - val_loss: 0.1920 - val_accuracy: 0.9301\n",
      "Epoch 95/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1725 - accuracy: 0.9374 - val_loss: 0.1918 - val_accuracy: 0.9305\n",
      "Epoch 96/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1721 - accuracy: 0.9376 - val_loss: 0.1911 - val_accuracy: 0.9302\n",
      "Epoch 97/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1717 - accuracy: 0.9378 - val_loss: 0.1904 - val_accuracy: 0.9306\n",
      "Epoch 98/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1713 - accuracy: 0.9379 - val_loss: 0.1905 - val_accuracy: 0.9306\n",
      "Epoch 99/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1709 - accuracy: 0.9380 - val_loss: 0.1899 - val_accuracy: 0.9306\n",
      "Epoch 100/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1705 - accuracy: 0.9380 - val_loss: 0.1898 - val_accuracy: 0.9306\n",
      "Epoch 101/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1702 - accuracy: 0.9381 - val_loss: 0.1893 - val_accuracy: 0.9309\n",
      "Epoch 102/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1698 - accuracy: 0.9382 - val_loss: 0.1892 - val_accuracy: 0.9308\n",
      "Epoch 103/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1694 - accuracy: 0.9385 - val_loss: 0.1887 - val_accuracy: 0.9308\n",
      "Epoch 104/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1691 - accuracy: 0.9385 - val_loss: 0.1885 - val_accuracy: 0.9310\n",
      "Epoch 105/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1688 - accuracy: 0.9384 - val_loss: 0.1881 - val_accuracy: 0.9312\n",
      "Epoch 106/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1684 - accuracy: 0.9386 - val_loss: 0.1877 - val_accuracy: 0.9312\n",
      "Epoch 107/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1681 - accuracy: 0.9388 - val_loss: 0.1877 - val_accuracy: 0.9312\n",
      "Epoch 108/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1678 - accuracy: 0.9390 - val_loss: 0.1870 - val_accuracy: 0.9313\n",
      "Epoch 109/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1674 - accuracy: 0.9388 - val_loss: 0.1868 - val_accuracy: 0.9314\n",
      "Epoch 110/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1672 - accuracy: 0.9389 - val_loss: 0.1866 - val_accuracy: 0.9317\n",
      "Epoch 111/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1668 - accuracy: 0.9391 - val_loss: 0.1862 - val_accuracy: 0.9319\n",
      "Epoch 112/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1665 - accuracy: 0.9392 - val_loss: 0.1862 - val_accuracy: 0.9321\n",
      "Epoch 113/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1661 - accuracy: 0.9394 - val_loss: 0.1855 - val_accuracy: 0.9318\n",
      "Epoch 114/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1659 - accuracy: 0.9394 - val_loss: 0.1852 - val_accuracy: 0.9321\n",
      "Epoch 115/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1656 - accuracy: 0.9394 - val_loss: 0.1848 - val_accuracy: 0.9321\n",
      "Epoch 116/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1652 - accuracy: 0.9396 - val_loss: 0.1849 - val_accuracy: 0.9321\n",
      "Epoch 117/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1649 - accuracy: 0.9397 - val_loss: 0.1850 - val_accuracy: 0.9320\n",
      "Epoch 118/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1647 - accuracy: 0.9398 - val_loss: 0.1841 - val_accuracy: 0.9316\n",
      "Epoch 119/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1643 - accuracy: 0.9398 - val_loss: 0.1843 - val_accuracy: 0.9323\n",
      "Epoch 120/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1640 - accuracy: 0.9401 - val_loss: 0.1837 - val_accuracy: 0.9325\n",
      "Epoch 121/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1637 - accuracy: 0.9401 - val_loss: 0.1836 - val_accuracy: 0.9321\n",
      "Epoch 122/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1634 - accuracy: 0.9401 - val_loss: 0.1831 - val_accuracy: 0.9326\n",
      "Epoch 123/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1631 - accuracy: 0.9403 - val_loss: 0.1832 - val_accuracy: 0.9326\n",
      "Epoch 124/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1628 - accuracy: 0.9404 - val_loss: 0.1824 - val_accuracy: 0.9326\n",
      "Epoch 125/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1624 - accuracy: 0.9403 - val_loss: 0.1825 - val_accuracy: 0.9328\n",
      "Epoch 126/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1622 - accuracy: 0.9406 - val_loss: 0.1818 - val_accuracy: 0.9328\n",
      "Epoch 127/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1619 - accuracy: 0.9407 - val_loss: 0.1814 - val_accuracy: 0.9332\n",
      "Epoch 128/800\n",
      "6000/6000 [==============================] - 1s 89us/step - loss: 0.1616 - accuracy: 0.9408 - val_loss: 0.1815 - val_accuracy: 0.9330\n",
      "Epoch 129/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1613 - accuracy: 0.9408 - val_loss: 0.1817 - val_accuracy: 0.9333\n",
      "Epoch 130/800\n",
      "6000/6000 [==============================] - 1s 85us/step - loss: 0.1611 - accuracy: 0.9409 - val_loss: 0.1808 - val_accuracy: 0.9333\n",
      "Epoch 131/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1608 - accuracy: 0.9410 - val_loss: 0.1807 - val_accuracy: 0.9333\n",
      "Epoch 132/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1606 - accuracy: 0.9411 - val_loss: 0.1802 - val_accuracy: 0.9333\n",
      "Epoch 133/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1603 - accuracy: 0.9413 - val_loss: 0.1802 - val_accuracy: 0.9332\n",
      "Epoch 134/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1600 - accuracy: 0.9411 - val_loss: 0.1804 - val_accuracy: 0.9333\n",
      "Epoch 135/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1597 - accuracy: 0.9414 - val_loss: 0.1798 - val_accuracy: 0.9339\n",
      "Epoch 136/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1594 - accuracy: 0.9414 - val_loss: 0.1800 - val_accuracy: 0.9335\n",
      "Epoch 137/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1591 - accuracy: 0.9416 - val_loss: 0.1792 - val_accuracy: 0.9339\n",
      "Epoch 138/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1589 - accuracy: 0.9418 - val_loss: 0.1789 - val_accuracy: 0.9341\n",
      "Epoch 139/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1586 - accuracy: 0.9418 - val_loss: 0.1786 - val_accuracy: 0.9339\n",
      "Epoch 140/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1583 - accuracy: 0.9418 - val_loss: 0.1784 - val_accuracy: 0.9337\n",
      "Epoch 141/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1580 - accuracy: 0.9420 - val_loss: 0.1780 - val_accuracy: 0.9344\n",
      "Epoch 142/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1577 - accuracy: 0.9421 - val_loss: 0.1782 - val_accuracy: 0.9345\n",
      "Epoch 143/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1574 - accuracy: 0.9422 - val_loss: 0.1777 - val_accuracy: 0.9344\n",
      "Epoch 144/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1572 - accuracy: 0.9423 - val_loss: 0.1776 - val_accuracy: 0.9343\n",
      "Epoch 145/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1568 - accuracy: 0.9424 - val_loss: 0.1773 - val_accuracy: 0.9347\n",
      "Epoch 146/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1566 - accuracy: 0.9424 - val_loss: 0.1770 - val_accuracy: 0.9348\n",
      "Epoch 147/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1563 - accuracy: 0.9426 - val_loss: 0.1764 - val_accuracy: 0.9346\n",
      "Epoch 148/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1561 - accuracy: 0.9427 - val_loss: 0.1766 - val_accuracy: 0.9343\n",
      "Epoch 149/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1558 - accuracy: 0.9428 - val_loss: 0.1766 - val_accuracy: 0.9349\n",
      "Epoch 150/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1556 - accuracy: 0.9428 - val_loss: 0.1762 - val_accuracy: 0.9350\n",
      "Epoch 151/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1553 - accuracy: 0.9430 - val_loss: 0.1756 - val_accuracy: 0.9349\n",
      "Epoch 152/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1550 - accuracy: 0.9430 - val_loss: 0.1754 - val_accuracy: 0.9352\n",
      "Epoch 153/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1548 - accuracy: 0.9432 - val_loss: 0.1758 - val_accuracy: 0.9355\n",
      "Epoch 154/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1546 - accuracy: 0.9432 - val_loss: 0.1753 - val_accuracy: 0.9358\n",
      "Epoch 155/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1544 - accuracy: 0.9433 - val_loss: 0.1752 - val_accuracy: 0.9356\n",
      "Epoch 156/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1540 - accuracy: 0.9434 - val_loss: 0.1745 - val_accuracy: 0.9359\n",
      "Epoch 157/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1538 - accuracy: 0.9434 - val_loss: 0.1751 - val_accuracy: 0.9364\n",
      "Epoch 158/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1536 - accuracy: 0.9435 - val_loss: 0.1741 - val_accuracy: 0.9357\n",
      "Epoch 159/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1534 - accuracy: 0.9436 - val_loss: 0.1739 - val_accuracy: 0.9359\n",
      "Epoch 160/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1531 - accuracy: 0.9436 - val_loss: 0.1736 - val_accuracy: 0.9357\n",
      "Epoch 161/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1529 - accuracy: 0.9437 - val_loss: 0.1737 - val_accuracy: 0.9358\n",
      "Epoch 162/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1527 - accuracy: 0.9438 - val_loss: 0.1736 - val_accuracy: 0.9364\n",
      "Epoch 163/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1525 - accuracy: 0.9440 - val_loss: 0.1732 - val_accuracy: 0.9361\n",
      "Epoch 164/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1522 - accuracy: 0.9439 - val_loss: 0.1733 - val_accuracy: 0.9359\n",
      "Epoch 165/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1521 - accuracy: 0.9440 - val_loss: 0.1731 - val_accuracy: 0.9362\n",
      "Epoch 166/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1519 - accuracy: 0.9442 - val_loss: 0.1724 - val_accuracy: 0.9361\n",
      "Epoch 167/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1516 - accuracy: 0.9442 - val_loss: 0.1726 - val_accuracy: 0.9359\n",
      "Epoch 168/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1514 - accuracy: 0.9443 - val_loss: 0.1734 - val_accuracy: 0.9368\n",
      "Epoch 169/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1512 - accuracy: 0.9443 - val_loss: 0.1722 - val_accuracy: 0.9368\n",
      "Epoch 170/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1512 - accuracy: 0.9443 - val_loss: 0.1720 - val_accuracy: 0.9369\n",
      "Epoch 171/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1509 - accuracy: 0.9444 - val_loss: 0.1720 - val_accuracy: 0.9369\n",
      "Epoch 172/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1507 - accuracy: 0.9444 - val_loss: 0.1715 - val_accuracy: 0.9368\n",
      "Epoch 173/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1504 - accuracy: 0.9445 - val_loss: 0.1713 - val_accuracy: 0.9370\n",
      "Epoch 174/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1504 - accuracy: 0.9444 - val_loss: 0.1716 - val_accuracy: 0.9369\n",
      "Epoch 175/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1502 - accuracy: 0.9446 - val_loss: 0.1710 - val_accuracy: 0.9365\n",
      "Epoch 176/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1500 - accuracy: 0.9447 - val_loss: 0.1711 - val_accuracy: 0.9367\n",
      "Epoch 177/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1499 - accuracy: 0.9448 - val_loss: 0.1706 - val_accuracy: 0.9367\n",
      "Epoch 178/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1496 - accuracy: 0.9447 - val_loss: 0.1707 - val_accuracy: 0.9368\n",
      "Epoch 179/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1494 - accuracy: 0.9447 - val_loss: 0.1707 - val_accuracy: 0.9369\n",
      "Epoch 180/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1493 - accuracy: 0.9450 - val_loss: 0.1709 - val_accuracy: 0.9365\n",
      "Epoch 181/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1491 - accuracy: 0.9450 - val_loss: 0.1701 - val_accuracy: 0.9374\n",
      "Epoch 182/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1489 - accuracy: 0.9450 - val_loss: 0.1706 - val_accuracy: 0.9366\n",
      "Epoch 183/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1488 - accuracy: 0.9451 - val_loss: 0.1706 - val_accuracy: 0.9368\n",
      "Epoch 184/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1486 - accuracy: 0.9452 - val_loss: 0.1702 - val_accuracy: 0.9370\n",
      "Epoch 185/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1484 - accuracy: 0.9450 - val_loss: 0.1698 - val_accuracy: 0.9373\n",
      "Epoch 186/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1483 - accuracy: 0.9451 - val_loss: 0.1702 - val_accuracy: 0.9374\n",
      "Epoch 187/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1481 - accuracy: 0.9454 - val_loss: 0.1695 - val_accuracy: 0.9372\n",
      "Epoch 188/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1480 - accuracy: 0.9451 - val_loss: 0.1693 - val_accuracy: 0.9375\n",
      "Epoch 189/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1478 - accuracy: 0.9454 - val_loss: 0.1696 - val_accuracy: 0.9371\n",
      "Epoch 190/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1476 - accuracy: 0.9453 - val_loss: 0.1697 - val_accuracy: 0.9373\n",
      "Epoch 191/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1475 - accuracy: 0.9455 - val_loss: 0.1692 - val_accuracy: 0.9375\n",
      "Epoch 192/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1473 - accuracy: 0.9456 - val_loss: 0.1694 - val_accuracy: 0.9372\n",
      "Epoch 193/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1472 - accuracy: 0.9455 - val_loss: 0.1689 - val_accuracy: 0.9378\n",
      "Epoch 194/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1470 - accuracy: 0.9455 - val_loss: 0.1696 - val_accuracy: 0.9372\n",
      "Epoch 195/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1468 - accuracy: 0.9457 - val_loss: 0.1687 - val_accuracy: 0.9371\n",
      "Epoch 196/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1467 - accuracy: 0.9457 - val_loss: 0.1688 - val_accuracy: 0.9376\n",
      "Epoch 197/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1465 - accuracy: 0.9459 - val_loss: 0.1685 - val_accuracy: 0.9373\n",
      "Epoch 198/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1464 - accuracy: 0.9459 - val_loss: 0.1682 - val_accuracy: 0.9378\n",
      "Epoch 199/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1463 - accuracy: 0.9457 - val_loss: 0.1685 - val_accuracy: 0.9378\n",
      "Epoch 200/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1460 - accuracy: 0.9458 - val_loss: 0.1686 - val_accuracy: 0.9377\n",
      "Epoch 201/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1459 - accuracy: 0.9459 - val_loss: 0.1681 - val_accuracy: 0.9379\n",
      "Epoch 202/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1457 - accuracy: 0.9458 - val_loss: 0.1682 - val_accuracy: 0.9380\n",
      "Epoch 203/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1456 - accuracy: 0.9460 - val_loss: 0.1687 - val_accuracy: 0.9377\n",
      "Epoch 204/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1454 - accuracy: 0.9462 - val_loss: 0.1676 - val_accuracy: 0.9383\n",
      "Epoch 205/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1452 - accuracy: 0.9461 - val_loss: 0.1677 - val_accuracy: 0.9376\n",
      "Epoch 206/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1451 - accuracy: 0.9463 - val_loss: 0.1677 - val_accuracy: 0.9381\n",
      "Epoch 207/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1450 - accuracy: 0.9461 - val_loss: 0.1678 - val_accuracy: 0.9378\n",
      "Epoch 208/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1449 - accuracy: 0.9463 - val_loss: 0.1672 - val_accuracy: 0.9377\n",
      "Epoch 209/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1446 - accuracy: 0.9463 - val_loss: 0.1674 - val_accuracy: 0.9382\n",
      "Epoch 210/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1446 - accuracy: 0.9463 - val_loss: 0.1674 - val_accuracy: 0.9377\n",
      "Epoch 211/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1444 - accuracy: 0.9465 - val_loss: 0.1673 - val_accuracy: 0.9378\n",
      "Epoch 212/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1443 - accuracy: 0.9466 - val_loss: 0.1670 - val_accuracy: 0.9381\n",
      "Epoch 213/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1441 - accuracy: 0.9463 - val_loss: 0.1664 - val_accuracy: 0.9381\n",
      "Epoch 214/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1439 - accuracy: 0.9464 - val_loss: 0.1669 - val_accuracy: 0.9382\n",
      "Epoch 215/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1438 - accuracy: 0.9466 - val_loss: 0.1669 - val_accuracy: 0.9378\n",
      "Epoch 216/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1437 - accuracy: 0.9466 - val_loss: 0.1664 - val_accuracy: 0.9383\n",
      "Epoch 217/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1436 - accuracy: 0.9468 - val_loss: 0.1665 - val_accuracy: 0.9387\n",
      "Epoch 218/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1433 - accuracy: 0.9468 - val_loss: 0.1664 - val_accuracy: 0.9385\n",
      "Epoch 219/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1432 - accuracy: 0.9468 - val_loss: 0.1667 - val_accuracy: 0.9380\n",
      "Epoch 220/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1431 - accuracy: 0.9469 - val_loss: 0.1660 - val_accuracy: 0.9381\n",
      "Epoch 221/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1430 - accuracy: 0.9469 - val_loss: 0.1659 - val_accuracy: 0.9383\n",
      "Epoch 222/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1428 - accuracy: 0.9471 - val_loss: 0.1659 - val_accuracy: 0.9385\n",
      "Epoch 223/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1427 - accuracy: 0.9471 - val_loss: 0.1659 - val_accuracy: 0.9386\n",
      "Epoch 224/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1425 - accuracy: 0.9471 - val_loss: 0.1656 - val_accuracy: 0.9385\n",
      "Epoch 225/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1424 - accuracy: 0.9470 - val_loss: 0.1661 - val_accuracy: 0.9387\n",
      "Epoch 226/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1423 - accuracy: 0.9472 - val_loss: 0.1662 - val_accuracy: 0.9385\n",
      "Epoch 227/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1421 - accuracy: 0.9473 - val_loss: 0.1652 - val_accuracy: 0.9383\n",
      "Epoch 228/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1420 - accuracy: 0.9473 - val_loss: 0.1654 - val_accuracy: 0.9383\n",
      "Epoch 229/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1419 - accuracy: 0.9473 - val_loss: 0.1656 - val_accuracy: 0.9383\n",
      "Epoch 230/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1417 - accuracy: 0.9473 - val_loss: 0.1655 - val_accuracy: 0.9385\n",
      "Epoch 231/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1416 - accuracy: 0.9473 - val_loss: 0.1655 - val_accuracy: 0.9383\n",
      "Epoch 232/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1414 - accuracy: 0.9476 - val_loss: 0.1655 - val_accuracy: 0.9384\n",
      "Epoch 233/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1413 - accuracy: 0.9475 - val_loss: 0.1653 - val_accuracy: 0.9383\n",
      "Epoch 234/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1411 - accuracy: 0.9475 - val_loss: 0.1650 - val_accuracy: 0.9383\n",
      "Epoch 235/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1410 - accuracy: 0.9475 - val_loss: 0.1649 - val_accuracy: 0.9385\n",
      "Epoch 236/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1408 - accuracy: 0.9477 - val_loss: 0.1647 - val_accuracy: 0.9386\n",
      "Epoch 237/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1407 - accuracy: 0.9476 - val_loss: 0.1647 - val_accuracy: 0.9386\n",
      "Epoch 238/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1406 - accuracy: 0.9476 - val_loss: 0.1646 - val_accuracy: 0.9388\n",
      "Epoch 239/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1405 - accuracy: 0.9477 - val_loss: 0.1644 - val_accuracy: 0.9383\n",
      "Epoch 240/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1403 - accuracy: 0.9478 - val_loss: 0.1644 - val_accuracy: 0.9386\n",
      "Epoch 241/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1401 - accuracy: 0.9478 - val_loss: 0.1642 - val_accuracy: 0.9387\n",
      "Epoch 242/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1401 - accuracy: 0.9480 - val_loss: 0.1645 - val_accuracy: 0.9382\n",
      "Epoch 243/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1399 - accuracy: 0.9480 - val_loss: 0.1643 - val_accuracy: 0.9387\n",
      "Epoch 244/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1398 - accuracy: 0.9479 - val_loss: 0.1642 - val_accuracy: 0.9388\n",
      "Epoch 245/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1396 - accuracy: 0.9480 - val_loss: 0.1643 - val_accuracy: 0.9387\n",
      "Epoch 246/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1396 - accuracy: 0.9481 - val_loss: 0.1636 - val_accuracy: 0.9389\n",
      "Epoch 247/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1394 - accuracy: 0.9481 - val_loss: 0.1641 - val_accuracy: 0.9388\n",
      "Epoch 248/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1393 - accuracy: 0.9482 - val_loss: 0.1639 - val_accuracy: 0.9387\n",
      "Epoch 249/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1392 - accuracy: 0.9482 - val_loss: 0.1636 - val_accuracy: 0.9391\n",
      "Epoch 250/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1390 - accuracy: 0.9483 - val_loss: 0.1635 - val_accuracy: 0.9393\n",
      "Epoch 251/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1389 - accuracy: 0.9482 - val_loss: 0.1634 - val_accuracy: 0.9391\n",
      "Epoch 252/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1388 - accuracy: 0.9483 - val_loss: 0.1636 - val_accuracy: 0.9393\n",
      "Epoch 253/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1386 - accuracy: 0.9483 - val_loss: 0.1640 - val_accuracy: 0.9387\n",
      "Epoch 254/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1385 - accuracy: 0.9484 - val_loss: 0.1634 - val_accuracy: 0.9386\n",
      "Epoch 255/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1383 - accuracy: 0.9485 - val_loss: 0.1631 - val_accuracy: 0.9387\n",
      "Epoch 256/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1382 - accuracy: 0.9485 - val_loss: 0.1635 - val_accuracy: 0.9386\n",
      "Epoch 257/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1380 - accuracy: 0.9486 - val_loss: 0.1633 - val_accuracy: 0.9392\n",
      "Epoch 258/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1381 - accuracy: 0.9484 - val_loss: 0.1640 - val_accuracy: 0.9391\n",
      "Epoch 259/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1379 - accuracy: 0.9486 - val_loss: 0.1635 - val_accuracy: 0.9387\n",
      "Epoch 260/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1377 - accuracy: 0.9485 - val_loss: 0.1632 - val_accuracy: 0.9391\n",
      "Epoch 261/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1377 - accuracy: 0.9486 - val_loss: 0.1628 - val_accuracy: 0.9394\n",
      "Epoch 262/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1375 - accuracy: 0.9487 - val_loss: 0.1627 - val_accuracy: 0.9394\n",
      "Epoch 263/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1374 - accuracy: 0.9487 - val_loss: 0.1625 - val_accuracy: 0.9392\n",
      "Epoch 264/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1373 - accuracy: 0.9489 - val_loss: 0.1624 - val_accuracy: 0.9394\n",
      "Epoch 265/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1371 - accuracy: 0.9487 - val_loss: 0.1627 - val_accuracy: 0.9391\n",
      "Epoch 266/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1370 - accuracy: 0.9488 - val_loss: 0.1622 - val_accuracy: 0.9390\n",
      "Epoch 267/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1369 - accuracy: 0.9489 - val_loss: 0.1625 - val_accuracy: 0.9396\n",
      "Epoch 268/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1368 - accuracy: 0.9490 - val_loss: 0.1626 - val_accuracy: 0.9391\n",
      "Epoch 269/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1367 - accuracy: 0.9489 - val_loss: 0.1622 - val_accuracy: 0.9394\n",
      "Epoch 270/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1366 - accuracy: 0.9490 - val_loss: 0.1624 - val_accuracy: 0.9392\n",
      "Epoch 271/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1364 - accuracy: 0.9492 - val_loss: 0.1624 - val_accuracy: 0.9389\n",
      "Epoch 272/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1362 - accuracy: 0.9490 - val_loss: 0.1630 - val_accuracy: 0.9390\n",
      "Epoch 273/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1362 - accuracy: 0.9490 - val_loss: 0.1625 - val_accuracy: 0.9389\n",
      "Epoch 274/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1361 - accuracy: 0.9491 - val_loss: 0.1616 - val_accuracy: 0.9395\n",
      "Epoch 275/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1360 - accuracy: 0.9492 - val_loss: 0.1619 - val_accuracy: 0.9396\n",
      "Epoch 276/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1358 - accuracy: 0.9494 - val_loss: 0.1615 - val_accuracy: 0.9393\n",
      "Epoch 277/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1357 - accuracy: 0.9493 - val_loss: 0.1624 - val_accuracy: 0.9391\n",
      "Epoch 278/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1356 - accuracy: 0.9494 - val_loss: 0.1621 - val_accuracy: 0.9393\n",
      "Epoch 279/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1355 - accuracy: 0.9495 - val_loss: 0.1622 - val_accuracy: 0.9395\n",
      "Epoch 280/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1354 - accuracy: 0.9493 - val_loss: 0.1616 - val_accuracy: 0.9394\n",
      "Epoch 281/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1353 - accuracy: 0.9494 - val_loss: 0.1613 - val_accuracy: 0.9395\n",
      "Epoch 282/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1352 - accuracy: 0.9494 - val_loss: 0.1613 - val_accuracy: 0.9398\n",
      "Epoch 283/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1351 - accuracy: 0.9495 - val_loss: 0.1621 - val_accuracy: 0.9398\n",
      "Epoch 284/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1349 - accuracy: 0.9495 - val_loss: 0.1613 - val_accuracy: 0.9395\n",
      "Epoch 285/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1348 - accuracy: 0.9496 - val_loss: 0.1611 - val_accuracy: 0.9397\n",
      "Epoch 286/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1347 - accuracy: 0.9495 - val_loss: 0.1607 - val_accuracy: 0.9396\n",
      "Epoch 287/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1346 - accuracy: 0.9496 - val_loss: 0.1612 - val_accuracy: 0.9396\n",
      "Epoch 288/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1345 - accuracy: 0.9496 - val_loss: 0.1613 - val_accuracy: 0.9393\n",
      "Epoch 289/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1344 - accuracy: 0.9496 - val_loss: 0.1612 - val_accuracy: 0.9389\n",
      "Epoch 290/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1343 - accuracy: 0.9498 - val_loss: 0.1616 - val_accuracy: 0.9400\n",
      "Epoch 291/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1342 - accuracy: 0.9499 - val_loss: 0.1612 - val_accuracy: 0.9394\n",
      "Epoch 292/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1340 - accuracy: 0.9498 - val_loss: 0.1610 - val_accuracy: 0.9399\n",
      "Epoch 293/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1339 - accuracy: 0.9498 - val_loss: 0.1610 - val_accuracy: 0.9399\n",
      "Epoch 294/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1338 - accuracy: 0.9501 - val_loss: 0.1607 - val_accuracy: 0.9401\n",
      "Epoch 295/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1337 - accuracy: 0.9498 - val_loss: 0.1608 - val_accuracy: 0.9399\n",
      "Epoch 296/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1336 - accuracy: 0.9500 - val_loss: 0.1607 - val_accuracy: 0.9400\n",
      "Epoch 297/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1336 - accuracy: 0.9500 - val_loss: 0.1606 - val_accuracy: 0.9396\n",
      "Epoch 298/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1334 - accuracy: 0.9502 - val_loss: 0.1606 - val_accuracy: 0.9397\n",
      "Epoch 299/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1332 - accuracy: 0.9501 - val_loss: 0.1605 - val_accuracy: 0.9396\n",
      "Epoch 300/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1332 - accuracy: 0.9503 - val_loss: 0.1607 - val_accuracy: 0.9401\n",
      "Epoch 301/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1331 - accuracy: 0.9499 - val_loss: 0.1604 - val_accuracy: 0.9398\n",
      "Epoch 302/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1329 - accuracy: 0.9503 - val_loss: 0.1608 - val_accuracy: 0.9399\n",
      "Epoch 303/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1328 - accuracy: 0.9502 - val_loss: 0.1601 - val_accuracy: 0.9396\n",
      "Epoch 304/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1328 - accuracy: 0.9502 - val_loss: 0.1602 - val_accuracy: 0.9403\n",
      "Epoch 305/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1327 - accuracy: 0.9502 - val_loss: 0.1600 - val_accuracy: 0.9398\n",
      "Epoch 306/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1326 - accuracy: 0.9503 - val_loss: 0.1602 - val_accuracy: 0.9400\n",
      "Epoch 307/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1325 - accuracy: 0.9504 - val_loss: 0.1603 - val_accuracy: 0.9399\n",
      "Epoch 308/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1324 - accuracy: 0.9503 - val_loss: 0.1601 - val_accuracy: 0.9398\n",
      "Epoch 309/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1323 - accuracy: 0.9503 - val_loss: 0.1602 - val_accuracy: 0.9404\n",
      "Epoch 310/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1322 - accuracy: 0.9504 - val_loss: 0.1601 - val_accuracy: 0.9399\n",
      "Epoch 311/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1321 - accuracy: 0.9504 - val_loss: 0.1601 - val_accuracy: 0.9400\n",
      "Epoch 312/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1319 - accuracy: 0.9504 - val_loss: 0.1599 - val_accuracy: 0.9406\n",
      "Epoch 313/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1318 - accuracy: 0.9504 - val_loss: 0.1599 - val_accuracy: 0.9397\n",
      "Epoch 314/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1317 - accuracy: 0.9505 - val_loss: 0.1605 - val_accuracy: 0.9396\n",
      "Epoch 315/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1315 - accuracy: 0.9507 - val_loss: 0.1598 - val_accuracy: 0.9399\n",
      "Epoch 316/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1315 - accuracy: 0.9507 - val_loss: 0.1599 - val_accuracy: 0.9397\n",
      "Epoch 317/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1314 - accuracy: 0.9507 - val_loss: 0.1604 - val_accuracy: 0.9396\n",
      "Epoch 318/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1313 - accuracy: 0.9507 - val_loss: 0.1597 - val_accuracy: 0.9402\n",
      "Epoch 319/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1313 - accuracy: 0.9507 - val_loss: 0.1594 - val_accuracy: 0.9399\n",
      "Epoch 320/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1311 - accuracy: 0.9509 - val_loss: 0.1596 - val_accuracy: 0.9399\n",
      "Epoch 321/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1310 - accuracy: 0.9507 - val_loss: 0.1592 - val_accuracy: 0.9405\n",
      "Epoch 322/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1309 - accuracy: 0.9508 - val_loss: 0.1593 - val_accuracy: 0.9405\n",
      "Epoch 323/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1308 - accuracy: 0.9508 - val_loss: 0.1598 - val_accuracy: 0.9405\n",
      "Epoch 324/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1308 - accuracy: 0.9508 - val_loss: 0.1594 - val_accuracy: 0.9404\n",
      "Epoch 325/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1306 - accuracy: 0.9509 - val_loss: 0.1594 - val_accuracy: 0.9406\n",
      "Epoch 326/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1306 - accuracy: 0.9510 - val_loss: 0.1592 - val_accuracy: 0.9401\n",
      "Epoch 327/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1305 - accuracy: 0.9508 - val_loss: 0.1591 - val_accuracy: 0.9405\n",
      "Epoch 328/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1304 - accuracy: 0.9511 - val_loss: 0.1589 - val_accuracy: 0.9404\n",
      "Epoch 329/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1302 - accuracy: 0.9510 - val_loss: 0.1590 - val_accuracy: 0.9404\n",
      "Epoch 330/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1302 - accuracy: 0.9510 - val_loss: 0.1600 - val_accuracy: 0.9405\n",
      "Epoch 331/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1300 - accuracy: 0.9510 - val_loss: 0.1591 - val_accuracy: 0.9399\n",
      "Epoch 332/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1300 - accuracy: 0.9510 - val_loss: 0.1590 - val_accuracy: 0.9406\n",
      "Epoch 333/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1299 - accuracy: 0.9513 - val_loss: 0.1589 - val_accuracy: 0.9405\n",
      "Epoch 334/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1298 - accuracy: 0.9510 - val_loss: 0.1586 - val_accuracy: 0.9404\n",
      "Epoch 335/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1297 - accuracy: 0.9511 - val_loss: 0.1591 - val_accuracy: 0.9402\n",
      "Epoch 336/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1296 - accuracy: 0.9512 - val_loss: 0.1596 - val_accuracy: 0.9396\n",
      "Epoch 337/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1295 - accuracy: 0.9513 - val_loss: 0.1588 - val_accuracy: 0.9403\n",
      "Epoch 338/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1294 - accuracy: 0.9514 - val_loss: 0.1595 - val_accuracy: 0.9400\n",
      "Epoch 339/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1294 - accuracy: 0.9514 - val_loss: 0.1589 - val_accuracy: 0.9406\n",
      "Epoch 340/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1292 - accuracy: 0.9513 - val_loss: 0.1593 - val_accuracy: 0.9404\n",
      "Epoch 341/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1292 - accuracy: 0.9514 - val_loss: 0.1590 - val_accuracy: 0.9406\n",
      "Epoch 342/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1290 - accuracy: 0.9513 - val_loss: 0.1590 - val_accuracy: 0.9405\n",
      "Epoch 343/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1290 - accuracy: 0.9513 - val_loss: 0.1586 - val_accuracy: 0.9405\n",
      "Epoch 344/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1289 - accuracy: 0.9515 - val_loss: 0.1582 - val_accuracy: 0.9402\n",
      "Epoch 345/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1288 - accuracy: 0.9515 - val_loss: 0.1588 - val_accuracy: 0.9402\n",
      "Epoch 346/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1287 - accuracy: 0.9516 - val_loss: 0.1588 - val_accuracy: 0.9406\n",
      "Epoch 347/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1286 - accuracy: 0.9516 - val_loss: 0.1588 - val_accuracy: 0.9402\n",
      "Epoch 348/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1285 - accuracy: 0.9515 - val_loss: 0.1585 - val_accuracy: 0.9408\n",
      "Epoch 349/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1284 - accuracy: 0.9515 - val_loss: 0.1584 - val_accuracy: 0.9403\n",
      "Epoch 350/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1284 - accuracy: 0.9516 - val_loss: 0.1588 - val_accuracy: 0.9403\n",
      "Epoch 351/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1283 - accuracy: 0.9516 - val_loss: 0.1585 - val_accuracy: 0.9405\n",
      "Epoch 352/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1281 - accuracy: 0.9517 - val_loss: 0.1584 - val_accuracy: 0.9405\n",
      "Epoch 353/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1282 - accuracy: 0.9516 - val_loss: 0.1585 - val_accuracy: 0.9409\n",
      "Epoch 354/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1280 - accuracy: 0.9518 - val_loss: 0.1580 - val_accuracy: 0.9410\n",
      "Epoch 355/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1280 - accuracy: 0.9517 - val_loss: 0.1586 - val_accuracy: 0.9400\n",
      "Epoch 356/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1279 - accuracy: 0.9518 - val_loss: 0.1592 - val_accuracy: 0.9405\n",
      "Epoch 357/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1278 - accuracy: 0.9517 - val_loss: 0.1588 - val_accuracy: 0.9407\n",
      "Epoch 358/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1276 - accuracy: 0.9519 - val_loss: 0.1585 - val_accuracy: 0.9408\n",
      "Epoch 359/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1275 - accuracy: 0.9519 - val_loss: 0.1579 - val_accuracy: 0.9408\n",
      "Epoch 360/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1275 - accuracy: 0.9518 - val_loss: 0.1587 - val_accuracy: 0.9407\n",
      "Epoch 361/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1275 - accuracy: 0.9519 - val_loss: 0.1584 - val_accuracy: 0.9410\n",
      "Epoch 362/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1274 - accuracy: 0.9518 - val_loss: 0.1581 - val_accuracy: 0.9407\n",
      "Epoch 363/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1272 - accuracy: 0.9517 - val_loss: 0.1578 - val_accuracy: 0.9406\n",
      "Epoch 364/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1271 - accuracy: 0.9521 - val_loss: 0.1589 - val_accuracy: 0.9404\n",
      "Epoch 365/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1270 - accuracy: 0.9520 - val_loss: 0.1578 - val_accuracy: 0.9405\n",
      "Epoch 366/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1270 - accuracy: 0.9520 - val_loss: 0.1579 - val_accuracy: 0.9407\n",
      "Epoch 367/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1269 - accuracy: 0.9520 - val_loss: 0.1581 - val_accuracy: 0.9404\n",
      "Epoch 368/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1268 - accuracy: 0.9521 - val_loss: 0.1583 - val_accuracy: 0.9408\n",
      "Epoch 369/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1268 - accuracy: 0.9519 - val_loss: 0.1583 - val_accuracy: 0.9405\n",
      "Epoch 370/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1267 - accuracy: 0.9521 - val_loss: 0.1582 - val_accuracy: 0.9405\n",
      "Epoch 371/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1266 - accuracy: 0.9522 - val_loss: 0.1580 - val_accuracy: 0.9399\n",
      "Epoch 372/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1265 - accuracy: 0.9521 - val_loss: 0.1580 - val_accuracy: 0.9409\n",
      "Epoch 373/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1264 - accuracy: 0.9522 - val_loss: 0.1583 - val_accuracy: 0.9409\n",
      "Epoch 374/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1262 - accuracy: 0.9522 - val_loss: 0.1583 - val_accuracy: 0.9408\n",
      "Epoch 375/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1263 - accuracy: 0.9522 - val_loss: 0.1579 - val_accuracy: 0.9406\n",
      "Epoch 376/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1261 - accuracy: 0.9523 - val_loss: 0.1587 - val_accuracy: 0.9402\n",
      "Epoch 377/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1260 - accuracy: 0.9523 - val_loss: 0.1584 - val_accuracy: 0.9410\n",
      "Epoch 378/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1260 - accuracy: 0.9523 - val_loss: 0.1579 - val_accuracy: 0.9409\n",
      "Epoch 379/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1260 - accuracy: 0.9524 - val_loss: 0.1581 - val_accuracy: 0.9405\n",
      "Epoch 380/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1258 - accuracy: 0.9524 - val_loss: 0.1590 - val_accuracy: 0.9401\n",
      "Epoch 381/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1258 - accuracy: 0.9524 - val_loss: 0.1581 - val_accuracy: 0.9410\n",
      "Epoch 382/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1257 - accuracy: 0.9522 - val_loss: 0.1578 - val_accuracy: 0.9404\n",
      "Epoch 383/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1256 - accuracy: 0.9524 - val_loss: 0.1584 - val_accuracy: 0.9406\n",
      "Epoch 384/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1256 - accuracy: 0.9521 - val_loss: 0.1572 - val_accuracy: 0.9401\n",
      "Epoch 385/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1254 - accuracy: 0.9525 - val_loss: 0.1584 - val_accuracy: 0.9410\n",
      "Epoch 386/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1254 - accuracy: 0.9525 - val_loss: 0.1575 - val_accuracy: 0.9405\n",
      "Epoch 387/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1254 - accuracy: 0.9525 - val_loss: 0.1577 - val_accuracy: 0.9407\n",
      "Epoch 388/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1252 - accuracy: 0.9525 - val_loss: 0.1578 - val_accuracy: 0.9411\n",
      "Epoch 389/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1252 - accuracy: 0.9524 - val_loss: 0.1577 - val_accuracy: 0.9405\n",
      "Epoch 390/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1251 - accuracy: 0.9526 - val_loss: 0.1576 - val_accuracy: 0.9405\n",
      "Epoch 391/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1250 - accuracy: 0.9525 - val_loss: 0.1581 - val_accuracy: 0.9400\n",
      "Epoch 392/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1250 - accuracy: 0.9525 - val_loss: 0.1578 - val_accuracy: 0.9411\n",
      "Epoch 393/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1248 - accuracy: 0.9527 - val_loss: 0.1573 - val_accuracy: 0.9408\n",
      "Epoch 394/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1248 - accuracy: 0.9529 - val_loss: 0.1577 - val_accuracy: 0.9409\n",
      "Epoch 395/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1247 - accuracy: 0.9527 - val_loss: 0.1579 - val_accuracy: 0.9411\n",
      "Epoch 396/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1246 - accuracy: 0.9526 - val_loss: 0.1575 - val_accuracy: 0.9409\n",
      "Epoch 397/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1245 - accuracy: 0.9529 - val_loss: 0.1577 - val_accuracy: 0.9406\n",
      "Epoch 398/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1244 - accuracy: 0.9525 - val_loss: 0.1581 - val_accuracy: 0.9405\n",
      "Epoch 399/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1245 - accuracy: 0.9525 - val_loss: 0.1574 - val_accuracy: 0.9412\n",
      "Epoch 400/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1243 - accuracy: 0.9527 - val_loss: 0.1574 - val_accuracy: 0.9407\n",
      "Epoch 401/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1243 - accuracy: 0.9527 - val_loss: 0.1575 - val_accuracy: 0.9412\n",
      "Epoch 402/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1242 - accuracy: 0.9527 - val_loss: 0.1572 - val_accuracy: 0.9407\n",
      "Epoch 403/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1241 - accuracy: 0.9528 - val_loss: 0.1578 - val_accuracy: 0.9407\n",
      "Epoch 404/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1241 - accuracy: 0.9528 - val_loss: 0.1575 - val_accuracy: 0.9408\n",
      "Epoch 405/800\n",
      "6000/6000 [==============================] - 1s 92us/step - loss: 0.1240 - accuracy: 0.9529 - val_loss: 0.1576 - val_accuracy: 0.9406\n",
      "Epoch 406/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1239 - accuracy: 0.9528 - val_loss: 0.1581 - val_accuracy: 0.9403\n",
      "Epoch 407/800\n",
      "6000/6000 [==============================] - 1s 90us/step - loss: 0.1238 - accuracy: 0.9530 - val_loss: 0.1568 - val_accuracy: 0.9411\n",
      "Epoch 408/800\n",
      "6000/6000 [==============================] - 1s 93us/step - loss: 0.1238 - accuracy: 0.9529 - val_loss: 0.1574 - val_accuracy: 0.9406\n",
      "Epoch 409/800\n",
      "6000/6000 [==============================] - 1s 92us/step - loss: 0.1236 - accuracy: 0.9530 - val_loss: 0.1575 - val_accuracy: 0.9409\n",
      "Epoch 410/800\n",
      "6000/6000 [==============================] - 1s 88us/step - loss: 0.1235 - accuracy: 0.9530 - val_loss: 0.1579 - val_accuracy: 0.9410\n",
      "Epoch 411/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1235 - accuracy: 0.9530 - val_loss: 0.1572 - val_accuracy: 0.9407\n",
      "Epoch 412/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1234 - accuracy: 0.9530 - val_loss: 0.1576 - val_accuracy: 0.9409\n",
      "Epoch 413/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1234 - accuracy: 0.9529 - val_loss: 0.1576 - val_accuracy: 0.9406\n",
      "Epoch 414/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1233 - accuracy: 0.9528 - val_loss: 0.1578 - val_accuracy: 0.9406\n",
      "Epoch 415/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1232 - accuracy: 0.9531 - val_loss: 0.1573 - val_accuracy: 0.9410\n",
      "Epoch 416/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1232 - accuracy: 0.9531 - val_loss: 0.1581 - val_accuracy: 0.9409\n",
      "Epoch 417/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1231 - accuracy: 0.9532 - val_loss: 0.1575 - val_accuracy: 0.9407\n",
      "Epoch 418/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1230 - accuracy: 0.9532 - val_loss: 0.1574 - val_accuracy: 0.9406\n",
      "Epoch 419/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1230 - accuracy: 0.9531 - val_loss: 0.1578 - val_accuracy: 0.9401\n",
      "Epoch 420/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1229 - accuracy: 0.9532 - val_loss: 0.1575 - val_accuracy: 0.9404\n",
      "Epoch 421/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1228 - accuracy: 0.9532 - val_loss: 0.1575 - val_accuracy: 0.9409\n",
      "Epoch 422/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1228 - accuracy: 0.9532 - val_loss: 0.1572 - val_accuracy: 0.9405\n",
      "Epoch 423/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1226 - accuracy: 0.9532 - val_loss: 0.1576 - val_accuracy: 0.9411\n",
      "Epoch 424/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1225 - accuracy: 0.9531 - val_loss: 0.1570 - val_accuracy: 0.9407\n",
      "Epoch 425/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1225 - accuracy: 0.9532 - val_loss: 0.1577 - val_accuracy: 0.9408\n",
      "Epoch 426/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1224 - accuracy: 0.9531 - val_loss: 0.1574 - val_accuracy: 0.9412\n",
      "Epoch 427/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1224 - accuracy: 0.9532 - val_loss: 0.1574 - val_accuracy: 0.9409\n",
      "Epoch 428/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1223 - accuracy: 0.9534 - val_loss: 0.1576 - val_accuracy: 0.9400\n",
      "Epoch 429/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1222 - accuracy: 0.9532 - val_loss: 0.1570 - val_accuracy: 0.9408\n",
      "Epoch 430/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1222 - accuracy: 0.9534 - val_loss: 0.1577 - val_accuracy: 0.9404\n",
      "Epoch 431/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1220 - accuracy: 0.9534 - val_loss: 0.1582 - val_accuracy: 0.9409\n",
      "Epoch 432/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1221 - accuracy: 0.9534 - val_loss: 0.1577 - val_accuracy: 0.9407\n",
      "Epoch 433/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1220 - accuracy: 0.9533 - val_loss: 0.1573 - val_accuracy: 0.9407\n",
      "Epoch 434/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1219 - accuracy: 0.9535 - val_loss: 0.1574 - val_accuracy: 0.9409\n",
      "Epoch 435/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1218 - accuracy: 0.9532 - val_loss: 0.1574 - val_accuracy: 0.9406\n",
      "Epoch 436/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1217 - accuracy: 0.9535 - val_loss: 0.1579 - val_accuracy: 0.9403\n",
      "Epoch 437/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1217 - accuracy: 0.9536 - val_loss: 0.1573 - val_accuracy: 0.9411\n",
      "Epoch 438/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1216 - accuracy: 0.9535 - val_loss: 0.1573 - val_accuracy: 0.9410\n",
      "Epoch 439/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1215 - accuracy: 0.9534 - val_loss: 0.1575 - val_accuracy: 0.9414\n",
      "Epoch 440/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1214 - accuracy: 0.9536 - val_loss: 0.1574 - val_accuracy: 0.9408\n",
      "Epoch 441/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1213 - accuracy: 0.9536 - val_loss: 0.1573 - val_accuracy: 0.9404\n",
      "Epoch 442/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1214 - accuracy: 0.9536 - val_loss: 0.1575 - val_accuracy: 0.9405\n",
      "Epoch 443/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1212 - accuracy: 0.9538 - val_loss: 0.1582 - val_accuracy: 0.9408\n",
      "Epoch 444/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1212 - accuracy: 0.9534 - val_loss: 0.1572 - val_accuracy: 0.9407\n",
      "Epoch 445/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1211 - accuracy: 0.9537 - val_loss: 0.1580 - val_accuracy: 0.9407\n",
      "Epoch 446/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1210 - accuracy: 0.9538 - val_loss: 0.1573 - val_accuracy: 0.9409\n",
      "Epoch 447/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1210 - accuracy: 0.9538 - val_loss: 0.1579 - val_accuracy: 0.9406\n",
      "Epoch 448/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1209 - accuracy: 0.9536 - val_loss: 0.1569 - val_accuracy: 0.9409\n",
      "Epoch 449/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1209 - accuracy: 0.9537 - val_loss: 0.1581 - val_accuracy: 0.9408\n",
      "Epoch 450/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1208 - accuracy: 0.9538 - val_loss: 0.1583 - val_accuracy: 0.9402\n",
      "Epoch 451/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1207 - accuracy: 0.9538 - val_loss: 0.1573 - val_accuracy: 0.9412\n",
      "Epoch 452/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1207 - accuracy: 0.9536 - val_loss: 0.1579 - val_accuracy: 0.9409\n",
      "Epoch 453/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1205 - accuracy: 0.9536 - val_loss: 0.1583 - val_accuracy: 0.9404\n",
      "Epoch 454/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1205 - accuracy: 0.9537 - val_loss: 0.1572 - val_accuracy: 0.9409\n",
      "Epoch 455/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1205 - accuracy: 0.9538 - val_loss: 0.1573 - val_accuracy: 0.9410\n",
      "Epoch 456/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1204 - accuracy: 0.9538 - val_loss: 0.1577 - val_accuracy: 0.9403\n",
      "Epoch 457/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1203 - accuracy: 0.9540 - val_loss: 0.1572 - val_accuracy: 0.9406\n",
      "Epoch 458/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1204 - accuracy: 0.9538 - val_loss: 0.1578 - val_accuracy: 0.9405\n",
      "Epoch 459/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1202 - accuracy: 0.9539 - val_loss: 0.1584 - val_accuracy: 0.9409\n",
      "Epoch 460/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1200 - accuracy: 0.9539 - val_loss: 0.1580 - val_accuracy: 0.9401\n",
      "Epoch 461/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1200 - accuracy: 0.9540 - val_loss: 0.1577 - val_accuracy: 0.9404\n",
      "Epoch 462/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1200 - accuracy: 0.9539 - val_loss: 0.1577 - val_accuracy: 0.9408\n",
      "Epoch 463/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1199 - accuracy: 0.9541 - val_loss: 0.1569 - val_accuracy: 0.9407\n",
      "Epoch 464/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1198 - accuracy: 0.9540 - val_loss: 0.1576 - val_accuracy: 0.9402\n",
      "Epoch 465/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1198 - accuracy: 0.9540 - val_loss: 0.1570 - val_accuracy: 0.9411\n",
      "Epoch 466/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1197 - accuracy: 0.9540 - val_loss: 0.1585 - val_accuracy: 0.9404\n",
      "Epoch 467/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1196 - accuracy: 0.9542 - val_loss: 0.1577 - val_accuracy: 0.9404\n",
      "Epoch 468/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1196 - accuracy: 0.9541 - val_loss: 0.1575 - val_accuracy: 0.9410\n",
      "Epoch 469/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1195 - accuracy: 0.9543 - val_loss: 0.1583 - val_accuracy: 0.9407\n",
      "Epoch 470/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1195 - accuracy: 0.9542 - val_loss: 0.1575 - val_accuracy: 0.9407\n",
      "Epoch 471/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1194 - accuracy: 0.9542 - val_loss: 0.1576 - val_accuracy: 0.9403\n",
      "Epoch 472/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1193 - accuracy: 0.9539 - val_loss: 0.1574 - val_accuracy: 0.9411\n",
      "Epoch 473/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1191 - accuracy: 0.9541 - val_loss: 0.1572 - val_accuracy: 0.9406\n",
      "Epoch 474/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1191 - accuracy: 0.9540 - val_loss: 0.1574 - val_accuracy: 0.9406\n",
      "Epoch 475/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1191 - accuracy: 0.9541 - val_loss: 0.1580 - val_accuracy: 0.9408\n",
      "Epoch 476/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1191 - accuracy: 0.9541 - val_loss: 0.1577 - val_accuracy: 0.9406\n",
      "Epoch 477/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1191 - accuracy: 0.9542 - val_loss: 0.1575 - val_accuracy: 0.9402\n",
      "Epoch 478/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1189 - accuracy: 0.9542 - val_loss: 0.1575 - val_accuracy: 0.9406\n",
      "Epoch 479/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1188 - accuracy: 0.9543 - val_loss: 0.1569 - val_accuracy: 0.9410\n",
      "Epoch 480/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1188 - accuracy: 0.9543 - val_loss: 0.1573 - val_accuracy: 0.9411\n",
      "Epoch 481/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1188 - accuracy: 0.9544 - val_loss: 0.1579 - val_accuracy: 0.9408\n",
      "Epoch 482/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1186 - accuracy: 0.9543 - val_loss: 0.1588 - val_accuracy: 0.9403\n",
      "Epoch 483/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1186 - accuracy: 0.9546 - val_loss: 0.1575 - val_accuracy: 0.9408\n",
      "Epoch 484/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1185 - accuracy: 0.9543 - val_loss: 0.1572 - val_accuracy: 0.9407\n",
      "Epoch 485/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1183 - accuracy: 0.9546 - val_loss: 0.1577 - val_accuracy: 0.9406\n",
      "Epoch 486/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1184 - accuracy: 0.9543 - val_loss: 0.1574 - val_accuracy: 0.9406\n",
      "Epoch 487/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1184 - accuracy: 0.9543 - val_loss: 0.1579 - val_accuracy: 0.9405\n",
      "Epoch 488/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1183 - accuracy: 0.9545 - val_loss: 0.1578 - val_accuracy: 0.9409\n",
      "Epoch 489/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1182 - accuracy: 0.9545 - val_loss: 0.1574 - val_accuracy: 0.9407\n",
      "Epoch 490/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1181 - accuracy: 0.9544 - val_loss: 0.1573 - val_accuracy: 0.9405\n",
      "Epoch 491/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1181 - accuracy: 0.9544 - val_loss: 0.1570 - val_accuracy: 0.9409\n",
      "Epoch 492/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1180 - accuracy: 0.9547 - val_loss: 0.1583 - val_accuracy: 0.9405\n",
      "Epoch 493/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1179 - accuracy: 0.9547 - val_loss: 0.1576 - val_accuracy: 0.9404\n",
      "Epoch 494/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1180 - accuracy: 0.9545 - val_loss: 0.1577 - val_accuracy: 0.9402\n",
      "Epoch 495/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1179 - accuracy: 0.9545 - val_loss: 0.1577 - val_accuracy: 0.9408\n",
      "Epoch 496/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1177 - accuracy: 0.9547 - val_loss: 0.1573 - val_accuracy: 0.9409\n",
      "Epoch 497/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1178 - accuracy: 0.9547 - val_loss: 0.1584 - val_accuracy: 0.9408\n",
      "Epoch 498/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1176 - accuracy: 0.9547 - val_loss: 0.1571 - val_accuracy: 0.9406\n",
      "Epoch 499/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1176 - accuracy: 0.9545 - val_loss: 0.1575 - val_accuracy: 0.9406\n",
      "Epoch 500/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1175 - accuracy: 0.9547 - val_loss: 0.1580 - val_accuracy: 0.9410\n",
      "Epoch 501/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1175 - accuracy: 0.9547 - val_loss: 0.1576 - val_accuracy: 0.9412\n",
      "Epoch 502/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1174 - accuracy: 0.9547 - val_loss: 0.1580 - val_accuracy: 0.9415\n",
      "Epoch 503/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1172 - accuracy: 0.9549 - val_loss: 0.1577 - val_accuracy: 0.9411\n",
      "Epoch 504/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1171 - accuracy: 0.9548 - val_loss: 0.1580 - val_accuracy: 0.9405\n",
      "Epoch 505/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1173 - accuracy: 0.9548 - val_loss: 0.1576 - val_accuracy: 0.9404\n",
      "Epoch 506/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1172 - accuracy: 0.9546 - val_loss: 0.1583 - val_accuracy: 0.9402\n",
      "Epoch 507/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1171 - accuracy: 0.9550 - val_loss: 0.1580 - val_accuracy: 0.9409\n",
      "Epoch 508/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1170 - accuracy: 0.9548 - val_loss: 0.1575 - val_accuracy: 0.9408\n",
      "Epoch 509/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1169 - accuracy: 0.9550 - val_loss: 0.1581 - val_accuracy: 0.9406\n",
      "Epoch 510/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1168 - accuracy: 0.9550 - val_loss: 0.1576 - val_accuracy: 0.9414\n",
      "Epoch 511/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1168 - accuracy: 0.9550 - val_loss: 0.1580 - val_accuracy: 0.9410\n",
      "Epoch 512/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1168 - accuracy: 0.9548 - val_loss: 0.1589 - val_accuracy: 0.9406\n",
      "Epoch 513/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1167 - accuracy: 0.9551 - val_loss: 0.1587 - val_accuracy: 0.9405\n",
      "Epoch 514/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1166 - accuracy: 0.9549 - val_loss: 0.1585 - val_accuracy: 0.9399\n",
      "Epoch 515/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1165 - accuracy: 0.9551 - val_loss: 0.1578 - val_accuracy: 0.9408\n",
      "Epoch 516/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1165 - accuracy: 0.9551 - val_loss: 0.1577 - val_accuracy: 0.9408\n",
      "Epoch 517/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1164 - accuracy: 0.9550 - val_loss: 0.1590 - val_accuracy: 0.9406\n",
      "Epoch 518/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1164 - accuracy: 0.9550 - val_loss: 0.1581 - val_accuracy: 0.9407\n",
      "Epoch 519/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1163 - accuracy: 0.9550 - val_loss: 0.1585 - val_accuracy: 0.9401\n",
      "Epoch 520/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1162 - accuracy: 0.9552 - val_loss: 0.1576 - val_accuracy: 0.9410\n",
      "Epoch 521/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1162 - accuracy: 0.9551 - val_loss: 0.1586 - val_accuracy: 0.9407\n",
      "Epoch 522/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1161 - accuracy: 0.9551 - val_loss: 0.1582 - val_accuracy: 0.9407\n",
      "Epoch 523/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1161 - accuracy: 0.9552 - val_loss: 0.1580 - val_accuracy: 0.9409\n",
      "Epoch 524/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1160 - accuracy: 0.9551 - val_loss: 0.1583 - val_accuracy: 0.9404\n",
      "Epoch 525/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1158 - accuracy: 0.9554 - val_loss: 0.1579 - val_accuracy: 0.9409\n",
      "Epoch 526/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1158 - accuracy: 0.9553 - val_loss: 0.1589 - val_accuracy: 0.9398\n",
      "Epoch 527/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1158 - accuracy: 0.9552 - val_loss: 0.1594 - val_accuracy: 0.9404\n",
      "Epoch 528/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1156 - accuracy: 0.9554 - val_loss: 0.1582 - val_accuracy: 0.9405\n",
      "Epoch 529/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1157 - accuracy: 0.9554 - val_loss: 0.1581 - val_accuracy: 0.9399\n",
      "Epoch 530/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1157 - accuracy: 0.9550 - val_loss: 0.1581 - val_accuracy: 0.9409\n",
      "Epoch 531/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1153 - accuracy: 0.9554 - val_loss: 0.1591 - val_accuracy: 0.9402\n",
      "Epoch 532/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1154 - accuracy: 0.9557 - val_loss: 0.1588 - val_accuracy: 0.9399\n",
      "Epoch 533/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1154 - accuracy: 0.9554 - val_loss: 0.1588 - val_accuracy: 0.9404\n",
      "Epoch 534/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1154 - accuracy: 0.9556 - val_loss: 0.1580 - val_accuracy: 0.9410\n",
      "Epoch 535/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1153 - accuracy: 0.9554 - val_loss: 0.1587 - val_accuracy: 0.9407\n",
      "Epoch 536/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1153 - accuracy: 0.9554 - val_loss: 0.1583 - val_accuracy: 0.9401\n",
      "Epoch 537/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1152 - accuracy: 0.9556 - val_loss: 0.1577 - val_accuracy: 0.9409\n",
      "Epoch 538/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1151 - accuracy: 0.9553 - val_loss: 0.1581 - val_accuracy: 0.9401\n",
      "Epoch 539/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1151 - accuracy: 0.9554 - val_loss: 0.1590 - val_accuracy: 0.9403\n",
      "Epoch 540/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1149 - accuracy: 0.9556 - val_loss: 0.1589 - val_accuracy: 0.9401\n",
      "Epoch 541/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1149 - accuracy: 0.9554 - val_loss: 0.1579 - val_accuracy: 0.9406\n",
      "Epoch 542/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1148 - accuracy: 0.9558 - val_loss: 0.1592 - val_accuracy: 0.9405\n",
      "Epoch 543/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1149 - accuracy: 0.9556 - val_loss: 0.1585 - val_accuracy: 0.9406\n",
      "Epoch 544/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1147 - accuracy: 0.9556 - val_loss: 0.1589 - val_accuracy: 0.9407\n",
      "Epoch 545/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1147 - accuracy: 0.9556 - val_loss: 0.1586 - val_accuracy: 0.9406\n",
      "Epoch 546/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1147 - accuracy: 0.9555 - val_loss: 0.1579 - val_accuracy: 0.9407\n",
      "Epoch 547/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1145 - accuracy: 0.9556 - val_loss: 0.1582 - val_accuracy: 0.9406\n",
      "Epoch 548/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1145 - accuracy: 0.9559 - val_loss: 0.1586 - val_accuracy: 0.9402\n",
      "Epoch 549/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1144 - accuracy: 0.9556 - val_loss: 0.1586 - val_accuracy: 0.9407\n",
      "Epoch 550/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1143 - accuracy: 0.9557 - val_loss: 0.1588 - val_accuracy: 0.9407\n",
      "Epoch 551/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1142 - accuracy: 0.9558 - val_loss: 0.1584 - val_accuracy: 0.9404\n",
      "Epoch 552/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1142 - accuracy: 0.9556 - val_loss: 0.1587 - val_accuracy: 0.9402\n",
      "Epoch 553/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1142 - accuracy: 0.9558 - val_loss: 0.1589 - val_accuracy: 0.9401\n",
      "Epoch 554/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1141 - accuracy: 0.9557 - val_loss: 0.1588 - val_accuracy: 0.9405\n",
      "Epoch 555/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1140 - accuracy: 0.9558 - val_loss: 0.1588 - val_accuracy: 0.9405\n",
      "Epoch 556/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1139 - accuracy: 0.9559 - val_loss: 0.1589 - val_accuracy: 0.9400\n",
      "Epoch 557/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1139 - accuracy: 0.9558 - val_loss: 0.1584 - val_accuracy: 0.9405\n",
      "Epoch 558/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1139 - accuracy: 0.9558 - val_loss: 0.1579 - val_accuracy: 0.9407\n",
      "Epoch 559/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1137 - accuracy: 0.9561 - val_loss: 0.1594 - val_accuracy: 0.9410\n",
      "Epoch 560/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1137 - accuracy: 0.9561 - val_loss: 0.1597 - val_accuracy: 0.9405\n",
      "Epoch 561/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1136 - accuracy: 0.9560 - val_loss: 0.1591 - val_accuracy: 0.9397\n",
      "Epoch 562/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1136 - accuracy: 0.9559 - val_loss: 0.1590 - val_accuracy: 0.9401\n",
      "Epoch 563/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1135 - accuracy: 0.9558 - val_loss: 0.1586 - val_accuracy: 0.9400\n",
      "Epoch 564/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1135 - accuracy: 0.9561 - val_loss: 0.1591 - val_accuracy: 0.9404\n",
      "Epoch 565/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1133 - accuracy: 0.9561 - val_loss: 0.1598 - val_accuracy: 0.9407\n",
      "Epoch 566/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1134 - accuracy: 0.9560 - val_loss: 0.1590 - val_accuracy: 0.9399\n",
      "Epoch 567/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1133 - accuracy: 0.9560 - val_loss: 0.1596 - val_accuracy: 0.9403\n",
      "Epoch 568/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1132 - accuracy: 0.9562 - val_loss: 0.1603 - val_accuracy: 0.9408\n",
      "Epoch 569/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1131 - accuracy: 0.9561 - val_loss: 0.1592 - val_accuracy: 0.9407\n",
      "Epoch 570/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1132 - accuracy: 0.9563 - val_loss: 0.1592 - val_accuracy: 0.9399\n",
      "Epoch 571/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1131 - accuracy: 0.9559 - val_loss: 0.1593 - val_accuracy: 0.9408\n",
      "Epoch 572/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1130 - accuracy: 0.9562 - val_loss: 0.1602 - val_accuracy: 0.9402\n",
      "Epoch 573/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1129 - accuracy: 0.9564 - val_loss: 0.1586 - val_accuracy: 0.9406\n",
      "Epoch 574/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1129 - accuracy: 0.9562 - val_loss: 0.1597 - val_accuracy: 0.9401\n",
      "Epoch 575/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1127 - accuracy: 0.9564 - val_loss: 0.1596 - val_accuracy: 0.9402\n",
      "Epoch 576/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1128 - accuracy: 0.9564 - val_loss: 0.1595 - val_accuracy: 0.9408\n",
      "Epoch 577/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1127 - accuracy: 0.9562 - val_loss: 0.1594 - val_accuracy: 0.9397\n",
      "Epoch 578/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1126 - accuracy: 0.9562 - val_loss: 0.1591 - val_accuracy: 0.9401\n",
      "Epoch 579/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1126 - accuracy: 0.9563 - val_loss: 0.1594 - val_accuracy: 0.9408\n",
      "Epoch 580/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1125 - accuracy: 0.9561 - val_loss: 0.1600 - val_accuracy: 0.9399\n",
      "Epoch 581/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1125 - accuracy: 0.9563 - val_loss: 0.1597 - val_accuracy: 0.9405\n",
      "Epoch 582/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1124 - accuracy: 0.9565 - val_loss: 0.1592 - val_accuracy: 0.9404\n",
      "Epoch 583/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1124 - accuracy: 0.9562 - val_loss: 0.1603 - val_accuracy: 0.9404\n",
      "Epoch 584/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1123 - accuracy: 0.9563 - val_loss: 0.1587 - val_accuracy: 0.9404\n",
      "Epoch 585/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1121 - accuracy: 0.9564 - val_loss: 0.1592 - val_accuracy: 0.9406\n",
      "Epoch 586/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1120 - accuracy: 0.9568 - val_loss: 0.1593 - val_accuracy: 0.9400\n",
      "Epoch 587/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1119 - accuracy: 0.9567 - val_loss: 0.1597 - val_accuracy: 0.9401\n",
      "Epoch 588/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1120 - accuracy: 0.9565 - val_loss: 0.1593 - val_accuracy: 0.9398\n",
      "Epoch 589/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1119 - accuracy: 0.9565 - val_loss: 0.1599 - val_accuracy: 0.9398\n",
      "Epoch 590/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1118 - accuracy: 0.9564 - val_loss: 0.1595 - val_accuracy: 0.9402\n",
      "Epoch 591/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1118 - accuracy: 0.9564 - val_loss: 0.1597 - val_accuracy: 0.9400\n",
      "Epoch 592/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1118 - accuracy: 0.9564 - val_loss: 0.1594 - val_accuracy: 0.9401\n",
      "Epoch 593/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1117 - accuracy: 0.9566 - val_loss: 0.1597 - val_accuracy: 0.9409\n",
      "Epoch 594/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1117 - accuracy: 0.9566 - val_loss: 0.1600 - val_accuracy: 0.9402\n",
      "Epoch 595/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1115 - accuracy: 0.9569 - val_loss: 0.1598 - val_accuracy: 0.9398\n",
      "Epoch 596/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1115 - accuracy: 0.9568 - val_loss: 0.1603 - val_accuracy: 0.9401\n",
      "Epoch 597/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1115 - accuracy: 0.9568 - val_loss: 0.1600 - val_accuracy: 0.9400\n",
      "Epoch 598/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1113 - accuracy: 0.9568 - val_loss: 0.1597 - val_accuracy: 0.9400\n",
      "Epoch 599/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1113 - accuracy: 0.9564 - val_loss: 0.1599 - val_accuracy: 0.9404\n",
      "Epoch 600/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1113 - accuracy: 0.9569 - val_loss: 0.1601 - val_accuracy: 0.9399\n",
      "Epoch 601/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1112 - accuracy: 0.9569 - val_loss: 0.1596 - val_accuracy: 0.9402\n",
      "Epoch 602/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1110 - accuracy: 0.9571 - val_loss: 0.1599 - val_accuracy: 0.9404\n",
      "Epoch 603/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1110 - accuracy: 0.9568 - val_loss: 0.1597 - val_accuracy: 0.9402\n",
      "Epoch 604/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1109 - accuracy: 0.9568 - val_loss: 0.1607 - val_accuracy: 0.9398\n",
      "Epoch 605/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1109 - accuracy: 0.9568 - val_loss: 0.1604 - val_accuracy: 0.9402\n",
      "Epoch 606/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1109 - accuracy: 0.9570 - val_loss: 0.1597 - val_accuracy: 0.9403\n",
      "Epoch 607/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1107 - accuracy: 0.9570 - val_loss: 0.1601 - val_accuracy: 0.9397\n",
      "Epoch 608/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1108 - accuracy: 0.9569 - val_loss: 0.1605 - val_accuracy: 0.9402\n",
      "Epoch 609/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1108 - accuracy: 0.9567 - val_loss: 0.1602 - val_accuracy: 0.9393\n",
      "Epoch 610/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1106 - accuracy: 0.9570 - val_loss: 0.1609 - val_accuracy: 0.9403\n",
      "Epoch 611/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1105 - accuracy: 0.9570 - val_loss: 0.1601 - val_accuracy: 0.9400\n",
      "Epoch 612/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1105 - accuracy: 0.9570 - val_loss: 0.1602 - val_accuracy: 0.9401\n",
      "Epoch 613/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1105 - accuracy: 0.9569 - val_loss: 0.1609 - val_accuracy: 0.9398\n",
      "Epoch 614/800\n",
      "6000/6000 [==============================] - 1s 91us/step - loss: 0.1103 - accuracy: 0.9570 - val_loss: 0.1603 - val_accuracy: 0.9406\n",
      "Epoch 615/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1102 - accuracy: 0.9571 - val_loss: 0.1601 - val_accuracy: 0.9404\n",
      "Epoch 616/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1103 - accuracy: 0.9571 - val_loss: 0.1609 - val_accuracy: 0.9406\n",
      "Epoch 617/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1102 - accuracy: 0.9570 - val_loss: 0.1613 - val_accuracy: 0.9394\n",
      "Epoch 618/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1102 - accuracy: 0.9573 - val_loss: 0.1614 - val_accuracy: 0.9398\n",
      "Epoch 619/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1101 - accuracy: 0.9573 - val_loss: 0.1601 - val_accuracy: 0.9395\n",
      "Epoch 620/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1100 - accuracy: 0.9571 - val_loss: 0.1610 - val_accuracy: 0.9395\n",
      "Epoch 621/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1100 - accuracy: 0.9571 - val_loss: 0.1611 - val_accuracy: 0.9407\n",
      "Epoch 622/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1098 - accuracy: 0.9571 - val_loss: 0.1617 - val_accuracy: 0.9398\n",
      "Epoch 623/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1099 - accuracy: 0.9574 - val_loss: 0.1611 - val_accuracy: 0.9400\n",
      "Epoch 624/800\n",
      "6000/6000 [==============================] - 0s 71us/step - loss: 0.1098 - accuracy: 0.9573 - val_loss: 0.1607 - val_accuracy: 0.9401\n",
      "Epoch 625/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1097 - accuracy: 0.9574 - val_loss: 0.1604 - val_accuracy: 0.9408\n",
      "Epoch 626/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1095 - accuracy: 0.9574 - val_loss: 0.1609 - val_accuracy: 0.9398\n",
      "Epoch 627/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1095 - accuracy: 0.9576 - val_loss: 0.1618 - val_accuracy: 0.9403\n",
      "Epoch 628/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1095 - accuracy: 0.9572 - val_loss: 0.1621 - val_accuracy: 0.9405\n",
      "Epoch 629/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1094 - accuracy: 0.9575 - val_loss: 0.1609 - val_accuracy: 0.9402\n",
      "Epoch 630/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1094 - accuracy: 0.9576 - val_loss: 0.1611 - val_accuracy: 0.9401\n",
      "Epoch 631/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1094 - accuracy: 0.9575 - val_loss: 0.1613 - val_accuracy: 0.9401\n",
      "Epoch 632/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1093 - accuracy: 0.9573 - val_loss: 0.1619 - val_accuracy: 0.9397\n",
      "Epoch 633/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1092 - accuracy: 0.9576 - val_loss: 0.1619 - val_accuracy: 0.9399\n",
      "Epoch 634/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1092 - accuracy: 0.9576 - val_loss: 0.1620 - val_accuracy: 0.9394\n",
      "Epoch 635/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1091 - accuracy: 0.9575 - val_loss: 0.1609 - val_accuracy: 0.9398\n",
      "Epoch 636/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1090 - accuracy: 0.9577 - val_loss: 0.1611 - val_accuracy: 0.9395\n",
      "Epoch 637/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1090 - accuracy: 0.9576 - val_loss: 0.1611 - val_accuracy: 0.9396\n",
      "Epoch 638/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1087 - accuracy: 0.9577 - val_loss: 0.1623 - val_accuracy: 0.9394\n",
      "Epoch 639/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1088 - accuracy: 0.9578 - val_loss: 0.1612 - val_accuracy: 0.9403\n",
      "Epoch 640/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1089 - accuracy: 0.9577 - val_loss: 0.1611 - val_accuracy: 0.9403\n",
      "Epoch 641/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1087 - accuracy: 0.9579 - val_loss: 0.1614 - val_accuracy: 0.9400\n",
      "Epoch 642/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1086 - accuracy: 0.9577 - val_loss: 0.1624 - val_accuracy: 0.9401\n",
      "Epoch 643/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1085 - accuracy: 0.9577 - val_loss: 0.1617 - val_accuracy: 0.9397\n",
      "Epoch 644/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1085 - accuracy: 0.9578 - val_loss: 0.1615 - val_accuracy: 0.9406\n",
      "Epoch 645/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1085 - accuracy: 0.9575 - val_loss: 0.1616 - val_accuracy: 0.9400\n",
      "Epoch 646/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1083 - accuracy: 0.9578 - val_loss: 0.1620 - val_accuracy: 0.9396\n",
      "Epoch 647/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1083 - accuracy: 0.9578 - val_loss: 0.1625 - val_accuracy: 0.9399\n",
      "Epoch 648/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1082 - accuracy: 0.9578 - val_loss: 0.1623 - val_accuracy: 0.9397\n",
      "Epoch 649/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1081 - accuracy: 0.9580 - val_loss: 0.1619 - val_accuracy: 0.9396\n",
      "Epoch 650/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1081 - accuracy: 0.9578 - val_loss: 0.1618 - val_accuracy: 0.9397\n",
      "Epoch 651/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1080 - accuracy: 0.9577 - val_loss: 0.1619 - val_accuracy: 0.9403\n",
      "Epoch 652/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1080 - accuracy: 0.9581 - val_loss: 0.1627 - val_accuracy: 0.9395\n",
      "Epoch 653/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1080 - accuracy: 0.9579 - val_loss: 0.1620 - val_accuracy: 0.9399\n",
      "Epoch 654/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1079 - accuracy: 0.9578 - val_loss: 0.1617 - val_accuracy: 0.9395\n",
      "Epoch 655/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1078 - accuracy: 0.9580 - val_loss: 0.1631 - val_accuracy: 0.9396\n",
      "Epoch 656/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1078 - accuracy: 0.9579 - val_loss: 0.1628 - val_accuracy: 0.9396\n",
      "Epoch 657/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1076 - accuracy: 0.9581 - val_loss: 0.1632 - val_accuracy: 0.9398\n",
      "Epoch 658/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1077 - accuracy: 0.9580 - val_loss: 0.1629 - val_accuracy: 0.9393\n",
      "Epoch 659/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1076 - accuracy: 0.9580 - val_loss: 0.1627 - val_accuracy: 0.9391\n",
      "Epoch 660/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1075 - accuracy: 0.9581 - val_loss: 0.1621 - val_accuracy: 0.9398\n",
      "Epoch 661/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1074 - accuracy: 0.9583 - val_loss: 0.1627 - val_accuracy: 0.9396\n",
      "Epoch 662/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1073 - accuracy: 0.9582 - val_loss: 0.1621 - val_accuracy: 0.9400\n",
      "Epoch 663/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1074 - accuracy: 0.9581 - val_loss: 0.1632 - val_accuracy: 0.9393\n",
      "Epoch 664/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1072 - accuracy: 0.9584 - val_loss: 0.1645 - val_accuracy: 0.9389\n",
      "Epoch 665/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1072 - accuracy: 0.9582 - val_loss: 0.1632 - val_accuracy: 0.9393\n",
      "Epoch 666/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1070 - accuracy: 0.9580 - val_loss: 0.1635 - val_accuracy: 0.9402\n",
      "Epoch 667/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1069 - accuracy: 0.9584 - val_loss: 0.1624 - val_accuracy: 0.9391\n",
      "Epoch 668/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1069 - accuracy: 0.9583 - val_loss: 0.1630 - val_accuracy: 0.9397\n",
      "Epoch 669/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1068 - accuracy: 0.9584 - val_loss: 0.1649 - val_accuracy: 0.9384\n",
      "Epoch 670/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1069 - accuracy: 0.9585 - val_loss: 0.1628 - val_accuracy: 0.9398\n",
      "Epoch 671/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1068 - accuracy: 0.9585 - val_loss: 0.1637 - val_accuracy: 0.9392\n",
      "Epoch 672/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1067 - accuracy: 0.9582 - val_loss: 0.1636 - val_accuracy: 0.9396\n",
      "Epoch 673/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1067 - accuracy: 0.9584 - val_loss: 0.1637 - val_accuracy: 0.9388\n",
      "Epoch 674/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1066 - accuracy: 0.9582 - val_loss: 0.1628 - val_accuracy: 0.9401\n",
      "Epoch 675/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1065 - accuracy: 0.9583 - val_loss: 0.1629 - val_accuracy: 0.9398\n",
      "Epoch 676/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1064 - accuracy: 0.9586 - val_loss: 0.1655 - val_accuracy: 0.9379\n",
      "Epoch 677/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1064 - accuracy: 0.9586 - val_loss: 0.1644 - val_accuracy: 0.9401\n",
      "Epoch 678/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1064 - accuracy: 0.9583 - val_loss: 0.1626 - val_accuracy: 0.9396\n",
      "Epoch 679/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1062 - accuracy: 0.9588 - val_loss: 0.1639 - val_accuracy: 0.9401\n",
      "Epoch 680/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1062 - accuracy: 0.9585 - val_loss: 0.1627 - val_accuracy: 0.9396\n",
      "Epoch 681/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1063 - accuracy: 0.9585 - val_loss: 0.1633 - val_accuracy: 0.9395\n",
      "Epoch 682/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1061 - accuracy: 0.9587 - val_loss: 0.1640 - val_accuracy: 0.9401\n",
      "Epoch 683/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1060 - accuracy: 0.9586 - val_loss: 0.1638 - val_accuracy: 0.9390\n",
      "Epoch 684/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1059 - accuracy: 0.9587 - val_loss: 0.1634 - val_accuracy: 0.9396\n",
      "Epoch 685/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1059 - accuracy: 0.9585 - val_loss: 0.1658 - val_accuracy: 0.9398\n",
      "Epoch 686/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1059 - accuracy: 0.9588 - val_loss: 0.1638 - val_accuracy: 0.9392\n",
      "Epoch 687/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1058 - accuracy: 0.9588 - val_loss: 0.1639 - val_accuracy: 0.9395\n",
      "Epoch 688/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1057 - accuracy: 0.9588 - val_loss: 0.1650 - val_accuracy: 0.9398\n",
      "Epoch 689/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1056 - accuracy: 0.9586 - val_loss: 0.1644 - val_accuracy: 0.9398\n",
      "Epoch 690/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1057 - accuracy: 0.9589 - val_loss: 0.1641 - val_accuracy: 0.9390\n",
      "Epoch 691/800\n",
      "6000/6000 [==============================] - 0s 80us/step - loss: 0.1054 - accuracy: 0.9587 - val_loss: 0.1639 - val_accuracy: 0.9394\n",
      "Epoch 692/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1054 - accuracy: 0.9588 - val_loss: 0.1632 - val_accuracy: 0.9391\n",
      "Epoch 693/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1054 - accuracy: 0.9589 - val_loss: 0.1638 - val_accuracy: 0.9388\n",
      "Epoch 694/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.1053 - accuracy: 0.9589 - val_loss: 0.1638 - val_accuracy: 0.9395\n",
      "Epoch 695/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1053 - accuracy: 0.9590 - val_loss: 0.1659 - val_accuracy: 0.9381\n",
      "Epoch 696/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1052 - accuracy: 0.9588 - val_loss: 0.1653 - val_accuracy: 0.9394\n",
      "Epoch 697/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1051 - accuracy: 0.9588 - val_loss: 0.1640 - val_accuracy: 0.9389\n",
      "Epoch 698/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1051 - accuracy: 0.9588 - val_loss: 0.1647 - val_accuracy: 0.9390\n",
      "Epoch 699/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1049 - accuracy: 0.9591 - val_loss: 0.1653 - val_accuracy: 0.9395\n",
      "Epoch 700/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1050 - accuracy: 0.9589 - val_loss: 0.1645 - val_accuracy: 0.9390\n",
      "Epoch 701/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1049 - accuracy: 0.9590 - val_loss: 0.1649 - val_accuracy: 0.9392\n",
      "Epoch 702/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1048 - accuracy: 0.9591 - val_loss: 0.1646 - val_accuracy: 0.9387\n",
      "Epoch 703/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1049 - accuracy: 0.9591 - val_loss: 0.1648 - val_accuracy: 0.9392\n",
      "Epoch 704/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1047 - accuracy: 0.9592 - val_loss: 0.1644 - val_accuracy: 0.9399\n",
      "Epoch 705/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1046 - accuracy: 0.9589 - val_loss: 0.1642 - val_accuracy: 0.9386\n",
      "Epoch 706/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1045 - accuracy: 0.9590 - val_loss: 0.1648 - val_accuracy: 0.9399\n",
      "Epoch 707/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1044 - accuracy: 0.9593 - val_loss: 0.1663 - val_accuracy: 0.9393\n",
      "Epoch 708/800\n",
      "6000/6000 [==============================] - 0s 77us/step - loss: 0.1043 - accuracy: 0.9594 - val_loss: 0.1655 - val_accuracy: 0.9388\n",
      "Epoch 709/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1044 - accuracy: 0.9591 - val_loss: 0.1653 - val_accuracy: 0.9393\n",
      "Epoch 710/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1043 - accuracy: 0.9593 - val_loss: 0.1649 - val_accuracy: 0.9393\n",
      "Epoch 711/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1042 - accuracy: 0.9592 - val_loss: 0.1650 - val_accuracy: 0.9395\n",
      "Epoch 712/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1043 - accuracy: 0.9593 - val_loss: 0.1656 - val_accuracy: 0.9393\n",
      "Epoch 713/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1040 - accuracy: 0.9595 - val_loss: 0.1651 - val_accuracy: 0.9390\n",
      "Epoch 714/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1041 - accuracy: 0.9593 - val_loss: 0.1658 - val_accuracy: 0.9395\n",
      "Epoch 715/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1040 - accuracy: 0.9592 - val_loss: 0.1658 - val_accuracy: 0.9394\n",
      "Epoch 716/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1038 - accuracy: 0.9594 - val_loss: 0.1650 - val_accuracy: 0.9394\n",
      "Epoch 717/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1038 - accuracy: 0.9593 - val_loss: 0.1658 - val_accuracy: 0.9393\n",
      "Epoch 718/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1037 - accuracy: 0.9592 - val_loss: 0.1649 - val_accuracy: 0.9388\n",
      "Epoch 719/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1036 - accuracy: 0.9595 - val_loss: 0.1662 - val_accuracy: 0.9387\n",
      "Epoch 720/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1036 - accuracy: 0.9597 - val_loss: 0.1661 - val_accuracy: 0.9384\n",
      "Epoch 721/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1037 - accuracy: 0.9598 - val_loss: 0.1648 - val_accuracy: 0.9392\n",
      "Epoch 722/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1035 - accuracy: 0.9597 - val_loss: 0.1652 - val_accuracy: 0.9391\n",
      "Epoch 723/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1034 - accuracy: 0.9596 - val_loss: 0.1661 - val_accuracy: 0.9387\n",
      "Epoch 724/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1033 - accuracy: 0.9597 - val_loss: 0.1670 - val_accuracy: 0.9392\n",
      "Epoch 725/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1033 - accuracy: 0.9598 - val_loss: 0.1666 - val_accuracy: 0.9391\n",
      "Epoch 726/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1032 - accuracy: 0.9596 - val_loss: 0.1667 - val_accuracy: 0.9390\n",
      "Epoch 727/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1031 - accuracy: 0.9599 - val_loss: 0.1670 - val_accuracy: 0.9390\n",
      "Epoch 728/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1031 - accuracy: 0.9595 - val_loss: 0.1663 - val_accuracy: 0.9386\n",
      "Epoch 729/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1029 - accuracy: 0.9600 - val_loss: 0.1663 - val_accuracy: 0.9386\n",
      "Epoch 730/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1029 - accuracy: 0.9598 - val_loss: 0.1666 - val_accuracy: 0.9381\n",
      "Epoch 731/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1028 - accuracy: 0.9599 - val_loss: 0.1674 - val_accuracy: 0.9395\n",
      "Epoch 732/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1028 - accuracy: 0.9598 - val_loss: 0.1667 - val_accuracy: 0.9388\n",
      "Epoch 733/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1027 - accuracy: 0.9598 - val_loss: 0.1659 - val_accuracy: 0.9398\n",
      "Epoch 734/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1026 - accuracy: 0.9599 - val_loss: 0.1675 - val_accuracy: 0.9390\n",
      "Epoch 735/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1026 - accuracy: 0.9598 - val_loss: 0.1666 - val_accuracy: 0.9382\n",
      "Epoch 736/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1025 - accuracy: 0.9599 - val_loss: 0.1658 - val_accuracy: 0.9384\n",
      "Epoch 737/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1024 - accuracy: 0.9602 - val_loss: 0.1672 - val_accuracy: 0.9389\n",
      "Epoch 738/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1025 - accuracy: 0.9599 - val_loss: 0.1671 - val_accuracy: 0.9390\n",
      "Epoch 739/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1023 - accuracy: 0.9599 - val_loss: 0.1674 - val_accuracy: 0.9380\n",
      "Epoch 740/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1024 - accuracy: 0.9600 - val_loss: 0.1681 - val_accuracy: 0.9385\n",
      "Epoch 741/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1022 - accuracy: 0.9601 - val_loss: 0.1671 - val_accuracy: 0.9393\n",
      "Epoch 742/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1022 - accuracy: 0.9599 - val_loss: 0.1668 - val_accuracy: 0.9386\n",
      "Epoch 743/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1020 - accuracy: 0.9599 - val_loss: 0.1679 - val_accuracy: 0.9387\n",
      "Epoch 744/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1019 - accuracy: 0.9599 - val_loss: 0.1674 - val_accuracy: 0.9383\n",
      "Epoch 745/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1019 - accuracy: 0.9603 - val_loss: 0.1676 - val_accuracy: 0.9384\n",
      "Epoch 746/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1018 - accuracy: 0.9601 - val_loss: 0.1678 - val_accuracy: 0.9375\n",
      "Epoch 747/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1018 - accuracy: 0.9600 - val_loss: 0.1679 - val_accuracy: 0.9386\n",
      "Epoch 748/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1018 - accuracy: 0.9602 - val_loss: 0.1667 - val_accuracy: 0.9391\n",
      "Epoch 749/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1018 - accuracy: 0.9602 - val_loss: 0.1674 - val_accuracy: 0.9384\n",
      "Epoch 750/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1015 - accuracy: 0.9605 - val_loss: 0.1690 - val_accuracy: 0.9385\n",
      "Epoch 751/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1016 - accuracy: 0.9603 - val_loss: 0.1675 - val_accuracy: 0.9390\n",
      "Epoch 752/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1015 - accuracy: 0.9601 - val_loss: 0.1675 - val_accuracy: 0.9380\n",
      "Epoch 753/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.1013 - accuracy: 0.9603 - val_loss: 0.1683 - val_accuracy: 0.9383\n",
      "Epoch 754/800\n",
      "6000/6000 [==============================] - 0s 72us/step - loss: 0.1013 - accuracy: 0.9604 - val_loss: 0.1682 - val_accuracy: 0.9389\n",
      "Epoch 755/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1013 - accuracy: 0.9604 - val_loss: 0.1687 - val_accuracy: 0.9388\n",
      "Epoch 756/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1012 - accuracy: 0.9605 - val_loss: 0.1684 - val_accuracy: 0.9394\n",
      "Epoch 757/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1012 - accuracy: 0.9604 - val_loss: 0.1669 - val_accuracy: 0.9385\n",
      "Epoch 758/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1011 - accuracy: 0.9604 - val_loss: 0.1691 - val_accuracy: 0.9379\n",
      "Epoch 759/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.1010 - accuracy: 0.9603 - val_loss: 0.1692 - val_accuracy: 0.9384\n",
      "Epoch 760/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.1010 - accuracy: 0.9604 - val_loss: 0.1678 - val_accuracy: 0.9384\n",
      "Epoch 761/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.1009 - accuracy: 0.9604 - val_loss: 0.1697 - val_accuracy: 0.9385\n",
      "Epoch 762/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1009 - accuracy: 0.9607 - val_loss: 0.1693 - val_accuracy: 0.9387\n",
      "Epoch 763/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1007 - accuracy: 0.9607 - val_loss: 0.1685 - val_accuracy: 0.9383\n",
      "Epoch 764/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1007 - accuracy: 0.9607 - val_loss: 0.1681 - val_accuracy: 0.9386\n",
      "Epoch 765/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.1007 - accuracy: 0.9607 - val_loss: 0.1687 - val_accuracy: 0.9387\n",
      "Epoch 766/800\n",
      "6000/6000 [==============================] - 1s 84us/step - loss: 0.1007 - accuracy: 0.9604 - val_loss: 0.1682 - val_accuracy: 0.9383\n",
      "Epoch 767/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1006 - accuracy: 0.9606 - val_loss: 0.1700 - val_accuracy: 0.9392\n",
      "Epoch 768/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1003 - accuracy: 0.9608 - val_loss: 0.1697 - val_accuracy: 0.9386\n",
      "Epoch 769/800\n",
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1004 - accuracy: 0.9609 - val_loss: 0.1702 - val_accuracy: 0.9385\n",
      "Epoch 770/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1002 - accuracy: 0.9607 - val_loss: 0.1693 - val_accuracy: 0.9386\n",
      "Epoch 771/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 0s 82us/step - loss: 0.1001 - accuracy: 0.9610 - val_loss: 0.1704 - val_accuracy: 0.9383\n",
      "Epoch 772/800\n",
      "6000/6000 [==============================] - 0s 81us/step - loss: 0.1001 - accuracy: 0.9605 - val_loss: 0.1699 - val_accuracy: 0.9388\n",
      "Epoch 773/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.1001 - accuracy: 0.9608 - val_loss: 0.1701 - val_accuracy: 0.9370\n",
      "Epoch 774/800\n",
      "6000/6000 [==============================] - 1s 86us/step - loss: 0.1000 - accuracy: 0.9608 - val_loss: 0.1705 - val_accuracy: 0.9394\n",
      "Epoch 775/800\n",
      "6000/6000 [==============================] - 0s 83us/step - loss: 0.0999 - accuracy: 0.9608 - val_loss: 0.1713 - val_accuracy: 0.9391\n",
      "Epoch 776/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0999 - accuracy: 0.9609 - val_loss: 0.1690 - val_accuracy: 0.9383\n",
      "Epoch 777/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0998 - accuracy: 0.9608 - val_loss: 0.1698 - val_accuracy: 0.9382\n",
      "Epoch 778/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0997 - accuracy: 0.9610 - val_loss: 0.1694 - val_accuracy: 0.9379\n",
      "Epoch 779/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0998 - accuracy: 0.9611 - val_loss: 0.1692 - val_accuracy: 0.9383\n",
      "Epoch 780/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0996 - accuracy: 0.9609 - val_loss: 0.1702 - val_accuracy: 0.9384\n",
      "Epoch 781/800\n",
      "6000/6000 [==============================] - 0s 79us/step - loss: 0.0995 - accuracy: 0.9611 - val_loss: 0.1698 - val_accuracy: 0.9380\n",
      "Epoch 782/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0995 - accuracy: 0.9609 - val_loss: 0.1703 - val_accuracy: 0.9383\n",
      "Epoch 783/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0994 - accuracy: 0.9611 - val_loss: 0.1706 - val_accuracy: 0.9382\n",
      "Epoch 784/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0993 - accuracy: 0.9609 - val_loss: 0.1693 - val_accuracy: 0.9383\n",
      "Epoch 785/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0991 - accuracy: 0.9611 - val_loss: 0.1703 - val_accuracy: 0.9378\n",
      "Epoch 786/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0993 - accuracy: 0.9613 - val_loss: 0.1706 - val_accuracy: 0.9384\n",
      "Epoch 787/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0992 - accuracy: 0.9613 - val_loss: 0.1716 - val_accuracy: 0.9377\n",
      "Epoch 788/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0989 - accuracy: 0.9612 - val_loss: 0.1708 - val_accuracy: 0.9388\n",
      "Epoch 789/800\n",
      "6000/6000 [==============================] - 0s 73us/step - loss: 0.0989 - accuracy: 0.9614 - val_loss: 0.1711 - val_accuracy: 0.9378\n",
      "Epoch 790/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0989 - accuracy: 0.9612 - val_loss: 0.1719 - val_accuracy: 0.9379\n",
      "Epoch 791/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0987 - accuracy: 0.9613 - val_loss: 0.1713 - val_accuracy: 0.9381\n",
      "Epoch 792/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0986 - accuracy: 0.9614 - val_loss: 0.1700 - val_accuracy: 0.9383\n",
      "Epoch 793/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0987 - accuracy: 0.9613 - val_loss: 0.1712 - val_accuracy: 0.9382\n",
      "Epoch 794/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0986 - accuracy: 0.9614 - val_loss: 0.1726 - val_accuracy: 0.9381\n",
      "Epoch 795/800\n",
      "6000/6000 [==============================] - 0s 74us/step - loss: 0.0987 - accuracy: 0.9610 - val_loss: 0.1721 - val_accuracy: 0.9378\n",
      "Epoch 796/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0986 - accuracy: 0.9613 - val_loss: 0.1709 - val_accuracy: 0.9376\n",
      "Epoch 797/800\n",
      "6000/6000 [==============================] - 0s 76us/step - loss: 0.0985 - accuracy: 0.9613 - val_loss: 0.1721 - val_accuracy: 0.9369\n",
      "Epoch 798/800\n",
      "6000/6000 [==============================] - 0s 78us/step - loss: 0.0983 - accuracy: 0.9616 - val_loss: 0.1718 - val_accuracy: 0.9380\n",
      "Epoch 799/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0983 - accuracy: 0.9616 - val_loss: 0.1716 - val_accuracy: 0.9371\n",
      "Epoch 800/800\n",
      "6000/6000 [==============================] - 0s 75us/step - loss: 0.0984 - accuracy: 0.9612 - val_loss: 0.1724 - val_accuracy: 0.9383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:122: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[1999, 1]\n",
      "[0, 0]\n",
      "[1776, 45]\n",
      "[132, 47]\n",
      "[1759, 62]\n",
      "[20, 159]\n",
      "[1810, 56]\n",
      "[96, 38]\n",
      "[1793, 73]\n",
      "[49, 85]\n",
      "[1901, 35]\n",
      "[36, 28]\n",
      "[1837, 99]\n",
      "[24, 40]\n",
      "[1892, 30]\n",
      "[50, 28]\n",
      "[1800, 122]\n",
      "[49, 29]\n",
      "[1700, 131]\n",
      "[96, 73]\n",
      "[1790, 41]\n",
      "[36, 133]\n",
      "[1702, 109]\n",
      "[101, 88]\n",
      "[1773, 38]\n",
      "[55, 134]\n",
      "[1840, 67]\n",
      "[52, 41]\n",
      "[1829, 78]\n",
      "[30, 63]\n",
      "[1856, 50]\n",
      "[42, 52]\n",
      "[1829, 77]\n",
      "[34, 60]\n",
      "[1806, 67]\n",
      "[68, 59]\n",
      "[1790, 83]\n",
      "[59, 68]\n",
      "[1775, 51]\n",
      "[84, 90]\n",
      "[1761, 65]\n",
      "[67, 107]\n",
      "[1763, 45]\n",
      "[77, 115]\n",
      "[1755, 53]\n",
      "[66, 126]\n",
      "[1792, 72]\n",
      "[72, 64]\n",
      "[1767, 97]\n",
      "[70, 66]\n",
      "[1844, 41]\n",
      "[59, 56]\n",
      "[1806, 79]\n",
      "[45, 70]\n",
      "[1837, 48]\n",
      "[55, 60]\n",
      "[1802, 83]\n",
      "[31, 84]\n",
      "[1744, 121]\n",
      "[65, 70]\n",
      "[1828, 37]\n",
      "[22, 113]\n",
      "[1753, 77]\n",
      "[57, 113]\n",
      "[1769, 61]\n",
      "[77, 93]\n",
      "[1815, 66]\n",
      "[57, 62]\n",
      "[1810, 71]\n",
      "[42, 77]\n",
      "[1865, 39]\n",
      "[42, 54]\n",
      "[1826, 78]\n",
      "[35, 61]\n",
      "[1866, 35]\n",
      "[52, 47]\n",
      "[1818, 83]\n",
      "[46, 53]\n",
      "[1793, 30]\n",
      "[59, 118]\n",
      "[1776, 47]\n",
      "[53, 124]\n",
      "[1726, 79]\n",
      "[118, 77]\n",
      "[1721, 84]\n",
      "[102, 93]\n",
      "[1921, 20]\n",
      "[29, 30]\n",
      "[1832, 109]\n",
      "[19, 40]\n",
      "[1932, 10]\n",
      "[18, 40]\n",
      "[1849, 93]\n",
      "[19, 39]\n",
      "[1912, 22]\n",
      "[32, 34]\n",
      "[1840, 94]\n",
      "[29, 37]\n",
      "[1891, 29]\n",
      "[44, 36]\n",
      "[1849, 71]\n",
      "[24, 56]\n",
      "[1714, 115]\n",
      "[78, 93]\n",
      "[1776, 53]\n",
      "[51, 120]\n",
      "[1807, 33]\n",
      "[47, 113]\n",
      "[1788, 52]\n",
      "[41, 119]\n",
      "[1734, 53]\n",
      "[107, 106]\n",
      "[1730, 57]\n",
      "[145, 68]\n",
      "[1773, 54]\n",
      "[80, 93]\n",
      "[1762, 65]\n",
      "[69, 104]\n",
      "[1896, 22]\n",
      "[52, 30]\n",
      "[1842, 76]\n",
      "[34, 48]\n",
      "[1899, 43]\n",
      "[39, 19]\n",
      "[1842, 100]\n",
      "[19, 39]\n",
      "[1828, 74]\n",
      "[54, 44]\n",
      "[1846, 56]\n",
      "[39, 59]\n",
      "[1844, 51]\n",
      "[55, 50]\n",
      "[1828, 67]\n",
      "[18, 87]\n",
      "[1853, 31]\n",
      "[63, 53]\n",
      "[1793, 91]\n",
      "[46, 70]\n",
      "[1915, 27]\n",
      "[34, 24]\n",
      "[1843, 99]\n",
      "[17, 41]\n",
      "[1894, 26]\n",
      "[51, 29]\n",
      "[1820, 100]\n",
      "[41, 39]\n",
      "[1886, 37]\n",
      "[36, 41]\n",
      "[1845, 78]\n",
      "[21, 56]\n",
      "[1843, 48]\n",
      "[67, 42]\n",
      "[1800, 91]\n",
      "[56, 53]\n",
      "[1853, 49]\n",
      "[49, 49]\n",
      "[1833, 69]\n",
      "[43, 55]\n",
      "[1917, 14]\n",
      "[40, 29]\n",
      "[1828, 103]\n",
      "[30, 39]\n",
      "[1889, 47]\n",
      "[44, 20]\n",
      "[1854, 82]\n",
      "[24, 40]\n",
      "[1862, 39]\n",
      "[65, 34]\n",
      "[1813, 88]\n",
      "[54, 45]\n",
      "[1832, 50]\n",
      "[64, 54]\n",
      "[1810, 72]\n",
      "[37, 81]\n",
      "[1837, 48]\n",
      "[57, 58]\n",
      "[1801, 84]\n",
      "[45, 70]\n",
      "[1927, 12]\n",
      "[33, 28]\n",
      "[1835, 104]\n",
      "[27, 34]\n",
      "[1868, 48]\n",
      "[55, 29]\n",
      "[1817, 99]\n",
      "[44, 40]\n",
      "[1734, 96]\n",
      "[95, 75]\n",
      "[1791, 39]\n",
      "[40, 130]\n",
      "[1799, 29]\n",
      "[62, 110]\n",
      "[1785, 43]\n",
      "[61, 111]\n",
      "[1713, 123]\n",
      "[90, 74]\n",
      "[1782, 54]\n",
      "[43, 121]\n",
      "[1738, 76]\n",
      "[120, 66]\n",
      "[1735, 79]\n",
      "[102, 84]\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds of MWPM:\n",
      "> Accuracy: 0.9449721903754156 (+- 0.0012008469880829212)\n",
      "> F1: 0.6095281306100763(+- 0.007920987632584923)\n",
      "> Time: 104.8546061599995 (+- 0.812170981605861)\n",
      "##############################################################################\n",
      "Average scores for all folds of PLUT:\n",
      "> Accuracy: 0.9261858041567732 (+- 0.0003996761518919594)\n",
      "> F1: 0.143544227540668(+- 0.003692416495514664)\n",
      "> Time: 0.035407919999999996 (+- 0.001497005067994095)\n",
      "##############################################################################\n",
      "Average scores for all folds of NN:\n",
      "> Accuracy: 0.9425959428375889 (+- 0.0009438247501950641)\n",
      "> F1: 0.556508364632404(+- 0.0022116015274208484)\n",
      "> Time: 0.07701702000000002 (+- 0.0020009400774635916)\n",
      "##############################################################################\n",
      "> AUC for class : 0.3624312156078039 (+- 0.0)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 0.0\n",
      "> AUC for class X00: 0.5547543009867761 (+- 0.015760521141615694)\n",
      "X^2 for MWPM and NN: 43.75141242937853\n",
      "X^2 for PLUT and NN: 20.5\n",
      "> AUC for class X01: 0.8729854522846064 (+- 0.01324323566297572)\n",
      "X^2 for MWPM and NN: 11.05921052631579\n",
      "X^2 for PLUT and NN: 4.336065573770492\n",
      "> AUC for class X02: 0.9745246305670594 (+- 0.0032229882350464562)\n",
      "X^2 for MWPM and NN: 0.056338028169014086\n",
      "X^2 for PLUT and NN: 44.520325203252035\n",
      "> AUC for class X03: 0.9732156219746884 (+- 0.007501264687307033)\n",
      "X^2 for MWPM and NN: 5.5125\n",
      "X^2 for PLUT and NN: 30.31578947368421\n",
      "> AUC for class X04: 0.8746464331675181 (+- 0.012950141553579654)\n",
      "X^2 for MWPM and NN: 5.092511013215859\n",
      "X^2 for PLUT and NN: 0.2077922077922078\n",
      "> AUC for class X10: 0.8344062743623224 (+- 0.01700641327547282)\n",
      "X^2 for MWPM and NN: 0.23333333333333334\n",
      "X^2 for PLUT and NN: 3.4838709677419355\n",
      "> AUC for class X11: 0.9367955710568967 (+- 0.010923888941294077)\n",
      "X^2 for MWPM and NN: 1.6470588235294117\n",
      "X^2 for PLUT and NN: 20.453703703703702\n",
      "> AUC for class X12: 0.9370293633342298 (+- 0.008773877598918026)\n",
      "X^2 for MWPM and NN: 0.532608695652174\n",
      "X^2 for PLUT and NN: 15.891891891891891\n",
      "> AUC for class X13: 0.9326360259538401 (+- 0.009744629725662503)\n",
      "X^2 for MWPM and NN: 0.02962962962962963\n",
      "X^2 for PLUT and NN: 3.7253521126760565\n",
      "> AUC for class X14: 0.8620302949832525 (+- 0.01136349392522856)\n",
      "X^2 for MWPM and NN: 8.562962962962963\n",
      "X^2 for PLUT and NN: 0.06818181818181818\n",
      "> AUC for class X20: 0.843195089862849 (+- 0.021911398613496454)\n",
      "X^2 for MWPM and NN: 8.926229508196721\n",
      "X^2 for PLUT and NN: 1.6470588235294117\n",
      "> AUC for class X21: 0.9429428120039554 (+- 0.005104016846459212)\n",
      "X^2 for MWPM and NN: 0.006944444444444444\n",
      "X^2 for PLUT and NN: 4.047904191616767\n",
      "> AUC for class X22: 0.9492698450409577 (+- 0.008018683979318568)\n",
      "X^2 for MWPM and NN: 3.61\n",
      "X^2 for PLUT and NN: 8.78225806451613\n",
      "> AUC for class X23: 0.9296956540869854 (+- 0.008145083384804764)\n",
      "X^2 for MWPM and NN: 0.6213592233009708\n",
      "X^2 for PLUT and NN: 22.81578947368421\n",
      "> AUC for class X24: 0.8284729983702459 (+- 0.009390227335150917)\n",
      "X^2 for MWPM and NN: 16.263440860215052\n",
      "X^2 for PLUT and NN: 3.3220338983050848\n",
      "> AUC for class X30: 0.8815475563807775 (+- 0.01584652880635687)\n",
      "X^2 for MWPM and NN: 2.6940298507462686\n",
      "X^2 for PLUT and NN: 2.0942028985507246\n",
      "> AUC for class X31: 0.9465375570470327 (+- 0.007292224714701271)\n",
      "X^2 for MWPM and NN: 0.5203252032520326\n",
      "X^2 for PLUT and NN: 6.938053097345133\n",
      "> AUC for class X32: 0.9591973782896839 (+- 0.01004995583724082)\n",
      "X^2 for MWPM and NN: 0.19753086419753085\n",
      "X^2 for PLUT and NN: 15.610619469026549\n",
      "> AUC for class X33: 0.9536827983968641 (+- 0.004369753792298182)\n",
      "X^2 for MWPM and NN: 3.7241379310344827\n",
      "X^2 for PLUT and NN: 10.046511627906977\n",
      "> AUC for class X34: 0.835287146207772 (+- 0.0089327198970881)\n",
      "X^2 for MWPM and NN: 10.112359550561798\n",
      "X^2 for PLUT and NN: 0.49\n",
      "> AUC for class X40: 0.8870060444980489 (+- 0.011999420709042533)\n",
      "X^2 for MWPM and NN: 8.121827411167512\n",
      "X^2 for PLUT and NN: 1.9408602150537635\n",
      "> AUC for class X41: 0.9799142253144462 (+- 0.0020666781766609)\n",
      "X^2 for MWPM and NN: 2.0408163265306123\n",
      "X^2 for PLUT and NN: 61.8828125\n",
      "> AUC for class X42: 0.9821517895815205 (+- 0.0025664911532096873)\n",
      "X^2 for MWPM and NN: 2.892857142857143\n",
      "X^2 for PLUT and NN: 47.580357142857146\n",
      "> AUC for class X43: 0.9742522276042198 (+- 0.0037665223592774277)\n",
      "X^2 for MWPM and NN: 2.240740740740741\n",
      "X^2 for PLUT and NN: 33.300813008130085\n",
      "> AUC for class X44: 0.9534922859448084 (+- 0.008550495476167036)\n",
      "X^2 for MWPM and NN: 3.506849315068493\n",
      "X^2 for PLUT and NN: 22.273684210526316\n",
      "> AUC for class Z00: 0.8765330968879363 (+- 0.02357343229148252)\n",
      "X^2 for MWPM and NN: 6.715025906735751\n",
      "X^2 for PLUT and NN: 0.009615384615384616\n",
      "> AUC for class Z01: 0.8583054579929458 (+- 0.011123690280563238)\n",
      "X^2 for MWPM and NN: 2.8125\n",
      "X^2 for PLUT and NN: 1.075268817204301\n",
      "> AUC for class Z02: 0.841904743928168 (+- 0.02077459868119449)\n",
      "X^2 for MWPM and NN: 18.90625\n",
      "X^2 for PLUT and NN: 39.21287128712871\n",
      "> AUC for class Z03: 0.8501297508657167 (+- 0.006626586028794121)\n",
      "X^2 for MWPM and NN: 5.440298507462686\n",
      "X^2 for PLUT and NN: 0.1865671641791045\n",
      "> AUC for class Z04: 0.9590514671528483 (+- 0.009571314494155221)\n",
      "X^2 for MWPM and NN: 12.986486486486486\n",
      "X^2 for PLUT and NN: 15.281818181818181\n",
      "> AUC for class Z10: 0.9818487679943981 (+- 0.00277131842481071)\n",
      "X^2 for MWPM and NN: 0.10975609756097561\n",
      "X^2 for PLUT and NN: 53.78151260504202\n",
      "> AUC for class Z11: 0.9372461057920303 (+- 0.009607968469876656)\n",
      "X^2 for MWPM and NN: 2.8203125\n",
      "X^2 for PLUT and NN: 2.694736842105263\n",
      "> AUC for class Z12: 0.9382842266000523 (+- 0.008771600441397269)\n",
      "X^2 for MWPM and NN: 0.2358490566037736\n",
      "X^2 for PLUT and NN: 27.105882352941176\n",
      "> AUC for class Z13: 0.9495461548968868 (+- 0.006180687316553269)\n",
      "X^2 for MWPM and NN: 11.585106382978724\n",
      "X^2 for PLUT and NN: 14.13138686131387\n",
      "> AUC for class Z14: 0.971176115854069 (+- 0.003701061759929132)\n",
      "X^2 for MWPM and NN: 1.0491803278688525\n",
      "X^2 for PLUT and NN: 56.560344827586206\n",
      "> AUC for class Z20: 0.9817473890938103 (+- 0.0029897920972031125)\n",
      "X^2 for MWPM and NN: 8.779220779220779\n",
      "X^2 for PLUT and NN: 23.858156028368793\n",
      "> AUC for class Z21: 0.9525964127546803 (+- 0.007714544053340851)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 31.67676767676768\n",
      "> AUC for class Z22: 0.9336309718066976 (+- 0.005253567521954813)\n",
      "X^2 for MWPM and NN: 3.4782608695652173\n",
      "X^2 for PLUT and NN: 7.863945578231292\n",
      "> AUC for class Z23: 0.9488293624318386 (+- 0.0031585090204163655)\n",
      "X^2 for MWPM and NN: 0.01020408163265306\n",
      "X^2 for PLUT and NN: 5.580357142857143\n",
      "> AUC for class Z24: 0.9784011874723031 (+- 0.005048348770367595)\n",
      "X^2 for MWPM and NN: 13.5\n",
      "X^2 for PLUT and NN: 38.97744360902256\n",
      "> AUC for class Z30: 0.9755771394240632 (+- 0.00371877789950292)\n",
      "X^2 for MWPM and NN: 0.04395604395604396\n",
      "X^2 for PLUT and NN: 30.650943396226417\n",
      "> AUC for class Z31: 0.9500120929003673 (+- 0.010645618149952858)\n",
      "X^2 for MWPM and NN: 7.009615384615385\n",
      "X^2 for PLUT and NN: 7.669014084507042\n",
      "> AUC for class Z32: 0.929541747705041 (+- 0.0069754200941563515)\n",
      "X^2 for MWPM and NN: 1.9736842105263157\n",
      "X^2 for PLUT and NN: 10.605504587155963\n",
      "> AUC for class Z33: 0.9376508816354885 (+- 0.00854380775959684)\n",
      "X^2 for MWPM and NN: 0.9523809523809523\n",
      "X^2 for PLUT and NN: 11.193798449612403\n",
      "> AUC for class Z34: 0.9796554761808867 (+- 0.002905575347540848)\n",
      "X^2 for MWPM and NN: 10.755555555555556\n",
      "X^2 for PLUT and NN: 44.091603053435115\n",
      "> AUC for class Z40: 0.9621649223942657 (+- 0.007417845567120806)\n",
      "X^2 for MWPM and NN: 0.6213592233009708\n",
      "X^2 for PLUT and NN: 20.39160839160839\n",
      "> AUC for class Z41: 0.845287591911695 (+- 0.008234297104035657)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 0.05063291139240506\n",
      "> AUC for class Z42: 0.8371041911808959 (+- 0.01497993134283774)\n",
      "X^2 for MWPM and NN: 12.703296703296703\n",
      "X^2 for PLUT and NN: 3.4711538461538463\n",
      "> AUC for class Z43: 0.859203200844874 (+- 0.014210553901748933)\n",
      "X^2 for MWPM and NN: 4.807511737089202\n",
      "X^2 for PLUT and NN: 1.0309278350515463\n",
      "> AUC for class Z44: 0.8740791735989912 (+- 0.010606690233077615)\n",
      "X^2 for MWPM and NN: 10.331632653061224\n",
      "X^2 for PLUT and NN: 3.18232044198895\n",
      "###################################################################################\n",
      "TOTAL F1 NN: [0.5556516724336793, 0.5590668080593849, 0.5589112873881086, 0.5556763022531334, 0.5532357530277138]\n",
      "TOTAL F1 PLUT: [0.14168377823408626, 0.14470108695652176, 0.14984604858022577, 0.13874673035369045, 0.14274349357881577]\n",
      "TOTAL F1 MWPM: [0.6100850798920937, 0.5945308162132148, 0.6109080685971324, 0.6168611475523027, 0.6152555407956373]\n",
      "TOTAL ACC NN: [0.9424797892570496, 0.942480206489563, 0.9439607858657837, 0.9430099129676819, 0.941049019607866]\n",
      "TOTAL ACC PLUT: [0.9262721580386557, 0.925941176470615, 0.9269117647059101, 0.925754901960813, 0.926049019607872]\n",
      "TOTAL ACC MWPM: [0.9447629126613318, 0.9427254901960936, 0.9457254901960929, 0.9455980392157013, 0.9460490196078579]\n",
      "TOTAL TIME NN: [0.0760161, 0.0810189, 0.0760167, 0.0760175, 0.0760159]\n",
      "TOTAL TIME PLUT: [0.0340073, 0.0360084, 0.0340076, 0.035008, 0.0380083]\n",
      "TOTAL TIME MWPM: [103.48378619999957, 104.48240849999944, 105.08248069999924, 105.81301839999968, 105.41133699999955]\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAEiCAYAAAAyFTwvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAACUQElEQVR4nOzdeVyU1f7A8c+ZGXZHdlcQVMBhUVJxy9yrqy3mcu2XdvPaYotZmWZm11v32q20vN2rpZXa4lK5lKlle9lVs0zNVEDADRcQXBBkGWCW8/vjmaEREUFBEM779RphnufM83xnQOY755zne4SUEkVRFEVRFKX6dHUdgKIoiqIoyrVKJVKKoiiKoiiXSSVSiqIoiqIol0klUoqiKIqiKJdJJVKKoiiKoiiXSSVSiqIoiqIol0klUkqlhBD9hRBSCDHOZVu4Y9s/qniM94UQtVJnQwjxD0cs4bVxfEUjhLhOCPG9EOJsdX721wLH83m/ruNQFOXa1CgTKSGEtxBikhBisxAiRwhhEUJkCyG+EEKME0IY6jrG6hBCbBdClAohgitp00QIUSCESL2asdUEIcSw+vzG7ZJsut4KhBC/CSGerOz3SQjRVwixWgiR6fgZnnT8Hg67xDmjhBALhBApQohCIYRZCJEmhFgohOhWw8/PAHwCRAJ/B+4B1lTSfly518IihDjjeD3eEkL0rsn4qsKRcA+r5eOX/x1w3p6q5jGsQghTBfv7V3Q8l/N8cJHj/iiEKLi8Z6YoyqVcUwlDTRBCRAAbgCjgO+Bl4DTQDLgReA+IAZ6uqxgvwzvAm8BfgP9cpM2dgA/a87tSRwAvwFoDx6qKYcBfgX9UsO9fwCyg5CrFUpmPgC8AAbQAxgKvAdHAg+UbCyFeAqajvZ7vAIcdjxsDfCqEWAbcK6W0lXvc/Wg/72LHOX9H+1lEASOB8UKIWCllcg09r3aO2xQp5RvVeNw8YDvaBzZfIA4YATwkhPgQ7bmV1lCMl/I8sARYW8vneRLt74mrndU8hh7t79Lwaj5utBDiVSnl79V8nKIoV6BRJVJCCC/gc7Q3hZFSyvKfqmc7Ps1X+oleCGGUUubXUpiX4yO0N+x7uXgidS9gQ3szuSJSK4dffKXHqQlSSitXL6G7lN+klMudd4QQC4AU4AEhxN+klKdc9t2PlkR9B9whpSxy2fcKWmI1FkgHnnPZdyOwEEgG/iSlzHQNQAgxHXishp9XC8fXnGo+brOU8mPXDUKISWjPbQxwDnjkiqOrX9ZKKdOv8Bg7gGFCiF5Syp+r+Ji9aIn0bOBPV3h+RVGqobEN7T0AdAD+XUESBYCUcruUcoHzvhAi3dE13lkI8bUQIg/Y47K/rxDiWyFEnmN45TfHm+R5hBCxjiGcDCFEiRAiSwixUQhxq0sbT0f3fqoQokgIkSuE2CuEeLWyJyWlzAM+BjoKIRIqOHckcAPwpZTyhBCilRDi30KI34U256VYCJEshJgmhNBf6kUUF5kj5Yj/VccwlVkI8asQ4uaLHKO70OZOpTmea74Q4ichxPBy7X5E641yHcIom7MlLjJHyhHjMqEN2ZYIIQ4KIV4SQniXa+d8fAfH/uOO9ruFELdc6rWojJSyEPgFrYeqvcs53dF60gqAu12TKMfjrMBDwFHgKXH+kO1sx/H+r3wS5XyslPI/VemNqspr5Hj9/+e4+57L6x9eldeggvjMwDjgEFrP2XnHEUK0FEK8KYQ4KrShzkyhDVc2K9fO+XOLFULMc/x/MgshtgkhBpV7js75eX91/R2q4PXoJYT4n9CGSs8IIRYLIZpU9zkKIZqKK5se8E+gCHilGo85CiwAbnZ9/oqi1L5G1SMF/NnxdWE1H9cG+AFYjTZXpAmAEOJ24FMgC/g3kA/cBSwWQrSTUv7N0S7Q8XiAt9CGcoKABKAH2lAjwHzgPmApWg+TAW1eysAqxPgu2tyVe9E+0bq61/H1HcfXTmhDLJ8CBwE3YDDaEFk7tDfxy/ER2jDcZ8DXaMnDGrQhq/KGAyZgFdrrEYiWMK0RQtwtpfzQ0e5FtIS/j+P5OW29WBBCiDDgV7ThpAXAfqA/Wg9QbyHEIEey4moJYAHmAO7AJGCtECLqCnsYnAmUa29Ob7Reng+klCcrepCUslgIsRx4FrgFWCKEaAt0QevpuaJhu2q8Ri8CPzniWAhsdhziVPljVpWUslRow5bPo/WevO2IqQ3wM9rr/w7a72YEWq/VACFEguNDg6ulaD2tswEj2u/uV0KIIVLK7xxx3gMsc8R+sf/716H1Vr8HfOh4Le4H7FQwLFuJPY44bEKIX4EXpJRfVuPxoP09+Q/wNyHEUCnl+io+7kW0vx+zhRDdpFpIVVGuDillo7kBZ4C8aj4mHZDAA+W269ESgFyglct2d7Q3HhsQ6dg21HGMOy9xrhzgi8t8bgI44DiGh8t2HXAcyAYMjm1egKjgGMsccbd02dbfEfs4l23hjm3/cNl2s2Pb++WOOcyxXZbb7lPB+b2BVCC53Pb3yz/eZd8/HMcPd9n2gWPbLeXavurYfn8Fj//c9TVBG96VwMtVeO2dr9FzaAlyMNARLTGWwLZy7R9zbJ98ieOOcLSb47h/u+P+vBr4v1Cd1+iC34FLHHuco/2fq/Dc/u2ybR1wEggp1zYBbfjW9ffN+XPbBri7bA9B6+nbV+4YF/xulttnB3qU274BLbluUoXnPAktIfwr2v/3qUCG47hVfd2czykBaIqWBCYC+nI/h6cqiP9zx/fPOu7f5bL/R6DgSn9n1E3d1K3iW2Mb2muK1mtUXTlcOEm7K1pP1bvSZYhFapNnX0FLYO5wbHZ+ih4ihGhayXnygFghRFx1A5RSSrReKX+05MXpZqA1sFQ6emGklGZHe4QQ7kKIACFEEFovkg7tD3l1Oc953jCklHItWnJUPt5C5/dCu4oyEC2R+gGIvsTrdFFCCB3aG9kuKeUX5Xa/jPbGVtEk3rnO18QR33a0N+TIapz+n2hvfifReiYmoPXI3VGunfO5le9dKe+c46tvucedq6BtlV3Ba1STnM+hqSMmX+A2YD1QLIQIct7QPswcQPtdLu8/0mXCupTyOFqSaBJCRFcjnp+llNvKbfsBrVc4/FIPllL+V0r5kJRyiZRyvZTyVbSe32zgP9UdIpRSnkMb/o3FMbRdRf8FMoF/CSHcqnNORVEuT2NLpM6hdbtX10FZ7sopoK3ja1IF7Z3b2gFIKf+HNgQxDjjtmAv0TyFETLnHTUJLhPY65qssFkLc4XjjA8CR9LRwvbk8/n20HqX7XLY5v3/X5RgGIcQMIUQa2qTxM2gJwDJHE/8KX4XKtUN7A06rYN++8huEEM0cc1+ygUK0K51OAQ87mvhdRgyg9QY1oYKfi5QyBzjhiLW8QxVsO4M25FhVC4Gb0IbipqEl4CFcODG/fIJ0MeUTLufjLud32NXlvkY1qXxS2AHt79H9aL8H5W8dgOYVHOeC3y20ifhQvedwsZ8/VO93oIyU8gzaUL4fcP1lHOJNtGHxfwohPKt4ziK0nq32/PF/SVGUWtTYEqlEoKkQorpvEkWXblI5KeVf0YZ7/ob2B3oKsEcIMdGlzTq0T7/3oH0aHoR2ufaPjgnKoPVwnCh3cz4+E61X6UYhRIgQIgCt5+FnKaXrG85rwAvAb2jzp25BSwCmOfbX6u+FEEIA36B90l4C/B/aHK2b0Oan1HoMFSifKDuJahxjv5TyOynll1LKV9CG4rqhvZm6SnR87XKJ4zn37y33uM7ViKm+6uT46uytdL7Oy9F+Dyq6ja3FeC7283eN7XKkO74GVfeBjp62v6Ml409U46Hvol0tOkMIcaVJt6Iol9DYJpt/AvRFu3rv2Ss8lvMTbGwF+2LKtQFASpmI9mb4qhDCD21+xywhxHznsJKjR2A5sNyRcMxCq2l1B9pk9ylU3mP0Dlpi9Fe0ngwPXHqjHO4BNkkp73LdKLQaW5frEFryE8WFPR3lh1g6AfHATCnl8+VieKCCY1dn0uwptOHbC34uQgh/oCVa3aVaJ6Xc6phUPVYIMU9K6ZwgvxVtyOcOIUSQlLJ83SEcPRB/QevN+tJxvMNCiF1ok8FNUsqUywytTl8jx4eCe9CSl68dmw+g/ZzdpTZJvKqigd3ltlX4/6+OOIeGsy/z8R+i/Z9/hvN7mi9KSmkTWhmMT4EqFQNVFOXyNbYeqcVon4CfEkKUn7cCgBCiqxBiQhWO9RvaJcf3ug6vOeYlTEV7U1jn2BbgOjwHIKXMReu29wY8hRB6R3Ll2kYCuxx3Axzbdjp6Pcpu5eL6DO2NchzaH95CYGW5NjbKfcoWQvigFRO8XOscX6eWO+4wtGGZ8uenghjiqHhuToFjf8ClgpBS2tFeg85CiMHldj+D9jv/6aWOU4NeQHu+M50bpJQlaBPTm6AlzF6uDxBaCYoFQBjwqjz/yj5nr+GKcsO6ZY8VWtX+8sPGZeryNXI81/fRht3ellIeccR0Bq2Y6QghRM8KHidExZX7n3TprUUIEYJWoyq1XC9sAY7/QzXNMVR+wTCtECIU7YrDM1RylWllHH8DnkEbHpxejcetdZxzMlqxYUVRakmj6pGSUhYJIW5DuxpnrRDiG+BbtD90wcAAtMuxL1m/xfGpbyLaG852IcRCtE/5/wf0BF6SUu53NB+L9gf/U7RP3hagn+Ncq6SUZkcSdUIIsR4teTqJNg/rEeAs2htfVZ6jRQixFO1TLGhXKpWfYP8xWnXplWgFIZujJV1nuExSyq+FEJ+h1eoJAL5Cm6fxEFovnOsE+n1ovVZPC61mUSpaT9ZDaMNYXcsd/hdgIrBACOG8kmqblLKisgqg9TbehPYzXoD2mvdF+9lsogaKklaVlPKAEGIFcLcQoo+UcrNj+0JHD+BUINnxM0tHK4swGm0YeDnaBHbX430rhHgQbf5MqhDCtbJ5BFpl8/ac/3pX5Gq8Rn0cPWuC8yubBzue26Ry7R8BtgCbHK/HLrSkrh1aj+xSLqxubwA2O14HI9q8IC/g8XLtfkEb8p6G9gFISilXXPlTBLSE+LAQYi3a7/ZZtA8PDzj2jZZa/azLIqX8RgjxPdpQf3VMQyv5EI32gUpRlNpQ15cN1sUNrRfoSbQ/2mfR3piz0RKse3Bcbuxomw78WMmx+qElY+fQhmF24XLpuKPNdWhvTAfQ/qCdQxuOmIKjVAFa2YSX0Wr7nEFb8iQdbVgusprPLxpHyQGgz0We/6to5RuK0WoIPYP2h7p8qYP+FWwLp1z5A8d2L7R6WlmA2fFcbqaC8gVovS2r0XrPihxth1NxOQMdWn2n42i9O2XxVNTesb0t2uT5k0Ap2jDPS4B3uXYVPr4qP/sKXqOnLrI/2hH3xos89hO0uW6ljtfjS2D4Jc7ZAS2ZSnO8fsVoCenbQOcq/p5U9TW64HfgEscd5/L7J9GSvLNo/zfeAq6v5LFBjt9N54UQuWjJ9VwgpoKfWyzwuuN3rtjxe3RTBceNRJuXd84Zl8u+CksjuDyP/pd4vh5ovd17+ePvyQm0Dyzdq/H/1vmcEirY1xXtYo5Kyx9U8Lh1jv2q/IG6qVst3YSU1Zl+oiiKUveEVlX/eaCtvPIlWRRFUS5bY5sjpSiKoiiKUmNUIqUoiqIoinKZVCKlKIqiKIpymepsjpQQ4l20JSFOSikvuMLIUUNpLlpNpCK0ia6/Xd0oFUVRFEVRLq4uyx+8D7yBdklzRYagXWkTCfRAu0Kpx6UOGhQUJMPDw2smQkVRlEZi586dp6WUFdXqUhSlEnWWSEkpNwkhwitpcgfaQrsS+EUI4SeEaCmlPFHJYwgPD2fHjh01GaqiKA2ElNrNZgO7Xfvqer+ym9Wq3Wy2Cx/vbOM8luvxnOeFC4/puq18jM6bs43rNud9VxUds/yxpJTY7dpNSujUSU/fvtpjhBBHaudVV5SGrT4X5GwNHHO5f9yx7YJEylGg8EGANm3aXJXgFEXR3pytVigt1W4Wi3YrLtZuZrOkuBhKzHbMJZIis8RcLCkpgZJSbX9pKVhKocQiKSmxY7VK7TildkotYLOCdCQGNrvEbpNYrRKbTWK3C2xWLTGwWSU2q8Bmk9is2uMsVrBYBHYb2O0CKQUgHUmILPdcHPfLNsvzvpfOJ3zBQ2XZcYVzl5Tn1+0v1/68bytsJyvcfTHS5d8Lz3dxo8f60LevX9UaK4pSofqcSFWZlHIhsBAgISFBFcZSFLT3cmdSU1T0R3KjJTjarbBIS2wK8iV5uTYK8u0UFtgoMksKCmyUlArMRXZKS6G42I6lVFBSIiktlpSUCixWgd0mHTmH1u0htXKXjvtlKQgAQjprdJZF6dj2x32gLCEpSyKEa0Ihz2shcGkoXNMO4bgvQTjaIUBI9DqJTkh0OhA6iU6AEHb0eu1Qer1EILV9eh06nUSnk+j1YNBLdHrte50ehA50AvQ67XRCpx3X4CYc9x1nFs7jaNt1OolO79jnOIY2NfSPbUIHep22TeiEFq8QCCERQqArO7ZjHyD0Qoul7Dw6QKAvKsRn8yas4WFYO3ZECOja1btav1OKolyoPidSGUCoy/0QxzZFadAsFsjLk+Sek+TnS/ILJOfyIT9fUlggycuzU1BkJ/+cjYJzNoqKJMVFNkpKwFwkKSyAggKB2azHbtMSGmm3az0u0tFr4uyRkc47zgTGJdFxJi8uuYkQf2Q02hu6wE3YcfewYzCA3mDHw03i4WHD00Pi6WHHw8OOuxt4uEkMeomHtw53Dx3u7hI3N4G7px43Tz2enm64eehx9zRo290Fbm4Cg0GHwaAlEzq9QG8QGBw3nQ4tuTEI9Hpwc/vjq7s7LsegrL0oS1jKPa8Kvq9s2zVDSli7Fv77XzAXQk5zeHItuLnVcWCK0jDU50RqPTDRsU5ZDyDvUvOjFKU+sdu1hOjkaUnOWTu5eXD6jIWTJ22cOmEh55SVMzmSoiJBQSEUFkFRoZ7SEoF0THARjiUIAEfCY9c6WNAmw/yR6MiyN3utU0OHTlhw09vx8rDh7m7D013i5Q2e7nY8PMHTC+2+tw7vJnp8jHqaNBH4+Ljj7aPD01OPp5fA01OHl5cOTy/tq4cHeHgIvLwEnp5a4uJMqv6IQVzbyUdDcfw4/Otf4Jw32rcvPPOMSqIUpQbVWSLlWGS0PxAkhDiOttyDG4CU8i20leBvQVufrgi4t24iVZQ/WCxw5ozkxEkLh46Xkn3KSuZJC2dzBGdPSc6eluSehYJcHQUFeuz2P2YiC0dipI00SaSQ6NC+F47uHx0WPHSSJt6lePtY8PGRNPG24uMD3t7QxEfgYzTg7SNp0tSAsakbPk3d8fLW4+XjhrePG0199TRtKmjSRODhIRzDPjqV3DQmdjt89BEsWAAlJeDvD1Onwk03lRv+VBTlStXlVXujL7FfAo9epXAUhdJSOHUKjmaUcuh4CWnpZk5k2sg6buVsto6c0wYK8vWOy6a0XiKdBCHtlM1sEdrQmU5Y8RDQxLMEP2MJvk2s+PpKfP0FTQN0BARIAoL0BAZA0wBPmgY2oYlRT9OmOnyM7o55ObqyJEib56IoVWS3w4YNWhJ1yy0weTL4+dV1VIrSINXnoT1FqTF2O5w8ZWP/kRIOHSvh2BErmcesZGXaOJklyTntRlGBXpsYbdcmResQCLsOnXDXJv4CTQxW/JqUEOBbTEBTM/5+FgICJX7NPQgM0hMUKPAPNBAY7I5/kDteRj907t7odDr0er3qFVJqj/PKAqMRDAb4xz/g5Em44Ya6jkxRGjSVSCnXPKvNTm6+nQNHSjl8rJT0DDNHjpeQnSnIyYSzp/Tkn/XAZgNhl+jsEiEFCD06oXdcLSXx0dsIbGomqKmZ4GALzZvbaNZKR6sQPS2aS1q2cieohTcGTx90Bj90bl7o9Hr0en1dvwRKY5eUBP/8J7RvDy+/rG2LitJuiqLUKpVIKfWW3S4ptdkpKLZwrriYQ0dLOJFlITNTkpFhI+OY4MQxPWey3THn6xF2qd2kGzpp0IbYkAgBnjqJr08JQX6FtAgsomUbQbNgK61aCVq2kLQMa0Jgc2/cjUHo3T3R6/VqOE2p/4qL4c03tflQzqqh585B06Z1HZmiNBoqkVLqBYvNwtnifA5l5ZFywMa+VDsHD9g5nelGToYneac8webmSJK0y/T1UiKkHZ2w42+w0MyvgGYBRTQLNNOieQnNmtlo2UZPqxA3WoQ2pYmfEZ1PC/QePhgMBjXEplzbduyAF16AjAzQ6WDsWHjoIfDwqOvIFKVRUYmUclVZ7BbOlRRwuiiPgxkF7E22kZYmObrfk1PpRnJP+KKzg84uyhImnbTTRNho5ldIM/9CgpsWEBRYTKtmhYS00xMe5Unz0Ka4Nw3C4NMKvcFNu6khN6UhklIbvluzRrsfGQl//zvExNRtXIrSSKlESqlVBSWFHMk7Q0bOOX7+7Rz79rqTldqUM+lNKcxtgl4KR9KkVcRuorfROjCPdq3O0D40j5BWZtq0sxPSwR9jUy8M3n7ovcPRu2tzlVSypDQ6QoC7u1YL6oEH4K9/1SaXK4pSJ9T/PqXGWG12zhaZOZKXze8HTvPbLitH93ly9oA/J480Q2drgU4KnKuS+XrYaNM8l3atzxIRdg5TbAlRHQRNAgJwC2yLwbspbm6qZ0lRyMnRrsAzmbT7EybAiBHQrl3dxqUoikqklMtnsdk5W1TKueJSdqQdZ/PWEtIT3chMaUrhqXbo7WhXx+n0uOsEIa0KiG13iuj2Z+gUfZbWoQa8W7XDwzcEtyaBGAwGNcFbUVxJCV99BXPmgI8PrFihVWb19lZJlKLUEyqRUqqloMTK6QIze49ls+3XUvbv0XFotydnM4PR20CPDnQGmnjaiQw7R5wpl+jQTOIiTuHXOgjP5u3xDOiJu6eXSpoUpTLZ2dpcqC1btPsdOmgrTXurhYYVpT5RiZRSqWKLjVMFRaTnnGRbYi6//+rGkd1NyNrviyiV6OwCgQ6jJ8RE5RAXdYbO0dlERRbjExyMl38L3Jt2w90YoBInRakKux0+/RTmzoWiIq3A5pNPwu23q+VdFKUeUomUcp5ii41T+SVk5+eRdiqDPbvtpPzmxdHfAik46Y+w2hFSh5teEBmaR+eYbK4znSI2rgS/kNZ4BrTCw/c63Nw9VHkBRbkcM2bAN99o3w8YANOmQVBQ3cakKMpFqURKwW6XZOYVcCjnJGlZp0nbLUje0YQju9pgyTcgrIBdENDUSkL8aXrFH6VbxzP4hbbGKzgMd7/rcHd3V4mTotSEP/1JqxE1bRoMHKh6oRSlnlOJVCN2zlxK0skM9h0/xY5tNg5ta8GxvZHYS0DYJFLqCGlRTM/Op7ih6xHi2p/Bs0V7vJtF4xkQoobqFKUmpKVBYqJ2FR5Av37QrZuaC6Uo1wiVSDUy+cUW0nNy2J1xjJ07zez/pTmHdkUiinRIiw2Ejqi2Zrpfd4p+nQ8Q1s6Gt28gXi3i8fRvjU6VIlCUmlFaCu+8A++/r12dFxurTSgHlUQpyjVEJVKNgMVmJ+1kDsknj5C4/zSpW1uQtrUN5hxPhFUibXaiwvPoe/0pBnY7QPOAQjx8m+ERkoBXoOp5UpQat2ePtrzL4cPa/TvvhNDQuo1JUZTLohKpBqzUamfn8aPsyzpK8m8G9v0YzqG9HRAlNqTVTsvgAvp3z+TGXodoE27Fq1kY3s1uwMOvpUqeFKU2mM2wYIFWD0pKCAvTlne57rq6jkxRlMukEqkGyG6XJGZl82NKKrs3+ZH0Q0fOnXJHllhx15XQp0sWtww+SqeIU3gEheLTui+evs1U8qQote2117TSBjodjBsH48dry70oinLNUolUA1JqtXP07Fk++/UAmzYY2f9zZ+xFOrDaaWHM4dYbD3PLTYfxC/bBu2Uk3q0G4uauVopXlKvmgQfgyBGYPPmP5V4URbmmqUSqAZBScuhUHh9vTeXHdX4c3NYBg0WHLLUR3y6T4b120+OGArzCOmBsNRgvv2aqVIGiXA0//ghffAGzZmm9UM2bw8KFdR2Voig1SCVS1zCrzc7hM7ms//kwX65swtGdHTBYJO52C32uO87//Wkf7bsa8QntQZPAVrirIQRFuTpycuCVV+C777T733wDgwfXbUyKotQKlUhdo5Kyj/HZz0f48eMADv0ShsEKnrpSBnU+xJ13nSQ8rhlNQ27Fy8eo5j4pytUipdYD9e9/w7lz4OUFjz0GN99c15EpilJLVCJ1DSmyFHHo7HG+35XFVx804/DP0egt4GkQDOp9lP8bfozwbib8ml+Hp6dnXYerKI3LiRPw0kvw88/a/V694NlnoWXLuo1LUZRapRKpa0CJpZQdmWn8nJrBlo9CSNkcg94mcDPo6d8rkzFDU2nbrT3+oTfj4aEmjytKndi4UUuimjbVJpPfeqta3kVRGoFqJVJCiFDgn8DNQDNgsJTyByFEMDAbeFNKub3mw2y8dp84wpYD+9jxRSjb13dDFkkMBjd6X5/L6Bt3EtHZj8DIm/DyaVLXoSpK41NSAs4PL3fdBbm58H//B4GBdRqWoihXT5UTKSFEW+AXwNPxtay/Wkp5SgiRADwAqESqBpw157M5PYlvvrWx48Ou5J80gBR0va6Av9zxG9FtTuEfez0+zcLUFXiKcrVZrbB8OXz4IXzwAQQHa1flTZhQ15EpinKVVadH6kXADsQBZuBkuf1fALfXUFyNlsVmZ3fmcX5I2cv2D+NI2tQUYReEhlp5cNRuunU8gV94HD6t+6BzU/OgFOWqS02FmTO1r6CVOBg1qk5DUhSl7lQnkboReF1KeUwIUVG/9REgpGbCapzyiy18fyCJn389y6Z3e5OXCW5ugrF3ZTPi+i0YQyPxi7oLg0FNbVOUq660FBYv1hYZttuhVSv429+gR4+6jkxRlDpUnXfkpsCJSva7V/N4ioujZwr57sAufl4XyNa13ZFmK+3bFPLUpMNEBR3GaLoJn6AQNYynKHUhORmeew7S07UJ5HfdpQ3jeXvXdWSKotSx6iQ+x4DYSvb3BA5cWTiNj80uScnK5fvEZD5/K4zjiX6I0lJG3XKCv96ZSNMmbvjF3I7B27euQ1WUxu3oUQgP1xKqTp3qOhpFUeqJ6iRSa4CHhRDv8EfPlAQQQowERgHP12x4DVuxxcamA+ls/vUUn883UXLagK+3mWcmHyAh+gDG8OswhsYhVEFNRbn60tIgKkr7PiYG5s6Frl3VIsOKopynupPNbwO2AZvQkqhnhBAvAd2B34F/13SADVVBiZUtB4/w5Re5fPteDLLQTnyHszzz2G6aB1kIiL0VD6O6hFpRrrpz5+C11+Dzz7Wvfftq23v1qtu4FEWpl6qcSEkpzwkhegEvAGMAAdwE5AILgL9JKYtrI8iGpqDYwpcpe1m7xJ3fNrRHlNoYdmMmE0b/inebOPzbXofO4FbXYSpK4/PDD9oCwzk5Ws/T6dN1HZGiKPVctSaHSynPAU8ATziKcArglJRS1kZwDVFRqYUPd21h/fxwDm3zx2CXPHR/BsP67sI39maMQa3rOkRFaXxOn9YWGf7hB+1+587w979DmzZ1G5eiKPVedQpyPgeskVImglaEs9z+WGCklHJmzYbYcJhLLaz+7VdWz2lHxm4/vN2sPDtpP71i0vDveDOefi3qOkRFaXz27IEnnoD8fO0qvMcfhxEjtAKbiqIol1CdvxT/ACq7VCWOak42F0IMFkKkCiEOCCGeqWB/GyHERiHELiHEHiHELdU5fn1yLPcsi7du4r2ZoRzf2ZSmnhZeefZXel13gsDrblNJlKLUlYgILYG6/npYtQr+/GeVRCmKUmU1WffJE7BWtbEQQg/MR5tndRzYLoRYL6VMdmk2A1glpXxTCBGDVj09vOZCvjrSTubyRdJ2vnjtOrKT3QgKgtl/T6R9iI3ATrdhcFPzoRTlqrHbYf16+NOfwMtLS6Lefx+CgtQiw4qiVFuliZQQoing57IpUAhR0aSBAOButFpTVdUdOCClPOQ41wrgDsA1kZJohUABfIHMahy/XsjKK+J/h3bx3fw4jiW60yLYwuyZybT1zyag41D0KolSlKvn8GF44QVtOO/QIZg8WdseHFy3cSmKcs26VI/Uk8Bzju8l8F/HrSICeLoa527N+YnXcaD8Wgv/AL4RQjwG+KAtU3PhiYV4EHgQoE09mhxaUFLC12k72LCgHQd3+hDoZ2HWzGTa+p8goPPt6N296jpERWkcrFZYuhQWLQKLRet96tq1rqOq93bu3NnMYDAsRpu6ocY7lcbIDiRardYHunbtWn6NYeDSidSPjq8CLaH6FNhTro0ECoBfpJRbLz/WCo0G3pdS/ttRemGZECJOSmk/LwApFwILARISEurFFYSlVgur9m7iu/cjSN3qTxMvCy/+PZmIwJP4x9+GzsOnrkNUlMYhJUVbZDgtTbs/bJg2udxorNOwrgUGg2FxixYtooODg8/qdLp68bdVUa4mu90uTp06FZOVlbUYGFpRm0oTKSnl/4D/AQghwoC3pJTbaii+DCDU5X6IY5ur+4HBjlh+FkJ4AkFAhVlhfWGxW/jywC9sXdOG379rhpss4Z9PJ2JqfRq/TkPQeTSp6xAVpXE4dAjGjv1jkeEZM6B797qO6loSp5IopTHT6XQyODg4LysrK+5ibapTkPPemgmrzHYgUgjRFi2Bugut0Kero8Ag4H0hRDTahPZT1GNWu5VvD/7Mxi/8+OmTEHSlpfztsX1cF5lJQMdb0XuqJEpRrpp27WDgQGjWDB55RJtcrlSHTiVRSmPn+D9w0aHtal+157jazgT4V3RgKeWmqhxHSmkVQkwEvgb0wLtSyiQhxExgh5RyPTAFWCSEeBJtCHFcfS/+mXLmANu3efHDu+2g2MKDYzPok3CQwOvuwM276aUPoCjK5SsshPnzteE75zp5L72kyhkoilJrqvXXRQgxDTiNNk/qf8DGCm5VJqX8QkoZJaVsL6V80bHtOUcShZQyWUrZW0oZL6W8Tkr5TXWOf7XlFufy3W8ZfPpaByz5Vm6/+TQjB23Hr0MfPHx86zo8RWnYtm6FO+/UakG9/DI4P3OpJOqaptfru5pMppjIyMjYgQMHRpw+fVrv3Ldjxw7Pnj17RoWHh8eFhYXFTZ06taXd/scU2lWrVjWNi4uLbt++fWx0dHTM+PHjQ8of32w2i+uvvz7KZDLFLFq0yP9icXTv3r3Dpk2bvMtvnzdvXuDYsWMvuMrJbrczbty40DZt2sRFRUXFbNmy5YLHAhQUFIhu3bp1sFr/qB40c+bMZh4eHl3OnDlT9lwrOo9rTHl5eboxY8aEhYaGxsXGxkZ37969ww8//HBFk3Gr+hwWLVrkHxUVFRMRERH7yCOPlC3P8corrwRHRUXFmEymmK5du3bYuXOnJ8Cvv/7qNXLkyPAria0+qfJfGCHE/cDLaIsTz0CbgP5f4FUgB9gB3FfjEV4jLDYLX6f8zqrZ8RSfhe7X5fHoXT/RJKov3s3b1nV4itJw5ebCc89pFcmzsyEmBv72N1UTqoHw8PCwp6SkJO/fvz/Jz8/P+uqrrwaDloAMHz484umnn85KT09PTExMTN62bVuT2bNnBwNs377dc8qUKW2WLVt2+ODBg0l79+5NjoiIKCl//K1bt3oDpKSkJI8fP/5sTcW9evVq30OHDnmmp6cnvvnmm0cmTJhQ4SXlr7/+etDQoUPPGgx/DBB9/PHHAXFxcYXLly/3q+r57r777nB/f39renp6YlJS0r6lS5cePnny5BXViqzKc8jKytI/99xzIT/++GPagQMHkrKzs93WrVtnBHjggQfOpKWlJaekpCRPnjw5a9KkSaEA3bt3N584ccJ9//797lcSX31RnY9qj6BdmTcAxxVywAYp5TNoFc/D0YboGqXvDv7GJ4tCyDnmRUhgPs8+/DM+bWLxbdmurkNTlIZJSvj2Wxg1Cr74QltkeNIkeO89rVq50uD07NmzMCMjwx1g0aJFgQkJCQUjRow4B2A0Gu1vvvnm0blz57YEeOmll1pMmTLlROfOnYsBDAYD06ZNO2+ObUZGhuHee+9tu3fvXm+TyRSTlJTksW7dOmN0dHRMVFRUzKhRo8LNZvMFGfncuXMDw8PD4zp27Bi9devWCie+rlu3zu/uu+8+o9PpGDRoUOG5c+cMR44cuaBw4KpVqwLvvPPOXOf9pKQkj6KiIv3MmTMzVq1aFVCV1yUpKclj165dPnPnzs3Q67W3YZPJVHrXXXflVeXxF1OV55CamuoRHh5e0qpVKyvAoEGDzq1evdofICAgoKx7sKCgQC9cPtwMGTIkd8mSJRftAbyWVCeRigZWO753zlPSA0gpT6AlV0/UXGjXjqSsE3y/0cbe71rhZi9l+tif8GsZSED7Lgj1qVhRasfZs1pxzbNnoUsXWLkS/vIX0Dfaz3MNmtVqZePGjcZhw4blAiQlJXl26dKlyLVNbGxsSVFRkS4nJ0eXmprq1aNHj6IKD+bQunVr64IFC44kJCQUpKSkJLdt27b0oYcearty5cqDaWlpyVarFWcPmNORI0fcZs2a1Wrr1q0p27dvT0lLS6vwCoYTJ064hYeHlzrvt2zZsrR8ElJcXCyOHTvm0aFDh7J2S5cu9R8+fHjO4MGDCw4fPux57NixS/Yq/f77754xMTFFrr1aF3Prrbe2M5lMMeVvb7zxRuDlPIeYmJiSQ4cOeaamprpbLBbWr1/vn5mZWdbT9PLLLweHhobGPf/88yHz588/6tzeo0ePwq1btzaIGiTV6fazAYWO751fXV/4dCCyBmK6ppwtKuHrPan8sLgzWG3ce2sS0QkQGNsPnZqboSg1S0rtptNBQAA89ZRWbHPYMDUX6ipY93tGjU/2vOO61pX2mpSUlOhMJlNMdna2W/v27YuHDRt2rqZjcNq9e7dnSEhISadOnUoAxo0bd2b+/PnNcCm5s2nTJp+ePXvmO3tgRowYkZOWluZ5OefLysoyGI3G85ZWW7NmTeCaNWsO6PV6brnllrPLli3zf/bZZ09d7EN5dT+sb9iw4dDlxHoxwcHBtv/85z9HRo0a1U6n09GtW7eCw4cPezj3T58+/dT06dNPvfXWWwHPP/98yzVr1qQDtGzZ0pqdnd0glvaoTiJ1FGgLIKUsEUIcA/oAKxz7u6HNlWpUtqSn8O07ERSd1dO1XRYjb92HX8xwDG4NYuhXUeqPjAz4179gwABtUjnA0Arr4ym15FJJT21wzpHKz8/X9e/fP3LWrFnNZsyYcTImJqZ48+bN5w2rJScnu3t7e9sDAgLsUVFRxdu2bfPu1auX+WrHDNCyZUtLenp62RvBiRMn3MPCwiyubXx8fOylpaVlnwB+/fVXryNHjngMHjw4CsBisYiQkJDSZ5999lRQUJA1Nzf3vO7W3NxcffPmza0BAQG2ffv2eVutVi7VK3Xrrbe2O3jw4AWJ38SJE7MnTpx4prrPAWDMmDF5Y8aMyQOYM2dOkL6CXuHx48fnTJ06tWyOldls1nl6etovaHgNqs5HuE3ArS73VwMPCSHeFUK8DzyAtqhwo5Gdf47PNxRz+Hd/fD3MTB23BWNkd7z9guo6NEVpOOx2+PBD+L//g+3bYflyrRdKaVSMRqN93rx5RxcsWNDcYrHw4IMPntm+fbtx7dq1RtAmnz/66KNtHnvssSyA6dOnZ7322mst9+zZ4wFgs9l45ZVXKl1UMT4+vjgjI8M9MTHRA2Dp0qWBffr0yXdt07dv38Jt27YZs7Ky9CUlJeLTTz+tcJ7P0KFDcz/44INAu93O999/72M0Gm3lk5Dg4GCbzWYTRUVFwnG+gClTpmRmZGTszcjI2Hvy5Mk92dnZbmlpae433HBD4c6dO5scPXrUALBp0ybv0tJSXfv27UtjY2NLOnXqVDh58uRWzqsWU1NT3VesWHFBD+KGDRsOpaSkJJe/lU+iqvocQJtrBnDq1Cn94sWLm02YMOEUwN69e8t6plauXOkbFhZWNtk/OTnZo0OHDnWS5Na06vRIzQV2CyG8pJRm4HkgCvirY/83wDM1HF+9ZbNLvvj9IFtXRCEsNiaM3EZLUxB+4R3rOjRFaTgOHdKWd0lM1O4PHgxTpkAV5oIoDU/v3r3NJpPJvHDhwoBHH300Z82aNQcmTpzYZtKkSW52u51Ro0admT59+kmAHj16mGfPnn1s9OjR7cxms04IwU033VRpj5q3t7d866230keNGtXeZrMRHx9f9NRTT503QT0sLMwybdq0zJ49e0YbjUZbXFxchfOw7rzzzrwNGzb4hoWFxXl5edkXL16cXlG7vn375n3zzTdNhg0blr927dqAzz77bL/r/iFDhpxdsmRJwIsvvpg1e/bsY4MHD4602+3Cx8fHtnz58kPO3p/ly5enT5gwITQsLCzO09NT+vv7W1999dVjFZ2zqip7DiaTKSYlJSUZ4OGHHw5NTk72Bpg2bVqmc2j0tddea7Z58+amBoNB+vr6Wt9///3Dzsf/8MMPTW+77bar3sNZG8SV1rcUQvgCNillQc2EdGUSEhLkjh07av08iZkneea5HA5sbEXXtid4+dnttLh+JO6eqnKyolwxqxXefx8WL9a+b9YMpk+HPn3qOrIGSwixU0qZ4Lpt9+7d6fHx8afrKqbGYMuWLd5z5sxpvnbt2sOXbt0wmM1m0bNnzw47duxIcXO7NqZJ7d69Oyg+Pj68on1XPDtTSpknpSwQmnuu9HjXglKrnVXfHid1Uys8hIUn/roTv9g+KolSlJoiBPzvf1oSNWKEVmRTJVFKA3TDDTcU9e/f/5y1EQ1XHzhwwP3FF1/MuFaSqEu54v5xoV0yMBr4O9pQ37IrPWZ9t+d4Fp+/0xK9RTJmSBJhsX4Ym1VYa01RlKoqLoaSEvD11UoYPP885OVB1651HZmi1KpJkyZdMD+pIevYsWNJx44dLyiOeq26ZI+UEOIGIcQ6IUSyEGKLEOIhl31/AhLRkqdWwOzaC7X+eGtJLucyfGgblMOoOw7jF91P1YtSlCuxcyeMHg0vvvjHtogIlUQpilLvVdojJYToDXwPuPa/9RJC+ACewL+AXOAFYK6UssbK69dXB0+dZMtngbjZbYy//Wf8O/XDw+uKljNSlMaroADmzYM1a7T7Hh6Qnw/GBlGnT1GURuBSQ3vTgBLgz2gJVQSwFG2tPSPwNjBdSplbizHWKws+OIklpw3RgZkk3NIc3+ZqSE9RLsuWLfDSS3DypHYV3v33w7hx0EDmTSiK0jhcKpHqAbwtpfzMcX+PEOIptFIHS6SUj9RqdPXMvuwsvv84EHe7jVE3pxBkGqSqlytKdUmpzX/6wlF2Li5OW3S4nVqXUlGUa8+lsoBAIKncNuf9tTUeTT23dE02BVlNaGk8Tf+RwXj5VLhWpaIolREC/P21YbzJk+Hdd1USpVyUXq/vajKZYiIjI2MHDhwYcfr06bKy2Tt27PDs2bNnVHh4eFxYWFjc1KlTWzoLUgKsWrWqaVxcXHT79u1jo6OjY8aPHx9S/vhms1lcf/31USaTKWbRokUXXUS3e/fuHTZt2uRdfvu8efMCx44de8HQxK5duzyvu+46k7u7e5fnnnuu+cWOa7fb6dmzZ1ROTk7Z+/GyZcv8hBBdd+3aVVaB/PPPPzcOGDDgvNW4R44cGf7ee+/5A5SUlIgJEya0DgsLi4uJiYm+7rrrTKtWrWp6sfNW1fTp01u0adMmLjw8PO6TTz6p8Hjr1683xsTEREdGRsaOGDEi3GLRana++eabAVFRUTFRUVExnTt3Nv38889eoK0xmJCQ0MHZ7lp3qURKB5SW2+a8n08jkpF7jo1rAnCTNkbcsI+AqE5qgrmiVNXJk38U1QR45BGtpMGYMWqNPKVSziVi9u/fn+Tn52d1LiJcUFAghg8fHvH0009npaenJyYmJiZv27atyezZs4MBtm/f7jllypQ2y5YtO3zw4MGkvXv3JkdERFxwpdjWrVu9AVJSUpLHjx9fY/N8mzVrZp07d+7Rhx56KLuydqtWrfKNjY01BwQElGWAK1asCOjSpUvB0qVLA6p6vieffLJVVlaWW0pKSlJycvK+zz777MC5c+euaAXvnTt3eq5ZsyYgNTU16auvvkqbNGlSm/JlGmw2Gw8++GDbFStWHNq/f39SmzZtSt94440ggIiIiJKffvopNS0tLXn69OmZDz30UBiAp6en7Nev37nFixdX+fnVZ1X5C+YjhAhw3gDnEze6bnfZ3yB98n0WJw/74ueez00j3PDxURPMFeWS7HZtIvmoUfD001DoWO/c0xNat67b2JRrTs+ePQszMjLcARYtWhSYkJBQMGLEiHOgLSHz5ptvHp07d25LgJdeeqnFlClTTnTu3LkYwGAwMG3atPOqlGdkZBjuvffetnv37vU2mUwxSUlJHuvWrTNGR0fHREVFxYwaNSrcbDZf8Il57ty5geHh4XEdO3aM3rp1a4VDE61bt7b269evyM3NrdKq1x988EHA8OHDc5338/LydNu3b2/y3nvvpX/66adVek/Nz8/Xffjhh8GLFy8+6uXlJQFCQ0OtDzzwwBUlhh9//LHfiBEjcry8vKTJZCoNCwsr+fHHH89788vOzja4ubnZndXMBw8efG7t2rV+ADfddFNhcHCwDWDAgAGFWVlZZev2/fnPf85dsWJFg8gZqpJIvQWccrmlOLavKbf9FC4rZDckhSWlfPKBHje7naFdd9O8a3c1N0pRLuXYMa3n6aWXtATKZILS8h3cilI1VquVjRs3GocNG5YLkJSU5NmlS5fzlmeJjY0tKSoq0uXk5OhSU1O9evToUeHyLU6tW7e2Lliw4EhCQkJBSkpKctu2bUsfeuihtitXrjyYlpaWbLVacfaAOR05csRt1qxZrbZu3Zqyffv2lLS0tCuqxLxz584mvXv3LnTe//DDD/369++f16lTpxJ/f3/r5s2bLxhOLC85OdmjZcuWpa69Whdz//33h5pMppjyt2effbZF+bYZGRnuoaGhZf9pW7VqVXrs2DF31zYtWrSw2mw24Rz2XLlypf+JEyfcyx/r9ddfDxowYEDZkjDdunUz79mzp0H0SFxqsvmSqxJFPbd5bzZH9gbiL8wMudOA0devrkNSlPrLucjwm29qBTb9/bXeqBtv1OZHKdeuvasvWAT3inUcVel6ayUlJTqTyRSTnZ3t1r59++Jhw4adq/EYHHbv3u0ZEhJS4uxdGTdu3Jn58+c3w6WTYNOmTT49e/bMb9WqlRVgxIgROWlpaZ4XOeQl5eXlGfz9/csSoFWrVgU8/vjjJwFGjhyZs2zZsoA+ffoUCSEq7Nm62PaLeeedd65o/b3ydDodS5cuPfTkk0+GlpaW6gYMGJBXvqPhs88+My5fvjxo69atzo4YDAYDbm5u8uzZszrX538tqjSRklLee7UCqc8++rAEg81Inw6phPbqgnORSEVRKvDMM/DDD9r3t9yiLTLsW/Pvv0oduETSUxucc6Ty8/N1/fv3j5w1a1azGTNmnIyJiSnevHnzecNqycnJ7t7e3vaAgAB7VFRU8bZt27x79eplvtoxV4der5c2mw29Xk92drb+l19+MaampnpNnDgRm80mhBDSbrcfb9asmTUvL++89+yzZ88agoODrTExMSUnTpxwz8nJ0V2qV+r+++8P/emnny4o1DZixIicl156Kct1W+vWrc/rgcrMzDyvh8rpxhtvLNy5c2cqwJo1a5oeOHCgLLHctm2b14QJE8I2bNiwv0WLFjbXx1ksFuHt7X1lC/7WA2p86hJOnivkl++b4mG3MPiWAnz9G8SQrqLUnqFDoXlzmDsXZs5USZRSI4xGo33evHlHFyxY0NxisfDggw+e2b59u3Ht2rVG0CafP/roo20ee+yxLIDp06dnvfbaay337NnjAdqk6FdeeSW4snPEx8cXZ2RkuCcmJnoALF26NLBPnz7nXVjVt2/fwm3bthmzsrL0JSUl4tNPP73olX5V0bZt2+J9+/Z5ACxbtsx/+PDhOZmZmXszMjL2ZmVl7QkJCSn9+uuvm8TFxZVkZ2e7/fbbb54AaWlp7ikpKV49e/Y0G41G+1133XX6wQcfbFNcXCwAMjMzDe++++4Fsb3zzjvHUlJSksvfyidRACNHjsxds2ZNgNlsFikpKe7p6eme/fv3LyzfLiMjwwDaFZCvvvpqi4cffvgUwP79+91HjRrV/t133z3s7OVzysrK0vv5+Vk9PDxUItXQvbMqi9J8d9oFnKDzrVEYDFe8PKGiNCyJifDRR3/cv+EG+PRT6N277mJSGqTevXubTSaTeeHChQFNmjSRa9asOfDSSy+1Cg8Pj4uJiYnt0qVL4fTp008C9OjRwzx79uxjo0ePbteuXbvYqKio2EOHDnlUdnxvb2/51ltvpY8aNap9VFRUjE6n46mnnjpvgnpYWJhl2rRpmT179oxOSEgwRUVFFVd0rKNHjxqaN2/eaeHChc3/85//tGzevHkn1xIHTjfffHPeN998YwRYvXp1wIgRI86bIH7HHXecXb58eYCXl5d87733Dt17773hJpMpZsSIEe3nz59/JDAw0Abw3//+NyMoKMgaFRUVGxkZGTt48OAIX19fW/nzVUdCQkLxsGHDcqKiomIHDx4c9dprrx1xvgf269cvIj093Q1g5syZLdq1axcbHR0dO2TIkNyhQ4fmA8yYMaNlbm6u4bHHHgszmUwxcXFx0c5jf/nll01vvPHGq97DWRuElNd8MniehIQEuWPHjho5ls0u6XvLMc6kevP4yF3c+8INeHld0bxCRWk4zGZtHtRHH2lzn5YsgejoSz9OqZeEEDullAmu23bv3p0eHx9/uq5iagyOHDniNnr06PCtW7fur+tYrqabb765/Zw5c46X76mqr3bv3h0UHx8fXtE+1SNViR+2n+HY/qYY9WYGDDPi6XnZ8wkVpWHZvh3uukubVC4E3HOPKqqpKJchLCzMct99952uqLeqoSouLhZDhw7NvVaSqEtR41SVeOf9fNykHwPi0mjdsasqwKko+fna3Ke1a7X7UVHw97+rnihFuQJXWu/pWuPp6SknTpx4pq7jqCkqkbqI02dL2LnJiCdWBt9WiE8TtRq9ovDf/8K6ddrCwuPHw9ix2oLDiqIojZT6C3gRn35xFkuxJ7EB6cTdFK1KHigKwMMPw6lT8OST0LZtXUejKIpS56o1JiuEMAohnhNCbBFC7BdC9HJsD3JsN9VOmFff199YcbNbuL7raZq2CK3rcBTl6pMSvvgCHn8cbI6Lf4KDYd48lUQpiqI4VLlHSggRDGwB2gEHHF+9AKSUp4UQfwX8gMk1H+bVVWi2snuHJ+52C32HeKpJ5krjk52tLe3y00/a/e+/h5tvrtuYFEVR6qHq9Ej9C2gB9AD6AOVnXq8DBtVQXHXq06/OYDHrCAs4TYc+Heo6HEW5eux2+PhjbZHhn34CoxGefx5uuqmuI1MaKb1e39VkMsVERkbGDhw4MOL06dNl8yx27Njh2bNnz6jw8PC4sLCwuKlTp7a02/8o7L1q1aqmcXFx0e3bt4+Njo6OGT9+fEj545vNZnH99ddHmUymmEWLFl20uGb37t07ONeTczVv3rzAsWPHtim//c033wyIioqKiYqKiuncubPp559/rrB2jt1up2fPnlGuV+0tW7bMTwjRddeuXWWf4j///HPjgAEDIlwfO3LkyPD33nvPH6CkpERMmDChdVhYWFxMTEz0ddddZ1q1alXTiz2fqpo+fXqLNm3axIWHh8d98sknFR5v/fr1xpiYmOjIyMjYESNGhFssFgCWL1/uFxUVFeOsIfX11183Aa1YaJ8+fSKvNLb6ojqJ1G3AAinlb0BFxacOAQ1iDGzDl8W42W1cn5CLj1FVZVYaiaNHtTlQs2ZBUREMHAirV8Ptt6s18pQ641wiZv/+/Ul+fn5W5yLCBQUFYvjw4RFPP/10Vnp6emJiYmLytm3bmsyePTsYYPv27Z5Tpkxps2zZssMHDx5M2rt3b3JERMQFl9tv3brVGyAlJSV5/PjxNXb1XERERMlPP/2UmpaWljx9+vTMhx56KKyidqtWrfKNjY01uy7tsmLFioAuXboULF26tMpLaTz55JOtsrKy3FJSUpKSk5P3ffbZZwfOnTt3RZN7d+7c6blmzZqA1NTUpK+++ipt0qRJbaxW63ltbDYbDz74YNsVK1Yc2r9/f1KbNm1K33jjjSCA22+//Zyzcvo777yT/vDDD4cBtGrVytq8eXPLN9980yAWLa5OIhWENqR3MXbgmh8DKy61s2ubF+62UnoP8cHd/YJFrBWlYfr5Z/jtNwgIgFde0W5BQXUdlaKU6dmzZ2FGRoY7wKJFiwITEhIKRowYcQ60JWTefPPNo3Pnzm0J8NJLL7WYMmXKic6dOxeDtkjutGnTzqtSnpGRYbj33nvb7t2719tkMsUkJSV5rFu3zhgdHR0TFRUVM2rUqHCz2XzBp4i5c+cGhoeHx3Xs2DF669atTcrvB7jpppsKg4ODbQADBgwozMrKqvDN5IMPPggYPnx4rvN+Xl6ebvv27U3ee++99E8//bRKiVR+fr7uww8/DF68ePFRLy8vCRAaGmq90rIKH3/8sd+IESNyvLy8pMlkKg0LCyv58ccfz0t+srOzDW5ubnZnTajBgwefW7t2rR+Ar6+v3bmAcX5+vs61hNCwYcNyly5dGngl8dUX1UmksoD2lezvDBy9snDq3tf/y6M4T0/LgALi+6sJtUoDV+iybNaoUTBhgja0N3Bg3cWkKBWwWq1s3LjROGzYsFyApKQkzy5duhS5tomNjS0pKirS5eTk6FJTU7169OhRVOHBHFq3bm1dsGDBkYSEhIKUlJTktm3blj700ENtV65ceTAtLS3ZarXi7AFzOnLkiNusWbNabd26NWX79u0paWlpl1zu4vXXXw8aMGBAhcuh7Ny5s0nv3r3L/iN++OGHfv3798/r1KlTib+/v3Xz5s0XDCeWl5yc7NGyZcvSSy1YDNqixSaTKab87dlnn21Rvm1GRsZ5ixS3atXqvEWMAVq0aGG12WzCOey5cuVK/xMnTpS1Wbp0qV/btm1jR44cGblw4cJ05/bevXsX/vrrrxUmodea6pQ/+AK4XwjxOnDe6s9CiB7AWOC/NRda3Vi3oRCD3Z1e3fNo0kQlUkoDVVoKixdrSdNHH2mLDOt0cN99dR2ZUo99ceiLGp/rcEu7Wypdb62kpERnMplisrOz3dq3b188bNiwczUdg9Pu3bs9Q0JCSpy9K+PGjTszf/78ZsBJZ5tNmzb59OzZM79Vq1ZWgBEjRuSkpaVddDTms88+My5fvjxo69atKRXtz8vLM/j7+5clQKtWrQp4/PHHTwKMHDkyZ9myZQF9+vQpEkJUuJ7bxbZfzDvvvHOsOu0vRafTsXTp0kNPPvlkaGlpqW7AgAF5zl4ogLFjx+aOHTs298svv2zy3HPPtb7xxhvTQBveO3nyZIMY8qlOIvVPYCiwC1iPNk/qr0KI8cAIIBOYXZ2TCyEGA3MBPbBYSjmrgjZ3Av9wnG+3lHJMdc5RHRarnW1b3HCTNm64UY+bm1ttnUpR6s6ePTBzJqSna3Oftm6F4cPrOirlGnCppKc2OOdI5efn6/r37x85a9asZjNmzDgZExNTvHnz5vN6NJKTk929vb3tAQEB9qioqOJt27Z59+rVy3y1Y3batm2b14QJE8I2bNiwv0WLFhUuIKzX66XNZkOv15Odna3/5ZdfjKmpqV4TJ07EZrMJIYS02+3HmzVrZs3LyzvvPfvs2bOG4OBga0xMTMmJEyfcc3JydJfqlbr//vtDf/rppwsqTI8YMSLnpZdeynLd1rp16/N6oDIzM8/roXK68cYbC3fu3JkKsGbNmqYHDhy4ILEcMmRIwfjx4z1OnDhhaNmypbWoqEh4eHhcsgftWlDloT0pZRbQE9gG3Id21d49wJ3AN0AfKWVOVY8nhNAD84EhQAwwWggRU65NJDAd6C2ljAUmVfX4l+PHX89SeMaN4KaFJAwIVUvCKA1LURHMmQP3368lUWFhsGiRSqKUa4LRaLTPmzfv6IIFC5pbLBYefPDBM9u3bzeuXbvWCNrk80cffbTNY489lgUwffr0rNdee63lnj17PECbFP3KK68EV3aO+Pj44oyMDPfExEQPgKVLlwb26dMn37VN3759C7dt22bMysrSl5SUiE8//bTCK/3279/vPmrUqPbvvvvu4crWlGvbtm3xvn37PACWLVvmP3z48JzMzMy9GRkZe7OysvaEhISUfv31103i4uJKsrOz3X777TdPgLS0NPeUlBSvnj17mo1Go/2uu+46/eCDD7YpLi4WoF0Z9+67714Q2zvvvHPMOQHc9VY+iQIYOXJk7po1awLMZrNISUlxT09P9+zfv39h+XYZGRkG0K6AfPXVV1s8/PDDpwASExM9nFdRbtmyxbu0tFQ0b97c6tjnGRUVVWdJbk2qVmVzKeUx4A4hRFOgA1oydaA6CZSL7o7HHgIQQqwA7gCSXdqMB+ZLKc86zn/ygqPUoB82WdDbDHS/7gxNfBvEBYiKotm9W1sTLzNTG8IbN05b4kVdTKFcQ3r37m02mUzmhQsXBjz66KM5a9asOTBx4sQ2kyZNcrPb7YwaNerM9OnTTwL06NHDPHv27GOjR49uZzabdUIIbrrppkp71Ly9veVbb72VPmrUqPY2m434+Piip5566rwJ6mFhYZZp06Zl9uzZM9poNNri4uIqnIc1Y8aMlrm5uYbHHnssDMBgMMjExMR95dvdfPPNed98840xLi6uZPXq1QFTp049L6G54447zi5fvjxgyJAhBe+9996he++9N7ykpERnMBjk/PnzjwQGBtoA/vvf/2ZMmjSpdVRUVKyHh4f08vKyPf/885nVe4XPl5CQUDxs2LCcqKioWL1ez2uvvXbE4FgSql+/fhFLliw5Eh4ebpk5c2aLb7/91tdut4v77rvv5NChQ/MBPvroI/+VK1cGGgwG6enpaV+2bNkh57Dft99+axw8ePBV7+GsDULKqg2vCiECpZQ1tsigEOLPwGAp5QOO+/cAPaSUE13arAXSgN5ow3//kFJ+VcGxHgQeBGjTpk3XI0eOXFZMN488QfqvOv4x9SijH0tQPVJKw5GWBn/5C0REaHWhOqj6aMr5hBA7pZQJrtt2796dHh8ff7quYmoMjhw54jZ69OjwrVu37q/rWK6mhISEDl9++eUB55WN9d3u3buD4uPjwyvaV52r9jKFEGuEEHcIIa7WGn0GIBLoD4wGFgkh/Mo3klIulFImSCkTgoMr7bm9qJISycEkd/TSRo8/tVJJlHLt27v3j++jouCtt2DpUpVEKUo9EhYWZrnvvvtOuxbkbOgyMzMNTzzxRPa1kkRdSnV+cGuAPzm+nhBCzBNCJFziMZXJ4PwCniGOba6OA+ullBYp5WG03qlaqYb6y84ibEV22obk06pNlWugKUr9c+YMTJsG994LGzf+sb1LFzCodcoVpb554IEHzlaldEFD0apVK+s999yTW9dx1JTqTDYfjbZEzINo85geBbYJIZKEEFOFEK2qee7tQKQQoq0Qwh24C+1qQFdr0XqjEEIEAVFoFdRr3Lf/y0dvtxN/nRUPD4/aOIWi1C4pYcMGrR7U99+Dl9f5daIURVGUGletrkQpZb6U8h0pZT+0RYv/AbihlT04IoS4YP5SJceyAhOBr4F9wCopZZIQYqYQYqij2dfAGSFEMrARmFqT87Rcbd9mRy9tdL7BB9caGIpyTThxAh5/XJv/dO4c9OoFq1bBbbfVdWSKoigN2mX380spjwAvAC8IIUYDbwLVWtlUSvkFWqFP123PuXwvgcmOW60xF9s5lOyGm97G9f3VsJ5yjdm1S0uizGZo2hSmTIFbblHr4ymKolwFl51ICSGaoNWQGgvcgNa7lVhDcV1Vv+wswma2E9XWTLNmKpFSrjEdOoC/P1x/vTY3KkD9DiuKolwt1RrDEprBQogPgWxgMVoxzTeArlLKTrUQY637cXMRwmYnvptQ1cyV+s9q1ZZ1KXKUr/H21q7Gmz1bJVFKg6PX67uaTKaYyMjI2IEDB0acPn1a79y3Y8cOz549e0aFh4fHhYWFxU2dOrWlswAkwKpVq5rGxcVFt2/fPjY6Ojpm/PjxIeWPbzabxfXXXx9lMpliFi1aVGFxTYDu3bt3cK4n52revHmBY8eObVN++/Lly/2ioqJiTCZTTFxcXPTXX39d4bpyBQUFolu3bh2sVmvZtpkzZzbz8PDocubMmbLnWtF5XGPKy8vTjRkzJiw0NDQuNjY2unv37h1++OGH8xYYri673c64ceNC27RpExcVFRWzZcuWCtf9W7RokX9UVFRMRERE7COPPNLauf2VV14Jdr4GXbt27bBz505PgF9//dVr5MiR4VcSW31S5URKCDEH7aq6DWhLwnwJDANaSSknSSl31UqEV8GOLRZ0AhKu91JlD5T6LTUVxo6Ff/8b5s//Y7ufX52FpCi1yblEzP79+5P8/PyszkWECwoKxPDhwyOefvrprPT09MTExMTkbdu2NZk9e3YwwPbt2z2nTJnSZtmyZYcPHjyYtHfv3uSIiIgLKoxv3brVGyAlJSV5/PjxZ2sq7ttvv/2cs2r4O++8k/7www+HVdTu9ddfDxo6dOhZg8sVtR9//HFAXFxc4fLly/2qer6777473N/f35qenp6YlJS0b+nSpYdPnjx5RZfprl692vfQoUOe6enpiW+++eaRCRMmXJAwZmVl6Z977rmQH3/8Me3AgQNJ2dnZbuvWrTMCPPDAA2fS0tKSU1JSkidPnpw1adKkUIDu3bubT5w44b5///4GURG4Oj1Sk4FjwGNASynln6WU6x2Txq9ZZjOkpRjQu+npfUODWIhaaYhKS+GNN+Cee7Timq1aQZ8+dR2VolxVPXv2LMzIyHAHWLRoUWBCQkLBiBEjzoG2hMybb755dO7cuS0BXnrppRZTpkw50blz52IAg8HAtGnTzqtSnpGRYbj33nvb7t2719tkMsUkJSV5rFu3zhgdHR0TFRUVM2rUqHCz2XzBp+u5c+cGhoeHx3Xs2DF669atFb5x+Pr62p0XLuXn5+su9iF91apVgXfeeWeu835SUpJHUVGRfubMmRmrVq2qUhdzUlKSx65du3zmzp2boddrnVgmk6n0rrvuuqLK4evWrfO7++67z+h0OgYNGlR47tw5w5EjR84btklNTfUIDw8vcS7iPGjQoHOrV6/2B3At6VBQUKB3fQ2GDBmSu2TJkov2AF5LqpNIxUgpe0gpFziXbGkItu0sxlZio114CYGBquyBUg/9/jvcdRe8/75W4mD0aFixAnr2rOvIFOWqsVqtbNy40Ths2LBcgKSkJM8uXbqctzxLbGxsSVFRkS4nJ0eXmprq1aNHjwqXb3Fq3bq1dcGCBUcSEhIKUlJSktu2bVv60EMPtV25cuXBtLS0ZKvVirMHzOnIkSNus2bNarV169aU7du3p6SlpXld7PhLly71a9u2bezIkSMjFy5cmF5+f3FxsTh27JhHhw4dSl0e4z98+PCcwYMHFxw+fNjz2LFjl+xV+v333z1jYmKKDFWoE3frrbe2M5lMMeVvb7zxRmD5tidOnHALDw8vi61ly5al5ROpmJiYkkOHDnmmpqa6WywW1q9f75+ZmVnW0/Tyyy8Hh4aGxj3//PMh8+fPP+rc3qNHj8KtW7desHjytajK3X5SypTaDKSu/LS1CGGTdOwmqMovoaJcVQcPamviSQlt22rr5XW6JqciKg1A3uef+9b0MX1vu63SXpOSkhKdyWSKyc7Odmvfvn3xsGHDztV0DE67d+/2DAkJKXEuMjxu3Lgz8+fPbwaUrfO6adMmn549e+Y7e2BGjBiRk5aW5lnR8caOHZs7duzY3C+//LLJc8891/rGG29Mc92flZVlMBqN543qrFmzJnDNmjUH9Ho9t9xyy9lly5b5P/vss6cu1qNV3ekoGzZsqNFajMHBwbb//Oc/R0aNGtVOp9PRrVu3gsOHD5f1SkyfPv3U9OnTT7311lsBzz//fMs1a9akA7Rs2dKanZ3dICYlXzRzEEKMdXy7TEopXe5XSkq5tEYiu0p2/VoK6OjVu0H8PJWGpn17GDJEG8q77z61yLBSpy6V9NQG5xyp/Px8Xf/+/SNnzZrVbMaMGSdjYmKKN2/efN6wWnJysru3t7c9ICDAHhUVVbxt2zbvXr16ma92zOUNGTKkYPz48R4nTpwwtGzZsixx8vHxsZeWlpaNDP36669eR44c8Rg8eHAUgMViESEhIaXPPvvsqaCgIGtubq7e9bi5ubn65s2bWwMCAmz79u3ztlqtl+wQuPXWW9sdPHjwgsRv4sSJ2RMnTjyvTmPLli0t6enpZX90Tpw44R4WFmYp/9gxY8bkjRkzJg9gzpw5Qc7hRVfjx4/PmTp1atkcK7PZrPP09GwQ1dwrG9p7H3gPreCm6/33K7m9V9MB1ia7HVL3CXQGPd26VXgxgqJcXXl58M9/wj6XReL/+U94+GGVRCmNmtFotM+bN+/oggULmlssFh588MEz27dvN65du9YI2uTzRx99tM1jjz2WBTB9+vSs1157reWePXs8AGw2G6+88kqli7HGx8cXZ2RkuCcmJnoALF26NLBPnz75rm369u1buG3bNmNWVpa+pKREfPrppxXO80lMTPRwXkG4ZcsW79LSUtG8efPzep+Cg4NtNptNFBUVCcf5AqZMmZKZkZGxNyMjY+/Jkyf3ZGdnu6WlpbnfcMMNhTt37mxy9OhRA8CmTZu8S0tLde3bty+NjY0t6dSpU+HkyZNbOc+ZmprqvmLFigt6EDds2HDIOQne9VY+iQIYOnRo7gcffBBot9v5/vvvfYxGo62iRCojI8MAcOrUKf3ixYubTZgw4RTA3r17y3qmVq5c6RsWFlY22T85OdmjQ4cOdZ7k1oTKUtcBAFLKUtf7DUl6OhQV2GkeLGjRQs2PUuqQlPDDD1oJg5wc7Zfz3Xe1oprqSlJFAaB3795mk8lkXrhwYcCjjz6as2bNmgMTJ05sM2nSJDe73c6oUaPOTJ8+/SRAjx49zLNnzz42evTodmazWSeE4Kabbqq0R83b21u+9dZb6aNGjWpvs9mIj48veuqpp86boB4WFmaZNm1aZs+ePaONRqMtLi6uwnlYH330kf/KlSsDDQaD9PT0tC9btuxQRatm9O3bN++bb75pMmzYsPy1a9cGfPbZZ/td9w8ZMuTskiVLAl588cWs2bNnHxs8eHCk3W4XPj4+tuXLlx9y9v4sX748fcKECaFhYWFxnp6e0t/f3/rqq68eq94rfL4777wzb8OGDb5hYWFxXl5e9sWLF6c795lMppiUlJRkgIcffjg0OTnZG2DatGmZzqHR1157rdnmzZubGgwG6evra33//fcPOx//ww8/NL2tDno4a4PQioc3HAkJCXLHjh1VartmXSlPTThNvwGC95a3rOXIFOUiTp/WEijnAsOdO2tzodpccKWxotQaIcROKeV5C9Hv3r07PT4+/nRdxdQYbNmyxXvOnDnN165de/jSrRsGs9ksevbs2WHHjh0p10rtxt27dwfFx8eHV7SvOnWk3hVC9Khkf3chxLuXEV+d2fFzLkhJXGc1yVypA1LC+vXaIsMbN2qFNZ95Bt5+WyVRitJI3HDDDUX9+/c/51qQs6E7cOCA+4svvphxrSRRl1Kd8gfjgPaV7G8L/PWKornKdv9mRuj1dOzYMH6YyjXm7FmtsGZ+vra8y+rV8Oc/g1o0W1EalUmTJp1pTFeNd+zYseS2227Lv3TLa0NN/uR8gAsmodVXViscOuyBTq8nPl7Nj1KuEufyFTqdtpzLtGnaHKjBg9VcKEVRlGtQpYmUEKINEO6yySSE6FtB0wDgEeBAzYVWuw4elJQWS0La2AkKUldDKVfBoUPwr3/BTTdpRTUBbrmlbmNSFEVRrsileqTuBZ4HpOP2N8etPAHYHe2vCb/tKgKbJCpWT0U1LxSlxlitsGQJLF4MFgvk5mrzohpRV76iKEpDdam/5GuBdLRE6V1gIfBzuTYSKAC2Symv6FLLq2nXtjykEMTG1nUkSoO2bx/MnAn7HVc0DxsGTzyhkihFUZQGotJZrVLK3VLKJVLK94F/Am847rvelkop11xLSRRA4h4rQqfjung1rKfUAosF5s2Dv/5VS6Jat4YFC2DGDDA2iOWlFOWq0Ov1XU0mU0xkZGTswIEDI06fPl02hLBjxw7Pnj17RoWHh8eFhYXFTZ06taWzICXAqlWrmsbFxUW3b98+Njo6Omb8+PEh5Y9vNpvF9ddfH2UymWIWLVp00UV0u3fv3mHTpk0XVG6eN29e4NixYy96me3//vc/b4PB0PW9996r8NgFBQWiW7duHVyv2ps5c2YzDw+PLmfOnCl7rhWdxzWmvLw83ZgxY8JCQ0PjYmNjo7t3797hhx9+8LlYXFVht9sZN25caJs2beKioqJitmzZUmHl6kWLFvlHRUXFRERExD7yyCOtndtfeeWV4KioqBiTyRTTtWvXDjt37vQErYL7yJEjw68ktvqkypcHSSn/KaVMrM1grpbSUjh8xB29QU+nTiqRUmqBXg+7dmnf3323tshw9+51G5OiXIOcS8Ts378/yc/Pz+pcRLigoEAMHz484umnn85KT09PTExMTN62bVuT2bNnBwNs377dc8qUKW2WLVt2+ODBg0l79+5NjoiIKCl//K1bt3oDpKSkJI8fP/5sTcZutVqZNm1aSO/evS9aePL1118PGjp06FnXq/Y+/vjjgLi4uMLly5f7VfVcd999d7i/v781PT09MSkpad/SpUsPnzx58oq6vlevXu176NAhz/T09MQ333zzyIQJEy5IGLOysvTPPfdcyI8//ph24MCBpOzsbLd169YZAR544IEzaWlpySkpKcmTJ0/OmjRpUihA9+7dzSdOnHDfv39/g3gDvmgiJYTo6zqx3Hn/UrerE/aV2b8fbaJ5qAU/vwbxc1Tqg8JCrSo5aFflPf+8Vp38ySfB66ILxCuKUkU9e/YszMjIcAdYtGhRYEJCQsGIESPOgbaEzJtvvnl07ty5LQFeeumlFlOmTDnRuXPnYgCDwcC0adPOq1KekZFhuPfee9vu3bvX22QyxSQlJXmsW7fOGB0dHRMVFRUzatSocLPZfMHltHPnzg0MDw+P69ixY/TWrVublN/v9NJLLzW74447zgYFBV20SNSqVasC77zzzlzn/aSkJI+ioiL9zJkzM1atWhVQldclKSnJY9euXT5z587NcM75NZlMpXfdddcVVQ5ft26d3913331Gp9MxaNCgwnPnzhmOHDlyXr2g1NRUj/Dw8BLnIs6DBg06t3r1an+AgICAsu7BgoICvesCy0OGDMldsmTJRXsAryWV9Uj9CGwUQri73q/k5txf7/22qxDsdqKi9VRUsl9Rqu2nn+DOO+GFF7RCmwDh4RAXV6dhKUpDYbVa2bhxo3HYsGG5AElJSZ5dunQ5b3mW2NjYkqKiIl1OTo4uNTXVq0ePHhUu3+LUunVr64IFC44kJCQUpKSkJLdt27b0oYcearty5cqDaWlpyVarFWcPmNORI0fcZs2a1Wrr1q0p27dvT0lLS6vwU9Lhw4fdPvvsM/+nn376VEX7AYqLi8WxY8c8OnTo4FyKjaVLl/oPHz48Z/DgwQWHDx/2PHbs2CV7lX7//XfPmJiYoqrUorr11lvbmUymmPK3N954I7B82xMnTriFh4eXxdayZcvS8olUTExMyaFDhzxTU1PdLRYL69ev98/MzCzroXj55ZeDQ0ND455//vmQ+fPnH3Vu79GjR+HWrVsbxDyHyl71+9AmkjtrQ10zV+Rdyq4d+Uh0xHZUSZRyhXJz4bXX4IsvtPuBgVBQoOZBKQ1S2q9ZFyyCe6WiureotNekpKREZzKZYrKzs93at29fPGzYsHM1HYPT7t27PUNCQkqca8WNGzfuzPz585sBJ51tNm3a5NOzZ898Zw/MiBEjctLS0jzLH2vChAmhs2bNOl7ZVeFZWVkGo9F4Xm/VmjVrAtesWXNAr9dzyy23nF22bJn/s88+e0pcpM7cxbZfzIYNGw5V6wGXEBwcbPvPf/5zZNSoUe10Oh3dunUrOHz4cFlxxunTp5+aPn36qbfeeivg+eefb7lmzZp0gJYtW1qzs7MbRDXsiyZSjgnmrveX1Ho0V0niHhtCr6fzdWpYT7lMUsK338Krr2oVyt3dYcIErT6UKqehNFCXSnpqg3OOVH5+vq5///6Rs2bNajZjxoyTMTExxZs3bz5vWC05Odnd29vbHhAQYI+Kiiretm2bd69evcxXO2aAPXv2+IwdO7YdwNmzZw0bN270NRgM8p577sl1tvHx8bGXlpaWfaL/9ddfvY4cOeIxePDgKACLxSJCQkJKn3322VNBQUHW3Nzc8/645Obm6ps3b24NCAiw7du3z9tqtXKpXqlbb7213cGDBy9I/CZOnJg9ceLEM67bWrZsaUlPTy97ozxx4oR7WFjYBYW3x4wZkzdmzJg8gDlz5gRVlDyOHz8+Z+rUqWVzrMxms87T09N+QcNrUKPrkikthSNH3NDrdXTqpCqaK5fBbtcqkj/7rJZEde0KK1fCX/6ikihFqSVGo9E+b968owsWLGhusVh48MEHz2zfvt24du1aI2iTzx999NE2jz32WBbA9OnTs1577bWWe/bs8QCw2Wy88sorwZWdIz4+vjgjI8M9MTHRA2Dp0qWBffr0OW8pk759+xZu27bNmJWVpS8pKRGffvpphfN8MjIy9jpvQ4YMOfvvf//7qGsSBVpvjs1mE0VFRcJxvoApU6ZkOh938uTJPdnZ2W5paWnuN9xwQ+HOnTubHD161ACwadMm79LSUl379u1LY2NjSzp16lQ4efLkVs6rFlNTU91XrFhxQQ/ihg0bDqWkpCSXv5VPogCGDh2a+8EHHwTa7Xa+//57H6PRaKsokcrIyDAAnDp1Sr948eJmEyZMOAWwd+/esjfZlStX+oaFhZVN9k9OTvbo0KFDnSS5Na3KM/qFEN2BeCnlIpdtdwD/QqtsvkRK+WzNh1izjh4Fm8VOy1Z2jEbVI6VcBp0OQkPBx0erCTVsmFofT1Gugt69e5tNJpN54cKFAY8++mjOmjVrDkycOLHNpEmT3Ox2O6NGjTozffr0kwA9evQwz549+9jo0aPbmc1mnRCCm266qdIeNW9vb/nWW2+ljxo1qr3NZiM+Pr7oqaeeOm+OU1hYmGXatGmZPXv2jDYajba4uLhK52FdSt++ffO++eabJsOGDctfu3ZtwGeffbbfdf+QIUPOLlmyJODFF1/Mmj179rHBgwdH2u124ePjY1u+fPkhZ+/P8uXL0ydMmBAaFhYW5+npKf39/a2vvvrqFZUluvPOO/M2bNjgGxYWFufl5WVfvHhxunOfyWSKSUlJSQZ4+OGHQ5OTk70Bpk2blukcGn3ttdeabd68uanBYJC+vr7W999//7Dz8T/88EPT22677ar3cNYGIZ0TYy/VUIgNgF1KebvjfhsgBSgETgEdgAeklO/VUqxVkpCQIHfs2HHR/d9+Z+ehv2ZxfR/B8hUtr2JkyjUtIwNOnYLrrtPul5RAXh40a1anYSlKTRFC7JRSJrhu2717d3p8fPzpuoqpMdiyZYv3nDlzmq9du/bwpVs3DGazWfTs2bPDjh07Utzcro1pUrt37w6Kj48Pr2hfdT5GxwNbXO7fhVbx/DopZQzwDfDg5QZ5taSmFoNdEh6hKksrVWC3w4cfalfkTZ8O+Y5efg8PlUQpinLFbrjhhqL+/fufcy3I2dAdOHDA/cUXX8y4VpKoS6lONhEIZLvc/xOwSUqZ4bi/HnihpgKrLfsS8xA6Qfv2ai6LcgkHD2rLuyQlafe7dPmjtIGiKEoNmTRp0gXzkxqyjh07lnTs2PGC4qjXquokUrlAcwAhhAfQE3jJZb8E6n3VwUMH7QidnoiIhpEJK7XAYoH33tOKaVqtWs/T9OnQp09dR6YoiqLUM9VJpH4HHhBCfAcMBzyBr132t+X8Hqt6R0o4fswNoYfISJVIKRfx9NOwebP2/YgR8Pjj0OSixYsVRVGURqw6idQLaPOgfkWbG/WtlNJ1VvdtwLYajK3GnT4N5iJJU6MkOFglUspF3HknpKdrCwx37VrX0SiKoij1WJUTKSnlViFEF7S5UXnACuc+IUQgWpL1aY1HWIPS0yV2m53QMEll1WaVRmbHDkhOhrFjtfu9esHq1VCF5RYURVGUxq1a7xRSyjQgrYLtZ4Anayqo2rIv1ey4Yk8V4lTQlnKZNw/WrAEhICEBYmK0fSqJUpR64ejRo4YJEya02b17t3fTpk1tQUFBlttvvz13w4YNfhs3bjxQ1/EpSrXfLYQQTYEbgXaOTYfQhvnyL/6o+iE5MRchtLVklUZu0yZ4+WWtNpTBAPffD5GRdR2Voigu7HY7Q4cOjRgzZsyZzz///BDAzz//7LVmzRq/Og5NUcpUqxyzEOIB4BiwGnjFcVsNHBdC3F/dkwshBgshUoUQB4QQz1TSbqQQQgohEi7WpioO7bcidDpV+qAxO3sW/vY3mDxZS6Li4rQ6UePHQwOpaaIoDcXnn39uNBgM8umnny6rLt6rVy9zv379CgoLC/WDBw9u17Zt29ihQ4e2dS6N8tRTT7WMi4uLjoyMjB09enSYc3v37t07PPLII607duwYHR4eHvfVV181AbBarTz44IMhkZGRsVFRUTEvvvhiM4DNmzd7d+vWrUNsbGz0DTfcEHnkyBH1B0KpUHWWiBkKLETrgfo74CiuQyzwGLBQCHFSSvlZFY+nB+YDNwHHge1CiPVSyuRy7YzAE9TARPZjR3Sg0xEZqZaGabRefx2+/ho8PbVFhu+6Sy3voihVFRcXfdF9U6ee4K9/zQVgyRI/Xn314ktHJCbuq8rp9uzZ4xUfH1/hEiz79u3z+v333w+Fh4dbunbtavr222+b/OlPfyqYOnXqyTlz5pwAGDZsWNsVK1b4OhfUtVqtYu/evftWrlzpO3PmzFaDBw9O+/e//x189OhR9+Tk5CQ3Nzeys7P1JSUl4vHHH2+zYcOGA61atbIuWrTI/6mnnmq9evXq9KrErTQu1RnaexrYB/SQUha4bP9eCPEe8AswDahSIgV0Bw5IKQ8BCCFWAHcAyeXavQDMBqZWI9YLFBfD6dNuuLnpCAtT818aFSm1OVAAjz6qzY164glo3bpu41IU5bJ17NixsH379haA2NjYooMHD7oDfPnll8bXXnutRXFxsS43N9cQExNjRrtAilGjRp0FuP766wunTp3qDtqabw8//PApZ5Xt5s2b27Zv3+65f/9+r4EDB0aBNsQYHBx8wWK9igLVS6TigZnlkigApJT5QoglaD1VVdUabZjQ6TjQw7WB4yrBUCnlBiHERRMpIcSDOJanadOmTYVtjh4Fm81OaGs7np4qkWoU7HZYu1brgVqwAPR6CAyEV16p68gU5dpUxZ4k/vrX3LLeqSvQsWNH89q1a/0r2ufh4VG2zIBer8dqtYqioiIxZcqUsG3btiVHRERYJk+e3Kq4uLisy9nT01MCGAwGbDabuNh5pZQiIiLC/Pvvv6dc6XNQGr7qjGlc9JfOoUbXzhBC6IDXgCmXaiulXCilTJBSJgQHB1fY5sAhC9gkYeGgU0M5Dd/Ro/Dww/DSS7BzJ2zcWNcRKYpSTbfffnt+aWmpmDNnTpBz27Zt27z+97//VVght6ioSAfQokULa15enu6zzz6rMAlzNWjQoHNvv/12kMWidThlZ2frO3XqVJyTk2P47rvvfABKSkrEjh07PGvkSSkNTnUyit3AOCGET/kdQogmwDhHm6rKAEJd7oc4tjkZgTjgRyFEOtqSNOsvd8J50r5CBNCmveqNatBsNli2TJv79Ntv4O+vXZ03aFBdR6YoSjXpdDrWr19/8IcffmgaGhoaFxERETtt2rTWLVq0qHCYLSgoyHb33Xefio6Ojh0wYEBUfHx84aXO8eSTT54KCQkpNZlMsR06dIh55513Ajw9PeWKFSsOPvPMMyEdOnSIiY2NjblY8qYoQlZxEVYhxDBgDbAfmMcfc5mck80jgBFSynVVPJ4BrSbVILQEajswRkqZdJH2PwJPlaumfoGEhAS5Y8eFTR58MJPvNwj+/qI748YFViVE5Vpz4IC2yHCy41fzlltgyhTw9a3buBTlGiCE2CmlPO+D6u7du9Pj4+NP11VMilJf7N69Oyg+Pj68on3VqWy+VggxEW3i9+v8MZQngEJgYlWTKMfxrI7jfQ3ogXellElCiJnADinl+qoeqyrSD0mEumKvYdu9W0uimjfXShxcf31dR6QoiqI0cNWtbL5ACPEhWsmCto7NzoKcedU9uZTyC+CLctueu0jb/tU9/h+PhcxjBoReEBGhhvYalLy8P3qchg/XLs8cNgx8LhiBVhRFUZQad8mswjEEdwfa0N1pYJ2UcnVtB1aTTp2CYrPAz99KQIBKpBoEsxnefBPWrYOPPoJWrbR6UHffXdeRKYqiKI1IpVmFEMIf+BFt0rdAG857RQhxs5RyZ+2HVzPS00Ha7bRqVYpBraF27fv1V/jXvyAzU0uedu7UEilFURRFucoulVXMADoCn6PNZYoCHkarcN61dkOrOadO2ZF2SYsWOoS4VBUHpd7Kz4e5c7XaUKCtjff3v/+x0LCiKIqiXGWXSqRuB76SUg51bnCUIpgjhAiRUh6vzeBqSt5ZMyAxGlVv1DVrxw6YMQNOn9bWxBs/HsaO1RYcVhRFUZQ6cqk6UqGUmwyOtgSMAMJqJaJacOZ0PgiBt496071m+flpCw536qQtMnzffSqJUhRFUercpd6JPICcctvOuuy7JuSdKUYIDzy8VUXza4aUWi9UQoK2Tl5EBCxeDLGxapFhRVEUpd64knekGl0Spjbl5ZYgdODlra/rUJSqyMrSFhV+5BH4/vs/tnfsqJIoRWmEhBBd77jjDmfJHSwWC/7+/vEDBgyIqM3z6vX6riaTKSYyMjJ24MCBEadPny57Ezl48KDboEGD2oeFhcWFhobG3XvvvaHFxcVlk3CPHj1quO2229qFhobGxcbGRvfr1y9iz549F3RAFBQUiG7dunWwWq1l25YtW+YnhOi6a9eusmVpUlNT3SMjI2NdHzt58uRWzz33XPPqnK+6Pv7446bh4eFxbdq0iXv22WdbVNTmhRdeaBYZGRkbERERO3PmzGbO7UVFRaJjx47RHTp0iImIiIh98skna+SqoKrEVFmbivYVFxeLhISEDs6lgqqjKu9KU4QQ6503YDlaEvWi63bHrcoFOa+mgrwShNDhqVZKqt/sdli9Gu68E7ZuBaNR26YoSqPm5eVlT01N9SooKBAAn376adPmzZtX/x2vmjw8POwpKSnJ+/fvT/Lz87O++uqrwQB2u51hw4ZFDB06NPfIkSOJhw8fTiwsLNQ98cQTrZ37hw4dGtG3b9/8Y8eOJSYlJe2bNWtWRmZmplv5c7z++utBQ4cOPet6RfmKFSsCunTpUrB06dKAqsRZnfNVh9Vq5cknn2zzxRdfpKWlpSV98sknATt37jzvnXT79u2eS5cuDf7tt9/27du3L+mrr77yS0xM9ABtkegtW7akpqamJiclJSV///33Tb///vuLFvn7/PPPjSNHjgy/0pgqa3OxfZ6enrJfv37nFi9eXKXX3FVVJpl0dtzK61nBtnrZS1VYYEHoBT4+6oq9euvoUXjhBdi1S7s/YABMmwZBQZU/TlGUqyIujujaOG5iIvuq0u7GG2/MW716td+999579qOPPgoYOXJkztatW5sALFiwIODNN99sbrFYRJcuXQqXLl16xGAwcOONN7Y/ceKEe0lJie7hhx/Ofuqpp06npqa6DxkyJLJ79+4FO3bsaNK8efPSr7/++kCTJk0qff/q2bNn4Z49e7wAPvvsM6OHh4f9iSeeOANgMBh46623jrVr167TnDlzMjdu3OhjMBjk008/fcr5+F69epkrOu6qVasCV6xYcch5Py8vT7d9+/Ym3333XerQoUMj//Of/2Re6rX5/PPPjVU9X3X8+OOPPmFhYSUxMTGlACNGjMj5+OOP/bp27ZrlbLN3716vzp07FxiNRjtA796981esWOH3r3/9K1un0+Hr62sHKC0tFVarVVzplfNViamyNpXt+/Of/5z7zDPPtH7kkUfKT2mqVKU9UlJKXTVv9XLszFwEQqfHW82Rqp927NAWGd61CwIC4JVX4NVXVRKlKEqZe+65J2flypX+RUVFYt++fd69evUqBPjtt988P/7444AdO3akpKSkJOt0OvnWW28FAnzwwQfpSUlJ+37//ffkt99+u3lWVpYe4OjRo56PP/74yQMHDiT5+vrali5d6l/Zua1WKxs3bjQOGzYsF7TkIT4+vsi1TUBAgL1ly5alycnJHnv27Llgf0WKi4vFsWPHPDp06FDq3Pbhhx/69e/fP69Tp04l/v7+1s2bN3tf6jhVPR9A165dO5hMppjyt7Vr1xrLtz127Jh769aty2ILCQkpzcjIOG+dteuuu87866+/GrOysvT5+fm6b7/91vfYsWNlbaxWKyaTKaZ58+bx/fr1Ozdw4MALFpLu1KmTyWQyxUyYMCHsu+++83PG9MknnzS9nJgqa1PZvm7dupn37NlT7WUxGsVlT2Yz6HV6vL1Vj1S9FBenrY8XHw+TJ0PTC/7vKIpSx6rac1RbevToYT5+/LjHokWLAm688cayJcm++uorY2Jiond8fHw0QHFxsa5Zs2ZWgNmzZzffsGGDH0BWVpZbUlKSZ0hIiKV169Yl119/vRmgc+fORenp6RXOJSopKdGZTKaY7Oxst/bt2xcPGzbsXE0+p6ysLIPRaLS6blu1alXA448/fhJg5MiROcuWLQvo06dP0cV6cqrbw7Nz587Uy423Il26dCl+4oknsgYNGhTl5eVlj42NLdLr/+hTMRgMpKSkJJ8+fVp/6623tt++fbtnt27dil2PsWfPnhTQetbee++9wE8++SS9JmOsKoPBgJubmzx79qzO39+/yvNKGkUiVVws0OlVIlVvlJbCBx9oc6F8fMDTE5YtgyZN6joyRVHqscGDB+c+//zzod98803qyZMnDQBSSjFq1Kgz8+fPz3Bt+/nnnxv/97//GXfs2JFiNBrt3bt372A2m3UA7u7uZcN4er1eOreX55wjlZ+fr+vfv3/krFmzms2YMeNkXFycee3atef1YuXk5OhOnDjhHhMTU5KVlWUov78iPj4+9tLS0rJzZ2dn63/55Rdjamqq18SJE7HZbEIIIe12+/HmzZtb8/Lyzhv1ycnJ0bdt27akTZs2pVU5H2g9UoWFhReMHs2aNevYsGHD8l23hYaGntfbc/z48fN6c5yefPLJ008++eRpgIkTJ7YOCQm5oE1QUJCtT58++Z999plv+USqOqoSU2VtLvV4i8UivL29qzVNqcGPdVlLSikt1SN0Ory8VCJV5/bsgTFjYP58mDfvj+0qiVIU5RIeeeSR00899VRm9+7dy+b/DB48+Nznn3/un5GRYQAtGUlLS3PPzc3V+/r62oxGo33Xrl2eu3fvvuyVzI1Go33evHlHFyxY0NxisTB06ND84uJi3RtvvBEI2vDVhAkTQkeNGnXaaDTab7/99vzS0lIxZ86csvkJ27Zt8/rqq6/O+0MXHBxss9lsoqioSAAsW7bMf/jw4TmZmZl7MzIy9mZlZe0JCQkp/frrr5v4+vramzVrZlm/fr3R+Tx//PFH34EDBxZU9Xyg9UilpKQkl7+VT6IA+vXrV5ienu6ZkpLiXlxcLNasWRMwcuTI3PLtnK/9/v373Tds2OD3wAMP5ABkZmYanFc6FhQUiI0bNzaNjo6+aBJ122235V+qN6oqMVXWprJ9WVlZej8/P6uHh4dKpFzlF57DYnVH6HSqR6ouFRVp857uv19b/DAsDIYMqeuoFEW5hrRv394yY8aMk67bunbtWjxjxoyMQYMGRUVFRcUMHDgw6tixY24jR47Ms1qtol27drFTp05tHR8ff8HcnOro3bu32WQymRcuXBig0+lYu3btgTVr1viHhYXFtW3bNs7Dw8M+b968DACdTsf69esP/vDDD01DQ0PjIiIiYqdNm9a6devWF1xp2Ldv37xvvvmmCcDq1asDRowYcdZ1/x133HF2+fLlAQBLliw5/OKLL7Y0mUwx/fr16zBt2rTM2NjYkuqcrzrc3Nz497//fXTw4MFRkZGRscOGDctJSEgoBujXr19Eenq6G8DQoUPbt2/fPva2226L+O9//3s0KCjIBnDs2DG3Pn36dIiKiorp3LlzzIABA86NHj06r/x5nHOkyt8qmiNVlZgqa1PZvi+//LKp67BxVQkp6+WFdpctISFB7tixo+z+0cOHGXmLhRK3NnzyCURGqhoIV90vv8CLL8KJE1odqL/+VVvixd390o9VFOWqEELslFImuG7bvXt3enx8/Om6iqkx2LJli/ecOXOar1279nBdx9LY3Xzzze3nzJlzvFOnTiXl9+3evTsoPj4+vKLHNfg5UkUFZix2L0CVP6gT+/fDxIna91FR8Pzz0KFD3cakKIpST9xwww1FO3bsOGe1WjGoZa/qTHFxsRg6dGhuRUnUpTT4n1rRuTwstqboEfj4NPiRzPonMhLuuANCQuCee9T6eIqiKOVMmjTpTF3H0Nh5enrKiRMnXtbPodrvakKIcOBGoDnwgZQyXQjhDrQAsqSUF8zWr0vFBYVYrW7oQSVSV8OZM9pcqHvu0dbFA/j73+s2JkVRFEWpJdVKpIQQs4HJgB6tivnPQDrgCSQDM4D/1miEV6jgXCHodLi7S/R6NbRXa6SEzz+H//wHzp2DkyfhnXe0BYcVRVEUpYGqcheNEOIhYCowH7gZKHuHlFKeA9YDt9d0gFeq6GwxQujw8JDVLlymVFFmJjz2GPzzn1oS1auXNrlcvd6KoihKA1edHqkJwKdSyklCiMAK9u8BJtZMWDWn4JwVodPh6dmwrk6sF5yLDL/xhlY+vmlTmDIFbrlFJVGKoihKo1CdRCoKeLOS/aeAerc4mrnAjhBCJVK1ITcX3npLS6IGDdIWGQ6o9sLZiqIoinLNqk4iVQxUVhk2DMi9omhqQYnZjtAJPFX5qJphtWq9TXq9ljQ9+6z2/cCBdR2ZoiiKolx11bmM7VdgeEU7hBCewD3ATzURVE0qKtYhdHrVI1UTUlNh7FhtnTynm25SSZSiKIrSaFWnR+pV4GshxDLgXce2FkKIPwH/BEKAMTUc3xUrKRQInQ4Pjyov5KyUV1ICixbB0qXavCirFe6+W+uJUhSl0Th8+LC32WyusWJwXl5e1rZt2xbV1PEARo0aFf7999/7BgYGWvfv359U1cedPn1av3jx4oBnnnnmVEX7J0+e3KpJkya2mTNnZlfleNVtr1y7qtwjJaX8DngE+DPwnWPzMuALIB4YL6X8ucYjvELmEp2abH4lfv8dRo+G99/XShw4v1dJlKI0Omaz2eDj42OtqVt1k7LPP//cOHLkyPDK2tx3332n169fv7+6z+3MmTP6d955p1l1H6co1apQKaVcCLQFJqFNPH8beAqIkFK+X9PBXSmr1UapRa8mm1+O0lJ45RV44AE4ehTattXqQk2ZAt7edR2doihKhYYMGVIQHBxsrazNuXPndP3794/o0KFDTGRkZOyiRYv8p0yZEnLs2DEPk8kU89BDD4UATJs2rUV4eHhc165dO+zfv9/jUueurP2CBQsCOnbsGG0ymWLGjBkTZrVamTBhQuuXX3452Nlm8uTJrZ577rnml/vclbpR7S5aKWUW8HotxFLjLCWlWGw6QCVS1WYwaHOi9HoYNw7uv18tMqwoSp3o1KmTqbS0VFdUVKTLy8szmEymGIAXX3zx+MiRI89V93hr1qxp2qJFC8uPP/54ALTeqL59+xbedtttXikpKckAmzdv9v70008D9u7dm2yxWLjuuutiOnfufNFhyMra//bbb54ff/xxwI4dO1I8PDzkX/7ylzZvvfVW4N13350zadKkNtOnTz8FsG7dOv+vv/467XJeI6XuNOiFz8xmM6V2d0Dg4aESqUvKywOLBYKCQKfTFhguLtYWG1YURakje/bsSQFtaO+9994L/OSTT9Kv5HhdunQx/+1vfwt95JFHWt9xxx15gwcPLjh9+vR58xU2btzY5JZbbsk1Go12gJtvvjm3smNW1v6rr74yJiYmesfHx0cDFBcX65o1a2adOHHimTNnzhjS09PdTpw4YfD19bVFRERYruS5KVdflRMpIcQPVWgmpZSDriCeGlVsLsBiMQBS9UhVRkr4/nttKM9kgrlztRIHbdrUdWSKoig1rlOnTiW//fZb8ieffOL797//vfV33313bvz48bW2cLCUUowaNerM/PnzM8rvGzp06Nnly5f7Z2VluY0YMSKntmJQak915ki1Q5sf5XqLBPoC/YE4R5t6w1JSgtWmDUepOlIXcfo0TJ0KzzwDOTlaD1RRjV5EoyiKUiNuu+22/CvtjQJIT093MxqN9gkTJuRMnjw56/fff/f29fW1FRYWlr0nDhw4sOCLL77wKygoEGfPntV9++23fpUds7L2gwcPPvf555/7Z2RkGACys7P1aWlp7gB/+ctfcj755JOAzz//3P+ee+45e6XPTbn6qtwjJaUMr2i7EMIDbSHje4F+NRNWzbCWlGCVWiLl41OtefUNn5Tw2Wfw2mtQUKBNIH/iCRg+XBvWUxRFKcfLy8taWFhYo+UPqtLOOUeq/PaK5kjdfvvtbX/55Rfj2bNnDc2bN+/0zDPPZD755JOnXdvs3LnTa/r06SE6nQ6DwSAXLFhwpEWLFrauXbsWREZGxg4cODDv7bffPj58+PCcuLi42MDAQEunTp0KnY/v169fxJIlS46Eh4eXDcPdcMMNRRdr37Vr1+IZM2ZkDBo0KMput+Pm5ibnzZt3NCoqqjQhIaG4sLBQ17x589KwsDBLZedQ6ichZc0MeTnqSxmklKNr5ICXKSEhQe7YsQOAlN928tz0ElKzEpg2zcyYMb51GVr9YbfDpEmwdat2//rr4W9/g+bqYhFFaayEEDullAmu23bv3p0eHx9/+mKPUZTGYvfu3UHx8fHhFe2rycnmW4CXa/B4V8xSYsZqdQPAy0stoltGp9PmQiUlwVNPweDBapFhRVEURbkMNTmG0xao1vXxQojBQohUIcQBIcQzFeyfLIRIFkLsEUJ8L4QIq87xbRYrFqsWkrd3I08UDh2C7dv/uP/AA7B6NQwZopIoRVEURblM1blq72KXcAUANwKPAz9W43h6YD5wE3Ac2C6EWC+lTHZptgtIkFIWCSEeAV4B/q+q5ygtLqbUrhWqbbQ9UhYLLFmiFdM0GuHjj6FpU60mVEBAXUenKEr9Zrfb7UKn06nLnpVGy263C+Ci68xVZ2gvHbjYfyYBpKIlU1XVHTggpTwEIIRYAdwBlCVSUsqNLu1/Af5SjeNjs5Q07h6p5GR44QXY71gtoV8/NZFcUZTqSDx16lRMcHBwnkqmlMbIbreLU6dO+QKJF2tTnURqJhcmUhLIAdKA76SU1VkZuDVwzOX+caBHJe3vB76saIcQ4kHgQYA2LrWPrFY7pVbtKTZp0ojWhispgbffhuXLtYnlrVvDjBnQrVtdR6YoyjXEarU+kJWVtTgrKyuOmp0KoijXCjuQaLVaH7hYg+qUP/hHTUR0OYQQfwESuEh5BccagAtBu2rPud1mKcbqSKQaVY/UU0/Bzz9rvU933w0PPwxeXnUdlaIo15iuXbueBIbWdRyKUp9VKZESQjQBdgOvSyn/W0PnzgBCXe6HOLaVP/eNwN+AflLKkuqcwG61UVpqAEMjqyN1zz1w8iT8/e8QF1fX0SiKoihKg1Wl7EJKWQAEAgU1eO7tQKQQoq0Qwh24C1jv2kAI0Rl4GxgqpTxZ3RPYbJISR/kDb+8GnEht2QKLFv1xv3t3+OgjlUQpiqIoSi2rzhypX9CG1xbXxImllFYhxETga0APvCulTBJCzAR2SCnXA68CTYDVQrtE/6iUssrdzCUlNux2HUKAh0cDTKRyc+Hf/4YvHVPHeveGmBjtezWpXFEURVFqXXUSqWeAH4QQ24D3ZQ2URJdSfgF8UW7bcy7f33glxzebtRA9PSU6XQOaIyUlfPuttshwbi54eMAjj2hFNhVFURRFuWoqTaQctaNOSSnNwGvAWbQeqVeEEAeB8qvbSinloFqJ9DIUFUuE0BKpBuPkSZg1CzZt0u537apdkRcaWvnjFEVRFEWpcZfqkTqMVrvpI6AdWrmDo4599X5httJSPSAaViL19ttaEuXjo62XN2yYqkyuKIqiKHXkUomUcNyQUobXejQ1zFKiB9EAEim7/Y85TxMnatXKJ06EZs3qNi5FURRFaeQa9IzkkhIdgmt4aM9uhw8+gPvv15InAH9/mDlTJVGKoiiKUg9UZ7L5NaekROtQ8/C4BhOpgwe1hCkpSbu/eTMMHFi3MSmKoiiKcp6qJFJ9hBDVqYC+9AriqVHFJXq41iabWyzw3nvw7rtgtWo9T9OnQ58+dR2ZoiiKoijlVCVBKlvH7hIE2mT0epNIXXOTzZOT4Z//1HqjAEaMgMcfhyZN6jYuRVEURVEqVJVEaiFaMc5rjsWiLVR8zSRSaWlaEhUSoi3v0rVrXUekKIqiKEolqpJIbZZSfljrkdSCkhKDY2ivriOpxOnTEBSkfX/HHdpw3m231fOgFUVRFEWBBn7VXmmpjno72bygAF58UasDdfy4tk0I+POfVRKlKIqiKNeIBp1IlZRqT6/eDe1t2gSjRsGnn2o9UImJdR2RoiiKoiiXoWGXP7AYEELg41NPKn+fPQuvvgrffKPdj4uD556Ddu3qNi5FURRFUS5LpYmUlPKa7rGylBpACLy86kEi9csv8Le/QV6eNnQ3YQLcddcfFcsVRVEURbnmNOgeKYtVK39QLxKpZs2gqAi6d9cSqtat6zoiRVEURVGuUINOpEotBoQAb+86SKTsdvjpJ7jhBm0Sebt2sGQJREaqRYYVRVEUpYFo0ONKpRY36qRH6uhRePhhePJJ+PrrP7ZHRakkSlEURVEakIbdI2XV6kj5+FylfNFm0xYZfustKC3VFhhWpQwURVEUpcFq2ImUxQ2hF1dnaG//fnjhBW2ZF4BbboEpU8DXt/bPrSiKoihKnWiwiZSUEovVAPqrMEdq2zZtTTybDZo31yaTX3997Z5TURRFUZQ612ATKZvNqk0297gKdaSuu05bH697d5g4EXx8avd8iqIoiqLUCw02kbJbbVisbngI8Pau4TlSZjO8/z785S9gNIKHhzY3Ss2HUhRFUZRGpcEmUlarlVKrAQ9qOJH69Vf4178gMxNycrRhPFBJlKIoiqI0Qg02kSop1r66u0sMhhpIpPLz4b//hXXrtPtRUTBixJUfV1EURVGUa1aDTaQKC+1ADS1Y/OOPMGsWnD4Nbm4wfjyMHQuGBvvyKYqiKIpSBQ02Eyg2awnUFSdSaWnw1FPa9506aYsMh4df2TEVRVEURWkQGmwiVWTWrtS74kQqKgruvBPCwmDUKLXIsKIoiqIoZRpsVlBs1ob2PDyq+cDsbG1plz17/tj29NPwf/+nkihFURRFUc7TgHuktJ4oD48q9kjZ7fDJJ/D661BUBHl58O67tRihoiiKoijXuoabSBVVY47U0aPa8i67dmn3Bw6EadNqMTpFURRFURqCBptImc3a10oTKZsNli+Ht9/WFhkOCIBnntESKUVRFEVRlEtosIlUcbGWQHl5VZJInTsHS5ZoSdRtt8HkydC06VWKUFEURVGUa12DTaTMZVftldtRWqpNGjcYwN8f/v53rVGvXlc/SEVRFEVRrmkN9jI0c1EFk8337IExY2DZsj+2DRigkihFURRFUS5Lw02kil3qSBUVwauvwv33Q3o6fPutNj9KURRFURTlCtRpIiWEGCyESBVCHBBCPFPBfg8hxErH/m1CiPCqHrvYMdm8SXa6VgNq5UoQAu67D95/H/T6GnoWiqIoiqI0VnWWSAkh9MB8YAgQA4wWQsSUa3Y/cFZKGQH8B5hd1eObC6x45ecT8PEyOHECOnTQrtCbMAHc3WvqaSiKoiiK0ojVZY9Ud+CAlPKQlLIUWAHcUa7NHcASx/cfA4OEEKIqBy+26NHZbXi522DiRO3qvKioGgteURRFURSlLq/aaw0cc7l/HOhxsTZSSqsQIg8IBE67NhJCPAg8CNCmTRsAunYzUnSqgFZjnoShYbXyBBRFURRFadwaRPkDKeVCYCFAQkKCBPjLWHf+MlYlUIqiKIqi1J66TKQygFCX+yGObRW1OS6EMAC+wJnKDrpz587TQogjjrtBlOu9aqTU66BRr4N6DZzU66BxfR3UJ09FuQx1mUhtByKFEG3REqa7gDHl2qwH/gr8DPwZ+EFKWenieVLKYOf3QogdUsqEGo36GqReB416HdRr4KReB416HRTlytVZIuWY8zQR+BrQA+9KKZOEEDOBHVLK9cA7wDIhxAEgBy3ZUhRFURRFqRfqdI6UlPIL4Ity255z+b4Y/r+9u4+WqyrvOP79KYIGAyyMduFboy3RKOICsUVtS3yBSmgTRRQUhLDA14WKupDlSxeXSlGIaEVF3hYNQUHAF0i1KgoEDCUoBo0RBaIJAaEFESMYQiA8/ePZQ06GuZlz5849w53+PmudNTPn7DnnmX3PvfPcs/fZmzc3HZeZmZlZHUM7snlx5qADeJxwPSTXg+ugxfWQXA9m46QuXY7MzMzMbBTDfkXKzMzMbMI4kTIzMzPr0VAkUhM5+fFkUqMePiTpRknLJV0uaejGjelWB5Vyb5IUkoby1u869SDpLeV8+KWk85uOsQk1fieeK+lKSTeU34vZg4hzIkk6R9JdklaMsl2STi11tFzS7k3HaDaZTfpEaqInP54satbDDcAeEbErOXfhyc1GObFq1gGSpgIfAK5rNsJm1KkHSTsDHwVeFREvBo5uOs6JVvN8+ARwUUTsRg6vclqzUTZiAfD6LWzfF9i5LO8EvtxATGZDY9InUkzw5MeTSNd6iIgrI2JdebmUHE1+mNQ5FwA+SSbT65sMrkF16uEdwJci4l6AiLir4RibUKceAtiuPN8euKPB+BoREVeT4/CNZi6wMNJSYAdJOzUTndnkNwyJVKfJj581WpmIeBhoTX48TOrUQ9URwHcnNKLmda2D0mzxnIj4TpOBNazOuTADmCHpGklLJW3pisVkVaceRoBDJN1Ojmn3vmZCe1wZ698OM6sYikmLbWwkHQLsAew16FiaJOkJwGeBeQMO5fFgK7IpZxZ5ZfJqSS+JiD8OMqgBeCuwICJOkfQKciaFXSLikUEHZmaTwzBckRrL5MfUnfx4EqpTD0h6HfBxYE5EPNhQbE3pVgdTgV2AxZJWA3sCi4aww3mdc+F2YFFEPBQRq4CbycRqmNSphyOAiwAi4lrgyeREvv+f1PrbYWadDUMi9ejkx5K2JjuMLmor05r8GGpOfjwJda0HSbsBZ5BJ1DD2idliHUTE2oiYFhHTI2I62U9sTkRcP5hwJ0yd34lLyKtRSJpGNvX9tsEYm1CnHtYArwWQNJNMpO5uNMrBWwQcWu7e2xNYGxF3Djoos8li0jftefLjVLMe5gNPBS4ufe3XRMScgQXdZzXrYOjVrIfvA/tIuhHYCBwTEUN1lbZmPXwYOEvSB8mO5/OG7Z8sSReQSfO00hfsOOBJABFxOtk3bDawElgHHD6YSM0mJ08RY2ZmZtajYWjaMzMzMxsIJ1JmZmZmPXIiZWZmZtYjJ1JmZmZmPXIiZWZmZtYjJ1LWOEkjkkLS9EHH0qSxfm5J80r5WRMamJmZ9cyJlHUlaVb5Qh9t2XPQMdYlaXqH+NdJWiHpOElPaTieWSXB2qHJ49YlaXFbXT0k6Q5JF0raZZz7foOkkT6FamY2EJN+QE5r1AXk4H3tVjYdSB/8AFhYnj8dOJCcwPaVwD9O0DFPAD4NVKfmmUUOkLgA+GNb+fOArwEbJiieuh4EjizPnwK8jBy0cbakPSLiph73+wZyxoGR8QZoZjYoTqRsLJZFxFcGHUSf3Fz9LJK+QE4pso+kl0fET/p9wIh4GHh4DOU3kqOOD9rDbT/3s8qI6J8HjgLeN5iwzMwGz0171heS/kbSAkk3l6ay+yRdI+mNNd+/o6TPSfqNpPWS7pH0U0nHdCh7oKQl5RjrJF0n6YDxxF+SnMvLy7+uHOtIScskPSBpraTLJP1dh5j2k3SVpN+XsmskfVPSjEqZzfpISVpAXo0CWFVpPhsp2zfrIyVp3/L6/Z0+g6RrJd0t6UmVdTtLOk/SnZI2SFotab6kbXuurNSqq80mOq57HkhaTJn/sq3pcF6lzE6SvlzqckNpUjxT0jPGGbuZWd/4ipSNxRTlBLdVD0bEfcAbgRcCFwG3Ak8jvyi/KengiDi/y74vBv4BOB1YTjYhzSSbvua3Ckk6Afg48D3gX4BHyrEvlnRURHxpHJ+vlRT8vhzrJOAjwI+BjwFTgXcCV0qaGxH/VcrtRU78ugL4FNlE90zgdWRSdvMoxzsD2K7E/8HWccvn7+Qy4H+AQ4FTqxsk7QzsCZwaEQ+VdS8DrijxnAH8Dngp8H7gVZL2apXtwV+Vxz+0ra97Hvwb+Y/c3wNvr7z/v0vszwWuBbYm58r8DVmX7wFeXZoU1/YYu5lZ/0SEFy9bXMhkJkZZvlbKbNvhfVOAm4Ab29aPlPdOL6+3L69P6xLH7qXciR22XQL8CZjaZR/Tyz7OBqaVZSbZfymAVcA2wAvIJG0JsHXl/c8kE5PVwBPLus+W9z6jy7E3+9yjratsm1e2zaqsm1/Wvait7CfL+t0r634O/Lq9TshkpzVBb7ef/WLg/kpdPYfs27S67GN2W/mxnAcL8k9Qx+NeCtwFPLtt/R5k8+jIoH8vvHjx4iUi3LRnY3ImsHfbcgJARPy5VUjSFElPI79ArwBmStpuC/t9gOzQ/Lfa8tAAB5Nf3udKmlZdyCtCU4FX1PwsRwB3l+VG8irX1cA+EfEgMBcQcHJEPNrZOyLuAP4D+Etgt7K6dWXkTZIm+irvueXx0NYKSQIOAVZExLKy7iXArsD5wDZtdbUE+DOwT81jbsumuloDfIu8UnRYlKtyLeM8D1rv2x74J/Jnur4t9tXkzQ11Yzczm1Bu2rOxuCUifthpQ+m3cgKZgHTqw7IDecXoMSJig6Sjyc7Lq0pH5iuASyLi8krRmWRy8+stxPgXXT5Dy6XAF8nEbD2wMiL+t7L9eeXxlx3e21r3fOD6sp+5wGnASZKWkE2PF0TE3TXjqSUiVkhaBhws6WMR8QjZJDqdbIZsmVkejy9LJ3Xraj3wz+X5jmQStzcd+liO5zyoeEHZ9xFl6eS33YI2M2uCEykbt3JF5DLyy/vzZHKxlrzj7HDgbXS5sSEiTpd0KbAfsBdwAHCUpAsj4qDWocjEZ19Gv5utU+LTye2jJYVjFRH3SHo52d9nbzKx+RxwvKTZEXFtP45TsRD4d+A1wA/JxGYjUL2zTuXxFDKp6+TemsfbWK0rSV8Hvg2cKWlZRCwv68d9HrTF/hU2XYFr90DN2M3MJpQTKeuHXclOzP8aEcdVN0g6svNbHisi7iT7Lp0t6YnkOEpvlXRK5HAEtwCvB9ZExK/6Fn1nrSseLyY7Ole9qK0MkUMVLC4LknYFfgp8gkwORxM9xHY+2VfqUEnXkEnnD0r9tdxSHjf2K2FsiYhHJH2AbBL9DJua2cZ6Hoz22VeWbVv3O3Yzs35zHynrh9bVIVVXKke+7jr8QelLM6W6riQmrbvXdiyP55XHE0ui1b6fuk1VdSwiv8yPaRtOYCfy6sqtwA1lXfudjJDNjw+wKfbR3F8eu5V7VGku/C6wP9lvbDsee+XmBvIuwndLen77PiRtJan2MTvEcAuZ0O1dGQ5irOfB/WX7ZnFExD3kwK/7q8Oo+UpP7zV2M7N+8hUp64dfkU1qHykJ0U3ADOBdwC/IkbC3ZAZwlaRvkV/+95LNQ+8h76L7EUBE/KSMsTQC/EzSxcAdwE7lGLPJTtDjFhE3SZpP9ju6WtKFbBr+4KnAwSXZgxyg8tlks9at5NANB5byCx+z880tLY8nSfoq2R9pRUSs6PK+c4E5ZNPdWvKuxWr8IentZF+z5ZLOIX9GU8hhBPYHPkreOderE8lO7scDr2Xs58FSckDP0yR9B3gIuC4iVpE/+yVk3S8kE8MnkP3S5pL1OjKO2M3M+sKJlI1bRGyUtB/ZzHMYeZfXivL8pXRPpG4DzgFeTd5avw055tFZwEkRsa5yrOMlXU+OhXR0OdZd5XgdB6rsVUQcK2kl8F5yapcNwHXA2yLiR5Wi55FDFRxGTjfzJ7LZ64CI+EaXY1wj6Vjg3eTn3YpMTLolUt8mx3DaETg7ItZ32PfPJO1GJkxzyjHuI+98W8CmQTV7UpLNi4CDyphUV43xPLiAvPPxIODNZKJ0OLAqIm4r42AdSyZOh5BJ5m3Af5LjVJmZDZwieumiYWZmZmbuI2VmZmbWIydSZmZmZj1yImVmZmbWIydSZmZmZj1yImVmZmbWIydSZmZmZj1yImVmZmbWIydSZmZmZj1yImVmZmbWo/8DGY3sOmAa6a0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "inputs = x_d5.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = np.array(y_d5)\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "n_classes = 51\n",
    "\n",
    "acc_per_fold = []\n",
    "f1_per_fold = []\n",
    "time_per_fold = []\n",
    "\n",
    "acc_per_fold_plut = []\n",
    "f1_per_fold_plut = []\n",
    "time_per_fold_plut = []\n",
    "\n",
    "acc_per_fold_mwpm = []\n",
    "f1_per_fold_mwpm = []\n",
    "time_per_fold_mwpm = []\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "aucs_classes = {}\n",
    "for i in mlb.classes_:\n",
    "    aucs_classes[i] = []\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for i, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "    i_train = inputs[train].copy()\n",
    "    i_test = inputs[test].copy()\n",
    "    x_test_d5 = i_test[:,:2]\n",
    "    inputs_train = i_train[:,3:]\n",
    "    inputs_test = i_test[:,3:]\n",
    "    \n",
    "    ####################################################################################################\n",
    "    #test MWPM decoder for this fold\n",
    "    decoding_d5, time_mwpm = do_new_decoding(x_test_d5, 5, 0)\n",
    "    decoding_d5['combine'] = decoding_d5[[0, 1]].values.tolist()\n",
    "    decoding_d5['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "    decoding_d5 = np.array(decoding_d5[0])\n",
    "                                              \n",
    "    time_per_fold_mwpm.append(time_mwpm)\n",
    "                                              \n",
    "    pred_mwpm = mlb.transform(decoding_d5)\n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_mwpm)\n",
    "    else:\n",
    "        acc, contingency_mwpm = partial_accuracy_and_contingency(targets[test], pred_mwpm, mlb)\n",
    "        \n",
    "    acc_per_fold_mwpm.append(acc)\n",
    "    f1_per_fold_mwpm.append(f1_score(targets[test], pred_mwpm, average='micro'))\n",
    "    \n",
    "    #####################################################################################################\n",
    "    #test the plut decoder for this fold\n",
    "    \n",
    "    lookup_d5 = lookup_decoder(5)\n",
    "    \n",
    "    lookup_d5 = train_plut(lookup_d5, inputs_train, targets[train])\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    pred_plut_d5 = test_plut(lookup_d5, inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_plut_d5)\n",
    "    else:\n",
    "        acc, contingency_plut = partial_accuracy_and_contingency(targets[test], pred_plut_d5, mlb)\n",
    "        \n",
    "    acc_per_fold_plut.append(acc)\n",
    "    f1_per_fold_plut.append(f1_score(targets[test], pred_plut_d5, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #Test the NN decoder for this fold\n",
    "    \n",
    "    model_d5 = compile_FFNN_cv_model_DepthFive(5)\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    \n",
    "    history = model_d5.fit(\n",
    "    inputs_train,\n",
    "    targets[train],\n",
    "    validation_split=.25,\n",
    "    epochs = 800)\n",
    "    \n",
    "   # Generate generalization metrics\n",
    "    scores = model_d5.evaluate(inputs_test, targets[test], verbose=0)\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    predictions_d5 = model_d5.predict(inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    #threshold based on previous tests with train_test_split in hyperparameter tuning\n",
    "    pred=predictions_d5.copy() #change here\n",
    "    pred[pred>=.4]=1 \n",
    "    pred[pred<.4]=0\n",
    "    \n",
    "    if fold_no < 5:\n",
    "        acc = scores[1]\n",
    "    else:\n",
    "        acc, contingency_nn = partial_accuracy_and_contingency(targets[test], pred, mlb)\n",
    "\n",
    "    acc_per_fold.append(acc)\n",
    "    f1_per_fold.append(f1_score(targets[test], pred, average='micro'))\n",
    "\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d5.ravel())\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    \n",
    "    #get the AUCs of each class, used to get average AUC of each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d5[:, i]) \n",
    "        aucs_classes[mlb.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "        \n",
    "        \n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print(\"##############################################################################\")\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print(\"##############################################################################\")\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "print(\"##############################################################################\")\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "    \n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 5 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D7 Training, Testing, and Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data sets from CSV\n",
    "\n",
    "#### Data sets for D7:\n",
    "* Original:\n",
    "    - \"depth7_all_combos.csv\"\n",
    "* Randomly-sampled, with replacement (version 2):\n",
    "    - \"v2samples-d7-1000.csv\"\n",
    "    - \"v2samples-d7-10000.csv\"\n",
    "    - \"v2samples-d7-500000.csv\"\n",
    "* Randomly-sampled, without replacement (version 3):\n",
    "    - \"v3samples-d7-1000.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported and formatted in 4324.438215970993 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "trainData_d7 = pd.read_csv(\"SAMPLES/depth7_all_combos.csv\")\n",
    "trainData_d7 = trainData_d7.applymap(lambda x: add_noise(x,.01))\n",
    "\n",
    "#These four lines remove duplicates\n",
    "trainData_d7['Labels'] = trainData_d7['Labels'].map(lambda x: create_list_from_string(x))\n",
    "trainData_d7['Labels'] = trainData_d7['Labels'].astype(str)\n",
    "trainData_d7 = trainData_d7.drop_duplicates('Labels', keep='first', ignore_index=True)\n",
    "trainData_d7['Labels'] = trainData_d7['Labels'].map(lambda x: create_list_from_string(x))\n",
    "\n",
    "testData_d7_MWPM = graph_with_errs_d7(trainData_d7)\n",
    "\n",
    "#transforms the data to encoding for ML\n",
    "mlb_d7 = MultiLabelBinarizer()\n",
    "mlb_d7.fit(trainData_d7['Labels'])\n",
    "df = pd.DataFrame(mlb_d7.transform(trainData_d7['Labels']))\n",
    "df['Labels']= df.values.tolist()\n",
    "trainData_d7 = trainData_d7.drop(['Labels'], axis=1)\n",
    "trainData_d7 = pd.concat([df[\"Labels\"],testData_d7_MWPM, trainData_d7], axis=1, ignore_index=True)\n",
    "trainData_d7.columns = [\"Labels\",\"XSyn\", \"ZSyn\",\"X0\", \"Z1\", \"X2\", \"X3\", \"Z4\", \"X5\", \"X6\", \"Z7\", \"X8\", \"Z9\", \"Z10\", \"X11\", \"Z12\", \"X13\", \"Z14\", \"X15\", \"Z16\", \"Z17\", \"X18\", \"Z19\",\"X20\", \"Z21\", \"X22\", \"Z23\", \"Z24\", \"X25\", \"Z26\", \"X27\", \"Z28\", \"X29\", \"Z30\", \"Z31\", \"X32\", \"Z33\", \"X34\", \"Z35\", \"X36\", \"Z37\", \"Z38\", \"X39\", \"X40\", \"Z41\", \"X42\", \"X43\", \"Z44\", \"X45\", \"X46\", \"Z47\"]\n",
    "\n",
    "y_d7 = trainData_d7[\"Labels\"]\n",
    "x_d7 = trainData_d7.drop([\"Labels\"], axis=1)\n",
    "\n",
    "x_d7 = x_d7.replace([-1], 0)\n",
    "print(\"Data imported and formatted in %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Train on 236870 samples, validate on 78957 samples\n",
      "Epoch 1/150\n",
      "236870/236870 [==============================] - 29s 121us/step - loss: 0.2010 - accuracy: 0.9478 - val_loss: 0.1925 - val_accuracy: 0.9502\n",
      "Epoch 2/150\n",
      "236870/236870 [==============================] - 29s 120us/step - loss: 0.1838 - accuracy: 0.9502 - val_loss: 0.1709 - val_accuracy: 0.9503\n",
      "Epoch 3/150\n",
      "236870/236870 [==============================] - 29s 121us/step - loss: 0.1582 - accuracy: 0.9508 - val_loss: 0.1478 - val_accuracy: 0.9514\n",
      "Epoch 4/150\n",
      "236870/236870 [==============================] - 29s 121us/step - loss: 0.1396 - accuracy: 0.9527 - val_loss: 0.1340 - val_accuracy: 0.9538\n",
      "Epoch 5/150\n",
      "236870/236870 [==============================] - 29s 121us/step - loss: 0.1283 - accuracy: 0.9553 - val_loss: 0.1238 - val_accuracy: 0.9566\n",
      "Epoch 6/150\n",
      "236870/236870 [==============================] - 30s 125us/step - loss: 0.1194 - accuracy: 0.9579 - val_loss: 0.1165 - val_accuracy: 0.9589\n",
      "Epoch 7/150\n",
      "236870/236870 [==============================] - 29s 123us/step - loss: 0.1139 - accuracy: 0.9598 - val_loss: 0.1124 - val_accuracy: 0.9604\n",
      "Epoch 8/150\n",
      "236870/236870 [==============================] - 30s 128us/step - loss: 0.1101 - accuracy: 0.9611 - val_loss: 0.1096 - val_accuracy: 0.9616\n",
      "Epoch 9/150\n",
      "236870/236870 [==============================] - 29s 122us/step - loss: 0.1068 - accuracy: 0.9623 - val_loss: 0.1062 - val_accuracy: 0.9625\n",
      "Epoch 10/150\n",
      "236870/236870 [==============================] - 29s 122us/step - loss: 0.1040 - accuracy: 0.9633 - val_loss: 0.1037 - val_accuracy: 0.9634\n",
      "Epoch 11/150\n",
      "236870/236870 [==============================] - 30s 125us/step - loss: 0.1017 - accuracy: 0.9641 - val_loss: 0.1019 - val_accuracy: 0.9642\n",
      "Epoch 12/150\n",
      "236870/236870 [==============================] - 29s 124us/step - loss: 0.0998 - accuracy: 0.9647 - val_loss: 0.0998 - val_accuracy: 0.9648\n",
      "Epoch 13/150\n",
      "236870/236870 [==============================] - 29s 121us/step - loss: 0.0981 - accuracy: 0.9653 - val_loss: 0.0983 - val_accuracy: 0.9655\n",
      "Epoch 14/150\n",
      "236870/236870 [==============================] - 30s 128us/step - loss: 0.0965 - accuracy: 0.9658 - val_loss: 0.0963 - val_accuracy: 0.9658\n",
      "Epoch 15/150\n",
      "236870/236870 [==============================] - 29s 124us/step - loss: 0.0949 - accuracy: 0.9663 - val_loss: 0.0964 - val_accuracy: 0.9656\n",
      "Epoch 16/150\n",
      "236870/236870 [==============================] - 30s 126us/step - loss: 0.0935 - accuracy: 0.9667 - val_loss: 0.0934 - val_accuracy: 0.9667\n",
      "Epoch 17/150\n",
      "236870/236870 [==============================] - 30s 126us/step - loss: 0.0922 - accuracy: 0.9671 - val_loss: 0.0924 - val_accuracy: 0.9670\n",
      "Epoch 18/150\n",
      "236870/236870 [==============================] - 31s 131us/step - loss: 0.0909 - accuracy: 0.9675 - val_loss: 0.0914 - val_accuracy: 0.9673\n",
      "Epoch 19/150\n",
      "236870/236870 [==============================] - 29s 122us/step - loss: 0.0898 - accuracy: 0.9678 - val_loss: 0.0907 - val_accuracy: 0.9675\n",
      "Epoch 20/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0887 - accuracy: 0.9680 - val_loss: 0.0900 - val_accuracy: 0.9677\n",
      "Epoch 21/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0877 - accuracy: 0.9683 - val_loss: 0.0883 - val_accuracy: 0.9679\n",
      "Epoch 22/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0868 - accuracy: 0.9685 - val_loss: 0.0882 - val_accuracy: 0.9681\n",
      "Epoch 23/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0859 - accuracy: 0.9687 - val_loss: 0.0870 - val_accuracy: 0.9684\n",
      "Epoch 24/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0851 - accuracy: 0.9688 - val_loss: 0.0856 - val_accuracy: 0.9687\n",
      "Epoch 25/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0843 - accuracy: 0.9690 - val_loss: 0.0848 - val_accuracy: 0.9689\n",
      "Epoch 26/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0836 - accuracy: 0.9692 - val_loss: 0.0842 - val_accuracy: 0.9690\n",
      "Epoch 27/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0829 - accuracy: 0.9693 - val_loss: 0.0840 - val_accuracy: 0.9691\n",
      "Epoch 28/150\n",
      "236870/236870 [==============================] - 25s 108us/step - loss: 0.0823 - accuracy: 0.9694 - val_loss: 0.0835 - val_accuracy: 0.9691\n",
      "Epoch 29/150\n",
      "236870/236870 [==============================] - 26s 108us/step - loss: 0.0817 - accuracy: 0.9695 - val_loss: 0.0830 - val_accuracy: 0.9692\n",
      "Epoch 30/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0812 - accuracy: 0.9697 - val_loss: 0.0819 - val_accuracy: 0.9695\n",
      "Epoch 31/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0807 - accuracy: 0.9698 - val_loss: 0.0815 - val_accuracy: 0.9696\n",
      "Epoch 32/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0803 - accuracy: 0.9698 - val_loss: 0.0815 - val_accuracy: 0.9694\n",
      "Epoch 33/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0799 - accuracy: 0.9699 - val_loss: 0.0810 - val_accuracy: 0.9696\n",
      "Epoch 34/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0795 - accuracy: 0.9700 - val_loss: 0.0811 - val_accuracy: 0.9694\n",
      "Epoch 35/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0791 - accuracy: 0.9701 - val_loss: 0.0802 - val_accuracy: 0.9700\n",
      "Epoch 36/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0788 - accuracy: 0.9702 - val_loss: 0.0794 - val_accuracy: 0.9701\n",
      "Epoch 37/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0785 - accuracy: 0.9703 - val_loss: 0.0792 - val_accuracy: 0.9701\n",
      "Epoch 38/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0782 - accuracy: 0.9703 - val_loss: 0.0794 - val_accuracy: 0.9700\n",
      "Epoch 39/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0779 - accuracy: 0.9704 - val_loss: 0.0794 - val_accuracy: 0.9700\n",
      "Epoch 40/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0776 - accuracy: 0.9705 - val_loss: 0.0792 - val_accuracy: 0.9699\n",
      "Epoch 41/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0773 - accuracy: 0.9705 - val_loss: 0.0787 - val_accuracy: 0.9701\n",
      "Epoch 42/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0771 - accuracy: 0.9706 - val_loss: 0.0791 - val_accuracy: 0.9699\n",
      "Epoch 43/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0769 - accuracy: 0.9707 - val_loss: 0.0782 - val_accuracy: 0.9702\n",
      "Epoch 44/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0766 - accuracy: 0.9707 - val_loss: 0.0776 - val_accuracy: 0.9705\n",
      "Epoch 45/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0764 - accuracy: 0.9708 - val_loss: 0.0780 - val_accuracy: 0.9702\n",
      "Epoch 46/150\n",
      "236870/236870 [==============================] - 25s 104us/step - loss: 0.0762 - accuracy: 0.9708 - val_loss: 0.0778 - val_accuracy: 0.9702\n",
      "Epoch 47/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0760 - accuracy: 0.9709 - val_loss: 0.0770 - val_accuracy: 0.9706\n",
      "Epoch 48/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0758 - accuracy: 0.9709 - val_loss: 0.0774 - val_accuracy: 0.9705\n",
      "Epoch 49/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0756 - accuracy: 0.9710 - val_loss: 0.0768 - val_accuracy: 0.9706\n",
      "Epoch 50/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0754 - accuracy: 0.9710 - val_loss: 0.0771 - val_accuracy: 0.9706\n",
      "Epoch 51/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0753 - accuracy: 0.9711 - val_loss: 0.0762 - val_accuracy: 0.9708\n",
      "Epoch 52/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0751 - accuracy: 0.9711 - val_loss: 0.0780 - val_accuracy: 0.9700\n",
      "Epoch 53/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0749 - accuracy: 0.9711 - val_loss: 0.0767 - val_accuracy: 0.9704\n",
      "Epoch 54/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0748 - accuracy: 0.9712 - val_loss: 0.0770 - val_accuracy: 0.9704\n",
      "Epoch 55/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0746 - accuracy: 0.9712 - val_loss: 0.0766 - val_accuracy: 0.9706\n",
      "Epoch 56/150\n",
      "236870/236870 [==============================] - 25s 104us/step - loss: 0.0744 - accuracy: 0.9713 - val_loss: 0.0758 - val_accuracy: 0.9707\n",
      "Epoch 57/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0743 - accuracy: 0.9713 - val_loss: 0.0767 - val_accuracy: 0.9708\n",
      "Epoch 58/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0741 - accuracy: 0.9714 - val_loss: 0.0794 - val_accuracy: 0.9698\n",
      "Epoch 59/150\n",
      "236870/236870 [==============================] - 25s 104us/step - loss: 0.0740 - accuracy: 0.9714 - val_loss: 0.0766 - val_accuracy: 0.9704\n",
      "Epoch 60/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0738 - accuracy: 0.9714 - val_loss: 0.0775 - val_accuracy: 0.9699\n",
      "Epoch 61/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0737 - accuracy: 0.9715 - val_loss: 0.0750 - val_accuracy: 0.9711\n",
      "Epoch 62/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0736 - accuracy: 0.9715 - val_loss: 0.0759 - val_accuracy: 0.9707\n",
      "Epoch 63/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0734 - accuracy: 0.9716 - val_loss: 0.0754 - val_accuracy: 0.9707\n",
      "Epoch 64/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0733 - accuracy: 0.9716 - val_loss: 0.0758 - val_accuracy: 0.9707\n",
      "Epoch 65/150\n",
      "236870/236870 [==============================] - 25s 104us/step - loss: 0.0732 - accuracy: 0.9716 - val_loss: 0.0754 - val_accuracy: 0.9707\n",
      "Epoch 66/150\n",
      "236870/236870 [==============================] - 25s 108us/step - loss: 0.0730 - accuracy: 0.9717 - val_loss: 0.0747 - val_accuracy: 0.9710\n",
      "Epoch 67/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0729 - accuracy: 0.9717 - val_loss: 0.0746 - val_accuracy: 0.9710\n",
      "Epoch 68/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0728 - accuracy: 0.9717 - val_loss: 0.0741 - val_accuracy: 0.9712\n",
      "Epoch 69/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0727 - accuracy: 0.9718 - val_loss: 0.0742 - val_accuracy: 0.9713\n",
      "Epoch 70/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0725 - accuracy: 0.9718 - val_loss: 0.0747 - val_accuracy: 0.9709\n",
      "Epoch 71/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0724 - accuracy: 0.9718 - val_loss: 0.0741 - val_accuracy: 0.9712\n",
      "Epoch 72/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0723 - accuracy: 0.9719 - val_loss: 0.0743 - val_accuracy: 0.9712\n",
      "Epoch 73/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0722 - accuracy: 0.9719 - val_loss: 0.0738 - val_accuracy: 0.9712\n",
      "Epoch 74/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0721 - accuracy: 0.9719 - val_loss: 0.0736 - val_accuracy: 0.9713\n",
      "Epoch 75/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0720 - accuracy: 0.9719 - val_loss: 0.0734 - val_accuracy: 0.9714\n",
      "Epoch 76/150\n",
      "236870/236870 [==============================] - 25s 104us/step - loss: 0.0719 - accuracy: 0.9720 - val_loss: 0.0737 - val_accuracy: 0.9712\n",
      "Epoch 77/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0717 - accuracy: 0.9720 - val_loss: 0.0743 - val_accuracy: 0.9709\n",
      "Epoch 78/150\n",
      "236870/236870 [==============================] - 25s 104us/step - loss: 0.0716 - accuracy: 0.9720 - val_loss: 0.0743 - val_accuracy: 0.9711\n",
      "Epoch 79/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0715 - accuracy: 0.9720 - val_loss: 0.0734 - val_accuracy: 0.9714\n",
      "Epoch 80/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0714 - accuracy: 0.9721 - val_loss: 0.0734 - val_accuracy: 0.9713\n",
      "Epoch 81/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0713 - accuracy: 0.9721 - val_loss: 0.0735 - val_accuracy: 0.9713\n",
      "Epoch 82/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0712 - accuracy: 0.9721 - val_loss: 0.0733 - val_accuracy: 0.9713\n",
      "Epoch 83/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0711 - accuracy: 0.9721 - val_loss: 0.0729 - val_accuracy: 0.9716\n",
      "Epoch 84/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0710 - accuracy: 0.9722 - val_loss: 0.0728 - val_accuracy: 0.9716\n",
      "Epoch 85/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0709 - accuracy: 0.9722 - val_loss: 0.0733 - val_accuracy: 0.9712\n",
      "Epoch 86/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0708 - accuracy: 0.9722 - val_loss: 0.0724 - val_accuracy: 0.9716\n",
      "Epoch 87/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0707 - accuracy: 0.9722 - val_loss: 0.0729 - val_accuracy: 0.9714\n",
      "Epoch 88/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0706 - accuracy: 0.9723 - val_loss: 0.0740 - val_accuracy: 0.9711\n",
      "Epoch 89/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0706 - accuracy: 0.9723 - val_loss: 0.0729 - val_accuracy: 0.9714\n",
      "Epoch 90/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0705 - accuracy: 0.9723 - val_loss: 0.0729 - val_accuracy: 0.9714\n",
      "Epoch 91/150\n",
      "236870/236870 [==============================] - 25s 104us/step - loss: 0.0704 - accuracy: 0.9723 - val_loss: 0.0722 - val_accuracy: 0.9717\n",
      "Epoch 92/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0703 - accuracy: 0.9724 - val_loss: 0.0722 - val_accuracy: 0.9718\n",
      "Epoch 93/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0702 - accuracy: 0.9724 - val_loss: 0.0722 - val_accuracy: 0.9716\n",
      "Epoch 94/150\n",
      "236870/236870 [==============================] - 25s 104us/step - loss: 0.0701 - accuracy: 0.9724 - val_loss: 0.0723 - val_accuracy: 0.9716\n",
      "Epoch 95/150\n",
      "236870/236870 [==============================] - 26s 109us/step - loss: 0.0700 - accuracy: 0.9724 - val_loss: 0.0723 - val_accuracy: 0.9716\n",
      "Epoch 96/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0700 - accuracy: 0.9724 - val_loss: 0.0716 - val_accuracy: 0.9718\n",
      "Epoch 97/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0699 - accuracy: 0.9725 - val_loss: 0.0719 - val_accuracy: 0.9715\n",
      "Epoch 98/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0698 - accuracy: 0.9725 - val_loss: 0.0721 - val_accuracy: 0.9713\n",
      "Epoch 99/150\n",
      "236870/236870 [==============================] - 25s 105us/step - loss: 0.0697 - accuracy: 0.9725 - val_loss: 0.0719 - val_accuracy: 0.9718\n",
      "Epoch 100/150\n",
      "236870/236870 [==============================] - 25s 106us/step - loss: 0.0696 - accuracy: 0.9725 - val_loss: 0.0723 - val_accuracy: 0.9714\n",
      "Epoch 101/150\n",
      "236870/236870 [==============================] - 25s 107us/step - loss: 0.0696 - accuracy: 0.9725 - val_loss: 0.0716 - val_accuracy: 0.9719\n",
      "Epoch 102/150\n",
      "236870/236870 [==============================] - 27s 115us/step - loss: 0.0695 - accuracy: 0.9726 - val_loss: 0.0717 - val_accuracy: 0.9718\n",
      "Epoch 103/150\n",
      "236870/236870 [==============================] - 28s 119us/step - loss: 0.0694 - accuracy: 0.9726 - val_loss: 0.0721 - val_accuracy: 0.9715\n",
      "Epoch 104/150\n",
      "236870/236870 [==============================] - 30s 125us/step - loss: 0.0693 - accuracy: 0.9726 - val_loss: 0.0715 - val_accuracy: 0.9718\n",
      "Epoch 105/150\n",
      "236870/236870 [==============================] - 28s 119us/step - loss: 0.0693 - accuracy: 0.9726 - val_loss: 0.0716 - val_accuracy: 0.9715\n",
      "Epoch 106/150\n",
      "236870/236870 [==============================] - 28s 116us/step - loss: 0.0692 - accuracy: 0.9726 - val_loss: 0.0714 - val_accuracy: 0.9718\n",
      "Epoch 107/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236870/236870 [==============================] - 27s 114us/step - loss: 0.0691 - accuracy: 0.9726 - val_loss: 0.0709 - val_accuracy: 0.9720\n",
      "Epoch 108/150\n",
      "236870/236870 [==============================] - 27s 114us/step - loss: 0.0690 - accuracy: 0.9727 - val_loss: 0.0719 - val_accuracy: 0.9715\n",
      "Epoch 109/150\n",
      "236870/236870 [==============================] - 27s 115us/step - loss: 0.0690 - accuracy: 0.9727 - val_loss: 0.0711 - val_accuracy: 0.9720\n",
      "Epoch 110/150\n",
      "236870/236870 [==============================] - 27s 114us/step - loss: 0.0689 - accuracy: 0.9727 - val_loss: 0.0718 - val_accuracy: 0.9719\n",
      "Epoch 111/150\n",
      "236870/236870 [==============================] - 27s 114us/step - loss: 0.0688 - accuracy: 0.9727 - val_loss: 0.0711 - val_accuracy: 0.9718\n",
      "Epoch 112/150\n",
      "236870/236870 [==============================] - 27s 114us/step - loss: 0.0688 - accuracy: 0.9728 - val_loss: 0.0715 - val_accuracy: 0.9715\n",
      "Epoch 113/150\n",
      "236870/236870 [==============================] - 27s 115us/step - loss: 0.0687 - accuracy: 0.9728 - val_loss: 0.0710 - val_accuracy: 0.9719\n",
      "Epoch 114/150\n",
      "236870/236870 [==============================] - 28s 116us/step - loss: 0.0686 - accuracy: 0.9728 - val_loss: 0.0721 - val_accuracy: 0.9715\n",
      "Epoch 115/150\n",
      "236870/236870 [==============================] - 27s 115us/step - loss: 0.0686 - accuracy: 0.9728 - val_loss: 0.0718 - val_accuracy: 0.9715\n",
      "Epoch 116/150\n",
      "236870/236870 [==============================] - 28s 116us/step - loss: 0.0685 - accuracy: 0.9728 - val_loss: 0.0707 - val_accuracy: 0.9720\n",
      "Epoch 117/150\n",
      "236870/236870 [==============================] - 28s 120us/step - loss: 0.0684 - accuracy: 0.9728 - val_loss: 0.0708 - val_accuracy: 0.9721\n",
      "Epoch 118/150\n",
      "236870/236870 [==============================] - 27s 115us/step - loss: 0.0684 - accuracy: 0.9728 - val_loss: 0.0710 - val_accuracy: 0.9719\n",
      "Epoch 119/150\n",
      "236870/236870 [==============================] - 29s 121us/step - loss: 0.0683 - accuracy: 0.9729 - val_loss: 0.0715 - val_accuracy: 0.9718\n",
      "Epoch 120/150\n",
      "236870/236870 [==============================] - 28s 117us/step - loss: 0.0683 - accuracy: 0.9729 - val_loss: 0.0712 - val_accuracy: 0.9717\n",
      "Epoch 121/150\n",
      "236870/236870 [==============================] - 29s 120us/step - loss: 0.0682 - accuracy: 0.9729 - val_loss: 0.0706 - val_accuracy: 0.9717\n",
      "Epoch 122/150\n",
      "236870/236870 [==============================] - 28s 118us/step - loss: 0.0681 - accuracy: 0.9729 - val_loss: 0.0711 - val_accuracy: 0.9717\n",
      "Epoch 123/150\n",
      "236870/236870 [==============================] - 31s 132us/step - loss: 0.0681 - accuracy: 0.9729 - val_loss: 0.0703 - val_accuracy: 0.9721\n",
      "Epoch 124/150\n",
      "236870/236870 [==============================] - 29s 121us/step - loss: 0.0680 - accuracy: 0.9729 - val_loss: 0.0706 - val_accuracy: 0.9718\n",
      "Epoch 125/150\n",
      "236870/236870 [==============================] - 28s 119us/step - loss: 0.0680 - accuracy: 0.9730 - val_loss: 0.0715 - val_accuracy: 0.9716\n",
      "Epoch 126/150\n",
      "236870/236870 [==============================] - 29s 121us/step - loss: 0.0679 - accuracy: 0.9730 - val_loss: 0.0708 - val_accuracy: 0.9719\n",
      "Epoch 127/150\n",
      "236870/236870 [==============================] - 31s 130us/step - loss: 0.0679 - accuracy: 0.9730 - val_loss: 0.0703 - val_accuracy: 0.9722\n",
      "Epoch 128/150\n",
      "236870/236870 [==============================] - 30s 125us/step - loss: 0.0678 - accuracy: 0.9730 - val_loss: 0.0705 - val_accuracy: 0.9721\n",
      "Epoch 129/150\n",
      "236870/236870 [==============================] - 29s 124us/step - loss: 0.0678 - accuracy: 0.9730 - val_loss: 0.0699 - val_accuracy: 0.9722\n",
      "Epoch 130/150\n",
      "236870/236870 [==============================] - 30s 125us/step - loss: 0.0677 - accuracy: 0.9730 - val_loss: 0.0702 - val_accuracy: 0.9721\n",
      "Epoch 131/150\n",
      "236870/236870 [==============================] - 29s 124us/step - loss: 0.0677 - accuracy: 0.9730 - val_loss: 0.0704 - val_accuracy: 0.9721\n",
      "Epoch 132/150\n",
      "236870/236870 [==============================] - 29s 124us/step - loss: 0.0676 - accuracy: 0.9731 - val_loss: 0.0697 - val_accuracy: 0.9722\n",
      "Epoch 133/150\n",
      "236870/236870 [==============================] - 30s 125us/step - loss: 0.0675 - accuracy: 0.9731 - val_loss: 0.0709 - val_accuracy: 0.9719\n",
      "Epoch 134/150\n",
      "236870/236870 [==============================] - 29s 124us/step - loss: 0.0675 - accuracy: 0.9731 - val_loss: 0.0699 - val_accuracy: 0.9721\n",
      "Epoch 135/150\n",
      "236870/236870 [==============================] - 29s 124us/step - loss: 0.0674 - accuracy: 0.9731 - val_loss: 0.0708 - val_accuracy: 0.9718\n",
      "Epoch 136/150\n",
      "236870/236870 [==============================] - 30s 126us/step - loss: 0.0674 - accuracy: 0.9731 - val_loss: 0.0701 - val_accuracy: 0.9720\n",
      "Epoch 137/150\n",
      "236870/236870 [==============================] - 29s 124us/step - loss: 0.0673 - accuracy: 0.9731 - val_loss: 0.0702 - val_accuracy: 0.9721\n",
      "Epoch 138/150\n",
      "236870/236870 [==============================] - 29s 124us/step - loss: 0.0673 - accuracy: 0.9732 - val_loss: 0.0703 - val_accuracy: 0.9721\n",
      "Epoch 139/150\n",
      "236870/236870 [==============================] - 30s 125us/step - loss: 0.0672 - accuracy: 0.9732 - val_loss: 0.0704 - val_accuracy: 0.9719\n",
      "Epoch 140/150\n",
      "236870/236870 [==============================] - 29s 124us/step - loss: 0.0672 - accuracy: 0.9732 - val_loss: 0.0699 - val_accuracy: 0.9721\n",
      "Epoch 141/150\n",
      "236870/236870 [==============================] - 30s 126us/step - loss: 0.0671 - accuracy: 0.9732 - val_loss: 0.0707 - val_accuracy: 0.9718\n",
      "Epoch 142/150\n",
      "236870/236870 [==============================] - 30s 126us/step - loss: 0.0671 - accuracy: 0.9732 - val_loss: 0.0699 - val_accuracy: 0.9721\n",
      "Epoch 143/150\n",
      "236870/236870 [==============================] - 30s 126us/step - loss: 0.0670 - accuracy: 0.9732 - val_loss: 0.0709 - val_accuracy: 0.9719\n",
      "Epoch 144/150\n",
      "236870/236870 [==============================] - 30s 125us/step - loss: 0.0670 - accuracy: 0.9732 - val_loss: 0.0703 - val_accuracy: 0.9719\n",
      "Epoch 145/150\n",
      "236870/236870 [==============================] - 30s 126us/step - loss: 0.0670 - accuracy: 0.9732 - val_loss: 0.0700 - val_accuracy: 0.9719\n",
      "Epoch 146/150\n",
      "236870/236870 [==============================] - 30s 126us/step - loss: 0.0669 - accuracy: 0.9732 - val_loss: 0.0709 - val_accuracy: 0.9719\n",
      "Epoch 147/150\n",
      "236870/236870 [==============================] - 30s 129us/step - loss: 0.0669 - accuracy: 0.9733 - val_loss: 0.0705 - val_accuracy: 0.9721\n",
      "Epoch 148/150\n",
      "236870/236870 [==============================] - 30s 126us/step - loss: 0.0668 - accuracy: 0.9733 - val_loss: 0.0698 - val_accuracy: 0.9721\n",
      "Epoch 149/150\n",
      "236870/236870 [==============================] - 30s 126us/step - loss: 0.0668 - accuracy: 0.9733 - val_loss: 0.0712 - val_accuracy: 0.9719\n",
      "Epoch 150/150\n",
      "236870/236870 [==============================] - 30s 126us/step - loss: 0.0667 - accuracy: 0.9733 - val_loss: 0.0706 - val_accuracy: 0.9718\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_499 (Dense)            (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "dense_500 (Dense)            (None, 400)               19600     \n",
      "_________________________________________________________________\n",
      "dense_501 (Dense)            (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dense_502 (Dense)            (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dense_503 (Dense)            (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dense_504 (Dense)            (None, 99)                39699     \n",
      "=================================================================\n",
      "Total params: 542,851\n",
      "Trainable params: 542,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model trained in 4030.898465156555 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "inputs = x_d7.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = y_d7.copy()\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "train_input_d7 = inputs[:,2:]\n",
    "train_output_d7 = targets\n",
    "\n",
    "x_train_d7, x_test_d7, Y_train_d7, Y_test_d7 = train_test_split(train_input_d7, train_output_d7, train_size=0.75, shuffle=True)\n",
    "\n",
    "model_d7 = compile_FFNN_cv_model_DepthSeven(7)\n",
    "print(\"Fit model on training data\")\n",
    "history = model_d7.fit(\n",
    "    x=x_train_d7,\n",
    "    y=Y_train_d7,\n",
    "    validation_split=.25,\n",
    "    epochs=150\n",
    ")\n",
    "model_d7.summary()\n",
    "print(\"Model trained in %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive:   308881\n",
      "False positive:  84933\n",
      "True negative:   9718555\n",
      "False negative:  204581\n"
     ]
    }
   ],
   "source": [
    "predictions_d7 = model_d7.predict(x_test_d7)\n",
    "\n",
    "y_pred = predictions_d7\n",
    "y_test = Y_test_d7\n",
    "\n",
    "y_pred[y_pred>=.5]=1 \n",
    "y_pred[y_pred<.5]=0\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(y_pred)-1):\n",
    "    for j in range(len(y_test[0])-1):\n",
    "        if y_test[i][j] == y_pred[i][j] and y_test[i][j] == 1:\n",
    "            TP += 1\n",
    "        if y_pred[i][j] == 1 and y_test[i][j] != y_pred[i][j]:\n",
    "            FP += 1\n",
    "        if y_test[i][j] == y_pred[i][j] and y_test[i][j] == 0:\n",
    "            TN += 1\n",
    "        if y_pred[i][j] == 0 and y_test[i][j] != y_pred[i][j]:\n",
    "            FN += 1\n",
    "\n",
    "        \n",
    "print(\"True positive:   \" + str(TP) + \"\\nFalse positive:  \" + str(FP) + \"\\nTrue negative:   \" + str(TN) + \"\\nFalse negative:  \" + str(FN))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Epoch vs. Loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss (MSE)')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Depth 7 Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Epoch vs. Accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Depth 7 Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d7.save(\"model_d7_v2-500k.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Train on 254089 samples, validate on 84697 samples\n",
      "Epoch 1/150\n",
      "254089/254089 [==============================] - 31s 123us/step - loss: 0.1625 - accuracy: 0.9605 - val_loss: 0.1861 - val_accuracy: 0.9523\n",
      "Epoch 2/150\n",
      "254089/254089 [==============================] - 31s 121us/step - loss: 0.1392 - accuracy: 0.9625 - val_loss: 0.1470 - val_accuracy: 0.9532\n",
      "Epoch 3/150\n",
      "254089/254089 [==============================] - 30s 120us/step - loss: 0.1074 - accuracy: 0.9650 - val_loss: 0.1150 - val_accuracy: 0.9599\n",
      "Epoch 4/150\n",
      "254089/254089 [==============================] - 32s 126us/step - loss: 0.0872 - accuracy: 0.9698 - val_loss: 0.1005 - val_accuracy: 0.9646\n",
      "Epoch 5/150\n",
      "254089/254089 [==============================] - 31s 122us/step - loss: 0.0766 - accuracy: 0.9732 - val_loss: 0.0922 - val_accuracy: 0.9677\n",
      "Epoch 6/150\n",
      "254089/254089 [==============================] - 31s 122us/step - loss: 0.0699 - accuracy: 0.9755 - val_loss: 0.0861 - val_accuracy: 0.9701\n",
      "Epoch 7/150\n",
      "254089/254089 [==============================] - 31s 121us/step - loss: 0.0648 - accuracy: 0.9773 - val_loss: 0.0811 - val_accuracy: 0.9720\n",
      "Epoch 8/150\n",
      "254089/254089 [==============================] - 31s 121us/step - loss: 0.0610 - accuracy: 0.9786 - val_loss: 0.0779 - val_accuracy: 0.9732\n",
      "Epoch 9/150\n",
      "254089/254089 [==============================] - 31s 121us/step - loss: 0.0581 - accuracy: 0.9796 - val_loss: 0.0750 - val_accuracy: 0.9743\n",
      "Epoch 10/150\n",
      "254089/254089 [==============================] - 31s 122us/step - loss: 0.0557 - accuracy: 0.9804 - val_loss: 0.0722 - val_accuracy: 0.9753\n",
      "Epoch 11/150\n",
      "254089/254089 [==============================] - 34s 134us/step - loss: 0.0538 - accuracy: 0.9810 - val_loss: 0.0708 - val_accuracy: 0.9760\n",
      "Epoch 12/150\n",
      "254089/254089 [==============================] - 34s 133us/step - loss: 0.0522 - accuracy: 0.9816 - val_loss: 0.0686 - val_accuracy: 0.9766\n",
      "Epoch 13/150\n",
      "254089/254089 [==============================] - 33s 128us/step - loss: 0.0508 - accuracy: 0.9820 - val_loss: 0.0671 - val_accuracy: 0.9771\n",
      "Epoch 14/150\n",
      "254089/254089 [==============================] - 32s 124us/step - loss: 0.0496 - accuracy: 0.9824 - val_loss: 0.0661 - val_accuracy: 0.9777\n",
      "Epoch 15/150\n",
      "254089/254089 [==============================] - 32s 126us/step - loss: 0.0486 - accuracy: 0.9827 - val_loss: 0.0647 - val_accuracy: 0.9782\n",
      "Epoch 16/150\n",
      "254089/254089 [==============================] - 31s 124us/step - loss: 0.0477 - accuracy: 0.9830 - val_loss: 0.0634 - val_accuracy: 0.9786\n",
      "Epoch 17/150\n",
      "254089/254089 [==============================] - 32s 128us/step - loss: 0.0470 - accuracy: 0.9832 - val_loss: 0.0627 - val_accuracy: 0.9788\n",
      "Epoch 18/150\n",
      "254089/254089 [==============================] - 30s 118us/step - loss: 0.0463 - accuracy: 0.9834 - val_loss: 0.0616 - val_accuracy: 0.9791\n",
      "Epoch 19/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0456 - accuracy: 0.9836 - val_loss: 0.0603 - val_accuracy: 0.9795\n",
      "Epoch 20/150\n",
      "254089/254089 [==============================] - 29s 115us/step - loss: 0.0450 - accuracy: 0.9838 - val_loss: 0.0598 - val_accuracy: 0.9797\n",
      "Epoch 21/150\n",
      "254089/254089 [==============================] - 30s 117us/step - loss: 0.0445 - accuracy: 0.9839 - val_loss: 0.0591 - val_accuracy: 0.9800\n",
      "Epoch 22/150\n",
      "254089/254089 [==============================] - 30s 118us/step - loss: 0.0440 - accuracy: 0.9840 - val_loss: 0.0585 - val_accuracy: 0.9801\n",
      "Epoch 23/150\n",
      "254089/254089 [==============================] - 30s 119us/step - loss: 0.0435 - accuracy: 0.9841 - val_loss: 0.0571 - val_accuracy: 0.9805\n",
      "Epoch 24/150\n",
      "254089/254089 [==============================] - 33s 131us/step - loss: 0.0431 - accuracy: 0.9843 - val_loss: 0.0571 - val_accuracy: 0.9806\n",
      "Epoch 25/150\n",
      "254089/254089 [==============================] - 34s 132us/step - loss: 0.0427 - accuracy: 0.9844 - val_loss: 0.0571 - val_accuracy: 0.9807\n",
      "Epoch 26/150\n",
      "254089/254089 [==============================] - 32s 127us/step - loss: 0.0423 - accuracy: 0.9845 - val_loss: 0.0569 - val_accuracy: 0.9807\n",
      "Epoch 27/150\n",
      "254089/254089 [==============================] - 33s 130us/step - loss: 0.0419 - accuracy: 0.9846 - val_loss: 0.0557 - val_accuracy: 0.9810\n",
      "Epoch 28/150\n",
      "254089/254089 [==============================] - 33s 129us/step - loss: 0.0416 - accuracy: 0.9846 - val_loss: 0.0553 - val_accuracy: 0.9811\n",
      "Epoch 29/150\n",
      "254089/254089 [==============================] - 32s 126us/step - loss: 0.0413 - accuracy: 0.9847 - val_loss: 0.0549 - val_accuracy: 0.9814\n",
      "Epoch 30/150\n",
      "254089/254089 [==============================] - 33s 131us/step - loss: 0.0409 - accuracy: 0.9848 - val_loss: 0.0548 - val_accuracy: 0.9813\n",
      "Epoch 31/150\n",
      "254089/254089 [==============================] - 32s 127us/step - loss: 0.0406 - accuracy: 0.9849 - val_loss: 0.0540 - val_accuracy: 0.9816\n",
      "Epoch 32/150\n",
      "254089/254089 [==============================] - 31s 121us/step - loss: 0.0403 - accuracy: 0.9849 - val_loss: 0.0532 - val_accuracy: 0.9817\n",
      "Epoch 33/150\n",
      "254089/254089 [==============================] - 30s 118us/step - loss: 0.0400 - accuracy: 0.9850 - val_loss: 0.0531 - val_accuracy: 0.9818\n",
      "Epoch 34/150\n",
      "254089/254089 [==============================] - 32s 124us/step - loss: 0.0398 - accuracy: 0.9851 - val_loss: 0.0528 - val_accuracy: 0.9818\n",
      "Epoch 35/150\n",
      "254089/254089 [==============================] - 32s 125us/step - loss: 0.0395 - accuracy: 0.9852 - val_loss: 0.0523 - val_accuracy: 0.9820\n",
      "Epoch 36/150\n",
      "254089/254089 [==============================] - 31s 122us/step - loss: 0.0392 - accuracy: 0.9852 - val_loss: 0.0521 - val_accuracy: 0.9821\n",
      "Epoch 37/150\n",
      "254089/254089 [==============================] - 33s 129us/step - loss: 0.0390 - accuracy: 0.9853 - val_loss: 0.0517 - val_accuracy: 0.9823\n",
      "Epoch 38/150\n",
      "254089/254089 [==============================] - 30s 119us/step - loss: 0.0387 - accuracy: 0.9853 - val_loss: 0.0522 - val_accuracy: 0.9820\n",
      "Epoch 39/150\n",
      "254089/254089 [==============================] - 33s 130us/step - loss: 0.0385 - accuracy: 0.9854 - val_loss: 0.0516 - val_accuracy: 0.9824\n",
      "Epoch 40/150\n",
      "254089/254089 [==============================] - 31s 122us/step - loss: 0.0383 - accuracy: 0.9854 - val_loss: 0.0510 - val_accuracy: 0.9825\n",
      "Epoch 41/150\n",
      "254089/254089 [==============================] - 29s 115us/step - loss: 0.0381 - accuracy: 0.9855 - val_loss: 0.0510 - val_accuracy: 0.9824\n",
      "Epoch 42/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0379 - accuracy: 0.9856 - val_loss: 0.0508 - val_accuracy: 0.9826\n",
      "Epoch 43/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0376 - accuracy: 0.9856 - val_loss: 0.0507 - val_accuracy: 0.9826\n",
      "Epoch 44/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0375 - accuracy: 0.9856 - val_loss: 0.0499 - val_accuracy: 0.9828\n",
      "Epoch 45/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0373 - accuracy: 0.9857 - val_loss: 0.0498 - val_accuracy: 0.9828\n",
      "Epoch 46/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0371 - accuracy: 0.9857 - val_loss: 0.0498 - val_accuracy: 0.9829\n",
      "Epoch 47/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0369 - accuracy: 0.9858 - val_loss: 0.0492 - val_accuracy: 0.9831\n",
      "Epoch 48/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0367 - accuracy: 0.9858 - val_loss: 0.0494 - val_accuracy: 0.9829\n",
      "Epoch 49/150\n",
      "254089/254089 [==============================] - 29s 115us/step - loss: 0.0366 - accuracy: 0.9859 - val_loss: 0.0493 - val_accuracy: 0.9831\n",
      "Epoch 50/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0364 - accuracy: 0.9859 - val_loss: 0.0490 - val_accuracy: 0.9831\n",
      "Epoch 51/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0362 - accuracy: 0.9859 - val_loss: 0.0487 - val_accuracy: 0.9832\n",
      "Epoch 52/150\n",
      "254089/254089 [==============================] - 29s 115us/step - loss: 0.0361 - accuracy: 0.9860 - val_loss: 0.0491 - val_accuracy: 0.9831\n",
      "Epoch 53/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0359 - accuracy: 0.9860 - val_loss: 0.0489 - val_accuracy: 0.9832\n",
      "Epoch 54/150\n",
      "254089/254089 [==============================] - 28s 112us/step - loss: 0.0358 - accuracy: 0.9861 - val_loss: 0.0489 - val_accuracy: 0.9833\n",
      "Epoch 55/150\n",
      "254089/254089 [==============================] - 29s 115us/step - loss: 0.0357 - accuracy: 0.9861 - val_loss: 0.0480 - val_accuracy: 0.9834\n",
      "Epoch 56/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0355 - accuracy: 0.9861 - val_loss: 0.0475 - val_accuracy: 0.9834\n",
      "Epoch 57/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0354 - accuracy: 0.9862 - val_loss: 0.0477 - val_accuracy: 0.9835\n",
      "Epoch 58/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0353 - accuracy: 0.9862 - val_loss: 0.0483 - val_accuracy: 0.9834\n",
      "Epoch 59/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0351 - accuracy: 0.9863 - val_loss: 0.0478 - val_accuracy: 0.9836\n",
      "Epoch 60/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0350 - accuracy: 0.9863 - val_loss: 0.0477 - val_accuracy: 0.9835\n",
      "Epoch 61/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0349 - accuracy: 0.9863 - val_loss: 0.0476 - val_accuracy: 0.9837\n",
      "Epoch 62/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0348 - accuracy: 0.9864 - val_loss: 0.0474 - val_accuracy: 0.9836\n",
      "Epoch 63/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0346 - accuracy: 0.9864 - val_loss: 0.0468 - val_accuracy: 0.9838\n",
      "Epoch 64/150\n",
      "254089/254089 [==============================] - 29s 112us/step - loss: 0.0345 - accuracy: 0.9864 - val_loss: 0.0475 - val_accuracy: 0.9837\n",
      "Epoch 65/150\n",
      "254089/254089 [==============================] - 29s 115us/step - loss: 0.0344 - accuracy: 0.9865 - val_loss: 0.0472 - val_accuracy: 0.9838\n",
      "Epoch 66/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0343 - accuracy: 0.9865 - val_loss: 0.0467 - val_accuracy: 0.9839\n",
      "Epoch 67/150\n",
      "254089/254089 [==============================] - 29s 112us/step - loss: 0.0342 - accuracy: 0.9865 - val_loss: 0.0464 - val_accuracy: 0.9840\n",
      "Epoch 68/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0341 - accuracy: 0.9865 - val_loss: 0.0465 - val_accuracy: 0.9839\n",
      "Epoch 69/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0340 - accuracy: 0.9866 - val_loss: 0.0466 - val_accuracy: 0.9840\n",
      "Epoch 70/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0339 - accuracy: 0.9866 - val_loss: 0.0467 - val_accuracy: 0.9840\n",
      "Epoch 71/150\n",
      "254089/254089 [==============================] - 28s 112us/step - loss: 0.0338 - accuracy: 0.9866 - val_loss: 0.0468 - val_accuracy: 0.9839\n",
      "Epoch 72/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0337 - accuracy: 0.9867 - val_loss: 0.0461 - val_accuracy: 0.9840\n",
      "Epoch 73/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0336 - accuracy: 0.9867 - val_loss: 0.0462 - val_accuracy: 0.9840\n",
      "Epoch 74/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0335 - accuracy: 0.9867 - val_loss: 0.0462 - val_accuracy: 0.9841\n",
      "Epoch 75/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0334 - accuracy: 0.9868 - val_loss: 0.0461 - val_accuracy: 0.9842\n",
      "Epoch 76/150\n",
      "254089/254089 [==============================] - 28s 112us/step - loss: 0.0333 - accuracy: 0.9868 - val_loss: 0.0463 - val_accuracy: 0.9841\n",
      "Epoch 77/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0332 - accuracy: 0.9868 - val_loss: 0.0457 - val_accuracy: 0.9841\n",
      "Epoch 78/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0332 - accuracy: 0.9868 - val_loss: 0.0456 - val_accuracy: 0.9843\n",
      "Epoch 79/150\n",
      "254089/254089 [==============================] - 28s 112us/step - loss: 0.0331 - accuracy: 0.9869 - val_loss: 0.0452 - val_accuracy: 0.9844\n",
      "Epoch 80/150\n",
      "254089/254089 [==============================] - 29s 115us/step - loss: 0.0330 - accuracy: 0.9869 - val_loss: 0.0445 - val_accuracy: 0.9844\n",
      "Epoch 81/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0329 - accuracy: 0.9869 - val_loss: 0.0453 - val_accuracy: 0.9842\n",
      "Epoch 82/150\n",
      "254089/254089 [==============================] - 28s 112us/step - loss: 0.0328 - accuracy: 0.9869 - val_loss: 0.0455 - val_accuracy: 0.9843\n",
      "Epoch 83/150\n",
      "254089/254089 [==============================] - 29s 112us/step - loss: 0.0328 - accuracy: 0.9870 - val_loss: 0.0445 - val_accuracy: 0.9846\n",
      "Epoch 84/150\n",
      "254089/254089 [==============================] - 29s 115us/step - loss: 0.0327 - accuracy: 0.9870 - val_loss: 0.0456 - val_accuracy: 0.9843\n",
      "Epoch 85/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0326 - accuracy: 0.9870 - val_loss: 0.0450 - val_accuracy: 0.9845\n",
      "Epoch 86/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0325 - accuracy: 0.9870 - val_loss: 0.0451 - val_accuracy: 0.9845\n",
      "Epoch 87/150\n",
      "254089/254089 [==============================] - 29s 112us/step - loss: 0.0325 - accuracy: 0.9870 - val_loss: 0.0446 - val_accuracy: 0.9845\n",
      "Epoch 88/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0324 - accuracy: 0.9871 - val_loss: 0.0455 - val_accuracy: 0.9844\n",
      "Epoch 89/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0323 - accuracy: 0.9871 - val_loss: 0.0460 - val_accuracy: 0.9842\n",
      "Epoch 90/150\n",
      "254089/254089 [==============================] - 29s 115us/step - loss: 0.0322 - accuracy: 0.9871 - val_loss: 0.0439 - val_accuracy: 0.9848\n",
      "Epoch 91/150\n",
      "254089/254089 [==============================] - 29s 115us/step - loss: 0.0322 - accuracy: 0.9871 - val_loss: 0.0457 - val_accuracy: 0.9844\n",
      "Epoch 92/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0321 - accuracy: 0.9872 - val_loss: 0.0443 - val_accuracy: 0.9847\n",
      "Epoch 93/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0320 - accuracy: 0.9872 - val_loss: 0.0449 - val_accuracy: 0.9846\n",
      "Epoch 94/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0320 - accuracy: 0.9872 - val_loss: 0.0439 - val_accuracy: 0.9849\n",
      "Epoch 95/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0319 - accuracy: 0.9872 - val_loss: 0.0441 - val_accuracy: 0.9848\n",
      "Epoch 96/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0318 - accuracy: 0.9872 - val_loss: 0.0438 - val_accuracy: 0.9848\n",
      "Epoch 97/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0318 - accuracy: 0.9873 - val_loss: 0.0438 - val_accuracy: 0.9849\n",
      "Epoch 98/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0317 - accuracy: 0.9873 - val_loss: 0.0443 - val_accuracy: 0.9846\n",
      "Epoch 99/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0317 - accuracy: 0.9873 - val_loss: 0.0440 - val_accuracy: 0.9848\n",
      "Epoch 100/150\n",
      "254089/254089 [==============================] - 28s 112us/step - loss: 0.0316 - accuracy: 0.9873 - val_loss: 0.0435 - val_accuracy: 0.9848\n",
      "Epoch 101/150\n",
      "254089/254089 [==============================] - 28s 112us/step - loss: 0.0316 - accuracy: 0.9873 - val_loss: 0.0439 - val_accuracy: 0.9849\n",
      "Epoch 102/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0315 - accuracy: 0.9873 - val_loss: 0.0436 - val_accuracy: 0.9849\n",
      "Epoch 103/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0314 - accuracy: 0.9873 - val_loss: 0.0434 - val_accuracy: 0.9850\n",
      "Epoch 104/150\n",
      "254089/254089 [==============================] - 29s 112us/step - loss: 0.0314 - accuracy: 0.9874 - val_loss: 0.0432 - val_accuracy: 0.9850\n",
      "Epoch 105/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0313 - accuracy: 0.9874 - val_loss: 0.0432 - val_accuracy: 0.9851\n",
      "Epoch 106/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0313 - accuracy: 0.9874 - val_loss: 0.0441 - val_accuracy: 0.9849\n",
      "Epoch 107/150\n",
      "254089/254089 [==============================] - 28s 112us/step - loss: 0.0312 - accuracy: 0.9874 - val_loss: 0.0437 - val_accuracy: 0.9850\n",
      "Epoch 108/150\n",
      "254089/254089 [==============================] - 28s 112us/step - loss: 0.0312 - accuracy: 0.9874 - val_loss: 0.0442 - val_accuracy: 0.9849\n",
      "Epoch 109/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0311 - accuracy: 0.9875 - val_loss: 0.0439 - val_accuracy: 0.9849\n",
      "Epoch 110/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0311 - accuracy: 0.9875 - val_loss: 0.0433 - val_accuracy: 0.9851\n",
      "Epoch 111/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.0435 - val_accuracy: 0.9850\n",
      "Epoch 112/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.0441 - val_accuracy: 0.9849\n",
      "Epoch 113/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0309 - accuracy: 0.9875 - val_loss: 0.0433 - val_accuracy: 0.9851\n",
      "Epoch 114/150\n",
      "254089/254089 [==============================] - 29s 112us/step - loss: 0.0309 - accuracy: 0.9875 - val_loss: 0.0432 - val_accuracy: 0.9851\n",
      "Epoch 115/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.0433 - val_accuracy: 0.9851\n",
      "Epoch 116/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.0437 - val_accuracy: 0.9849\n",
      "Epoch 117/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0307 - accuracy: 0.9876 - val_loss: 0.0429 - val_accuracy: 0.9852\n",
      "Epoch 118/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0307 - accuracy: 0.9876 - val_loss: 0.0430 - val_accuracy: 0.9851\n",
      "Epoch 119/150\n",
      "254089/254089 [==============================] - 28s 111us/step - loss: 0.0306 - accuracy: 0.9876 - val_loss: 0.0428 - val_accuracy: 0.9852\n",
      "Epoch 120/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0306 - accuracy: 0.9876 - val_loss: 0.0426 - val_accuracy: 0.9852\n",
      "Epoch 121/150\n",
      "254089/254089 [==============================] - 29s 112us/step - loss: 0.0305 - accuracy: 0.9876 - val_loss: 0.0425 - val_accuracy: 0.9853\n",
      "Epoch 122/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0429 - val_accuracy: 0.9852\n",
      "Epoch 123/150\n",
      "254089/254089 [==============================] - 29s 112us/step - loss: 0.0304 - accuracy: 0.9877 - val_loss: 0.0424 - val_accuracy: 0.9853\n",
      "Epoch 124/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0304 - accuracy: 0.9877 - val_loss: 0.0421 - val_accuracy: 0.9854\n",
      "Epoch 125/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0303 - accuracy: 0.9877 - val_loss: 0.0432 - val_accuracy: 0.9852\n",
      "Epoch 126/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0303 - accuracy: 0.9877 - val_loss: 0.0422 - val_accuracy: 0.9853\n",
      "Epoch 127/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0302 - accuracy: 0.9877 - val_loss: 0.0421 - val_accuracy: 0.9853\n",
      "Epoch 128/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0302 - accuracy: 0.9877 - val_loss: 0.0422 - val_accuracy: 0.9855\n",
      "Epoch 129/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0302 - accuracy: 0.9877 - val_loss: 0.0427 - val_accuracy: 0.9854\n",
      "Epoch 130/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.0420 - val_accuracy: 0.9855\n",
      "Epoch 131/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.0425 - val_accuracy: 0.9854\n",
      "Epoch 132/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.0428 - val_accuracy: 0.9853\n",
      "Epoch 133/150\n",
      "254089/254089 [==============================] - 28s 112us/step - loss: 0.0300 - accuracy: 0.9878 - val_loss: 0.0422 - val_accuracy: 0.9854\n",
      "Epoch 134/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0300 - accuracy: 0.9878 - val_loss: 0.0421 - val_accuracy: 0.9854\n",
      "Epoch 135/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0299 - accuracy: 0.9878 - val_loss: 0.0433 - val_accuracy: 0.9853\n",
      "Epoch 136/150\n",
      "254089/254089 [==============================] - 28s 112us/step - loss: 0.0299 - accuracy: 0.9878 - val_loss: 0.0424 - val_accuracy: 0.9853\n",
      "Epoch 137/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0298 - accuracy: 0.9878 - val_loss: 0.0417 - val_accuracy: 0.9855\n",
      "Epoch 138/150\n",
      "254089/254089 [==============================] - 28s 112us/step - loss: 0.0298 - accuracy: 0.9879 - val_loss: 0.0422 - val_accuracy: 0.9854\n",
      "Epoch 139/150\n",
      "254089/254089 [==============================] - 29s 112us/step - loss: 0.0298 - accuracy: 0.9879 - val_loss: 0.0421 - val_accuracy: 0.9855\n",
      "Epoch 140/150\n",
      "254089/254089 [==============================] - 29s 114us/step - loss: 0.0297 - accuracy: 0.9879 - val_loss: 0.0425 - val_accuracy: 0.9853\n",
      "Epoch 141/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0297 - accuracy: 0.9879 - val_loss: 0.0419 - val_accuracy: 0.9855\n",
      "Epoch 142/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0297 - accuracy: 0.9879 - val_loss: 0.0430 - val_accuracy: 0.9854\n",
      "Epoch 143/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0296 - accuracy: 0.9879 - val_loss: 0.0419 - val_accuracy: 0.9855\n",
      "Epoch 144/150\n",
      "254089/254089 [==============================] - 29s 115us/step - loss: 0.0296 - accuracy: 0.9879 - val_loss: 0.0419 - val_accuracy: 0.9856\n",
      "Epoch 145/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0295 - accuracy: 0.9879 - val_loss: 0.0416 - val_accuracy: 0.9855\n",
      "Epoch 146/150\n",
      "254089/254089 [==============================] - 29s 112us/step - loss: 0.0295 - accuracy: 0.9879 - val_loss: 0.0418 - val_accuracy: 0.9854\n",
      "Epoch 147/150\n",
      "254089/254089 [==============================] - 28s 112us/step - loss: 0.0295 - accuracy: 0.9880 - val_loss: 0.0415 - val_accuracy: 0.9857\n",
      "Epoch 148/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0294 - accuracy: 0.9880 - val_loss: 0.0420 - val_accuracy: 0.9855\n",
      "Epoch 149/150\n",
      "254089/254089 [==============================] - 29s 113us/step - loss: 0.0294 - accuracy: 0.9880 - val_loss: 0.0418 - val_accuracy: 0.9856\n",
      "Epoch 150/150\n",
      "254089/254089 [==============================] - 28s 112us/step - loss: 0.0294 - accuracy: 0.9880 - val_loss: 0.0419 - val_accuracy: 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:136: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Train on 254090 samples, validate on 84697 samples\n",
      "Epoch 1/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.1631 - accuracy: 0.9603 - val_loss: 0.1866 - val_accuracy: 0.9523\n",
      "Epoch 2/150\n",
      "254090/254090 [==============================] - 31s 121us/step - loss: 0.1396 - accuracy: 0.9625 - val_loss: 0.1458 - val_accuracy: 0.9534\n",
      "Epoch 3/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.1078 - accuracy: 0.9651 - val_loss: 0.1168 - val_accuracy: 0.9598\n",
      "Epoch 4/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0900 - accuracy: 0.9692 - val_loss: 0.1027 - val_accuracy: 0.9643\n",
      "Epoch 5/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0783 - accuracy: 0.9727 - val_loss: 0.0934 - val_accuracy: 0.9678\n",
      "Epoch 6/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0708 - accuracy: 0.9752 - val_loss: 0.0874 - val_accuracy: 0.9700\n",
      "Epoch 7/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0659 - accuracy: 0.9770 - val_loss: 0.0825 - val_accuracy: 0.9718\n",
      "Epoch 8/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0618 - accuracy: 0.9784 - val_loss: 0.0789 - val_accuracy: 0.9733\n",
      "Epoch 9/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0588 - accuracy: 0.9794 - val_loss: 0.0762 - val_accuracy: 0.9743\n",
      "Epoch 10/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0564 - accuracy: 0.9802 - val_loss: 0.0737 - val_accuracy: 0.9751\n",
      "Epoch 11/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0545 - accuracy: 0.9809 - val_loss: 0.0718 - val_accuracy: 0.9759\n",
      "Epoch 12/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0528 - accuracy: 0.9814 - val_loss: 0.0702 - val_accuracy: 0.9765\n",
      "Epoch 13/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0514 - accuracy: 0.9819 - val_loss: 0.0677 - val_accuracy: 0.9771\n",
      "Epoch 14/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0502 - accuracy: 0.9823 - val_loss: 0.0668 - val_accuracy: 0.9776\n",
      "Epoch 15/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0492 - accuracy: 0.9826 - val_loss: 0.0658 - val_accuracy: 0.9780\n",
      "Epoch 16/150\n",
      "254090/254090 [==============================] - 31s 120us/step - loss: 0.0483 - accuracy: 0.9829 - val_loss: 0.0648 - val_accuracy: 0.9784\n",
      "Epoch 17/150\n",
      "254090/254090 [==============================] - 33s 131us/step - loss: 0.0475 - accuracy: 0.9831 - val_loss: 0.0631 - val_accuracy: 0.9788\n",
      "Epoch 18/150\n",
      "254090/254090 [==============================] - 33s 129us/step - loss: 0.0467 - accuracy: 0.9833 - val_loss: 0.0624 - val_accuracy: 0.9790\n",
      "Epoch 19/150\n",
      "254090/254090 [==============================] - 32s 125us/step - loss: 0.0461 - accuracy: 0.9835 - val_loss: 0.0618 - val_accuracy: 0.9793\n",
      "Epoch 20/150\n",
      "254090/254090 [==============================] - 36s 140us/step - loss: 0.0455 - accuracy: 0.9837 - val_loss: 0.0602 - val_accuracy: 0.9797\n",
      "Epoch 21/150\n",
      "254090/254090 [==============================] - 34s 133us/step - loss: 0.0449 - accuracy: 0.9839 - val_loss: 0.0595 - val_accuracy: 0.9798\n",
      "Epoch 22/150\n",
      "254090/254090 [==============================] - 33s 130us/step - loss: 0.0444 - accuracy: 0.9840 - val_loss: 0.0596 - val_accuracy: 0.9799\n",
      "Epoch 23/150\n",
      "254090/254090 [==============================] - 33s 131us/step - loss: 0.0439 - accuracy: 0.9841 - val_loss: 0.0590 - val_accuracy: 0.9801\n",
      "Epoch 24/150\n",
      "254090/254090 [==============================] - 33s 131us/step - loss: 0.0434 - accuracy: 0.9842 - val_loss: 0.0580 - val_accuracy: 0.9805\n",
      "Epoch 25/150\n",
      "254090/254090 [==============================] - 33s 131us/step - loss: 0.0430 - accuracy: 0.9843 - val_loss: 0.0577 - val_accuracy: 0.9806\n",
      "Epoch 26/150\n",
      "254090/254090 [==============================] - 35s 138us/step - loss: 0.0426 - accuracy: 0.9845 - val_loss: 0.0572 - val_accuracy: 0.9807\n",
      "Epoch 27/150\n",
      "254090/254090 [==============================] - 34s 134us/step - loss: 0.0422 - accuracy: 0.9845 - val_loss: 0.0569 - val_accuracy: 0.9809\n",
      "Epoch 28/150\n",
      "254090/254090 [==============================] - 37s 144us/step - loss: 0.0418 - accuracy: 0.9846 - val_loss: 0.0561 - val_accuracy: 0.9811\n",
      "Epoch 29/150\n",
      "254090/254090 [==============================] - 34s 133us/step - loss: 0.0414 - accuracy: 0.9847 - val_loss: 0.0560 - val_accuracy: 0.9812\n",
      "Epoch 30/150\n",
      "254090/254090 [==============================] - 33s 132us/step - loss: 0.0411 - accuracy: 0.9848 - val_loss: 0.0548 - val_accuracy: 0.9813\n",
      "Epoch 31/150\n",
      "254090/254090 [==============================] - 33s 130us/step - loss: 0.0408 - accuracy: 0.9849 - val_loss: 0.0547 - val_accuracy: 0.9814\n",
      "Epoch 32/150\n",
      "254090/254090 [==============================] - 33s 131us/step - loss: 0.0405 - accuracy: 0.9850 - val_loss: 0.0546 - val_accuracy: 0.9816\n",
      "Epoch 33/150\n",
      "254090/254090 [==============================] - 34s 132us/step - loss: 0.0402 - accuracy: 0.9850 - val_loss: 0.0540 - val_accuracy: 0.9818\n",
      "Epoch 34/150\n",
      "254090/254090 [==============================] - 33s 132us/step - loss: 0.0399 - accuracy: 0.9851 - val_loss: 0.0532 - val_accuracy: 0.9820\n",
      "Epoch 35/150\n",
      "254090/254090 [==============================] - 33s 130us/step - loss: 0.0396 - accuracy: 0.9851 - val_loss: 0.0529 - val_accuracy: 0.9821\n",
      "Epoch 36/150\n",
      "254090/254090 [==============================] - 33s 129us/step - loss: 0.0394 - accuracy: 0.9852 - val_loss: 0.0526 - val_accuracy: 0.9821\n",
      "Epoch 37/150\n",
      "254090/254090 [==============================] - 33s 129us/step - loss: 0.0391 - accuracy: 0.9853 - val_loss: 0.0524 - val_accuracy: 0.9822\n",
      "Epoch 38/150\n",
      "254090/254090 [==============================] - 33s 130us/step - loss: 0.0389 - accuracy: 0.9853 - val_loss: 0.0523 - val_accuracy: 0.9822\n",
      "Epoch 39/150\n",
      "254090/254090 [==============================] - 33s 130us/step - loss: 0.0387 - accuracy: 0.9854 - val_loss: 0.0524 - val_accuracy: 0.9822\n",
      "Epoch 40/150\n",
      "254090/254090 [==============================] - 33s 129us/step - loss: 0.0384 - accuracy: 0.9854 - val_loss: 0.0524 - val_accuracy: 0.9823\n",
      "Epoch 41/150\n",
      "254090/254090 [==============================] - 33s 132us/step - loss: 0.0382 - accuracy: 0.9855 - val_loss: 0.0518 - val_accuracy: 0.9824\n",
      "Epoch 42/150\n",
      "254090/254090 [==============================] - 33s 130us/step - loss: 0.0380 - accuracy: 0.9855 - val_loss: 0.0511 - val_accuracy: 0.9824\n",
      "Epoch 43/150\n",
      "254090/254090 [==============================] - 33s 129us/step - loss: 0.0378 - accuracy: 0.9856 - val_loss: 0.0510 - val_accuracy: 0.9827\n",
      "Epoch 44/150\n",
      "254090/254090 [==============================] - 33s 129us/step - loss: 0.0376 - accuracy: 0.9856 - val_loss: 0.0512 - val_accuracy: 0.9826\n",
      "Epoch 45/150\n",
      "254090/254090 [==============================] - 33s 129us/step - loss: 0.0375 - accuracy: 0.9857 - val_loss: 0.0508 - val_accuracy: 0.9827\n",
      "Epoch 46/150\n",
      "254090/254090 [==============================] - 33s 130us/step - loss: 0.0373 - accuracy: 0.9857 - val_loss: 0.0509 - val_accuracy: 0.9826\n",
      "Epoch 47/150\n",
      "254090/254090 [==============================] - 33s 129us/step - loss: 0.0371 - accuracy: 0.9858 - val_loss: 0.0506 - val_accuracy: 0.9828\n",
      "Epoch 48/150\n",
      "254090/254090 [==============================] - 33s 130us/step - loss: 0.0369 - accuracy: 0.9858 - val_loss: 0.0504 - val_accuracy: 0.9828\n",
      "Epoch 49/150\n",
      "254090/254090 [==============================] - 34s 133us/step - loss: 0.0368 - accuracy: 0.9859 - val_loss: 0.0498 - val_accuracy: 0.9830\n",
      "Epoch 50/150\n",
      "254090/254090 [==============================] - 33s 130us/step - loss: 0.0366 - accuracy: 0.9859 - val_loss: 0.0506 - val_accuracy: 0.9829\n",
      "Epoch 51/150\n",
      "254090/254090 [==============================] - 33s 130us/step - loss: 0.0365 - accuracy: 0.9859 - val_loss: 0.0495 - val_accuracy: 0.9829\n",
      "Epoch 52/150\n",
      "254090/254090 [==============================] - 36s 142us/step - loss: 0.0363 - accuracy: 0.9860 - val_loss: 0.0497 - val_accuracy: 0.9830\n",
      "Epoch 53/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254090/254090 [==============================] - 35s 138us/step - loss: 0.0362 - accuracy: 0.9860 - val_loss: 0.0496 - val_accuracy: 0.9832\n",
      "Epoch 54/150\n",
      "254090/254090 [==============================] - 35s 138us/step - loss: 0.0360 - accuracy: 0.9860 - val_loss: 0.0494 - val_accuracy: 0.9832\n",
      "Epoch 55/150\n",
      "254090/254090 [==============================] - 35s 138us/step - loss: 0.0359 - accuracy: 0.9861 - val_loss: 0.0494 - val_accuracy: 0.9832\n",
      "Epoch 56/150\n",
      "254090/254090 [==============================] - 35s 138us/step - loss: 0.0358 - accuracy: 0.9861 - val_loss: 0.0486 - val_accuracy: 0.9833\n",
      "Epoch 57/150\n",
      "254090/254090 [==============================] - 35s 138us/step - loss: 0.0356 - accuracy: 0.9861 - val_loss: 0.0488 - val_accuracy: 0.9833\n",
      "Epoch 58/150\n",
      "254090/254090 [==============================] - 36s 141us/step - loss: 0.0355 - accuracy: 0.9862 - val_loss: 0.0492 - val_accuracy: 0.9833\n",
      "Epoch 59/150\n",
      "254090/254090 [==============================] - 33s 129us/step - loss: 0.0354 - accuracy: 0.9862 - val_loss: 0.0487 - val_accuracy: 0.9834\n",
      "Epoch 60/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0353 - accuracy: 0.9863 - val_loss: 0.0485 - val_accuracy: 0.9834\n",
      "Epoch 61/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0351 - accuracy: 0.9863 - val_loss: 0.0481 - val_accuracy: 0.9835\n",
      "Epoch 62/150\n",
      "254090/254090 [==============================] - 31s 120us/step - loss: 0.0350 - accuracy: 0.9863 - val_loss: 0.0484 - val_accuracy: 0.9834\n",
      "Epoch 63/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0349 - accuracy: 0.9864 - val_loss: 0.0474 - val_accuracy: 0.9837\n",
      "Epoch 64/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0348 - accuracy: 0.9864 - val_loss: 0.0483 - val_accuracy: 0.9836\n",
      "Epoch 65/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0347 - accuracy: 0.9864 - val_loss: 0.0481 - val_accuracy: 0.9836\n",
      "Epoch 66/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0346 - accuracy: 0.9864 - val_loss: 0.0476 - val_accuracy: 0.9837\n",
      "Epoch 67/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0345 - accuracy: 0.9865 - val_loss: 0.0474 - val_accuracy: 0.9838\n",
      "Epoch 68/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0344 - accuracy: 0.9865 - val_loss: 0.0480 - val_accuracy: 0.9838\n",
      "Epoch 69/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0343 - accuracy: 0.9865 - val_loss: 0.0469 - val_accuracy: 0.9839\n",
      "Epoch 70/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0342 - accuracy: 0.9866 - val_loss: 0.0469 - val_accuracy: 0.9839\n",
      "Epoch 71/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0341 - accuracy: 0.9866 - val_loss: 0.0467 - val_accuracy: 0.9840\n",
      "Epoch 72/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0340 - accuracy: 0.9866 - val_loss: 0.0472 - val_accuracy: 0.9838\n",
      "Epoch 73/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0339 - accuracy: 0.9866 - val_loss: 0.0470 - val_accuracy: 0.9839\n",
      "Epoch 74/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0338 - accuracy: 0.9867 - val_loss: 0.0469 - val_accuracy: 0.9840\n",
      "Epoch 75/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0337 - accuracy: 0.9867 - val_loss: 0.0461 - val_accuracy: 0.9842\n",
      "Epoch 76/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0336 - accuracy: 0.9867 - val_loss: 0.0467 - val_accuracy: 0.9841\n",
      "Epoch 77/150\n",
      "254090/254090 [==============================] - 31s 121us/step - loss: 0.0335 - accuracy: 0.9867 - val_loss: 0.0465 - val_accuracy: 0.9840\n",
      "Epoch 78/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0335 - accuracy: 0.9868 - val_loss: 0.0465 - val_accuracy: 0.9841\n",
      "Epoch 79/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0334 - accuracy: 0.9868 - val_loss: 0.0467 - val_accuracy: 0.9842\n",
      "Epoch 80/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0333 - accuracy: 0.9868 - val_loss: 0.0467 - val_accuracy: 0.9841\n",
      "Epoch 81/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0332 - accuracy: 0.9868 - val_loss: 0.0458 - val_accuracy: 0.9843\n",
      "Epoch 82/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0331 - accuracy: 0.9869 - val_loss: 0.0466 - val_accuracy: 0.9841\n",
      "Epoch 83/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0331 - accuracy: 0.9869 - val_loss: 0.0461 - val_accuracy: 0.9842\n",
      "Epoch 84/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0330 - accuracy: 0.9869 - val_loss: 0.0462 - val_accuracy: 0.9843\n",
      "Epoch 85/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0329 - accuracy: 0.9869 - val_loss: 0.0467 - val_accuracy: 0.9842\n",
      "Epoch 86/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0328 - accuracy: 0.9869 - val_loss: 0.0455 - val_accuracy: 0.9844\n",
      "Epoch 87/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0328 - accuracy: 0.9870 - val_loss: 0.0457 - val_accuracy: 0.9844\n",
      "Epoch 88/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0327 - accuracy: 0.9870 - val_loss: 0.0458 - val_accuracy: 0.9844\n",
      "Epoch 89/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0326 - accuracy: 0.9870 - val_loss: 0.0457 - val_accuracy: 0.9844\n",
      "Epoch 90/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0325 - accuracy: 0.9870 - val_loss: 0.0455 - val_accuracy: 0.9845\n",
      "Epoch 91/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0325 - accuracy: 0.9871 - val_loss: 0.0455 - val_accuracy: 0.9845\n",
      "Epoch 92/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0324 - accuracy: 0.9871 - val_loss: 0.0453 - val_accuracy: 0.9845\n",
      "Epoch 93/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0323 - accuracy: 0.9871 - val_loss: 0.0457 - val_accuracy: 0.9845\n",
      "Epoch 94/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0323 - accuracy: 0.9871 - val_loss: 0.0449 - val_accuracy: 0.9846\n",
      "Epoch 95/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0322 - accuracy: 0.9871 - val_loss: 0.0445 - val_accuracy: 0.9847\n",
      "Epoch 96/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0322 - accuracy: 0.9872 - val_loss: 0.0443 - val_accuracy: 0.9846\n",
      "Epoch 97/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0321 - accuracy: 0.9872 - val_loss: 0.0449 - val_accuracy: 0.9847\n",
      "Epoch 98/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0320 - accuracy: 0.9872 - val_loss: 0.0453 - val_accuracy: 0.9847\n",
      "Epoch 99/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0320 - accuracy: 0.9872 - val_loss: 0.0445 - val_accuracy: 0.9847\n",
      "Epoch 100/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0319 - accuracy: 0.9872 - val_loss: 0.0446 - val_accuracy: 0.9848\n",
      "Epoch 101/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0318 - accuracy: 0.9872 - val_loss: 0.0452 - val_accuracy: 0.9847\n",
      "Epoch 102/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0318 - accuracy: 0.9873 - val_loss: 0.0447 - val_accuracy: 0.9847\n",
      "Epoch 103/150\n",
      "254090/254090 [==============================] - 30s 120us/step - loss: 0.0317 - accuracy: 0.9873 - val_loss: 0.0449 - val_accuracy: 0.9848\n",
      "Epoch 104/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0317 - accuracy: 0.9873 - val_loss: 0.0448 - val_accuracy: 0.9848\n",
      "Epoch 105/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0316 - accuracy: 0.9873 - val_loss: 0.0441 - val_accuracy: 0.9848\n",
      "Epoch 106/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0316 - accuracy: 0.9873 - val_loss: 0.0447 - val_accuracy: 0.9849\n",
      "Epoch 107/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0315 - accuracy: 0.9874 - val_loss: 0.0439 - val_accuracy: 0.9848\n",
      "Epoch 108/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0315 - accuracy: 0.9874 - val_loss: 0.0447 - val_accuracy: 0.9848\n",
      "Epoch 109/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0314 - accuracy: 0.9874 - val_loss: 0.0444 - val_accuracy: 0.9849\n",
      "Epoch 110/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0313 - accuracy: 0.9874 - val_loss: 0.0452 - val_accuracy: 0.9848\n",
      "Epoch 111/150\n",
      "254090/254090 [==============================] - 30s 120us/step - loss: 0.0313 - accuracy: 0.9874 - val_loss: 0.0439 - val_accuracy: 0.9850\n",
      "Epoch 112/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0312 - accuracy: 0.9874 - val_loss: 0.0444 - val_accuracy: 0.9848\n",
      "Epoch 113/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0312 - accuracy: 0.9875 - val_loss: 0.0440 - val_accuracy: 0.9849\n",
      "Epoch 114/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0311 - accuracy: 0.9875 - val_loss: 0.0448 - val_accuracy: 0.9849\n",
      "Epoch 115/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0311 - accuracy: 0.9875 - val_loss: 0.0441 - val_accuracy: 0.9850\n",
      "Epoch 116/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.0440 - val_accuracy: 0.9850\n",
      "Epoch 117/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.0440 - val_accuracy: 0.9850\n",
      "Epoch 118/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0309 - accuracy: 0.9875 - val_loss: 0.0439 - val_accuracy: 0.9850\n",
      "Epoch 119/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0309 - accuracy: 0.9875 - val_loss: 0.0436 - val_accuracy: 0.9851\n",
      "Epoch 120/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.0444 - val_accuracy: 0.9850\n",
      "Epoch 121/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.0441 - val_accuracy: 0.9850\n",
      "Epoch 122/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.0437 - val_accuracy: 0.9851\n",
      "Epoch 123/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0307 - accuracy: 0.9876 - val_loss: 0.0433 - val_accuracy: 0.9851\n",
      "Epoch 124/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0307 - accuracy: 0.9876 - val_loss: 0.0435 - val_accuracy: 0.9851\n",
      "Epoch 125/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0306 - accuracy: 0.9876 - val_loss: 0.0440 - val_accuracy: 0.9851\n",
      "Epoch 126/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0306 - accuracy: 0.9877 - val_loss: 0.0433 - val_accuracy: 0.9851\n",
      "Epoch 127/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0437 - val_accuracy: 0.9852\n",
      "Epoch 128/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0435 - val_accuracy: 0.9852\n",
      "Epoch 129/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0304 - accuracy: 0.9877 - val_loss: 0.0436 - val_accuracy: 0.9851\n",
      "Epoch 130/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0304 - accuracy: 0.9877 - val_loss: 0.0431 - val_accuracy: 0.9852\n",
      "Epoch 131/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0303 - accuracy: 0.9877 - val_loss: 0.0435 - val_accuracy: 0.9852\n",
      "Epoch 132/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0303 - accuracy: 0.9877 - val_loss: 0.0435 - val_accuracy: 0.9852\n",
      "Epoch 133/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0303 - accuracy: 0.9877 - val_loss: 0.0434 - val_accuracy: 0.9853\n",
      "Epoch 134/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0302 - accuracy: 0.9878 - val_loss: 0.0434 - val_accuracy: 0.9853\n",
      "Epoch 135/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0302 - accuracy: 0.9878 - val_loss: 0.0434 - val_accuracy: 0.9852\n",
      "Epoch 136/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.0431 - val_accuracy: 0.9853\n",
      "Epoch 137/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.0426 - val_accuracy: 0.9854\n",
      "Epoch 138/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.0435 - val_accuracy: 0.9852\n",
      "Epoch 139/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0300 - accuracy: 0.9878 - val_loss: 0.0437 - val_accuracy: 0.9852\n",
      "Epoch 140/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0300 - accuracy: 0.9878 - val_loss: 0.0431 - val_accuracy: 0.9852\n",
      "Epoch 141/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0299 - accuracy: 0.9878 - val_loss: 0.0438 - val_accuracy: 0.9853\n",
      "Epoch 142/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0299 - accuracy: 0.9879 - val_loss: 0.0439 - val_accuracy: 0.9853\n",
      "Epoch 143/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0299 - accuracy: 0.9879 - val_loss: 0.0429 - val_accuracy: 0.9854\n",
      "Epoch 144/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0298 - accuracy: 0.9879 - val_loss: 0.0432 - val_accuracy: 0.9853\n",
      "Epoch 145/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0298 - accuracy: 0.9879 - val_loss: 0.0427 - val_accuracy: 0.9854\n",
      "Epoch 146/150\n",
      "254090/254090 [==============================] - 30s 119us/step - loss: 0.0298 - accuracy: 0.9879 - val_loss: 0.0434 - val_accuracy: 0.9853\n",
      "Epoch 147/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0297 - accuracy: 0.9879 - val_loss: 0.0425 - val_accuracy: 0.9854\n",
      "Epoch 148/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0297 - accuracy: 0.9879 - val_loss: 0.0425 - val_accuracy: 0.9855\n",
      "Epoch 149/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0297 - accuracy: 0.9879 - val_loss: 0.0435 - val_accuracy: 0.9853\n",
      "Epoch 150/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0296 - accuracy: 0.9880 - val_loss: 0.0428 - val_accuracy: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:136: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Train on 254090 samples, validate on 84697 samples\n",
      "Epoch 1/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.1619 - accuracy: 0.9610 - val_loss: 0.1864 - val_accuracy: 0.9523\n",
      "Epoch 2/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.1430 - accuracy: 0.9625 - val_loss: 0.1542 - val_accuracy: 0.9526\n",
      "Epoch 3/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.1132 - accuracy: 0.9642 - val_loss: 0.1211 - val_accuracy: 0.9583\n",
      "Epoch 4/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0922 - accuracy: 0.9686 - val_loss: 0.1054 - val_accuracy: 0.9633\n",
      "Epoch 5/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0814 - accuracy: 0.9719 - val_loss: 0.0962 - val_accuracy: 0.9665\n",
      "Epoch 6/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0739 - accuracy: 0.9744 - val_loss: 0.0902 - val_accuracy: 0.9688\n",
      "Epoch 7/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0685 - accuracy: 0.9762 - val_loss: 0.0861 - val_accuracy: 0.9703\n",
      "Epoch 8/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0646 - accuracy: 0.9775 - val_loss: 0.0829 - val_accuracy: 0.9716\n",
      "Epoch 9/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0615 - accuracy: 0.9785 - val_loss: 0.0798 - val_accuracy: 0.9727\n",
      "Epoch 10/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0590 - accuracy: 0.9794 - val_loss: 0.0768 - val_accuracy: 0.9737\n",
      "Epoch 11/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0568 - accuracy: 0.9801 - val_loss: 0.0745 - val_accuracy: 0.9745\n",
      "Epoch 12/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0548 - accuracy: 0.9807 - val_loss: 0.0716 - val_accuracy: 0.9753\n",
      "Epoch 13/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0532 - accuracy: 0.9813 - val_loss: 0.0703 - val_accuracy: 0.9760\n",
      "Epoch 14/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0517 - accuracy: 0.9817 - val_loss: 0.0687 - val_accuracy: 0.9765\n",
      "Epoch 15/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0505 - accuracy: 0.9821 - val_loss: 0.0667 - val_accuracy: 0.9772\n",
      "Epoch 16/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0495 - accuracy: 0.9824 - val_loss: 0.0652 - val_accuracy: 0.9777\n",
      "Epoch 17/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0486 - accuracy: 0.9827 - val_loss: 0.0641 - val_accuracy: 0.9780\n",
      "Epoch 18/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0477 - accuracy: 0.9830 - val_loss: 0.0634 - val_accuracy: 0.9783\n",
      "Epoch 19/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0470 - accuracy: 0.9832 - val_loss: 0.0623 - val_accuracy: 0.9786\n",
      "Epoch 20/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0463 - accuracy: 0.9834 - val_loss: 0.0614 - val_accuracy: 0.9790\n",
      "Epoch 21/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0457 - accuracy: 0.9836 - val_loss: 0.0603 - val_accuracy: 0.9793\n",
      "Epoch 22/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0452 - accuracy: 0.9837 - val_loss: 0.0601 - val_accuracy: 0.9795\n",
      "Epoch 23/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0446 - accuracy: 0.9839 - val_loss: 0.0592 - val_accuracy: 0.9797\n",
      "Epoch 24/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0441 - accuracy: 0.9840 - val_loss: 0.0587 - val_accuracy: 0.9800\n",
      "Epoch 25/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0437 - accuracy: 0.9841 - val_loss: 0.0581 - val_accuracy: 0.9802\n",
      "Epoch 26/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0432 - accuracy: 0.9842 - val_loss: 0.0565 - val_accuracy: 0.9806\n",
      "Epoch 27/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0428 - accuracy: 0.9843 - val_loss: 0.0571 - val_accuracy: 0.9804\n",
      "Epoch 28/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0424 - accuracy: 0.9844 - val_loss: 0.0570 - val_accuracy: 0.9806\n",
      "Epoch 29/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0421 - accuracy: 0.9845 - val_loss: 0.0559 - val_accuracy: 0.9810\n",
      "Epoch 30/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0417 - accuracy: 0.9846 - val_loss: 0.0554 - val_accuracy: 0.9811\n",
      "Epoch 31/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0414 - accuracy: 0.9847 - val_loss: 0.0555 - val_accuracy: 0.9811\n",
      "Epoch 32/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0411 - accuracy: 0.9847 - val_loss: 0.0551 - val_accuracy: 0.9812\n",
      "Epoch 33/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0408 - accuracy: 0.9848 - val_loss: 0.0543 - val_accuracy: 0.9815\n",
      "Epoch 34/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0405 - accuracy: 0.9849 - val_loss: 0.0539 - val_accuracy: 0.9815\n",
      "Epoch 35/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0402 - accuracy: 0.9849 - val_loss: 0.0533 - val_accuracy: 0.9817\n",
      "Epoch 36/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0399 - accuracy: 0.9850 - val_loss: 0.0536 - val_accuracy: 0.9817\n",
      "Epoch 37/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0397 - accuracy: 0.9851 - val_loss: 0.0528 - val_accuracy: 0.9818\n",
      "Epoch 38/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0394 - accuracy: 0.9852 - val_loss: 0.0532 - val_accuracy: 0.9819\n",
      "Epoch 39/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0392 - accuracy: 0.9852 - val_loss: 0.0520 - val_accuracy: 0.9822\n",
      "Epoch 40/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0390 - accuracy: 0.9853 - val_loss: 0.0520 - val_accuracy: 0.9821\n",
      "Epoch 41/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0387 - accuracy: 0.9853 - val_loss: 0.0518 - val_accuracy: 0.9822\n",
      "Epoch 42/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0385 - accuracy: 0.9854 - val_loss: 0.0513 - val_accuracy: 0.9824\n",
      "Epoch 43/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0383 - accuracy: 0.9854 - val_loss: 0.0518 - val_accuracy: 0.9822\n",
      "Epoch 44/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0381 - accuracy: 0.9855 - val_loss: 0.0510 - val_accuracy: 0.9825\n",
      "Epoch 45/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0379 - accuracy: 0.9855 - val_loss: 0.0508 - val_accuracy: 0.9824\n",
      "Epoch 46/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0378 - accuracy: 0.9856 - val_loss: 0.0508 - val_accuracy: 0.9826\n",
      "Epoch 47/150\n",
      "254090/254090 [==============================] - 29s 114us/step - loss: 0.0376 - accuracy: 0.9856 - val_loss: 0.0506 - val_accuracy: 0.9825\n",
      "Epoch 48/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0374 - accuracy: 0.9856 - val_loss: 0.0504 - val_accuracy: 0.9827\n",
      "Epoch 49/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0372 - accuracy: 0.9857 - val_loss: 0.0507 - val_accuracy: 0.9828\n",
      "Epoch 50/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0371 - accuracy: 0.9858 - val_loss: 0.0496 - val_accuracy: 0.9829\n",
      "Epoch 51/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0369 - accuracy: 0.9858 - val_loss: 0.0498 - val_accuracy: 0.9830\n",
      "Epoch 52/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0368 - accuracy: 0.9858 - val_loss: 0.0490 - val_accuracy: 0.9830\n",
      "Epoch 53/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0366 - accuracy: 0.9859 - val_loss: 0.0491 - val_accuracy: 0.9831\n",
      "Epoch 54/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0365 - accuracy: 0.9859 - val_loss: 0.0487 - val_accuracy: 0.9832\n",
      "Epoch 55/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0363 - accuracy: 0.9860 - val_loss: 0.0494 - val_accuracy: 0.9831\n",
      "Epoch 56/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0362 - accuracy: 0.9860 - val_loss: 0.0491 - val_accuracy: 0.9832\n",
      "Epoch 57/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0360 - accuracy: 0.9860 - val_loss: 0.0489 - val_accuracy: 0.9832\n",
      "Epoch 58/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0359 - accuracy: 0.9861 - val_loss: 0.0491 - val_accuracy: 0.9832\n",
      "Epoch 59/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0358 - accuracy: 0.9861 - val_loss: 0.0479 - val_accuracy: 0.9835\n",
      "Epoch 60/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0356 - accuracy: 0.9862 - val_loss: 0.0487 - val_accuracy: 0.9834\n",
      "Epoch 61/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0355 - accuracy: 0.9862 - val_loss: 0.0486 - val_accuracy: 0.9834\n",
      "Epoch 62/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0354 - accuracy: 0.9862 - val_loss: 0.0478 - val_accuracy: 0.9835\n",
      "Epoch 63/150\n",
      "254090/254090 [==============================] - 31s 121us/step - loss: 0.0353 - accuracy: 0.9862 - val_loss: 0.0479 - val_accuracy: 0.9836\n",
      "Epoch 64/150\n",
      "254090/254090 [==============================] - 36s 143us/step - loss: 0.0352 - accuracy: 0.9863 - val_loss: 0.0480 - val_accuracy: 0.9836\n",
      "Epoch 65/150\n",
      "254090/254090 [==============================] - 36s 140us/step - loss: 0.0351 - accuracy: 0.9863 - val_loss: 0.0472 - val_accuracy: 0.9837\n",
      "Epoch 66/150\n",
      "254090/254090 [==============================] - 32s 128us/step - loss: 0.0349 - accuracy: 0.9864 - val_loss: 0.0482 - val_accuracy: 0.9835\n",
      "Epoch 67/150\n",
      "254090/254090 [==============================] - 32s 126us/step - loss: 0.0348 - accuracy: 0.9864 - val_loss: 0.0473 - val_accuracy: 0.9838\n",
      "Epoch 68/150\n",
      "254090/254090 [==============================] - 32s 126us/step - loss: 0.0347 - accuracy: 0.9864 - val_loss: 0.0483 - val_accuracy: 0.9836\n",
      "Epoch 69/150\n",
      "254090/254090 [==============================] - 32s 128us/step - loss: 0.0346 - accuracy: 0.9865 - val_loss: 0.0477 - val_accuracy: 0.9838\n",
      "Epoch 70/150\n",
      "254090/254090 [==============================] - 32s 126us/step - loss: 0.0345 - accuracy: 0.9865 - val_loss: 0.0471 - val_accuracy: 0.9838\n",
      "Epoch 71/150\n",
      "254090/254090 [==============================] - 32s 127us/step - loss: 0.0344 - accuracy: 0.9865 - val_loss: 0.0479 - val_accuracy: 0.9836\n",
      "Epoch 72/150\n",
      "254090/254090 [==============================] - 33s 128us/step - loss: 0.0343 - accuracy: 0.9865 - val_loss: 0.0475 - val_accuracy: 0.9838\n",
      "Epoch 73/150\n",
      "254090/254090 [==============================] - 32s 127us/step - loss: 0.0342 - accuracy: 0.9866 - val_loss: 0.0462 - val_accuracy: 0.9838\n",
      "Epoch 74/150\n",
      "254090/254090 [==============================] - 32s 126us/step - loss: 0.0341 - accuracy: 0.9866 - val_loss: 0.0464 - val_accuracy: 0.9840\n",
      "Epoch 75/150\n",
      "254090/254090 [==============================] - 32s 127us/step - loss: 0.0340 - accuracy: 0.9866 - val_loss: 0.0475 - val_accuracy: 0.9838\n",
      "Epoch 76/150\n",
      "254090/254090 [==============================] - 32s 126us/step - loss: 0.0340 - accuracy: 0.9866 - val_loss: 0.0463 - val_accuracy: 0.9840\n",
      "Epoch 77/150\n",
      "254090/254090 [==============================] - 32s 127us/step - loss: 0.0339 - accuracy: 0.9867 - val_loss: 0.0463 - val_accuracy: 0.9841\n",
      "Epoch 78/150\n",
      "254090/254090 [==============================] - 32s 127us/step - loss: 0.0338 - accuracy: 0.9867 - val_loss: 0.0465 - val_accuracy: 0.9840\n",
      "Epoch 79/150\n",
      "254090/254090 [==============================] - 32s 127us/step - loss: 0.0337 - accuracy: 0.9867 - val_loss: 0.0465 - val_accuracy: 0.9840\n",
      "Epoch 80/150\n",
      "254090/254090 [==============================] - 33s 131us/step - loss: 0.0336 - accuracy: 0.9867 - val_loss: 0.0453 - val_accuracy: 0.9843\n",
      "Epoch 81/150\n",
      "254090/254090 [==============================] - 33s 130us/step - loss: 0.0335 - accuracy: 0.9868 - val_loss: 0.0461 - val_accuracy: 0.9842\n",
      "Epoch 82/150\n",
      "254090/254090 [==============================] - 32s 126us/step - loss: 0.0334 - accuracy: 0.9868 - val_loss: 0.0466 - val_accuracy: 0.9841\n",
      "Epoch 83/150\n",
      "254090/254090 [==============================] - 32s 126us/step - loss: 0.0334 - accuracy: 0.9868 - val_loss: 0.0460 - val_accuracy: 0.9843\n",
      "Epoch 84/150\n",
      "254090/254090 [==============================] - 32s 125us/step - loss: 0.0333 - accuracy: 0.9868 - val_loss: 0.0455 - val_accuracy: 0.9843\n",
      "Epoch 85/150\n",
      "254090/254090 [==============================] - 32s 125us/step - loss: 0.0332 - accuracy: 0.9869 - val_loss: 0.0460 - val_accuracy: 0.9843\n",
      "Epoch 86/150\n",
      "254090/254090 [==============================] - 32s 126us/step - loss: 0.0331 - accuracy: 0.9869 - val_loss: 0.0461 - val_accuracy: 0.9842\n",
      "Epoch 87/150\n",
      "254090/254090 [==============================] - 32s 126us/step - loss: 0.0330 - accuracy: 0.9869 - val_loss: 0.0453 - val_accuracy: 0.9844\n",
      "Epoch 88/150\n",
      "254090/254090 [==============================] - 32s 126us/step - loss: 0.0330 - accuracy: 0.9869 - val_loss: 0.0455 - val_accuracy: 0.9842\n",
      "Epoch 89/150\n",
      "254090/254090 [==============================] - 33s 132us/step - loss: 0.0329 - accuracy: 0.9869 - val_loss: 0.0453 - val_accuracy: 0.9844\n",
      "Epoch 90/150\n",
      "254090/254090 [==============================] - 33s 132us/step - loss: 0.0328 - accuracy: 0.9870 - val_loss: 0.0456 - val_accuracy: 0.9844\n",
      "Epoch 91/150\n",
      "254090/254090 [==============================] - 33s 129us/step - loss: 0.0327 - accuracy: 0.9870 - val_loss: 0.0447 - val_accuracy: 0.9845\n",
      "Epoch 92/150\n",
      "254090/254090 [==============================] - 31s 121us/step - loss: 0.0327 - accuracy: 0.9870 - val_loss: 0.0444 - val_accuracy: 0.9846\n",
      "Epoch 93/150\n",
      "254090/254090 [==============================] - 29s 114us/step - loss: 0.0326 - accuracy: 0.9871 - val_loss: 0.0453 - val_accuracy: 0.9844\n",
      "Epoch 94/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0325 - accuracy: 0.9871 - val_loss: 0.0448 - val_accuracy: 0.9846\n",
      "Epoch 95/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0325 - accuracy: 0.9871 - val_loss: 0.0453 - val_accuracy: 0.9845\n",
      "Epoch 96/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0324 - accuracy: 0.9871 - val_loss: 0.0448 - val_accuracy: 0.9846\n",
      "Epoch 97/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0323 - accuracy: 0.9871 - val_loss: 0.0452 - val_accuracy: 0.9844\n",
      "Epoch 98/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0323 - accuracy: 0.9871 - val_loss: 0.0450 - val_accuracy: 0.9845\n",
      "Epoch 99/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0322 - accuracy: 0.9872 - val_loss: 0.0450 - val_accuracy: 0.9846\n",
      "Epoch 100/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0321 - accuracy: 0.9872 - val_loss: 0.0448 - val_accuracy: 0.9846\n",
      "Epoch 101/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0321 - accuracy: 0.9872 - val_loss: 0.0449 - val_accuracy: 0.9846\n",
      "Epoch 102/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0320 - accuracy: 0.9872 - val_loss: 0.0441 - val_accuracy: 0.9848\n",
      "Epoch 103/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0320 - accuracy: 0.9872 - val_loss: 0.0443 - val_accuracy: 0.9848\n",
      "Epoch 104/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0319 - accuracy: 0.9873 - val_loss: 0.0449 - val_accuracy: 0.9847\n",
      "Epoch 105/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0318 - accuracy: 0.9873 - val_loss: 0.0442 - val_accuracy: 0.9847\n",
      "Epoch 106/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0318 - accuracy: 0.9873 - val_loss: 0.0445 - val_accuracy: 0.9847\n",
      "Epoch 107/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0317 - accuracy: 0.9873 - val_loss: 0.0438 - val_accuracy: 0.9849\n",
      "Epoch 108/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0317 - accuracy: 0.9873 - val_loss: 0.0440 - val_accuracy: 0.9849\n",
      "Epoch 109/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0316 - accuracy: 0.9873 - val_loss: 0.0441 - val_accuracy: 0.9849\n",
      "Epoch 110/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0316 - accuracy: 0.9874 - val_loss: 0.0439 - val_accuracy: 0.9848\n",
      "Epoch 111/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0315 - accuracy: 0.9874 - val_loss: 0.0443 - val_accuracy: 0.9849\n",
      "Epoch 112/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0315 - accuracy: 0.9874 - val_loss: 0.0440 - val_accuracy: 0.9849\n",
      "Epoch 113/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0314 - accuracy: 0.9874 - val_loss: 0.0446 - val_accuracy: 0.9848\n",
      "Epoch 114/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0313 - accuracy: 0.9874 - val_loss: 0.0442 - val_accuracy: 0.9849\n",
      "Epoch 115/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0313 - accuracy: 0.9874 - val_loss: 0.0438 - val_accuracy: 0.9849\n",
      "Epoch 116/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0312 - accuracy: 0.9875 - val_loss: 0.0437 - val_accuracy: 0.9850\n",
      "Epoch 117/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0312 - accuracy: 0.9875 - val_loss: 0.0438 - val_accuracy: 0.9850\n",
      "Epoch 118/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0311 - accuracy: 0.9875 - val_loss: 0.0433 - val_accuracy: 0.9850\n",
      "Epoch 119/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0311 - accuracy: 0.9875 - val_loss: 0.0439 - val_accuracy: 0.9850\n",
      "Epoch 120/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.0441 - val_accuracy: 0.9849\n",
      "Epoch 121/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.0431 - val_accuracy: 0.9851\n",
      "Epoch 122/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0309 - accuracy: 0.9876 - val_loss: 0.0439 - val_accuracy: 0.9849\n",
      "Epoch 123/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0309 - accuracy: 0.9876 - val_loss: 0.0433 - val_accuracy: 0.9851\n",
      "Epoch 124/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.0441 - val_accuracy: 0.9850\n",
      "Epoch 125/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.0436 - val_accuracy: 0.9851\n",
      "Epoch 126/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0307 - accuracy: 0.9876 - val_loss: 0.0439 - val_accuracy: 0.9850\n",
      "Epoch 127/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0307 - accuracy: 0.9876 - val_loss: 0.0435 - val_accuracy: 0.9850\n",
      "Epoch 128/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0306 - accuracy: 0.9876 - val_loss: 0.0433 - val_accuracy: 0.9852\n",
      "Epoch 129/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0306 - accuracy: 0.9876 - val_loss: 0.0433 - val_accuracy: 0.9851\n",
      "Epoch 130/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0434 - val_accuracy: 0.9851\n",
      "Epoch 131/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0435 - val_accuracy: 0.9851\n",
      "Epoch 132/150\n",
      "254090/254090 [==============================] - 30s 116us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0428 - val_accuracy: 0.9852\n",
      "Epoch 133/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0304 - accuracy: 0.9877 - val_loss: 0.0431 - val_accuracy: 0.9852\n",
      "Epoch 134/150\n",
      "254090/254090 [==============================] - 29s 114us/step - loss: 0.0304 - accuracy: 0.9877 - val_loss: 0.0428 - val_accuracy: 0.9853\n",
      "Epoch 135/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0303 - accuracy: 0.9877 - val_loss: 0.0427 - val_accuracy: 0.9853\n",
      "Epoch 136/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0303 - accuracy: 0.9878 - val_loss: 0.0426 - val_accuracy: 0.9853\n",
      "Epoch 137/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0302 - accuracy: 0.9878 - val_loss: 0.0427 - val_accuracy: 0.9853\n",
      "Epoch 138/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0302 - accuracy: 0.9878 - val_loss: 0.0427 - val_accuracy: 0.9854\n",
      "Epoch 139/150\n",
      "254090/254090 [==============================] - 30s 118us/step - loss: 0.0302 - accuracy: 0.9878 - val_loss: 0.0422 - val_accuracy: 0.9854\n",
      "Epoch 140/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.0426 - val_accuracy: 0.9853\n",
      "Epoch 141/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.0421 - val_accuracy: 0.9855\n",
      "Epoch 142/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0300 - accuracy: 0.9878 - val_loss: 0.0423 - val_accuracy: 0.9854\n",
      "Epoch 143/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0300 - accuracy: 0.9879 - val_loss: 0.0425 - val_accuracy: 0.9855\n",
      "Epoch 144/150\n",
      "254090/254090 [==============================] - 30s 117us/step - loss: 0.0299 - accuracy: 0.9879 - val_loss: 0.0428 - val_accuracy: 0.9853\n",
      "Epoch 145/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0299 - accuracy: 0.9879 - val_loss: 0.0424 - val_accuracy: 0.9854\n",
      "Epoch 146/150\n",
      "254090/254090 [==============================] - 29s 114us/step - loss: 0.0299 - accuracy: 0.9879 - val_loss: 0.0430 - val_accuracy: 0.9853\n",
      "Epoch 147/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0298 - accuracy: 0.9879 - val_loss: 0.0426 - val_accuracy: 0.9854\n",
      "Epoch 148/150\n",
      "254090/254090 [==============================] - 29s 115us/step - loss: 0.0298 - accuracy: 0.9879 - val_loss: 0.0426 - val_accuracy: 0.9854\n",
      "Epoch 149/150\n",
      "254090/254090 [==============================] - 29s 116us/step - loss: 0.0298 - accuracy: 0.9879 - val_loss: 0.0428 - val_accuracy: 0.9854\n",
      "Epoch 150/150\n",
      "254090/254090 [==============================] - 29s 114us/step - loss: 0.0297 - accuracy: 0.9879 - val_loss: 0.0427 - val_accuracy: 0.9853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:136: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[200, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[194, 3]\n",
      "[3, 0]\n",
      "[195, 2]\n",
      "[1, 2]\n",
      "[192, 2]\n",
      "[6, 0]\n",
      "[187, 7]\n",
      "[1, 5]\n",
      "[197, 1]\n",
      "[2, 0]\n",
      "[195, 3]\n",
      "[0, 2]\n",
      "[197, 2]\n",
      "[1, 0]\n",
      "[187, 12]\n",
      "[1, 0]\n",
      "[196, 2]\n",
      "[1, 1]\n",
      "[185, 13]\n",
      "[2, 0]\n",
      "[194, 3]\n",
      "[1, 2]\n",
      "[189, 8]\n",
      "[3, 0]\n",
      "[179, 12]\n",
      "[2, 7]\n",
      "[184, 7]\n",
      "[4, 5]\n",
      "[185, 11]\n",
      "[4, 0]\n",
      "[193, 3]\n",
      "[0, 4]\n",
      "[195, 2]\n",
      "[2, 1]\n",
      "[194, 3]\n",
      "[1, 2]\n",
      "[195, 3]\n",
      "[2, 0]\n",
      "[192, 6]\n",
      "[0, 2]\n",
      "[199, 1]\n",
      "[0, 0]\n",
      "[196, 4]\n",
      "[0, 0]\n",
      "[196, 2]\n",
      "[1, 1]\n",
      "[192, 6]\n",
      "[1, 1]\n",
      "[194, 5]\n",
      "[0, 1]\n",
      "[193, 6]\n",
      "[0, 1]\n",
      "[186, 4]\n",
      "[3, 7]\n",
      "[186, 4]\n",
      "[2, 8]\n",
      "[196, 1]\n",
      "[1, 2]\n",
      "[195, 2]\n",
      "[1, 2]\n",
      "[194, 4]\n",
      "[0, 2]\n",
      "[194, 4]\n",
      "[2, 0]\n",
      "[200, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[195, 5]\n",
      "[0, 0]\n",
      "[200, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[190, 10]\n",
      "[0, 0]\n",
      "[198, 0]\n",
      "[1, 1]\n",
      "[194, 4]\n",
      "[1, 1]\n",
      "[193, 5]\n",
      "[1, 1]\n",
      "[190, 8]\n",
      "[1, 1]\n",
      "[185, 12]\n",
      "[1, 2]\n",
      "[191, 6]\n",
      "[0, 3]\n",
      "[186, 12]\n",
      "[2, 0]\n",
      "[194, 4]\n",
      "[1, 1]\n",
      "[193, 6]\n",
      "[0, 1]\n",
      "[193, 6]\n",
      "[1, 0]\n",
      "[196, 2]\n",
      "[2, 0]\n",
      "[194, 4]\n",
      "[2, 0]\n",
      "[197, 0]\n",
      "[0, 3]\n",
      "both b and c are zero\n",
      "[190, 7]\n",
      "[2, 1]\n",
      "[197, 0]\n",
      "[1, 2]\n",
      "[191, 6]\n",
      "[1, 2]\n",
      "[192, 5]\n",
      "[1, 2]\n",
      "[186, 11]\n",
      "[1, 2]\n",
      "[193, 6]\n",
      "[0, 1]\n",
      "[192, 7]\n",
      "[0, 1]\n",
      "[194, 4]\n",
      "[0, 2]\n",
      "[195, 3]\n",
      "[0, 2]\n",
      "[191, 6]\n",
      "[1, 2]\n",
      "[191, 6]\n",
      "[1, 2]\n",
      "[196, 2]\n",
      "[2, 0]\n",
      "[192, 6]\n",
      "[2, 0]\n",
      "[199, 0]\n",
      "[0, 1]\n",
      "both b and c are zero\n",
      "[195, 4]\n",
      "[0, 1]\n",
      "[194, 3]\n",
      "[1, 2]\n",
      "[192, 5]\n",
      "[1, 2]\n",
      "[194, 3]\n",
      "[2, 1]\n",
      "[190, 7]\n",
      "[1, 2]\n",
      "[178, 12]\n",
      "[5, 5]\n",
      "[187, 3]\n",
      "[1, 9]\n",
      "[188, 7]\n",
      "[3, 2]\n",
      "[190, 5]\n",
      "[3, 2]\n",
      "[196, 4]\n",
      "[0, 0]\n",
      "[193, 7]\n",
      "[0, 0]\n",
      "[198, 1]\n",
      "[0, 1]\n",
      "[193, 6]\n",
      "[0, 1]\n",
      "[200, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[194, 6]\n",
      "[0, 0]\n",
      "[196, 2]\n",
      "[1, 1]\n",
      "[193, 5]\n",
      "[0, 2]\n",
      "[193, 5]\n",
      "[1, 1]\n",
      "[190, 8]\n",
      "[0, 2]\n",
      "[188, 3]\n",
      "[3, 6]\n",
      "[187, 4]\n",
      "[3, 6]\n",
      "[191, 5]\n",
      "[2, 2]\n",
      "[191, 5]\n",
      "[0, 4]\n",
      "[197, 3]\n",
      "[0, 0]\n",
      "[193, 7]\n",
      "[0, 0]\n",
      "[197, 2]\n",
      "[1, 0]\n",
      "[192, 7]\n",
      "[0, 1]\n",
      "[200, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[197, 3]\n",
      "[0, 0]\n",
      "[200, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[193, 7]\n",
      "[0, 0]\n",
      "[199, 0]\n",
      "[1, 0]\n",
      "[194, 5]\n",
      "[1, 0]\n",
      "[199, 1]\n",
      "[0, 0]\n",
      "[198, 2]\n",
      "[0, 0]\n",
      "[181, 11]\n",
      "[1, 7]\n",
      "[192, 0]\n",
      "[3, 5]\n",
      "[185, 3]\n",
      "[0, 12]\n",
      "[184, 4]\n",
      "[0, 12]\n",
      "[179, 15]\n",
      "[4, 2]\n",
      "[192, 2]\n",
      "[1, 5]\n",
      "[185, 10]\n",
      "[2, 3]\n",
      "[185, 10]\n",
      "[2, 3]\n",
      "[173, 19]\n",
      "[4, 4]\n",
      "[185, 7]\n",
      "[3, 5]\n",
      "[184, 9]\n",
      "[3, 4]\n",
      "[184, 9]\n",
      "[2, 5]\n",
      "[191, 1]\n",
      "[5, 3]\n",
      "[184, 8]\n",
      "[3, 5]\n",
      "[196, 2]\n",
      "[1, 1]\n",
      "[193, 5]\n",
      "[1, 1]\n",
      "[192, 5]\n",
      "[0, 3]\n",
      "[193, 4]\n",
      "[3, 0]\n",
      "[194, 3]\n",
      "[2, 1]\n",
      "[187, 10]\n",
      "[1, 2]\n",
      "[192, 5]\n",
      "[1, 2]\n",
      "[194, 3]\n",
      "[1, 2]\n",
      "[193, 5]\n",
      "[2, 0]\n",
      "[193, 5]\n",
      "[1, 1]\n",
      "[192, 6]\n",
      "[1, 1]\n",
      "[193, 5]\n",
      "[0, 2]\n",
      "[197, 0]\n",
      "[1, 2]\n",
      "[191, 6]\n",
      "[0, 3]\n",
      "[198, 0]\n",
      "[0, 2]\n",
      "both b and c are zero\n",
      "[191, 7]\n",
      "[0, 2]\n",
      "[193, 4]\n",
      "[1, 2]\n",
      "[192, 5]\n",
      "[1, 2]\n",
      "[198, 2]\n",
      "[0, 0]\n",
      "[196, 4]\n",
      "[0, 0]\n",
      "[196, 4]\n",
      "[0, 0]\n",
      "[192, 8]\n",
      "[0, 0]\n",
      "[198, 1]\n",
      "[1, 0]\n",
      "[195, 4]\n",
      "[1, 0]\n",
      "[198, 0]\n",
      "[2, 0]\n",
      "[191, 7]\n",
      "[0, 2]\n",
      "[196, 4]\n",
      "[0, 0]\n",
      "[193, 7]\n",
      "[0, 0]\n",
      "[198, 1]\n",
      "[0, 1]\n",
      "[193, 6]\n",
      "[0, 1]\n",
      "[198, 1]\n",
      "[1, 0]\n",
      "[193, 6]\n",
      "[0, 1]\n",
      "[197, 2]\n",
      "[1, 0]\n",
      "[194, 5]\n",
      "[0, 1]\n",
      "[197, 2]\n",
      "[0, 1]\n",
      "[191, 8]\n",
      "[0, 1]\n",
      "[197, 0]\n",
      "[2, 1]\n",
      "[186, 11]\n",
      "[1, 2]\n",
      "[198, 1]\n",
      "[0, 1]\n",
      "[194, 5]\n",
      "[0, 1]\n",
      "[199, 0]\n",
      "[0, 1]\n",
      "both b and c are zero\n",
      "[191, 8]\n",
      "[1, 0]\n",
      "[196, 1]\n",
      "[0, 3]\n",
      "[194, 3]\n",
      "[1, 2]\n",
      "[198, 2]\n",
      "[0, 0]\n",
      "[192, 8]\n",
      "[0, 0]\n",
      "[198, 1]\n",
      "[1, 0]\n",
      "[194, 5]\n",
      "[0, 1]\n",
      "[197, 3]\n",
      "[0, 0]\n",
      "[198, 2]\n",
      "[0, 0]\n",
      "[198, 0]\n",
      "[1, 1]\n",
      "[195, 3]\n",
      "[0, 2]\n",
      "[197, 0]\n",
      "[2, 1]\n",
      "[191, 6]\n",
      "[0, 3]\n",
      "[196, 1]\n",
      "[1, 2]\n",
      "[192, 5]\n",
      "[2, 1]\n",
      "[192, 4]\n",
      "[2, 2]\n",
      "[191, 5]\n",
      "[1, 3]\n",
      "[197, 1]\n",
      "[1, 1]\n",
      "[193, 5]\n",
      "[0, 2]\n",
      "[196, 2]\n",
      "[2, 0]\n",
      "[192, 6]\n",
      "[1, 1]\n",
      "[197, 1]\n",
      "[1, 1]\n",
      "[191, 7]\n",
      "[0, 2]\n",
      "[195, 0]\n",
      "[4, 1]\n",
      "[189, 6]\n",
      "[2, 3]\n",
      "[195, 1]\n",
      "[3, 1]\n",
      "[192, 4]\n",
      "[1, 3]\n",
      "[196, 2]\n",
      "[0, 2]\n",
      "[193, 5]\n",
      "[1, 1]\n",
      "[192, 6]\n",
      "[1, 1]\n",
      "[190, 8]\n",
      "[0, 2]\n",
      "[180, 15]\n",
      "[3, 2]\n",
      "[192, 3]\n",
      "[1, 4]\n",
      "[191, 2]\n",
      "[0, 7]\n",
      "[189, 4]\n",
      "[0, 7]\n",
      "[193, 6]\n",
      "[1, 0]\n",
      "[198, 1]\n",
      "[0, 1]\n",
      "[194, 5]\n",
      "[0, 1]\n",
      "[195, 4]\n",
      "[0, 1]\n",
      "[184, 15]\n",
      "[1, 0]\n",
      "[194, 5]\n",
      "[0, 1]\n",
      "[190, 5]\n",
      "[0, 5]\n",
      "[192, 3]\n",
      "[2, 3]\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds of MWPM:\n",
      "> Accuracy: 0.9747979797979793 (+- 0.0013228081670413356)\n",
      "> F1: 0.7077032606235628(+- 0.016787260621390097)\n",
      "> Time: 40.77175403333336 (+- 0.8878513588731103)\n",
      "Average scores for all folds of PLUT:\n",
      "> Accuracy: 0.9623732652983833 (+- 0.0003574584534018108)\n",
      "> F1: 0.22185269732232457(+- 0.008295400708186318)\n",
      "> Time: 5.6218388 (+- 0.840558535009601)\n",
      "Average scores for all folds of NN:\n",
      "> Accuracy: 0.9865701089322766 (+- 0.00015165898607678345)\n",
      "> F1: 0.8231992807928211(+- 0.0017457313201526467)\n",
      "> Time: 4.4053097 (+- 0.024520245590939762)\n",
      "> AUC for class : 0.9994657394343331 (+- 0.0)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 0\n",
      "> AUC for class X00: 0.8774409453266084 (+- 0.0027760367651362004)\n",
      "X^2 for MWPM and NN: 0.16666666666666666\n",
      "X^2 for PLUT and NN: 0.0\n",
      "> AUC for class X01: 0.9859277732495751 (+- 0.0007918833851738588)\n",
      "X^2 for MWPM and NN: 3.125\n",
      "X^2 for PLUT and NN: 3.125\n",
      "> AUC for class X02: 0.9983842319440995 (+- 0.00012124301638930536)\n",
      "X^2 for MWPM and NN: 1.3333333333333333\n",
      "X^2 for PLUT and NN: 1.3333333333333333\n",
      "> AUC for class X03: 0.9986612339879608 (+- 0.00014234330199056958)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 7.6923076923076925\n",
      "> AUC for class X04: 0.9986844679351711 (+- 6.53235331699108e-05)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 6.666666666666667\n",
      "> AUC for class X05: 0.9982844359656031 (+- 7.248032257265058e-05)\n",
      "X^2 for MWPM and NN: 0.25\n",
      "X^2 for PLUT and NN: 1.4545454545454546\n",
      "> AUC for class X06: 0.9813348658429577 (+- 0.0005027571270402814)\n",
      "X^2 for MWPM and NN: 5.785714285714286\n",
      "X^2 for PLUT and NN: 0.36363636363636365\n",
      "> AUC for class X10: 0.9801404621275154 (+- 0.0005732499649348818)\n",
      "X^2 for MWPM and NN: 2.4\n",
      "X^2 for PLUT and NN: 1.3333333333333333\n",
      "> AUC for class X11: 0.9957253065502876 (+- 9.263320655411614e-05)\n",
      "X^2 for MWPM and NN: 0.25\n",
      "X^2 for PLUT and NN: 0.25\n",
      "> AUC for class X12: 0.9972357530784746 (+- 0.00019282302017491692)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 4.166666666666667\n",
      "> AUC for class X13: 0.9978031720443288 (+- 2.2775236436124688e-05)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 2.25\n",
      "> AUC for class X14: 0.9977064706253493 (+- 0.00031599680229315295)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 2.2857142857142856\n",
      "> AUC for class X15: 0.996863058086341 (+- 7.769879556989325e-05)\n",
      "X^2 for MWPM and NN: 3.2\n",
      "X^2 for PLUT and NN: 4.166666666666667\n",
      "> AUC for class X16: 0.9805009690664525 (+- 0.00017342321055963393)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 0.16666666666666666\n",
      "> AUC for class X20: 0.9799649307896784 (+- 0.00031696733277229705)\n",
      "X^2 for MWPM and NN: 0.5\n",
      "X^2 for PLUT and NN: 0.0\n",
      "> AUC for class X21: 0.9966984739141354 (+- 0.0004946445258307719)\n",
      "X^2 for MWPM and NN: 2.25\n",
      "X^2 for PLUT and NN: 0.16666666666666666\n",
      "> AUC for class X22: 0.9975217515070968 (+- 9.974341911829855e-05)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 3.2\n",
      "> AUC for class X23: 0.9977808744396867 (+- 0.0001084238666875347)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 8.1\n",
      "> AUC for class X24: 0.9977341046393596 (+- 7.775260087441897e-05)\n",
      "X^2 for MWPM and NN: 4.0\n",
      "X^2 for PLUT and NN: 0.8\n",
      "> AUC for class X25: 0.996946922658079 (+- 8.734322058076628e-05)\n",
      "X^2 for MWPM and NN: 1.5\n",
      "X^2 for PLUT and NN: 4.0\n",
      "> AUC for class X26: 0.9806907846146936 (+- 0.00027268540610627095)\n",
      "X^2 for MWPM and NN: 7.6923076923076925\n",
      "X^2 for PLUT and NN: 4.166666666666667\n",
      "> AUC for class X30: 0.9812734592363285 (+- 0.0012667384471547153)\n",
      "X^2 for MWPM and NN: 5.785714285714286\n",
      "X^2 for PLUT and NN: 0.8\n",
      "> AUC for class X31: 0.9970490998849567 (+- 0.0001425720433420006)\n",
      "X^2 for MWPM and NN: 4.166666666666667\n",
      "X^2 for PLUT and NN: 2.2857142857142856\n",
      "> AUC for class X32: 0.9975790755448211 (+- 0.00011791515814585755)\n",
      "X^2 for MWPM and NN: 0.25\n",
      "X^2 for PLUT and NN: 0.16666666666666666\n",
      "> AUC for class X33: 0.9979125259696121 (+- 0.00017441122742111966)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 1.7777777777777777\n",
      "> AUC for class X34: 0.9976845320223884 (+- 5.707346475106092e-05)\n",
      "X^2 for MWPM and NN: 4.0\n",
      "X^2 for PLUT and NN: 2.2857142857142856\n",
      "> AUC for class X35: 0.9970470329927301 (+- 0.0001755504527783598)\n",
      "X^2 for MWPM and NN: 1.5\n",
      "X^2 for PLUT and NN: 6.75\n",
      "> AUC for class X36: 0.9802520604524733 (+- 0.0009243962809110029)\n",
      "X^2 for MWPM and NN: 4.166666666666667\n",
      "X^2 for PLUT and NN: 5.142857142857143\n",
      "> AUC for class X40: 0.9810303322048105 (+- 0.0007445016825329274)\n",
      "X^2 for MWPM and NN: 2.25\n",
      "X^2 for PLUT and NN: 1.3333333333333333\n",
      "> AUC for class X41: 0.9970169669271455 (+- 0.00028898437805877715)\n",
      "X^2 for MWPM and NN: 2.2857142857142856\n",
      "X^2 for PLUT and NN: 2.2857142857142856\n",
      "> AUC for class X42: 0.99758009824061 (+- 8.966095268975391e-05)\n",
      "X^2 for MWPM and NN: 0.25\n",
      "X^2 for PLUT and NN: 1.125\n",
      "> AUC for class X43: 0.9978542646695076 (+- 9.78628886020979e-05)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 2.25\n",
      "> AUC for class X44: 0.9977296902654977 (+- 0.00013515497564209268)\n",
      "X^2 for MWPM and NN: 0.25\n",
      "X^2 for PLUT and NN: 1.5\n",
      "> AUC for class X45: 0.9968332009764641 (+- 0.0002069028748980521)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 3.125\n",
      "> AUC for class X46: 0.9807911081176037 (+- 0.0001821908382801511)\n",
      "X^2 for MWPM and NN: 2.1176470588235294\n",
      "X^2 for PLUT and NN: 0.25\n",
      "> AUC for class X50: 0.9804414937313247 (+- 9.227859910866703e-05)\n",
      "X^2 for MWPM and NN: 0.9\n",
      "X^2 for PLUT and NN: 0.125\n",
      "> AUC for class X51: 0.9969619036546012 (+- 0.00014540811380847908)\n",
      "X^2 for MWPM and NN: 2.25\n",
      "X^2 for PLUT and NN: 5.142857142857143\n",
      "> AUC for class X52: 0.9978840538153283 (+- 5.27620395982792e-05)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 4.166666666666667\n",
      "> AUC for class X53: 0.9978218168697032 (+- 0.00011214496128063619)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 4.166666666666667\n",
      "> AUC for class X54: 0.9979365240239231 (+- 3.42200073509433e-05)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 3.2\n",
      "> AUC for class X55: 0.9974276625696445 (+- 7.709852513765737e-05)\n",
      "X^2 for MWPM and NN: 1.5\n",
      "X^2 for PLUT and NN: 6.125\n",
      "> AUC for class X56: 0.9808394336008126 (+- 0.0004525026534136668)\n",
      "X^2 for MWPM and NN: 0.16666666666666666\n",
      "X^2 for PLUT and NN: 0.0\n",
      "> AUC for class X60: 0.9809227940741617 (+- 0.00027891476153380266)\n",
      "X^2 for MWPM and NN: 0.5714285714285714\n",
      "X^2 for PLUT and NN: 3.2\n",
      "> AUC for class X61: 0.9982903263860244 (+- 9.653531106665371e-05)\n",
      "X^2 for MWPM and NN: 1.3333333333333333\n",
      "X^2 for PLUT and NN: 5.142857142857143\n",
      "> AUC for class X62: 0.9987329356040512 (+- 7.898482230799412e-05)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 5.142857142857143\n",
      "> AUC for class X63: 0.9986803760153807 (+- 0.00012439940604578754)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 1.3333333333333333\n",
      "> AUC for class X64: 0.9987007620329539 (+- 6.479751033128755e-05)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 5.142857142857143\n",
      "> AUC for class X65: 0.9977278565668394 (+- 1.3983663542279265e-05)\n",
      "X^2 for MWPM and NN: 4.0\n",
      "X^2 for PLUT and NN: 1.5\n",
      "> AUC for class X66: 0.9933703412630065 (+- 0.00021659895441742544)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 0.5\n",
      "> AUC for class Z00: 0.9743116807005077 (+- 0.001123069557427328)\n",
      "X^2 for MWPM and NN: 6.75\n",
      "X^2 for PLUT and NN: 5.333333333333333\n",
      "> AUC for class Z01: 0.9740676279528392 (+- 0.0006856079694126877)\n",
      "X^2 for MWPM and NN: 1.3333333333333333\n",
      "X^2 for PLUT and NN: 2.25\n",
      "> AUC for class Z02: 0.9768000236174653 (+- 0.0007559092477391061)\n",
      "X^2 for MWPM and NN: 5.2631578947368425\n",
      "X^2 for PLUT and NN: 0.0\n",
      "> AUC for class Z03: 0.9773351657221726 (+- 0.0003046718174691877)\n",
      "X^2 for MWPM and NN: 4.083333333333333\n",
      "X^2 for PLUT and NN: 4.083333333333333\n",
      "> AUC for class Z04: 0.9779529759886411 (+- 0.0006306398526002122)\n",
      "X^2 for MWPM and NN: 8.521739130434783\n",
      "X^2 for PLUT and NN: 0.9\n",
      "> AUC for class Z05: 0.9785902779620477 (+- 0.0005674105558863318)\n",
      "X^2 for MWPM and NN: 2.0833333333333335\n",
      "X^2 for PLUT and NN: 3.272727272727273\n",
      "> AUC for class Z06: 0.9922127054761779 (+- 0.00023332372474182907)\n",
      "X^2 for MWPM and NN: 4.166666666666667\n",
      "X^2 for PLUT and NN: 1.4545454545454546\n",
      "> AUC for class Z10: 0.9978703816929837 (+- 0.0001782152391498477)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 1.5\n",
      "> AUC for class Z11: 0.9948641264347119 (+- 0.00037313683000564374)\n",
      "X^2 for MWPM and NN: 3.2\n",
      "X^2 for PLUT and NN: 0.0\n",
      "> AUC for class Z12: 0.9957959103892303 (+- 0.00021235497597483873)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 5.818181818181818\n",
      "> AUC for class Z13: 0.9961696515424503 (+- 0.00018066043891290837)\n",
      "X^2 for MWPM and NN: 1.5\n",
      "X^2 for PLUT and NN: 0.25\n",
      "> AUC for class Z14: 0.9960161388724251 (+- 0.00015259383635632368)\n",
      "X^2 for MWPM and NN: 0.5714285714285714\n",
      "X^2 for PLUT and NN: 1.5\n",
      "> AUC for class Z15: 0.9963204640462223 (+- 0.00016339630769624994)\n",
      "X^2 for MWPM and NN: 2.2857142857142856\n",
      "X^2 for PLUT and NN: 3.2\n",
      "> AUC for class Z16: 0.997061272632381 (+- 0.00029828797596274524)\n",
      "X^2 for MWPM and NN: 4.0\n",
      "X^2 for PLUT and NN: 4.166666666666667\n",
      "> AUC for class Z20: 0.9981926530539925 (+- 0.00027835497703306017)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 5.142857142857143\n",
      "> AUC for class Z21: 0.9966340945941589 (+- 0.00015515550213465048)\n",
      "X^2 for MWPM and NN: 0.8\n",
      "X^2 for PLUT and NN: 1.5\n",
      "> AUC for class Z22: 0.996257366114237 (+- 0.000289587596851719)\n",
      "X^2 for MWPM and NN: 0.5\n",
      "X^2 for PLUT and NN: 2.25\n",
      "> AUC for class Z23: 0.9966429937315691 (+- 0.0003223930560645845)\n",
      "X^2 for MWPM and NN: 2.25\n",
      "X^2 for PLUT and NN: 6.125\n",
      "> AUC for class Z24: 0.9963445401997468 (+- 0.00030110790600446557)\n",
      "X^2 for MWPM and NN: 0.5\n",
      "X^2 for PLUT and NN: 0.8\n",
      "> AUC for class Z25: 0.996824733755974 (+- 7.906444499182232e-05)\n",
      "X^2 for MWPM and NN: 4.5\n",
      "X^2 for PLUT and NN: 5.142857142857143\n",
      "> AUC for class Z26: 0.9983864503040031 (+- 1.8134589084737604e-05)\n",
      "X^2 for MWPM and NN: 2.25\n",
      "X^2 for PLUT and NN: 5.142857142857143\n",
      "> AUC for class Z30: 0.998315488118816 (+- 9.9782560920235e-05)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 4.166666666666667\n",
      "> AUC for class Z31: 0.9969140168776099 (+- 0.0004490148772799515)\n",
      "X^2 for MWPM and NN: 0.5\n",
      "X^2 for PLUT and NN: 4.166666666666667\n",
      "> AUC for class Z32: 0.9965033292717921 (+- 0.00040489941641239915)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 3.2\n",
      "> AUC for class Z33: 0.9967217115403599 (+- 1.6415605648119223e-05)\n",
      "X^2 for MWPM and NN: 0.5\n",
      "X^2 for PLUT and NN: 6.125\n",
      "> AUC for class Z34: 0.9964700163323615 (+- 0.00038683704514315577)\n",
      "X^2 for MWPM and NN: 4.5\n",
      "X^2 for PLUT and NN: 6.75\n",
      "> AUC for class Z35: 0.997153525397334 (+- 0.00031388308636972945)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 3.2\n",
      "> AUC for class Z36: 0.9983654256252988 (+- 0.00010403761951939716)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 4.0\n",
      "> AUC for class Z40: 0.9981932992554698 (+- 4.95740940546089e-05)\n",
      "X^2 for MWPM and NN: 0.0\n",
      "X^2 for PLUT and NN: 0.25\n",
      "> AUC for class Z41: 0.9968428949626283 (+- 0.00021817904396718218)\n",
      "X^2 for MWPM and NN: 0.5\n",
      "X^2 for PLUT and NN: 6.125\n",
      "> AUC for class Z42: 0.9965738122537253 (+- 8.259812261671357e-05)\n",
      "X^2 for MWPM and NN: 0.5\n",
      "X^2 for PLUT and NN: 3.2\n",
      "> AUC for class Z43: 0.9968127246425648 (+- 0.00025052550130755225)\n",
      "X^2 for MWPM and NN: 1.3333333333333333\n",
      "X^2 for PLUT and NN: 0.5\n",
      "> AUC for class Z44: 0.9965964221279561 (+- 0.00032152060912409464)\n",
      "X^2 for MWPM and NN: 4.0\n",
      "X^2 for PLUT and NN: 1.3333333333333333\n",
      "> AUC for class Z45: 0.9968104602782818 (+- 0.000250637424170755)\n",
      "X^2 for MWPM and NN: 4.5\n",
      "X^2 for PLUT and NN: 4.166666666666667\n",
      "> AUC for class Z46: 0.9983276956764553 (+- 8.27211192514004e-05)\n",
      "X^2 for MWPM and NN: 0.5\n",
      "X^2 for PLUT and NN: 0.5714285714285714\n",
      "> AUC for class Z50: 0.996944100761595 (+- 0.0004645749493526014)\n",
      "X^2 for MWPM and NN: 0.16666666666666666\n",
      "X^2 for PLUT and NN: 1.5\n",
      "> AUC for class Z51: 0.9963344255739205 (+- 0.00015978175791416186)\n",
      "X^2 for MWPM and NN: 0.5\n",
      "X^2 for PLUT and NN: 3.2\n",
      "> AUC for class Z52: 0.9957225664293615 (+- 0.00017824621483942646)\n",
      "X^2 for MWPM and NN: 0.25\n",
      "X^2 for PLUT and NN: 2.2857142857142856\n",
      "> AUC for class Z53: 0.9958127754544871 (+- 0.00017299615846021941)\n",
      "X^2 for MWPM and NN: 0.5\n",
      "X^2 for PLUT and NN: 5.142857142857143\n",
      "> AUC for class Z54: 0.9956693815040533 (+- 0.0001192597393527484)\n",
      "X^2 for MWPM and NN: 6.25\n",
      "X^2 for PLUT and NN: 1.125\n",
      "> AUC for class Z55: 0.9959290620679934 (+- 0.00011335347820165764)\n",
      "X^2 for MWPM and NN: 2.25\n",
      "X^2 for PLUT and NN: 0.8\n",
      "> AUC for class Z56: 0.997990115682792 (+- 7.807251753803366e-05)\n",
      "X^2 for MWPM and NN: 0.5\n",
      "X^2 for PLUT and NN: 1.5\n",
      "> AUC for class Z60: 0.992417151289069 (+- 0.00029150275345067204)\n",
      "X^2 for MWPM and NN: 2.2857142857142856\n",
      "X^2 for PLUT and NN: 6.125\n",
      "> AUC for class Z61: 0.9781450095897442 (+- 0.00022210427944083659)\n",
      "X^2 for MWPM and NN: 6.722222222222222\n",
      "X^2 for PLUT and NN: 0.25\n",
      "> AUC for class Z62: 0.9775582577945524 (+- 0.0009942557027849824)\n",
      "X^2 for MWPM and NN: 0.5\n",
      "X^2 for PLUT and NN: 2.25\n",
      "> AUC for class Z63: 0.9771818613208918 (+- 0.0003044244826790068)\n",
      "X^2 for MWPM and NN: 2.2857142857142856\n",
      "X^2 for PLUT and NN: 0.0\n",
      "> AUC for class Z64: 0.9771890379303083 (+- 0.0010763096511018568)\n",
      "X^2 for MWPM and NN: 3.2\n",
      "X^2 for PLUT and NN: 2.25\n",
      "> AUC for class Z65: 0.9765206330647468 (+- 0.0007950438863501371)\n",
      "X^2 for MWPM and NN: 10.5625\n",
      "X^2 for PLUT and NN: 3.2\n",
      "> AUC for class Z66: 0.9779923991401726 (+- 0.00043125725969757887)\n",
      "X^2 for MWPM and NN: 3.2\n",
      "X^2 for PLUT and NN: 0.0\n",
      "###################################################################################\n",
      "TOTAL F1 NN: [0.8256612120897465, 0.822128119650419, 0.8218085106382979]\n",
      "TOTAL F1 PLUT: [0.2156269331782469, 0.21635451645296036, 0.23357664233576644]\n",
      "TOTAL F1 MWPM: [0.6883500887049083, 0.7292882147024505, 0.7054714784633295]\n",
      "TOTAL ACC NN: [0.9867845773696899, 0.9864611029624939, 0.986464646464646]\n",
      "TOTAL ACC PLUT: [0.9621204071107815, 0.9621206009055814, 0.962878787878787]\n",
      "TOTAL ACC MWPM: [0.9733838383838378, 0.9765656565656561, 0.9744444444444439]\n",
      "TOTAL TIME NN: [4.4039281, 4.4360077, 4.3759933]\n",
      "TOTAL TIME PLUT: [5.0338307, 5.0211402, 6.8105455]\n",
      "TOTAL TIME MWPM: [39.7456981, 40.65802290000005, 41.91154110000003]\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAEiCAYAAAAyFTwvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAB2v0lEQVR4nO3dd3xUVdrA8d8zqZRQQq8JLYQkgkJEsIFYFl1FBPG1d1FZLICKKJbFXdeuoKIiioIFQRGxV1wLygIqVQjFUAKhE0rqZM77x5mBYUiZSSaZlOf7+QyZe++59z5zM2SeOefcc8QYg1JKKaWUCpwj1AEopZRSSlVXmkgppZRSSpWRJlJKKaWUUmWkiZRSSimlVBlpIqWUUkopVUaaSCmllFJKlZEmUqpEItJfRIyIXOu1Lt697mE/j/GGiFTIOBsi8rA7lviKOL6yROR4EflWRPYG8ruvDtyv541Qx6GUqp5qZSIlInVF5E4R+VFE9ohIgYhsF5HPRORaEQkPdYyBEJFFIpIvIs1KKFNfRA6KyJrKjC0YRGRwVf7g9ko2vR8HReQ3ERlV0vtJRE4XkdkistX9O9zhfh8OLuWcCSIyWURWi8ghEckRkTQRmSIiJwb59YUDHwBdgAeAq4A5JZS/1udaFIjIbvf1eFlETglmfP5wJ9yDK/D4vr9/38f9fsZoRMQpIolFbPe8z+4q5txvF3Pc70XkYNlfnVKqJNUqYQgGEekMfAokAN8A/wF2Ac2Bs4BpQBJwT6hiLIPXgJeAK4FniylzCVAP+/rKayNQB3AG4Vj+GAxcAzxcxLZ/AY8BeZUUS0neBT4DBGgJXA08A3QDhvsWFpFHgXHY6/ka8Jd7v8uBD0VkBnCdMabQZ78bsL/vXPc5/8D+LhKAocBNIpJsjFkVpNfV0f0YY4x5IYD9JgGLsF/YGgIpwBDgZhF5B/va8oMUY2keAt4E5lbQ8a8qZv3DQCfg4wCOFYb9u3RRgDFcJiJPGmP+CHA/pVQ51KpESkTqAJ9gPxSGGmN8v1U/7v42X+I3ehGJMcYcqKAwy+Jd7Af2dRSfSF0HFGI/TMrF2OHwc8t7nGAwxjipvISuNL8ZY97yLIjIZGA1cKOI3G+M2em17QZsEvUNcKExJttr2xPYxOpqIB140GvbWcAUYBXwN2PMVu8ARGQccFuQX1dL9889Ae73ozHmfe8VInIn9rVdDuwHbi13dFWA9+/dQ0TaAh2AxcaYZQEcbjEwWET6GmN+8XOf5dhE+nHgbwGcSylVTrWtae9GoCvwdBFJFADGmEXGmMmeZRFJd1eNnyAiX4pIFrDMa/vpIvK1iGS5m1d+c39IHkVEkt1NOBkikicimSIyX0T+7lUm2l29v0ZEskVkn4gsF5EnS3pRxpgs4H3gOBFJLeLcXYBTgc+NMdtEpLWIPC0if4jt85IrIqtEZKyIhJV2EaWYPlLu+J90N1PliMj/ROScYo7RW2zfqTT3az0gIj+LyEU+5b7H1kb5Np9c615XZB8pd4wzxDbZ5onIehF5VETq+pTz7N/VvX2Lu/xSETmvtGtREmPMIeBXbA1VJ69zRmJr0g4CV3gnUe79nMDNwCbgLjm6yfZx9/H+zzeJ8uxrjHnWn9oof66R+/r/1704zev6x/tzDYqILwe4FtiArTk76jgi0kpEXhKRTWKbOreKba5s7lPO83tLFpFJ7v9POSKyUETO9HmNnv5513i/h4q4Hn1F5L9im0p3i8hUEalfltfpdh32b+zUAPf7J5ANPBHAPpuAycA53q9fKVXxalWNFHCx++eUAPdrD3wHzMb2FakPICIXAB8CmcDTwAHgUmCqiHQ0xtzvLtfEvT/Ay9imnKZAKnAStqkR4EXgemA6toYpHNsvZYAfMb6ObV64DvuN1tt17p+vuX92xzaxfAisByKAgdgmso7YD/GyeBfbDPcx8CU2eZiDbbLydRGQCMzCXo8m2IRpjohcYYx5x13u39gPo9M4uvlkQXFBiEgc8D9sc9JkYC3QH1sDdIqInOlOVry9CRQATwGRwJ3AXBFJMMakl/rKi+dJoLxrc07B1vK8bYzZUdROxphcEXkLuA84D3hTRDoAPbE1PeVqtgvgGv0b+NkdxxTgR/chdvoe01/GmHyxzZYPYWtPXnHH1B74BXv9X8O+Nztja63OEJFU95cGb9OxNa2PAzHY9+4XInKuMeYbd5xXATPcsRf3f/94bG31NOAd97W4AXBRRLNsaUREsP/vDmH/XwQiE1uzfL+IDDLGzPNzv39j/348LiInGp1IVanKYYypNQ9gN5AV4D7pgAFu9Fkfhk0A9gGtvdZHYj94CoEu7nWD3Me4pJRz7QE+K+NrE2Cd+xhRXusdwBZgOxDuXlcHkCKOMcMddyuvdf3dsV/rtS7eve5hr3XnuNe94XPMwe71xmd9vSLOXxdYA6zyWf+G7/5e2x52Hz/ea93b7nXn+ZR90r3+hiL2/8T7mmCbdw3wHz+uvecaPYhNkJsBx2ETYwMs9Cl/m3v96FKOO8Rd7in38gXu5UlB+L8QyDU65j1QyrGvdZe/2I/X9rTXuo+AHUBbn7Kp2OZb7/eb5/e2EIj0Wt8WW9P3p88xjnlv+mxzASf5rP8Um1zXL8P1PdN93GkB7ON5TalAA2wSuAII8/k93FVE/J+4n9/nXr7Ua/v3wMHyvmf0oQ99FP2obU17DbC1RoHaw7GdtHtha6peN15NLMZ2nn0Cm8Bc6F7t+RZ9rog0KOE8WUCyiKQEGqAxxmBrpRpjkxePc4A2wHTjroUxxuS4yyMikSISKyJNsbVIDuwf8kB5znlUM6QxZi42OfKN95Dnudi7KJtgE6nvgG6lXKdiiYgDm7j+boz5zGfzf7AfmEV14p3ouSbu+BZhP5C7BHD6f2I//HZgm39HYGvkLvQp53ltvrUrvva7fzb02W9/EWX9Vo5rFEye19DAHVND4HxgHpArIk09D+yXmXXY97KvZ41Xh3VjzBZskpgoIt0CiOcXY8xCn3XfYWuF4wM4jseN7p+vlViqGMaY/djm32TcTdt+eg7YCvxLRCLKcm6lVGBqWyK1H1v9H6j1xufOKWwnUoCVRZT3rOsIYIz5L7YJ4lpgl7sv0D9FJMlnvzuxidByd3+VqSJyofuDDwB30tPS++G1/xvYGqXrvdZ5nr/udYxwERkvImnYTuO7sQnADHeRxkVehZJ1xH4ApxWx7U/fFSLS3N33ZTu2+WOXO4Zb3EUalSEGsLVB9Sni92KM2QNsc8fqa0MR63Zjmxz9NQU4G9sUNxabgLfl2I75vglScXwTLs9+ZXkPeyvrNQom36SwK/bv0Q3Y94HvoyvQoojjHPPewnbEh8BeQ3G/fwjsPYCIxGIT0dXGmJ8C2dfHS9hm8X+KSLQ/Oxjb3+5hbJPyLSWXVkoFQ21LpFYADUQk0A+J7NKLlMwYcw22ued+7B/oMcAyERnpVeYj7Lffq7Dfhs/E3q79vbuDMtgajm0+D8/+W7G1SmeJSFv3H/RB2G/b3h84zwCPAL9h+3Gch00Axrq3V+j7wt1/5CvsN+03gf/D9tE6G9s/pcJjKIJvouwhARxjrTHmG2PM58aYJ7BNcSdi+8V5W+H+2bOU43m2L/fZ74QAYqqqurt/emorPdf5Lez7oKjH1RUYT3G/f+/Y/HUFEEUZa6M83DVtD2CT8TsC2PV17N2i40WkvEm3UqoUta2z+QfA6dhq9/vKeSzPN9jkIrYl+ZQBwBizAvth+KSINML273hMRF70NCu5awTeAt5yJxyPYce0uhDb2X0MJdcYvYZNjK7B1mRE4VUb5XYV8IMx5lLvlWLH2CqrDdjkJ4Fjazp8m1i6Az2ACcaYh3xiuJFjBdJpdie2+faY34uINAZaYcddqnDGmAXuTtVXi8gkY4yng/wCbJ+1C0WkqTFmVxGxRmPHBcsFPncf7y8R+R3bGTzRGLO6jKGF9Bq5vxRchU1evnSvXof9PUca20ncX92ApT7rivz/V4luwPatmh6EY72D/T9/L0fXNBfLGFModhiMD4G7SiuvlCqf2lYjNRX7DfguEfHttwKAiPQSkRF+HOs37C3H13k3r7n7JdyN/VD4yL0u1rt5DsAYsw9bbV8XiBaRMHdy5V3GAL+7F2Pd65a4az0OP3zi+hj7QXkt9g/vIeA9nzKF+HzLFpF6wCg/XndxPnL/vNvnuIOxzTK+56eIGFIoum/OQff22NKCMMa4sNfgBBEZ6LP5Xux7/sPSjhNEj2Bf7wTPCmNMHrZjen1swlzHewexQ1BMBuKAJ83Rd/Z5ag1n+jTrHt5X7Kj9vs3Gh4XyGrlf6xvYZrdXjDEb3THtxg5mOkRE+hSxn0jRI/eP8qqt9YzddDmwxqcW9iDu/0MVSezwIz2Aj00xd2QGwv034F5sU/e4APabi03YR2MHG1ZKVZBaVSNljMkWkfOxd+PMFZGvgK+xTW3NgDOwt2OXOn6L+1vfSOwHziIRmYL9lv9/QB/gUWPMWnfxq7F/8D/EfvMuAPq5zzXLGJPjTqK2icg8bPK0A9sP61ZgL36OjGyMKRCR6dhvsWDvVPLtYP8+dnTp97ADQrbAJl27KSNjzJci8jF2rJ5Y4AtsP42bsbVw3h3o/8TWWt0jdsyiNdiarJuxzVi9fA7/KzASmCwinjupFhpjihpWAWxt49nY3/Fk7DU/Hfu7+YEgDErqL2PMOhGZCVwhIqcZY350r5/irgG8G1jl/p2lY4dFuAzbDPwWtgO79/G+FpHh2P4za0TEe2TzztiRzTtx9PUuSmVco9PcNWvC0SObN3O/tjt9yt8K/AT84L4ev2OTuo7YGtnpHDu6fTjwo/s6xGD7BdUBbvcp9yu2yXss9guQMcbMLP9LPIZnDLlAx44qljHmKxH5FtvUH4ix2CEfumG/UCmlKkKobxsMxQNbCzQK+0d7L/aDeTs2wboK9+3G7rLpwPclHKsfNhnbj22G+R2vW8fdZY7HfjCtw/5B249tjhiDe6gC7LAJ/8GO7bMbO+VJOrZZrkuAr68b7iEHgNOKef1PYodvyMWOIXQvR27ZvtarbP8i1sXjM/yBe30d7HhamUCO+7WcQxHDF2BrW2Zja8+y3WUvoujhDBzY8Z22YGt3DsdTVHn3+g7YzvM7gHxsM8+jQF2fckXu78/vvohrdFcx27u5455fzL4fYPu65buvx+fARaWcsys2mUpzX79cbEL6CnCCn+8Tf6/RMe+BUo57rdf7z2CTvL3Y/xsvAyeXsG9T93vTcyPEPmxyPRFIKuL3lgw8737P5brfR2cXcdwu2H55+z1xeW0rcmgEr9fR38/XXccd7ybAEcj/WZ/XlFrEtl7YmzlKHP6giP0+cm/X4Q/0oY8KeogxgXQ/UUqp0BM7qv5DQAdTvgFTlVKqXGpbHymllFJKqaDRREoppZRSqow0kVJKKaWUKqOQ9ZESkdexU0LsMMYcc4eRewylidgxkbKxHV1/q9wolVJKKaWKF8rhD94AXqD4QevOxd5p0wU4CXuH0kmlHbRp06YmPj4+OBEqpVQtsWTJkl3GmKLG6lJKlSBkiZQx5gcRiS+hyIXYiXYN8KuINBKRVsaYbSXsQ3x8PIsXLw5mqLWaMfZRWAgul/1ZWHj0Ou+HZ733T+9tnp/ez73XFbcMx673fnjH6r3Os6/3Ot+ynmXfcqVt863M9T1+ceWKOrbv86KWy1PO34rnksqVdVtZypVFZVWuV4cbnT23ZZcmJcXB6afb5yKysYLDUqpGqsoDcrYBNnstb3GvOyaRcg9QOBygffv2lRJcRSgogOxsOHQIcnPtIyfnyHPPIy/P8zDk5BSSm19IXq4hP99FfoGLvDxDQQEUOA0F+YYCp8FZYChwgtMJhU4ocB5Jilzun06nUOjyXideiYD9o3z4XwPGe+YW32XPc+M9v4vvM+O7+pj9i95kjikpRZYtLsPwa5XfW/0vffQWMYEeWfmv8q9sdfxdXvl/DTj99AalF1RKFasqJ1J+M8ZMAaYApKamVom/Z/n5sHMn7NgBe/bYx+7dLnbuKmDPngL27itkX5aLgwfh0EE4dEjIzxeMcbkfBoPx+mZpjqzzSmTsHCtif4pnxhU5sv7wJCxHZmMRxGvxSFnvCVvEu7yAwwEOh8ERZnAIhIUZEAhzrxcHOMSrbJiNLSzMrvOst88NInL4mOC9zbusTY9sWXc5AfGURQ4fSxxHwhexBR1yZFk4cmzvSyUiXs+N+/nR6xyOo+/J8CyKiNc5jdeB5cjx3MfyHM+4s74jv5cj8R2J6+hrX8Sv5xhSzMaj1hd3AO/rUsI5StteXAy+R/BcKyllB/+OFxxS6iv3KV/GCyGAOCrxhXmf+8BBIufPp7BDB5zH2W6pPXpEhCQWpWqSqpxIZQDtvJbbutdVGXl58NdfsH49rF1fyIa/ctm4qYDMbZC1Tyh0FeJyOXF5JUfg+fB2uD9kxf3TgcMBdeq4iI52EV3HUCfaEB0tREcboqMd1IkWoqOEqGgH0VFCdLSDqCghMhIiI4WICIiKsj/Dw4+sDw+HiAghIsI+Dw8/8jwsTA5vCws7st3zsMlOaP7wK6WCwBiYOxeeew6yD8GuFnDHXIjQJEqpYKjKidQ8YKR7nrKTgKzS+kdVJJfLJk2//2745X+5LF2WR8ZmKHA6KXQ5cbkKbc2JOHBIGGFhQtOmhTRt4iK2CTRpHE7TJmHExobRqJG4H2E0bOigQQMHDRqEUa9emCYtSqng2bIF/vUv8PQbPf10uPdeTaKUCqKQJVLuSUb7A01FZAt2uocIAGPMy9iZ4M/Dzk+XDVxX2TE6nbBkieHTL/L4+ps8du504izMB+MiTMIJDw+jfdsCOnaADh0iiYuLIC4ujPj4CFq2jCAiIqyyQ1ZKKfvN7913YfJkW3XeuDHcfTecfXbltpkqVQuE8q69y0rZboB/VFI4R8nKgunvFPDWW9ns3JmPy5VPuCOcpk0Nx3eH7sdF0Ss1ipSUaOrWDS+1r4dSSlUqlws+/dQmUeedB6NHQ6NGoY5KqRqpKjftVbp9++DpSXnM+SCb7OxcHAhx7Qxn9A/nb3+Lplev+oSHay2TUqoKKiiwt/XGxEB4ODz8sL3b5dRTQx2ZUjWaJlJuPy5wMuaeA+zcnku4hHFKb7j8inDOPrsRERF6mZRSVdjKlfDPf0KnTvCf/9h1CQn2oZSqULU+Q3A64bGnc5g27RAUFnBCijDuvnB69Wp6zG3vSilVpeTmwksv2f5QLpf9g7Z/PzTQsaGUqiy1OpEyBm4bnc2XXxwgMky46loHo0Y1om7dqFCHppRSJVu8GB55BDIy7OBmV18NN98MUfr3S6nKVKsTqbdnZ/PlFweJqQNPPGE4++xmWgullKrajLHNd3Pm2OUuXeCBByApKbRxKVVL1dpEKn2Lk8f+s59wCeO224Rzzmmqd98ppao+EYiMtGNB3XgjXHON7VyulAqJWvm/zxgYfc9ecg/BKX3DuPrqGE2ilFJV15499g68xES7PGIEDBkCHTuGNi6lFLWyHevNtwv4Y7GLxg0jePDBMCIjdZRfpVQVZAx8/jkMGwb33GNnNQeoW1eTKKWqiFpXI5WfD889m4MYw513OunYMTbUISml1LG2b7d9oX76yS537Qo5OTaJUkpVGbUukVq6vJADB3KIjxcuuSRWm/SUUlWLywUffggTJ9oaqJgYGDUKLrhAp3dRqgqqdYnUDz/uweDi+O7RROjEnUqpqmb8ePjqK/v8jDNg7Fho2jS0MSmlilXrEqn/Lc4iTBqRkuIKdShKKXWsv/3NjhE1diwMGKC1UEpVcbUqkSpwulizOpKI8Eh6966V/eyVUlVNWhqsWGHvwgPo1w9OPFH7QilVTdSqRGpN2gH274+gRZNwEhIiQx2OUqo2y8+H116DN96wd+clJ9sO5aBJlFLVSK1KpH7+dR8OqUNSkpOICP1DpZQKkWXL7PQuf/1lly+5BNq1C21MSqkyqVWJ1JI/cnFIPZKSnKEORSlVG+XkwOTJMHOmrYWKi7PTuxx/fKgjU0qVUa1KpP5cFUGYhNOzp3beVEqFwDPP2KENHA649lq46SY73YtSqtqqNYnUvv0utm6uS73IcHr21GEPlFIhcOONsHEjjB59ZLoXpVS1VmtuXVv0Wz7G5aJzZxcNGug3QKVUJfj+ezu1i8s93EqLFjBliiZRStUgtaZG6n+LDwFCt6RCHc1cKVWx9uyBJ56Ab76xy199BQMHhjYmpVSFqDWJ1NI/CnBImA7EqZSqOMbAZ5/B00/D/v1Qpw7cdhucc06oI1NKVZBakUi5XJC2OgKHwEknRYc6HKVUTbRtGzz6KPzyi13u2xfuuw9atQptXEqpClUrEqn0dDh4wNCsqYu4OE2klFIVYP58m0Q1aGA7k//97zq9i1K1QECdzUWknYi8LiJbRCRfRAa41zdzrz+xYsIsn7/+gkKXk06dnISFhYU6HKVUTZGXd+T5pZfC9dfD7Nlw/vmaRClVS/idSIlIB2AxMBRYCRzOSIwxO4FU4MZgBxgM2bkujHERExMV6lCUUjWB02mndrngAti5065zOGDECGjSJKShKaUqVyA1Uv8GXEAKcAXg+3XrM+DUIMUVVIeycwGIitDxo5RS5bRmDVxzDbzwgr077/vvQx2RUiqEAukjdRbwvDFms4gU9ZVrI9A2OGEF18FDB3GIg/Ba0SNMKVUh8vNh6lRbE+VyQevWcP/9cNJJoY5MKRVCgaQWDYBtJWyPDPB4leZgdjYidQkPN6EORSlVHa1aBQ8+aO9cEbH9oUaMgLo6+blStV0gic9mILmE7X2AdeULp2IczM7BIfVx1Jpx3JVSQbdpE8TH24Sqe/dQR6OUqiICSS3mANeLSIrXOgMgIkOBYcCsIMYWNHl5eYg27SmlApGWduR5UhJMnAjvvKNJlFLqKIF2Nt8CLATewiZR94rIL9gEainwdNAjDILcvHwcDgdhYdq0p5Qqxf798PDDcPnl8MMPR9b37QuROk+nUupofidSxpj9QF9gKnaoAwHOBroCk4EzjDG5FRFkeeXm5eOQMHQIKaVUib77Di6+GD75xCZNu3aFOiKlVBUXUGOXO5m6A7hDRJphk6mdxpgqXdWTl+d0N+05Qx2KUqoq2rXLTjL83Xd2+YQT4IEHoH370MallKry/E6kRORBYI4xZgUcHoTTe3syMNQYMyG4IZaPMYb8/HwcIoSF6UjDSikfy5bBHXfAgQP2Lrzbb4chQ9C7U5RS/gjkL8XDQEm9LFOAhwI5uYgMFJE1IrJORO4tYnt7EZkvIr+LyDIROS+Q4wPkF7ooLHQhEqadzZVSx+rc2SZQJ58Ms2bZpj1NopRSfgpmahEN+N12JiJhwIvYflZbgEUiMs8Ys8qr2HhgljHmJRFJwo6eHh9IUDl5ORjCEBFNpJRSdjDNefPgb3+DOnVsEvXGG9C0qc6Pp5QKWImphYg0ABp5rWoiIkV1GojFThuzOYBz9wbWGWM2uM81E7gQ8E6kDHYgUICGwNYAjg9ATm42gr3TJjxc/0gqVav99Rc88ohtztuwAUaPtuubNQttXEqpaqu0OppRwIPu5wZ4zv0oigD3BHDuNhydeG0BfOdaeBj4SkRuA+php6k59sQiw4HhAO19Oofm5h1CjCeRCiA6pVTN4XTC9Onw6qtQUGBrn3r1CnVUSqkaoLTU4nv3T8EmVB8Cy3zKGOAg8KsxZkFQo4PLgDeMMU+LSF9ghoikGGNcRwVgzBRgCkBqaupRdxDm5B8ETaSUqr1Wr4YJE44MsDl4sO1cHhMT0rCUUjVDiamFMea/wH8BRCQOeNkYszBI584A2nktt3Wv83YDMNAdyy8iEg00BXb4e5LcvGwcUgeAiAht2lOqVtmwAa6++sgkw+PHQ+/eoY5KKVWD+F1HY4y5LsjnXgR0EZEO2ATqUuBynzKbgDOBN0SkG7ZD+04CkFuQA66GgNZIKVXrdOwIAwZA8+Zw6622c7lSSgVRwKmF+267RKAxRQyfYIz54ZidimCMcYrISOBLIAx43RizUkQmAIuNMfOAMcCrIjIK24R4baCDf+blH8Ih2tlcqVrh0CF48UXbfJeQYNc9+qgOZ6CUqjABJVIiMha4lyN30hXF74lYjDGfYYc08F73oNfzVcApgcToKyc/G2Psy9QaKaVqsAUL4N//hu3b4c8/4fXX7XAGmkQppSpQICOb3wD8B9tn6ivsJMbPAgXYvkwbsHPuVSkFznwd/kCpmmzfPnjmGfjM/Z0sKQnuv1/HhFJKVYpA6mhuxd6Zd4aINMEmUp8aY74TkYnAHwRQG1VZ8vKzwUQAEBZWpacEVEoFwhj45hs7R97evXaS4REj4LLL0BnKlVKVJZA6727AbPdzT0YSBmCM2YYdfuCO4IUWHPmF+Yeb9vSuPaVqkL177eCae/dCz57w3ntw5ZWaRCmlKlUgNVKFwCH3c8/PJl7b04EuQYgpaIwxuJx5CJ4aqRAHpJQqH2Psw+GA2Fi46y472ObgwdoXSikVEoH85dkEdAAwxuRhRyU/zWv7icCe4IVWfoUug6EA47KJlNZIKVWNZWTYprv33z+ybtAgGDJEkyilVMgEUiP1A/B3YJx7eTZwp4jUwSZkVwKvBze88ikodCGmAJcrDHBqIqVUdeRywcyZMHky5ObahGrIEL0NVylVJQTyl2gisFRE6hhjcoCHgATgGvf2r7BDI1QZufm5REgYhS77bVWb9pSqZjZssNO7rFhhlwcOhDFjNIlSSlUZgYxsvgZY47V8CBgkIg2BQmPMwQqIr1zy8rMJj4jE6bTLWiOlVDXhdMIbb8DUqfZ58+YwbhycdlqpuyqlVGUqd8cCY0yWMeagWFcFI6hgyc3LJjwsisJCu6yJlFLVhAj89782iRoyBGbN0iRKKVUllbt+XEQEuAx4ANvUN6O8xwyW/IJcwhxHaqS0NUCpKiw3F/LyoGFD2w7/0EOQlQW9eoU6slpryZIlzcPDw6cCKQThi7dS1ZALWOF0Om/s1avXjqIKlJpaiMipwN3YoQ32ADOMMa+4t/0NeAY7995B4PEgBR4UzsI8IsKjtGlPqapuyRL417+gSxc7wCZA586hjUkRHh4+tWXLlt2aNWu21+Fw6IjGqtZxuVyyc+fOpMzMzKnAoKLKlJhIicgpwLfgHojJ6isi9YBo4F/APuARYKIxZm8wAg8WZ0Ee4WERh5v2dIoYpaqYgwdh0iSYM8cuR0XBgQMQExPauJRHiiZRqjZzOBymWbNmWZmZmSnFlSmtRmoskAdcjE2oOgPTgfFADPAKMM4Ysy8oEQdZgTOf8PAIrZFSqir66Sd49FHYscO2u99wA1x7LURElLqrqjQOTaJUbef+P1Bs03ZpidRJwCvGmI/dy8tE5C7sUAdvGmNuDU6YFaOgsIAwx5FESoc/UKoKMMb2f/JMMpySAg8+CB07hjYupZQqg9I6DzYBVvqs8yzPDXo0QVboyiciTGuklKpSRKBxY9uMN3o0vP66JlGqWGFhYb0SExOTunTpkjxgwIDOu3btOvyVePHixdF9+vRJiI+PT4mLi0u5++67W7lcrsP7zpo1q0FKSkq3Tp06JXfr1i3ppptuaut7/JycHDn55JMTEhMTk1599dXGxcXRu3fvrj/88ENd3/WTJk1qcvXVV7f3Xe9yubj22mvbtW/fPiUhISHpp59+OmZfgIMHD8qJJ57Y1en5oAImTJjQPCoqqufu3bsPv9aizuMdU1ZWluPyyy+Pa9euXUpycnK33r17d/3uu+/qFfd6/OHva3j11VcbJyQkJHXu3Dn51ltvbeNZn5aWFtm3b9+EhISEpN69e3ddv359BMDWrVvDTzvttCo1pVx5lJZIOYB8n3We5QPBDye4CgudhGkipVTo7dhxZFBNgFtvtUMaXH65Tu+iShQVFeVavXr1qrVr165s1KiR88knn2wGNgG56KKLOt9zzz2Z6enpK1asWLFq4cKF9R9//PFmAIsWLYoeM2ZM+xkzZvy1fv36lcuXL1/VuXPnPN/jL1iwoC7A6tWrV910001B6+c7e/bshhs2bIhOT09f8dJLL20cMWLEMckWwPPPP9900KBBe8O9bit///33Y1NSUg699dZbjfw93xVXXBHfuHFjZ3p6+oqVK1f+OX369L927NhRrnvV/XkNmZmZYQ8++GDb77//Pm3dunUrt2/fHvHRRx/FANxxxx1tL7/88t1paWmrxo8fv3XMmDFtAVq3bu1s0aJFwVdffVWuRK+q8OcvWD0RifU8gFj3+hjv9V7bqwxXYQFh2tlcqdBxuWxH8mHD4J574JB7vvPoaGjTpuR9lfLRp0+fQxkZGZEAr776apPU1NSDQ4YM2Q8QExPjeumllzZNnDixFcCjjz7acsyYMdtOOOGEXIDw8HDGjh270/t4GRkZ4dddd12H5cuX101MTExauXJl1EcffRTTrVu3pISEhKRhw4bF5+TkHPPBMXHixCbx8fEpxx13XLcFCxbULyrWjz76qNEVV1yx2+FwcOaZZx7av39/+MaNG4/pADhr1qwml1xyyT7P8sqVK6Oys7PDJkyYkDFr1iy/PlNXrlwZ9fvvv9ebOHFiRpi7D0tiYmL+pZdemuXP/sXx5zWsWbMmKj4+Pq9169ZOgDPPPHP/7NmzGwOsXbu2zrnnnrsf4Pzzzz/wzTffNPLsN3jw4H3Tp09vUp74qgp/EqmXgZ1ej9Xu9XN81u8EihxjIVScLidhEqaJlFKhsHmzrXl69FGbQCUmQr5vBbdS/nE6ncyfPz9m8ODB+wBWrlwZ3bNnz2zvMsnJyXnZ2dmOPXv2ONasWVPnpJNOyi7yYG5t2rRxTp48eWNqaurB1atXr+rQoUP+zTff3OG9995bn5aWtsrpdOKpAfPYuHFjxGOPPdZ6wYIFqxctWrQ6LS2tTlHH3rZtW0R8fPzhN3yrVq3yfZOQ3Nxc2bx5c1TXrl0Pl5s+fXrjiy66aM/AgQMP/vXXX9GbN28utVbpjz/+iE5KSsoO92OwxL///e8dExMTk3wfL7zwwjFJjT+vISkpKW/Dhg3Ra9asiSwoKGDevHmNt27dGgnQrVu37HfffbcxwIwZMxodOnTIkZmZGQZwyimnHPrf//5XZBJa3ZR21d+slCgqiMsUYogADCIQFqaJlFIVzuWCd96Bl16yA2w2bmxro846y/aPUtXWR39kNAz2MS88vk2JtSZ5eXmOxMTEpO3bt0d06tQpd/DgwfuDHYPH0qVLo9u2bZvXvXv3PIBrr71294svvtgcr0qCH374oV6fPn0OeGpghgwZsictLS26LOfLzMwMj4mJcXqvmzNnTpM5c+asCwsL47zzzts7Y8aMxvfdd99OKeb/TnHri/Ppp59uKEusxWnWrFnhs88+u3HYsGEdHQ4HJ5544sG//vorCuD555/fMnz48PbdunVr2qdPnwPNmzcv8CR7rVu3du7YsSMymLGESomJlDHmusoKpCK4XIWIsS8xPFzv4FWqUtx7L3z3nX1+3nl2kuGGQf/8VSFQWtJTETx9pA4cOODo379/l8cee6z5+PHjdyQlJeX++OOPR9VorFq1KrJu3bqu2NhYV0JCQu7ChQvr9u3bN6eyYwZo1apVQXp6+uFEYdu2bZFxcXEF3mXq1avnys/PP9wy9L///a/Oxo0bowYOHJgAUFBQIG3bts2/7777djZt2tS5b9++o+4937dvX1iLFi2csbGxhX/++Wddp9NJabVSf//73zuuX7/+mMRv5MiR20eOHLk70NcAcPnll2ddfvnlWQBPPfVUU0/zYnx8fMFXX321Hmxn+M8++6xx06ZNCwGys7MlKirK5Xus6qhG9/J0uZy4XLYWUqeHUaqSDBoELVrAxIkwYYImUSooYmJiXJMmTdo0efLkFgUFBQwfPnz3okWLYubOnRsDtvP5P/7xj/a33XZbJsC4ceMyn3nmmVbLli2LAigsLOSJJ55oVtI5evTokZuRkRG5YsWKKIDp06c3Oe200466ser0008/tHDhwpjMzMywvLw8+fDDD4u802/QoEH73n777SYul4tvv/22XkxMTKFvEtKsWbPCwsJCyc7OFvf5YseMGbM1IyNjeUZGxvIdO3Ys2759e0RaWlrkqaeeemjJkiX1N23aFA7www8/1M3Pz3d06tQpPzk5Oa979+6HRo8e3dpz1+KaNWsiZ86cecx/vk8//XTD6tWrV/k+fJMof18D2L5mADt37gybOnVq8xEjRuwE2LZtW3ihu2/N+PHjW1122WW7PPusWLEiOiEhISRJbrDV7ETKuBBjM2O9MUipCrJiBbz77pHlU0+FDz+EU04JXUyqRjrllFNyEhMTc6ZMmRJbv359M2fOnHWPPvpo6/j4+JSkpKTknj17Hho3btwOgJNOOinn8ccf33zZZZd17NixY3JCQkLyhg0boko6ft26dc3LL7+cPmzYsE4JCQlJDoeDu+6666gO6nFxcQVjx47d2qdPn26pqamJCQkJuUUd65JLLsmKi4vLi4uLS7n11lvjXnzxxY1FlTv99NOzvvrqq/oAc+fOjfXueA5w7rnn7n3zzTdj27Vr53z88cc3Dxw4sEtiYmLSqFGj2r311lsbPLU/b731VvqOHTsi4uLiUrp06ZJ81VVXdWjVqtUxSU8gSnoNiYmJSZ7nt9xyS7tOnTol9+nTJ3H06NHbPE2jX3zxRUzHjh1T4uPjU3bs2BH+n//8Z5tnn6+//jpm4MCBlV7DWRHEmJrV5JWammoWL14MwMc/vE7rxn0Zfm0i9erl8cMPZWrGVkoVJSfH9oN6913b9+nNN6Fbt1BHpcpIRJYYY1K91y1dujS9R48eu4rbR5XfTz/9VPepp55qMXfu3L9CHUtlSk1N7fr555+va9asWWGoY/HH0qVLm/bo0SO+qG01usHLZVwYlwMwWiOlVDAtWmQnGc7IsNW9V12lg2oqVQannnpq9uLFi/f707+ppti6dWv4HXfcsb26JFGlqdG/NWMMrkJb7VlL3p9KVawDB2zfp7lz7XJCAjzwgNZEKVUOd9555zH9k2qy1q1bO6+66qp9oY4jWGp0euFyFeJyeRKpmtWEqVRIPPccfPSRnVj4ppvg6qv1W4pSqlar4X8BDS7tbK5U8NxyC+zcCaNGQYcOoY5GKaVCLqD0QkRiRORBEflJRNaKSF/3+qbu9YkVE2bZuIyLwkIHxmiNlFIBMwY++wxuv53D0wM0awaTJmkSpZRSbn7XSIlIM+AnoCOwzv2zDoAxZpeIXAM0AkYHP8yyMbgwRjubKxWw7dvt1C4//2yXv/0WzjkntDEppVQVFEh68S+gJXAScBrgOy79R8CZQYorKIzLYArtS9RuHEr5weWC99+3kwz//DPExMBDD8HZZ4c6MlVLhYWF9UpMTEzq0qVL8oABAzrv2rXr8Ojeixcvju7Tp09CfHx8SlxcXMrdd9/dyjMgJcCsWbMapKSkdOvUqVNyt27dkm666aa2vsfPycmRk08+OSExMTHp1VdfLXJwTYDevXt3/eGHH+r6rp80aVKTq6++ur3v+t9//z36+OOPT4yMjOz54IMPtijuuC6Xiz59+iTs2bPn8OfxjBkzGolIr99///3wmD2ffPJJzBlnnNHZe9+hQ4fGT5s2rTFAXl6ejBgxok1cXFxKUlJSt+OPPz5x1qxZDYo7r7/GjRvXsn379inx8fEpH3zwQZHHmzdvXkxSUlK3Ll26JA8ZMiS+oMAOX7Vz586ws88+u1NCQkLScccd123RokXRYOcYTE1N7eopV90FkkidD0w2xvwGFNVOtgFoF5SogsZQWGjzPW3aU6oUmzbZPlCPPQbZ2TBgAMyeDRdcoHPkqZDxTBGzdu3alY0aNXJ6JhE+ePCgXHTRRZ3vueeezPT09BUrVqxYtXDhwvqPP/54M4BFixZFjxkzpv2MGTP+Wr9+/crly5ev6ty5c57v8RcsWFAXYPXq1atuuummvcGKu3nz5s6JEyduuvnmm7eXVG7WrFkNk5OTc2JjYw9ngDNnzozt2bPnwenTp8f6e75Ro0a1zszMjFi9evXKVatW/fnxxx+v279/f1jpexZvyZIl0XPmzIlds2bNyi+++CLtzjvvbO90HjU1IIWFhQwfPrzDzJkzN6xdu3Zl+/bt81944YWmYEcz7969e3ZaWtqq6dOn/3X77be3B4iOjjb9+vXbP3XqVL9fX1UWSCLVFNukVxwXUKVGvDQY9zhSEFaut5NStcAvv8Bvv0FsLDzxhH00bRrqqJQ6rE+fPocyMjIiAV599dUmqampB4cMGbIf7BQyL7300qaJEye2Anj00UdbjhkzZtsJJ5yQCxAeHs7YsWOPGqU8IyMj/LrrruuwfPnyuomJiUkrV66M+uijj2K6deuWlJCQkDRs2LD4nJycY75FTJw4sUl8fHzKcccd123BggX1fbcDtGnTxtmvX7/siIiIEr/Fv/3227EXXXTRPs9yVlaWY9GiRfWnTZuW/uGHH/qVaBw4cMDxzjvvNJs6deqmOnXqGIB27do5b7zxxnIlhu+//36jIUOG7KlTp45JTEzMj4uLy/v+++/reZfZvn17eEREhMszmvnAgQP3z507txHAmjVros8+++wDACeccELuli1bIjdv3hwOcPHFF++bOXNmrUukMoFOJWw/AdhUvnCCyxgXhS7tbK5UsQ4dOvJ82DAYMcI27Q0YELqYlCqC0+lk/vz5MYMHD94HsHLlyuiePXtme5dJTk7Oy87OduzZs8exZs2aOieddFJ2kQdza9OmjXPy5MkbU1NTD65evXpVhw4d8m+++eYO77333vq0tLRVTqcTTw2Yx8aNGyMee+yx1gsWLFi9aNGi1WlpaXXK87qWLFlS/5RTTjn8H/Gdd95p1L9//6zu3bvnNW7c2Pnjjz8e05zoa9WqVVGtWrXK967VKs4NN9zQLjExMcn3cd9997X0LZuRkRHZrl27fM9y69at8zdv3hzpXaZly5bOwsJC8TR7vvfee423bdsWCZCSkpIze/bsxgDz58+vu23btijPJMgnnnhizrJly45KyqqrQHoOfQbcICLPA/neG0TkJOBq4LnghRYEBgrdfaS0s7lSXvLzYepUmzS9+66dZNjhgOuvD3VkqipbPjv4M1AfN6zE+dby8vIciYmJSdu3b4/o1KlT7uDBg/cHPQa3pUuXRrdt2zbPU7ty7bXX7n7xxRebAzs8ZX744Yd6ffr0OdC6dWsnwJAhQ/akpaWVuTUmKysrvHHjxocToFmzZsXefvvtOwCGDh26Z8aMGbGnnXZatogUWRtQ3PrivPbaa5vLGmtRHA4H06dP3zBq1Kh2+fn5jjPOOCPL4f7AnTBhwrbhw4e3dydrOYmJidlhYWEGbA1hRESE2bt3r8P79VdHgSRS/wQGAb8D87D9pK4RkZuAIcBW4PFATi4iA4GJQBgw1RjzWBFlLgEedp9vqTHmcn+P7zIuXC4BjHY2V8pj2TKYMAHS023fpwUL4KKLQh2Vqg5KSXoqgqeP1IEDBxz9+/fv8thjjzUfP378jqSkpNwff/zxqGa1VatWRdatW9cVGxvrSkhIyF24cGHdvn375lR2zIEICwszhYWFhIWFsX379rBff/01Zs2aNXVGjhxJYWGhiIhxuVxbmjdv7szKyjrqk2zv3r3hzZo1cyYlJeVt27Ytcs+ePY7SaqVuuOGGdj///HOM7/ohQ4bsefTRRzO917Vp0+aoGqitW7ceVUPlcdZZZx1asmTJGoA5c+Y0WLduXTRAbGys6/33308H26m+Xbt2xyUmJh7up1ZQUCB169at9s1FftfTGGMygT7AQuB67F17VwGXAF8Bpxlj9vh7PBEJA14EzgWSgMtEJMmnTBdgHHCKMSYZuNPf43sUumzztjsJVqr2ys6Gp56CG26wSVRcHLz6qiZRqlqIiYlxTZo0adPkyZNbFBQUMHz48N2LFi2KmTt3bgzYzuf/+Mc/2t92222ZAOPGjct85plnWi1btiwKbKfoJ554ollJ5+jRo0duRkZG5IoVK6IApk+f3uS000474F3m9NNPP7Rw4cKYzMzMsLy8PPnwww+LvdPPHx06dMj9888/owBmzJjR+KKLLtqzdevW5RkZGcszMzOXtW3bNv/LL7+sn5KSkrd9+/aI3377LRogLS0tcvXq1XX69OmTExMT47r00kt3DR8+vH1ubq6Anc/u9ddfPya21157bfPq1atX+T58kyiAoUOH7pszZ05sTk6OrF69OjI9PT26f//+h3zLZWRkhIO9A/LJJ59secstt+wE2LVrV5gnnmeffbZp7969D3gSvczMzLBGjRo5o6Kiqv2Hc0ANXsaYzcaYC4FY7DAIfYBmxpgLjDFbAjx3b2CdMWaDMSYfmAlc6FPmJuBFY8xe9/l3EACDodDpSaQCjE6pmmTpUrj0Upg509ZCXXedbdI7/vhQR6aU30455ZScxMTEnClTpsTWr1/fzJkzZ92jjz7aOj4+PiUpKSm5Z8+eh8aNG7cD4KSTTsp5/PHHN1922WUdO3bsmJyQkJC8YcOGqJKOX7duXfPyyy+nDxs2rFNCQkKSw+HgrrvuOqqDelxcXMHYsWO39unTp1tqampiQkJCblHH2rRpU3iLFi26T5kypcWzzz7bqkWLFt29hzjwOOecc7K++uqrGIDZs2fHDhky5KgO4hdeeOHet956K7ZOnTpm2rRpG6677rr4xMTEpCFDhnR68cUXNzZp0qQQ4Lnnnsto2rSpMyEhIblLly7JAwcO7NywYcNyTQqcmpqaO3jw4D0JCQnJAwcOTHjmmWc2eiZW7tevX+f09PQIgAkTJrTs2LFjcrdu3ZLPPffcfYMGDToA8Mcff0QnJiYmx8fHp3z55ZcNp0yZcrhZ8fPPP29w1llnVXoNZ0UQY/xLBkWkiTEmaBMrisjFwEBjzI3u5auAk4wxI73KzAXSgFOwzX8PG2O+KOJYw4HhAO3bt++1ceNGAN76/Amic0bwrwnR9OuXzcSJ5R5SQ6nqKS0NrrwSOne240J17RrqiFQVIyJLjDGp3uuWLl2a3qNHj12hiqk22LhxY8Rll10Wv2DBgrWhjqUynXPOOZ2eeuqpLZ7+aFXd0qVLm/bo0SO+qG2B1EhtFZE5InKhiFRWj6NwoAvQH7gMeFVEGvkWMsZMMcakGmNSmzXzrrk9Mo6UdjZXtc7y5UeeJyTAyy/D9OmaRClVhcTFxRVcf/31u4qqraqpcnNzZdCgQfuqSxJVmkB+cXOAv7l/bhORSSKSWso+Jcng6AE827rXedsCzDPGFBhj/sLWTnXx+wzG4CrUzuaqltm9G8aOtc138+cfWd+zpw7xr1QVdOONN+71Z+iCmiI6OtqMHDkyaC1coRZIZ/PLsFPEDAdWAf8AForIShG5W0RaB3juRUAXEekgIpHApdi7Ab3NxdZGISJNgQTsCOp+05HNVa1hDHz6qR0P6ttvoU6do8eJUkopFXSBdjY/YIx5zRjTDztp8cNABHbYg40ickz/pRKO5QRGAl8CfwKzjDErRWSCiAxyF/sS2C0iq4D5wN2B9NNygTbtqdph2za4/Xbb/2n/fujbF2bNgvPPD3VkSilVo5W5nt8YsxF4BHhERC4DXgICmtnUGPMZdqBP73UPej03wGj3oyxRUliIe2Tzsh1BqSrv999tEpWTAw0awJgxcN55Oj+eUkpVgjKnFyJSHzuG1NXAqdjarRVBiis4DDidOo6UquG6doXGjeHkk23fqNgaMX2VUkpVCwE1eIk1UETeAbYDU7GDab4A9DLGdK+AGMvB4HLZn1ojpWoMp9OOAZXtnkasbl17N97jj2sSpWqcsLCwXomJiUldunRJHjBgQOddu3YdHhVw8eLF0X369EmIj49PiYuLS7n77rtbuVxH+mzPmjWrQUpKSrdOnTold+vWLemmm25q63v8nJwcOfnkkxMSExOTXn311WIH1+zdu3dXz3xy3iZNmtTk6quvbu+7/qWXXopNSEhISkhISDrhhBMSf/nllyLn5HO5XPTp0yfB+669GTNmNBKRXr///vvhqWc++eSTmDPOOKOz975Dhw6NnzZtWmOAvLw8GTFiRJu4uLiUpKSkbscff3zirFmzyj3mz7hx41q2b98+JT4+PuWDDz4o8njz5s2LSUpK6talS5fkIUOGxBcUFACwc+fOsLPPPrtTQkJC0nHHHddt0aJF0WDv2ktNTe3qKVfd+Z1IichT2LvqPsVOCfM5MBhobYy50xjze4VEWC4Gp9O+RK2RUjXCmjVw9dXw9NPw4otH1jdqFLKQlKpInili1q5du7JRo0ZOzyTCBw8elIsuuqjzPffck5menr5ixYoVqxYuXFj/8ccfbwawaNGi6DFjxrSfMWPGX+vXr1+5fPnyVZ07dz7mdvsFCxbUBVi9evWqm266aa/v9rLq3Llz3s8//7wmLS1t1bhx47befPPNcUWVmzVrVsPk5OQc77v2Zs6cGduzZ8+D06dP9/ub0ahRo1pnZmZGrF69euWqVav+/Pjjj9ft37+/XENRL1myJHrOnDmxa9asWfnFF1+k3Xnnne2dTudRZQoLCxk+fHiHmTNnbli7du3K9u3b57/wwgtNAcaPH9+qe/fu2WlpaaumT5/+1+23394e7F17/fr12z916tQa8c0vkBqp0cBm4DaglTHmYmPMPHen8SrJYHC5x3UND9f+Iqoay8+HF16Aq66yg2u2bg2nnRbqqJSqVH369DmUkZERCfDqq682SU1NPThkyJD9YKeQeemllzZNnDixFcCjjz7acsyYMdtOOOGEXLCT5I4dO/aoUcozMjLCr7vuug7Lly+vm5iYmLRy5cqojz76KKZbt25JCQkJScOGDYvPyck55sNj4sSJTeLj41OOO+64bgsWLKjvux3g7LPPPtSsWbNCgDPOOONQZmZmZFHl3n777diLLrpon2c5KyvLsWjRovrTpk1L//DDD/1KNA4cOOB45513mk2dOnVTnTp1DEC7du2cN954Y7kSw/fff7/RkCFD9tSpU8ckJibmx8XF5X3//ff1vMts3749PCIiwuUZE2rgwIH7586d2whgzZo10WefffYBgBNOOCF3y5YtkZs3bw4HuPjii/fNnDmz1iVSScaYk4wxkz1TtlQHnrv2IiJCHIhSZfXHH3Z6lzfesHdOXHaZneqlT59QR6ZUpXE6ncyfPz9m8ODB+wBWrlwZ3bNnz2zvMsnJyXnZ2dmOPXv2ONasWVPnpJNOyi7yYG5t2rRxTp48eWNqaurB1atXr+rQoUP+zTff3OG9995bn5aWtsrpdOKpAfPYuHFjxGOPPdZ6wYIFqxctWrQ6LS2tyCY7b88//3zTM844o8jpUJYsWVL/lFNOOTxOyTvvvNOof//+Wd27d89r3Lix88cffzymOdHXqlWrolq1apXvz1hUN9xwQ7vExMQk38d9993X0rdsRkbGUZMUt27d+qhJjAFatmzpLCwsFE+z53vvvdd427ZtkQApKSk5s2fPbgwwf/78utu2bYtKT0+PBDjxxBNzli1bdlRSVl353XPIGLO6IgOpCMYYPLWQWiOlqqX16+Gmm2wC1aEDPPAAdK9iXRFVrfHZhs8aBvuY53U8r8T51vLy8hyJiYlJ27dvj+jUqVPu4MGD9wc7Bo+lS5dGt23bNs9Tu3LttdfufvHFF5sDh+d5/eGHH+r16dPnQOvWrZ0AQ4YM2ZOWlhZdzCH5+OOPY956662mCxYsKPIzNCsrK7xx48aHE6BZs2bF3n777TsAhg4dumfGjBmxp512WraIFNk/pbj1xXnttdc2l17Kfw6Hg+nTp28YNWpUu/z8fMcZZ5yR5XCPNzRhwoRtw4cPb+9O1nISExOzw9z9bMLDw4mIiDB79+51eL/+6qjYREpErnY/nWGMMV7LJTLGTA9KZEFS6G7a0z5Sqlrq1AnOPdc25V1/PUQW2TqgVKUoLempCJ4+UgcOHHD079+/y2OPPdZ8/PjxO5KSknJ//PHHo5rVVq1aFVm3bl1XbGysKyEhIXfhwoV1+/btm1PZMXssXLiwzogRI+I+/fTTtS1btixyAuGwsDBTWFhIWFgY27dvD/v1119j1qxZU2fkyJEUFhaKiBiXy7WlefPmzqysrKM+s/fu3RverFkzZ1JSUt62bdsi9+zZ4yitVuqGG25o9/PPP8f4rh8yZMieRx99NNN7XZs2bY6qgdq6detRNVQeZ5111qElS5asAZgzZ06DdevWRQPExsa63n///XSwnerbtWt3XGJi4uF+agUFBVK3bt1q/+FcUtPeG8A07ICb3stvlPCYFuwAy8sz/IHWSKlqISsL/vlP+PPPI+v++U+45RZNolStFhMT45o0adKmyZMntygoKGD48OG7Fy1aFDN37twYsJ3P//GPf7S/7bbbMgHGjRuX+cwzz7RatmxZFNhO0U888USzks7Ro0eP3IyMjMgVK1ZEAUyfPr3JaaeddsC7zOmnn35o4cKFMZmZmWF5eXny4YcfFnmn39q1ayOHDRvW6fXXX/+rpDnlOnTokPvnn39GAcyYMaPxRRddtGfr1q3LMzIylmdmZi5r27Zt/pdfflk/JSUlb/v27RG//fZbNEBaWlrk6tWr6/Tp0ycnJibGdemll+4aPnx4+9zcXAHYunVr+Ouvv35MbK+99trm1atXr/J9+CZRAEOHDt03Z86c2JycHFm9enVkenp6dP/+/Y+ZLiEjIyMc7B2QTz75ZMtbbrllJ8CuXbvCPPE8++yzTXv37n3Ak+hlZmaGNWrUyBkVFVXtE6mSmvbOADDG5HsvVyfGGK8aqdDGolSJjIHvvrNDGOzZA+np8PrrdlBNHVhTKQBOOeWUnMTExJwpU6bE/uMf/9gzZ86cdSNHjmx/5513RrhcLoYNG7Z73LhxOwBOOumknMcff3zzZZdd1jEnJ8chIpx99tkl1qjVrVvXvPzyy+nDhg3rVFhYSI8ePbLvuuuuozqox8XFFYwdO3Zrnz59usXExBSmpKQU2Q9r/Pjxrfbt2xd+2223xQGEh4ebFStW/Olb7pxzzsn66quvYlJSUvJmz54de/fddx+V0Fx44YV733rrrdhzzz334LRp0zZcd9118Xl5eY7w8HDz4osvbmzSpEkhwHPPPZdx5513tklISEiOiooyderUKXzooYe2BnaFj5aampo7ePDgPQkJCclhYWE888wzG8PdYwn169ev85tvvrkxPj6+YMKECS2//vrrhi6XS66//vodgwYNOgDwxx9/RN94440dABISEnLefvvtdM+xP//88wZnnXVWpddwVgSxg4fXHKmpqWbx4sUATPt4An8teoCPPirgnntyueKKcg+poVTw7dplEyjPBMMnnGD7QrU/ZmgapSqMiCwxxhw1Ef3SpUvTe/TosStUMdUGGzdujLjsssviFyxYsDbUsVSmc845p9NTTz21paTauqpk6dKlTXv06BFf1LZAxpF6XUROKmF7bxF5vQzxVQhPgniks3kIg1GqKMbAvHl2kuH58+3AmvfeC6+8okmUUrVEXFxcwfXXX7/Le0DOmi43N1cGDRq0r7okUaUJ5Bd3LdCphO0dgGvKFU0wGYPhSGdzTaRUlbN3rx1Y88ABO73L7Nlw8cU6w7ZStcyNN96415+hC2qK6OhoM3LkyN2hjiNYgple1AOq1njvcmQcKe1srqoEz/QVDoedzmXsWNsHauBA7QullFLVUImJlIi0B+K9ViWKyOlFFI0FbgXWBS+08vE07WmNlKoyNmyAf/0Lzj7bDqoJcN55oY1JKaVUuZSWXlwHPAQY9+N+98OXAC53+SrBGIPIkT5SERH6bV+FiNMJb74JU6dCQQHs22f7RWl2r5RS1V5pf8nnAunYROl1YArwi08ZAxwEFhljgjpiankJ4pVIhTYWVUv9+SdMmABr3TfkDB4Md9yhSZRSStUQJf41N8YsBZYCiEgc8IExZkVlBFZeLmP7ohwZR0prpFQlKiiAl16Ct96y/aLatIH774fevUMdmVLVyqZNm8JHjBjRfunSpXUbNGhQ2LRp04ILLrhg36efftpo/vz5VaY7iaq9Aplr758VGUhF0aY9FRJhYfD77/b5FVfYkcnrlDq3qVLKi8vlYtCgQZ0vv/zy3Z988skGgF9++aXOnDlzGoU4NKUOK2muvdMBjDE/eC+XxlO+qvAkUjqyuapwhw5BXp69G8/hgIcegoMHISUl1JEpVS198sknMeHh4eaee+45PLp43759c3bv3h3+3//+t8HAgQM7rlmzps5xxx2XPXfu3L8cDgd33XVXqy+++KJRXl6eIzU19eDbb7+90eFw0Lt37669evU6+NNPPzU4cOBA2Msvv5w+cODAg06nkxEjRrSdP39+QxEx11xzza77779/x48//lh39OjR7bKzsx2NGzd2vv322+lxcXFV6850VSWUVCP1PWBEpI57mpjvsf2hiiPu7VUiZdEBOVWl+vlnePRRSEiAZ56xQxnEx4c6KqWCKyWlW7Hb7r57G9dcsw+AN99sxJNPtiq2bBFTpRRl2bJldXr06FHkFCx//vlnnT/++GNDfHx8Qa9evRK//vrr+n/7298O3n333TueeuqpbQCDBw/uMHPmzIaXX355FoDT6ZTly5f/+d577zWcMGFC64EDB6Y9/fTTzTZt2hS5atWqlREREWzfvj0sLy9Pbr/99vaffvrputatWztfffXVxnfddVeb2bNnp/sTt6pdSkovrscmRp4MvMrckeevozuba9OeqgD79tnE6bPP7HKTJrYWKuaYydWVUkF03HHHHerUqVMBQHJycvb69esjAT7//POYZ555pmVubq5j37594UlJSTlAFsCwYcP2Apx88smH7r777kiA7777rsEtt9yyM8J9R1KLFi0KFy1aFL127do6AwYMSADbxNisWTOtjVJFKjaRMsa84bP8ZoVHE2QG8RpHShMpFUTGwNdfw5NP2hHKIyNhxAg7PpS2I6uays+aJK65Zt/h2qlyOO6443Lmzp3buKhtUVFRh1tIwsLCcDqdkp2dLWPGjIlbuHDhqs6dOxeMHj26dW5u7uGpAqKjow1AeHg4hZ7RmotgjJHOnTvn/PHHH6vL+xpUzVfj56LQpj0VdC6XHZH8vvtsEtWrF7z3Hlx5pSZRSgXRBRdccCA/P1+eeuqppp51CxcurPPf//63flHls7OzHQAtW7Z0ZmVlOT7++OMikzBvZ5555v5XXnmlaUGBrXDavn17WPfu3XP37NkT/s0339QDyMvLk8WLF0cH5UWpGieQSYt7i8hNPusuFJHlIpIhIo8GP7zy0xopFXQOB7RrB/Xq2WTqpZfsslIqqBwOB/PmzVv/3XffNWjXrl1K586dk8eOHdumZcuWRTazNW3atPCKK67Y2a1bt+QzzjgjoUePHodKO8eoUaN2tm3bNj8xMTG5a9euSa+99lpsdHS0mTlz5vp77723bdeuXZOSk5OTikvelBJPp+xSC4p8CriMMRe4l9sDq4FDwE6gK3CjMWZaBcXql9TUVLN48WLy8/N49+unePf5+9m2LZ9PP4W2bSNDGZqqzjIyYOdOOP54u5yXB1lZ0Lx5SMNSKlhEZIkxJtV73dKlS9N79OixK1QxKVVVLF26tGmPHj3ii9oWSNNeD+Anr+VLsXfqHW+MSQK+AoaXNciKop3NVbm4XPDOO3DJJTBuHBw4YNdHRWkSpZRSyv8BOYEmwHav5b8BPxhjMtzL84BHghVYsHia9jSRUgFbv95O77JypV3u2dN2MldKKaXcAkmk9gEtAEQkCugDePeLMkCVGbrZuKeI0RopFbCCApg2DV5/3b6Bmje3tVGnnRbqyJRSSlUxgSRSfwA3isg3wEVANPCl1/YOHF1jVSVoZ3MVsHvugR9/tM+HDIHbb4f62s9UKaXUsQJJpB7B9oP6H7Zv1NfGmMVe288HFgYxtqDQGikVsEsugfR0GD/eDm2glFJKFSOQSYsXiEhPbN+oLGCmZ5uINMEmWR8GPcIyMhhcLttXGOwd60oVafFiWLUKrr7aLvftC7Nn6+BjSimlShXQJ4UxJg1IK2L9bmBUsIIKFpdxAAaHAxwOrZFSPg4ehEmTYM4cOzdeaiokJdltmkQppZTyQ8CfFiLSADgL6OhetQHbzHcgmIEFg6vQjjIdHq53WikfP/wA//mPHRsqPBxuuAG6dAl1VEoppaqZgBq8RORGYDMwG3jC/ZgNbBGRGwI9uYgMFJE1IrJORO4todxQETEiklpcmaK4XLYWSmftUIft3Qv33w+jR9skKiXFjhN1003gnrRUKVW1iEivCy+8sINnuaCggMaNG/c444wzOlfkecPCwnolJiYmdenSJXnAgAGdd+3adfjTZP369RFnnnlmp7i4uJR27dqlXHfdde1yc3MPN31s2rQp/Pzzz+/Yrl27lOTk5G79+vXrvGzZsijfcxw8eFBOPPHErk5Ph15gxowZjUSk1++//354Wpo1a9ZEdunSJdl739GjR7d+8MEHWwRyvkC9//77DeLj41Pat2+fct9997UsqswjjzzSvEuXLsmdO3dOnjBhQnN/t1VkTCWVKWpbbm6upKamdvVMFRSIQKaIGQRMwY5iPgo42/0YBewApojIBQEcLwx4ETgXSAIuE5GkIsrFAHdQho7srkIHxmgipbw8/zx8+SVER9tk6vXXoWPH0vdTSoVMnTp1XGvWrKlz8OBBAfjwww8btGjRIvBPvABFRUW5Vq9evWrt2rUrGzVq5HzyySebAbhcLgYPHtx50KBB+zZu3Ljir7/+WnHo0CHHHXfc0cazfdCgQZ1PP/30A5s3b16xcuXKPx977LGMrVu3HvNt7fnnn286aNCgveFe3QlmzpwZ27Nnz4PTp0+P9SfOQM4XCKfTyahRo9p/9tlnaWlpaSs/+OCD2CVLlhw15+CiRYuip0+f3uy33377888//1z5xRdfNFqxYkVUaduK8sknn8QMHTo0vrwxlVSmuG3R0dGmX79++6dOnerXNfcWSI3UPcCf2JHMJxljvnU/JgE9sdPFjA3geL2BdcaYDcaYfGzn9QuLKPcI8DiQG8CxAZtIgdGmvdrOexDNf/wDBgywkwxffrnehaCUn1JS6FYRD3/Pf9ZZZ2XNnj27EcC7774bO3To0D2ebZMnT4497rjjuiUmJiZdfvnlcZ7anbPOOqtTcnJyt86dOyd7Jj5es2ZNZMeOHZMvvfTSuM6dOyefcsopXTwJWkn69OlzKCMjIxLg448/jomKinLdcccduwHCw8N5+eWXN7/33ntNDxw44Pjkk09iwsPDzT333LPTs3/fvn1zBg4ceND3uLNmzWpyySWX7PMsZ2VlORYtWlR/2rRp6R9++KFfH+qBnC8Q33//fb24uLi8pKSk/OjoaDNkyJA977//fiPvMsuXL69zwgknHIyJiXFFRERwyimnHJg5c2aj0rZVZEwllSlp28UXX7xv5syZFZpI9QDeMMYc84tx9496013GX22wzYQeW9zrDnPfJdjOGPNpSQcSkeEislhEFu/cefh9hMtlX572G66lXC7bkfyWW44MKNakCTzxBLRpU/K+Sqkq5aqrrtrz3nvvNc7OzpY///yzbt++fQ8B/Pbbb9Hvv/9+7OLFi1evXr16lcPhMC+//HITgLfffjt95cqVf/7xxx+rXnnllRaZmZlhAJs2bYq+/fbbd6xbt25lw4YNC6dPn964pHM7nU7mz58fM3jw4H1gE4QePXpke5eJjY11tWrVKn/VqlVRy5YtO2Z7UXJzc2Xz5s1RXbt2zfese+eddxr1798/q3v37nmNGzd2/vjjj3VLO46/5wPo1atX18TExCTfx9y5c2N8y27evDmyTZs2h2Nr27ZtvieZ9Dj++ONz/ve//8VkZmaGHThwwPH111833Lx5c2Rp27x17949MTExMWnEiBFx33zzTSNPTB988EGDssRUUpmStp144ok5y5Ytq+fPdfQWSIpRWsYe1GofEXEAzwDXllbWGDMF2+xIamrq4TgKC7WPVK21aRP861/w2292ef58OOus0MakVDW2YgV/hvL8J510Us6WLVuiXn311dizzjory7P+iy++iFmxYkXdHj16dAPIzc11NG/e3Anw+OOPt/j0008bAWRmZkasXLkyum3btgVt2rTJO/nkk3MATjjhhOz09PQim5vy8vIciYmJSdu3b4/o1KlT7uDBg/cH8zVlZmaGx8TEOL3XzZo1K/b222/fATB06NA9M2bMiD3ttNOyRYr+CC5ufXGWLFmypqzxFqVnz565d9xxR+aZZ56ZUKdOHVdycnJ2mPtDt6Rt3pYtW7YabM3atGnTmnzwwQfpwYzRX+Hh4URERJi9e/c6Gjdu7PJ7vwDOsRS4VkQmG2MOeW8QkfrYhGdpAMfLANp5Lbd1r/OIAVKA791vlJbAPBEZ5DMQaJGMMRh3jVRYmDbt1RqFhbbz+EsvQX4+NG5sRyo/88xQR6aUKqeBAwfue+ihh9p99dVXa3bs2BEOYIyRYcOG7X7xxRe9Pz/45JNPYv773//GLF68eHVMTIyrd+/eXXNychwAkZGRhz8UwsLCjGe9L08fqQMHDjj69+/f5bHHHms+fvz4HSkpKTlz5849qhZrz549jm3btkUmJSXlZWZmhvtuL0q9evVc+fn5h8+9ffv2sF9//TVmzZo1dUaOHElhYaGIiHG5XFtatGjhzMrKOioL2bNnT1iHDh3y2rdvn+/P+cDWSB06dOiYbOaxxx7bPHjw4KPuvm/Xrt1RtT1btmw5qjbHY9SoUbtGjRq1C2DkyJFt2rZtm+/PtrLwJ6aSypS2f0FBgdStWzegpCGQpr0ngW7AbyLyDxE5w/0YCSwBEt1l/LUI6CIiHUQkErgUO/ExAMaYLGNMU2NMvDEmHvgV8CuJ8igs9CRSAUSlqq916+C662DiRJtEnXcevP8+nH22HSdKKVWt3Xrrrbvuuuuurb17987xrBs4cOD+Tz75pHFGRkY42GQkLS0tct++fWENGzYsjImJcf3+++/RS5cuDbjJxiMmJsY1adKkTZMnT25RUFDAoEGDDuTm5jpeeOGFJmCb/kaMGNFu2LBhu2JiYlwXXHDBgfz8fPH0ywJYuHBhnS+++OKouaaaNWtWWFhYKNnZ2QIwY8aMxhdddNGerVu3Ls/IyFiemZm5rG3btvlffvll/YYNG7qaN29eMG/evBjP6/z+++8bDhgw4KC/5wNbI7V69epVvg/fJAqgX79+h9LT06NXr14dmZubK3PmzIkdOnToPt9ynmu/du3ayE8//bTRjTfeuMefbb7OP//8A6XVRvkTU0llStqWmZkZ1qhRI2dUVFTFJFLGmLnASKA18Dzwjfsxyb1upDHmowCO53Qf70tsJ/ZZxpiVIjLBfYdguRhsHyljdBypWmPpUjtCeYsWdqDNCROgYcNQR6WUCpJOnToVjB8/fof3ul69euWOHz8+48wzz0xISEhIGjBgQMLmzZsjhg4dmuV0OqVjx47Jd999d5sePXocKu64/jjllFNyEhMTc6ZMmRLrcDiYO3fuujlz5jSOi4tL6dChQ0pUVJRr0qRJGQAOh4N58+at/+677xq0a9cupXPnzsljx45t06ZNm2PuNDz99NOzvvrqq/oAs2fPjh0yZMhe7+0XXnjh3rfeeisW4M033/zr3//+d6vExMSkfv36dR07duzW5OTkvEDOF4iIiAiefvrpTQMHDkzo0qVL8uDBg/ekpqbmAvTr169zenp6BMCgQYM6derUKfn888/v/Nxzz21q2rRpoecYJW3z8PSR8n0U1UfKn5hKKlPSts8//7yBd7Oxv8SYwJIMEWmEHfbAM6aHZ0DOgE9eEVJTU83ixYvJzj3ExDfeZvaUG+jQIY8PPii1v56qjrKyjiRLLhe8+y4MHgz1yvzlU6laSUSWGGOOGqtv6dKl6T169NgVqphqg59++qnuU0891WLu3Ll/hTqW2u6cc87p9NRTT23p3r17nu+2pUuXNu3Ro0d8UfuV2kdKRMKxwxJ0BnYBHxljZpcz3kqhnc1rsJwc2w/qo49s8tS6tR3K4IorQh2ZUkr57dRTT81evHjxfqfTSbjeYh4yubm5MmjQoH1FJVGlKfG3JiKNge+xnb4F22L2hIicY4xZUpZgK5NOEVND/e9/9o68rVtt8rRkiU2klFKqGrrzzjt3hzqG2i46OtqMHDmyTL+H0tLf8cBxwCfYvkwJwC3YoQZ6leWElckzjpSOuVhDHDhgO5LPnWuXu3SBBx44MtGwUkopVclKS6QuAL4wxhzu/C0i6cBTItLWGLOlIoMrL88UMVpbWgMsXgzjx8OuXXZOvJtugquv1l+uUkqpkCqtrqYd8JnPuo+xzXxxFRJRENkaKaPjSNUEjRrZCYe7d7fjRF1/vSZRSimlQq60T6IowHfMh71e26o0l44jVX0ZY2uhUlPtGFCdO8PUqZCcrG21SimlqozyfCJV+Woez117WnFRzWRmwh13wK23wrffHll/3HGaRCmllKpS/EkxxojIpV7LEdgk6t8i4ju+iDHGXBi06MrJMyCnNu1VEy4XfPABPP88ZGdDTIxdp5RSSlVR/iRSJ7gfvvoUsa5KZSyepj2tkaoGNm2CRx6B33+3y2ecAWPHQtOmJe+nlFJKhVCJKYYxplq3o7hcngE5q1R+p3wtXgy3327nx4uNhXvvhQEDQh2VUsrHX3/9VTcnJydoX03r1Knj7NChQ3awjgcwbNiw+G+//bZhkyZNnGvXrl3p7367du0Kmzp1auy99967s6jto0ePbl2/fv3CCRMmbPfneIGWV9VXtU6USmKMZ9Jio53Nq7qUFDs/3vnn20mGNYlSqkrKyckJr1evnjNYj0CTsk8++SRm6NCh8SWVuf7663fNmzdvbaCvbffu3WGvvfZa80D3U6rGJlJgDg/IqU17VUx+PkybBofcc4hGR8OMGfDww9DgmDkqlVLKb+eee+7BZs2aOUsqs3//fkf//v07d+3aNalLly7Jr776auMxY8a03bx5c1RiYmLSzTff3BZg7NixLePj41N69erVde3ataXeqV5S+cmTJ8ced9xx3RITE5Muv/zyOKfTyYgRI9r85z//aeYpM3r06NYPPvhgi7K+dhUaNTfFMMZdI6VNe1XKsmUwYQKkp9u788aNs+vr1w9pWEqpqqt79+6J+fn5juzsbEdWVlZ4YmJiEsC///3vLUOHDt0f6PHmzJnToGXLlgXff//9OrC1Uaeffvqh888/v87q1atXAfz44491P/zww9jly5evKigo4Pjjj0864YQTim2GLKn8b7/9Fv3+++/HLl68eHVUVJS58sor27/88stNrrjiij133nln+3Hjxu0E+Oijjxp/+eWXaWW5Rip0am4ixZGRzbVprwrIzoYXX4RZs2y7a1wcnHtuqKNSSlUDy5YtWw22aW/atGlNPvjgg/TyHK9nz545999/f7tbb721zYUXXpg1cODAg7t27Trqk2L+/Pn1zzvvvH0xMTEugHPOOWdfSccsqfwXX3wRs2LFiro9evToBpCbm+to3ry5c+TIkbt3794dnp6eHrFt27bwhg0bFnbu3LmgPK9NVb6anUgd7mwe4kBqu19/hX//G7Zts+NAXXutneIlMjLUkSmlaqHu3bvn/fbbb6s++OCDhg888ECbb775Zv9NN91UYRMHG2Nk2LBhu1988cUM322DBg3a+9ZbbzXOzMyMGDJkiO8A2KoaqMF9pKBQp4gJvbVrYeRIm0QlJNi+UP/4hyZRSqmAnX/++QfKWxsFkJ6eHhETE+MaMWLEntGjR2f+8ccfdRs2bFh46NChw5+JAwYMOPjZZ581OnjwoOzdu9fx9ddfNyrpmCWVHzhw4P5PPvmkcUZGRjjA9u3bw9LS0iIBrrzyyj0ffPBB7CeffNL4qquu2lvM4VUVVrNrpHQcqdDr0gUuvBDatoWrrtJfhlLVWJ06dZyHDh0K6vAH/pTz9JHyXV9UH6kLLrigw6+//hqzd+/e8BYtWnS/9957t44aNeqowaOXLFlSZ9y4cW0dDgfh4eFm8uTJG1u2bFnYq1evg126dEkeMGBA1iuvvLLloosu2pOSkpLcpEmTgu7dux/y7N+vX7/Ob7755sb4+PjDzXCnnnpqdnHle/XqlTt+/PiMM888M8HlchEREWEmTZq0KSEhIT81NTX30KFDjhYtWuTHxcUVlHQOVTWJMYHV1ohIPHAW0AJ42xiTLiKRQEsg0xiTH/QoA5CammoWL17MoewDjLjrV/74uR/XXJPN6NGNQhlW7bF7Nzz5pE2akpNDHY1Syk8issQYk+q9bunSpek9evTwncFCqVpn6dKlTXv06BFf1LaAvlmIyOPAaCAMO4r5L0A6EA2sAsYDz5U91OAq1BqpymMMfPIJPPss7N8PO3bAa6/ZCYeVUkqpGsrvPlIicjNwN/AicA5w+BPSGLMfmAdcEOwAy8PT2TwiQj/MK9TWrXDbbfDPf9okqm9f27lckyillFI1XCB1NSOAD40xd4pIkyK2LwNGBies4NA+UhXM5YLZs+GFFyAnxw6mOWYMnHeeJlFK1Qwul8slDodD79hRtZbL1sq4itseyF17CcDXJWzfCVSZGWYNRpv2Ktq+ffDyyzaJOvNMO73L3/+uSZRSNceKnTt3NnR5qveVqmVcLpfs3LmzIbCiuDKBpBi5QL0StscB+wI4XsUy5nDTXni4/g0IGqfTJkphYXaC4fvus891fjylahyn03ljZmbm1MzMzBRq+HA5ShXDBaxwOp03FlcgkETqf8BFwNO+G0QkGrgK+DnQCCuKwWjTXrCtWWP7QQ0cCFdfbdedfXZoY1JKVZhevXrtAAaFOg6lqrJAvmE8CfQVkRlAd/e6liLyN+B7oC3wVHDDK58jTXtaI1UueXm2H9RVV0Famr07r7Aw1FEppZRSIed3XY0x5hsRuRWYCFzuXj3D/TMfuMkY80uQ4ysXnbQ4CP74w04yvGmTbdK77DK49Vadd0cppZQiwHGkjDFTRGQeMAxIxA6BsBaYZYw5Zg6hUHO5bCKlwx+UQX4+PPecnWQYoEMHeOAB6N69xN2UUkqp2iTg3kPGmEzg+QqIJeh00uJyCA+3faLCwuwkwzfcoPPjKaWUUj5qdDdsT2dzrZHyU1YWFBRA06bgcMBDD0Furp1sWCmllFLH8DuREpHv/ChmjDFnliOeoPI07elde6UwBr79Fp54AhITYeJE2x+qfftQR6aUUkpVaYGkGB2x8+v57t8Ke/ffLuCQ706hpHft+WHXLnjsMfj+e7ucmwvZ2VCvpCHDlFJKKQWB3bUXX9R6EYnCTmR8HdAvOGEFh6tQ59orljHw8cfwzDNw8CDUrQt33AEXXWSb9ZRSSilVqnI3ehlj8oD/iEgS8AxwWbmjCgJjjDbtFcflgjvvhAUL7PLJJ8P990OLFiENSymllKpugpli/AT8J4jHK7dC7WxeNIfD9oVauRLuusuOVK7z4ymllFIBC2YbTgcgoPvjRWSgiKwRkXUicm8R20eLyCoRWSYi34pInL/HNuhce0fZsAEWLTqyfOONMHs2nHuuJlFKKaVUGQVy115xt3DFAmcBt2OnivH3eGHAi8DZwBZgkYjMM8as8ir2O5BqjMl2j6r+BPB//p5D59rDDmfw5pvw2msQEwPvvw8NGtgxoWJjQx2dUkopVa0FkmKkc+xdex4CrMEmU/7qDawzxmwAEJGZwIXA4UTKGDPfq/yvwJUBHF+b9latgkcegbVr7XK/ftqRXCmllAqiQBKpCRybSBlgD5AGfGOMcQVwvDbAZq/lLcBJJZS/Afi8qA0iMhwYDtDea+wjV20d/iAvD155Bd56y3Ysb9MGxo+HE08MdWRKKaVUjRLI8AcPV2AcJRKRK4FUihlewRgzBZgCkJqaejjZK3Q5cFALm/buugt++cXWPl1xBdxyC9SpE+qolFJKqRrHrxRDROoDS4HnjTHPBencGUA7r+W27nW+5z4LuB/o5x5qwW/GVUvHkbrqKtixw04ynJIS6miUUkqpGsuvDjPGmINAE+BgEM+9COgiIh1EJBK4FJjnXUBETgBeAQYZY3YEeoJaM7L5Tz/Bq68eWe7dG959V5MopZRSqoIF0uj1K7Z5bWowTmyMcYrISOBLIAx43RizUkQmAIuNMfOAJ4H6wGyxt+hvMsYM8vcchYUOCK/BNVL79sHTT8Pn7q5jp5wCSUn2uXYqV0oppSpcIInUvcB3IrIQeMMYU9wdfH4zxnwGfOaz7kGv52eV5/g1dhwpY+Drr+0kw/v2QVQU3HqrHWRTKaWUUpWmxETKPXbUTmNMDnb6l73YGqknRGQ9kO2zizHGnFkhkQbImCN37dWoGqkdO+wkwz/8YJd79bJ35LVrV/J+SimllAq60mqk/sKO3fQu0BE73MEm97YqPTGbp77M4YCwsBqUSL3yik2i6tWz8+UNHqwjkyullFIhUloiJe4Hxpj4Co8miJxO+7NGdBVyuY68kJEj7WjlI0dC8+ahjUsppZSq5WpCmlEkpxMwEB5e7q5coeNywdtvww032OQJoHFjmDBBkyillFKqCqixQ1U63XlHWFho4yiz9ettwrRypV3+8UcYMCC0MSmllFLqKP4kUqeJSCAjoE8vRzxB43Tamqhql0gVFMC0afD667ZarXlzGDcOTjst1JEppZRSyoc/CdLheexKIdjO6FUikSp02WCqVdPeqlXwz3/a2iiAIUPg9tuhfv3QxqWUUkqpIvmTSE3BDsZZrdjO5qZ6dTZPS7NJVNu2dnqXXr1CHZFSSimlSuBPIvWjMeadCo8kyJxOz2CcVbxGatcuaNrUPr/wQpsBnn8+REeHNi6llFJKlao61dcExFUIIFW3j9TBg/Dvf9txoLZssetE4OKLNYlSSimlqokam0h5mvaqZCL1ww8wbBh8+KENdMWKUEeklFJKqTKoscMfFLqqYNPe3r3w5JPw1Vd2OSUFHnwQOnYMbVxKKaWUKpMSEyljTLWtsfKMbF5laqR+/RXuvx+ysmzT3YgRcOmlNWTodaWUUqp2qrE1Up5EKryqvMLmzSE7G3r3tglVmzahjkgppZRS5VRV0oygs53NISwsRE17Lhf8/DOceqrtRN6xI7z5JnTpopMMK6WUUjVEjW1XKgjlFDGbNsEtt8CoUfDll0fWJyRoEqWUUkrVIDW2RupI014l1kgVFtpJhl9+GfLz7QTDOpSBUkopVWPV2ESq0D0gZ6X15V67Fh55xE7zAnDeeTBmDDRsWEkBKKWUUqqy1dhEqlI7my9caOfEKyyEFi1sZ/KTT66EEyullFIqlGpsIlXoAkwldTY//ng7P17v3jByJNSrV/HnVEoppVTI1dhEyukUkArqbJ6TA2+8AVdeCTExEBVl+0ZpfyillFKqVqmxiZSrEDAV0LT3v//Bv/4FW7fCnj22GQ80iVJKKaVqoRqbSB0Z2TxITXsHDsBzz8FHH9nlhAQYMiQ4x1ZKKaVUtVRzE6lCMASpae/77+Gxx2DXLoiIgJtugquvrkLDpiullFIqFGpsJlBY6Jm0uJwHSkuDu+6yz7t3t5MMx8eX86BKKaWUqglqbiIVrKa9hAS45BKIi4Nhw3SSYaWUUkodVmOzAmehCyhDjdT27XZql2XLjqy75x74v//TJEoppZRSR6mxNVJOpwDG/xoplws++ACefx6ysyErC15/vUJjVEoppVT1VoMTKfvTr87mmzbZ6V1+/90uDxgAY8dWWGxKKaWUqhlqbCJV6E8iVVgIb70Fr7xiJxmOjYV777WJlFJKKaVUKWpsIuX05669/fvhzTdtEnX++TB6NDRoUDkBKqWUUqraq7mJlBNAjk2k8vNtp/HwcGjcGB54wI5K3rdvCKJUSimlVHVWY29DKyy0P8PD5cjKZcvg8sthxowj6844Q5MopZRSSpVJzU2knF5Ne9nZ8OSTcMMNkJ4OX399JNNSSimllCqjkCZSIjJQRNaIyDoRubeI7VEi8p57+0IRiff32O5hpIjauN6OAfXeeyAC118Pb7wRpLljlFJKKVWbhSyREpEw4EXgXCAJuExEknyK3QDsNcZ0Bp4FHvf3+M7cQuru2U+9t96Ebduga1d7h96IERAZGayXoZRSSqlaLJQ1Ur2BdcaYDcaYfGAmcKFPmQuBN93P3wfOFBHBD4UmDIezkPAIgZEj7d15CQlBC14ppZRSKpR37bUBNnstbwFOKq6MMcYpIllAE2CXdyERGQ4MB2jfvj0APXvWIXtwQ1oOHQ0Xtq+QF6CUUkqp2q1GDH9gjJkCTAFITU01AFdcEc4VV7QJaVxKKaWUqtlCmUhlAO28ltu61xVVZouIhAMNgd0lHXTJkiW7RGSje7EpPrVXtZReB0uvg14DD70Olvd1iAtlIEpVV6FMpBYBXUSkAzZhuhS43KfMPOAa4BfgYuA7Y0yJsxAbY5p5novIYmNMalCjrob0Olh6HfQaeOh1sPQ6KFV+IUuk3H2eRgJfAmHA68aYlSIyAVhsjJkHvAbMEJF1wB5ssqWUUkopVSWEtI+UMeYz4DOfdQ96Pc8FhlV2XEoppZRS/qixI5u7TQl1AFWEXgdLr4NeAw+9DpZeB6XKSUrpcqSUUkoppYpR02uklFJKKaUqjCZSSimllFJlVCMSqYqc/Lg68eM6jBaRVSKyTES+FZEaN25MadfAq9xQETEiUiNv/fbnOojIJe73w0oReaeyY6wMfvyfaC8i80Xkd/f/i/NCEWdFEpHXRWSHiKwoZruIyCT3NVomIj0rO0alqrNqn0hV9OTH1YWf1+F3INUY0x07d+ETlRtlxfLzGiAiMcAdwMLKjbBy+HMdRKQLMA44xRiTDNxZ2XFWND/fD+OBWcaYE7DDq0yu3CgrxRvAwBK2nwt0cT+GAy9VQkxK1RjVPpGigic/rkZKvQ7GmPnGmGz34q/Y0eRrEn/eCwCPYJPp3MoMrhL5cx1uAl40xuwFMMbsqOQYK4M/18EADdzPGwJbKzG+SmGM+QE7Dl9xLgSmG+tXoJGItKqc6JSq/mpCIlXU5Me+k+wdNfkx4Jn8uCbx5zp4uwH4vEIjqnylXgN3s0U7Y8ynlRlYJfPnvZAAJIjIzyLyq4iUVGNRXflzHR4GrhSRLdgx7W6rnNCqlED/diilvNSISYtVYETkSiAV6BfqWCqTiDiAZ4BrQxxKVRCObcrpj62Z/EFEjjPG7AtlUCFwGfCGMeZpEemLnUkhxRjjCnVgSqnqoSbUSAUy+TH+Tn5cDflzHRCRs4D7gUHGmLxKiq2ylHYNYoAU4HsRSQf6APNqYIdzf94LW4B5xpgCY8xfQBo2sapJ/LkONwCzAIwxvwDR2Il8axO//nYopYpWExKpw5Mfi0gktsPoPJ8ynsmPwc/Jj6uhUq+DiJwAvIJNompin5gSr4ExJssY09QYE2+Micf2ExtkjFkcmnArjD//J+Zia6MQkabYpr4NlRhjZfDnOmwCzgQQkW7YRGpnpUYZevOAq9137/UBsowx20IdlFLVRbVv2tPJjy0/r8OTQH1gtruv/SZjzKCQBR1kfl6DGs/P6/AlcI6IrAIKgbuNMTWqltbP6zAGeFVERmE7nl9b075kici72KS5qbsv2ENABIAx5mVs37DzgHVANnBdaCJVqnrSKWKUUkoppcqoJjTtKaWUUkqFhCZSSimllFJlpImUUkoppVQZaSKllFJKKVVGmkgppZRSSpWRJlKq0onIwyJiRCQ+1LFUpkBft4hc6y7fv0IDU0opVWaaSKlSiUh/9wd6cY8+oY7RXyISX0T82SKyQkQeEpE6lRxPf3eC1agyz+svEfne51oViMhWEXlPRFLKeezBIvJwkEJVSqmQqPYDcqpK9S528D5f6yo7kCD4Gpjuft4M+D/sBLYnA3+roHP+C3gM8J6apz92gMQ3gH0+5WcAM4H8CorHX3nAje7ndYBe2EEbzxORVGPMmjIedzB2xoGHyxugUkqFiiZSKhC/GWPeCnUQQZLm/VpE5HnslCLniMiJxphFwT6hMcYJOAMoX4gddTzUnD6/91fdI6JPBEYCt4UmLKWUCj1t2lNBISK9ReQNEUlzN5UdEJGfReQiP/ePFZFnRWS9iOSKyG4RWSIidxdR9v9E5Cf3ObJFZKGIXFye+N1Jzrfuxc5e57pRRH4TkRwRyRKRr0Tk1CJi+ruI/FdEdrnLbhKROSKS4FXmqD5SIvIGtjYK4C+v5rOH3duP6iMlIue6l28v6jWIyC8islNEIrzWdRGRGSKyTUTyRSRdRJ4UkXplvliW51odNdGxv+8DEfke9/yXPk2H13qVaSUiL7mvZb67SXGKiDQvZ+xKKRU0WiOlAlFX7AS33vKMMQeAi4BEYBawEWiC/aCcIyJXGGPeKeXYs4HTgZeBZdgmpG7Ypq8nPYVE5F/A/cAXwAOAy33u2SIy0hjzYjlenycp2OU+1+PAPcD/gPuAGGA4MF9ELjTGfOYu1w878esK4D/YJrrWwFnYpCytmPO9AjRwxz/Kc1736y/KV0AmcDUwyXuDiHQB+gCTjDEF7nW9gO/c8bwCZAA9gNuBU0Skn6dsGXRy/9zjs97f98G/sV/kTgOu8tp/gTv29sAvQCR2rsz12Gt5K3CGu0kxq4yxK6VU8Bhj9KGPEh/YZMYU85jpLlOviP3qAmuAVT7rH3bvG+9ebuhenlxKHD3d5R4tYttcYD8QU8ox4t3HmAo0dT+6YfsvGeAvIAroik3SfgIivfZvjU1M0oEw97pn3Ps2L+XcR73u4tZ5bbvWva2/17on3euSfMo+4l7f02vdUmC17zXBJjueCXpL+91/Dxz0ulbtsH2b0t3HOM+nfCDvgzfsn6Aiz/sRsANo67M+Fds8+nCo/1/oQx/60IcxRpv2VECmAGf7PP4FYIw55CkkInVFpAn2A/Q7oJuINCjhuDnYDs0nSclDA1yB/fB+U0Saej+wNUIxQF8/X8sNwE73YxW2lusH4BxjTB5wISDAE8aYw529jTFbgWlAHHCCe7WnZmSoiFR0Le+b7p9Xe1aIiABXAiuMMb+51x0HdAfeAaJ8rtVPwCHgHD/PWY8j12oT8CG2puga466V8yjn+8CzX0PgfOzvNNcn9nTszQ3+xq6UUhVKm/ZUINYaY74paoO738q/sAlIUX1YGmFrjI5hjMkXkTuxnZf/cndk/g6Ya4z51qtoN2xys7qEGFuU8ho8PgJewCZmucA6Y8x2r+0d3D9XFrGvZ11HYLH7OBcCk4HHReQnbNPju8aYnX7G4xdjzAoR+Q24QkTuM8a4sE2i8dhmSI9u7p//dD+K4u+1ygUucD+PxSZxZ1NEH8vyvA+8dHUf+wb3oygbSgtaKaUqgyZSqtzcNSJfYT+8J2KTiyzsHWfXAZdTyo0NxpiXReQj4O9AP+BiYKSIvGeMudRzKmzicy7F381WVOJTlC3FJYWBMsbsFpETsf19zsYmNs8C/xSR84wxvwTjPF6mA88BA4BvsIlNIeB9Z524fz6NTeqKstfP8xV6XysReR/4BJgiIr8ZY5a515f7feAT+1scqYHzleNn7EopVaE0kVLB0B3biXmCMeYh7w0icmPRuxzLGLMN23dpqoiEYcdRukxEnjZ2OIK1wEBgkzHmz6BFXzRPjUcytqOztySfMhg7VMH37gci0h1YAozHJofFMWWI7R1sX6mrReRnbNL5tfv6eax1/ywMVsLoYYxxicgd2CbRpzjSzBbo+6C4177OvS0y2LErpVSwaR8pFQye2iHxXil25OtShz9w96Wp673OnZh47l6Ldf+c4f75qDvR8j2Ov01V/piH/TC/22c4gVbY2pWNwO/udb53MoJtfszhSOzFOej+WVq5w9zNhZ8DQ7D9xhpwbM3N79i7CG8RkY6+xxCRcBHx+5xFxLAWm9Cd7TUcRKDvg4Pu7UfFYYzZjR34dYgUMWq+WM3KGrtSSgWT1kipYPgT26R2jzshWgMkADcDy7EjYZckAfiviHyI/fDfi20euhV7F92PAMaYRe4xlh4G/hCR2cBWoJX7HOdhO0GXmzFmjYg8ie139IOIvMeR4Q/qA1e4kz2wA1S2xTZrbcQO3fB/7vLTjzn40X51/3xcRN7G9kdaYYxZUcp+bwKDsE13Wdi7Fr3jNyJyFbav2TIReR37O6qLHUZgCDAOe+dcWT2K7eT+T+BMAn8f/Iod0HOyiHwKFAALjTF/YX/3P2Gv/XRsYujA9ku7EHtdHy5H7EopFRSaSKlyM8YUisjfsc0812Dv8lrhft6D0hOpzcDrwBnYW+ujsGMevQo8bozJ9jrXP0VkMXYspDvd59rhPl+RA1WWlTFmrIisA0Zgp3bJBxYClxtjfvQqOgM7VME12Olm9mObvS42xnxQyjl+FpGxwC3Y1xuOTUxKS6Q+wY7hFAtMNcbkFnHsP0TkBGzCNMh9jgPYO9/e4MigmmXiTjZnAZe6x6T6b4Dvg3exdz5eCgzDJkrXAX8ZYza7x8Eai02crsQmmZuBj7HjVCmlVMiJMWXpoqGUUkoppbSPlFJKKaVUGWkipZRSSilVRppIKaWUUkqVkSZSSimllFJlpImUUkoppVQZaSKllFJKKVVGmkgppZRSSpWRJlJKKaWUUmWkiZRSSimlVBn9P52qB/USno7HAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "inputs = x_d7.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = np.array(y_d7)\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "n_classes = 99\n",
    "\n",
    "acc_per_fold = []\n",
    "f1_per_fold = []\n",
    "time_per_fold = []\n",
    "\n",
    "acc_per_fold_plut = []\n",
    "f1_per_fold_plut = []\n",
    "time_per_fold_plut = []\n",
    "\n",
    "acc_per_fold_mwpm = []\n",
    "f1_per_fold_mwpm = []\n",
    "time_per_fold_mwpm = []\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "aucs_classes = {}\n",
    "for i in mlb_d7.classes_:\n",
    "    aucs_classes[i] = []\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for i, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "    i_train = inputs[train].copy()\n",
    "    i_test = inputs[test].copy()\n",
    "    t_test = targets[test].copy()\n",
    "    x_test_d7 = i_test[:,:2]\n",
    "    inputs_train = i_train[:,3:]\n",
    "    inputs_test = i_test[:,3:]\n",
    "    indices = np.random.choice(inputs[test].shape[0], 200, replace=False)#20000, replace=False)\n",
    "    x_test_d7 = x_test_d7[indices]\n",
    "    inputs_test_2 = inputs_test[indices]\n",
    "    targets_test_2 = targets[test][indices]\n",
    "    \n",
    "    ####################################################################################################\n",
    "    #test MWPM decoder for this fold\n",
    "    \n",
    "    decoding_d7, time_mwpm = do_new_decoding(x_test_d7, 7, 0)\n",
    "    decoding_d7['combine'] = decoding_d7[[0, 1]].values.tolist()\n",
    "    decoding_d7['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "    decoding_d7 = np.array(decoding_d7[0])\n",
    "                                              \n",
    "    time_per_fold_mwpm.append(time_mwpm)\n",
    "                                              \n",
    "    pred_mwpm = mlb_d7.transform(decoding_d7)\n",
    "\n",
    "    if fold_no < 3:\n",
    "        acc = partial_accuracy(targets_test_2, pred_mwpm)\n",
    "    else:\n",
    "        acc, contingency_mwpm = partial_accuracy_and_contingency(targets_test_2, pred_mwpm, mlb_d7)\n",
    "        \n",
    "    acc_per_fold_mwpm.append(acc)\n",
    "    f1_per_fold_mwpm.append(f1_score(targets_test_2, pred_mwpm, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #test the plut decoder for this fold\n",
    "    \n",
    "    lookup_d7 = lookup_decoder(7)\n",
    "    \n",
    "    lookup_d7 = train_plut(lookup_d7, inputs_train, targets[train])\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    pred_plut_d7 = test_plut(lookup_d7, inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    if fold_no < 3:\n",
    "        acc = partial_accuracy(targets[test], pred_plut_d7)\n",
    "        f1 = f1_score(targets[test], pred_plut_d7, average='micro')\n",
    "    else:\n",
    "        pred_plut_d7 = test_plut(lookup_d7, inputs_test_2)\n",
    "        f1 = f1_score(targets_test_2, pred_plut_d7, average='micro')\n",
    "        acc, contingency_plut = partial_accuracy_and_contingency(targets_test_2, pred_plut_d7, mlb_d7)\n",
    "        \n",
    "    acc_per_fold_plut.append(acc)\n",
    "    f1_per_fold_plut.append(f1)\n",
    "    \n",
    "    #####################################################################################################\n",
    "    #Test the NN decoder for this fold\n",
    "    \n",
    "    model_d7 = compile_FFNN_cv_model_DepthSeven(7)\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = model_d7.fit(\n",
    "        x=inputs_train ,\n",
    "        y=targets[train],\n",
    "        validation_split=.25,\n",
    "        epochs= 150)\n",
    "    \n",
    "   # Generate generalization metrics\n",
    "    scores = model_d7.evaluate(inputs_test, targets[test], verbose=0)\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    predictions_d7 = model_d7.predict(inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    #threshold based on previous tests with train_test_split in hyperparameter tuning\n",
    "    pred=predictions_d7.copy() #change here\n",
    "    pred[pred>=.5]=1 \n",
    "    pred[pred<.5]=0\n",
    "     \n",
    "    if fold_no < 3:\n",
    "        acc = scores[1]\n",
    "        f1 = f1_score(targets[test], pred, average='micro')\n",
    "    else:\n",
    "        pred = model_d7.predict(inputs_test_2)\n",
    "        pred[pred>=.5]=1 \n",
    "        pred[pred<.5]=0\n",
    "        acc, contingency_nn = partial_accuracy_and_contingency(targets_test_2, pred, mlb_d7)\n",
    "        f1 = f1_score(targets_test_2, pred, average='micro')\n",
    " \n",
    "    acc_per_fold.append(acc)\n",
    "    f1_per_fold.append(f1)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d7.ravel())\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    \n",
    "    #get the AUCs of each class, used to get average AUC of each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d7[:, i]) \n",
    "        aucs_classes[mlb_d7.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "\n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb_d7.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 7 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
