{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import precision_score,accuracy_score, f1_score, recall_score, hamming_loss\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import backend as K\n",
    "\n",
    "#%matplotlib inline\n",
    "#import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "\n",
    "print (pd.__version__)\n",
    "\n",
    "######### DEFINITION OF GLOBAL VARIABLES #########\n",
    "RUN_CONFIGURATION_LOOP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "#sys.path.append('/')\n",
    "import circuits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are super long functions to be hard coded because i dont have time to properly fix them, sorry bout it\n",
    "#[(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 1.5, -0.5), (0, 1.5, 1.5)]\n",
    "def graph_with_errs_d3(df):\n",
    "    x_data = []\n",
    "    z_data = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        x_data.append([])\n",
    "        z_data.append([])\n",
    "        \n",
    "        if df.loc[i].at[\"X0\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 0.5))\n",
    "        if df.loc[i].at[\"Z1\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 0.5))\n",
    "        if df.loc[i].at[\"X2\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 1.5))\n",
    "        if df.loc[i].at[\"Z3\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 2.5))\n",
    "        if df.loc[i].at[\"Z4\"] == -1:\n",
    "            z_data[i].append((0, 1.5, -0.5))\n",
    "        if df.loc[i].at[\"X5\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 0.5))\n",
    "        if df.loc[i].at[\"X6\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 1.5))\n",
    "        if df.loc[i].at[\"Z7\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 1.5))\n",
    "        x_data[i] = str(x_data[i])\n",
    "        z_data[i] = str(z_data[i])\n",
    "    #graph_df = pd.DataFrame(df[\"Labels\"], x_data, z_data, columns=[\"Labels\", \"XSyn\", \"ZSyn\"])\n",
    "    graph_df = pd.DataFrame({\"XSyn\":x_data, \"ZSyn\":z_data})\n",
    "    return graph_df\n",
    "        \n",
    "\n",
    "def graph_with_errs_d5(df):\n",
    "    x_data = []\n",
    "    z_data = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        x_data.append([])\n",
    "        z_data.append([])\n",
    "        if df.loc[i].at[\"X0\"] == -1:\n",
    "             x_data[i].append((0, -0.5, 0.5))\n",
    "        if df.loc[i].at[\"Z1\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 0.5))\n",
    "        if df.loc[i].at[\"X2\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 1.5))\n",
    "        if df.loc[i].at[\"X3\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 2.5))\n",
    "        if df.loc[i].at[\"Z4\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 2.5))\n",
    "        if df.loc[i].at[\"X5\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 3.5))\n",
    "        if df.loc[i].at[\"Z6\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 4.5))\n",
    "        if df.loc[i].at[\"Z7\"] == -1:\n",
    "            z_data[i].append((0, 1.5, -0.5))\n",
    "        if df.loc[i].at[\"X8\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 0.5))\n",
    "        if df.loc[i].at[\"Z9\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 1.5))\n",
    "        if df.loc[i].at[\"X10\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 2.5))\n",
    "        if df.loc[i].at[\"Z11\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 3.5))\n",
    "        if df.loc[i].at[\"Z12\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 0.5))\n",
    "        if df.loc[i].at[\"X13\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 1.5))\n",
    "        if df.loc[i].at[\"Z14\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 2.5))\n",
    "        if df.loc[i].at[\"X15\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 3.5))\n",
    "        if df.loc[i].at[\"Z16\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 4.5))\n",
    "        if df.loc[i].at[\"Z17\"] == -1:\n",
    "            z_data[i].append((0, 3.5, -0.5))\n",
    "        if df.loc[i].at[\"X18\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 0.5))\n",
    "        if df.loc[i].at[\"X19\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 1.5))\n",
    "        if df.loc[i].at[\"Z20\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 1.5))\n",
    "        if df.loc[i].at[\"X21\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 2.5))\n",
    "        if df.loc[i].at[\"X22\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 3.5))\n",
    "        if df.loc[i].at[\"Z23\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 3.5))\n",
    "        x_data[i] = str(x_data[i])\n",
    "        z_data[i] = str(z_data[i])\n",
    "            \n",
    "    graph_df = pd.DataFrame({\"XSyn\":x_data, \"ZSyn\":z_data})\n",
    "    return graph_df\n",
    "    \n",
    "def graph_with_errs_d7(df):\n",
    "    x_data = []\n",
    "    z_data = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        x_data.append([])\n",
    "        z_data.append([])\n",
    "        \n",
    "        if df.loc[i].at[\"X0\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 0.5))\n",
    "        if df.loc[i].at[\"Z1\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 0.5))\n",
    "        if df.loc[i].at[\"X2\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 1.5))\n",
    "        if df.loc[i].at[\"X3\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 2.5))\n",
    "        if df.loc[i].at[\"Z4\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 2.5))\n",
    "        if df.loc[i].at[\"X5\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 3.5))\n",
    "        if df.loc[i].at[\"X6\"] == -1:\n",
    "            x_data[i].append((0, -0.5, 4.5))\n",
    "        if df.loc[i].at[\"Z7\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 4.5))\n",
    "        if df.loc[i].at[\"X8\"] == -1:\n",
    "            x_data[i].append((0, 0.5, 5.5))\n",
    "        if df.loc[i].at[\"Z9\"] == -1:\n",
    "            z_data[i].append((0, 0.5, 6.5))\n",
    "        if df.loc[i].at[\"Z10\"] == -1:\n",
    "            z_data[i].append((0, 1.5, -0.5))\n",
    "        if df.loc[i].at[\"X11\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 0.5))\n",
    "        if df.loc[i].at[\"Z12\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 1.5))\n",
    "        if df.loc[i].at[\"X13\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 2.5))\n",
    "        if df.loc[i].at[\"Z14\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 3.5))\n",
    "        if df.loc[i].at[\"X15\"] == -1:\n",
    "            x_data[i].append((0, 1.5, 4.5))\n",
    "        if df.loc[i].at[\"Z16\"] == -1:\n",
    "            z_data[i].append((0, 1.5, 5.5))\n",
    "        if df.loc[i].at[\"Z17\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 0.5))\n",
    "        if df.loc[i].at[\"X18\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 1.5))\n",
    "        if df.loc[i].at[\"Z19\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 2.5))\n",
    "        if df.loc[i].at[\"X20\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 3.5))\n",
    "        if df.loc[i].at[\"Z21\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 4.5))\n",
    "        if df.loc[i].at[\"X22\"] == -1:\n",
    "            x_data[i].append((0, 2.5, 5.5))\n",
    "        if df.loc[i].at[\"Z23\"] == -1:\n",
    "            z_data[i].append((0, 2.5, 6.5))\n",
    "        if df.loc[i].at[\"Z24\"] == -1:\n",
    "            z_data[i].append((0, 3.5, -0.5))\n",
    "        if df.loc[i].at[\"X25\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 0.5))\n",
    "        if df.loc[i].at[\"Z26\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 1.5))\n",
    "        if df.loc[i].at[\"X27\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 2.5))\n",
    "        if df.loc[i].at[\"Z28\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 3.5))\n",
    "        if df.loc[i].at[\"X29\"] == -1:\n",
    "            x_data[i].append((0, 3.5, 4.5))\n",
    "        if df.loc[i].at[\"Z30\"] == -1:\n",
    "            z_data[i].append((0, 3.5, 5.5))\n",
    "        if df.loc[i].at[\"Z31\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 0.5))\n",
    "        if df.loc[i].at[\"X32\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 1.5))\n",
    "        if df.loc[i].at[\"Z33\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 2.5))\n",
    "        if df.loc[i].at[\"X34\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 3.5))\n",
    "        if df.loc[i].at[\"Z35\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 4.5))\n",
    "        if df.loc[i].at[\"X36\"] == -1:\n",
    "            x_data[i].append((0, 4.5, 5.5))\n",
    "        if df.loc[i].at[\"Z37\"] == -1:\n",
    "            z_data[i].append((0, 4.5, 6.5))\n",
    "        if df.loc[i].at[\"Z38\"] == -1:\n",
    "            z_data[i].append((0, 5.5, -0.5))\n",
    "        if df.loc[i].at[\"X39\"] == -1:\n",
    "            x_data[i].append((0, 5.5, 0.5))\n",
    "        if df.loc[i].at[\"X40\"] == -1:\n",
    "            x_data[i].append((0, 6.5, 1.5))\n",
    "        if df.loc[i].at[\"Z41\"] == -1:\n",
    "            z_data[i].append((0, 5.5, 1.5))\n",
    "        if df.loc[i].at[\"X42\"] == -1:\n",
    "            x_data[i].append((0, 5.5, 2.5))\n",
    "        if df.loc[i].at[\"X43\"] == -1:\n",
    "            x_data[i].append((0, 6.5, 3.5))\n",
    "        if df.loc[i].at[\"Z44\"] == -1:\n",
    "            z_data[i].append((0, 5.5, 3.5))\n",
    "        if df.loc[i].at[\"X45\"] == -1:\n",
    "            x_data[i].append((0, 5.5, 4.5))\n",
    "        if df.loc[i].at[\"X46\"] == -1:\n",
    "            x_data[i].append((0, 6.5, 5.5))\n",
    "        if df.loc[i].at[\"Z47\"] == -1: \n",
    "            z_data[i].append((0, 5.5, 5.5))\n",
    "        x_data[i] = str(x_data[i])\n",
    "        z_data[i] = str(z_data[i])\n",
    "    graph_df = pd.DataFrame({\"XSyn\":x_data, \"ZSyn\":z_data})\n",
    "    return graph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions needed to work with the GraphDecoder/MWPM module\n",
    "import time\n",
    "\n",
    "def add_measurement_errs(curr_syn, prob_err, x_syn, depth):\n",
    "    #x_syn is True if it is x syndrome, False if it is Z syndrome\n",
    "    total_time = 0\n",
    "    new_syn = []\n",
    "    if x_syn:\n",
    "        for i in curr_syn:\n",
    "            rand = random.random()\n",
    "            if rand > prob_err:\n",
    "                new_syn.append(i)\n",
    "        return (new_syn + return_xmeasurement_errs(depth, prob_err))\n",
    "    else:\n",
    "        for i in curr_syn:\n",
    "            rand = random.random()\n",
    "            if rand > prob_err:\n",
    "                new_syn.append(i)\n",
    "        return (new_syn + return_zmeasurement_errs(depth, prob_err))\n",
    "    \n",
    "def do_new_decoding(data, depth, prob_err):\n",
    "    decoder = circuits.GraphDecoder(depth,1)\n",
    "    G = decoder.S['Z']\n",
    "    #decoder.graph_2D(G,'distance')\n",
    "    df = pd.DataFrame()\n",
    "    syn = []\n",
    "    total_time = 0\n",
    "    \n",
    "    for row in data:\n",
    "        x_input = []\n",
    "        z_input = []\n",
    "        x_type = True\n",
    "        for col in row:\n",
    "            if not col == \"[]\":\n",
    "                col = eval(col)\n",
    "                for c in col:\n",
    "                    if x_type:\n",
    "                        x_input.append(c)\n",
    "                    else:\n",
    "                        z_input.append(c)\n",
    "            x_type = not x_type  \n",
    "            \n",
    "        if prob_err > 0:\n",
    "            syndromes_x = add_measurement_errs(x_input, prob_err, True, depth)\n",
    "            syndromes_z = add_measurement_errs(z_input, prob_err, False, depth)\n",
    "        else:\n",
    "            syndromes_x = x_input\n",
    "            syndromes_z = z_input\n",
    "\n",
    "        start = time.time_ns()\n",
    "        error_graph_x, paths_x = decoder.make_error_graph(syndromes_x,'X')\n",
    "        matching_graph_x = decoder.matching_graph(error_graph_x,'X')\n",
    "        matches_x = decoder.matching(matching_graph_x,'X')\n",
    "        flips_x = decoder.calculate_qubit_flips(matches_x, paths_x,'X')\n",
    "        syn_x = (translate_errors(flips_x))\n",
    "\n",
    "        error_graph_z, paths_z = decoder.make_error_graph(syndromes_z,'Z')\n",
    "        matching_graph_z = decoder.matching_graph(error_graph_z,'Z')\n",
    "        matches_z = decoder.matching(matching_graph_z,'Z')\n",
    "        flips_z = decoder.calculate_qubit_flips(matches_z, paths_z,'Z')\n",
    "        syn_z = translate_errors(flips_z)\n",
    "        df = df.append(pd.Series([syn_x, syn_z]), ignore_index=True)\n",
    "        end = time.time_ns()\n",
    "        total_time += (end - start)/ (10 ** 9)\n",
    "    return (df, total_time) \n",
    "\n",
    "import random\n",
    "def return_xmeasurement_errs(depth, prob):\n",
    "    \n",
    "    new_errs = []\n",
    "    \n",
    "    if depth == 3:\n",
    "        errs = [(0, -0.5, 0.5), (0, 0.5, 1.5), (0, 1.5, 0.5), (0, 2.5, 1.5)]\n",
    "    elif depth == 5:\n",
    "        errs = [(0, -0.5, 0.5), (0, 0.5, 1.5), (0, -0.5, 2.5), (0, 0.5, 3.5), (0, 1.5, 0.5), (0, 1.5, 2.5),\n",
    "                        (0, 2.5, 1.5), (0, 2.5, 3.5), (0, 3.5, 0.5), (0, 4.5, 1.5), (0, 3.5, 2.5), (0, 4.5, 3.5)]\n",
    "    else:\n",
    "        errs = [(0, -0.5, 0.5), (0, 0.5, 1.5), (0, -0.5, 2.5), (0, 0.5, 3.5), (0, -0.5, 4.5), (0, 0.5, 5.5),\n",
    "                        (0, 1.5, 0.5), (0, 1.5, 2.5), (0, 1.5, 4.5), (0, 2.5, 1.5), (0, 2.5, 3.5), (0, 2.5, 5.5),\n",
    "                        (0, 3.5, 0.5),  (0, 3.5, 2.5), (0, 3.5, 4.5), (0, 4.5, 1.5), (0, 4.5, 3.5), (0, 4.5, 5.5),\n",
    "                       (0, 5.5, 0.5), (0, 6.5, 1.5), (0, 5.5, 2.5), (0, 6.5, 3.5), (0, 5.5, 4.5), (0, 6.5, 5.5)]\n",
    "    for e in errs:\n",
    "        rand = random.random()\n",
    "        if rand <= prob:\n",
    "            new_errs.append(e)\n",
    "            \n",
    "    return new_errs\n",
    "            \n",
    "\n",
    "def return_zmeasurement_errs(depth, prob):\n",
    "    \n",
    "    new_errs = []\n",
    "    \n",
    "    if depth == 3:\n",
    "        errs = [(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 1.5, -0.5), (0, 1.5, 1.5)]\n",
    "    elif depth == 5:\n",
    "        errs = [(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 0.5, 4.5), (0, 1.5, -0.5), (0, 1.5, 1.5), (0, 1.5, 3.5),\n",
    "                        (0, 2.5, 0.5), (0, 2.5, 2.5), (0, 2.5, 4.5), (0, 3.5, -0.5), (0, 3.5, 1.5), (0, 3.5, 3.5)]\n",
    "    else:\n",
    "        errs = [(0, 0.5, 0.5), (0, 0.5, 2.5), (0, 0.5, 4.5), (0, 0.5, 6.5), (0, 1.5, -0.5), (0, 1.5, 1.5),\n",
    "                        (0, 1.5, 3.5), (0, 1.5, 5.5), (0, 2.5, 0.5), (0, 2.5, 2.5), (0, 2.5, 4.5), (0, 2.5, 6.5),\n",
    "                        (0, 3.5, -0.5),  (0, 3.5, 1.5), (0, 3.5, 3.5), (0, 3.5, 5.5), (0, 4.5, 0.5), (0, 4.5, 2.5),\n",
    "                       (0, 4.5, 4.5), (0, 4.5, 6.5), (0, 5.5, -0.5), (0, 5.5, 1.5), (0, 5.5, 3.5), (0, 5.5, 5.5)]\n",
    "        \n",
    "    for e in errs:\n",
    "        rand = random.random()\n",
    "        if rand <= prob:\n",
    "            new_errs.append(e)\n",
    "            \n",
    "    return new_errs\n",
    "\n",
    "def translate_errors (phys_errs):\n",
    "    flipX = np.array([(0, 1),(1, 0)])\n",
    "    flipZ = np.array([(1, 0), (0, -1)])\n",
    "    errs = []\n",
    "    str2 = \"\"\n",
    "    for qubit, flip in phys_errs.items():\n",
    "        row = int(qubit[1])\n",
    "        col = int(qubit[2])\n",
    "        if str(flip) == \"X\":\n",
    "            str1 = \"X\"\n",
    "        elif str(flip) == \"Z\":\n",
    "            str1 = \"Z\"\n",
    "        else:\n",
    "            str1 = \"X\"\n",
    "            str2 = \"Z\"\n",
    "        str1 += str(row) + str(col)\n",
    "        errs.append(str1)\n",
    "        if str2 != \"\":\n",
    "            str2 += str(row) +str(col)\n",
    "            errs.append(str2)\n",
    "            str2 = \"\"\n",
    "    return errs   \n",
    "\n",
    "def translate_to_graph(df_graph, labels, mlb):\n",
    "#go through labels given\n",
    "    indices = []\n",
    "    labels = mlb.inverse_transform(labels)\n",
    "    \n",
    "    for row in labels:\n",
    "        label_str = str(row)\n",
    "        for index, r in df_graph.iterrows():\n",
    "            if label_str == \"('',)\":\n",
    "                if str(r[\"Labels\"]) == \"[' ']\":\n",
    "                    indices.append([index])\n",
    "                    break\n",
    "            if set(row) == set(r[\"Labels\"]):\n",
    "                indices.append([index])\n",
    "                break\n",
    "\n",
    "    df_syns = df_graph.drop(['Labels'], axis=1)\n",
    "    return_df = pd.DataFrame()\n",
    "    for i in indices:\n",
    "        return_df = return_df.append(df_syns.loc[i])\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function needed for preprocessing. CSV file reads in a string, needs to be a list for labels \n",
    "#for preprocessing csv files\n",
    "def create_list_from_string(err_list):\n",
    "    newstring = err_list.replace(\"'\", \"\")\n",
    "    new_err_list = newstring.strip('][').split(', ')\n",
    "    return sorted(set(new_err_list))\n",
    "\n",
    "\n",
    "def create_string_from_list(err_list):\n",
    "    return_string = \"[\"\n",
    "    if err_list[0] == \"''\":\n",
    "        return \"[' ']\"\n",
    "    else:\n",
    "        for index, i in enumerate(err_list):\n",
    "            return_string = return_string +  \"'\" + i + \"'\"\n",
    "            if index < (len(err_list)-1):\n",
    "                return_string += \", \"\n",
    "    return return_string + \"]\"\n",
    "        \n",
    "\n",
    "#take in two 2d arrays of predicted values, true values, and threshold to determine labels. \n",
    "#calculates the partial accuracy of the predicted values, averaged out for all obersvations\n",
    "def partial_accuracy(y_pred, y_true):\n",
    "    total = 0\n",
    "    rows = y_pred.shape[0]\n",
    "    cols = y_pred.shape[1]\n",
    "    for i in range(0, rows):\n",
    "        row_correct = 0\n",
    "        for j in range(0, cols):\n",
    "            if y_pred[i,j] == y_true[i,j]:\n",
    "                row_correct += 1\n",
    "        total += row_correct/cols\n",
    "    return total/rows\n",
    "\n",
    "def partial_accuracy_and_contingency(y_pred, y_true, mlb):\n",
    "    total = 0\n",
    "    a= np.zeros(shape=y_true.shape)\n",
    "    rows = y_pred.shape[0]\n",
    "    cols = y_pred.shape[1]\n",
    "    df = pd.DataFrame(a, columns = mlb.classes_)\n",
    "    for i in range(0, rows):\n",
    "        row_correct = 0\n",
    "        for j, label in enumerate(mlb.classes_):\n",
    "            if y_pred[i,j] == y_true[i,j]:\n",
    "                row_correct += 1\n",
    "                df.at[i, label] = 1\n",
    "            else:\n",
    "                df.at[i, label] = 0\n",
    "\n",
    "        total += row_correct/cols\n",
    "\n",
    "    return (total/rows, df)\n",
    "\n",
    "def contingency_table_and_t (clf1, clf2):\n",
    "    a = 0 #clf1 pos, clf2 pos\n",
    "    b = 0 #clf1 pos, clf2 neg\n",
    "    c = 0 #clf1 neg, clf2 pos\n",
    "    d = 0 #clf1 neg, clf2 neg\n",
    "    \n",
    "    for index, value in clf1.items():\n",
    "        if value == 1 and clf2[index] == 1:\n",
    "            a+=1\n",
    "        elif value == 1 and clf2[index] == 0: #classifier 1 right, classifier 2 wrong\n",
    "            b+=1\n",
    "        elif value == 0 and clf2[index] == 1: #classifier 1 wrong, classifier 2 right\n",
    "            c+=1\n",
    "        else:\n",
    "            d+=1\n",
    "    print(\"[\"+str(a)+\", \"+str(b)+\"]\")\n",
    "    print(\"[\"+str(c)+\", \"+str(d)+\"]\")\n",
    "    if b == 0 and c ==0:\n",
    "        print(\"both b and c are zero\")\n",
    "        t=0\n",
    "    else:\n",
    "        t = (((b-c)-1)**2)/(b+c)\n",
    "    return ([[a,b],[c,d]], t)\n",
    "\n",
    "def add_noise(val, noise_level):\n",
    "    rand = random.uniform(0, 1)\n",
    "    if rand <= noise_level:\n",
    "        if val == -1:\n",
    "            val = 1\n",
    "        elif val == 1:\n",
    "            val = -1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_d7= trainData_d7.dropna()\n",
    "#######################################################################################################\n",
    "\"\"\"\n",
    "trainData_d7 = pd.read_csv(\"depth7_all_combos.csv\")\n",
    "trainData_d7 = trainData_d7.applymap(lambda x: add_noise(x,.01))\n",
    "\n",
    "#These four lines remove duplicates\n",
    "trainData_d7['Labels'] = trainData_d7['Labels'].map(lambda x: create_list_from_string(x))\n",
    "trainData_d7['Labels'] = trainData_d7['Labels'].astype(str)\n",
    "trainData_d7 = trainData_d7.drop_duplicates('Labels', keep='first', ignore_index=True)\n",
    "trainData_d7['Labels'] = trainData_d7['Labels'].map(lambda x: create_list_from_string(x))\n",
    "\n",
    "testData_d7_MWPM = graph_with_errs_d7(trainData_d7)\n",
    "\n",
    "#transforms the data to encoding for ML\n",
    "mlb_d7 = MultiLabelBinarizer()\n",
    "mlb_d7.fit(trainData_d7['Labels'])\n",
    "df = pd.DataFrame(mlb_d7.transform(trainData_d7['Labels']))\n",
    "df['Labels']= df.values.tolist()\n",
    "trainData_d7 = trainData_d7.drop(['Labels'], axis=1)\n",
    "trainData_d7 = pd.concat([df[\"Labels\"],testData_d7_MWPM, trainData_d7], axis=1, ignore_index=True)\n",
    "trainData_d7.columns = [\"Labels\",\"XSyn\", \"ZSyn\",\"X0\", \"Z1\", \"X2\", \"X3\", \"Z4\", \"X5\", \"X6\", \"Z7\", \"X8\", \"Z9\", \"Z10\", \"X11\", \"Z12\", \"X13\", \"Z14\", \"X15\", \"Z16\", \"Z17\", \"X18\", \"Z19\",\"X20\", \"Z21\", \"X22\", \"Z23\", \"Z24\", \"X25\", \"Z26\", \"X27\", \"Z28\", \"X29\", \"Z30\", \"Z31\", \"X32\", \"Z33\", \"X34\", \"Z35\", \"X36\", \"Z37\", \"Z38\", \"X39\", \"X40\", \"Z41\", \"X42\", \"X43\", \"Z44\", \"X45\", \"X46\", \"Z47\"]\n",
    "\"\"\"\n",
    "#######################################################################################\n",
    "\"\"\"\n",
    "trainData_d5 = pd.read_csv(\"depth5_all_combos.csv\")\n",
    "trainData_d5 = trainData_d5.applymap(lambda x: add_noise(x,.01)) #was .05\n",
    "#These four lines remove duplicates\n",
    "trainData_d5['Labels'] = trainData_d5['Labels'].map(lambda x: create_list_from_string(x))\n",
    "trainData_d5['Labels'] = trainData_d5['Labels'].astype(str)\n",
    "trainData_d5 = trainData_d5.drop_duplicates('Labels', keep='first', ignore_index=True)\n",
    "trainData_d5['Labels'] = trainData_d5['Labels'].map(lambda x: create_list_from_string(x))\n",
    "\n",
    "\n",
    "testData_d5_MWPM = graph_with_errs_d5(trainData_d5)\n",
    "\n",
    "\n",
    "#transforms the data to encoding for ML\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(trainData_d5['Labels'])\n",
    "df = pd.DataFrame(mlb.transform(trainData_d5['Labels']))\n",
    "df['Labels']= df.values.tolist()\n",
    "trainData_d5 = trainData_d5.drop(['Labels'], axis=1)\n",
    "trainData_d5 = pd.concat([df[\"Labels\"], testData_d5_MWPM, trainData_d5], axis=1, ignore_index=True)\n",
    "trainData_d5.columns = [\"Labels\",\"XSyn\", \"ZSyn\",\"X0\",\"Z1\",\"X2\",\"X3\",\"Z4\",\"X5\",\"Z6\",\"Z7\",\"X8\",\"Z9\",\"X10\",\"Z11\",\"Z12\",\"X13\",\"Z14\",\"X15\",\"Z16\",\"Z17\",\"X18\",\"X19\",\"Z20\",\"X21\",\"X22\",\"Z23\"]\n",
    "\"\"\"\n",
    "#########################################################################################\n",
    "\n",
    "#Has no duplicates, small enough to check manually\n",
    "trainData_d3 = pd.read_csv(\"depth3_all_combos.csv\")\n",
    "\n",
    "trainData_d3[\"Labels\"] = trainData_d3['Labels'].map(lambda x: create_list_from_string(x))\n",
    "trainData_d3 = trainData_d3.applymap(lambda x: add_noise(x,.01))\n",
    "\n",
    "testData_d3_MWPM = graph_with_errs_d3(trainData_d3)\n",
    "\n",
    "mlb_d3 = MultiLabelBinarizer()\n",
    "mlb_d3.fit(trainData_d3[\"Labels\"])\n",
    "df = pd.DataFrame(mlb_d3.transform(trainData_d3['Labels']))\n",
    "df['Labels']= df.values.tolist()\n",
    "trainData_d3 = trainData_d3.drop(['Labels'], axis=1)\n",
    "trainData_d3 = pd.concat([df['Labels'], testData_d3_MWPM, trainData_d3], axis=1, ignore_index=True)\n",
    "trainData_d3.columns = [\"Labels\",\"XSyn\", \"ZSyn\", \"X0\", \"Z1\", \"X2\", \"Z3\", \"Z4\", \"X5\", \"X6\", \"Z7\"]\n",
    "#########################################################################################\n",
    "y_d3 = trainData_d3[\"Labels\"]\n",
    "x_d3 = trainData_d3.drop([\"Labels\"], axis=1)\n",
    "\n",
    "#y_d5 = trainData_d5[\"Labels\"] \n",
    "#x_d5 = trainData_d5.drop([\"Labels\"], axis=1) \n",
    "\n",
    "#y_d7 = trainData_d7[\"Labels\"]\n",
    "#x_d7 = trainData_d7.drop([\"Labels\"], axis=1)\n",
    "\n",
    "\n",
    "x_d3 = x_d3.replace([-1], 0)\n",
    "#x_d5 = x_d5.replace([-1], 0)\n",
    "#x_d7 = x_d7.replace([-1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_d7 = trainData_d7[\"Labels\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for creating lookup tables here:\n",
    "from collections import defaultdict\n",
    "from math import log2\n",
    "\n",
    "def generateAllBinaryStrings(n, arr, i, lookup):  \n",
    "    if i == n: \n",
    "        lookup.setBitStringArray(arr, n)  \n",
    "        return\n",
    "      \n",
    "    # First assign \"0\" at ith position  \n",
    "    # and try for all other permutations  \n",
    "    # for remaining positions  \n",
    "    arr[i] = 0\n",
    "    generateAllBinaryStrings(n, arr, i + 1, lookup)  \n",
    "  \n",
    "    # And then assign \"1\" at ith position  , \n",
    "    # and try for all other permutations  \n",
    "    # for remaining positions  \n",
    "    arr[i] = 1\n",
    "    generateAllBinaryStrings(n, arr, i + 1, lookup)\n",
    "\n",
    "class lookup_decoder:\n",
    "    \n",
    "    def __init__(self, depth):\n",
    "        #self.lookupTable = defaultdict()\n",
    "        self.lookupTable = {}\n",
    "        self.distributions = {}\n",
    "        self.depth = depth\n",
    "        #generating all possible syndrome observations\n",
    "        #arr = [None] * (depth**2 - 1)\n",
    "        #generateAllBinaryStrings((depth**2 - 1), arr, 0, self)\n",
    "        \n",
    "    def setBitStringArray(self, arr, n): \n",
    "        new_str = \"\"\n",
    "        for i in range(0, n):  \n",
    "            new_str += str(arr[i])\n",
    "        self.lookupTable.update({new_str:defaultdict()})  \n",
    "        \n",
    "    def update_table (self, syndrome, phys_errs):\n",
    "        #all the keys are made in the init, so simply update the physical error combinations for the given syndrome\n",
    "        if syndrome not in self.lookupTable:\n",
    "            self.lookupTable[syndrome] = {}\n",
    "            self.lookupTable[syndrome][phys_errs] = 1\n",
    "            return\n",
    "        \n",
    "        if phys_errs not in self.lookupTable[syndrome]:\n",
    "            self.lookupTable[syndrome].update({phys_errs: 1})\n",
    "        else:\n",
    "            self.lookupTable[syndrome][phys_errs] += 1\n",
    "     \n",
    "    def get_probable_error(self, syndrome):\n",
    "        return_key = []\n",
    "\n",
    "        if syndrome not in self.lookupTable.keys():\n",
    "            for i in range(2* int(self.depth**2) + 1):\n",
    "                return_key.append(0)\n",
    "            return return_key\n",
    "        \n",
    "        key, value = max(self.lookupTable[syndrome].items(), key=lambda x:x[1])\n",
    "        \n",
    "        for character in key:\n",
    "            if character == '0' or character == '1':\n",
    "                return_key.append(int(character))\n",
    "                \n",
    "        return return_key\n",
    "        \n",
    "    def make_distribution_graph(self, syn):\n",
    "        \n",
    "        plt.bar(list(self.lookupTable[syn].keys()), self.lookupTable[syn].values(), color='g')\n",
    "        plt.show()\n",
    "        \n",
    "    def syndrome_count_graph(self):\n",
    "        graph_dict = {}\n",
    "        for syn in self.lookupTable:\n",
    "            graph_dict.update({syn:sum(self.lookupTable[syn].values())})\n",
    "        plt.ylim((0,4))\n",
    "        plt.bar(graph_dict.keys(), graph_dict.values())\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def length_of_lookup(self):\n",
    "        print(len(self.lookupTable))\n",
    "        \n",
    "            \n",
    "    def get_entropies(self):\n",
    "        entropies = {}\n",
    "        for syn in self.lookupTable:\n",
    "            total = sum(self.lookupTable[syn].values())\n",
    "            h = 0\n",
    "            for key in self.lookupTable[syn]:\n",
    "                p = self.lookupTable[syn][key]/total\n",
    "                h += p+log2(p)\n",
    "            entropies[syn] = -h\n",
    "        print(entropies)\n",
    "            \n",
    "    def get_syndromes(self):\n",
    "        return self.lookupTable.keys()\n",
    "                     \n",
    "    def print_lookup(self):\n",
    "        for syn in self.lookupTable:\n",
    "            print(self.lookupTable[syn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_plut(table, data_x, data_y):\n",
    "    i = 0\n",
    "    for index, x in enumerate(data_x):\n",
    "        syn = \"\".join([str(i) for i in x])\n",
    "        syn = syn.replace(\".0\",\"\")\n",
    "        labels = np.array2string(np.array(data_y[i]), precision=1, separator='',suppress_small=True).replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "        table.update_table(syn, labels)\n",
    "        i+=1\n",
    "    return table\n",
    "\n",
    "\n",
    "def test_plut(table, test_set):\n",
    "    predictions_lookup = []\n",
    "    for index, x in enumerate(test_set):\n",
    "        syn_x = \"\".join([str(i) for i in x])\n",
    "        syn_x = syn_x.replace(\".0\",\"\")\n",
    "        predictions_lookup.append(table.get_probable_error(syn_x))\n",
    "    return np.array(predictions_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_FFNN_model_DepthThree(depth):\n",
    "    model = Sequential()\n",
    "    layers = 2\n",
    "    #input layer\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    \n",
    "    #hidden layers go here\n",
    "    for i in range(layers):\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(19 , activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(lr=0.05),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#make any needed changes here\n",
    "def compile_FFNN_model_DepthFive(depth):\n",
    "    model = Sequential()\n",
    "    layers = 4\n",
    "    \n",
    "    #input layer\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    \n",
    "    #hidden layers go here\n",
    "    for i in range(layers):\n",
    "        model.add(Dense(240, activation='relu'))\n",
    "    \n",
    "    #model.add(Dense((2*depth**2) , activation='sigmoid'))\n",
    "    model.add(Dense(51, activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(learning_rate=0.05),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "#make any needed changes here\n",
    "def compile_FFNN_model_DepthSeven(depth):\n",
    "    model = Sequential()\n",
    "    layers = 4\n",
    "    \n",
    "    #input layer\n",
    "    model.add(Dense(48, activation='relu'))\n",
    "    \n",
    "    #hidden layers go here\n",
    "    for i in range(layers):\n",
    "        model.add(Dense(400, activation='relu'))\n",
    "    \n",
    "    #model.add(Dense((2*depth**2) , activation='sigmoid'))\n",
    "    model.add(Dense(99, activation='sigmoid'))\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.SGD(learning_rate=0.05),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Train on 17 samples, validate on 5 samples\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.5170 - val_loss: 0.6666 - val_accuracy: 0.5684\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6766 - accuracy: 0.5201 - val_loss: 0.6646 - val_accuracy: 0.5789\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6745 - accuracy: 0.5232 - val_loss: 0.6627 - val_accuracy: 0.5895\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.6724 - accuracy: 0.5294 - val_loss: 0.6607 - val_accuracy: 0.6105\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.6703 - accuracy: 0.5418 - val_loss: 0.6588 - val_accuracy: 0.6105\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6683 - accuracy: 0.5449 - val_loss: 0.6568 - val_accuracy: 0.6105\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6661 - accuracy: 0.5542 - val_loss: 0.6548 - val_accuracy: 0.6000\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6640 - accuracy: 0.5604 - val_loss: 0.6529 - val_accuracy: 0.6000\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6619 - accuracy: 0.5728 - val_loss: 0.6509 - val_accuracy: 0.5895\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6597 - accuracy: 0.5789 - val_loss: 0.6488 - val_accuracy: 0.5895\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.6574 - accuracy: 0.5851 - val_loss: 0.6468 - val_accuracy: 0.5895\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.6552 - accuracy: 0.5882 - val_loss: 0.6447 - val_accuracy: 0.5789\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.6529 - accuracy: 0.5913 - val_loss: 0.6426 - val_accuracy: 0.5789\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6506 - accuracy: 0.5913 - val_loss: 0.6405 - val_accuracy: 0.5789\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6483 - accuracy: 0.6130 - val_loss: 0.6384 - val_accuracy: 0.5895\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.6460 - accuracy: 0.6285 - val_loss: 0.6362 - val_accuracy: 0.6000\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6437 - accuracy: 0.6316 - val_loss: 0.6340 - val_accuracy: 0.6105\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.6413 - accuracy: 0.6316 - val_loss: 0.6318 - val_accuracy: 0.6316\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6389 - accuracy: 0.6533 - val_loss: 0.6296 - val_accuracy: 0.6526\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6365 - accuracy: 0.6533 - val_loss: 0.6274 - val_accuracy: 0.6526\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6341 - accuracy: 0.6718 - val_loss: 0.6252 - val_accuracy: 0.6526\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6316 - accuracy: 0.6718 - val_loss: 0.6229 - val_accuracy: 0.6526\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6292 - accuracy: 0.6904 - val_loss: 0.6205 - val_accuracy: 0.6737\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6267 - accuracy: 0.7090 - val_loss: 0.6181 - val_accuracy: 0.6737\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6241 - accuracy: 0.7245 - val_loss: 0.6157 - val_accuracy: 0.6842\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6215 - accuracy: 0.7245 - val_loss: 0.6132 - val_accuracy: 0.6947\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6189 - accuracy: 0.7276 - val_loss: 0.6107 - val_accuracy: 0.6947\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6163 - accuracy: 0.7307 - val_loss: 0.6081 - val_accuracy: 0.6947\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6137 - accuracy: 0.7337 - val_loss: 0.6055 - val_accuracy: 0.7053\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6109 - accuracy: 0.7368 - val_loss: 0.6029 - val_accuracy: 0.7368\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6082 - accuracy: 0.7399 - val_loss: 0.6002 - val_accuracy: 0.7368\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6054 - accuracy: 0.7430 - val_loss: 0.5975 - val_accuracy: 0.7579\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6025 - accuracy: 0.7523 - val_loss: 0.5948 - val_accuracy: 0.7684\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5996 - accuracy: 0.7616 - val_loss: 0.5920 - val_accuracy: 0.7684\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5967 - accuracy: 0.7616 - val_loss: 0.5892 - val_accuracy: 0.7684\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5937 - accuracy: 0.7709 - val_loss: 0.5864 - val_accuracy: 0.7684\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.5907 - accuracy: 0.7833 - val_loss: 0.5835 - val_accuracy: 0.7684\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5875 - accuracy: 0.7864 - val_loss: 0.5805 - val_accuracy: 0.7684\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5844 - accuracy: 0.7864 - val_loss: 0.5775 - val_accuracy: 0.7684\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5812 - accuracy: 0.7895 - val_loss: 0.5745 - val_accuracy: 0.7895\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5779 - accuracy: 0.7957 - val_loss: 0.5714 - val_accuracy: 0.7895\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5746 - accuracy: 0.8050 - val_loss: 0.5682 - val_accuracy: 0.8000\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5712 - accuracy: 0.8173 - val_loss: 0.5650 - val_accuracy: 0.8105\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5677 - accuracy: 0.8328 - val_loss: 0.5618 - val_accuracy: 0.8105\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5642 - accuracy: 0.8359 - val_loss: 0.5584 - val_accuracy: 0.8211\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5607 - accuracy: 0.8421 - val_loss: 0.5551 - val_accuracy: 0.8316\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5570 - accuracy: 0.8452 - val_loss: 0.5517 - val_accuracy: 0.8316\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5533 - accuracy: 0.8483 - val_loss: 0.5482 - val_accuracy: 0.8316\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5496 - accuracy: 0.8545 - val_loss: 0.5447 - val_accuracy: 0.8421\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5458 - accuracy: 0.8607 - val_loss: 0.5412 - val_accuracy: 0.8421\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5419 - accuracy: 0.8638 - val_loss: 0.5375 - val_accuracy: 0.8632\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5380 - accuracy: 0.8669 - val_loss: 0.5339 - val_accuracy: 0.8632\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5340 - accuracy: 0.8669 - val_loss: 0.5301 - val_accuracy: 0.8632\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5299 - accuracy: 0.8669 - val_loss: 0.5264 - val_accuracy: 0.8632\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5257 - accuracy: 0.8762 - val_loss: 0.5225 - val_accuracy: 0.8632\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.5215 - accuracy: 0.8824 - val_loss: 0.5186 - val_accuracy: 0.8632\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5173 - accuracy: 0.8824 - val_loss: 0.5146 - val_accuracy: 0.8632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5129 - accuracy: 0.8824 - val_loss: 0.5106 - val_accuracy: 0.8632\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5085 - accuracy: 0.8854 - val_loss: 0.5065 - val_accuracy: 0.8632\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.5040 - accuracy: 0.8854 - val_loss: 0.5023 - val_accuracy: 0.8632\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4995 - accuracy: 0.8854 - val_loss: 0.4981 - val_accuracy: 0.8737\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4949 - accuracy: 0.8916 - val_loss: 0.4939 - val_accuracy: 0.8737\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4903 - accuracy: 0.8916 - val_loss: 0.4897 - val_accuracy: 0.8842\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4856 - accuracy: 0.8916 - val_loss: 0.4854 - val_accuracy: 0.8842\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4808 - accuracy: 0.8885 - val_loss: 0.4811 - val_accuracy: 0.8842\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.4760 - accuracy: 0.8947 - val_loss: 0.4767 - val_accuracy: 0.8842\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4712 - accuracy: 0.8978 - val_loss: 0.4723 - val_accuracy: 0.8737\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4663 - accuracy: 0.9009 - val_loss: 0.4679 - val_accuracy: 0.8947\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4614 - accuracy: 0.9133 - val_loss: 0.4635 - val_accuracy: 0.8947\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4564 - accuracy: 0.9133 - val_loss: 0.4590 - val_accuracy: 0.9053\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.4514 - accuracy: 0.9164 - val_loss: 0.4546 - val_accuracy: 0.9053\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4464 - accuracy: 0.9226 - val_loss: 0.4501 - val_accuracy: 0.9053\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4413 - accuracy: 0.9257 - val_loss: 0.4457 - val_accuracy: 0.9053\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4362 - accuracy: 0.9319 - val_loss: 0.4412 - val_accuracy: 0.9053\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.4311 - accuracy: 0.9350 - val_loss: 0.4367 - val_accuracy: 0.9053\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4260 - accuracy: 0.9350 - val_loss: 0.4323 - val_accuracy: 0.9053\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4209 - accuracy: 0.9350 - val_loss: 0.4279 - val_accuracy: 0.9053\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4158 - accuracy: 0.9350 - val_loss: 0.4235 - val_accuracy: 0.9053\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4106 - accuracy: 0.9350 - val_loss: 0.4191 - val_accuracy: 0.9053\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4055 - accuracy: 0.9350 - val_loss: 0.4147 - val_accuracy: 0.9053\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4004 - accuracy: 0.9350 - val_loss: 0.4104 - val_accuracy: 0.9053\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.3952 - accuracy: 0.9350 - val_loss: 0.4062 - val_accuracy: 0.9053\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3902 - accuracy: 0.9350 - val_loss: 0.4020 - val_accuracy: 0.9053\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3851 - accuracy: 0.9350 - val_loss: 0.3978 - val_accuracy: 0.9053\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3801 - accuracy: 0.9350 - val_loss: 0.3937 - val_accuracy: 0.9053\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3752 - accuracy: 0.9350 - val_loss: 0.3897 - val_accuracy: 0.9053\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3703 - accuracy: 0.9350 - val_loss: 0.3858 - val_accuracy: 0.9053\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3655 - accuracy: 0.9350 - val_loss: 0.3820 - val_accuracy: 0.9053\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.3607 - accuracy: 0.9350 - val_loss: 0.3782 - val_accuracy: 0.9053\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.3561 - accuracy: 0.9350 - val_loss: 0.3745 - val_accuracy: 0.9053\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3515 - accuracy: 0.9350 - val_loss: 0.3710 - val_accuracy: 0.9053\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3469 - accuracy: 0.9350 - val_loss: 0.3675 - val_accuracy: 0.9053\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3425 - accuracy: 0.9350 - val_loss: 0.3642 - val_accuracy: 0.9053\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3382 - accuracy: 0.9350 - val_loss: 0.3609 - val_accuracy: 0.9053\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3340 - accuracy: 0.9350 - val_loss: 0.3578 - val_accuracy: 0.9053\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3298 - accuracy: 0.9350 - val_loss: 0.3548 - val_accuracy: 0.9053\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3258 - accuracy: 0.9350 - val_loss: 0.3519 - val_accuracy: 0.9053\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3220 - accuracy: 0.9350 - val_loss: 0.3492 - val_accuracy: 0.9053\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3182 - accuracy: 0.9350 - val_loss: 0.3465 - val_accuracy: 0.9053\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3145 - accuracy: 0.9350 - val_loss: 0.3440 - val_accuracy: 0.9053\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.3109 - accuracy: 0.9350 - val_loss: 0.3416 - val_accuracy: 0.9053\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3075 - accuracy: 0.9350 - val_loss: 0.3393 - val_accuracy: 0.9053\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3042 - accuracy: 0.9350 - val_loss: 0.3371 - val_accuracy: 0.9053\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.3009 - accuracy: 0.9350 - val_loss: 0.3351 - val_accuracy: 0.9053\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2978 - accuracy: 0.9350 - val_loss: 0.3332 - val_accuracy: 0.9053\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2949 - accuracy: 0.9350 - val_loss: 0.3314 - val_accuracy: 0.9053\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2920 - accuracy: 0.9350 - val_loss: 0.3297 - val_accuracy: 0.9053\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2892 - accuracy: 0.9350 - val_loss: 0.3281 - val_accuracy: 0.9053\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.2866 - accuracy: 0.9350 - val_loss: 0.3266 - val_accuracy: 0.9053\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2841 - accuracy: 0.9350 - val_loss: 0.3252 - val_accuracy: 0.9053\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2816 - accuracy: 0.9350 - val_loss: 0.3239 - val_accuracy: 0.9053\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2793 - accuracy: 0.9350 - val_loss: 0.3228 - val_accuracy: 0.9053\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2771 - accuracy: 0.9350 - val_loss: 0.3217 - val_accuracy: 0.9053\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2749 - accuracy: 0.9350 - val_loss: 0.3207 - val_accuracy: 0.9053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2729 - accuracy: 0.9350 - val_loss: 0.3198 - val_accuracy: 0.9053\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2710 - accuracy: 0.9350 - val_loss: 0.3190 - val_accuracy: 0.9053\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2691 - accuracy: 0.9350 - val_loss: 0.3182 - val_accuracy: 0.9053\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.2673 - accuracy: 0.9350 - val_loss: 0.3176 - val_accuracy: 0.9053\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2657 - accuracy: 0.9350 - val_loss: 0.3170 - val_accuracy: 0.9053\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2640 - accuracy: 0.9350 - val_loss: 0.3165 - val_accuracy: 0.9053\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2625 - accuracy: 0.9350 - val_loss: 0.3160 - val_accuracy: 0.9053\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2610 - accuracy: 0.9350 - val_loss: 0.3156 - val_accuracy: 0.9053\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2597 - accuracy: 0.9350 - val_loss: 0.3153 - val_accuracy: 0.9053\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.2583 - accuracy: 0.9350 - val_loss: 0.3150 - val_accuracy: 0.9053\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2571 - accuracy: 0.9350 - val_loss: 0.3148 - val_accuracy: 0.9053\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2558 - accuracy: 0.9350 - val_loss: 0.3146 - val_accuracy: 0.9053\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2547 - accuracy: 0.9350 - val_loss: 0.3145 - val_accuracy: 0.9053\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.2536 - accuracy: 0.9350 - val_loss: 0.3144 - val_accuracy: 0.9053\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2526 - accuracy: 0.9350 - val_loss: 0.3144 - val_accuracy: 0.9053\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2516 - accuracy: 0.9350 - val_loss: 0.3144 - val_accuracy: 0.9053\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.2506 - accuracy: 0.9350 - val_loss: 0.3144 - val_accuracy: 0.9053\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2497 - accuracy: 0.9350 - val_loss: 0.3145 - val_accuracy: 0.9053\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.2488 - accuracy: 0.9350 - val_loss: 0.3146 - val_accuracy: 0.9053\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2480 - accuracy: 0.9350 - val_loss: 0.3148 - val_accuracy: 0.9053\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2472 - accuracy: 0.9350 - val_loss: 0.3149 - val_accuracy: 0.9053\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2465 - accuracy: 0.9350 - val_loss: 0.3151 - val_accuracy: 0.9053\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2457 - accuracy: 0.9350 - val_loss: 0.3153 - val_accuracy: 0.9053\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 117us/step - loss: 0.2450 - accuracy: 0.9350 - val_loss: 0.3155 - val_accuracy: 0.9053\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2444 - accuracy: 0.9350 - val_loss: 0.3158 - val_accuracy: 0.9053\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.2437 - accuracy: 0.9350 - val_loss: 0.3161 - val_accuracy: 0.9053\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2431 - accuracy: 0.9350 - val_loss: 0.3163 - val_accuracy: 0.9053\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2425 - accuracy: 0.9350 - val_loss: 0.3166 - val_accuracy: 0.9053\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.2420 - accuracy: 0.9350 - val_loss: 0.3170 - val_accuracy: 0.9053\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2415 - accuracy: 0.9350 - val_loss: 0.3173 - val_accuracy: 0.9053\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2409 - accuracy: 0.9350 - val_loss: 0.3176 - val_accuracy: 0.9053\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2404 - accuracy: 0.9350 - val_loss: 0.3180 - val_accuracy: 0.9053\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2400 - accuracy: 0.9350 - val_loss: 0.3184 - val_accuracy: 0.9053\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2395 - accuracy: 0.9350 - val_loss: 0.3187 - val_accuracy: 0.9053\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.2391 - accuracy: 0.9350 - val_loss: 0.3191 - val_accuracy: 0.9053\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2386 - accuracy: 0.9350 - val_loss: 0.3195 - val_accuracy: 0.9053\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2382 - accuracy: 0.9350 - val_loss: 0.3199 - val_accuracy: 0.9053\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2378 - accuracy: 0.9350 - val_loss: 0.3203 - val_accuracy: 0.9053\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2375 - accuracy: 0.9350 - val_loss: 0.3208 - val_accuracy: 0.9053\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2371 - accuracy: 0.9350 - val_loss: 0.3212 - val_accuracy: 0.9053\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2367 - accuracy: 0.9350 - val_loss: 0.3216 - val_accuracy: 0.9053\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2364 - accuracy: 0.9350 - val_loss: 0.3220 - val_accuracy: 0.9053\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.2361 - accuracy: 0.9350 - val_loss: 0.3225 - val_accuracy: 0.9053\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2357 - accuracy: 0.9350 - val_loss: 0.3229 - val_accuracy: 0.9053\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2354 - accuracy: 0.9350 - val_loss: 0.3233 - val_accuracy: 0.9053\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2351 - accuracy: 0.9350 - val_loss: 0.3238 - val_accuracy: 0.9053\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2348 - accuracy: 0.9350 - val_loss: 0.3242 - val_accuracy: 0.9053\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2345 - accuracy: 0.9350 - val_loss: 0.3246 - val_accuracy: 0.9053\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2343 - accuracy: 0.9350 - val_loss: 0.3251 - val_accuracy: 0.9053\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2340 - accuracy: 0.9350 - val_loss: 0.3255 - val_accuracy: 0.9053\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2337 - accuracy: 0.9350 - val_loss: 0.3260 - val_accuracy: 0.9053\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2335 - accuracy: 0.9350 - val_loss: 0.3264 - val_accuracy: 0.9053\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2332 - accuracy: 0.9350 - val_loss: 0.3268 - val_accuracy: 0.9053\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2330 - accuracy: 0.9350 - val_loss: 0.3273 - val_accuracy: 0.9053\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2328 - accuracy: 0.9350 - val_loss: 0.3277 - val_accuracy: 0.9053\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2325 - accuracy: 0.9350 - val_loss: 0.3282 - val_accuracy: 0.9053\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2323 - accuracy: 0.9350 - val_loss: 0.3286 - val_accuracy: 0.9053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2321 - accuracy: 0.9350 - val_loss: 0.3290 - val_accuracy: 0.9053\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2319 - accuracy: 0.9350 - val_loss: 0.3295 - val_accuracy: 0.9053\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2317 - accuracy: 0.9350 - val_loss: 0.3299 - val_accuracy: 0.9053\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2315 - accuracy: 0.9350 - val_loss: 0.3303 - val_accuracy: 0.9053\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.2313 - accuracy: 0.9350 - val_loss: 0.3308 - val_accuracy: 0.9053\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.2311 - accuracy: 0.9350 - val_loss: 0.3312 - val_accuracy: 0.9053\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2309 - accuracy: 0.9350 - val_loss: 0.3316 - val_accuracy: 0.9053\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2307 - accuracy: 0.9350 - val_loss: 0.3321 - val_accuracy: 0.9053\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2305 - accuracy: 0.9350 - val_loss: 0.3325 - val_accuracy: 0.9053\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2303 - accuracy: 0.9350 - val_loss: 0.3329 - val_accuracy: 0.9053\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.2302 - accuracy: 0.9350 - val_loss: 0.3334 - val_accuracy: 0.9053\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2300 - accuracy: 0.9350 - val_loss: 0.3338 - val_accuracy: 0.9053\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.2298 - accuracy: 0.9350 - val_loss: 0.3342 - val_accuracy: 0.9053\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.2296 - accuracy: 0.9350 - val_loss: 0.3346 - val_accuracy: 0.9053\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.2295 - accuracy: 0.9350 - val_loss: 0.3350 - val_accuracy: 0.9053\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2293 - accuracy: 0.9350 - val_loss: 0.3354 - val_accuracy: 0.9053\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2292 - accuracy: 0.9350 - val_loss: 0.3358 - val_accuracy: 0.9053\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2290 - accuracy: 0.9350 - val_loss: 0.3363 - val_accuracy: 0.9053\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2289 - accuracy: 0.9350 - val_loss: 0.3367 - val_accuracy: 0.9053\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2287 - accuracy: 0.9350 - val_loss: 0.3371 - val_accuracy: 0.9053\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2286 - accuracy: 0.9350 - val_loss: 0.3375 - val_accuracy: 0.9053\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2284 - accuracy: 0.9350 - val_loss: 0.3379 - val_accuracy: 0.9053\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2283 - accuracy: 0.9350 - val_loss: 0.3382 - val_accuracy: 0.9053\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2282 - accuracy: 0.9350 - val_loss: 0.3386 - val_accuracy: 0.9053\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2280 - accuracy: 0.9350 - val_loss: 0.3390 - val_accuracy: 0.9053\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2279 - accuracy: 0.9350 - val_loss: 0.3394 - val_accuracy: 0.9053\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2278 - accuracy: 0.9350 - val_loss: 0.3398 - val_accuracy: 0.9053\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2276 - accuracy: 0.9350 - val_loss: 0.3402 - val_accuracy: 0.9053\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2275 - accuracy: 0.9350 - val_loss: 0.3406 - val_accuracy: 0.9053\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:128: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17 samples, validate on 5 samples\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6959 - accuracy: 0.4458 - val_loss: 0.6943 - val_accuracy: 0.5368\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6952 - accuracy: 0.5077 - val_loss: 0.6937 - val_accuracy: 0.5579\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6944 - accuracy: 0.5511 - val_loss: 0.6931 - val_accuracy: 0.6105\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6937 - accuracy: 0.6223 - val_loss: 0.6924 - val_accuracy: 0.6316\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6929 - accuracy: 0.6409 - val_loss: 0.6918 - val_accuracy: 0.6316\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6922 - accuracy: 0.6687 - val_loss: 0.6912 - val_accuracy: 0.6632\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6915 - accuracy: 0.6842 - val_loss: 0.6905 - val_accuracy: 0.6947\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6908 - accuracy: 0.6997 - val_loss: 0.6899 - val_accuracy: 0.7263\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6901 - accuracy: 0.7245 - val_loss: 0.6893 - val_accuracy: 0.7474\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6895 - accuracy: 0.7307 - val_loss: 0.6887 - val_accuracy: 0.7579\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6888 - accuracy: 0.7399 - val_loss: 0.6881 - val_accuracy: 0.7895\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.6881 - accuracy: 0.7430 - val_loss: 0.6874 - val_accuracy: 0.7895\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6874 - accuracy: 0.7523 - val_loss: 0.6868 - val_accuracy: 0.8105\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.6867 - accuracy: 0.7616 - val_loss: 0.6862 - val_accuracy: 0.8105\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6860 - accuracy: 0.7709 - val_loss: 0.6856 - val_accuracy: 0.8211\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6853 - accuracy: 0.7771 - val_loss: 0.6850 - val_accuracy: 0.8316\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6847 - accuracy: 0.7895 - val_loss: 0.6844 - val_accuracy: 0.8421\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6840 - accuracy: 0.7864 - val_loss: 0.6838 - val_accuracy: 0.8316\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6833 - accuracy: 0.7926 - val_loss: 0.6832 - val_accuracy: 0.8316\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6826 - accuracy: 0.8019 - val_loss: 0.6827 - val_accuracy: 0.8316\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6820 - accuracy: 0.8050 - val_loss: 0.6821 - val_accuracy: 0.8316\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6813 - accuracy: 0.8050 - val_loss: 0.6815 - val_accuracy: 0.8316\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.6806 - accuracy: 0.8111 - val_loss: 0.6809 - val_accuracy: 0.8526\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6799 - accuracy: 0.8142 - val_loss: 0.6803 - val_accuracy: 0.8526\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6793 - accuracy: 0.8173 - val_loss: 0.6797 - val_accuracy: 0.8526\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6786 - accuracy: 0.8173 - val_loss: 0.6791 - val_accuracy: 0.8526\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6779 - accuracy: 0.8235 - val_loss: 0.6785 - val_accuracy: 0.8526\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6772 - accuracy: 0.8328 - val_loss: 0.6780 - val_accuracy: 0.8526\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6766 - accuracy: 0.8328 - val_loss: 0.6774 - val_accuracy: 0.8526\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6759 - accuracy: 0.8328 - val_loss: 0.6768 - val_accuracy: 0.8632\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6752 - accuracy: 0.8359 - val_loss: 0.6762 - val_accuracy: 0.8632\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6746 - accuracy: 0.8452 - val_loss: 0.6756 - val_accuracy: 0.8632\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6739 - accuracy: 0.8452 - val_loss: 0.6750 - val_accuracy: 0.8737\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6732 - accuracy: 0.8452 - val_loss: 0.6744 - val_accuracy: 0.8737\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6726 - accuracy: 0.8545 - val_loss: 0.6739 - val_accuracy: 0.8737\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6719 - accuracy: 0.8576 - val_loss: 0.6733 - val_accuracy: 0.8842\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.6712 - accuracy: 0.8638 - val_loss: 0.6727 - val_accuracy: 0.8842\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6706 - accuracy: 0.8669 - val_loss: 0.6721 - val_accuracy: 0.8737\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.6700 - accuracy: 0.8669 - val_loss: 0.6716 - val_accuracy: 0.8737\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6693 - accuracy: 0.8700 - val_loss: 0.6710 - val_accuracy: 0.8737\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6687 - accuracy: 0.8731 - val_loss: 0.6704 - val_accuracy: 0.8737\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6680 - accuracy: 0.8793 - val_loss: 0.6698 - val_accuracy: 0.8737\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6674 - accuracy: 0.8793 - val_loss: 0.6693 - val_accuracy: 0.8737\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6667 - accuracy: 0.8824 - val_loss: 0.6687 - val_accuracy: 0.8842\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6661 - accuracy: 0.8824 - val_loss: 0.6681 - val_accuracy: 0.8842\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6655 - accuracy: 0.8885 - val_loss: 0.6676 - val_accuracy: 0.8842\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6648 - accuracy: 0.8885 - val_loss: 0.6670 - val_accuracy: 0.8842\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6642 - accuracy: 0.8885 - val_loss: 0.6665 - val_accuracy: 0.8947\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6636 - accuracy: 0.8978 - val_loss: 0.6659 - val_accuracy: 0.8947\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.6629 - accuracy: 0.8978 - val_loss: 0.6653 - val_accuracy: 0.8947\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6623 - accuracy: 0.9009 - val_loss: 0.6648 - val_accuracy: 0.8947\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6616 - accuracy: 0.9009 - val_loss: 0.6642 - val_accuracy: 0.8947\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6610 - accuracy: 0.9009 - val_loss: 0.6636 - val_accuracy: 0.8947\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6604 - accuracy: 0.9009 - val_loss: 0.6631 - val_accuracy: 0.8947\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.6597 - accuracy: 0.9009 - val_loss: 0.6625 - val_accuracy: 0.8947\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6591 - accuracy: 0.9071 - val_loss: 0.6620 - val_accuracy: 0.8947\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.6585 - accuracy: 0.9071 - val_loss: 0.6614 - val_accuracy: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6578 - accuracy: 0.9102 - val_loss: 0.6608 - val_accuracy: 0.8947\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6572 - accuracy: 0.9102 - val_loss: 0.6603 - val_accuracy: 0.8947\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6566 - accuracy: 0.9102 - val_loss: 0.6597 - val_accuracy: 0.8947\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6559 - accuracy: 0.9102 - val_loss: 0.6592 - val_accuracy: 0.9053\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6553 - accuracy: 0.9102 - val_loss: 0.6586 - val_accuracy: 0.9053\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6546 - accuracy: 0.9102 - val_loss: 0.6580 - val_accuracy: 0.9053\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6540 - accuracy: 0.9102 - val_loss: 0.6575 - val_accuracy: 0.9053\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6534 - accuracy: 0.9133 - val_loss: 0.6569 - val_accuracy: 0.9053\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6527 - accuracy: 0.9133 - val_loss: 0.6563 - val_accuracy: 0.9053\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.6521 - accuracy: 0.9133 - val_loss: 0.6558 - val_accuracy: 0.9053\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6515 - accuracy: 0.9133 - val_loss: 0.6552 - val_accuracy: 0.9053\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6508 - accuracy: 0.9133 - val_loss: 0.6547 - val_accuracy: 0.9053\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6502 - accuracy: 0.9164 - val_loss: 0.6541 - val_accuracy: 0.9053\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6496 - accuracy: 0.9195 - val_loss: 0.6535 - val_accuracy: 0.9053\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.6489 - accuracy: 0.9226 - val_loss: 0.6530 - val_accuracy: 0.9053\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6483 - accuracy: 0.9226 - val_loss: 0.6524 - val_accuracy: 0.9053\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6477 - accuracy: 0.9257 - val_loss: 0.6519 - val_accuracy: 0.9053\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6470 - accuracy: 0.9257 - val_loss: 0.6513 - val_accuracy: 0.9053\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6464 - accuracy: 0.9257 - val_loss: 0.6507 - val_accuracy: 0.9053\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6458 - accuracy: 0.9257 - val_loss: 0.6502 - val_accuracy: 0.9053\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6451 - accuracy: 0.9257 - val_loss: 0.6496 - val_accuracy: 0.9053\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6445 - accuracy: 0.9257 - val_loss: 0.6491 - val_accuracy: 0.9053\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6439 - accuracy: 0.9257 - val_loss: 0.6485 - val_accuracy: 0.9053\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6432 - accuracy: 0.9257 - val_loss: 0.6480 - val_accuracy: 0.9053\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6426 - accuracy: 0.9257 - val_loss: 0.6474 - val_accuracy: 0.9053\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6420 - accuracy: 0.9257 - val_loss: 0.6469 - val_accuracy: 0.9053\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6413 - accuracy: 0.9257 - val_loss: 0.6463 - val_accuracy: 0.9053\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6407 - accuracy: 0.9257 - val_loss: 0.6458 - val_accuracy: 0.9053\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6401 - accuracy: 0.9257 - val_loss: 0.6452 - val_accuracy: 0.9053\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6394 - accuracy: 0.9288 - val_loss: 0.6447 - val_accuracy: 0.9053\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6388 - accuracy: 0.9288 - val_loss: 0.6441 - val_accuracy: 0.9053\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6382 - accuracy: 0.9288 - val_loss: 0.6436 - val_accuracy: 0.9053\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6375 - accuracy: 0.9288 - val_loss: 0.6430 - val_accuracy: 0.9053\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6369 - accuracy: 0.9288 - val_loss: 0.6425 - val_accuracy: 0.9053\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6363 - accuracy: 0.9288 - val_loss: 0.6419 - val_accuracy: 0.9053\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6356 - accuracy: 0.9288 - val_loss: 0.6414 - val_accuracy: 0.9053\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6350 - accuracy: 0.9319 - val_loss: 0.6408 - val_accuracy: 0.9053\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6344 - accuracy: 0.9319 - val_loss: 0.6403 - val_accuracy: 0.9053\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6337 - accuracy: 0.9319 - val_loss: 0.6397 - val_accuracy: 0.9053\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6331 - accuracy: 0.9319 - val_loss: 0.6392 - val_accuracy: 0.9053\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6325 - accuracy: 0.9319 - val_loss: 0.6386 - val_accuracy: 0.9053\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6318 - accuracy: 0.9319 - val_loss: 0.6381 - val_accuracy: 0.9053\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.6312 - accuracy: 0.9319 - val_loss: 0.6375 - val_accuracy: 0.9053\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6306 - accuracy: 0.9319 - val_loss: 0.6370 - val_accuracy: 0.9053\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6299 - accuracy: 0.9319 - val_loss: 0.6364 - val_accuracy: 0.9053\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6293 - accuracy: 0.9319 - val_loss: 0.6359 - val_accuracy: 0.9053\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6287 - accuracy: 0.9319 - val_loss: 0.6353 - val_accuracy: 0.9053\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6280 - accuracy: 0.9319 - val_loss: 0.6347 - val_accuracy: 0.9053\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6274 - accuracy: 0.9319 - val_loss: 0.6342 - val_accuracy: 0.9053\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6267 - accuracy: 0.9319 - val_loss: 0.6336 - val_accuracy: 0.9053\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6261 - accuracy: 0.9319 - val_loss: 0.6331 - val_accuracy: 0.9053\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6255 - accuracy: 0.9319 - val_loss: 0.6325 - val_accuracy: 0.9053\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6248 - accuracy: 0.9319 - val_loss: 0.6320 - val_accuracy: 0.9053\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6242 - accuracy: 0.9319 - val_loss: 0.6314 - val_accuracy: 0.9053\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6235 - accuracy: 0.9319 - val_loss: 0.6308 - val_accuracy: 0.9053\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.6229 - accuracy: 0.9319 - val_loss: 0.6303 - val_accuracy: 0.9053\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6223 - accuracy: 0.9319 - val_loss: 0.6297 - val_accuracy: 0.9053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6216 - accuracy: 0.9319 - val_loss: 0.6292 - val_accuracy: 0.9053\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6210 - accuracy: 0.9319 - val_loss: 0.6286 - val_accuracy: 0.9053\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6203 - accuracy: 0.9319 - val_loss: 0.6280 - val_accuracy: 0.9053\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6197 - accuracy: 0.9319 - val_loss: 0.6275 - val_accuracy: 0.9053\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.6190 - accuracy: 0.9319 - val_loss: 0.6269 - val_accuracy: 0.9053\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6184 - accuracy: 0.9319 - val_loss: 0.6264 - val_accuracy: 0.9053\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6178 - accuracy: 0.9319 - val_loss: 0.6258 - val_accuracy: 0.9053\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6171 - accuracy: 0.9319 - val_loss: 0.6252 - val_accuracy: 0.9053\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6165 - accuracy: 0.9319 - val_loss: 0.6247 - val_accuracy: 0.9053\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6158 - accuracy: 0.9319 - val_loss: 0.6241 - val_accuracy: 0.9053\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6152 - accuracy: 0.9319 - val_loss: 0.6235 - val_accuracy: 0.9053\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.6145 - accuracy: 0.9319 - val_loss: 0.6230 - val_accuracy: 0.9053\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6139 - accuracy: 0.9319 - val_loss: 0.6224 - val_accuracy: 0.9053\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6132 - accuracy: 0.9319 - val_loss: 0.6218 - val_accuracy: 0.9053\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6126 - accuracy: 0.9319 - val_loss: 0.6213 - val_accuracy: 0.9053\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6119 - accuracy: 0.9319 - val_loss: 0.6207 - val_accuracy: 0.9053\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6113 - accuracy: 0.9319 - val_loss: 0.6201 - val_accuracy: 0.9053\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6106 - accuracy: 0.9319 - val_loss: 0.6196 - val_accuracy: 0.9053\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6099 - accuracy: 0.9319 - val_loss: 0.6190 - val_accuracy: 0.9053\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6093 - accuracy: 0.9319 - val_loss: 0.6184 - val_accuracy: 0.9053\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6086 - accuracy: 0.9319 - val_loss: 0.6178 - val_accuracy: 0.9053\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.6080 - accuracy: 0.9319 - val_loss: 0.6173 - val_accuracy: 0.9053\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6073 - accuracy: 0.9319 - val_loss: 0.6167 - val_accuracy: 0.9053\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6067 - accuracy: 0.9319 - val_loss: 0.6161 - val_accuracy: 0.9053\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6060 - accuracy: 0.9319 - val_loss: 0.6155 - val_accuracy: 0.9053\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6053 - accuracy: 0.9319 - val_loss: 0.6150 - val_accuracy: 0.9053\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.6047 - accuracy: 0.9319 - val_loss: 0.6144 - val_accuracy: 0.9053\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6040 - accuracy: 0.9319 - val_loss: 0.6138 - val_accuracy: 0.9053\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6033 - accuracy: 0.9319 - val_loss: 0.6132 - val_accuracy: 0.9053\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6026 - accuracy: 0.9319 - val_loss: 0.6126 - val_accuracy: 0.9053\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6020 - accuracy: 0.9319 - val_loss: 0.6121 - val_accuracy: 0.9053\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6013 - accuracy: 0.9350 - val_loss: 0.6115 - val_accuracy: 0.9053\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6006 - accuracy: 0.9350 - val_loss: 0.6109 - val_accuracy: 0.9053\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5999 - accuracy: 0.9350 - val_loss: 0.6103 - val_accuracy: 0.9053\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5992 - accuracy: 0.9350 - val_loss: 0.6097 - val_accuracy: 0.9053\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.5986 - accuracy: 0.9350 - val_loss: 0.6091 - val_accuracy: 0.9053\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.5979 - accuracy: 0.9350 - val_loss: 0.6085 - val_accuracy: 0.9053\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5972 - accuracy: 0.9350 - val_loss: 0.6079 - val_accuracy: 0.9053\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5965 - accuracy: 0.9350 - val_loss: 0.6074 - val_accuracy: 0.9053\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.5958 - accuracy: 0.9350 - val_loss: 0.6068 - val_accuracy: 0.9053\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5951 - accuracy: 0.9350 - val_loss: 0.6062 - val_accuracy: 0.9053\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5944 - accuracy: 0.9350 - val_loss: 0.6056 - val_accuracy: 0.9053\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5938 - accuracy: 0.9350 - val_loss: 0.6050 - val_accuracy: 0.9053\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5931 - accuracy: 0.9350 - val_loss: 0.6044 - val_accuracy: 0.9053\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5924 - accuracy: 0.9350 - val_loss: 0.6038 - val_accuracy: 0.9053\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5917 - accuracy: 0.9350 - val_loss: 0.6032 - val_accuracy: 0.9053\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5910 - accuracy: 0.9350 - val_loss: 0.6026 - val_accuracy: 0.9053\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.5902 - accuracy: 0.9350 - val_loss: 0.6020 - val_accuracy: 0.9053\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5895 - accuracy: 0.9350 - val_loss: 0.6014 - val_accuracy: 0.9053\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5888 - accuracy: 0.9350 - val_loss: 0.6008 - val_accuracy: 0.9053\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5881 - accuracy: 0.9350 - val_loss: 0.6002 - val_accuracy: 0.9053\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5874 - accuracy: 0.9350 - val_loss: 0.5995 - val_accuracy: 0.9053\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.5867 - accuracy: 0.9350 - val_loss: 0.5989 - val_accuracy: 0.9053\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5859 - accuracy: 0.9350 - val_loss: 0.5983 - val_accuracy: 0.9053\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.5852 - accuracy: 0.9350 - val_loss: 0.5977 - val_accuracy: 0.9053\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.5845 - accuracy: 0.9350 - val_loss: 0.5971 - val_accuracy: 0.9053\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5837 - accuracy: 0.9350 - val_loss: 0.5965 - val_accuracy: 0.9053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5830 - accuracy: 0.9350 - val_loss: 0.5959 - val_accuracy: 0.9053\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5823 - accuracy: 0.9350 - val_loss: 0.5953 - val_accuracy: 0.9053\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.5815 - accuracy: 0.9350 - val_loss: 0.5946 - val_accuracy: 0.9053\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5808 - accuracy: 0.9350 - val_loss: 0.5940 - val_accuracy: 0.9053\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5800 - accuracy: 0.9350 - val_loss: 0.5934 - val_accuracy: 0.9053\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5793 - accuracy: 0.9350 - val_loss: 0.5928 - val_accuracy: 0.9053\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5786 - accuracy: 0.9350 - val_loss: 0.5921 - val_accuracy: 0.9053\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.5778 - accuracy: 0.9350 - val_loss: 0.5915 - val_accuracy: 0.9053\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5770 - accuracy: 0.9350 - val_loss: 0.5909 - val_accuracy: 0.9053\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5763 - accuracy: 0.9350 - val_loss: 0.5903 - val_accuracy: 0.9053\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5755 - accuracy: 0.9381 - val_loss: 0.5896 - val_accuracy: 0.9053\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5748 - accuracy: 0.9381 - val_loss: 0.5890 - val_accuracy: 0.9053\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5740 - accuracy: 0.9381 - val_loss: 0.5884 - val_accuracy: 0.9053\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5732 - accuracy: 0.9381 - val_loss: 0.5877 - val_accuracy: 0.9053\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5725 - accuracy: 0.9381 - val_loss: 0.5871 - val_accuracy: 0.9053\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5717 - accuracy: 0.9381 - val_loss: 0.5864 - val_accuracy: 0.9053\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5709 - accuracy: 0.9381 - val_loss: 0.5858 - val_accuracy: 0.9053\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5701 - accuracy: 0.9381 - val_loss: 0.5852 - val_accuracy: 0.9053\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.5694 - accuracy: 0.9381 - val_loss: 0.5845 - val_accuracy: 0.9053\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5686 - accuracy: 0.9381 - val_loss: 0.5839 - val_accuracy: 0.9053\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5678 - accuracy: 0.9381 - val_loss: 0.5832 - val_accuracy: 0.9053\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5670 - accuracy: 0.9381 - val_loss: 0.5826 - val_accuracy: 0.9053\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5662 - accuracy: 0.9381 - val_loss: 0.5819 - val_accuracy: 0.9053\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5654 - accuracy: 0.9381 - val_loss: 0.5813 - val_accuracy: 0.9053\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5646 - accuracy: 0.9381 - val_loss: 0.5806 - val_accuracy: 0.9053\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5638 - accuracy: 0.9381 - val_loss: 0.5799 - val_accuracy: 0.9053\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5630 - accuracy: 0.9381 - val_loss: 0.5793 - val_accuracy: 0.9053\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5622 - accuracy: 0.9381 - val_loss: 0.5786 - val_accuracy: 0.9053\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5614 - accuracy: 0.9381 - val_loss: 0.5780 - val_accuracy: 0.9053\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:128: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17 samples, validate on 5 samples\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6991 - accuracy: 0.4272 - val_loss: 0.6931 - val_accuracy: 0.5053\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6972 - accuracy: 0.4334 - val_loss: 0.6917 - val_accuracy: 0.5158\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6954 - accuracy: 0.4334 - val_loss: 0.6902 - val_accuracy: 0.5158\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6935 - accuracy: 0.4489 - val_loss: 0.6888 - val_accuracy: 0.5158\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6917 - accuracy: 0.4551 - val_loss: 0.6875 - val_accuracy: 0.5158\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6900 - accuracy: 0.4706 - val_loss: 0.6863 - val_accuracy: 0.5368\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6882 - accuracy: 0.4861 - val_loss: 0.6851 - val_accuracy: 0.5368\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6866 - accuracy: 0.5077 - val_loss: 0.6839 - val_accuracy: 0.5579\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6850 - accuracy: 0.5139 - val_loss: 0.6827 - val_accuracy: 0.5895\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.6834 - accuracy: 0.5232 - val_loss: 0.6816 - val_accuracy: 0.5895\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.6818 - accuracy: 0.5325 - val_loss: 0.6805 - val_accuracy: 0.6105\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.6803 - accuracy: 0.5387 - val_loss: 0.6794 - val_accuracy: 0.6105\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.6787 - accuracy: 0.5480 - val_loss: 0.6783 - val_accuracy: 0.6105\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6772 - accuracy: 0.5573 - val_loss: 0.6773 - val_accuracy: 0.6105\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6758 - accuracy: 0.5635 - val_loss: 0.6763 - val_accuracy: 0.6105\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6743 - accuracy: 0.5913 - val_loss: 0.6752 - val_accuracy: 0.6211\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6729 - accuracy: 0.5975 - val_loss: 0.6742 - val_accuracy: 0.6421\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6715 - accuracy: 0.6068 - val_loss: 0.6732 - val_accuracy: 0.6421\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.6700 - accuracy: 0.6223 - val_loss: 0.6722 - val_accuracy: 0.6526\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6687 - accuracy: 0.6254 - val_loss: 0.6713 - val_accuracy: 0.6526\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6673 - accuracy: 0.6347 - val_loss: 0.6703 - val_accuracy: 0.6632\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6659 - accuracy: 0.6440 - val_loss: 0.6693 - val_accuracy: 0.6842\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6646 - accuracy: 0.6440 - val_loss: 0.6683 - val_accuracy: 0.6842\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6633 - accuracy: 0.6471 - val_loss: 0.6674 - val_accuracy: 0.7053\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6620 - accuracy: 0.6471 - val_loss: 0.6665 - val_accuracy: 0.7158\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s 131us/step - loss: 0.6607 - accuracy: 0.6594 - val_loss: 0.6656 - val_accuracy: 0.7158\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6594 - accuracy: 0.6780 - val_loss: 0.6647 - val_accuracy: 0.7263\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6581 - accuracy: 0.6873 - val_loss: 0.6638 - val_accuracy: 0.7368\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6569 - accuracy: 0.6966 - val_loss: 0.6628 - val_accuracy: 0.7368\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6556 - accuracy: 0.7152 - val_loss: 0.6619 - val_accuracy: 0.7579\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6544 - accuracy: 0.7152 - val_loss: 0.6610 - val_accuracy: 0.7579\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6531 - accuracy: 0.7276 - val_loss: 0.6600 - val_accuracy: 0.7579\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6519 - accuracy: 0.7337 - val_loss: 0.6591 - val_accuracy: 0.7579\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6506 - accuracy: 0.7492 - val_loss: 0.6582 - val_accuracy: 0.7579\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.6494 - accuracy: 0.7523 - val_loss: 0.6572 - val_accuracy: 0.7579\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.6481 - accuracy: 0.7616 - val_loss: 0.6562 - val_accuracy: 0.7474\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6468 - accuracy: 0.7678 - val_loss: 0.6552 - val_accuracy: 0.7474\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6455 - accuracy: 0.7802 - val_loss: 0.6542 - val_accuracy: 0.7579\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.6442 - accuracy: 0.7895 - val_loss: 0.6532 - val_accuracy: 0.7579\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6429 - accuracy: 0.7988 - val_loss: 0.6522 - val_accuracy: 0.7579\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6416 - accuracy: 0.8019 - val_loss: 0.6512 - val_accuracy: 0.7474\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6403 - accuracy: 0.8050 - val_loss: 0.6502 - val_accuracy: 0.7579\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6390 - accuracy: 0.8050 - val_loss: 0.6492 - val_accuracy: 0.7579\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6376 - accuracy: 0.8050 - val_loss: 0.6481 - val_accuracy: 0.7579\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6363 - accuracy: 0.8050 - val_loss: 0.6471 - val_accuracy: 0.7789\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.6349 - accuracy: 0.8050 - val_loss: 0.6460 - val_accuracy: 0.7895\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6335 - accuracy: 0.8050 - val_loss: 0.6449 - val_accuracy: 0.7895\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6321 - accuracy: 0.8050 - val_loss: 0.6438 - val_accuracy: 0.7895\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6307 - accuracy: 0.8080 - val_loss: 0.6427 - val_accuracy: 0.7895\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6292 - accuracy: 0.8111 - val_loss: 0.6416 - val_accuracy: 0.7895\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6277 - accuracy: 0.8173 - val_loss: 0.6405 - val_accuracy: 0.7895\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6262 - accuracy: 0.8173 - val_loss: 0.6393 - val_accuracy: 0.7895\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6247 - accuracy: 0.8173 - val_loss: 0.6381 - val_accuracy: 0.8000\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6232 - accuracy: 0.8173 - val_loss: 0.6370 - val_accuracy: 0.8000\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.6216 - accuracy: 0.8173 - val_loss: 0.6358 - val_accuracy: 0.8000\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.6200 - accuracy: 0.8173 - val_loss: 0.6345 - val_accuracy: 0.8000\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.6184 - accuracy: 0.8173 - val_loss: 0.6333 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6168 - accuracy: 0.8173 - val_loss: 0.6321 - val_accuracy: 0.8000\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6151 - accuracy: 0.8173 - val_loss: 0.6308 - val_accuracy: 0.8000\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6134 - accuracy: 0.8173 - val_loss: 0.6295 - val_accuracy: 0.8000\n",
      "Epoch 61/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6117 - accuracy: 0.8173 - val_loss: 0.6282 - val_accuracy: 0.8000\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6100 - accuracy: 0.8204 - val_loss: 0.6269 - val_accuracy: 0.8000\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6082 - accuracy: 0.8204 - val_loss: 0.6256 - val_accuracy: 0.8000\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6064 - accuracy: 0.8204 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6046 - accuracy: 0.8204 - val_loss: 0.6228 - val_accuracy: 0.8000\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6027 - accuracy: 0.8204 - val_loss: 0.6214 - val_accuracy: 0.8000\n",
      "Epoch 67/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.6008 - accuracy: 0.8204 - val_loss: 0.6199 - val_accuracy: 0.8105\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5988 - accuracy: 0.8235 - val_loss: 0.6185 - val_accuracy: 0.8105\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.5969 - accuracy: 0.8235 - val_loss: 0.6170 - val_accuracy: 0.8105\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5949 - accuracy: 0.8235 - val_loss: 0.6155 - val_accuracy: 0.8105\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5928 - accuracy: 0.8235 - val_loss: 0.6139 - val_accuracy: 0.8105\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5907 - accuracy: 0.8235 - val_loss: 0.6124 - val_accuracy: 0.8105\n",
      "Epoch 73/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5886 - accuracy: 0.8235 - val_loss: 0.6108 - val_accuracy: 0.8105\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5864 - accuracy: 0.8235 - val_loss: 0.6091 - val_accuracy: 0.8105\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5842 - accuracy: 0.8235 - val_loss: 0.6075 - val_accuracy: 0.8105\n",
      "Epoch 76/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5819 - accuracy: 0.8266 - val_loss: 0.6058 - val_accuracy: 0.8105\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5796 - accuracy: 0.8266 - val_loss: 0.6041 - val_accuracy: 0.8211\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.5773 - accuracy: 0.8266 - val_loss: 0.6023 - val_accuracy: 0.8211\n",
      "Epoch 79/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5749 - accuracy: 0.8266 - val_loss: 0.6006 - val_accuracy: 0.8211\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5724 - accuracy: 0.8266 - val_loss: 0.5987 - val_accuracy: 0.8211\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5699 - accuracy: 0.8266 - val_loss: 0.5969 - val_accuracy: 0.8105\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5674 - accuracy: 0.8266 - val_loss: 0.5950 - val_accuracy: 0.8105\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5648 - accuracy: 0.8266 - val_loss: 0.5931 - val_accuracy: 0.8105\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5621 - accuracy: 0.8266 - val_loss: 0.5912 - val_accuracy: 0.8105\n",
      "Epoch 85/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5594 - accuracy: 0.8266 - val_loss: 0.5892 - val_accuracy: 0.8105\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5567 - accuracy: 0.8266 - val_loss: 0.5872 - val_accuracy: 0.8105\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.5539 - accuracy: 0.8266 - val_loss: 0.5851 - val_accuracy: 0.8105\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.5510 - accuracy: 0.8266 - val_loss: 0.5830 - val_accuracy: 0.8105\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5481 - accuracy: 0.8297 - val_loss: 0.5809 - val_accuracy: 0.8105\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5451 - accuracy: 0.8297 - val_loss: 0.5787 - val_accuracy: 0.8105\n",
      "Epoch 91/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5421 - accuracy: 0.8359 - val_loss: 0.5764 - val_accuracy: 0.8105\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.5390 - accuracy: 0.8359 - val_loss: 0.5742 - val_accuracy: 0.8105\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5359 - accuracy: 0.8359 - val_loss: 0.5719 - val_accuracy: 0.8105\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5327 - accuracy: 0.8390 - val_loss: 0.5695 - val_accuracy: 0.8105\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5295 - accuracy: 0.8421 - val_loss: 0.5671 - val_accuracy: 0.8105\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.5261 - accuracy: 0.8452 - val_loss: 0.5647 - val_accuracy: 0.8105\n",
      "Epoch 97/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.5228 - accuracy: 0.8421 - val_loss: 0.5622 - val_accuracy: 0.8211\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.5193 - accuracy: 0.8421 - val_loss: 0.5597 - val_accuracy: 0.8211\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5158 - accuracy: 0.8421 - val_loss: 0.5572 - val_accuracy: 0.8316\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5123 - accuracy: 0.8421 - val_loss: 0.5545 - val_accuracy: 0.8316\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5087 - accuracy: 0.8421 - val_loss: 0.5519 - val_accuracy: 0.8316\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5050 - accuracy: 0.8545 - val_loss: 0.5492 - val_accuracy: 0.8316\n",
      "Epoch 103/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.5013 - accuracy: 0.8576 - val_loss: 0.5464 - val_accuracy: 0.8421\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4975 - accuracy: 0.8607 - val_loss: 0.5436 - val_accuracy: 0.8421\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4936 - accuracy: 0.8607 - val_loss: 0.5408 - val_accuracy: 0.8421\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.4897 - accuracy: 0.8607 - val_loss: 0.5379 - val_accuracy: 0.8421\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.4858 - accuracy: 0.8638 - val_loss: 0.5350 - val_accuracy: 0.8421\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4817 - accuracy: 0.8638 - val_loss: 0.5321 - val_accuracy: 0.8421\n",
      "Epoch 109/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4777 - accuracy: 0.8700 - val_loss: 0.5291 - val_accuracy: 0.8526\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4736 - accuracy: 0.8824 - val_loss: 0.5261 - val_accuracy: 0.8526\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4694 - accuracy: 0.8824 - val_loss: 0.5230 - val_accuracy: 0.8526\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4652 - accuracy: 0.8885 - val_loss: 0.5199 - val_accuracy: 0.8632\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.4609 - accuracy: 0.8947 - val_loss: 0.5167 - val_accuracy: 0.8632\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4565 - accuracy: 0.8978 - val_loss: 0.5135 - val_accuracy: 0.8632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4522 - accuracy: 0.8978 - val_loss: 0.5103 - val_accuracy: 0.8632\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4477 - accuracy: 0.8978 - val_loss: 0.5071 - val_accuracy: 0.8737\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.4433 - accuracy: 0.9040 - val_loss: 0.5038 - val_accuracy: 0.8737\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4388 - accuracy: 0.9288 - val_loss: 0.5005 - val_accuracy: 0.8737\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4343 - accuracy: 0.9319 - val_loss: 0.4971 - val_accuracy: 0.8947\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4297 - accuracy: 0.9319 - val_loss: 0.4938 - val_accuracy: 0.9053\n",
      "Epoch 121/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4251 - accuracy: 0.9350 - val_loss: 0.4904 - val_accuracy: 0.9053\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4205 - accuracy: 0.9350 - val_loss: 0.4870 - val_accuracy: 0.9053\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4159 - accuracy: 0.9319 - val_loss: 0.4836 - val_accuracy: 0.9053\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4112 - accuracy: 0.9319 - val_loss: 0.4802 - val_accuracy: 0.9053\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4066 - accuracy: 0.9381 - val_loss: 0.4768 - val_accuracy: 0.8947\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.4019 - accuracy: 0.9381 - val_loss: 0.4734 - val_accuracy: 0.8947\n",
      "Epoch 127/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3973 - accuracy: 0.9381 - val_loss: 0.4700 - val_accuracy: 0.8947\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3926 - accuracy: 0.9381 - val_loss: 0.4666 - val_accuracy: 0.8947\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3880 - accuracy: 0.9381 - val_loss: 0.4632 - val_accuracy: 0.8947\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3834 - accuracy: 0.9381 - val_loss: 0.4598 - val_accuracy: 0.8947\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.3788 - accuracy: 0.9381 - val_loss: 0.4565 - val_accuracy: 0.8947\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.3742 - accuracy: 0.9381 - val_loss: 0.4531 - val_accuracy: 0.8947\n",
      "Epoch 133/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3696 - accuracy: 0.9381 - val_loss: 0.4498 - val_accuracy: 0.8947\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s 116us/step - loss: 0.3651 - accuracy: 0.9381 - val_loss: 0.4465 - val_accuracy: 0.8947\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3607 - accuracy: 0.9381 - val_loss: 0.4432 - val_accuracy: 0.8947\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.3562 - accuracy: 0.9381 - val_loss: 0.4400 - val_accuracy: 0.8947\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.3519 - accuracy: 0.9381 - val_loss: 0.4368 - val_accuracy: 0.8947\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3476 - accuracy: 0.9381 - val_loss: 0.4337 - val_accuracy: 0.8947\n",
      "Epoch 139/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3433 - accuracy: 0.9381 - val_loss: 0.4306 - val_accuracy: 0.8947\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3391 - accuracy: 0.9381 - val_loss: 0.4276 - val_accuracy: 0.8947\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3350 - accuracy: 0.9381 - val_loss: 0.4246 - val_accuracy: 0.8947\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3310 - accuracy: 0.9381 - val_loss: 0.4217 - val_accuracy: 0.8947\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3270 - accuracy: 0.9381 - val_loss: 0.4188 - val_accuracy: 0.8947\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3232 - accuracy: 0.9381 - val_loss: 0.4160 - val_accuracy: 0.8947\n",
      "Epoch 145/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3194 - accuracy: 0.9381 - val_loss: 0.4133 - val_accuracy: 0.8947\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.3157 - accuracy: 0.9381 - val_loss: 0.4106 - val_accuracy: 0.8947\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3121 - accuracy: 0.9381 - val_loss: 0.4080 - val_accuracy: 0.8947\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3086 - accuracy: 0.9381 - val_loss: 0.4055 - val_accuracy: 0.8947\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.3051 - accuracy: 0.9381 - val_loss: 0.4030 - val_accuracy: 0.8947\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.3018 - accuracy: 0.9381 - val_loss: 0.4006 - val_accuracy: 0.8947\n",
      "Epoch 151/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2986 - accuracy: 0.9381 - val_loss: 0.3983 - val_accuracy: 0.8947\n",
      "Epoch 152/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2955 - accuracy: 0.9381 - val_loss: 0.3961 - val_accuracy: 0.8947\n",
      "Epoch 153/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2925 - accuracy: 0.9381 - val_loss: 0.3939 - val_accuracy: 0.8947\n",
      "Epoch 154/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2895 - accuracy: 0.9381 - val_loss: 0.3919 - val_accuracy: 0.8947\n",
      "Epoch 155/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2867 - accuracy: 0.9381 - val_loss: 0.3899 - val_accuracy: 0.8947\n",
      "Epoch 156/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.2840 - accuracy: 0.9381 - val_loss: 0.3879 - val_accuracy: 0.8947\n",
      "Epoch 157/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2813 - accuracy: 0.9381 - val_loss: 0.3861 - val_accuracy: 0.8947\n",
      "Epoch 158/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2788 - accuracy: 0.9381 - val_loss: 0.3843 - val_accuracy: 0.8947\n",
      "Epoch 159/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.2764 - accuracy: 0.9381 - val_loss: 0.3826 - val_accuracy: 0.8947\n",
      "Epoch 160/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2740 - accuracy: 0.9381 - val_loss: 0.3810 - val_accuracy: 0.8947\n",
      "Epoch 161/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2718 - accuracy: 0.9381 - val_loss: 0.3794 - val_accuracy: 0.8947\n",
      "Epoch 162/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2696 - accuracy: 0.9381 - val_loss: 0.3779 - val_accuracy: 0.8947\n",
      "Epoch 163/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2676 - accuracy: 0.9381 - val_loss: 0.3765 - val_accuracy: 0.8947\n",
      "Epoch 164/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.2656 - accuracy: 0.9381 - val_loss: 0.3751 - val_accuracy: 0.8947\n",
      "Epoch 165/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2637 - accuracy: 0.9381 - val_loss: 0.3738 - val_accuracy: 0.8947\n",
      "Epoch 166/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2619 - accuracy: 0.9381 - val_loss: 0.3726 - val_accuracy: 0.8947\n",
      "Epoch 167/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2601 - accuracy: 0.9381 - val_loss: 0.3714 - val_accuracy: 0.8947\n",
      "Epoch 168/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2585 - accuracy: 0.9381 - val_loss: 0.3703 - val_accuracy: 0.8947\n",
      "Epoch 169/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2569 - accuracy: 0.9381 - val_loss: 0.3692 - val_accuracy: 0.8947\n",
      "Epoch 170/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2554 - accuracy: 0.9381 - val_loss: 0.3682 - val_accuracy: 0.8947\n",
      "Epoch 171/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2539 - accuracy: 0.9381 - val_loss: 0.3672 - val_accuracy: 0.8947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.2525 - accuracy: 0.9381 - val_loss: 0.3663 - val_accuracy: 0.8947\n",
      "Epoch 173/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2512 - accuracy: 0.9381 - val_loss: 0.3655 - val_accuracy: 0.8947\n",
      "Epoch 174/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.2500 - accuracy: 0.9381 - val_loss: 0.3647 - val_accuracy: 0.8947\n",
      "Epoch 175/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2488 - accuracy: 0.9381 - val_loss: 0.3639 - val_accuracy: 0.8947\n",
      "Epoch 176/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2476 - accuracy: 0.9381 - val_loss: 0.3632 - val_accuracy: 0.8947\n",
      "Epoch 177/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.2465 - accuracy: 0.9381 - val_loss: 0.3625 - val_accuracy: 0.8947\n",
      "Epoch 178/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2455 - accuracy: 0.9381 - val_loss: 0.3618 - val_accuracy: 0.8947\n",
      "Epoch 179/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2445 - accuracy: 0.9381 - val_loss: 0.3612 - val_accuracy: 0.8947\n",
      "Epoch 180/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2436 - accuracy: 0.9381 - val_loss: 0.3606 - val_accuracy: 0.8947\n",
      "Epoch 181/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2427 - accuracy: 0.9381 - val_loss: 0.3601 - val_accuracy: 0.8947\n",
      "Epoch 182/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2418 - accuracy: 0.9381 - val_loss: 0.3596 - val_accuracy: 0.8947\n",
      "Epoch 183/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2410 - accuracy: 0.9381 - val_loss: 0.3591 - val_accuracy: 0.8947\n",
      "Epoch 184/200\n",
      "17/17 [==============================] - 0s 177us/step - loss: 0.2402 - accuracy: 0.9381 - val_loss: 0.3587 - val_accuracy: 0.8947\n",
      "Epoch 185/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2395 - accuracy: 0.9381 - val_loss: 0.3582 - val_accuracy: 0.8947\n",
      "Epoch 186/200\n",
      "17/17 [==============================] - 0s 176us/step - loss: 0.2388 - accuracy: 0.9381 - val_loss: 0.3578 - val_accuracy: 0.8947\n",
      "Epoch 187/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2381 - accuracy: 0.9381 - val_loss: 0.3575 - val_accuracy: 0.8947\n",
      "Epoch 188/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2374 - accuracy: 0.9381 - val_loss: 0.3571 - val_accuracy: 0.8947\n",
      "Epoch 189/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2368 - accuracy: 0.9381 - val_loss: 0.3568 - val_accuracy: 0.8947\n",
      "Epoch 190/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2362 - accuracy: 0.9381 - val_loss: 0.3565 - val_accuracy: 0.8947\n",
      "Epoch 191/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2357 - accuracy: 0.9381 - val_loss: 0.3562 - val_accuracy: 0.8947\n",
      "Epoch 192/200\n",
      "17/17 [==============================] - 0s 59us/step - loss: 0.2351 - accuracy: 0.9381 - val_loss: 0.3559 - val_accuracy: 0.8947\n",
      "Epoch 193/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2346 - accuracy: 0.9381 - val_loss: 0.3556 - val_accuracy: 0.8947\n",
      "Epoch 194/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2341 - accuracy: 0.9381 - val_loss: 0.3554 - val_accuracy: 0.8947\n",
      "Epoch 195/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2337 - accuracy: 0.9381 - val_loss: 0.3552 - val_accuracy: 0.8947\n",
      "Epoch 196/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2332 - accuracy: 0.9381 - val_loss: 0.3550 - val_accuracy: 0.8947\n",
      "Epoch 197/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2328 - accuracy: 0.9381 - val_loss: 0.3548 - val_accuracy: 0.8947\n",
      "Epoch 198/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2324 - accuracy: 0.9381 - val_loss: 0.3546 - val_accuracy: 0.8947\n",
      "Epoch 199/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2320 - accuracy: 0.9381 - val_loss: 0.3544 - val_accuracy: 0.8947\n",
      "Epoch 200/200\n",
      "17/17 [==============================] - 0s 118us/step - loss: 0.2316 - accuracy: 0.9381 - val_loss: 0.3543 - val_accuracy: 0.8947\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:128: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18 samples, validate on 5 samples\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6829 - accuracy: 0.5409 - val_loss: 0.6781 - val_accuracy: 0.5684\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.6814 - accuracy: 0.5468 - val_loss: 0.6769 - val_accuracy: 0.5684\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6799 - accuracy: 0.5556 - val_loss: 0.6756 - val_accuracy: 0.5684\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6785 - accuracy: 0.5643 - val_loss: 0.6744 - val_accuracy: 0.5895\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6770 - accuracy: 0.5643 - val_loss: 0.6731 - val_accuracy: 0.5895\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6755 - accuracy: 0.5643 - val_loss: 0.6718 - val_accuracy: 0.5895\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.6740 - accuracy: 0.5760 - val_loss: 0.6705 - val_accuracy: 0.5895\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.6725 - accuracy: 0.5877 - val_loss: 0.6692 - val_accuracy: 0.5895\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6709 - accuracy: 0.5906 - val_loss: 0.6678 - val_accuracy: 0.6105\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6693 - accuracy: 0.6257 - val_loss: 0.6665 - val_accuracy: 0.6316\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6677 - accuracy: 0.6287 - val_loss: 0.6651 - val_accuracy: 0.6737\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6661 - accuracy: 0.6374 - val_loss: 0.6637 - val_accuracy: 0.6842\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6644 - accuracy: 0.6404 - val_loss: 0.6623 - val_accuracy: 0.6947\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6628 - accuracy: 0.6491 - val_loss: 0.6610 - val_accuracy: 0.7158\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6612 - accuracy: 0.6491 - val_loss: 0.6596 - val_accuracy: 0.7263\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6595 - accuracy: 0.6579 - val_loss: 0.6582 - val_accuracy: 0.7263\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.6578 - accuracy: 0.6696 - val_loss: 0.6568 - val_accuracy: 0.7474\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.6561 - accuracy: 0.6784 - val_loss: 0.6553 - val_accuracy: 0.7684\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.6544 - accuracy: 0.6959 - val_loss: 0.6538 - val_accuracy: 0.7684\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6527 - accuracy: 0.7193 - val_loss: 0.6523 - val_accuracy: 0.7895\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6509 - accuracy: 0.7368 - val_loss: 0.6507 - val_accuracy: 0.7895\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6491 - accuracy: 0.7485 - val_loss: 0.6491 - val_accuracy: 0.8211\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6473 - accuracy: 0.7602 - val_loss: 0.6475 - val_accuracy: 0.8105\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6454 - accuracy: 0.7661 - val_loss: 0.6459 - val_accuracy: 0.8105\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 112us/step - loss: 0.6435 - accuracy: 0.7719 - val_loss: 0.6443 - val_accuracy: 0.8105\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 110us/step - loss: 0.6416 - accuracy: 0.7778 - val_loss: 0.6426 - val_accuracy: 0.8211\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6397 - accuracy: 0.7865 - val_loss: 0.6410 - val_accuracy: 0.8211\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.6378 - accuracy: 0.7895 - val_loss: 0.6393 - val_accuracy: 0.8211\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.6358 - accuracy: 0.7895 - val_loss: 0.6376 - val_accuracy: 0.8211\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.6339 - accuracy: 0.7895 - val_loss: 0.6359 - val_accuracy: 0.8316\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6319 - accuracy: 0.7982 - val_loss: 0.6341 - val_accuracy: 0.8316\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6299 - accuracy: 0.8012 - val_loss: 0.6324 - val_accuracy: 0.8316\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6278 - accuracy: 0.8012 - val_loss: 0.6306 - val_accuracy: 0.8316\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.6258 - accuracy: 0.8070 - val_loss: 0.6288 - val_accuracy: 0.8316\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.6237 - accuracy: 0.8099 - val_loss: 0.6270 - val_accuracy: 0.8316\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6216 - accuracy: 0.8129 - val_loss: 0.6251 - val_accuracy: 0.8316\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6195 - accuracy: 0.8129 - val_loss: 0.6233 - val_accuracy: 0.8105\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6173 - accuracy: 0.8158 - val_loss: 0.6214 - val_accuracy: 0.8105\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6151 - accuracy: 0.8187 - val_loss: 0.6194 - val_accuracy: 0.8105\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6128 - accuracy: 0.8246 - val_loss: 0.6174 - val_accuracy: 0.8105\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6105 - accuracy: 0.8246 - val_loss: 0.6154 - val_accuracy: 0.8105\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6081 - accuracy: 0.8246 - val_loss: 0.6134 - val_accuracy: 0.8105\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6057 - accuracy: 0.8216 - val_loss: 0.6114 - val_accuracy: 0.8105\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6033 - accuracy: 0.8216 - val_loss: 0.6092 - val_accuracy: 0.8105\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6007 - accuracy: 0.8216 - val_loss: 0.6071 - val_accuracy: 0.8105\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5982 - accuracy: 0.8216 - val_loss: 0.6049 - val_accuracy: 0.8105\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.5955 - accuracy: 0.8216 - val_loss: 0.6026 - val_accuracy: 0.8105\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.5929 - accuracy: 0.8246 - val_loss: 0.6004 - val_accuracy: 0.8000\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 129us/step - loss: 0.5902 - accuracy: 0.8275 - val_loss: 0.5981 - val_accuracy: 0.8000\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5874 - accuracy: 0.8333 - val_loss: 0.5957 - val_accuracy: 0.8105\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5846 - accuracy: 0.8450 - val_loss: 0.5933 - val_accuracy: 0.8105\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5818 - accuracy: 0.8450 - val_loss: 0.5909 - val_accuracy: 0.8105\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.5789 - accuracy: 0.8450 - val_loss: 0.5885 - val_accuracy: 0.8211\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5759 - accuracy: 0.8509 - val_loss: 0.5859 - val_accuracy: 0.8211\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5729 - accuracy: 0.8509 - val_loss: 0.5834 - val_accuracy: 0.8211\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5699 - accuracy: 0.8538 - val_loss: 0.5808 - val_accuracy: 0.8211\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5668 - accuracy: 0.8538 - val_loss: 0.5782 - val_accuracy: 0.8211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5636 - accuracy: 0.8538 - val_loss: 0.5755 - val_accuracy: 0.8211\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.5604 - accuracy: 0.8538 - val_loss: 0.5727 - val_accuracy: 0.8211\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5571 - accuracy: 0.8538 - val_loss: 0.5700 - val_accuracy: 0.8211\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5538 - accuracy: 0.8538 - val_loss: 0.5672 - val_accuracy: 0.8211\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5504 - accuracy: 0.8538 - val_loss: 0.5643 - val_accuracy: 0.8211\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5470 - accuracy: 0.8538 - val_loss: 0.5614 - val_accuracy: 0.8211\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5435 - accuracy: 0.8538 - val_loss: 0.5583 - val_accuracy: 0.8211\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5400 - accuracy: 0.8567 - val_loss: 0.5553 - val_accuracy: 0.8211\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5364 - accuracy: 0.8567 - val_loss: 0.5522 - val_accuracy: 0.8316\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5327 - accuracy: 0.8567 - val_loss: 0.5490 - val_accuracy: 0.8316\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.5290 - accuracy: 0.8596 - val_loss: 0.5458 - val_accuracy: 0.8316\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5253 - accuracy: 0.8596 - val_loss: 0.5425 - val_accuracy: 0.8316\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5215 - accuracy: 0.8596 - val_loss: 0.5392 - val_accuracy: 0.8316\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5176 - accuracy: 0.8596 - val_loss: 0.5359 - val_accuracy: 0.8316\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.5137 - accuracy: 0.8596 - val_loss: 0.5325 - val_accuracy: 0.8316\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5096 - accuracy: 0.8596 - val_loss: 0.5290 - val_accuracy: 0.8316\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.5055 - accuracy: 0.8626 - val_loss: 0.5255 - val_accuracy: 0.8316\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5012 - accuracy: 0.8626 - val_loss: 0.5218 - val_accuracy: 0.8316\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4969 - accuracy: 0.8626 - val_loss: 0.5181 - val_accuracy: 0.8421\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4926 - accuracy: 0.8713 - val_loss: 0.5144 - val_accuracy: 0.8421\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4881 - accuracy: 0.8772 - val_loss: 0.5106 - val_accuracy: 0.8421\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4837 - accuracy: 0.8860 - val_loss: 0.5068 - val_accuracy: 0.8526\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4791 - accuracy: 0.8860 - val_loss: 0.5029 - val_accuracy: 0.8632\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4746 - accuracy: 0.8977 - val_loss: 0.4990 - val_accuracy: 0.8737\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4700 - accuracy: 0.9006 - val_loss: 0.4951 - val_accuracy: 0.8737\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4653 - accuracy: 0.9035 - val_loss: 0.4912 - val_accuracy: 0.8737\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4606 - accuracy: 0.9064 - val_loss: 0.4872 - val_accuracy: 0.8632\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4559 - accuracy: 0.9181 - val_loss: 0.4832 - val_accuracy: 0.8632\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4512 - accuracy: 0.9211 - val_loss: 0.4792 - val_accuracy: 0.8632\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4464 - accuracy: 0.9211 - val_loss: 0.4751 - val_accuracy: 0.8632\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4416 - accuracy: 0.9240 - val_loss: 0.4710 - val_accuracy: 0.8737\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4367 - accuracy: 0.9240 - val_loss: 0.4670 - val_accuracy: 0.8737\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 333us/step - loss: 0.4319 - accuracy: 0.9269 - val_loss: 0.4629 - val_accuracy: 0.8737\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4270 - accuracy: 0.9269 - val_loss: 0.4588 - val_accuracy: 0.8947\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4221 - accuracy: 0.9298 - val_loss: 0.4547 - val_accuracy: 0.8947\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4172 - accuracy: 0.9298 - val_loss: 0.4506 - val_accuracy: 0.8947\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4123 - accuracy: 0.9298 - val_loss: 0.4466 - val_accuracy: 0.8947\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4074 - accuracy: 0.9298 - val_loss: 0.4425 - val_accuracy: 0.8947\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4026 - accuracy: 0.9298 - val_loss: 0.4384 - val_accuracy: 0.8947\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3977 - accuracy: 0.9327 - val_loss: 0.4344 - val_accuracy: 0.8947\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3929 - accuracy: 0.9327 - val_loss: 0.4304 - val_accuracy: 0.8947\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.3881 - accuracy: 0.9357 - val_loss: 0.4264 - val_accuracy: 0.8947\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3833 - accuracy: 0.9386 - val_loss: 0.4225 - val_accuracy: 0.9053\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3785 - accuracy: 0.9415 - val_loss: 0.4186 - val_accuracy: 0.9053\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3738 - accuracy: 0.9415 - val_loss: 0.4147 - val_accuracy: 0.9053\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.3691 - accuracy: 0.9415 - val_loss: 0.4109 - val_accuracy: 0.9053\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3645 - accuracy: 0.9415 - val_loss: 0.4072 - val_accuracy: 0.9053\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3598 - accuracy: 0.9415 - val_loss: 0.4034 - val_accuracy: 0.9053\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3553 - accuracy: 0.9415 - val_loss: 0.3998 - val_accuracy: 0.9053\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 110us/step - loss: 0.3508 - accuracy: 0.9415 - val_loss: 0.3962 - val_accuracy: 0.9053\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3464 - accuracy: 0.9415 - val_loss: 0.3926 - val_accuracy: 0.9053\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3420 - accuracy: 0.9415 - val_loss: 0.3892 - val_accuracy: 0.9053\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3378 - accuracy: 0.9415 - val_loss: 0.3858 - val_accuracy: 0.9053\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.3336 - accuracy: 0.9415 - val_loss: 0.3825 - val_accuracy: 0.9053\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3295 - accuracy: 0.9415 - val_loss: 0.3792 - val_accuracy: 0.9053\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3254 - accuracy: 0.9415 - val_loss: 0.3761 - val_accuracy: 0.9053\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3215 - accuracy: 0.9415 - val_loss: 0.3730 - val_accuracy: 0.9053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3176 - accuracy: 0.9415 - val_loss: 0.3700 - val_accuracy: 0.9053\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3139 - accuracy: 0.9415 - val_loss: 0.3671 - val_accuracy: 0.9053\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3102 - accuracy: 0.9415 - val_loss: 0.3643 - val_accuracy: 0.9053\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3066 - accuracy: 0.9415 - val_loss: 0.3615 - val_accuracy: 0.9053\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3032 - accuracy: 0.9415 - val_loss: 0.3589 - val_accuracy: 0.9053\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2998 - accuracy: 0.9415 - val_loss: 0.3563 - val_accuracy: 0.9053\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2965 - accuracy: 0.9415 - val_loss: 0.3538 - val_accuracy: 0.9053\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2933 - accuracy: 0.9415 - val_loss: 0.3515 - val_accuracy: 0.9053\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2903 - accuracy: 0.9415 - val_loss: 0.3492 - val_accuracy: 0.9053\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.2873 - accuracy: 0.9415 - val_loss: 0.3470 - val_accuracy: 0.9053\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2844 - accuracy: 0.9415 - val_loss: 0.3449 - val_accuracy: 0.9053\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2816 - accuracy: 0.9415 - val_loss: 0.3429 - val_accuracy: 0.9053\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2790 - accuracy: 0.9415 - val_loss: 0.3409 - val_accuracy: 0.9053\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2764 - accuracy: 0.9415 - val_loss: 0.3391 - val_accuracy: 0.9053\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2739 - accuracy: 0.9415 - val_loss: 0.3373 - val_accuracy: 0.9053\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2715 - accuracy: 0.9415 - val_loss: 0.3356 - val_accuracy: 0.9053\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2692 - accuracy: 0.9415 - val_loss: 0.3340 - val_accuracy: 0.9053\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2670 - accuracy: 0.9415 - val_loss: 0.3325 - val_accuracy: 0.9053\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2649 - accuracy: 0.9415 - val_loss: 0.3311 - val_accuracy: 0.9053\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2628 - accuracy: 0.9415 - val_loss: 0.3297 - val_accuracy: 0.9053\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2609 - accuracy: 0.9415 - val_loss: 0.3284 - val_accuracy: 0.9053\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2590 - accuracy: 0.9415 - val_loss: 0.3272 - val_accuracy: 0.9053\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2572 - accuracy: 0.9415 - val_loss: 0.3260 - val_accuracy: 0.9053\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2555 - accuracy: 0.9415 - val_loss: 0.3249 - val_accuracy: 0.9053\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2539 - accuracy: 0.9415 - val_loss: 0.3239 - val_accuracy: 0.9053\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2523 - accuracy: 0.9415 - val_loss: 0.3229 - val_accuracy: 0.9053\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2508 - accuracy: 0.9415 - val_loss: 0.3220 - val_accuracy: 0.9053\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2494 - accuracy: 0.9415 - val_loss: 0.3212 - val_accuracy: 0.9053\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2480 - accuracy: 0.9415 - val_loss: 0.3204 - val_accuracy: 0.9053\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2467 - accuracy: 0.9415 - val_loss: 0.3196 - val_accuracy: 0.9053\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2455 - accuracy: 0.9415 - val_loss: 0.3189 - val_accuracy: 0.9053\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2443 - accuracy: 0.9415 - val_loss: 0.3183 - val_accuracy: 0.9053\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2432 - accuracy: 0.9415 - val_loss: 0.3177 - val_accuracy: 0.9053\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2421 - accuracy: 0.9415 - val_loss: 0.3171 - val_accuracy: 0.9053\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2411 - accuracy: 0.9415 - val_loss: 0.3166 - val_accuracy: 0.9053\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2402 - accuracy: 0.9415 - val_loss: 0.3161 - val_accuracy: 0.9053\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2392 - accuracy: 0.9415 - val_loss: 0.3156 - val_accuracy: 0.9053\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2383 - accuracy: 0.9415 - val_loss: 0.3152 - val_accuracy: 0.9053\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2375 - accuracy: 0.9415 - val_loss: 0.3148 - val_accuracy: 0.9053\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2367 - accuracy: 0.9415 - val_loss: 0.3145 - val_accuracy: 0.9053\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2359 - accuracy: 0.9415 - val_loss: 0.3142 - val_accuracy: 0.9053\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2352 - accuracy: 0.9415 - val_loss: 0.3139 - val_accuracy: 0.9053\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2345 - accuracy: 0.9415 - val_loss: 0.3136 - val_accuracy: 0.9053\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2339 - accuracy: 0.9415 - val_loss: 0.3134 - val_accuracy: 0.9053\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2332 - accuracy: 0.9415 - val_loss: 0.3131 - val_accuracy: 0.9053\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2326 - accuracy: 0.9415 - val_loss: 0.3129 - val_accuracy: 0.9053\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2321 - accuracy: 0.9415 - val_loss: 0.3128 - val_accuracy: 0.9053\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2315 - accuracy: 0.9415 - val_loss: 0.3126 - val_accuracy: 0.9053\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2310 - accuracy: 0.9415 - val_loss: 0.3125 - val_accuracy: 0.9053\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2305 - accuracy: 0.9415 - val_loss: 0.3123 - val_accuracy: 0.9053\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2300 - accuracy: 0.9415 - val_loss: 0.3122 - val_accuracy: 0.9053\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2296 - accuracy: 0.9415 - val_loss: 0.3121 - val_accuracy: 0.9053\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2291 - accuracy: 0.9415 - val_loss: 0.3120 - val_accuracy: 0.9053\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2287 - accuracy: 0.9415 - val_loss: 0.3120 - val_accuracy: 0.9053\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2283 - accuracy: 0.9415 - val_loss: 0.3119 - val_accuracy: 0.9053\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2279 - accuracy: 0.9415 - val_loss: 0.3119 - val_accuracy: 0.9053\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2275 - accuracy: 0.9415 - val_loss: 0.3118 - val_accuracy: 0.9053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2272 - accuracy: 0.9415 - val_loss: 0.3118 - val_accuracy: 0.9053\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2268 - accuracy: 0.9415 - val_loss: 0.3118 - val_accuracy: 0.9053\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2265 - accuracy: 0.9415 - val_loss: 0.3118 - val_accuracy: 0.9053\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2262 - accuracy: 0.9415 - val_loss: 0.3118 - val_accuracy: 0.9053\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2259 - accuracy: 0.9415 - val_loss: 0.3118 - val_accuracy: 0.9053\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2256 - accuracy: 0.9415 - val_loss: 0.3118 - val_accuracy: 0.9053\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2253 - accuracy: 0.9415 - val_loss: 0.3119 - val_accuracy: 0.9053\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2251 - accuracy: 0.9415 - val_loss: 0.3119 - val_accuracy: 0.9053\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2248 - accuracy: 0.9415 - val_loss: 0.3119 - val_accuracy: 0.9053\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2246 - accuracy: 0.9415 - val_loss: 0.3120 - val_accuracy: 0.9053\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2243 - accuracy: 0.9415 - val_loss: 0.3120 - val_accuracy: 0.9053\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2241 - accuracy: 0.9415 - val_loss: 0.3121 - val_accuracy: 0.9053\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2239 - accuracy: 0.9415 - val_loss: 0.3121 - val_accuracy: 0.9053\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2236 - accuracy: 0.9415 - val_loss: 0.3122 - val_accuracy: 0.9053\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2234 - accuracy: 0.9415 - val_loss: 0.3122 - val_accuracy: 0.9053\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2232 - accuracy: 0.9415 - val_loss: 0.3123 - val_accuracy: 0.9053\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2230 - accuracy: 0.9415 - val_loss: 0.3124 - val_accuracy: 0.9053\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2228 - accuracy: 0.9415 - val_loss: 0.3125 - val_accuracy: 0.9053\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2227 - accuracy: 0.9415 - val_loss: 0.3125 - val_accuracy: 0.9053\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2225 - accuracy: 0.9415 - val_loss: 0.3126 - val_accuracy: 0.9053\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2223 - accuracy: 0.9415 - val_loss: 0.3127 - val_accuracy: 0.9053\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2221 - accuracy: 0.9415 - val_loss: 0.3128 - val_accuracy: 0.9053\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2220 - accuracy: 0.9415 - val_loss: 0.3129 - val_accuracy: 0.9053\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2218 - accuracy: 0.9415 - val_loss: 0.3130 - val_accuracy: 0.9053\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2216 - accuracy: 0.9415 - val_loss: 0.3131 - val_accuracy: 0.9053\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2215 - accuracy: 0.9415 - val_loss: 0.3131 - val_accuracy: 0.9053\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2213 - accuracy: 0.9415 - val_loss: 0.3132 - val_accuracy: 0.9053\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.2212 - accuracy: 0.9415 - val_loss: 0.3133 - val_accuracy: 0.9053\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2210 - accuracy: 0.9415 - val_loss: 0.3134 - val_accuracy: 0.9053\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:128: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18 samples, validate on 5 samples\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.5877 - val_loss: 0.6882 - val_accuracy: 0.5579\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6888 - accuracy: 0.6053 - val_loss: 0.6870 - val_accuracy: 0.5684\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6872 - accuracy: 0.6140 - val_loss: 0.6857 - val_accuracy: 0.5684\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6855 - accuracy: 0.6170 - val_loss: 0.6845 - val_accuracy: 0.5684\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6839 - accuracy: 0.6199 - val_loss: 0.6833 - val_accuracy: 0.5789\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6824 - accuracy: 0.6257 - val_loss: 0.6821 - val_accuracy: 0.5684\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6808 - accuracy: 0.6316 - val_loss: 0.6809 - val_accuracy: 0.5789\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6792 - accuracy: 0.6462 - val_loss: 0.6797 - val_accuracy: 0.5789\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6777 - accuracy: 0.6696 - val_loss: 0.6785 - val_accuracy: 0.5895\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6761 - accuracy: 0.6696 - val_loss: 0.6773 - val_accuracy: 0.6000\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6746 - accuracy: 0.6725 - val_loss: 0.6760 - val_accuracy: 0.6000\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6730 - accuracy: 0.6725 - val_loss: 0.6748 - val_accuracy: 0.6105\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6715 - accuracy: 0.6754 - val_loss: 0.6737 - val_accuracy: 0.6211\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6699 - accuracy: 0.6842 - val_loss: 0.6725 - val_accuracy: 0.6211\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6683 - accuracy: 0.6988 - val_loss: 0.6714 - val_accuracy: 0.6211\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6668 - accuracy: 0.6988 - val_loss: 0.6702 - val_accuracy: 0.6211\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6653 - accuracy: 0.6988 - val_loss: 0.6690 - val_accuracy: 0.6211\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6638 - accuracy: 0.6988 - val_loss: 0.6679 - val_accuracy: 0.6316\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6623 - accuracy: 0.6988 - val_loss: 0.6667 - val_accuracy: 0.6421\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6609 - accuracy: 0.6988 - val_loss: 0.6656 - val_accuracy: 0.6526\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.6594 - accuracy: 0.7135 - val_loss: 0.6644 - val_accuracy: 0.6526\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6580 - accuracy: 0.7222 - val_loss: 0.6633 - val_accuracy: 0.6526\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6565 - accuracy: 0.7222 - val_loss: 0.6621 - val_accuracy: 0.6632\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6550 - accuracy: 0.7251 - val_loss: 0.6609 - val_accuracy: 0.6632\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6535 - accuracy: 0.7281 - val_loss: 0.6597 - val_accuracy: 0.6632\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6520 - accuracy: 0.7310 - val_loss: 0.6586 - val_accuracy: 0.6842\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6504 - accuracy: 0.7339 - val_loss: 0.6574 - val_accuracy: 0.6842\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.6489 - accuracy: 0.7310 - val_loss: 0.6562 - val_accuracy: 0.7053\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6474 - accuracy: 0.7398 - val_loss: 0.6550 - val_accuracy: 0.7053\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6459 - accuracy: 0.7456 - val_loss: 0.6538 - val_accuracy: 0.7053\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6443 - accuracy: 0.7485 - val_loss: 0.6525 - val_accuracy: 0.7053\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6428 - accuracy: 0.7544 - val_loss: 0.6513 - val_accuracy: 0.7158\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6413 - accuracy: 0.7573 - val_loss: 0.6500 - val_accuracy: 0.7158\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6397 - accuracy: 0.7602 - val_loss: 0.6488 - val_accuracy: 0.7158\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6382 - accuracy: 0.7602 - val_loss: 0.6475 - val_accuracy: 0.7158\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6366 - accuracy: 0.7661 - val_loss: 0.6462 - val_accuracy: 0.7158\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6350 - accuracy: 0.7690 - val_loss: 0.6449 - val_accuracy: 0.7158\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 222us/step - loss: 0.6334 - accuracy: 0.7690 - val_loss: 0.6436 - val_accuracy: 0.7158\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6318 - accuracy: 0.7807 - val_loss: 0.6423 - val_accuracy: 0.7158\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6302 - accuracy: 0.7865 - val_loss: 0.6409 - val_accuracy: 0.7158\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6285 - accuracy: 0.7865 - val_loss: 0.6396 - val_accuracy: 0.7263\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6269 - accuracy: 0.7865 - val_loss: 0.6382 - val_accuracy: 0.7263\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6252 - accuracy: 0.7895 - val_loss: 0.6368 - val_accuracy: 0.7368\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6235 - accuracy: 0.7924 - val_loss: 0.6354 - val_accuracy: 0.7368\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6217 - accuracy: 0.7924 - val_loss: 0.6340 - val_accuracy: 0.7368\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6200 - accuracy: 0.7924 - val_loss: 0.6326 - val_accuracy: 0.7368\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6183 - accuracy: 0.7953 - val_loss: 0.6312 - val_accuracy: 0.7368\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6165 - accuracy: 0.7982 - val_loss: 0.6297 - val_accuracy: 0.7474\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6147 - accuracy: 0.7982 - val_loss: 0.6282 - val_accuracy: 0.7579\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6129 - accuracy: 0.7982 - val_loss: 0.6267 - val_accuracy: 0.7789\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6110 - accuracy: 0.8012 - val_loss: 0.6252 - val_accuracy: 0.7789\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.6091 - accuracy: 0.8012 - val_loss: 0.6236 - val_accuracy: 0.7789\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6072 - accuracy: 0.8070 - val_loss: 0.6220 - val_accuracy: 0.7789\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6052 - accuracy: 0.8158 - val_loss: 0.6204 - val_accuracy: 0.7789\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6032 - accuracy: 0.8158 - val_loss: 0.6188 - val_accuracy: 0.7789\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.6012 - accuracy: 0.8216 - val_loss: 0.6171 - val_accuracy: 0.7789\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5991 - accuracy: 0.8246 - val_loss: 0.6154 - val_accuracy: 0.7789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5970 - accuracy: 0.8246 - val_loss: 0.6137 - val_accuracy: 0.7895\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5949 - accuracy: 0.8246 - val_loss: 0.6120 - val_accuracy: 0.7895\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5927 - accuracy: 0.8246 - val_loss: 0.6102 - val_accuracy: 0.7895\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5905 - accuracy: 0.8275 - val_loss: 0.6084 - val_accuracy: 0.7895\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.5882 - accuracy: 0.8275 - val_loss: 0.6065 - val_accuracy: 0.7895\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5859 - accuracy: 0.8275 - val_loss: 0.6046 - val_accuracy: 0.7895\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5835 - accuracy: 0.8363 - val_loss: 0.6027 - val_accuracy: 0.7895\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5811 - accuracy: 0.8363 - val_loss: 0.6008 - val_accuracy: 0.8000\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.5787 - accuracy: 0.8363 - val_loss: 0.5988 - val_accuracy: 0.8000\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5762 - accuracy: 0.8363 - val_loss: 0.5968 - val_accuracy: 0.8000\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.5737 - accuracy: 0.8363 - val_loss: 0.5947 - val_accuracy: 0.8000\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5711 - accuracy: 0.8363 - val_loss: 0.5926 - val_accuracy: 0.8105\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5685 - accuracy: 0.8363 - val_loss: 0.5905 - val_accuracy: 0.8105\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5658 - accuracy: 0.8363 - val_loss: 0.5883 - val_accuracy: 0.8105\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5631 - accuracy: 0.8392 - val_loss: 0.5861 - val_accuracy: 0.8105\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5603 - accuracy: 0.8392 - val_loss: 0.5839 - val_accuracy: 0.8211\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5575 - accuracy: 0.8392 - val_loss: 0.5816 - val_accuracy: 0.8211\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5546 - accuracy: 0.8392 - val_loss: 0.5792 - val_accuracy: 0.8211\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.5517 - accuracy: 0.8392 - val_loss: 0.5768 - val_accuracy: 0.8211\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5487 - accuracy: 0.8392 - val_loss: 0.5744 - val_accuracy: 0.8211\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5457 - accuracy: 0.8392 - val_loss: 0.5719 - val_accuracy: 0.8211\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.5427 - accuracy: 0.8450 - val_loss: 0.5694 - val_accuracy: 0.8211\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.5396 - accuracy: 0.8450 - val_loss: 0.5669 - val_accuracy: 0.8211\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5364 - accuracy: 0.8450 - val_loss: 0.5643 - val_accuracy: 0.8211\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5332 - accuracy: 0.8450 - val_loss: 0.5616 - val_accuracy: 0.8211\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.5299 - accuracy: 0.8450 - val_loss: 0.5590 - val_accuracy: 0.8211\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5266 - accuracy: 0.8450 - val_loss: 0.5563 - val_accuracy: 0.8211\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5232 - accuracy: 0.8450 - val_loss: 0.5535 - val_accuracy: 0.8211\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.5197 - accuracy: 0.8450 - val_loss: 0.5507 - val_accuracy: 0.8211\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5163 - accuracy: 0.8450 - val_loss: 0.5478 - val_accuracy: 0.8211\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.5127 - accuracy: 0.8450 - val_loss: 0.5449 - val_accuracy: 0.8211\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5091 - accuracy: 0.8509 - val_loss: 0.5420 - val_accuracy: 0.8211\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5054 - accuracy: 0.8509 - val_loss: 0.5390 - val_accuracy: 0.8211\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.5017 - accuracy: 0.8509 - val_loss: 0.5360 - val_accuracy: 0.8211\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4979 - accuracy: 0.8538 - val_loss: 0.5329 - val_accuracy: 0.8316\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4941 - accuracy: 0.8538 - val_loss: 0.5298 - val_accuracy: 0.8316\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4902 - accuracy: 0.8538 - val_loss: 0.5267 - val_accuracy: 0.8316\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4863 - accuracy: 0.8538 - val_loss: 0.5235 - val_accuracy: 0.8316\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4823 - accuracy: 0.8538 - val_loss: 0.5203 - val_accuracy: 0.8316\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4783 - accuracy: 0.8538 - val_loss: 0.5171 - val_accuracy: 0.8316\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4742 - accuracy: 0.8538 - val_loss: 0.5138 - val_accuracy: 0.8316\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4701 - accuracy: 0.8596 - val_loss: 0.5104 - val_accuracy: 0.8421\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4660 - accuracy: 0.8655 - val_loss: 0.5071 - val_accuracy: 0.8526\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.4618 - accuracy: 0.8684 - val_loss: 0.5037 - val_accuracy: 0.8526\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.4575 - accuracy: 0.8684 - val_loss: 0.5003 - val_accuracy: 0.8526\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.4532 - accuracy: 0.8743 - val_loss: 0.4968 - val_accuracy: 0.8526\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4489 - accuracy: 0.8743 - val_loss: 0.4934 - val_accuracy: 0.8526\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4445 - accuracy: 0.8743 - val_loss: 0.4899 - val_accuracy: 0.8632\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4402 - accuracy: 0.8801 - val_loss: 0.4863 - val_accuracy: 0.8632\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4357 - accuracy: 0.8830 - val_loss: 0.4828 - val_accuracy: 0.8632\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4313 - accuracy: 0.8860 - val_loss: 0.4793 - val_accuracy: 0.8632\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4269 - accuracy: 0.8918 - val_loss: 0.4757 - val_accuracy: 0.8632\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4224 - accuracy: 0.8918 - val_loss: 0.4721 - val_accuracy: 0.8632\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4179 - accuracy: 0.8918 - val_loss: 0.4686 - val_accuracy: 0.8737\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4134 - accuracy: 0.8918 - val_loss: 0.4650 - val_accuracy: 0.8737\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4089 - accuracy: 0.8918 - val_loss: 0.4614 - val_accuracy: 0.8737\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.4044 - accuracy: 0.8918 - val_loss: 0.4578 - val_accuracy: 0.8737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.3999 - accuracy: 0.8918 - val_loss: 0.4543 - val_accuracy: 0.8842\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3954 - accuracy: 0.8918 - val_loss: 0.4507 - val_accuracy: 0.8842\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3910 - accuracy: 0.8918 - val_loss: 0.4472 - val_accuracy: 0.8842\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3865 - accuracy: 0.8918 - val_loss: 0.4437 - val_accuracy: 0.8842\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3821 - accuracy: 0.8918 - val_loss: 0.4402 - val_accuracy: 0.8947\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3776 - accuracy: 0.8918 - val_loss: 0.4367 - val_accuracy: 0.8947\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3733 - accuracy: 0.9006 - val_loss: 0.4333 - val_accuracy: 0.9053\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3689 - accuracy: 0.9211 - val_loss: 0.4298 - val_accuracy: 0.8947\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3646 - accuracy: 0.9240 - val_loss: 0.4265 - val_accuracy: 0.9053\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3603 - accuracy: 0.9269 - val_loss: 0.4232 - val_accuracy: 0.9053\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3561 - accuracy: 0.9269 - val_loss: 0.4199 - val_accuracy: 0.9053\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3519 - accuracy: 0.9386 - val_loss: 0.4166 - val_accuracy: 0.9053\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3478 - accuracy: 0.9386 - val_loss: 0.4135 - val_accuracy: 0.9053\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3438 - accuracy: 0.9386 - val_loss: 0.4103 - val_accuracy: 0.9053\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.3398 - accuracy: 0.9386 - val_loss: 0.4073 - val_accuracy: 0.9053\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.3359 - accuracy: 0.9386 - val_loss: 0.4043 - val_accuracy: 0.9053\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3320 - accuracy: 0.9386 - val_loss: 0.4013 - val_accuracy: 0.9053\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.3282 - accuracy: 0.9386 - val_loss: 0.3984 - val_accuracy: 0.9053\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3246 - accuracy: 0.9386 - val_loss: 0.3956 - val_accuracy: 0.9053\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3209 - accuracy: 0.9386 - val_loss: 0.3929 - val_accuracy: 0.9053\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3174 - accuracy: 0.9386 - val_loss: 0.3902 - val_accuracy: 0.9053\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.3140 - accuracy: 0.9386 - val_loss: 0.3876 - val_accuracy: 0.9053\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3106 - accuracy: 0.9386 - val_loss: 0.3851 - val_accuracy: 0.9053\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3073 - accuracy: 0.9386 - val_loss: 0.3827 - val_accuracy: 0.9053\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3041 - accuracy: 0.9386 - val_loss: 0.3803 - val_accuracy: 0.9053\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.3010 - accuracy: 0.9386 - val_loss: 0.3780 - val_accuracy: 0.9053\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2980 - accuracy: 0.9386 - val_loss: 0.3758 - val_accuracy: 0.9053\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2951 - accuracy: 0.9386 - val_loss: 0.3737 - val_accuracy: 0.9053\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2923 - accuracy: 0.9386 - val_loss: 0.3716 - val_accuracy: 0.9053\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2896 - accuracy: 0.9386 - val_loss: 0.3696 - val_accuracy: 0.9053\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2869 - accuracy: 0.9386 - val_loss: 0.3677 - val_accuracy: 0.9053\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.2844 - accuracy: 0.9386 - val_loss: 0.3659 - val_accuracy: 0.9053\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2819 - accuracy: 0.9386 - val_loss: 0.3642 - val_accuracy: 0.9053\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2795 - accuracy: 0.9386 - val_loss: 0.3625 - val_accuracy: 0.9053\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2773 - accuracy: 0.9386 - val_loss: 0.3609 - val_accuracy: 0.9053\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2751 - accuracy: 0.9386 - val_loss: 0.3594 - val_accuracy: 0.9053\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2730 - accuracy: 0.9386 - val_loss: 0.3579 - val_accuracy: 0.9053\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2709 - accuracy: 0.9386 - val_loss: 0.3565 - val_accuracy: 0.9053\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2690 - accuracy: 0.9386 - val_loss: 0.3552 - val_accuracy: 0.9053\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2671 - accuracy: 0.9386 - val_loss: 0.3539 - val_accuracy: 0.9053\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2653 - accuracy: 0.9386 - val_loss: 0.3527 - val_accuracy: 0.9053\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.2636 - accuracy: 0.9386 - val_loss: 0.3516 - val_accuracy: 0.9053\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.2620 - accuracy: 0.9386 - val_loss: 0.3505 - val_accuracy: 0.9053\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2604 - accuracy: 0.9386 - val_loss: 0.3495 - val_accuracy: 0.9053\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2589 - accuracy: 0.9386 - val_loss: 0.3485 - val_accuracy: 0.9053\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2574 - accuracy: 0.9386 - val_loss: 0.3476 - val_accuracy: 0.9053\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2561 - accuracy: 0.9386 - val_loss: 0.3468 - val_accuracy: 0.9053\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2547 - accuracy: 0.9386 - val_loss: 0.3460 - val_accuracy: 0.9053\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2535 - accuracy: 0.9386 - val_loss: 0.3452 - val_accuracy: 0.9053\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2523 - accuracy: 0.9386 - val_loss: 0.3445 - val_accuracy: 0.9053\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2511 - accuracy: 0.9386 - val_loss: 0.3438 - val_accuracy: 0.9053\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.2500 - accuracy: 0.9386 - val_loss: 0.3432 - val_accuracy: 0.9053\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2490 - accuracy: 0.9386 - val_loss: 0.3426 - val_accuracy: 0.9053\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2480 - accuracy: 0.9386 - val_loss: 0.3420 - val_accuracy: 0.9053\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2470 - accuracy: 0.9386 - val_loss: 0.3415 - val_accuracy: 0.9053\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2461 - accuracy: 0.9386 - val_loss: 0.3410 - val_accuracy: 0.9053\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 167us/step - loss: 0.2452 - accuracy: 0.9386 - val_loss: 0.3406 - val_accuracy: 0.9053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2444 - accuracy: 0.9386 - val_loss: 0.3402 - val_accuracy: 0.9053\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2436 - accuracy: 0.9386 - val_loss: 0.3398 - val_accuracy: 0.9053\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2428 - accuracy: 0.9386 - val_loss: 0.3394 - val_accuracy: 0.9053\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2421 - accuracy: 0.9386 - val_loss: 0.3390 - val_accuracy: 0.9053\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2414 - accuracy: 0.9386 - val_loss: 0.3387 - val_accuracy: 0.9053\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 56us/step - loss: 0.2407 - accuracy: 0.9386 - val_loss: 0.3384 - val_accuracy: 0.9053\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2401 - accuracy: 0.9386 - val_loss: 0.3381 - val_accuracy: 0.9053\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2395 - accuracy: 0.9386 - val_loss: 0.3378 - val_accuracy: 0.9053\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2389 - accuracy: 0.9386 - val_loss: 0.3376 - val_accuracy: 0.9053\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2384 - accuracy: 0.9386 - val_loss: 0.3374 - val_accuracy: 0.9053\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2378 - accuracy: 0.9386 - val_loss: 0.3372 - val_accuracy: 0.9053\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2373 - accuracy: 0.9386 - val_loss: 0.3370 - val_accuracy: 0.9053\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2368 - accuracy: 0.9386 - val_loss: 0.3368 - val_accuracy: 0.9053\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2364 - accuracy: 0.9386 - val_loss: 0.3366 - val_accuracy: 0.9053\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2359 - accuracy: 0.9386 - val_loss: 0.3365 - val_accuracy: 0.9053\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2355 - accuracy: 0.9386 - val_loss: 0.3363 - val_accuracy: 0.9053\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2351 - accuracy: 0.9386 - val_loss: 0.3362 - val_accuracy: 0.9053\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2347 - accuracy: 0.9386 - val_loss: 0.3361 - val_accuracy: 0.9053\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2343 - accuracy: 0.9386 - val_loss: 0.3360 - val_accuracy: 0.9053\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2339 - accuracy: 0.9386 - val_loss: 0.3359 - val_accuracy: 0.9053\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2336 - accuracy: 0.9386 - val_loss: 0.3358 - val_accuracy: 0.9053\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2332 - accuracy: 0.9386 - val_loss: 0.3357 - val_accuracy: 0.9053\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2329 - accuracy: 0.9386 - val_loss: 0.3357 - val_accuracy: 0.9053\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2326 - accuracy: 0.9386 - val_loss: 0.3356 - val_accuracy: 0.9053\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2323 - accuracy: 0.9386 - val_loss: 0.3355 - val_accuracy: 0.9053\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2320 - accuracy: 0.9386 - val_loss: 0.3355 - val_accuracy: 0.9053\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2317 - accuracy: 0.9386 - val_loss: 0.3355 - val_accuracy: 0.9053\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2314 - accuracy: 0.9386 - val_loss: 0.3354 - val_accuracy: 0.9053\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 111us/step - loss: 0.2311 - accuracy: 0.9386 - val_loss: 0.3354 - val_accuracy: 0.9053\n",
      "[5, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[4, 1]\n",
      "[0, 0]\n",
      "[1, 0]\n",
      "[4, 0]\n",
      "[1, 0]\n",
      "[3, 1]\n",
      "[2, 0]\n",
      "[2, 1]\n",
      "[1, 1]\n",
      "[3, 0]\n",
      "[2, 0]\n",
      "[3, 0]\n",
      "[2, 0]\n",
      "[2, 1]\n",
      "[2, 1]\n",
      "[2, 0]\n",
      "[2, 1]\n",
      "[2, 0]\n",
      "[3, 0]\n",
      "[1, 1]\n",
      "[3, 0]\n",
      "[2, 0]\n",
      "[0, 0]\n",
      "[5, 0]\n",
      "[0, 0]\n",
      "[5, 0]\n",
      "[5, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[5, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[2, 1]\n",
      "[2, 0]\n",
      "[3, 0]\n",
      "[0, 2]\n",
      "both b and c are zero\n",
      "[2, 0]\n",
      "[3, 0]\n",
      "[2, 0]\n",
      "[3, 0]\n",
      "[4, 0]\n",
      "[1, 0]\n",
      "[4, 0]\n",
      "[1, 0]\n",
      "[1, 0]\n",
      "[4, 0]\n",
      "[1, 0]\n",
      "[4, 0]\n",
      "[2, 0]\n",
      "[2, 1]\n",
      "[2, 0]\n",
      "[3, 0]\n",
      "[4, 0]\n",
      "[1, 0]\n",
      "[3, 1]\n",
      "[1, 0]\n",
      "[3, 0]\n",
      "[2, 0]\n",
      "[3, 0]\n",
      "[2, 0]\n",
      "[4, 0]\n",
      "[1, 0]\n",
      "[4, 0]\n",
      "[1, 0]\n",
      "[3, 0]\n",
      "[2, 0]\n",
      "[3, 0]\n",
      "[2, 0]\n",
      "[3, 0]\n",
      "[2, 0]\n",
      "[2, 1]\n",
      "[2, 0]\n",
      "[5, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[5, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds of MWPM:\n",
      "> Accuracy: 0.9435087719298245 (+- 0.03231881807626512)\n",
      "> F1: 0.6415266106442576(+- 0.1642064136470523)\n",
      "> Time: 0.048210960000000004 (+- 0.002136356076687595)\n",
      "#####################################################################################\n",
      "Average scores for all folds of PLUT:\n",
      "> Accuracy: 0.9115789473684209 (+- 0.003437880340748317)\n",
      "> F1: 0.04(+- 0.08)\n",
      "> Time: 0.0 (+- 0.0)\n",
      "#####################################################################################\n",
      "Average scores for all folds of NN:\n",
      "> Accuracy: 0.860350883634467 (+- 0.14094872952295295)\n",
      "> F1: 0.07136408376607949(+- 0.059697642408967716)\n",
      "> Time: 0.0290062 (+- 0.0006319812149106967)\n",
      "#####################################################################################\n",
      "> AUC for class : 0.0 (+- 0.0)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 0.0\n",
      "> AUC for class X00: 0.25 (+- 0.25)\n",
      "X^2 for MWPM and NN: 6.25\n",
      "X^2 for PLUT and NN: 5.333333333333333\n",
      "> AUC for class X01: 0.675 (+- 0.07500000000000001)\n",
      "X^2 for MWPM and NN: 4.5\n",
      "X^2 for PLUT and NN: 2.25\n",
      "> AUC for class X02: 0.525 (+- 0.275)\n",
      "X^2 for MWPM and NN: 5.333333333333333\n",
      "X^2 for PLUT and NN: 4.5\n",
      "> AUC for class X10: 0.7 (+- 0.3)\n",
      "X^2 for MWPM and NN: 1.3333333333333333\n",
      "X^2 for PLUT and NN: 1.3333333333333333\n",
      "> AUC for class X11: 1.0 (+- 0.0)\n",
      "X^2 for MWPM and NN: 4.0\n",
      "X^2 for PLUT and NN: 4.5\n",
      "> AUC for class X12: 0.3 (+- 0.10000000000000003)\n",
      "X^2 for MWPM and NN: 7.2\n",
      "X^2 for PLUT and NN: 7.2\n",
      "> AUC for class X20: 1.0 (+- 0.0)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 0\n",
      "> AUC for class X21: 0.6666666666666667 (+- 0.0)\n",
      "X^2 for MWPM and NN: 1.3333333333333333\n",
      "X^2 for PLUT and NN: 0\n",
      "> AUC for class X22: 0.22499999999999998 (+- 0.025000000000000022)\n",
      "X^2 for MWPM and NN: 5.333333333333333\n",
      "X^2 for PLUT and NN: 5.333333333333333\n",
      "> AUC for class Z00: 0.625 (+- 0.375)\n",
      "X^2 for MWPM and NN: 4.0\n",
      "X^2 for PLUT and NN: 4.0\n",
      "> AUC for class Z01: 0.575 (+- 0.175)\n",
      "X^2 for MWPM and NN: 6.25\n",
      "X^2 for PLUT and NN: 6.25\n",
      "> AUC for class Z02: 0.5 (+- 0.0)\n",
      "X^2 for MWPM and NN: 4.5\n",
      "X^2 for PLUT and NN: 5.333333333333333\n",
      "> AUC for class Z10: 1.0 (+- 0.0)\n",
      "X^2 for MWPM and NN: 4.0\n",
      "X^2 for PLUT and NN: 0.5\n",
      "> AUC for class Z11: 0.875 (+- 0.0)\n",
      "X^2 for MWPM and NN: 4.5\n",
      "X^2 for PLUT and NN: 4.5\n",
      "> AUC for class Z12: 0.8 (+- 0.0)\n",
      "X^2 for MWPM and NN: 4.0\n",
      "X^2 for PLUT and NN: 4.0\n",
      "> AUC for class Z20: 0.25 (+- 0.0)\n",
      "X^2 for MWPM and NN: 4.5\n",
      "X^2 for PLUT and NN: 4.5\n",
      "> AUC for class Z21: 0.375 (+- 0.375)\n",
      "X^2 for MWPM and NN: 4.5\n",
      "X^2 for PLUT and NN: 1.3333333333333333\n",
      "> AUC for class Z22: 0.16666666666666669 (+- 0.0)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 0\n",
      "###################################################################################\n",
      "TOTAL F1 NN: [0.0, 0.13114754098360656, 0.09523809523809523, 0.0, 0.13043478260869565]\n",
      "TOTAL F1 PLUT: [0.0, 0.0, 0.0, 0.2, 0.0]\n",
      "TOTAL F1 MWPM: [0.6666666666666666, 0.625, 0.8571428571428571, 0.35294117647058826, 0.7058823529411764]\n",
      "TOTAL ACC NN: [0.9385964870452881, 0.9298245906829834, 0.9385964870452881, 0.9157894849777222, 0.5789473684210527]\n",
      "TOTAL ACC PLUT: [0.9122807017543858, 0.9122807017543858, 0.9122807017543858, 0.9157894736842105, 0.9052631578947368]\n",
      "TOTAL ACC MWPM: [0.9561403508771931, 0.9473684210526315, 0.9824561403508772, 0.8842105263157896, 0.9473684210526315]\n",
      "TOTAL TIME NN: [0.0290063, 0.0280068, 0.0290061, 0.0300053, 0.0290065]\n",
      "TOTAL TIME PLUT: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "TOTAL TIME MWPM: [0.051013100000000006, 0.045009799999999996, 0.0480109, 0.047010300000000005, 0.050010700000000005]\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:128: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\User\\anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "inputs = x_d3.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = y_d3.copy()\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "n_classes = 19\n",
    "\n",
    "acc_per_fold = []\n",
    "f1_per_fold = []\n",
    "time_per_fold = []\n",
    "\n",
    "\n",
    "acc_per_fold_plut = []\n",
    "f1_per_fold_plut = []\n",
    "time_per_fold_plut = []\n",
    "\n",
    "acc_per_fold_mwpm = []\n",
    "f1_per_fold_mwpm = []\n",
    "time_per_fold_mwpm = []\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "aucs_classes = {}\n",
    "for i in mlb_d3.classes_:\n",
    "    aucs_classes[i] = []\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#for i in range(5):\n",
    "    \n",
    "    # K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for i, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "    i_train = inputs[train].copy()\n",
    "    i_test = inputs[test].copy()\n",
    "    x_test_d3 = i_test[:,:2]\n",
    "    inputs_train = i_train[:,3:]\n",
    "    inputs_test = i_test[:,3:]\n",
    "    ####################################################################################################\n",
    "    #test MWPM decoder for this fold\n",
    "    #labels = targets[train], features = inputs[train]\n",
    "    #x_test_d3 = translate_to_graph(testData_d3_MWPM, targets[test], mlb_d3)\n",
    "    decoding_d3, time_mwpm = do_new_decoding(x_test_d3, 3, .03)\n",
    "    decoding_d3['combine'] = decoding_d3[[0, 1]].values.tolist()\n",
    "    decoding_d3['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "    decoding_d3 = np.array(decoding_d3[0])\n",
    "\n",
    "    time_per_fold_mwpm.append(time_mwpm)\n",
    "\n",
    "    pred_mwpm = mlb_d3.transform(decoding_d3)\n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_mwpm)\n",
    "    else:\n",
    "        acc, contingency_mwpm = partial_accuracy_and_contingency(targets[test], pred_mwpm, mlb_d3)\n",
    "        \n",
    "    acc_per_fold_mwpm.append(acc)\n",
    "    f1_per_fold_mwpm.append(f1_score(targets[test], pred_mwpm, average='micro'))\n",
    "\n",
    "\n",
    "    #####################################################################################################\n",
    "    #test the plut decoder for this fold\n",
    "\n",
    "    lookup_d3 = lookup_decoder(3)\n",
    "\n",
    "    lookup_d3 = train_plut(lookup_d3, inputs_train, targets[train])\n",
    "\n",
    "    start = time.time_ns()\n",
    "    pred_plut_d3 = test_plut(lookup_d3, inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_plut_d3)\n",
    "    else:\n",
    "        acc, contingency_plut = partial_accuracy_and_contingency(targets[test], pred_plut_d3, mlb_d3)\n",
    "\n",
    "    acc_per_fold_plut.append(acc)\n",
    "    f1_per_fold_plut.append(f1_score(targets[test], pred_plut_d3, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #Test the NN decoder for this fold\n",
    "\n",
    "    model = compile_FFNN_model_DepthThree(3)\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "\n",
    "    history = model.fit(\n",
    "        inputs_train, targets[train],\n",
    "        validation_split=.2,\n",
    "        epochs=200,\n",
    "        verbose=1)\n",
    "\n",
    "   # Generate generalization metrics\n",
    "    scores = model.evaluate(inputs_test, targets[test], verbose=0)\n",
    "\n",
    "    #get the time to predicting test\n",
    "    start = time.time_ns()\n",
    "    predictions_d3 = model.predict(inputs_test) #change here\n",
    "    end = time.time_ns()\n",
    "    time_per_fold.append((end - start)/ (10 ** 9))\n",
    "\n",
    "    #threshold based on previous tests with train_test_split in hyperparameter tuning\n",
    "    pred=predictions_d3.copy() #change here\n",
    "    pred[pred>=.1]=1 \n",
    "    pred[pred<.1]=0\n",
    "    \n",
    "    if fold_no <5:\n",
    "        acc = scores[1]\n",
    "    else:\n",
    "        acc, contingency_nn = partial_accuracy_and_contingency(targets[test], pred, mlb_d3)\n",
    "\n",
    "    acc_per_fold.append(acc)\n",
    "    f1_per_fold.append(f1_score(targets[test], pred, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #comput ROC AUC for classes and the mircoaverage\n",
    "    fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d3.ravel())\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    #get the AUCs of each class, used to get average AUC of each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d3[:, i]) #change here\n",
    "        aucs_classes[mlb_d3.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "        \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "        \n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb_d3.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "    \n",
    "############print mean and stdev of AUC of each class#####################      \n",
    "    \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print(\"#####################################################################################\")\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print(\"#####################################################################################\")\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "print(\"#####################################################################################\")\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 3 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_train_d3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-67e2e66d47b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fit model on training data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m history = model.fit(\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train_d3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_train_d3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train_d3' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "model = compile_FFNN_model_DepthThree(3)\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x=x_train_d3.values,\n",
    "    y=Y_train_d3,\n",
    "    validation_split=.25,\n",
    "    epochs=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss (MSE)')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Make a quick epoch vs. loss plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Depth 3 Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Make a quick epoch vs. accuracy plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Depth 3 Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[(0, -0.5, 0.5)]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-fc8d9ea9ee82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions_d3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_d3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Time: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CNNs\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m                                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CNNs\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CNNs\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3719\u001b[0m               'You must feed a value for placeholder %s' % (tensor,))\n\u001b[0;32m   3720\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3721\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3722\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3723\u001b[0m         \u001b[1;31m# Temporary workaround due to `convert_to_tensor` not casting floats.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CNNs\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CNNs\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CNNs\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    256\u001b[0m   \"\"\"\n\u001b[0;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 258\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CNNs\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    264\u001b[0m   \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CNNs\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '[(0, -0.5, 0.5)]'"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "predictions_d3 = model.predict(x_test_d3.values)\n",
    "end = time.time()\n",
    "print(\"Time: \" + str(end - start))\n",
    "# predict\n",
    "\n",
    "thresholds=[0.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "for val in thresholds:\n",
    "    pred=predictions_d3.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "\n",
    "    precision = precision_score(Y_test_d3, pred, average='micro')\n",
    "    recall = recall_score(Y_test_d3, pred, average='micro')\n",
    "    f1 = f1_score(Y_test_d3, pred, average='micro')\n",
    "   \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "    print(\"Accuracy = \",accuracy_score(Y_test_d3, pred))\n",
    "    print(\"Partial Accuracy = \",partial_accuracy(Y_test_d3, pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Train on 1665 samples, validate on 555 samples\n",
      "Epoch 1/800\n",
      "1665/1665 [==============================] - 0s 162us/step - loss: 0.5803 - accuracy: 0.8328 - val_loss: 0.4023 - val_accuracy: 0.9326\n",
      "Epoch 2/800\n",
      "1665/1665 [==============================] - 0s 86us/step - loss: 0.2260 - accuracy: 0.9538 - val_loss: 0.2529 - val_accuracy: 0.9326\n",
      "Epoch 3/800\n",
      "1665/1665 [==============================] - 0s 104us/step - loss: 0.1889 - accuracy: 0.9538 - val_loss: 0.2510 - val_accuracy: 0.9326\n",
      "Epoch 4/800\n",
      "1665/1665 [==============================] - 0s 84us/step - loss: 0.1873 - accuracy: 0.9538 - val_loss: 0.2504 - val_accuracy: 0.9326\n",
      "Epoch 5/800\n",
      "1665/1665 [==============================] - 0s 93us/step - loss: 0.1867 - accuracy: 0.9538 - val_loss: 0.2500 - val_accuracy: 0.9326\n",
      "Epoch 6/800\n",
      "1665/1665 [==============================] - 0s 113us/step - loss: 0.1863 - accuracy: 0.9538 - val_loss: 0.2501 - val_accuracy: 0.9326\n",
      "Epoch 7/800\n",
      "1665/1665 [==============================] - 0s 94us/step - loss: 0.1862 - accuracy: 0.9538 - val_loss: 0.2493 - val_accuracy: 0.9326\n",
      "Epoch 8/800\n",
      "1665/1665 [==============================] - 0s 88us/step - loss: 0.1861 - accuracy: 0.9538 - val_loss: 0.2492 - val_accuracy: 0.9326\n",
      "Epoch 9/800\n",
      "1665/1665 [==============================] - 0s 89us/step - loss: 0.1859 - accuracy: 0.9538 - val_loss: 0.2492 - val_accuracy: 0.9326\n",
      "Epoch 10/800\n",
      "1665/1665 [==============================] - 0s 89us/step - loss: 0.1859 - accuracy: 0.9538 - val_loss: 0.2494 - val_accuracy: 0.9326\n",
      "Epoch 11/800\n",
      "1665/1665 [==============================] - 0s 88us/step - loss: 0.1858 - accuracy: 0.9538 - val_loss: 0.2489 - val_accuracy: 0.9326\n",
      "Epoch 12/800\n",
      "1665/1665 [==============================] - 0s 85us/step - loss: 0.1856 - accuracy: 0.9538 - val_loss: 0.2488 - val_accuracy: 0.9326\n",
      "Epoch 13/800\n",
      "1665/1665 [==============================] - 0s 86us/step - loss: 0.1855 - accuracy: 0.9538 - val_loss: 0.2485 - val_accuracy: 0.9326\n",
      "Epoch 14/800\n",
      "1665/1665 [==============================] - 0s 91us/step - loss: 0.1854 - accuracy: 0.9538 - val_loss: 0.2485 - val_accuracy: 0.9326\n",
      "Epoch 15/800\n",
      "1665/1665 [==============================] - 0s 92us/step - loss: 0.1854 - accuracy: 0.9538 - val_loss: 0.2492 - val_accuracy: 0.9326\n",
      "Epoch 16/800\n",
      "1665/1665 [==============================] - 0s 98us/step - loss: 0.1852 - accuracy: 0.9538 - val_loss: 0.2484 - val_accuracy: 0.9326\n",
      "Epoch 17/800\n",
      "1665/1665 [==============================] - 0s 93us/step - loss: 0.1851 - accuracy: 0.9538 - val_loss: 0.2483 - val_accuracy: 0.9326\n",
      "Epoch 18/800\n",
      "1665/1665 [==============================] - 0s 102us/step - loss: 0.1850 - accuracy: 0.9538 - val_loss: 0.2482 - val_accuracy: 0.9326\n",
      "Epoch 19/800\n",
      "1665/1665 [==============================] - 0s 101us/step - loss: 0.1849 - accuracy: 0.9538 - val_loss: 0.2478 - val_accuracy: 0.9326\n",
      "Epoch 20/800\n",
      "1665/1665 [==============================] - 0s 99us/step - loss: 0.1847 - accuracy: 0.9538 - val_loss: 0.2475 - val_accuracy: 0.9326\n",
      "Epoch 21/800\n",
      "1665/1665 [==============================] - 0s 101us/step - loss: 0.1847 - accuracy: 0.9538 - val_loss: 0.2473 - val_accuracy: 0.9326\n",
      "Epoch 22/800\n",
      "1665/1665 [==============================] - 0s 98us/step - loss: 0.1846 - accuracy: 0.9538 - val_loss: 0.2479 - val_accuracy: 0.9326\n",
      "Epoch 23/800\n",
      "1665/1665 [==============================] - 0s 98us/step - loss: 0.1845 - accuracy: 0.9538 - val_loss: 0.2475 - val_accuracy: 0.9326\n",
      "Epoch 24/800\n",
      "1665/1665 [==============================] - 0s 95us/step - loss: 0.1844 - accuracy: 0.9538 - val_loss: 0.2469 - val_accuracy: 0.9326\n",
      "Epoch 25/800\n",
      "1665/1665 [==============================] - 0s 101us/step - loss: 0.1843 - accuracy: 0.9538 - val_loss: 0.2467 - val_accuracy: 0.9326\n",
      "Epoch 26/800\n",
      "1665/1665 [==============================] - 0s 105us/step - loss: 0.1841 - accuracy: 0.9538 - val_loss: 0.2470 - val_accuracy: 0.9326\n",
      "Epoch 27/800\n",
      "1665/1665 [==============================] - 0s 95us/step - loss: 0.1840 - accuracy: 0.9538 - val_loss: 0.2462 - val_accuracy: 0.9326\n",
      "Epoch 28/800\n",
      "1665/1665 [==============================] - 0s 93us/step - loss: 0.1839 - accuracy: 0.9538 - val_loss: 0.2458 - val_accuracy: 0.9326\n",
      "Epoch 29/800\n",
      "1665/1665 [==============================] - 0s 98us/step - loss: 0.1838 - accuracy: 0.9538 - val_loss: 0.2458 - val_accuracy: 0.9326\n",
      "Epoch 30/800\n",
      "1665/1665 [==============================] - 0s 92us/step - loss: 0.1837 - accuracy: 0.9538 - val_loss: 0.2463 - val_accuracy: 0.9326\n",
      "Epoch 31/800\n",
      "1665/1665 [==============================] - 0s 97us/step - loss: 0.1836 - accuracy: 0.9538 - val_loss: 0.2461 - val_accuracy: 0.9326\n",
      "Epoch 32/800\n",
      "1665/1665 [==============================] - 0s 99us/step - loss: 0.1835 - accuracy: 0.9538 - val_loss: 0.2462 - val_accuracy: 0.9326\n",
      "Epoch 33/800\n",
      "1665/1665 [==============================] - 0s 93us/step - loss: 0.1834 - accuracy: 0.9538 - val_loss: 0.2455 - val_accuracy: 0.9326\n",
      "Epoch 34/800\n",
      "1665/1665 [==============================] - 0s 93us/step - loss: 0.1833 - accuracy: 0.9538 - val_loss: 0.2459 - val_accuracy: 0.9326\n",
      "Epoch 35/800\n",
      "1665/1665 [==============================] - 0s 102us/step - loss: 0.1831 - accuracy: 0.9538 - val_loss: 0.2456 - val_accuracy: 0.9326\n",
      "Epoch 36/800\n",
      "1665/1665 [==============================] - 0s 99us/step - loss: 0.1830 - accuracy: 0.9538 - val_loss: 0.2453 - val_accuracy: 0.9326\n",
      "Epoch 37/800\n",
      "1665/1665 [==============================] - 0s 98us/step - loss: 0.1829 - accuracy: 0.9538 - val_loss: 0.2445 - val_accuracy: 0.9326\n",
      "Epoch 38/800\n",
      "1665/1665 [==============================] - 0s 101us/step - loss: 0.1827 - accuracy: 0.9538 - val_loss: 0.2443 - val_accuracy: 0.9326\n",
      "Epoch 39/800\n",
      "1665/1665 [==============================] - 0s 102us/step - loss: 0.1826 - accuracy: 0.9538 - val_loss: 0.2439 - val_accuracy: 0.9326\n",
      "Epoch 40/800\n",
      "1665/1665 [==============================] - 0s 102us/step - loss: 0.1824 - accuracy: 0.9538 - val_loss: 0.2438 - val_accuracy: 0.9326\n",
      "Epoch 41/800\n",
      "1665/1665 [==============================] - 0s 98us/step - loss: 0.1823 - accuracy: 0.9538 - val_loss: 0.2440 - val_accuracy: 0.9326\n",
      "Epoch 42/800\n",
      "1665/1665 [==============================] - 0s 99us/step - loss: 0.1822 - accuracy: 0.9538 - val_loss: 0.2435 - val_accuracy: 0.9326\n",
      "Epoch 43/800\n",
      "1665/1665 [==============================] - 0s 99us/step - loss: 0.1820 - accuracy: 0.9538 - val_loss: 0.2437 - val_accuracy: 0.9326\n",
      "Epoch 44/800\n",
      "1665/1665 [==============================] - 0s 98us/step - loss: 0.1818 - accuracy: 0.9538 - val_loss: 0.2428 - val_accuracy: 0.9326\n",
      "Epoch 45/800\n",
      "1665/1665 [==============================] - 0s 92us/step - loss: 0.1817 - accuracy: 0.9538 - val_loss: 0.2429 - val_accuracy: 0.9326\n",
      "Epoch 46/800\n",
      "1665/1665 [==============================] - 0s 96us/step - loss: 0.1815 - accuracy: 0.9538 - val_loss: 0.2424 - val_accuracy: 0.9326\n",
      "Epoch 47/800\n",
      "1665/1665 [==============================] - 0s 92us/step - loss: 0.1812 - accuracy: 0.9538 - val_loss: 0.2423 - val_accuracy: 0.9326\n",
      "Epoch 48/800\n",
      "1665/1665 [==============================] - 0s 94us/step - loss: 0.1810 - accuracy: 0.9538 - val_loss: 0.2421 - val_accuracy: 0.9326\n",
      "Epoch 49/800\n",
      "1665/1665 [==============================] - 0s 91us/step - loss: 0.1808 - accuracy: 0.9538 - val_loss: 0.2416 - val_accuracy: 0.9326\n",
      "Epoch 50/800\n",
      "1665/1665 [==============================] - 0s 88us/step - loss: 0.1807 - accuracy: 0.9538 - val_loss: 0.2410 - val_accuracy: 0.9326\n",
      "Epoch 51/800\n",
      "1665/1665 [==============================] - 0s 90us/step - loss: 0.1804 - accuracy: 0.9538 - val_loss: 0.2410 - val_accuracy: 0.9326\n",
      "Epoch 52/800\n",
      "1665/1665 [==============================] - 0s 89us/step - loss: 0.1803 - accuracy: 0.9538 - val_loss: 0.2409 - val_accuracy: 0.9326\n",
      "Epoch 53/800\n",
      "1665/1665 [==============================] - 0s 89us/step - loss: 0.1800 - accuracy: 0.9538 - val_loss: 0.2405 - val_accuracy: 0.9326\n",
      "Epoch 54/800\n",
      "1665/1665 [==============================] - 0s 100us/step - loss: 0.1798 - accuracy: 0.9538 - val_loss: 0.2406 - val_accuracy: 0.9326\n",
      "Epoch 55/800\n",
      "1665/1665 [==============================] - 0s 88us/step - loss: 0.1795 - accuracy: 0.9538 - val_loss: 0.2393 - val_accuracy: 0.9326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/800\n",
      "1665/1665 [==============================] - 0s 89us/step - loss: 0.1793 - accuracy: 0.9538 - val_loss: 0.2396 - val_accuracy: 0.9326\n",
      "Epoch 57/800\n",
      "1665/1665 [==============================] - 0s 96us/step - loss: 0.1790 - accuracy: 0.9538 - val_loss: 0.2397 - val_accuracy: 0.9326\n",
      "Epoch 58/800\n",
      "1665/1665 [==============================] - 0s 98us/step - loss: 0.1788 - accuracy: 0.9538 - val_loss: 0.2392 - val_accuracy: 0.9326\n",
      "Epoch 59/800\n",
      "1665/1665 [==============================] - 0s 94us/step - loss: 0.1785 - accuracy: 0.9538 - val_loss: 0.2389 - val_accuracy: 0.9326\n",
      "Epoch 60/800\n",
      "1665/1665 [==============================] - 0s 109us/step - loss: 0.1782 - accuracy: 0.9538 - val_loss: 0.2381 - val_accuracy: 0.9326\n",
      "Epoch 61/800\n",
      "1665/1665 [==============================] - 0s 98us/step - loss: 0.1779 - accuracy: 0.9538 - val_loss: 0.2367 - val_accuracy: 0.9326\n",
      "Epoch 62/800\n",
      "1665/1665 [==============================] - 0s 98us/step - loss: 0.1777 - accuracy: 0.9538 - val_loss: 0.2374 - val_accuracy: 0.9326\n",
      "Epoch 63/800\n",
      "1665/1665 [==============================] - 0s 101us/step - loss: 0.1773 - accuracy: 0.9538 - val_loss: 0.2369 - val_accuracy: 0.9326\n",
      "Epoch 64/800\n",
      "1665/1665 [==============================] - 0s 99us/step - loss: 0.1770 - accuracy: 0.9538 - val_loss: 0.2367 - val_accuracy: 0.9326\n",
      "Epoch 65/800\n",
      "1665/1665 [==============================] - 0s 101us/step - loss: 0.1767 - accuracy: 0.9538 - val_loss: 0.2361 - val_accuracy: 0.9326\n",
      "Epoch 66/800\n",
      "1665/1665 [==============================] - 0s 98us/step - loss: 0.1763 - accuracy: 0.9538 - val_loss: 0.2352 - val_accuracy: 0.9326\n",
      "Epoch 67/800\n",
      "1665/1665 [==============================] - 0s 98us/step - loss: 0.1760 - accuracy: 0.9538 - val_loss: 0.2348 - val_accuracy: 0.9326\n",
      "Epoch 68/800\n",
      "1665/1665 [==============================] - 0s 90us/step - loss: 0.1755 - accuracy: 0.9538 - val_loss: 0.2341 - val_accuracy: 0.9326\n",
      "Epoch 69/800\n",
      "1665/1665 [==============================] - 0s 93us/step - loss: 0.1751 - accuracy: 0.9538 - val_loss: 0.2334 - val_accuracy: 0.9326\n",
      "Epoch 70/800\n",
      "1665/1665 [==============================] - 0s 86us/step - loss: 0.1747 - accuracy: 0.9538 - val_loss: 0.2326 - val_accuracy: 0.9326\n",
      "Epoch 71/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1743 - accuracy: 0.9538 - val_loss: 0.2322 - val_accuracy: 0.9326\n",
      "Epoch 72/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1739 - accuracy: 0.9538 - val_loss: 0.2319 - val_accuracy: 0.9326\n",
      "Epoch 73/800\n",
      "1665/1665 [==============================] - 0s 90us/step - loss: 0.1734 - accuracy: 0.9538 - val_loss: 0.2314 - val_accuracy: 0.9326\n",
      "Epoch 74/800\n",
      "1665/1665 [==============================] - 0s 86us/step - loss: 0.1729 - accuracy: 0.9538 - val_loss: 0.2298 - val_accuracy: 0.9326\n",
      "Epoch 75/800\n",
      "1665/1665 [==============================] - 0s 88us/step - loss: 0.1725 - accuracy: 0.9538 - val_loss: 0.2291 - val_accuracy: 0.9326\n",
      "Epoch 76/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1720 - accuracy: 0.9538 - val_loss: 0.2295 - val_accuracy: 0.9326\n",
      "Epoch 77/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1715 - accuracy: 0.9538 - val_loss: 0.2284 - val_accuracy: 0.9326\n",
      "Epoch 78/800\n",
      "1665/1665 [==============================] - 0s 82us/step - loss: 0.1710 - accuracy: 0.9538 - val_loss: 0.2275 - val_accuracy: 0.9326\n",
      "Epoch 79/800\n",
      "1665/1665 [==============================] - 0s 85us/step - loss: 0.1705 - accuracy: 0.9538 - val_loss: 0.2268 - val_accuracy: 0.9326\n",
      "Epoch 80/800\n",
      "1665/1665 [==============================] - 0s 88us/step - loss: 0.1699 - accuracy: 0.9538 - val_loss: 0.2262 - val_accuracy: 0.9326\n",
      "Epoch 81/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1694 - accuracy: 0.9538 - val_loss: 0.2256 - val_accuracy: 0.9327\n",
      "Epoch 82/800\n",
      "1665/1665 [==============================] - 0s 88us/step - loss: 0.1689 - accuracy: 0.9538 - val_loss: 0.2246 - val_accuracy: 0.9327\n",
      "Epoch 83/800\n",
      "1665/1665 [==============================] - 0s 88us/step - loss: 0.1683 - accuracy: 0.9538 - val_loss: 0.2239 - val_accuracy: 0.9327\n",
      "Epoch 84/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1676 - accuracy: 0.9538 - val_loss: 0.2234 - val_accuracy: 0.9327\n",
      "Epoch 85/800\n",
      "1665/1665 [==============================] - 0s 86us/step - loss: 0.1671 - accuracy: 0.9538 - val_loss: 0.2217 - val_accuracy: 0.9328\n",
      "Epoch 86/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1665 - accuracy: 0.9538 - val_loss: 0.2209 - val_accuracy: 0.9328\n",
      "Epoch 87/800\n",
      "1665/1665 [==============================] - 0s 86us/step - loss: 0.1660 - accuracy: 0.9538 - val_loss: 0.2211 - val_accuracy: 0.9328\n",
      "Epoch 88/800\n",
      "1665/1665 [==============================] - 0s 84us/step - loss: 0.1653 - accuracy: 0.9539 - val_loss: 0.2202 - val_accuracy: 0.9328\n",
      "Epoch 89/800\n",
      "1665/1665 [==============================] - 0s 86us/step - loss: 0.1648 - accuracy: 0.9539 - val_loss: 0.2180 - val_accuracy: 0.9328\n",
      "Epoch 90/800\n",
      "1665/1665 [==============================] - 0s 83us/step - loss: 0.1642 - accuracy: 0.9539 - val_loss: 0.2185 - val_accuracy: 0.9328\n",
      "Epoch 91/800\n",
      "1665/1665 [==============================] - 0s 84us/step - loss: 0.1636 - accuracy: 0.9539 - val_loss: 0.2177 - val_accuracy: 0.9328\n",
      "Epoch 92/800\n",
      "1665/1665 [==============================] - 0s 84us/step - loss: 0.1630 - accuracy: 0.9540 - val_loss: 0.2171 - val_accuracy: 0.9328\n",
      "Epoch 93/800\n",
      "1665/1665 [==============================] - 0s 86us/step - loss: 0.1624 - accuracy: 0.9540 - val_loss: 0.2157 - val_accuracy: 0.9328\n",
      "Epoch 94/800\n",
      "1665/1665 [==============================] - 0s 86us/step - loss: 0.1618 - accuracy: 0.9540 - val_loss: 0.2147 - val_accuracy: 0.9328\n",
      "Epoch 95/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1612 - accuracy: 0.9540 - val_loss: 0.2140 - val_accuracy: 0.9327\n",
      "Epoch 96/800\n",
      "1665/1665 [==============================] - 0s 125us/step - loss: 0.1606 - accuracy: 0.9540 - val_loss: 0.2138 - val_accuracy: 0.9327\n",
      "Epoch 97/800\n",
      "1665/1665 [==============================] - 0s 96us/step - loss: 0.1601 - accuracy: 0.9540 - val_loss: 0.2127 - val_accuracy: 0.9328\n",
      "Epoch 98/800\n",
      "1665/1665 [==============================] - 0s 90us/step - loss: 0.1595 - accuracy: 0.9540 - val_loss: 0.2127 - val_accuracy: 0.9330\n",
      "Epoch 99/800\n",
      "1665/1665 [==============================] - 0s 84us/step - loss: 0.1590 - accuracy: 0.9540 - val_loss: 0.2110 - val_accuracy: 0.9328\n",
      "Epoch 100/800\n",
      "1665/1665 [==============================] - 0s 83us/step - loss: 0.1583 - accuracy: 0.9541 - val_loss: 0.2091 - val_accuracy: 0.9327\n",
      "Epoch 101/800\n",
      "1665/1665 [==============================] - 0s 99us/step - loss: 0.1577 - accuracy: 0.9541 - val_loss: 0.2089 - val_accuracy: 0.9327\n",
      "Epoch 102/800\n",
      "1665/1665 [==============================] - 0s 92us/step - loss: 0.1572 - accuracy: 0.9541 - val_loss: 0.2087 - val_accuracy: 0.9327\n",
      "Epoch 103/800\n",
      "1665/1665 [==============================] - 0s 88us/step - loss: 0.1566 - accuracy: 0.9541 - val_loss: 0.2082 - val_accuracy: 0.9328\n",
      "Epoch 104/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1560 - accuracy: 0.9541 - val_loss: 0.2083 - val_accuracy: 0.9328\n",
      "Epoch 105/800\n",
      "1665/1665 [==============================] - 0s 130us/step - loss: 0.1554 - accuracy: 0.9541 - val_loss: 0.2066 - val_accuracy: 0.9327\n",
      "Epoch 106/800\n",
      "1665/1665 [==============================] - 0s 108us/step - loss: 0.1548 - accuracy: 0.9542 - val_loss: 0.2063 - val_accuracy: 0.9328\n",
      "Epoch 107/800\n",
      "1665/1665 [==============================] - 0s 126us/step - loss: 0.1543 - accuracy: 0.9541 - val_loss: 0.2047 - val_accuracy: 0.9328\n",
      "Epoch 108/800\n",
      "1665/1665 [==============================] - 0s 126us/step - loss: 0.1538 - accuracy: 0.9542 - val_loss: 0.2042 - val_accuracy: 0.9331\n",
      "Epoch 109/800\n",
      "1665/1665 [==============================] - 0s 108us/step - loss: 0.1532 - accuracy: 0.9542 - val_loss: 0.2034 - val_accuracy: 0.9330\n",
      "Epoch 110/800\n",
      "1665/1665 [==============================] - 0s 127us/step - loss: 0.1527 - accuracy: 0.9543 - val_loss: 0.2027 - val_accuracy: 0.9331\n",
      "Epoch 111/800\n",
      "1665/1665 [==============================] - 0s 134us/step - loss: 0.1522 - accuracy: 0.9543 - val_loss: 0.2021 - val_accuracy: 0.9329\n",
      "Epoch 112/800\n",
      "1665/1665 [==============================] - 0s 123us/step - loss: 0.1516 - accuracy: 0.9543 - val_loss: 0.2013 - val_accuracy: 0.9327\n",
      "Epoch 113/800\n",
      "1665/1665 [==============================] - 0s 114us/step - loss: 0.1511 - accuracy: 0.9543 - val_loss: 0.2006 - val_accuracy: 0.9328\n",
      "Epoch 114/800\n",
      "1665/1665 [==============================] - 0s 135us/step - loss: 0.1506 - accuracy: 0.9544 - val_loss: 0.2010 - val_accuracy: 0.9329\n",
      "Epoch 115/800\n",
      "1665/1665 [==============================] - 0s 170us/step - loss: 0.1501 - accuracy: 0.9544 - val_loss: 0.1987 - val_accuracy: 0.9330\n",
      "Epoch 116/800\n",
      "1665/1665 [==============================] - 0s 172us/step - loss: 0.1496 - accuracy: 0.9545 - val_loss: 0.1988 - val_accuracy: 0.9331\n",
      "Epoch 117/800\n",
      "1665/1665 [==============================] - 0s 131us/step - loss: 0.1491 - accuracy: 0.9545 - val_loss: 0.1988 - val_accuracy: 0.9333\n",
      "Epoch 118/800\n",
      "1665/1665 [==============================] - 0s 110us/step - loss: 0.1485 - accuracy: 0.9545 - val_loss: 0.1976 - val_accuracy: 0.9334\n",
      "Epoch 119/800\n",
      "1665/1665 [==============================] - 0s 142us/step - loss: 0.1481 - accuracy: 0.9546 - val_loss: 0.1969 - val_accuracy: 0.9334\n",
      "Epoch 120/800\n",
      "1665/1665 [==============================] - 0s 93us/step - loss: 0.1477 - accuracy: 0.9546 - val_loss: 0.1963 - val_accuracy: 0.9336\n",
      "Epoch 121/800\n",
      "1665/1665 [==============================] - 0s 90us/step - loss: 0.1472 - accuracy: 0.9546 - val_loss: 0.1958 - val_accuracy: 0.9332\n",
      "Epoch 122/800\n",
      "1665/1665 [==============================] - 0s 89us/step - loss: 0.1467 - accuracy: 0.9546 - val_loss: 0.1948 - val_accuracy: 0.9338\n",
      "Epoch 123/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1462 - accuracy: 0.9546 - val_loss: 0.1949 - val_accuracy: 0.9335\n",
      "Epoch 124/800\n",
      "1665/1665 [==============================] - 0s 86us/step - loss: 0.1457 - accuracy: 0.9548 - val_loss: 0.1928 - val_accuracy: 0.9336\n",
      "Epoch 125/800\n",
      "1665/1665 [==============================] - 0s 85us/step - loss: 0.1453 - accuracy: 0.9547 - val_loss: 0.1933 - val_accuracy: 0.9340\n",
      "Epoch 126/800\n",
      "1665/1665 [==============================] - 0s 88us/step - loss: 0.1449 - accuracy: 0.9547 - val_loss: 0.1927 - val_accuracy: 0.9338\n",
      "Epoch 127/800\n",
      "1665/1665 [==============================] - 0s 93us/step - loss: 0.1443 - accuracy: 0.9547 - val_loss: 0.1953 - val_accuracy: 0.9329\n",
      "Epoch 128/800\n",
      "1665/1665 [==============================] - 0s 86us/step - loss: 0.1441 - accuracy: 0.9548 - val_loss: 0.1920 - val_accuracy: 0.9336\n",
      "Epoch 129/800\n",
      "1665/1665 [==============================] - 0s 86us/step - loss: 0.1434 - accuracy: 0.9547 - val_loss: 0.1907 - val_accuracy: 0.9338\n",
      "Epoch 130/800\n",
      "1665/1665 [==============================] - 0s 85us/step - loss: 0.1429 - accuracy: 0.9548 - val_loss: 0.1914 - val_accuracy: 0.9340\n",
      "Epoch 131/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1426 - accuracy: 0.9547 - val_loss: 0.1902 - val_accuracy: 0.9338\n",
      "Epoch 132/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1420 - accuracy: 0.9550 - val_loss: 0.1898 - val_accuracy: 0.9340\n",
      "Epoch 133/800\n",
      "1665/1665 [==============================] - ETA: 0s - loss: 0.1416 - accuracy: 0.95 - 0s 87us/step - loss: 0.1416 - accuracy: 0.9550 - val_loss: 0.1898 - val_accuracy: 0.9338\n",
      "Epoch 134/800\n",
      "1665/1665 [==============================] - 0s 89us/step - loss: 0.1411 - accuracy: 0.9550 - val_loss: 0.1888 - val_accuracy: 0.9336\n",
      "Epoch 135/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1406 - accuracy: 0.9550 - val_loss: 0.1892 - val_accuracy: 0.9341\n",
      "Epoch 136/800\n",
      "1665/1665 [==============================] - 0s 92us/step - loss: 0.1402 - accuracy: 0.9551 - val_loss: 0.1867 - val_accuracy: 0.9346\n",
      "Epoch 137/800\n",
      "1665/1665 [==============================] - 0s 86us/step - loss: 0.1397 - accuracy: 0.9552 - val_loss: 0.1864 - val_accuracy: 0.9342\n",
      "Epoch 138/800\n",
      "1665/1665 [==============================] - 0s 86us/step - loss: 0.1392 - accuracy: 0.9552 - val_loss: 0.1861 - val_accuracy: 0.9344\n",
      "Epoch 139/800\n",
      "1665/1665 [==============================] - 0s 85us/step - loss: 0.1387 - accuracy: 0.9553 - val_loss: 0.1859 - val_accuracy: 0.9344\n",
      "Epoch 140/800\n",
      "1665/1665 [==============================] - 0s 85us/step - loss: 0.1382 - accuracy: 0.9554 - val_loss: 0.1856 - val_accuracy: 0.9344\n",
      "Epoch 141/800\n",
      "1665/1665 [==============================] - 0s 84us/step - loss: 0.1378 - accuracy: 0.9553 - val_loss: 0.1847 - val_accuracy: 0.9346\n",
      "Epoch 142/800\n",
      "1665/1665 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.95 - 0s 90us/step - loss: 0.1373 - accuracy: 0.9553 - val_loss: 0.1837 - val_accuracy: 0.9345\n",
      "Epoch 143/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1368 - accuracy: 0.9556 - val_loss: 0.1841 - val_accuracy: 0.9343\n",
      "Epoch 144/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1363 - accuracy: 0.9557 - val_loss: 0.1833 - val_accuracy: 0.9342\n",
      "Epoch 145/800\n",
      "1665/1665 [==============================] - 0s 89us/step - loss: 0.1359 - accuracy: 0.9556 - val_loss: 0.1822 - val_accuracy: 0.9353\n",
      "Epoch 146/800\n",
      "1665/1665 [==============================] - 0s 85us/step - loss: 0.1355 - accuracy: 0.9559 - val_loss: 0.1829 - val_accuracy: 0.9345\n",
      "Epoch 147/800\n",
      "1665/1665 [==============================] - 0s 87us/step - loss: 0.1349 - accuracy: 0.9557 - val_loss: 0.1813 - val_accuracy: 0.9354\n",
      "Epoch 148/800\n",
      "1344/1665 [=======================>......] - ETA: 0s - loss: 0.1352 - accuracy: 0.9555"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "inputs = x_d5.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = np.array(y_d5)\n",
    "#targets = np.stack(targets)\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "\n",
    "n_classes = 51\n",
    "\n",
    "acc_per_fold = []\n",
    "f1_per_fold = []\n",
    "time_per_fold = []\n",
    "\n",
    "acc_per_fold_plut = []\n",
    "f1_per_fold_plut = []\n",
    "time_per_fold_plut = []\n",
    "\n",
    "acc_per_fold_mwpm = []\n",
    "f1_per_fold_mwpm = []\n",
    "time_per_fold_mwpm = []\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "aucs_classes = {}\n",
    "for i in mlb.classes_:\n",
    "    aucs_classes[i] = []\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for i, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "    i_train = inputs[train].copy()\n",
    "    i_test = inputs[test].copy()\n",
    "    x_test_d5 = i_test[:,:2]\n",
    "    inputs_train = i_train[:,3:]\n",
    "    inputs_test = i_test[:,3:]\n",
    "    \n",
    "    ####################################################################################################\n",
    "    #test MWPM decoder for this fold\n",
    "    #labels = targets[train], features = inputs[train]\n",
    "    #x_test_d5 = translate_to_graph(testData_d5_MWPM, targets[test], mlb)\n",
    "    decoding_d5, time_mwpm = do_new_decoding(x_test_d5, 5, 0)\n",
    "    decoding_d5['combine'] = decoding_d5[[0, 1]].values.tolist()\n",
    "    decoding_d5['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "    decoding_d5 = np.array(decoding_d5[0])\n",
    "                                              \n",
    "    time_per_fold_mwpm.append(time_mwpm)\n",
    "                                              \n",
    "    pred_mwpm = mlb.transform(decoding_d5)\n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_mwpm)\n",
    "    else:\n",
    "        acc, contingency_mwpm = partial_accuracy_and_contingency(targets[test], pred_mwpm, mlb)\n",
    "        \n",
    "    acc_per_fold_mwpm.append(acc)\n",
    "    f1_per_fold_mwpm.append(f1_score(targets[test], pred_mwpm, average='micro'))\n",
    "    \n",
    "    #####################################################################################################\n",
    "    #test the plut decoder for this fold\n",
    "    \n",
    "    lookup_d5 = lookup_decoder(5)\n",
    "    \n",
    "    lookup_d5 = train_plut(lookup_d5, inputs_train, targets[train])\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    pred_plut_d5 = test_plut(lookup_d5, inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    if fold_no < 5:\n",
    "        acc = partial_accuracy(targets[test], pred_plut_d5)\n",
    "    else:\n",
    "        acc, contingency_plut = partial_accuracy_and_contingency(targets[test], pred_plut_d5, mlb)\n",
    "        \n",
    "    acc_per_fold_plut.append(acc)\n",
    "    f1_per_fold_plut.append(f1_score(targets[test], pred_plut_d5, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #Test the NN decoder for this fold\n",
    "    \n",
    "    model_d5 = compile_FFNN_model_DepthFive(5)\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    \n",
    "    history = model_d5.fit(\n",
    "    inputs_train,\n",
    "    targets[train],\n",
    "    validation_split=.25,\n",
    "    epochs = 800\n",
    ")\n",
    "   # Generate generalization metrics\n",
    "    scores = model_d5.evaluate(inputs_test, targets[test], verbose=0)\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    predictions_d5 = model_d5.predict(inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    #threshold based on previous tests with train_test_split in hyperparameter tuning\n",
    "    pred=predictions_d5.copy() #change here\n",
    "    pred[pred>=.4]=1 \n",
    "    pred[pred<.4]=0\n",
    "    \n",
    "    if fold_no < 5:\n",
    "        acc = scores[1]\n",
    "    else:\n",
    "        acc, contingency_nn = partial_accuracy_and_contingency(targets[test], pred, mlb)\n",
    "\n",
    "    acc_per_fold.append(acc)\n",
    "    f1_per_fold.append(f1_score(targets[test], pred, average='micro'))\n",
    "\n",
    "    \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d5.ravel())\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    \n",
    "    #get the AUCs of each class, used to get average AUC of each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d5[:, i]) \n",
    "        aucs_classes[mlb.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "        \n",
    "        \n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print(\"##############################################################################\")\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print(\"##############################################################################\")\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "print(\"##############################################################################\")\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "    \n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 5 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Train on 254089 samples, validate on 84697 samples\n",
      "Epoch 1/150\n",
      "254089/254089 [==============================] - 42s 164us/step - loss: 0.1630 - accuracy: 0.9604 - val_loss: 0.1871 - val_accuracy: 0.9523\n",
      "Epoch 2/150\n",
      "254089/254089 [==============================] - 40s 159us/step - loss: 0.1417 - accuracy: 0.9624 - val_loss: 0.1512 - val_accuracy: 0.9529\n",
      "Epoch 3/150\n",
      "254089/254089 [==============================] - 48s 189us/step - loss: 0.1117 - accuracy: 0.9643 - val_loss: 0.1195 - val_accuracy: 0.9587\n",
      "Epoch 4/150\n",
      "254089/254089 [==============================] - 56s 222us/step - loss: 0.0910 - accuracy: 0.9689 - val_loss: 0.1023 - val_accuracy: 0.9644\n",
      "Epoch 5/150\n",
      "254089/254089 [==============================] - 50s 195us/step - loss: 0.0787 - accuracy: 0.9727 - val_loss: 0.0936 - val_accuracy: 0.9677\n",
      "Epoch 6/150\n",
      "254089/254089 [==============================] - 46s 180us/step - loss: 0.0717 - accuracy: 0.9750 - val_loss: 0.0878 - val_accuracy: 0.9698\n",
      "Epoch 7/150\n",
      "254089/254089 [==============================] - 48s 190us/step - loss: 0.0668 - accuracy: 0.9766 - val_loss: 0.0832 - val_accuracy: 0.9716\n",
      "Epoch 8/150\n",
      "254089/254089 [==============================] - 47s 186us/step - loss: 0.0627 - accuracy: 0.9780 - val_loss: 0.0793 - val_accuracy: 0.9730\n",
      "Epoch 9/150\n",
      "254089/254089 [==============================] - 47s 184us/step - loss: 0.0596 - accuracy: 0.9790 - val_loss: 0.0761 - val_accuracy: 0.9741\n",
      "Epoch 10/150\n",
      "254089/254089 [==============================] - 47s 183us/step - loss: 0.0570 - accuracy: 0.9799 - val_loss: 0.0738 - val_accuracy: 0.9750\n",
      "Epoch 11/150\n",
      "254089/254089 [==============================] - 41s 160us/step - loss: 0.0548 - accuracy: 0.9807 - val_loss: 0.0710 - val_accuracy: 0.9758\n",
      "Epoch 12/150\n",
      "254089/254089 [==============================] - 43s 168us/step - loss: 0.0530 - accuracy: 0.9813 - val_loss: 0.0691 - val_accuracy: 0.9767\n",
      "Epoch 13/150\n",
      "254089/254089 [==============================] - 40s 158us/step - loss: 0.0515 - accuracy: 0.9818 - val_loss: 0.0666 - val_accuracy: 0.9773\n",
      "Epoch 14/150\n",
      "254089/254089 [==============================] - 53s 207us/step - loss: 0.0503 - accuracy: 0.9822 - val_loss: 0.0653 - val_accuracy: 0.9779\n",
      "Epoch 15/150\n",
      "254089/254089 [==============================] - 43s 169us/step - loss: 0.0492 - accuracy: 0.9825 - val_loss: 0.0643 - val_accuracy: 0.9781\n",
      "Epoch 16/150\n",
      "254089/254089 [==============================] - 44s 173us/step - loss: 0.0483 - accuracy: 0.9829 - val_loss: 0.0633 - val_accuracy: 0.9786\n",
      "Epoch 17/150\n",
      "254089/254089 [==============================] - 44s 172us/step - loss: 0.0475 - accuracy: 0.9831 - val_loss: 0.0620 - val_accuracy: 0.9790\n",
      "Epoch 18/150\n",
      "254089/254089 [==============================] - 55s 217us/step - loss: 0.0468 - accuracy: 0.9833 - val_loss: 0.0615 - val_accuracy: 0.9792\n",
      "Epoch 19/150\n",
      "254089/254089 [==============================] - 50s 198us/step - loss: 0.0461 - accuracy: 0.9835 - val_loss: 0.0605 - val_accuracy: 0.9795\n",
      "Epoch 20/150\n",
      "254089/254089 [==============================] - 45s 179us/step - loss: 0.0455 - accuracy: 0.9837 - val_loss: 0.0597 - val_accuracy: 0.9798\n",
      "Epoch 21/150\n",
      "254089/254089 [==============================] - 46s 182us/step - loss: 0.0450 - accuracy: 0.9838 - val_loss: 0.0586 - val_accuracy: 0.9801\n",
      "Epoch 22/150\n",
      "254089/254089 [==============================] - 47s 187us/step - loss: 0.0445 - accuracy: 0.9840 - val_loss: 0.0586 - val_accuracy: 0.9801\n",
      "Epoch 23/150\n",
      "254089/254089 [==============================] - 47s 184us/step - loss: 0.0440 - accuracy: 0.9841 - val_loss: 0.0575 - val_accuracy: 0.9804\n",
      "Epoch 24/150\n",
      "254089/254089 [==============================] - 44s 175us/step - loss: 0.0436 - accuracy: 0.9842 - val_loss: 0.0568 - val_accuracy: 0.9807\n",
      "Epoch 25/150\n",
      "254089/254089 [==============================] - 45s 179us/step - loss: 0.0431 - accuracy: 0.9843 - val_loss: 0.0569 - val_accuracy: 0.9807\n",
      "Epoch 26/150\n",
      "254089/254089 [==============================] - 45s 177us/step - loss: 0.0428 - accuracy: 0.9844 - val_loss: 0.0561 - val_accuracy: 0.9809\n",
      "Epoch 27/150\n",
      "254089/254089 [==============================] - 45s 177us/step - loss: 0.0424 - accuracy: 0.9845 - val_loss: 0.0554 - val_accuracy: 0.9811\n",
      "Epoch 28/150\n",
      "254089/254089 [==============================] - 45s 176us/step - loss: 0.0420 - accuracy: 0.9846 - val_loss: 0.0561 - val_accuracy: 0.9809\n",
      "Epoch 29/150\n",
      "254089/254089 [==============================] - 45s 177us/step - loss: 0.0417 - accuracy: 0.9847 - val_loss: 0.0548 - val_accuracy: 0.9814\n",
      "Epoch 30/150\n",
      "254089/254089 [==============================] - 45s 178us/step - loss: 0.0414 - accuracy: 0.9847 - val_loss: 0.0548 - val_accuracy: 0.9814\n",
      "Epoch 31/150\n",
      "254089/254089 [==============================] - 45s 177us/step - loss: 0.0411 - accuracy: 0.9848 - val_loss: 0.0539 - val_accuracy: 0.9816\n",
      "Epoch 32/150\n",
      "254089/254089 [==============================] - 45s 178us/step - loss: 0.0408 - accuracy: 0.9849 - val_loss: 0.0540 - val_accuracy: 0.9817\n",
      "Epoch 33/150\n",
      "254089/254089 [==============================] - 45s 177us/step - loss: 0.0405 - accuracy: 0.9850 - val_loss: 0.0533 - val_accuracy: 0.9817\n",
      "Epoch 34/150\n",
      "254089/254089 [==============================] - 46s 183us/step - loss: 0.0402 - accuracy: 0.9850 - val_loss: 0.0532 - val_accuracy: 0.9818\n",
      "Epoch 35/150\n",
      "254089/254089 [==============================] - 44s 174us/step - loss: 0.0400 - accuracy: 0.9851 - val_loss: 0.0527 - val_accuracy: 0.9820\n",
      "Epoch 36/150\n",
      "254089/254089 [==============================] - 47s 184us/step - loss: 0.0397 - accuracy: 0.9851 - val_loss: 0.0525 - val_accuracy: 0.9821\n",
      "Epoch 37/150\n",
      "254089/254089 [==============================] - 44s 173us/step - loss: 0.0395 - accuracy: 0.9852 - val_loss: 0.0524 - val_accuracy: 0.9821\n",
      "Epoch 38/150\n",
      "254089/254089 [==============================] - 44s 173us/step - loss: 0.0393 - accuracy: 0.9853 - val_loss: 0.0518 - val_accuracy: 0.9823\n",
      "Epoch 39/150\n",
      "254089/254089 [==============================] - 44s 174us/step - loss: 0.0390 - accuracy: 0.9853 - val_loss: 0.0517 - val_accuracy: 0.9823\n",
      "Epoch 40/150\n",
      "254089/254089 [==============================] - 44s 173us/step - loss: 0.0388 - accuracy: 0.9854 - val_loss: 0.0511 - val_accuracy: 0.9825\n",
      "Epoch 41/150\n",
      "254089/254089 [==============================] - 44s 174us/step - loss: 0.0386 - accuracy: 0.9854 - val_loss: 0.0506 - val_accuracy: 0.9826\n",
      "Epoch 42/150\n",
      "254089/254089 [==============================] - 50s 197us/step - loss: 0.0384 - accuracy: 0.9855 - val_loss: 0.0505 - val_accuracy: 0.9826\n",
      "Epoch 43/150\n",
      "254089/254089 [==============================] - 44s 174us/step - loss: 0.0382 - accuracy: 0.9855 - val_loss: 0.0503 - val_accuracy: 0.9826\n",
      "Epoch 44/150\n",
      "254089/254089 [==============================] - 44s 173us/step - loss: 0.0380 - accuracy: 0.9856 - val_loss: 0.0501 - val_accuracy: 0.9829\n",
      "Epoch 45/150\n",
      "254089/254089 [==============================] - 45s 176us/step - loss: 0.0378 - accuracy: 0.9856 - val_loss: 0.0502 - val_accuracy: 0.9828\n",
      "Epoch 46/150\n",
      "254089/254089 [==============================] - 45s 177us/step - loss: 0.0377 - accuracy: 0.9856 - val_loss: 0.0502 - val_accuracy: 0.9828\n",
      "Epoch 47/150\n",
      "254089/254089 [==============================] - 45s 177us/step - loss: 0.0375 - accuracy: 0.9857 - val_loss: 0.0498 - val_accuracy: 0.9829\n",
      "Epoch 48/150\n",
      "254089/254089 [==============================] - 45s 176us/step - loss: 0.0373 - accuracy: 0.9857 - val_loss: 0.0498 - val_accuracy: 0.9829\n",
      "Epoch 49/150\n",
      "254089/254089 [==============================] - 45s 178us/step - loss: 0.0371 - accuracy: 0.9858 - val_loss: 0.0491 - val_accuracy: 0.9831\n",
      "Epoch 50/150\n",
      "254089/254089 [==============================] - 45s 176us/step - loss: 0.0370 - accuracy: 0.9858 - val_loss: 0.0493 - val_accuracy: 0.9831\n",
      "Epoch 51/150\n",
      "254089/254089 [==============================] - 44s 173us/step - loss: 0.0368 - accuracy: 0.9859 - val_loss: 0.0485 - val_accuracy: 0.9833\n",
      "Epoch 52/150\n",
      "254089/254089 [==============================] - 44s 175us/step - loss: 0.0367 - accuracy: 0.9859 - val_loss: 0.0489 - val_accuracy: 0.9832\n",
      "Epoch 53/150\n",
      "254089/254089 [==============================] - 44s 175us/step - loss: 0.0365 - accuracy: 0.9859 - val_loss: 0.0486 - val_accuracy: 0.9833\n",
      "Epoch 54/150\n",
      "254089/254089 [==============================] - 44s 172us/step - loss: 0.0364 - accuracy: 0.9860 - val_loss: 0.0489 - val_accuracy: 0.9832\n",
      "Epoch 55/150\n",
      "254089/254089 [==============================] - 44s 173us/step - loss: 0.0362 - accuracy: 0.9860 - val_loss: 0.0486 - val_accuracy: 0.9833\n",
      "Epoch 56/150\n",
      "254089/254089 [==============================] - 46s 182us/step - loss: 0.0361 - accuracy: 0.9860 - val_loss: 0.0483 - val_accuracy: 0.9835\n",
      "Epoch 57/150\n",
      "254089/254089 [==============================] - 47s 184us/step - loss: 0.0359 - accuracy: 0.9861 - val_loss: 0.0482 - val_accuracy: 0.9835\n",
      "Epoch 58/150\n",
      "254089/254089 [==============================] - 49s 192us/step - loss: 0.0358 - accuracy: 0.9861 - val_loss: 0.0480 - val_accuracy: 0.9835\n",
      "Epoch 59/150\n",
      "254089/254089 [==============================] - 42s 163us/step - loss: 0.0357 - accuracy: 0.9862 - val_loss: 0.0479 - val_accuracy: 0.9835\n",
      "Epoch 60/150\n",
      "254089/254089 [==============================] - 44s 172us/step - loss: 0.0356 - accuracy: 0.9862 - val_loss: 0.0485 - val_accuracy: 0.9834\n",
      "Epoch 61/150\n",
      "254089/254089 [==============================] - 42s 165us/step - loss: 0.0354 - accuracy: 0.9862 - val_loss: 0.0477 - val_accuracy: 0.9836\n",
      "Epoch 62/150\n",
      "254089/254089 [==============================] - 40s 158us/step - loss: 0.0353 - accuracy: 0.9863 - val_loss: 0.0479 - val_accuracy: 0.9836\n",
      "Epoch 63/150\n",
      "254089/254089 [==============================] - 43s 167us/step - loss: 0.0352 - accuracy: 0.9863 - val_loss: 0.0472 - val_accuracy: 0.9837\n",
      "Epoch 64/150\n",
      "254089/254089 [==============================] - 40s 159us/step - loss: 0.0351 - accuracy: 0.9863 - val_loss: 0.0473 - val_accuracy: 0.9837\n",
      "Epoch 65/150\n",
      "254089/254089 [==============================] - 42s 167us/step - loss: 0.0350 - accuracy: 0.9864 - val_loss: 0.0472 - val_accuracy: 0.9838\n",
      "Epoch 66/150\n",
      "254089/254089 [==============================] - 45s 176us/step - loss: 0.0348 - accuracy: 0.9864 - val_loss: 0.0469 - val_accuracy: 0.9839\n",
      "Epoch 67/150\n",
      "254089/254089 [==============================] - 44s 173us/step - loss: 0.0347 - accuracy: 0.9864 - val_loss: 0.0467 - val_accuracy: 0.9839\n",
      "Epoch 68/150\n",
      "254089/254089 [==============================] - 43s 170us/step - loss: 0.0346 - accuracy: 0.9864 - val_loss: 0.0465 - val_accuracy: 0.9840\n",
      "Epoch 69/150\n",
      "254089/254089 [==============================] - 43s 171us/step - loss: 0.0345 - accuracy: 0.9865 - val_loss: 0.0467 - val_accuracy: 0.9840\n",
      "Epoch 70/150\n",
      "254089/254089 [==============================] - 44s 172us/step - loss: 0.0344 - accuracy: 0.9865 - val_loss: 0.0470 - val_accuracy: 0.9839\n",
      "Epoch 71/150\n",
      "254089/254089 [==============================] - 43s 170us/step - loss: 0.0343 - accuracy: 0.9865 - val_loss: 0.0464 - val_accuracy: 0.9841\n",
      "Epoch 72/150\n",
      "254089/254089 [==============================] - 44s 173us/step - loss: 0.0342 - accuracy: 0.9866 - val_loss: 0.0464 - val_accuracy: 0.9841\n",
      "Epoch 73/150\n",
      "254089/254089 [==============================] - 45s 175us/step - loss: 0.0341 - accuracy: 0.9866 - val_loss: 0.0462 - val_accuracy: 0.9842\n",
      "Epoch 74/150\n",
      "254089/254089 [==============================] - 44s 172us/step - loss: 0.0340 - accuracy: 0.9866 - val_loss: 0.0463 - val_accuracy: 0.9841\n",
      "Epoch 75/150\n",
      "254089/254089 [==============================] - 45s 176us/step - loss: 0.0339 - accuracy: 0.9866 - val_loss: 0.0458 - val_accuracy: 0.9843\n",
      "Epoch 76/150\n",
      "254089/254089 [==============================] - 44s 172us/step - loss: 0.0339 - accuracy: 0.9867 - val_loss: 0.0461 - val_accuracy: 0.9842\n",
      "Epoch 77/150\n",
      "254089/254089 [==============================] - 46s 181us/step - loss: 0.0338 - accuracy: 0.9867 - val_loss: 0.0455 - val_accuracy: 0.9843\n",
      "Epoch 78/150\n",
      "254089/254089 [==============================] - 43s 171us/step - loss: 0.0337 - accuracy: 0.9867 - val_loss: 0.0456 - val_accuracy: 0.9843\n",
      "Epoch 79/150\n",
      "254089/254089 [==============================] - 43s 170us/step - loss: 0.0336 - accuracy: 0.9867 - val_loss: 0.0457 - val_accuracy: 0.9842\n",
      "Epoch 80/150\n",
      "254089/254089 [==============================] - 43s 170us/step - loss: 0.0335 - accuracy: 0.9868 - val_loss: 0.0453 - val_accuracy: 0.9844\n",
      "Epoch 81/150\n",
      "254089/254089 [==============================] - 44s 172us/step - loss: 0.0334 - accuracy: 0.9868 - val_loss: 0.0458 - val_accuracy: 0.9842\n",
      "Epoch 82/150\n",
      "254089/254089 [==============================] - 43s 171us/step - loss: 0.0333 - accuracy: 0.9868 - val_loss: 0.0456 - val_accuracy: 0.9843\n",
      "Epoch 83/150\n",
      "254089/254089 [==============================] - 43s 170us/step - loss: 0.0333 - accuracy: 0.9868 - val_loss: 0.0455 - val_accuracy: 0.9844\n",
      "Epoch 84/150\n",
      "254089/254089 [==============================] - 44s 173us/step - loss: 0.0332 - accuracy: 0.9869 - val_loss: 0.0458 - val_accuracy: 0.9844\n",
      "Epoch 85/150\n",
      "254089/254089 [==============================] - 44s 171us/step - loss: 0.0331 - accuracy: 0.9869 - val_loss: 0.0451 - val_accuracy: 0.9845\n",
      "Epoch 86/150\n",
      "254089/254089 [==============================] - 44s 174us/step - loss: 0.0330 - accuracy: 0.9869 - val_loss: 0.0456 - val_accuracy: 0.9844\n",
      "Epoch 87/150\n",
      "254089/254089 [==============================] - 43s 170us/step - loss: 0.0330 - accuracy: 0.9869 - val_loss: 0.0453 - val_accuracy: 0.9844\n",
      "Epoch 88/150\n",
      "254089/254089 [==============================] - 44s 174us/step - loss: 0.0329 - accuracy: 0.9870 - val_loss: 0.0448 - val_accuracy: 0.9846\n",
      "Epoch 89/150\n",
      "254089/254089 [==============================] - 44s 175us/step - loss: 0.0328 - accuracy: 0.9870 - val_loss: 0.0451 - val_accuracy: 0.9845\n",
      "Epoch 90/150\n",
      "254089/254089 [==============================] - 45s 177us/step - loss: 0.0327 - accuracy: 0.9870 - val_loss: 0.0453 - val_accuracy: 0.9845\n",
      "Epoch 91/150\n",
      "254089/254089 [==============================] - 45s 175us/step - loss: 0.0327 - accuracy: 0.9870 - val_loss: 0.0448 - val_accuracy: 0.9846\n",
      "Epoch 92/150\n",
      "254089/254089 [==============================] - 43s 171us/step - loss: 0.0326 - accuracy: 0.9870 - val_loss: 0.0449 - val_accuracy: 0.9845\n",
      "Epoch 93/150\n",
      "254089/254089 [==============================] - 46s 183us/step - loss: 0.0325 - accuracy: 0.9871 - val_loss: 0.0447 - val_accuracy: 0.9847\n",
      "Epoch 94/150\n",
      "254089/254089 [==============================] - 45s 177us/step - loss: 0.0325 - accuracy: 0.9871 - val_loss: 0.0445 - val_accuracy: 0.9846\n",
      "Epoch 95/150\n",
      "254089/254089 [==============================] - 46s 180us/step - loss: 0.0324 - accuracy: 0.9871 - val_loss: 0.0447 - val_accuracy: 0.9847\n",
      "Epoch 96/150\n",
      "254089/254089 [==============================] - 44s 174us/step - loss: 0.0323 - accuracy: 0.9872 - val_loss: 0.0448 - val_accuracy: 0.9846\n",
      "Epoch 97/150\n",
      "254089/254089 [==============================] - 46s 182us/step - loss: 0.0323 - accuracy: 0.9872 - val_loss: 0.0443 - val_accuracy: 0.9848\n",
      "Epoch 98/150\n",
      "254089/254089 [==============================] - 44s 172us/step - loss: 0.0322 - accuracy: 0.9872 - val_loss: 0.0444 - val_accuracy: 0.9848\n",
      "Epoch 99/150\n",
      "254089/254089 [==============================] - 47s 187us/step - loss: 0.0321 - accuracy: 0.9872 - val_loss: 0.0443 - val_accuracy: 0.9848\n",
      "Epoch 100/150\n",
      "254089/254089 [==============================] - 46s 181us/step - loss: 0.0321 - accuracy: 0.9872 - val_loss: 0.0447 - val_accuracy: 0.9847\n",
      "Epoch 101/150\n",
      "254089/254089 [==============================] - 43s 171us/step - loss: 0.0320 - accuracy: 0.9872 - val_loss: 0.0444 - val_accuracy: 0.9848\n",
      "Epoch 102/150\n",
      "254089/254089 [==============================] - 44s 172us/step - loss: 0.0319 - accuracy: 0.9873 - val_loss: 0.0439 - val_accuracy: 0.9849\n",
      "Epoch 103/150\n",
      "254089/254089 [==============================] - 46s 179us/step - loss: 0.0319 - accuracy: 0.9873 - val_loss: 0.0445 - val_accuracy: 0.9847\n",
      "Epoch 104/150\n",
      "254089/254089 [==============================] - 46s 181us/step - loss: 0.0318 - accuracy: 0.9873 - val_loss: 0.0446 - val_accuracy: 0.9847\n",
      "Epoch 105/150\n",
      "254089/254089 [==============================] - 43s 168us/step - loss: 0.0318 - accuracy: 0.9873 - val_loss: 0.0444 - val_accuracy: 0.9848\n",
      "Epoch 106/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254089/254089 [==============================] - 41s 160us/step - loss: 0.0317 - accuracy: 0.9873 - val_loss: 0.0437 - val_accuracy: 0.9849\n",
      "Epoch 107/150\n",
      "254089/254089 [==============================] - 44s 174us/step - loss: 0.0316 - accuracy: 0.9873 - val_loss: 0.0443 - val_accuracy: 0.9848\n",
      "Epoch 108/150\n",
      "254089/254089 [==============================] - 46s 183us/step - loss: 0.0316 - accuracy: 0.9874 - val_loss: 0.0440 - val_accuracy: 0.9849\n",
      "Epoch 109/150\n",
      "254089/254089 [==============================] - 39s 155us/step - loss: 0.0315 - accuracy: 0.9874 - val_loss: 0.0440 - val_accuracy: 0.9849\n",
      "Epoch 110/150\n",
      "254089/254089 [==============================] - 39s 155us/step - loss: 0.0315 - accuracy: 0.9874 - val_loss: 0.0436 - val_accuracy: 0.9850\n",
      "Epoch 111/150\n",
      "254089/254089 [==============================] - 39s 155us/step - loss: 0.0314 - accuracy: 0.9874 - val_loss: 0.0434 - val_accuracy: 0.9850\n",
      "Epoch 112/150\n",
      "254089/254089 [==============================] - 40s 157us/step - loss: 0.0314 - accuracy: 0.9874 - val_loss: 0.0435 - val_accuracy: 0.9850\n",
      "Epoch 113/150\n",
      "254089/254089 [==============================] - 39s 155us/step - loss: 0.0313 - accuracy: 0.9874 - val_loss: 0.0441 - val_accuracy: 0.9849\n",
      "Epoch 114/150\n",
      "254089/254089 [==============================] - 40s 159us/step - loss: 0.0313 - accuracy: 0.9875 - val_loss: 0.0441 - val_accuracy: 0.9849\n",
      "Epoch 115/150\n",
      "254089/254089 [==============================] - 40s 156us/step - loss: 0.0312 - accuracy: 0.9875 - val_loss: 0.0438 - val_accuracy: 0.9849\n",
      "Epoch 116/150\n",
      "254089/254089 [==============================] - 58s 227us/step - loss: 0.0312 - accuracy: 0.9875 - val_loss: 0.0436 - val_accuracy: 0.9850\n",
      "Epoch 117/150\n",
      "254089/254089 [==============================] - 99s 388us/step - loss: 0.0311 - accuracy: 0.9875 - val_loss: 0.0431 - val_accuracy: 0.9851\n",
      "Epoch 118/150\n",
      "254089/254089 [==============================] - 95s 374us/step - loss: 0.0311 - accuracy: 0.9875 - val_loss: 0.0440 - val_accuracy: 0.9848\n",
      "Epoch 119/150\n",
      "254089/254089 [==============================] - 99s 391us/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.0438 - val_accuracy: 0.9850\n",
      "Epoch 120/150\n",
      "254089/254089 [==============================] - 95s 376us/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.0433 - val_accuracy: 0.9851\n",
      "Epoch 121/150\n",
      "254089/254089 [==============================] - 96s 380us/step - loss: 0.0309 - accuracy: 0.9876 - val_loss: 0.0436 - val_accuracy: 0.9851\n",
      "Epoch 122/150\n",
      "254089/254089 [==============================] - 106s 416us/step - loss: 0.0309 - accuracy: 0.9876 - val_loss: 0.0435 - val_accuracy: 0.9851\n",
      "Epoch 123/150\n",
      "254089/254089 [==============================] - 102s 401us/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.0431 - val_accuracy: 0.9851\n",
      "Epoch 124/150\n",
      "254089/254089 [==============================] - 96s 377us/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.0433 - val_accuracy: 0.9852\n",
      "Epoch 125/150\n",
      "254089/254089 [==============================] - 94s 372us/step - loss: 0.0307 - accuracy: 0.9876 - val_loss: 0.0440 - val_accuracy: 0.9850\n",
      "Epoch 126/150\n",
      "254089/254089 [==============================] - 94s 371us/step - loss: 0.0307 - accuracy: 0.9876 - val_loss: 0.0432 - val_accuracy: 0.9852\n",
      "Epoch 127/150\n",
      "254089/254089 [==============================] - 98s 384us/step - loss: 0.0306 - accuracy: 0.9877 - val_loss: 0.0430 - val_accuracy: 0.9852\n",
      "Epoch 128/150\n",
      "254089/254089 [==============================] - 74s 290us/step - loss: 0.0306 - accuracy: 0.9877 - val_loss: 0.0427 - val_accuracy: 0.9852\n",
      "Epoch 129/150\n",
      "254089/254089 [==============================] - 40s 159us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0431 - val_accuracy: 0.9852\n",
      "Epoch 130/150\n",
      "254089/254089 [==============================] - 40s 156us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0432 - val_accuracy: 0.9851\n",
      "Epoch 131/150\n",
      "254089/254089 [==============================] - 41s 161us/step - loss: 0.0304 - accuracy: 0.9877 - val_loss: 0.0435 - val_accuracy: 0.9852\n",
      "Epoch 132/150\n",
      "254089/254089 [==============================] - 41s 160us/step - loss: 0.0304 - accuracy: 0.9877 - val_loss: 0.0420 - val_accuracy: 0.9855\n",
      "Epoch 133/150\n",
      "254089/254089 [==============================] - 39s 154us/step - loss: 0.0304 - accuracy: 0.9877 - val_loss: 0.0423 - val_accuracy: 0.9854\n",
      "Epoch 134/150\n",
      "254089/254089 [==============================] - 40s 156us/step - loss: 0.0303 - accuracy: 0.9878 - val_loss: 0.0434 - val_accuracy: 0.9852\n",
      "Epoch 135/150\n",
      "254089/254089 [==============================] - 40s 156us/step - loss: 0.0303 - accuracy: 0.9878 - val_loss: 0.0424 - val_accuracy: 0.9854\n",
      "Epoch 136/150\n",
      "254089/254089 [==============================] - 39s 155us/step - loss: 0.0302 - accuracy: 0.9878 - val_loss: 0.0426 - val_accuracy: 0.9853\n",
      "Epoch 137/150\n",
      "254089/254089 [==============================] - 39s 155us/step - loss: 0.0302 - accuracy: 0.9878 - val_loss: 0.0426 - val_accuracy: 0.9854\n",
      "Epoch 138/150\n",
      "254089/254089 [==============================] - 39s 155us/step - loss: 0.0302 - accuracy: 0.9878 - val_loss: 0.0431 - val_accuracy: 0.9853\n",
      "Epoch 139/150\n",
      "254089/254089 [==============================] - 39s 155us/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.0425 - val_accuracy: 0.9854\n",
      "Epoch 140/150\n",
      "254089/254089 [==============================] - 39s 155us/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.0424 - val_accuracy: 0.9854\n",
      "Epoch 141/150\n",
      "254089/254089 [==============================] - 40s 156us/step - loss: 0.0300 - accuracy: 0.9878 - val_loss: 0.0424 - val_accuracy: 0.9853\n",
      "Epoch 142/150\n",
      "254089/254089 [==============================] - 40s 157us/step - loss: 0.0300 - accuracy: 0.9878 - val_loss: 0.0422 - val_accuracy: 0.9854\n",
      "Epoch 143/150\n",
      "254089/254089 [==============================] - 39s 155us/step - loss: 0.0300 - accuracy: 0.9879 - val_loss: 0.0420 - val_accuracy: 0.9855\n",
      "Epoch 144/150\n",
      "254089/254089 [==============================] - 40s 157us/step - loss: 0.0299 - accuracy: 0.9879 - val_loss: 0.0426 - val_accuracy: 0.9854\n",
      "Epoch 145/150\n",
      "254089/254089 [==============================] - 39s 155us/step - loss: 0.0299 - accuracy: 0.9879 - val_loss: 0.0423 - val_accuracy: 0.9854\n",
      "Epoch 146/150\n",
      "254089/254089 [==============================] - 40s 158us/step - loss: 0.0298 - accuracy: 0.9879 - val_loss: 0.0424 - val_accuracy: 0.9854\n",
      "Epoch 147/150\n",
      "254089/254089 [==============================] - 40s 159us/step - loss: 0.0298 - accuracy: 0.9879 - val_loss: 0.0424 - val_accuracy: 0.9854\n",
      "Epoch 148/150\n",
      "254089/254089 [==============================] - 39s 155us/step - loss: 0.0298 - accuracy: 0.9879 - val_loss: 0.0421 - val_accuracy: 0.9855\n",
      "Epoch 149/150\n",
      "254089/254089 [==============================] - 40s 156us/step - loss: 0.0297 - accuracy: 0.9879 - val_loss: 0.0421 - val_accuracy: 0.9856\n",
      "Epoch 150/150\n",
      "254089/254089 [==============================] - 39s 154us/step - loss: 0.0297 - accuracy: 0.9879 - val_loss: 0.0419 - val_accuracy: 0.9855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clair\\Anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:136: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\clair\\Anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Train on 254090 samples, validate on 84697 samples\n",
      "Epoch 1/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.1632 - accuracy: 0.9607 - val_loss: 0.1882 - val_accuracy: 0.9523\n",
      "Epoch 2/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.1426 - accuracy: 0.9624 - val_loss: 0.1496 - val_accuracy: 0.9528\n",
      "Epoch 3/150\n",
      "254090/254090 [==============================] - 42s 165us/step - loss: 0.1105 - accuracy: 0.9645 - val_loss: 0.1188 - val_accuracy: 0.9585\n",
      "Epoch 4/150\n",
      "254090/254090 [==============================] - 46s 179us/step - loss: 0.0921 - accuracy: 0.9683 - val_loss: 0.1044 - val_accuracy: 0.9634\n",
      "Epoch 5/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0805 - accuracy: 0.9718 - val_loss: 0.0942 - val_accuracy: 0.9668\n",
      "Epoch 6/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0729 - accuracy: 0.9744 - val_loss: 0.0881 - val_accuracy: 0.9690\n",
      "Epoch 7/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0677 - accuracy: 0.9762 - val_loss: 0.0837 - val_accuracy: 0.9706\n",
      "Epoch 8/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0638 - accuracy: 0.9775 - val_loss: 0.0799 - val_accuracy: 0.9721\n",
      "Epoch 9/150\n",
      "254090/254090 [==============================] - 42s 167us/step - loss: 0.0607 - accuracy: 0.9785 - val_loss: 0.0767 - val_accuracy: 0.9733\n",
      "Epoch 10/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0582 - accuracy: 0.9794 - val_loss: 0.0742 - val_accuracy: 0.9743\n",
      "Epoch 11/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0559 - accuracy: 0.9802 - val_loss: 0.0726 - val_accuracy: 0.9750\n",
      "Epoch 12/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0541 - accuracy: 0.9808 - val_loss: 0.0704 - val_accuracy: 0.9758\n",
      "Epoch 13/150\n",
      "254090/254090 [==============================] - 42s 166us/step - loss: 0.0525 - accuracy: 0.9814 - val_loss: 0.0683 - val_accuracy: 0.9765\n",
      "Epoch 14/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0512 - accuracy: 0.9818 - val_loss: 0.0668 - val_accuracy: 0.9771\n",
      "Epoch 15/150\n",
      "254090/254090 [==============================] - 41s 159us/step - loss: 0.0500 - accuracy: 0.9822 - val_loss: 0.0653 - val_accuracy: 0.9775\n",
      "Epoch 16/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0490 - accuracy: 0.9826 - val_loss: 0.0640 - val_accuracy: 0.9779\n",
      "Epoch 17/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0481 - accuracy: 0.9828 - val_loss: 0.0624 - val_accuracy: 0.9784\n",
      "Epoch 18/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0474 - accuracy: 0.9831 - val_loss: 0.0623 - val_accuracy: 0.9786\n",
      "Epoch 19/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0467 - accuracy: 0.9833 - val_loss: 0.0615 - val_accuracy: 0.9789\n",
      "Epoch 20/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0461 - accuracy: 0.9834 - val_loss: 0.0605 - val_accuracy: 0.9793\n",
      "Epoch 21/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0455 - accuracy: 0.9836 - val_loss: 0.0594 - val_accuracy: 0.9796\n",
      "Epoch 22/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0450 - accuracy: 0.9837 - val_loss: 0.0593 - val_accuracy: 0.9797\n",
      "Epoch 23/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0445 - accuracy: 0.9839 - val_loss: 0.0585 - val_accuracy: 0.9800\n",
      "Epoch 24/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0440 - accuracy: 0.9840 - val_loss: 0.0590 - val_accuracy: 0.9797\n",
      "Epoch 25/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0436 - accuracy: 0.9841 - val_loss: 0.0568 - val_accuracy: 0.9804\n",
      "Epoch 26/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0432 - accuracy: 0.9842 - val_loss: 0.0569 - val_accuracy: 0.9804\n",
      "Epoch 27/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0428 - accuracy: 0.9843 - val_loss: 0.0570 - val_accuracy: 0.9804\n",
      "Epoch 28/150\n",
      "254090/254090 [==============================] - 46s 182us/step - loss: 0.0424 - accuracy: 0.9844 - val_loss: 0.0556 - val_accuracy: 0.9808\n",
      "Epoch 29/150\n",
      "254090/254090 [==============================] - 43s 171us/step - loss: 0.0421 - accuracy: 0.9845 - val_loss: 0.0561 - val_accuracy: 0.9808\n",
      "Epoch 30/150\n",
      "254090/254090 [==============================] - 43s 169us/step - loss: 0.0417 - accuracy: 0.9846 - val_loss: 0.0559 - val_accuracy: 0.9809\n",
      "Epoch 31/150\n",
      "254090/254090 [==============================] - 44s 174us/step - loss: 0.0414 - accuracy: 0.9847 - val_loss: 0.0545 - val_accuracy: 0.9813\n",
      "Epoch 32/150\n",
      "254090/254090 [==============================] - 44s 172us/step - loss: 0.0411 - accuracy: 0.9847 - val_loss: 0.0548 - val_accuracy: 0.9811\n",
      "Epoch 33/150\n",
      "254090/254090 [==============================] - 47s 186us/step - loss: 0.0408 - accuracy: 0.9848 - val_loss: 0.0541 - val_accuracy: 0.9813\n",
      "Epoch 34/150\n",
      "254090/254090 [==============================] - 50s 197us/step - loss: 0.0405 - accuracy: 0.9849 - val_loss: 0.0531 - val_accuracy: 0.9816\n",
      "Epoch 35/150\n",
      "254090/254090 [==============================] - 57s 224us/step - loss: 0.0403 - accuracy: 0.9850 - val_loss: 0.0531 - val_accuracy: 0.9817\n",
      "Epoch 36/150\n",
      "254090/254090 [==============================] - 43s 168us/step - loss: 0.0400 - accuracy: 0.9850 - val_loss: 0.0537 - val_accuracy: 0.9816\n",
      "Epoch 37/150\n",
      "254090/254090 [==============================] - 47s 184us/step - loss: 0.0397 - accuracy: 0.9851 - val_loss: 0.0535 - val_accuracy: 0.9817\n",
      "Epoch 38/150\n",
      "254090/254090 [==============================] - 45s 176us/step - loss: 0.0395 - accuracy: 0.9851 - val_loss: 0.0525 - val_accuracy: 0.9819\n",
      "Epoch 39/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0393 - accuracy: 0.9852 - val_loss: 0.0525 - val_accuracy: 0.9819\n",
      "Epoch 40/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0390 - accuracy: 0.9852 - val_loss: 0.0527 - val_accuracy: 0.9820\n",
      "Epoch 41/150\n",
      "254090/254090 [==============================] - 42s 167us/step - loss: 0.0388 - accuracy: 0.9853 - val_loss: 0.0518 - val_accuracy: 0.9822\n",
      "Epoch 42/150\n",
      "254090/254090 [==============================] - 41s 163us/step - loss: 0.0386 - accuracy: 0.9854 - val_loss: 0.0525 - val_accuracy: 0.9820\n",
      "Epoch 43/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0384 - accuracy: 0.9854 - val_loss: 0.0504 - val_accuracy: 0.9825\n",
      "Epoch 44/150\n",
      "254090/254090 [==============================] - 43s 168us/step - loss: 0.0382 - accuracy: 0.9855 - val_loss: 0.0511 - val_accuracy: 0.9823\n",
      "Epoch 45/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0380 - accuracy: 0.9855 - val_loss: 0.0519 - val_accuracy: 0.9822\n",
      "Epoch 46/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0378 - accuracy: 0.9855 - val_loss: 0.0504 - val_accuracy: 0.9826\n",
      "Epoch 47/150\n",
      "254090/254090 [==============================] - 41s 163us/step - loss: 0.0376 - accuracy: 0.9856 - val_loss: 0.0503 - val_accuracy: 0.9827\n",
      "Epoch 48/150\n",
      "254090/254090 [==============================] - 42s 165us/step - loss: 0.0375 - accuracy: 0.9856 - val_loss: 0.0507 - val_accuracy: 0.9826\n",
      "Epoch 49/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0373 - accuracy: 0.9857 - val_loss: 0.0497 - val_accuracy: 0.9828\n",
      "Epoch 50/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0371 - accuracy: 0.9857 - val_loss: 0.0498 - val_accuracy: 0.9828\n",
      "Epoch 51/150\n",
      "254090/254090 [==============================] - 41s 159us/step - loss: 0.0370 - accuracy: 0.9858 - val_loss: 0.0496 - val_accuracy: 0.9828\n",
      "Epoch 52/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0368 - accuracy: 0.9858 - val_loss: 0.0488 - val_accuracy: 0.9830\n",
      "Epoch 53/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0367 - accuracy: 0.9858 - val_loss: 0.0494 - val_accuracy: 0.9829\n",
      "Epoch 54/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0366 - accuracy: 0.9859 - val_loss: 0.0500 - val_accuracy: 0.9829\n",
      "Epoch 55/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0364 - accuracy: 0.9859 - val_loss: 0.0491 - val_accuracy: 0.9830\n",
      "Epoch 56/150\n",
      "254090/254090 [==============================] - 43s 168us/step - loss: 0.0363 - accuracy: 0.9860 - val_loss: 0.0493 - val_accuracy: 0.9831\n",
      "Epoch 57/150\n",
      "254090/254090 [==============================] - 42s 165us/step - loss: 0.0362 - accuracy: 0.9860 - val_loss: 0.0486 - val_accuracy: 0.9832\n",
      "Epoch 58/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0360 - accuracy: 0.9860 - val_loss: 0.0485 - val_accuracy: 0.9832\n",
      "Epoch 59/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0359 - accuracy: 0.9861 - val_loss: 0.0486 - val_accuracy: 0.9832\n",
      "Epoch 60/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0358 - accuracy: 0.9861 - val_loss: 0.0483 - val_accuracy: 0.9833\n",
      "Epoch 61/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0357 - accuracy: 0.9861 - val_loss: 0.0480 - val_accuracy: 0.9834\n",
      "Epoch 62/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0355 - accuracy: 0.9861 - val_loss: 0.0486 - val_accuracy: 0.9833\n",
      "Epoch 63/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0354 - accuracy: 0.9862 - val_loss: 0.0483 - val_accuracy: 0.9834\n",
      "Epoch 64/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0353 - accuracy: 0.9862 - val_loss: 0.0480 - val_accuracy: 0.9835\n",
      "Epoch 65/150\n",
      "254090/254090 [==============================] - 41s 159us/step - loss: 0.0352 - accuracy: 0.9863 - val_loss: 0.0480 - val_accuracy: 0.9834\n",
      "Epoch 66/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0351 - accuracy: 0.9863 - val_loss: 0.0477 - val_accuracy: 0.9835\n",
      "Epoch 67/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0350 - accuracy: 0.9863 - val_loss: 0.0481 - val_accuracy: 0.9834\n",
      "Epoch 68/150\n",
      "254090/254090 [==============================] - 41s 159us/step - loss: 0.0349 - accuracy: 0.9863 - val_loss: 0.0473 - val_accuracy: 0.9838\n",
      "Epoch 69/150\n",
      "254090/254090 [==============================] - 43s 169us/step - loss: 0.0348 - accuracy: 0.9864 - val_loss: 0.0478 - val_accuracy: 0.9835\n",
      "Epoch 70/150\n",
      "254090/254090 [==============================] - 47s 184us/step - loss: 0.0347 - accuracy: 0.9864 - val_loss: 0.0472 - val_accuracy: 0.9838\n",
      "Epoch 71/150\n",
      "254090/254090 [==============================] - 42s 163us/step - loss: 0.0346 - accuracy: 0.9864 - val_loss: 0.0473 - val_accuracy: 0.9837\n",
      "Epoch 72/150\n",
      "254090/254090 [==============================] - 42s 167us/step - loss: 0.0345 - accuracy: 0.9864 - val_loss: 0.0469 - val_accuracy: 0.9838\n",
      "Epoch 73/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0344 - accuracy: 0.9865 - val_loss: 0.0469 - val_accuracy: 0.9838\n",
      "Epoch 74/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0343 - accuracy: 0.9865 - val_loss: 0.0470 - val_accuracy: 0.9837\n",
      "Epoch 75/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0342 - accuracy: 0.9865 - val_loss: 0.0473 - val_accuracy: 0.9837\n",
      "Epoch 76/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0342 - accuracy: 0.9866 - val_loss: 0.0466 - val_accuracy: 0.9838\n",
      "Epoch 77/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0341 - accuracy: 0.9866 - val_loss: 0.0464 - val_accuracy: 0.9840\n",
      "Epoch 78/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0340 - accuracy: 0.9866 - val_loss: 0.0472 - val_accuracy: 0.9838\n",
      "Epoch 79/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0339 - accuracy: 0.9866 - val_loss: 0.0466 - val_accuracy: 0.9839\n",
      "Epoch 80/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0338 - accuracy: 0.9867 - val_loss: 0.0464 - val_accuracy: 0.9840\n",
      "Epoch 81/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0337 - accuracy: 0.9867 - val_loss: 0.0465 - val_accuracy: 0.9840\n",
      "Epoch 82/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0337 - accuracy: 0.9867 - val_loss: 0.0466 - val_accuracy: 0.9840\n",
      "Epoch 83/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0336 - accuracy: 0.9867 - val_loss: 0.0460 - val_accuracy: 0.9842\n",
      "Epoch 84/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0335 - accuracy: 0.9868 - val_loss: 0.0468 - val_accuracy: 0.9841\n",
      "Epoch 85/150\n",
      "254090/254090 [==============================] - 42s 166us/step - loss: 0.0334 - accuracy: 0.9868 - val_loss: 0.0459 - val_accuracy: 0.9842\n",
      "Epoch 86/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0334 - accuracy: 0.9868 - val_loss: 0.0459 - val_accuracy: 0.9841\n",
      "Epoch 87/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0333 - accuracy: 0.9868 - val_loss: 0.0465 - val_accuracy: 0.9841\n",
      "Epoch 88/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0332 - accuracy: 0.9869 - val_loss: 0.0464 - val_accuracy: 0.9842\n",
      "Epoch 89/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0331 - accuracy: 0.9869 - val_loss: 0.0459 - val_accuracy: 0.9842\n",
      "Epoch 90/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0331 - accuracy: 0.9869 - val_loss: 0.0459 - val_accuracy: 0.9842\n",
      "Epoch 91/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0330 - accuracy: 0.9869 - val_loss: 0.0457 - val_accuracy: 0.9843\n",
      "Epoch 92/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0329 - accuracy: 0.9869 - val_loss: 0.0459 - val_accuracy: 0.9842\n",
      "Epoch 93/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0329 - accuracy: 0.9870 - val_loss: 0.0454 - val_accuracy: 0.9843\n",
      "Epoch 94/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0328 - accuracy: 0.9870 - val_loss: 0.0454 - val_accuracy: 0.9844\n",
      "Epoch 95/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0327 - accuracy: 0.9870 - val_loss: 0.0458 - val_accuracy: 0.9843\n",
      "Epoch 96/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0327 - accuracy: 0.9870 - val_loss: 0.0446 - val_accuracy: 0.9846\n",
      "Epoch 97/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0326 - accuracy: 0.9870 - val_loss: 0.0453 - val_accuracy: 0.9845\n",
      "Epoch 98/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0325 - accuracy: 0.9871 - val_loss: 0.0447 - val_accuracy: 0.9846\n",
      "Epoch 99/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0325 - accuracy: 0.9871 - val_loss: 0.0455 - val_accuracy: 0.9845\n",
      "Epoch 100/150\n",
      "254090/254090 [==============================] - 43s 168us/step - loss: 0.0324 - accuracy: 0.9871 - val_loss: 0.0451 - val_accuracy: 0.9845\n",
      "Epoch 101/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0323 - accuracy: 0.9871 - val_loss: 0.0453 - val_accuracy: 0.9845\n",
      "Epoch 102/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0323 - accuracy: 0.9871 - val_loss: 0.0451 - val_accuracy: 0.9845\n",
      "Epoch 103/150\n",
      "254090/254090 [==============================] - 43s 168us/step - loss: 0.0322 - accuracy: 0.9872 - val_loss: 0.0449 - val_accuracy: 0.9844\n",
      "Epoch 104/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0322 - accuracy: 0.9872 - val_loss: 0.0450 - val_accuracy: 0.9846\n",
      "Epoch 105/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0321 - accuracy: 0.9872 - val_loss: 0.0446 - val_accuracy: 0.9847\n",
      "Epoch 106/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254090/254090 [==============================] - 40s 156us/step - loss: 0.0320 - accuracy: 0.9872 - val_loss: 0.0450 - val_accuracy: 0.9846\n",
      "Epoch 107/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0320 - accuracy: 0.9872 - val_loss: 0.0447 - val_accuracy: 0.9847\n",
      "Epoch 108/150\n",
      "254090/254090 [==============================] - 40s 156us/step - loss: 0.0319 - accuracy: 0.9872 - val_loss: 0.0446 - val_accuracy: 0.9847\n",
      "Epoch 109/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0319 - accuracy: 0.9872 - val_loss: 0.0448 - val_accuracy: 0.9847\n",
      "Epoch 110/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0318 - accuracy: 0.9873 - val_loss: 0.0448 - val_accuracy: 0.9846\n",
      "Epoch 111/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0318 - accuracy: 0.9873 - val_loss: 0.0446 - val_accuracy: 0.9846\n",
      "Epoch 112/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0317 - accuracy: 0.9873 - val_loss: 0.0443 - val_accuracy: 0.9848\n",
      "Epoch 113/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0317 - accuracy: 0.9873 - val_loss: 0.0448 - val_accuracy: 0.9846\n",
      "Epoch 114/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0316 - accuracy: 0.9873 - val_loss: 0.0445 - val_accuracy: 0.9846\n",
      "Epoch 115/150\n",
      "254090/254090 [==============================] - 42s 165us/step - loss: 0.0316 - accuracy: 0.9874 - val_loss: 0.0445 - val_accuracy: 0.9848\n",
      "Epoch 116/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0315 - accuracy: 0.9874 - val_loss: 0.0444 - val_accuracy: 0.9848\n",
      "Epoch 117/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0315 - accuracy: 0.9874 - val_loss: 0.0439 - val_accuracy: 0.9848\n",
      "Epoch 118/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0314 - accuracy: 0.9874 - val_loss: 0.0439 - val_accuracy: 0.9848\n",
      "Epoch 119/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0314 - accuracy: 0.9874 - val_loss: 0.0446 - val_accuracy: 0.9847\n",
      "Epoch 120/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0313 - accuracy: 0.9874 - val_loss: 0.0446 - val_accuracy: 0.9848\n",
      "Epoch 121/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0313 - accuracy: 0.9874 - val_loss: 0.0436 - val_accuracy: 0.9850\n",
      "Epoch 122/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0312 - accuracy: 0.9875 - val_loss: 0.0439 - val_accuracy: 0.9849\n",
      "Epoch 123/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0312 - accuracy: 0.9875 - val_loss: 0.0434 - val_accuracy: 0.9850\n",
      "Epoch 124/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0311 - accuracy: 0.9875 - val_loss: 0.0441 - val_accuracy: 0.9849\n",
      "Epoch 125/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0311 - accuracy: 0.9875 - val_loss: 0.0442 - val_accuracy: 0.9849\n",
      "Epoch 126/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.0434 - val_accuracy: 0.9851\n",
      "Epoch 127/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.0436 - val_accuracy: 0.9850\n",
      "Epoch 128/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0309 - accuracy: 0.9875 - val_loss: 0.0441 - val_accuracy: 0.9850\n",
      "Epoch 129/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0309 - accuracy: 0.9876 - val_loss: 0.0443 - val_accuracy: 0.9849\n",
      "Epoch 130/150\n",
      "254090/254090 [==============================] - 42s 167us/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.0438 - val_accuracy: 0.9849\n",
      "Epoch 131/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.0437 - val_accuracy: 0.9850\n",
      "Epoch 132/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0307 - accuracy: 0.9876 - val_loss: 0.0435 - val_accuracy: 0.9851\n",
      "Epoch 133/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0307 - accuracy: 0.9876 - val_loss: 0.0439 - val_accuracy: 0.9851\n",
      "Epoch 134/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0307 - accuracy: 0.9876 - val_loss: 0.0441 - val_accuracy: 0.9849\n",
      "Epoch 135/150\n",
      "254090/254090 [==============================] - 41s 163us/step - loss: 0.0306 - accuracy: 0.9877 - val_loss: 0.0429 - val_accuracy: 0.9852\n",
      "Epoch 136/150\n",
      "254090/254090 [==============================] - 45s 175us/step - loss: 0.0306 - accuracy: 0.9877 - val_loss: 0.0433 - val_accuracy: 0.9851\n",
      "Epoch 137/150\n",
      "254090/254090 [==============================] - 42s 167us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0442 - val_accuracy: 0.9850\n",
      "Epoch 138/150\n",
      "254090/254090 [==============================] - 45s 178us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0430 - val_accuracy: 0.9851\n",
      "Epoch 139/150\n",
      "254090/254090 [==============================] - 45s 177us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0439 - val_accuracy: 0.9851\n",
      "Epoch 140/150\n",
      "254090/254090 [==============================] - 47s 185us/step - loss: 0.0304 - accuracy: 0.9877 - val_loss: 0.0431 - val_accuracy: 0.9852\n",
      "Epoch 141/150\n",
      "254090/254090 [==============================] - 52s 203us/step - loss: 0.0304 - accuracy: 0.9877 - val_loss: 0.0443 - val_accuracy: 0.9850\n",
      "Epoch 142/150\n",
      "254090/254090 [==============================] - 41s 163us/step - loss: 0.0303 - accuracy: 0.9877 - val_loss: 0.0437 - val_accuracy: 0.9851\n",
      "Epoch 143/150\n",
      "254090/254090 [==============================] - 48s 188us/step - loss: 0.0303 - accuracy: 0.9877 - val_loss: 0.0433 - val_accuracy: 0.9852\n",
      "Epoch 144/150\n",
      "254090/254090 [==============================] - 42s 165us/step - loss: 0.0303 - accuracy: 0.9878 - val_loss: 0.0433 - val_accuracy: 0.9852\n",
      "Epoch 145/150\n",
      "254090/254090 [==============================] - 42s 164us/step - loss: 0.0302 - accuracy: 0.9878 - val_loss: 0.0434 - val_accuracy: 0.9852\n",
      "Epoch 146/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0302 - accuracy: 0.9878 - val_loss: 0.0429 - val_accuracy: 0.9853\n",
      "Epoch 147/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.0431 - val_accuracy: 0.9852\n",
      "Epoch 148/150\n",
      "254090/254090 [==============================] - 42s 164us/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.0427 - val_accuracy: 0.9854\n",
      "Epoch 149/150\n",
      "254090/254090 [==============================] - 41s 163us/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.0436 - val_accuracy: 0.9851\n",
      "Epoch 150/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0300 - accuracy: 0.9878 - val_loss: 0.0435 - val_accuracy: 0.9851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clair\\Anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:136: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\clair\\Anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Train on 254090 samples, validate on 84697 samples\n",
      "Epoch 1/150\n",
      "254090/254090 [==============================] - 39s 152us/step - loss: 0.1634 - accuracy: 0.9600 - val_loss: 0.1869 - val_accuracy: 0.9522\n",
      "Epoch 2/150\n",
      "254090/254090 [==============================] - 37s 147us/step - loss: 0.1408 - accuracy: 0.9625 - val_loss: 0.1512 - val_accuracy: 0.9528\n",
      "Epoch 3/150\n",
      "254090/254090 [==============================] - 38s 151us/step - loss: 0.1115 - accuracy: 0.9644 - val_loss: 0.1201 - val_accuracy: 0.9585\n",
      "Epoch 4/150\n",
      "254090/254090 [==============================] - 40s 156us/step - loss: 0.0908 - accuracy: 0.9688 - val_loss: 0.1040 - val_accuracy: 0.9634\n",
      "Epoch 5/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0797 - accuracy: 0.9721 - val_loss: 0.0949 - val_accuracy: 0.9666\n",
      "Epoch 6/150\n",
      "254090/254090 [==============================] - 40s 156us/step - loss: 0.0724 - accuracy: 0.9745 - val_loss: 0.0888 - val_accuracy: 0.9689\n",
      "Epoch 7/150\n",
      "254090/254090 [==============================] - 43s 168us/step - loss: 0.0671 - accuracy: 0.9763 - val_loss: 0.0840 - val_accuracy: 0.9707\n",
      "Epoch 8/150\n",
      "254090/254090 [==============================] - 42s 165us/step - loss: 0.0630 - accuracy: 0.9777 - val_loss: 0.0801 - val_accuracy: 0.9722\n",
      "Epoch 9/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0597 - accuracy: 0.9788 - val_loss: 0.0771 - val_accuracy: 0.9733\n",
      "Epoch 10/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0571 - accuracy: 0.9797 - val_loss: 0.0742 - val_accuracy: 0.9744\n",
      "Epoch 11/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0549 - accuracy: 0.9805 - val_loss: 0.0721 - val_accuracy: 0.9752\n",
      "Epoch 12/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0532 - accuracy: 0.9811 - val_loss: 0.0698 - val_accuracy: 0.9760\n",
      "Epoch 13/150\n",
      "254090/254090 [==============================] - 42s 166us/step - loss: 0.0516 - accuracy: 0.9816 - val_loss: 0.0681 - val_accuracy: 0.9767\n",
      "Epoch 14/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0504 - accuracy: 0.9820 - val_loss: 0.0664 - val_accuracy: 0.9773\n",
      "Epoch 15/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0493 - accuracy: 0.9824 - val_loss: 0.0652 - val_accuracy: 0.9777\n",
      "Epoch 16/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0483 - accuracy: 0.9827 - val_loss: 0.0638 - val_accuracy: 0.9781\n",
      "Epoch 17/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0475 - accuracy: 0.9830 - val_loss: 0.0623 - val_accuracy: 0.9786\n",
      "Epoch 18/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0468 - accuracy: 0.9832 - val_loss: 0.0609 - val_accuracy: 0.9790\n",
      "Epoch 19/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0461 - accuracy: 0.9834 - val_loss: 0.0604 - val_accuracy: 0.9793\n",
      "Epoch 20/150\n",
      "254090/254090 [==============================] - 41s 159us/step - loss: 0.0455 - accuracy: 0.9836 - val_loss: 0.0605 - val_accuracy: 0.9794\n",
      "Epoch 21/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0449 - accuracy: 0.9837 - val_loss: 0.0594 - val_accuracy: 0.9797\n",
      "Epoch 22/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0444 - accuracy: 0.9839 - val_loss: 0.0596 - val_accuracy: 0.9797\n",
      "Epoch 23/150\n",
      "254090/254090 [==============================] - 42s 166us/step - loss: 0.0440 - accuracy: 0.9840 - val_loss: 0.0579 - val_accuracy: 0.9801\n",
      "Epoch 24/150\n",
      "254090/254090 [==============================] - 41s 159us/step - loss: 0.0435 - accuracy: 0.9841 - val_loss: 0.0576 - val_accuracy: 0.9803\n",
      "Epoch 25/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0431 - accuracy: 0.9842 - val_loss: 0.0569 - val_accuracy: 0.9806\n",
      "Epoch 26/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0427 - accuracy: 0.9843 - val_loss: 0.0564 - val_accuracy: 0.9807\n",
      "Epoch 27/150\n",
      "254090/254090 [==============================] - 41s 163us/step - loss: 0.0423 - accuracy: 0.9844 - val_loss: 0.0566 - val_accuracy: 0.9807\n",
      "Epoch 28/150\n",
      "254090/254090 [==============================] - 42s 164us/step - loss: 0.0420 - accuracy: 0.9845 - val_loss: 0.0560 - val_accuracy: 0.9809\n",
      "Epoch 29/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0417 - accuracy: 0.9846 - val_loss: 0.0546 - val_accuracy: 0.9812\n",
      "Epoch 30/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0413 - accuracy: 0.9847 - val_loss: 0.0548 - val_accuracy: 0.9812\n",
      "Epoch 31/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0410 - accuracy: 0.9847 - val_loss: 0.0547 - val_accuracy: 0.9813\n",
      "Epoch 32/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0407 - accuracy: 0.9848 - val_loss: 0.0548 - val_accuracy: 0.9813\n",
      "Epoch 33/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0405 - accuracy: 0.9849 - val_loss: 0.0540 - val_accuracy: 0.9815\n",
      "Epoch 34/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0402 - accuracy: 0.9849 - val_loss: 0.0534 - val_accuracy: 0.9817\n",
      "Epoch 35/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0399 - accuracy: 0.9850 - val_loss: 0.0531 - val_accuracy: 0.9817\n",
      "Epoch 36/150\n",
      "254090/254090 [==============================] - 41s 163us/step - loss: 0.0397 - accuracy: 0.9851 - val_loss: 0.0529 - val_accuracy: 0.9819\n",
      "Epoch 37/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0394 - accuracy: 0.9851 - val_loss: 0.0522 - val_accuracy: 0.9820\n",
      "Epoch 38/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0392 - accuracy: 0.9852 - val_loss: 0.0528 - val_accuracy: 0.9819\n",
      "Epoch 39/150\n",
      "254090/254090 [==============================] - 41s 163us/step - loss: 0.0390 - accuracy: 0.9853 - val_loss: 0.0524 - val_accuracy: 0.9820\n",
      "Epoch 40/150\n",
      "254090/254090 [==============================] - 42s 165us/step - loss: 0.0388 - accuracy: 0.9853 - val_loss: 0.0515 - val_accuracy: 0.9823\n",
      "Epoch 41/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0386 - accuracy: 0.9854 - val_loss: 0.0520 - val_accuracy: 0.9822\n",
      "Epoch 42/150\n",
      "254090/254090 [==============================] - 43s 167us/step - loss: 0.0384 - accuracy: 0.9854 - val_loss: 0.0519 - val_accuracy: 0.9821\n",
      "Epoch 43/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0382 - accuracy: 0.9855 - val_loss: 0.0520 - val_accuracy: 0.9821\n",
      "Epoch 44/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0380 - accuracy: 0.9855 - val_loss: 0.0508 - val_accuracy: 0.9825\n",
      "Epoch 45/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0378 - accuracy: 0.9856 - val_loss: 0.0511 - val_accuracy: 0.9824\n",
      "Epoch 46/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0376 - accuracy: 0.9856 - val_loss: 0.0511 - val_accuracy: 0.9825\n",
      "Epoch 47/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0374 - accuracy: 0.9857 - val_loss: 0.0505 - val_accuracy: 0.9827\n",
      "Epoch 48/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0373 - accuracy: 0.9857 - val_loss: 0.0505 - val_accuracy: 0.9827\n",
      "Epoch 49/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0371 - accuracy: 0.9858 - val_loss: 0.0501 - val_accuracy: 0.9827\n",
      "Epoch 50/150\n",
      "254090/254090 [==============================] - 41s 159us/step - loss: 0.0370 - accuracy: 0.9858 - val_loss: 0.0494 - val_accuracy: 0.9830\n",
      "Epoch 51/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0368 - accuracy: 0.9858 - val_loss: 0.0496 - val_accuracy: 0.9830\n",
      "Epoch 52/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0367 - accuracy: 0.9859 - val_loss: 0.0494 - val_accuracy: 0.9830\n",
      "Epoch 53/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0365 - accuracy: 0.9859 - val_loss: 0.0492 - val_accuracy: 0.9830\n",
      "Epoch 54/150\n",
      "254090/254090 [==============================] - 41s 163us/step - loss: 0.0364 - accuracy: 0.9860 - val_loss: 0.0493 - val_accuracy: 0.9831\n",
      "Epoch 55/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0363 - accuracy: 0.9860 - val_loss: 0.0489 - val_accuracy: 0.9831\n",
      "Epoch 56/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0361 - accuracy: 0.9860 - val_loss: 0.0494 - val_accuracy: 0.9831\n",
      "Epoch 57/150\n",
      "254090/254090 [==============================] - 42s 166us/step - loss: 0.0360 - accuracy: 0.9861 - val_loss: 0.0491 - val_accuracy: 0.9832\n",
      "Epoch 58/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0359 - accuracy: 0.9861 - val_loss: 0.0481 - val_accuracy: 0.9833\n",
      "Epoch 59/150\n",
      "254090/254090 [==============================] - 41s 159us/step - loss: 0.0358 - accuracy: 0.9861 - val_loss: 0.0483 - val_accuracy: 0.9833\n",
      "Epoch 60/150\n",
      "254090/254090 [==============================] - 43s 168us/step - loss: 0.0356 - accuracy: 0.9862 - val_loss: 0.0481 - val_accuracy: 0.9833\n",
      "Epoch 61/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0355 - accuracy: 0.9862 - val_loss: 0.0482 - val_accuracy: 0.9834\n",
      "Epoch 62/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0354 - accuracy: 0.9862 - val_loss: 0.0485 - val_accuracy: 0.9833\n",
      "Epoch 63/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0353 - accuracy: 0.9863 - val_loss: 0.0480 - val_accuracy: 0.9835\n",
      "Epoch 64/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0352 - accuracy: 0.9863 - val_loss: 0.0477 - val_accuracy: 0.9836\n",
      "Epoch 65/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0351 - accuracy: 0.9863 - val_loss: 0.0476 - val_accuracy: 0.9836\n",
      "Epoch 66/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0350 - accuracy: 0.9864 - val_loss: 0.0478 - val_accuracy: 0.9836\n",
      "Epoch 67/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0349 - accuracy: 0.9864 - val_loss: 0.0474 - val_accuracy: 0.9837\n",
      "Epoch 68/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0348 - accuracy: 0.9864 - val_loss: 0.0476 - val_accuracy: 0.9836\n",
      "Epoch 69/150\n",
      "254090/254090 [==============================] - 42s 164us/step - loss: 0.0347 - accuracy: 0.9864 - val_loss: 0.0473 - val_accuracy: 0.9836\n",
      "Epoch 70/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0346 - accuracy: 0.9864 - val_loss: 0.0470 - val_accuracy: 0.9838\n",
      "Epoch 71/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0345 - accuracy: 0.9865 - val_loss: 0.0469 - val_accuracy: 0.9838\n",
      "Epoch 72/150\n",
      "254090/254090 [==============================] - 43s 169us/step - loss: 0.0344 - accuracy: 0.9865 - val_loss: 0.0470 - val_accuracy: 0.9838\n",
      "Epoch 73/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0343 - accuracy: 0.9865 - val_loss: 0.0468 - val_accuracy: 0.9838\n",
      "Epoch 74/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0343 - accuracy: 0.9866 - val_loss: 0.0471 - val_accuracy: 0.9838\n",
      "Epoch 75/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0342 - accuracy: 0.9866 - val_loss: 0.0470 - val_accuracy: 0.9838\n",
      "Epoch 76/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0341 - accuracy: 0.9866 - val_loss: 0.0472 - val_accuracy: 0.9839\n",
      "Epoch 77/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0340 - accuracy: 0.9866 - val_loss: 0.0471 - val_accuracy: 0.9838\n",
      "Epoch 78/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0339 - accuracy: 0.9867 - val_loss: 0.0473 - val_accuracy: 0.9839\n",
      "Epoch 79/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0339 - accuracy: 0.9867 - val_loss: 0.0463 - val_accuracy: 0.9840\n",
      "Epoch 80/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0338 - accuracy: 0.9867 - val_loss: 0.0459 - val_accuracy: 0.9841\n",
      "Epoch 81/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0337 - accuracy: 0.9867 - val_loss: 0.0460 - val_accuracy: 0.9841\n",
      "Epoch 82/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0336 - accuracy: 0.9868 - val_loss: 0.0465 - val_accuracy: 0.9840\n",
      "Epoch 83/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0335 - accuracy: 0.9868 - val_loss: 0.0471 - val_accuracy: 0.9838\n",
      "Epoch 84/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0335 - accuracy: 0.9868 - val_loss: 0.0463 - val_accuracy: 0.9841\n",
      "Epoch 85/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0334 - accuracy: 0.9868 - val_loss: 0.0459 - val_accuracy: 0.9842\n",
      "Epoch 86/150\n",
      "254090/254090 [==============================] - 42s 164us/step - loss: 0.0333 - accuracy: 0.9869 - val_loss: 0.0458 - val_accuracy: 0.9841\n",
      "Epoch 87/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0333 - accuracy: 0.9869 - val_loss: 0.0462 - val_accuracy: 0.9841\n",
      "Epoch 88/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0332 - accuracy: 0.9869 - val_loss: 0.0463 - val_accuracy: 0.9842\n",
      "Epoch 89/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0331 - accuracy: 0.9869 - val_loss: 0.0461 - val_accuracy: 0.9841\n",
      "Epoch 90/150\n",
      "254090/254090 [==============================] - 41s 163us/step - loss: 0.0331 - accuracy: 0.9869 - val_loss: 0.0459 - val_accuracy: 0.9843\n",
      "Epoch 91/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0330 - accuracy: 0.9869 - val_loss: 0.0458 - val_accuracy: 0.9843\n",
      "Epoch 92/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0329 - accuracy: 0.9870 - val_loss: 0.0457 - val_accuracy: 0.9843\n",
      "Epoch 93/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0329 - accuracy: 0.9870 - val_loss: 0.0463 - val_accuracy: 0.9843\n",
      "Epoch 94/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0328 - accuracy: 0.9870 - val_loss: 0.0459 - val_accuracy: 0.9842\n",
      "Epoch 95/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0327 - accuracy: 0.9870 - val_loss: 0.0456 - val_accuracy: 0.9843\n",
      "Epoch 96/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0327 - accuracy: 0.9870 - val_loss: 0.0455 - val_accuracy: 0.9844\n",
      "Epoch 97/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0326 - accuracy: 0.9870 - val_loss: 0.0458 - val_accuracy: 0.9844\n",
      "Epoch 98/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0326 - accuracy: 0.9871 - val_loss: 0.0457 - val_accuracy: 0.9843\n",
      "Epoch 99/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0325 - accuracy: 0.9871 - val_loss: 0.0456 - val_accuracy: 0.9844\n",
      "Epoch 100/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0324 - accuracy: 0.9871 - val_loss: 0.0452 - val_accuracy: 0.9845\n",
      "Epoch 101/150\n",
      "254090/254090 [==============================] - 42s 166us/step - loss: 0.0324 - accuracy: 0.9871 - val_loss: 0.0453 - val_accuracy: 0.9845\n",
      "Epoch 102/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0323 - accuracy: 0.9871 - val_loss: 0.0452 - val_accuracy: 0.9845\n",
      "Epoch 103/150\n",
      "254090/254090 [==============================] - 42s 163us/step - loss: 0.0323 - accuracy: 0.9872 - val_loss: 0.0454 - val_accuracy: 0.9845\n",
      "Epoch 104/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0322 - accuracy: 0.9872 - val_loss: 0.0450 - val_accuracy: 0.9846\n",
      "Epoch 105/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0321 - accuracy: 0.9872 - val_loss: 0.0451 - val_accuracy: 0.9846\n",
      "Epoch 106/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0321 - accuracy: 0.9872 - val_loss: 0.0452 - val_accuracy: 0.9846\n",
      "Epoch 107/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0320 - accuracy: 0.9872 - val_loss: 0.0450 - val_accuracy: 0.9847\n",
      "Epoch 108/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0320 - accuracy: 0.9873 - val_loss: 0.0444 - val_accuracy: 0.9847\n",
      "Epoch 109/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0319 - accuracy: 0.9873 - val_loss: 0.0452 - val_accuracy: 0.9846\n",
      "Epoch 110/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0319 - accuracy: 0.9873 - val_loss: 0.0442 - val_accuracy: 0.9848\n",
      "Epoch 111/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0318 - accuracy: 0.9873 - val_loss: 0.0447 - val_accuracy: 0.9847\n",
      "Epoch 112/150\n",
      "254090/254090 [==============================] - 42s 164us/step - loss: 0.0318 - accuracy: 0.9873 - val_loss: 0.0447 - val_accuracy: 0.9847\n",
      "Epoch 113/150\n",
      "254090/254090 [==============================] - 41s 162us/step - loss: 0.0317 - accuracy: 0.9873 - val_loss: 0.0449 - val_accuracy: 0.9847\n",
      "Epoch 114/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0317 - accuracy: 0.9873 - val_loss: 0.0443 - val_accuracy: 0.9848\n",
      "Epoch 115/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0316 - accuracy: 0.9873 - val_loss: 0.0452 - val_accuracy: 0.9847\n",
      "Epoch 116/150\n",
      "254090/254090 [==============================] - 43s 169us/step - loss: 0.0316 - accuracy: 0.9874 - val_loss: 0.0450 - val_accuracy: 0.9847\n",
      "Epoch 117/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0315 - accuracy: 0.9874 - val_loss: 0.0442 - val_accuracy: 0.9848\n",
      "Epoch 118/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0315 - accuracy: 0.9874 - val_loss: 0.0443 - val_accuracy: 0.9849\n",
      "Epoch 119/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0314 - accuracy: 0.9874 - val_loss: 0.0443 - val_accuracy: 0.9848\n",
      "Epoch 120/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0314 - accuracy: 0.9874 - val_loss: 0.0448 - val_accuracy: 0.9847\n",
      "Epoch 121/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0313 - accuracy: 0.9874 - val_loss: 0.0440 - val_accuracy: 0.9849\n",
      "Epoch 122/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0313 - accuracy: 0.9875 - val_loss: 0.0439 - val_accuracy: 0.9848\n",
      "Epoch 123/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0312 - accuracy: 0.9875 - val_loss: 0.0446 - val_accuracy: 0.9848\n",
      "Epoch 124/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0312 - accuracy: 0.9875 - val_loss: 0.0441 - val_accuracy: 0.9849\n",
      "Epoch 125/150\n",
      "254090/254090 [==============================] - 42s 165us/step - loss: 0.0311 - accuracy: 0.9875 - val_loss: 0.0438 - val_accuracy: 0.9850\n",
      "Epoch 126/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0311 - accuracy: 0.9875 - val_loss: 0.0445 - val_accuracy: 0.9849\n",
      "Epoch 127/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.0443 - val_accuracy: 0.9849\n",
      "Epoch 128/150\n",
      "254090/254090 [==============================] - 41s 163us/step - loss: 0.0310 - accuracy: 0.9875 - val_loss: 0.0438 - val_accuracy: 0.9850\n",
      "Epoch 129/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0310 - accuracy: 0.9876 - val_loss: 0.0442 - val_accuracy: 0.9849\n",
      "Epoch 130/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0309 - accuracy: 0.9876 - val_loss: 0.0436 - val_accuracy: 0.9850\n",
      "Epoch 131/150\n",
      "254090/254090 [==============================] - 41s 163us/step - loss: 0.0309 - accuracy: 0.9876 - val_loss: 0.0433 - val_accuracy: 0.9850\n",
      "Epoch 132/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.0431 - val_accuracy: 0.9851\n",
      "Epoch 133/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.0439 - val_accuracy: 0.9851\n",
      "Epoch 134/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0307 - accuracy: 0.9876 - val_loss: 0.0442 - val_accuracy: 0.9850\n",
      "Epoch 135/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0307 - accuracy: 0.9876 - val_loss: 0.0442 - val_accuracy: 0.9850\n",
      "Epoch 136/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0307 - accuracy: 0.9876 - val_loss: 0.0437 - val_accuracy: 0.9851\n",
      "Epoch 137/150\n",
      "254090/254090 [==============================] - 40s 156us/step - loss: 0.0306 - accuracy: 0.9877 - val_loss: 0.0433 - val_accuracy: 0.9851\n",
      "Epoch 138/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0306 - accuracy: 0.9877 - val_loss: 0.0436 - val_accuracy: 0.9851\n",
      "Epoch 139/150\n",
      "254090/254090 [==============================] - 41s 159us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0437 - val_accuracy: 0.9851\n",
      "Epoch 140/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0438 - val_accuracy: 0.9850\n",
      "Epoch 141/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0305 - accuracy: 0.9877 - val_loss: 0.0438 - val_accuracy: 0.9850\n",
      "Epoch 142/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0304 - accuracy: 0.9877 - val_loss: 0.0436 - val_accuracy: 0.9851\n",
      "Epoch 143/150\n",
      "254090/254090 [==============================] - 42s 164us/step - loss: 0.0304 - accuracy: 0.9877 - val_loss: 0.0435 - val_accuracy: 0.9851\n",
      "Epoch 144/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0303 - accuracy: 0.9877 - val_loss: 0.0435 - val_accuracy: 0.9852\n",
      "Epoch 145/150\n",
      "254090/254090 [==============================] - 41s 160us/step - loss: 0.0303 - accuracy: 0.9878 - val_loss: 0.0432 - val_accuracy: 0.9852\n",
      "Epoch 146/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0303 - accuracy: 0.9878 - val_loss: 0.0430 - val_accuracy: 0.9852\n",
      "Epoch 147/150\n",
      "254090/254090 [==============================] - 40s 158us/step - loss: 0.0302 - accuracy: 0.9878 - val_loss: 0.0432 - val_accuracy: 0.9852\n",
      "Epoch 148/150\n",
      "254090/254090 [==============================] - 40s 159us/step - loss: 0.0302 - accuracy: 0.9878 - val_loss: 0.0431 - val_accuracy: 0.9852\n",
      "Epoch 149/150\n",
      "254090/254090 [==============================] - 40s 157us/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.0431 - val_accuracy: 0.9852\n",
      "Epoch 150/150\n",
      "254090/254090 [==============================] - 41s 161us/step - loss: 0.0301 - accuracy: 0.9878 - val_loss: 0.0426 - val_accuracy: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clair\\Anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:136: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20000, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[20000, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[18662, 534]\n",
      "[708, 96]\n",
      "[18864, 332]\n",
      "[60, 744]\n",
      "[19264, 324]\n",
      "[231, 181]\n",
      "[19051, 537]\n",
      "[126, 286]\n",
      "[19684, 193]\n",
      "[59, 64]\n",
      "[19291, 586]\n",
      "[43, 80]\n",
      "[19764, 115]\n",
      "[55, 66]\n",
      "[19244, 635]\n",
      "[48, 73]\n",
      "[19650, 235]\n",
      "[76, 39]\n",
      "[19284, 601]\n",
      "[27, 88]\n",
      "[19524, 329]\n",
      "[79, 68]\n",
      "[19210, 643]\n",
      "[67, 80]\n",
      "[18187, 1247]\n",
      "[287, 279]\n",
      "[18894, 540]\n",
      "[181, 385]\n",
      "[18506, 950]\n",
      "[328, 216]\n",
      "[18972, 484]\n",
      "[100, 444]\n",
      "[19473, 296]\n",
      "[121, 110]\n",
      "[19137, 632]\n",
      "[64, 167]\n",
      "[19623, 201]\n",
      "[91, 85]\n",
      "[19239, 585]\n",
      "[72, 104]\n",
      "[19654, 204]\n",
      "[64, 78]\n",
      "[19238, 620]\n",
      "[71, 71]\n",
      "[19660, 204]\n",
      "[59, 77]\n",
      "[19188, 676]\n",
      "[67, 69]\n",
      "[19363, 461]\n",
      "[79, 97]\n",
      "[19172, 652]\n",
      "[56, 120]\n",
      "[18891, 487]\n",
      "[247, 375]\n",
      "[18850, 528]\n",
      "[203, 419]\n",
      "[18988, 428]\n",
      "[250, 334]\n",
      "[18941, 475]\n",
      "[198, 386]\n",
      "[19343, 496]\n",
      "[95, 66]\n",
      "[19225, 614]\n",
      "[58, 103]\n",
      "[19664, 197]\n",
      "[67, 72]\n",
      "[19296, 565]\n",
      "[56, 83]\n",
      "[19618, 237]\n",
      "[79, 66]\n",
      "[19236, 619]\n",
      "[46, 99]\n",
      "[19484, 369]\n",
      "[72, 75]\n",
      "[19239, 614]\n",
      "[73, 74]\n",
      "[19478, 331]\n",
      "[109, 82]\n",
      "[19183, 626]\n",
      "[88, 103]\n",
      "[18531, 871]\n",
      "[235, 363]\n",
      "[18883, 519]\n",
      "[240, 358]\n",
      "[18383, 1030]\n",
      "[316, 271]\n",
      "[18932, 481]\n",
      "[130, 457]\n",
      "[19420, 408]\n",
      "[99, 73]\n",
      "[19199, 629]\n",
      "[59, 113]\n",
      "[19619, 237]\n",
      "[66, 78]\n",
      "[19230, 626]\n",
      "[51, 93]\n",
      "[19671, 200]\n",
      "[58, 71]\n",
      "[19265, 606]\n",
      "[42, 87]\n",
      "[19595, 246]\n",
      "[87, 72]\n",
      "[19215, 626]\n",
      "[80, 79]\n",
      "[19361, 479]\n",
      "[79, 81]\n",
      "[19186, 654]\n",
      "[55, 105]\n",
      "[19002, 445]\n",
      "[182, 371]\n",
      "[18972, 475]\n",
      "[148, 405]\n",
      "[19084, 381]\n",
      "[84, 451]\n",
      "[19018, 447]\n",
      "[86, 449]\n",
      "[19342, 501]\n",
      "[75, 82]\n",
      "[19204, 639]\n",
      "[77, 80]\n",
      "[19657, 201]\n",
      "[72, 70]\n",
      "[19215, 643]\n",
      "[67, 75]\n",
      "[19615, 251]\n",
      "[65, 69]\n",
      "[19278, 588]\n",
      "[37, 97]\n",
      "[19562, 288]\n",
      "[85, 65]\n",
      "[19189, 661]\n",
      "[61, 89]\n",
      "[19489, 350]\n",
      "[73, 88]\n",
      "[19229, 610]\n",
      "[64, 97]\n",
      "[18508, 929]\n",
      "[202, 361]\n",
      "[18884, 553]\n",
      "[204, 359]\n",
      "[18574, 845]\n",
      "[273, 308]\n",
      "[18925, 494]\n",
      "[172, 409]\n",
      "[19473, 340]\n",
      "[105, 82]\n",
      "[19188, 625]\n",
      "[82, 105]\n",
      "[19581, 268]\n",
      "[66, 85]\n",
      "[19232, 617]\n",
      "[52, 99]\n",
      "[19639, 209]\n",
      "[63, 89]\n",
      "[19222, 626]\n",
      "[53, 99]\n",
      "[19649, 214]\n",
      "[63, 74]\n",
      "[19242, 621]\n",
      "[52, 85]\n",
      "[19443, 353]\n",
      "[81, 123]\n",
      "[19145, 651]\n",
      "[95, 109]\n",
      "[18987, 432]\n",
      "[205, 376]\n",
      "[18960, 459]\n",
      "[156, 425]\n",
      "[19047, 403]\n",
      "[156, 394]\n",
      "[18999, 451]\n",
      "[125, 425]\n",
      "[19714, 170]\n",
      "[39, 77]\n",
      "[19235, 649]\n",
      "[38, 78]\n",
      "[19824, 68]\n",
      "[51, 57]\n",
      "[19251, 641]\n",
      "[60, 48]\n",
      "[19795, 108]\n",
      "[34, 63]\n",
      "[19237, 666]\n",
      "[54, 43]\n",
      "[19764, 121]\n",
      "[39, 76]\n",
      "[19238, 647]\n",
      "[61, 54]\n",
      "[19703, 141]\n",
      "[61, 95]\n",
      "[19202, 642]\n",
      "[52, 104]\n",
      "[19542, 183]\n",
      "[91, 184]\n",
      "[19154, 571]\n",
      "[111, 164]\n",
      "[18192, 1146]\n",
      "[301, 361]\n",
      "[19000, 338]\n",
      "[228, 434]\n",
      "[19010, 407]\n",
      "[152, 431]\n",
      "[18903, 514]\n",
      "[130, 453]\n",
      "[18469, 997]\n",
      "[311, 223]\n",
      "[19045, 421]\n",
      "[108, 426]\n",
      "[19093, 396]\n",
      "[96, 415]\n",
      "[19022, 467]\n",
      "[81, 430]\n",
      "[18445, 997]\n",
      "[337, 221]\n",
      "[18995, 447]\n",
      "[98, 460]\n",
      "[19109, 354]\n",
      "[102, 435]\n",
      "[19037, 426]\n",
      "[85, 452]\n",
      "[19511, 175]\n",
      "[159, 155]\n",
      "[19160, 526]\n",
      "[88, 226]\n",
      "[19536, 309]\n",
      "[98, 57]\n",
      "[19282, 563]\n",
      "[41, 114]\n",
      "[19318, 465]\n",
      "[114, 103]\n",
      "[19203, 580]\n",
      "[71, 146]\n",
      "[19460, 333]\n",
      "[106, 101]\n",
      "[19187, 606]\n",
      "[61, 146]\n",
      "[19337, 440]\n",
      "[118, 105]\n",
      "[19180, 597]\n",
      "[83, 140]\n",
      "[19397, 390]\n",
      "[114, 99]\n",
      "[19164, 623]\n",
      "[84, 129]\n",
      "[19409, 403]\n",
      "[106, 82]\n",
      "[19182, 630]\n",
      "[75, 113]\n",
      "[19709, 129]\n",
      "[84, 78]\n",
      "[19188, 650]\n",
      "[59, 103]\n",
      "[19742, 150]\n",
      "[54, 54]\n",
      "[19297, 595]\n",
      "[48, 60]\n",
      "[19645, 196]\n",
      "[86, 73]\n",
      "[19205, 636]\n",
      "[80, 79]\n",
      "[19527, 305]\n",
      "[85, 83]\n",
      "[19284, 548]\n",
      "[51, 117]\n",
      "[19503, 326]\n",
      "[102, 69]\n",
      "[19224, 605]\n",
      "[48, 123]\n",
      "[19564, 260]\n",
      "[102, 74]\n",
      "[19242, 582]\n",
      "[57, 119]\n",
      "[19656, 172]\n",
      "[85, 87]\n",
      "[19217, 611]\n",
      "[70, 102]\n",
      "[19720, 157]\n",
      "[67, 56]\n",
      "[19294, 583]\n",
      "[40, 83]\n",
      "[19677, 178]\n",
      "[85, 60]\n",
      "[19245, 610]\n",
      "[34, 111]\n",
      "[19644, 210]\n",
      "[72, 74]\n",
      "[19250, 604]\n",
      "[38, 108]\n",
      "[19597, 247]\n",
      "[78, 78]\n",
      "[19259, 585]\n",
      "[32, 124]\n",
      "[19622, 203]\n",
      "[89, 86]\n",
      "[19238, 587]\n",
      "[65, 110]\n",
      "[19642, 198]\n",
      "[87, 73]\n",
      "[19268, 572]\n",
      "[57, 103]\n",
      "[19637, 205]\n",
      "[75, 83]\n",
      "[19233, 609]\n",
      "[40, 118]\n",
      "[19765, 101]\n",
      "[59, 75]\n",
      "[19198, 668]\n",
      "[58, 76]\n",
      "[19676, 187]\n",
      "[74, 63]\n",
      "[19244, 619]\n",
      "[33, 104]\n",
      "[19593, 242]\n",
      "[82, 83]\n",
      "[19239, 596]\n",
      "[51, 114]\n",
      "[19573, 278]\n",
      "[85, 64]\n",
      "[19222, 629]\n",
      "[49, 100]\n",
      "[19511, 307]\n",
      "[106, 76]\n",
      "[19239, 579]\n",
      "[38, 144]\n",
      "[19569, 249]\n",
      "[89, 93]\n",
      "[19204, 614]\n",
      "[84, 98]\n",
      "[19574, 244]\n",
      "[85, 97]\n",
      "[19215, 603]\n",
      "[69, 113]\n",
      "[19755, 101]\n",
      "[77, 67]\n",
      "[19219, 637]\n",
      "[44, 100]\n",
      "[19423, 417]\n",
      "[88, 72]\n",
      "[19245, 595]\n",
      "[55, 105]\n",
      "[19572, 232]\n",
      "[85, 111]\n",
      "[19228, 576]\n",
      "[44, 152]\n",
      "[19342, 453]\n",
      "[113, 92]\n",
      "[19192, 603]\n",
      "[69, 136]\n",
      "[19493, 302]\n",
      "[82, 123]\n",
      "[19238, 557]\n",
      "[56, 149]\n",
      "[19334, 452]\n",
      "[96, 118]\n",
      "[19162, 624]\n",
      "[86, 128]\n",
      "[19459, 332]\n",
      "[93, 116]\n",
      "[19221, 570]\n",
      "[48, 161]\n",
      "[19671, 187]\n",
      "[66, 76]\n",
      "[19237, 621]\n",
      "[41, 101]\n",
      "[19267, 469]\n",
      "[126, 138]\n",
      "[19186, 550]\n",
      "[114, 150]\n",
      "[18438, 1040]\n",
      "[317, 205]\n",
      "[18999, 479]\n",
      "[83, 439]\n",
      "[19072, 385]\n",
      "[129, 414]\n",
      "[19013, 444]\n",
      "[101, 442]\n",
      "[18468, 1015]\n",
      "[287, 230]\n",
      "[18977, 506]\n",
      "[115, 402]\n",
      "[18909, 514]\n",
      "[269, 308]\n",
      "[18907, 516]\n",
      "[218, 359]\n",
      "[18407, 1002]\n",
      "[346, 245]\n",
      "[18967, 442]\n",
      "[121, 470]\n",
      "[19031, 410]\n",
      "[168, 391]\n",
      "[19008, 433]\n",
      "[118, 441]\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds of MWPM:\n",
      "> Accuracy: 0.9740728956229128 (+- 6.41637243913647e-05)\n",
      "> F1: 0.6989635170840348(+- 0.0007045742334666265)\n",
      "> Time: 3310.980690433331 (+- 57.87214651447051)\n",
      "Average scores for all folds of PLUT:\n",
      "> Accuracy: 0.962125135865279 (+- 1.7512619412737018e-05)\n",
      "> F1: 0.21745138362860852(+- 0.00042871448977584154)\n",
      "> Time: 5.394669633333334 (+- 0.1790883232414726)\n",
      "Average scores for all folds of NN:\n",
      "> Accuracy: 0.9865066146375333 (+- 8.370010686060943e-05)\n",
      "> F1: 0.8214243120606451(+- 0.0007256249779055657)\n",
      "> Time: 5.932276533333333 (+- 0.1120422246275134)\n",
      "> AUC for class : 0.9973080192689147 (+- 0.0)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 0\n",
      "> AUC for class X00: 0.8754114828928028 (+- 0.002339450944796075)\n",
      "X^2 for MWPM and NN: 24.65780998389694\n",
      "X^2 for PLUT and NN: 187.34948979591837\n",
      "> AUC for class X01: 0.9856740220472912 (+- 0.00030800780190851703)\n",
      "X^2 for MWPM and NN: 15.250450450450451\n",
      "X^2 for PLUT and NN: 253.5444947209653\n",
      "> AUC for class X02: 0.9982601846486924 (+- 0.00028340631288781043)\n",
      "X^2 for MWPM and NN: 70.19444444444444\n",
      "X^2 for PLUT and NN: 467.033386327504\n",
      "> AUC for class X03: 0.99878941812558 (+- 8.690489580794966e-05)\n",
      "X^2 for MWPM and NN: 20.476470588235294\n",
      "X^2 for PLUT and NN: 502.77598828696927\n",
      "> AUC for class X04: 0.9985478315945507 (+- 0.00010970061316727045)\n",
      "X^2 for MWPM and NN: 80.27009646302251\n",
      "X^2 for PLUT and NN: 522.8168789808917\n",
      "> AUC for class X05: 0.9980617517622066 (+- 0.0002391094328452319)\n",
      "X^2 for MWPM and NN: 151.96323529411765\n",
      "X^2 for PLUT and NN: 465.66901408450707\n",
      "> AUC for class X06: 0.9805773589431248 (+- 0.00031712217326180587)\n",
      "X^2 for MWPM and NN: 599.5312907431552\n",
      "X^2 for PLUT and NN: 177.75866851595006\n",
      "> AUC for class X10: 0.9793000448601389 (+- 0.00048781353437478647)\n",
      "X^2 for MWPM and NN: 301.7535211267606\n",
      "X^2 for PLUT and NN: 251.17979452054794\n",
      "> AUC for class X11: 0.9957562490841211 (+- 0.0001773305277382383)\n",
      "X^2 for MWPM and NN: 72.60431654676259\n",
      "X^2 for PLUT and NN: 461.9094827586207\n",
      "> AUC for class X12: 0.997354597305907 (+- 0.00011721274528248819)\n",
      "X^2 for MWPM and NN: 40.68835616438356\n",
      "X^2 for PLUT and NN: 399.0015220700152\n",
      "> AUC for class X13: 0.9978736305158508 (+- 0.00013859552027428224)\n",
      "X^2 for MWPM and NN: 72.09328358208955\n",
      "X^2 for PLUT and NN: 434.5933429811867\n",
      "> AUC for class X14: 0.9978118773722775 (+- 7.601463528315523e-05)\n",
      "X^2 for MWPM and NN: 78.84410646387833\n",
      "X^2 for PLUT and NN: 497.52893674293404\n",
      "> AUC for class X15: 0.9969539077736043 (+- 0.0001255606603380254)\n",
      "X^2 for MWPM and NN: 268.81666666666666\n",
      "X^2 for PLUT and NN: 500.0353107344633\n",
      "> AUC for class X16: 0.9800625243151241 (+- 0.00041438154024774077)\n",
      "X^2 for MWPM and NN: 77.82152588555859\n",
      "X^2 for PLUT and NN: 143.6060191518468\n",
      "> AUC for class X20: 0.9796543072166383 (+- 0.0015430082035079221)\n",
      "X^2 for MWPM and NN: 46.20796460176991\n",
      "X^2 for PLUT and NN: 113.18870728083209\n",
      "> AUC for class X21: 0.9967765434510332 (+- 0.0001173171894463195)\n",
      "X^2 for MWPM and NN: 270.72758037225043\n",
      "X^2 for PLUT and NN: 458.3705357142857\n",
      "> AUC for class X22: 0.9975836526499996 (+- 4.432957497497511e-05)\n",
      "X^2 for MWPM and NN: 63.03409090909091\n",
      "X^2 for PLUT and NN: 415.5619967793881\n",
      "> AUC for class X23: 0.997919141592201 (+- 0.00021951377361635157)\n",
      "X^2 for MWPM and NN: 78.00316455696202\n",
      "X^2 for PLUT and NN: 492.006015037594\n",
      "> AUC for class X24: 0.997711548250968 (+- 0.00014204166591415325)\n",
      "X^2 for MWPM and NN: 198.67573696145124\n",
      "X^2 for PLUT and NN: 424.4541484716157\n",
      "> AUC for class X25: 0.9968483602722179 (+- 8.401924017984733e-05)\n",
      "X^2 for MWPM and NN: 111.00227272727273\n",
      "X^2 for PLUT and NN: 403.8781512605042\n",
      "> AUC for class X26: 0.9806110481770899 (+- 0.0004373246104477904)\n",
      "X^2 for MWPM and NN: 364.57956600361666\n",
      "X^2 for PLUT and NN: 101.82345191040844\n",
      "> AUC for class X30: 0.9805628432126084 (+- 9.127821250139486e-05)\n",
      "X^2 for MWPM and NN: 377.6887072808321\n",
      "X^2 for PLUT and NN: 200.49099836333878\n",
      "> AUC for class X31: 0.9967689309510899 (+- 0.00018210948883781657)\n",
      "X^2 for MWPM and NN: 187.10848126232742\n",
      "X^2 for PLUT and NN: 470.5828488372093\n",
      "> AUC for class X32: 0.9978073240387713 (+- 9.179955396368122e-05)\n",
      "X^2 for MWPM and NN: 95.37953795379538\n",
      "X^2 for PLUT and NN: 486.67060561299854\n",
      "> AUC for class X33: 0.9978090681002026 (+- 0.00017336336578088868)\n",
      "X^2 for MWPM and NN: 77.05813953488372\n",
      "X^2 for PLUT and NN: 489.1496913580247\n",
      "> AUC for class X34: 0.9976955029860934 (+- 5.266078982125676e-05)\n",
      "X^2 for MWPM and NN: 74.96696696696696\n",
      "X^2 for PLUT and NN: 420.71529745042494\n",
      "> AUC for class X35: 0.9967194207910556 (+- 7.724236748386963e-05)\n",
      "X^2 for MWPM and NN: 285.30645161290323\n",
      "X^2 for PLUT and NN: 504.37799717912554\n",
      "> AUC for class X36: 0.9807336086346535 (+- 0.0006503167915049386)\n",
      "X^2 for MWPM and NN: 109.48006379585327\n",
      "X^2 for PLUT and NN: 170.58747993579453\n",
      "> AUC for class X40: 0.980274393433573 (+- 0.0001335779852820403)\n",
      "X^2 for MWPM and NN: 188.42150537634407\n",
      "X^2 for PLUT and NN: 243.15196998123827\n",
      "> AUC for class X41: 0.9970527335506977 (+- 1.6758404779014412e-05)\n",
      "X^2 for MWPM and NN: 313.58506944444446\n",
      "X^2 for PLUT and NN: 439.554469273743\n",
      "> AUC for class X42: 0.9976911789437058 (+- 8.902069856922156e-05)\n",
      "X^2 for MWPM and NN: 60.014652014652015\n",
      "X^2 for PLUT and NN: 465.66901408450707\n",
      "> AUC for class X43: 0.997657727173639 (+- 0.00013026034434011126)\n",
      "X^2 for MWPM and NN: 108.30696202531645\n",
      "X^2 for PLUT and NN: 484.0\n",
      "> AUC for class X44: 0.9975341418887022 (+- 0.00010920055461340571)\n",
      "X^2 for MWPM and NN: 109.3941018766756\n",
      "X^2 for PLUT and NN: 496.95429362880884\n",
      "> AUC for class X45: 0.9969152727251195 (+- 0.00015067310670158237)\n",
      "X^2 for MWPM and NN: 180.08510638297872\n",
      "X^2 for PLUT and NN: 440.6899109792285\n",
      "> AUC for class X46: 0.9801372835137773 (+- 0.001260998961947179)\n",
      "X^2 for MWPM and NN: 466.026525198939\n",
      "X^2 for PLUT and NN: 159.9788639365918\n",
      "> AUC for class X50: 0.9803096838478762 (+- 0.0011841516839524637)\n",
      "X^2 for MWPM and NN: 291.628801431127\n",
      "X^2 for PLUT and NN: 154.71621621621622\n",
      "> AUC for class X51: 0.9969206594228041 (+- 0.00010398271135162506)\n",
      "X^2 for MWPM and NN: 123.04719101123595\n",
      "X^2 for PLUT and NN: 415.5077793493635\n",
      "> AUC for class X52: 0.9975224457954582 (+- 0.0001263402564001928)\n",
      "X^2 for MWPM and NN: 120.96107784431138\n",
      "X^2 for PLUT and NN: 475.47982062780267\n",
      "> AUC for class X53: 0.997981120105022 (+- 0.00014095542723804457)\n",
      "X^2 for MWPM and NN: 77.29779411764706\n",
      "X^2 for PLUT and NN: 481.86156111929307\n",
      "> AUC for class X54: 0.9976412303290743 (+- 7.836950948851268e-05)\n",
      "X^2 for MWPM and NN: 81.2274368231047\n",
      "X^2 for PLUT and NN: 479.3818722139673\n",
      "> AUC for class X55: 0.9971784848775732 (+- 0.00011001406629150249)\n",
      "X^2 for MWPM and NN: 169.2188940092166\n",
      "X^2 for PLUT and NN: 412.90214477211794\n",
      "> AUC for class X56: 0.980416337765388 (+- 0.0004136730570079822)\n",
      "X^2 for MWPM and NN: 80.18210361067504\n",
      "X^2 for PLUT and NN: 148.29918699186993\n",
      "> AUC for class X60: 0.9802618250378808 (+- 0.00038465325108545174)\n",
      "X^2 for MWPM and NN: 108.25760286225403\n",
      "X^2 for PLUT and NN: 183.37673611111111\n",
      "> AUC for class X61: 0.9981798960970306 (+- 0.00017220256394014625)\n",
      "X^2 for MWPM and NN: 80.86124401913875\n",
      "X^2 for PLUT and NN: 541.6302765647744\n",
      "> AUC for class X62: 0.9987597510159233 (+- 6.418255727701328e-05)\n",
      "X^2 for MWPM and NN: 2.1512605042016806\n",
      "X^2 for PLUT and NN: 479.88587731811697\n",
      "> AUC for class X63: 0.9987338544064635 (+- 7.847686828874334e-05)\n",
      "X^2 for MWPM and NN: 37.528169014084504\n",
      "X^2 for PLUT and NN: 518.5013888888889\n",
      "> AUC for class X64: 0.9985616374830485 (+- 9.395887758661698e-05)\n",
      "X^2 for MWPM and NN: 41.00625\n",
      "X^2 for PLUT and NN: 483.3686440677966\n",
      "> AUC for class X65: 0.9976165062310255 (+- 0.00010768916013223665)\n",
      "X^2 for MWPM and NN: 30.896039603960396\n",
      "X^2 for PLUT and NN: 499.88616714697406\n",
      "> AUC for class X66: 0.9931550914999511 (+- 0.0002756702601545991)\n",
      "X^2 for MWPM and NN: 30.222627737226276\n",
      "X^2 for PLUT and NN: 308.91642228739005\n",
      "> AUC for class Z00: 0.9737049269788537 (+- 0.0002974777427702566)\n",
      "X^2 for MWPM and NN: 492.28472702142363\n",
      "X^2 for PLUT and NN: 20.991166077738516\n",
      "> AUC for class Z01: 0.9746470098961106 (+- 0.0008503855291518433)\n",
      "X^2 for MWPM and NN: 115.41323792486583\n",
      "X^2 for PLUT and NN: 227.777950310559\n",
      "> AUC for class Z02: 0.9767790802037525 (+- 0.00047532664002989484)\n",
      "X^2 for MWPM and NN: 358.7347094801223\n",
      "X^2 for PLUT and NN: 184.01512287334594\n",
      "> AUC for class Z03: 0.9774785804745171 (+- 0.00043086455750648687)\n",
      "X^2 for MWPM and NN: 181.70934959349594\n",
      "X^2 for PLUT and NN: 270.4835766423358\n",
      "> AUC for class Z04: 0.9770327465058145 (+- 0.0007637189005145421)\n",
      "X^2 for MWPM and NN: 325.547976011994\n",
      "X^2 for PLUT and NN: 222.2091743119266\n",
      "> AUC for class Z05: 0.9776267609607444 (+- 0.0005216970625019921)\n",
      "X^2 for MWPM and NN: 138.16008771929825\n",
      "X^2 for PLUT and NN: 226.22309197651663\n",
      "> AUC for class Z06: 0.9919965374652114 (+- 0.00037206985985865546)\n",
      "X^2 for MWPM and NN: 0.6736526946107785\n",
      "X^2 for PLUT and NN: 311.0244299674267\n",
      "> AUC for class Z10: 0.9975401103371414 (+- 0.00015942730843055393)\n",
      "X^2 for MWPM and NN: 108.35380835380835\n",
      "X^2 for PLUT and NN: 449.40562913907286\n",
      "> AUC for class Z11: 0.9952449419127095 (+- 0.00042524239718930195)\n",
      "X^2 for MWPM and NN: 211.57167530224524\n",
      "X^2 for PLUT and NN: 396.4116743471582\n",
      "> AUC for class Z12: 0.9957303143939974 (+- 0.00020453320068757294)\n",
      "X^2 for MWPM and NN: 116.34624145785877\n",
      "X^2 for PLUT and NN: 443.68215892053973\n",
      "> AUC for class Z13: 0.9959218319326304 (+- 0.0003971990896498716)\n",
      "X^2 for MWPM and NN: 184.66129032258064\n",
      "X^2 for PLUT and NN: 387.01323529411764\n",
      "> AUC for class Z14: 0.99599557858691 (+- 0.00010060537559325051)\n",
      "X^2 for MWPM and NN: 150.04960317460316\n",
      "X^2 for PLUT and NN: 409.3974540311174\n",
      "> AUC for class Z15: 0.9960738290048026 (+- 0.0002840509961858471)\n",
      "X^2 for MWPM and NN: 172.13359528487229\n",
      "X^2 for PLUT and NN: 435.3418439716312\n",
      "> AUC for class Z16: 0.9971594689806543 (+- 0.0001991112018200803)\n",
      "X^2 for MWPM and NN: 9.089201877934272\n",
      "X^2 for PLUT and NN: 490.9732016925247\n",
      "> AUC for class Z20: 0.9981568373388411 (+- 0.00017907090587737705)\n",
      "X^2 for MWPM and NN: 44.240196078431374\n",
      "X^2 for PLUT and NN: 463.63297045101086\n",
      "> AUC for class Z21: 0.9968176244657849 (+- 0.00021898579368164852)\n",
      "X^2 for MWPM and NN: 42.13120567375886\n",
      "X^2 for PLUT and NN: 430.20251396648047\n",
      "> AUC for class Z22: 0.9964592884114394 (+- 0.0003656272067924927)\n",
      "X^2 for MWPM and NN: 122.97692307692307\n",
      "X^2 for PLUT and NN: 410.7111853088481\n",
      "> AUC for class Z23: 0.9966664675848814 (+- 0.00025209105360076567)\n",
      "X^2 for MWPM and NN: 116.1892523364486\n",
      "X^2 for PLUT and NN: 473.40888208269524\n",
      "> AUC for class Z24: 0.9963317585419732 (+- 0.0001061419312527859)\n",
      "X^2 for MWPM and NN: 68.09116022099448\n",
      "X^2 for PLUT and NN: 429.6964006259781\n",
      "> AUC for class Z25: 0.99668919123842 (+- 0.00019259924116076668)\n",
      "X^2 for MWPM and NN: 28.77821011673152\n",
      "X^2 for PLUT and NN: 428.19383259911893\n",
      "> AUC for class Z26: 0.9981275890138811 (+- 0.00013311155779415163)\n",
      "X^2 for MWPM and NN: 35.361607142857146\n",
      "X^2 for PLUT and NN: 471.53130016051364\n",
      "> AUC for class Z30: 0.9981758383447019 (+- 0.0002518767457829254)\n",
      "X^2 for MWPM and NN: 32.18250950570342\n",
      "X^2 for PLUT and NN: 513.3928571428571\n",
      "> AUC for class Z31: 0.9971302789442076 (+- 0.00016641292138464835)\n",
      "X^2 for MWPM and NN: 66.55673758865248\n",
      "X^2 for PLUT and NN: 497.23520249221184\n",
      "> AUC for class Z32: 0.9964458847010961 (+- 0.0002475958761515828)\n",
      "X^2 for MWPM and NN: 86.84307692307692\n",
      "X^2 for PLUT and NN: 493.8476499189627\n",
      "> AUC for class Z33: 0.9964162712465741 (+- 0.0002930934384901463)\n",
      "X^2 for MWPM and NN: 43.72945205479452\n",
      "X^2 for PLUT and NN: 416.32055214723925\n",
      "> AUC for class Z34: 0.9961923403733524 (+- 0.0003410464187767008)\n",
      "X^2 for MWPM and NN: 42.45614035087719\n",
      "X^2 for PLUT and NN: 420.0254372019078\n",
      "> AUC for class Z35: 0.9970596107058395 (+- 0.00026258073344668836)\n",
      "X^2 for MWPM and NN: 59.43214285714286\n",
      "X^2 for PLUT and NN: 497.1093990755008\n",
      "> AUC for class Z36: 0.9982221336888654 (+- 0.00015513408767855023)\n",
      "X^2 for MWPM and NN: 10.50625\n",
      "X^2 for PLUT and NN: 510.85537190082647\n",
      "> AUC for class Z40: 0.9981343205102883 (+- 0.00022305686235154593)\n",
      "X^2 for MWPM and NN: 48.06130268199234\n",
      "X^2 for PLUT and NN: 524.8849693251534\n",
      "> AUC for class Z41: 0.99679717143658 (+- 0.00042220582005678603)\n",
      "X^2 for MWPM and NN: 78.02777777777777\n",
      "X^2 for PLUT and NN: 457.39721792890265\n",
      "> AUC for class Z42: 0.9963800557382944 (+- 5.243277194789775e-05)\n",
      "X^2 for MWPM and NN: 101.55371900826447\n",
      "X^2 for PLUT and NN: 494.45575221238937\n",
      "> AUC for class Z43: 0.9965286703804646 (+- 5.1230296617296774e-05)\n",
      "X^2 for MWPM and NN: 96.85230024213075\n",
      "X^2 for PLUT and NN: 472.60940032414914\n",
      "> AUC for class Z44: 0.9962487782411508 (+- 0.0001906764592184454)\n",
      "X^2 for MWPM and NN: 74.79585798816568\n",
      "X^2 for PLUT and NN: 400.9183381088825\n",
      "> AUC for class Z45: 0.9967134190540552 (+- 0.0002639650037015462)\n",
      "X^2 for MWPM and NN: 75.87841945288754\n",
      "X^2 for PLUT and NN: 422.7514880952381\n",
      "> AUC for class Z46: 0.9980069571186413 (+- 7.956844896414846e-05)\n",
      "X^2 for MWPM and NN: 2.9719101123595504\n",
      "X^2 for PLUT and NN: 514.6314243759177\n",
      "> AUC for class Z50: 0.997102952286519 (+- 0.0003435945437056253)\n",
      "X^2 for MWPM and NN: 213.03762376237623\n",
      "X^2 for PLUT and NN: 446.9553846153846\n",
      "> AUC for class Z51: 0.9959051857642022 (+- 0.0004746373447849767)\n",
      "X^2 for MWPM and NN: 67.2429022082019\n",
      "X^2 for PLUT and NN: 454.7758064516129\n",
      "> AUC for class Z52: 0.9957844630428508 (+- 0.0001950212572795427)\n",
      "X^2 for MWPM and NN: 203.04063604240284\n",
      "X^2 for PLUT and NN: 422.7514880952381\n",
      "> AUC for class Z53: 0.9957060187582384 (+- 0.00029051428037600276)\n",
      "X^2 for MWPM and NN: 124.8984375\n",
      "X^2 for PLUT and NN: 407.8303425774878\n",
      "> AUC for class Z54: 0.9954345305436881 (+- 0.0002594826621572507)\n",
      "X^2 for MWPM and NN: 229.97262773722628\n",
      "X^2 for PLUT and NN: 406.15352112676055\n",
      "> AUC for class Z55: 0.9954715527822465 (+- 0.0005030152977551174)\n",
      "X^2 for MWPM and NN: 133.28\n",
      "X^2 for PLUT and NN: 439.22491909385116\n",
      "> AUC for class Z56: 0.9977613259309485 (+- 3.52938821794975e-05)\n",
      "X^2 for MWPM and NN: 56.91699604743083\n",
      "X^2 for PLUT and NN: 506.40634441087616\n",
      "> AUC for class Z60: 0.9921892377526959 (+- 0.0009063308245144203)\n",
      "X^2 for MWPM and NN: 196.5781512605042\n",
      "X^2 for PLUT and NN: 284.9774096385542\n",
      "> AUC for class Z61: 0.9765189473591654 (+- 0.0004960206653482908)\n",
      "X^2 for MWPM and NN: 384.14443625644805\n",
      "X^2 for PLUT and NN: 277.62455516014234\n",
      "> AUC for class Z62: 0.9766488459945867 (+- 0.0011627513088625805)\n",
      "X^2 for MWPM and NN: 126.50778210116732\n",
      "X^2 for PLUT and NN: 214.61284403669725\n",
      "> AUC for class Z63: 0.9771883311782347 (+- 0.00034796110601017024)\n",
      "X^2 for MWPM and NN: 405.9362519201229\n",
      "X^2 for PLUT and NN: 244.92753623188406\n",
      "> AUC for class Z64: 0.9777157330566261 (+- 0.0005383076363242412)\n",
      "X^2 for MWPM and NN: 76.03575989782887\n",
      "X^2 for PLUT and NN: 120.1757493188011\n",
      "> AUC for class Z65: 0.9772084041496104 (+- 0.0004338425724580213)\n",
      "X^2 for MWPM and NN: 318.26780415430267\n",
      "X^2 for PLUT and NN: 181.88277087033748\n",
      "> AUC for class Z66: 0.9785580276765041 (+- 0.0006827469313093384)\n",
      "X^2 for MWPM and NN: 100.48615916955018\n",
      "X^2 for PLUT and NN: 178.94010889292196\n",
      "###################################################################################\n",
      "TOTAL F1 NN: [0.8216187116337902, 0.8204544989477296, 0.8221997256004157]\n",
      "TOTAL F1 PLUT: [0.21766525375186158, 0.2178357619582105, 0.21685313517575353]\n",
      "TOTAL F1 MWPM: [0.6999577702702703, 0.6984095334162189, 0.6985232475656156]\n",
      "TOTAL ACC NN: [0.9866034388542175, 0.986399233341217, 0.9865171717171654]\n",
      "TOTAL ACC PLUT: [0.9621289938698115, 0.9621443935241187, 0.962102020201907]\n",
      "TOTAL ACC MWPM: [0.9741636363636537, 0.9740272727272915, 0.9740277777777931]\n",
      "TOTAL TIME NN: [5.7770827, 5.9821905, 6.0375564]\n",
      "TOTAL TIME PLUT: [5.4490014, 5.1532726, 5.5817349]\n",
      "TOTAL TIME MWPM: [3258.326625199987, 3391.5704181000146, 3283.0450279999905]\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "inputs = x_d7.copy()\n",
    "inputs = np.array(inputs)\n",
    "inputs = np.stack(inputs)\n",
    "targets = np.array(y_d7)\n",
    "targets = np.array([np.array(xi) for xi in targets])\n",
    "\n",
    "n_classes = 99\n",
    "\n",
    "acc_per_fold = []\n",
    "f1_per_fold = []\n",
    "time_per_fold = []\n",
    "\n",
    "acc_per_fold_plut = []\n",
    "f1_per_fold_plut = []\n",
    "time_per_fold_plut = []\n",
    "\n",
    "acc_per_fold_mwpm = []\n",
    "f1_per_fold_mwpm = []\n",
    "time_per_fold_mwpm = []\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "aucs_classes = {}\n",
    "for i in mlb_d7.classes_:\n",
    "    aucs_classes[i] = []\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for i, (train, test) in enumerate(kfold.split(inputs, targets)):\n",
    "    i_train = inputs[train].copy()\n",
    "    i_test = inputs[test].copy()\n",
    "    t_test = targets[test].copy()\n",
    "    x_test_d7 = i_test[:,:2]\n",
    "    inputs_train = i_train[:,3:]\n",
    "    inputs_test = i_test[:,3:]\n",
    "    indices = np.random.choice(inputs[test].shape[0], 20000, replace=False)\n",
    "    x_test_d7 = x_test_d7[indices]\n",
    "    inputs_test_2 = inputs_test[indices]\n",
    "    targets_test_2 = targets[test][indices]\n",
    "    ####################################################################################################\n",
    "    #test MWPM decoder for this fold\n",
    "    #labels = targets[train], features = inputs[train]\n",
    "   # x_test_d7 = translate_to_graph(testData_d7_MWPM, targs, mlb_d7)\n",
    "    decoding_d7, time_mwpm = do_new_decoding(x_test_d7, 7, 0)\n",
    "    decoding_d7['combine'] = decoding_d7[[0, 1]].values.tolist()\n",
    "    decoding_d7['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "    decoding_d7 = np.array(decoding_d7[0])\n",
    "                                              \n",
    "    time_per_fold_mwpm.append(time_mwpm)\n",
    "                                              \n",
    "    pred_mwpm = mlb_d7.transform(decoding_d7)\n",
    "\n",
    "    if fold_no < 3:\n",
    "        acc = partial_accuracy(targets_test_2, pred_mwpm)\n",
    "    else:\n",
    "        acc, contingency_mwpm = partial_accuracy_and_contingency(targets_test_2, pred_mwpm, mlb_d7)\n",
    "        \n",
    "    acc_per_fold_mwpm.append(acc)\n",
    "    f1_per_fold_mwpm.append(f1_score(targets_test_2, pred_mwpm, average='micro'))\n",
    "\n",
    "    #####################################################################################################\n",
    "    #test the plut decoder for this fold\n",
    "    \n",
    "    lookup_d7 = lookup_decoder(7)\n",
    "    \n",
    "    lookup_d7 = train_plut(lookup_d7, inputs_train, targets[train])\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    pred_plut_d7 = test_plut(lookup_d7, inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    if fold_no < 3:\n",
    "        acc = partial_accuracy(targets[test], pred_plut_d7)\n",
    "        f1 = f1_score(targets[test], pred_plut_d7, average='micro')\n",
    "    else:\n",
    "        pred_plut_d7 = test_plut(lookup_d7, inputs_test_2)\n",
    "        f1 = f1_score(targets_test_2, pred_plut_d7, average='micro')\n",
    "        acc, contingency_plut = partial_accuracy_and_contingency(targets_test_2, pred_plut_d7, mlb_d7)\n",
    "        \n",
    "    acc_per_fold_plut.append(acc)\n",
    "    f1_per_fold_plut.append(f1)\n",
    "    \n",
    "    #####################################################################################################\n",
    "    #Test the NN decoder for this fold\n",
    "    \n",
    "    model_d7 = compile_FFNN_model_DepthSeven(7)\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = model_d7.fit(\n",
    "        x=inputs_train ,\n",
    "        y=targets[train],\n",
    "        validation_split=.25,\n",
    "        epochs= 150)\n",
    "    \n",
    "   # Generate generalization metrics\n",
    "    scores = model_d7.evaluate(inputs_test, targets[test], verbose=0)\n",
    "    \n",
    "    start = time.time_ns()\n",
    "    predictions_d7 = model_d7.predict(inputs_test)\n",
    "    end = time.time_ns() \n",
    "    time_per_fold.append((end - start)/ (10 ** 9))\n",
    "    \n",
    "    #threshold based on previous tests with train_test_split in hyperparameter tuning\n",
    "    pred=predictions_d7.copy() #change here\n",
    "    pred[pred>=.5]=1 \n",
    "    pred[pred<.5]=0\n",
    "     \n",
    "    if fold_no < 3:\n",
    "        acc = scores[1]\n",
    "        f1 = f1_score(targets[test], pred, average='micro')\n",
    "    else:\n",
    "        pred = model_d7.predict(inputs_test_2)\n",
    "        pred[pred>=.5]=1 \n",
    "        pred[pred<.5]=0\n",
    "        acc, contingency_nn = partial_accuracy_and_contingency(targets_test_2, pred, mlb_d7)\n",
    "        f1 = f1_score(targets_test_2, pred, average='micro')\n",
    " \n",
    "    acc_per_fold.append(acc)\n",
    "    f1_per_fold.append(f1)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d7.ravel())\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    \n",
    "    #get the AUCs of each class, used to get average AUC of each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d7[:, i]) \n",
    "        aucs_classes[mlb_d7.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "\n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb_d7.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 7 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL F1 NN: [0.7466026170895966, 0.7447298695420905, 0.7449999416902822]\n",
      "TOTAL F1 PLUT: [0.07436437291975014, 0.07319961646740877, 0.07392483964771193]\n",
      "TOTAL F1 MWPM: [0.5570304203885315, 0.5576631378129446, 0.5564358397963814]\n",
      "TOTAL ACC NN: [0.9817760586738586, 0.9817712903022766, 0.9817626262626084]\n",
      "TOTAL ACC PLUT: [0.960282959944449, 0.960287018882497, 0.9603099766722879]\n",
      "TOTAL ACC MWPM: [0.9570212121211669, 0.9571409090908701, 0.9570479797979491]\n",
      "TOTAL TIME NN: [13.6240815, 12.273374, 11.9565955]\n",
      "TOTAL TIME PLUT: [27.279464, 16.1340635, 5.2510398]\n",
      "TOTAL TIME MWPM: [4881.778657700013, 9217.311648799974, 3500.318302099989]\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test MWPM decoder for this fold\n",
    "#labels = targets[train], features = inputs[train]\n",
    "# x_test_d7 = translate_to_graph(testData_d7_MWPM, targs, mlb_d7)\n",
    "\"\"\"\n",
    "decoding_d7, time_mwpm = do_new_decoding(x_test_d7, 7, 0)\n",
    "decoding_d7['combine'] = decoding_d7[[0, 1]].values.tolist()\n",
    "decoding_d7['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "decoding_d7 = np.array(decoding_d7[0])\n",
    "\n",
    "time_per_fold_mwpm.append(time_mwpm)\n",
    "\n",
    "pred_mwpm = mlb_d7.transform(decoding_d7)\n",
    "\n",
    "if fold_no < 3:\n",
    "    acc = partial_accuracy(targets_test_2, pred_mwpm)\n",
    "else:\n",
    "    acc, contingency_mwpm = partial_accuracy_and_contingency(targets_test_2, pred_mwpm, mlb_d7)\"\"\"\n",
    "\n",
    "#acc_per_fold_mwpm.append(acc)\n",
    "#f1_per_fold_mwpm.append(f1_score(targets_test_2, pred_mwpm, average='micro'))\n",
    "\n",
    "#####################################################################################################\n",
    "#test the plut decoder for this fold\n",
    "\n",
    "#lookup_d7 = lookup_decoder(7)\n",
    "\n",
    "#lookup_d7 = train_plut(lookup_d7, inputs_train, targets[train])\n",
    "\n",
    "#start = time.time_ns()\n",
    "#pred_plut_d7 = test_plut(lookup_d7, inputs_test)\n",
    "#end = time.time_ns() \n",
    "#time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "\n",
    "pred_plut_d7 = test_plut(lookup_d7, inputs_test_2)\n",
    "#f1 = f1_score(targets_test_2, pred_plut_d7, average='micro')\n",
    "acc, contingency_plut = partial_accuracy_and_contingency(targets_test_2, pred_plut_d7, mlb_d7)\n",
    "\n",
    "#acc_per_fold_plut.append(acc)\n",
    "#f1_per_fold_plut.append(f1)\n",
    "\n",
    "#####################################################################################################\n",
    "#Test the NN decoder for this fold\n",
    "\"\"\"\n",
    "model_d7 = compile_FFNN_model_DepthSeven(7)\n",
    "\n",
    "# Generate a print\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "# Fit data to model\n",
    "history = model_d7.fit(\n",
    "    x=inputs_train ,\n",
    "    y=targets[train],\n",
    "    validation_split=.25,\n",
    "    epochs= 150)\"\"\"\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d7.ravel())\n",
    "tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "tprs[-1][0] = 0.0\n",
    "roc_auc = auc(fpr, tpr)\n",
    "aucs.append(roc_auc)\n",
    "plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "#get the AUCs of each class, used to get average AUC of each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d7[:, i]) \n",
    "    aucs_classes[mlb_d7.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "\n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb_d7.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 7 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clair\\Anaconda3\\envs\\CNNs\\lib\\site-packages\\ipykernel_launcher.py:74: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
      "C:\\Users\\clair\\Anaconda3\\envs\\CNNs\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20000, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[20000, 0]\n",
      "[0, 0]\n",
      "both b and c are zero\n",
      "[18054, 1145]\n",
      "[621, 180]\n",
      "[19047, 152]\n",
      "[21, 780]\n",
      "[18626, 796]\n",
      "[335, 243]\n",
      "[19002, 420]\n",
      "[148, 430]\n",
      "[19287, 478]\n",
      "[115, 120]\n",
      "[19151, 614]\n",
      "[90, 145]\n",
      "[19477, 295]\n",
      "[89, 139]\n",
      "[19136, 636]\n",
      "[59, 169]\n",
      "[19293, 487]\n",
      "[99, 121]\n",
      "[19111, 669]\n",
      "[85, 135]\n",
      "[19112, 663]\n",
      "[87, 138]\n",
      "[19133, 642]\n",
      "[99, 126]\n",
      "[17479, 1895]\n",
      "[365, 261]\n",
      "[19026, 348]\n",
      "[115, 511]\n",
      "[17995, 1396]\n",
      "[309, 300]\n",
      "[19020, 371]\n",
      "[105, 504]\n",
      "[19027, 641]\n",
      "[145, 187]\n",
      "[19091, 577]\n",
      "[106, 226]\n",
      "[19194, 507]\n",
      "[138, 161]\n",
      "[19105, 596]\n",
      "[119, 180]\n",
      "[19288, 449]\n",
      "[97, 166]\n",
      "[19101, 636]\n",
      "[140, 123]\n",
      "[19404, 347]\n",
      "[94, 155]\n",
      "[19098, 653]\n",
      "[123, 126]\n",
      "[18949, 761]\n",
      "[133, 157]\n",
      "[19085, 625]\n",
      "[136, 154]\n",
      "[19090, 284]\n",
      "[76, 550]\n",
      "[19053, 321]\n",
      "[82, 544]\n",
      "[19066, 339]\n",
      "[87, 508]\n",
      "[19007, 398]\n",
      "[91, 504]\n",
      "[18783, 938]\n",
      "[119, 160]\n",
      "[19113, 608]\n",
      "[95, 184]\n",
      "[19198, 514]\n",
      "[116, 172]\n",
      "[19068, 644]\n",
      "[150, 138]\n",
      "[19176, 549]\n",
      "[109, 166]\n",
      "[19082, 643]\n",
      "[87, 188]\n",
      "[19093, 654]\n",
      "[130, 123]\n",
      "[19165, 582]\n",
      "[80, 173]\n",
      "[19201, 515]\n",
      "[115, 169]\n",
      "[19101, 615]\n",
      "[105, 179]\n",
      "[18018, 1404]\n",
      "[303, 275]\n",
      "[19056, 366]\n",
      "[86, 492]\n",
      "[18054, 1371]\n",
      "[268, 307]\n",
      "[19018, 407]\n",
      "[146, 429]\n",
      "[18955, 754]\n",
      "[134, 157]\n",
      "[19076, 633]\n",
      "[143, 148]\n",
      "[19138, 616]\n",
      "[102, 144]\n",
      "[19126, 628]\n",
      "[99, 147]\n",
      "[19235, 467]\n",
      "[103, 195]\n",
      "[19081, 621]\n",
      "[101, 197]\n",
      "[19199, 505]\n",
      "[109, 187]\n",
      "[19062, 642]\n",
      "[110, 186]\n",
      "[18978, 758]\n",
      "[105, 159]\n",
      "[19109, 627]\n",
      "[87, 177]\n",
      "[19059, 368]\n",
      "[126, 447]\n",
      "[19026, 401]\n",
      "[126, 447]\n",
      "[19082, 366]\n",
      "[121, 431]\n",
      "[19065, 383]\n",
      "[112, 440]\n",
      "[18751, 977]\n",
      "[135, 137]\n",
      "[19176, 552]\n",
      "[113, 159]\n",
      "[19273, 442]\n",
      "[100, 185]\n",
      "[19050, 665]\n",
      "[115, 170]\n",
      "[19152, 552]\n",
      "[123, 173]\n",
      "[19096, 608]\n",
      "[86, 210]\n",
      "[19089, 640]\n",
      "[107, 164]\n",
      "[19114, 615]\n",
      "[113, 158]\n",
      "[19167, 533]\n",
      "[109, 191]\n",
      "[19090, 610]\n",
      "[126, 174]\n",
      "[17906, 1526]\n",
      "[278, 290]\n",
      "[19072, 360]\n",
      "[128, 440]\n",
      "[18017, 1365]\n",
      "[287, 331]\n",
      "[18973, 409]\n",
      "[206, 412]\n",
      "[19089, 614]\n",
      "[114, 183]\n",
      "[19076, 627]\n",
      "[99, 198]\n",
      "[19137, 570]\n",
      "[127, 166]\n",
      "[19024, 683]\n",
      "[183, 110]\n",
      "[19294, 448]\n",
      "[85, 173]\n",
      "[19149, 593]\n",
      "[89, 169]\n",
      "[19278, 447]\n",
      "[120, 155]\n",
      "[19106, 619]\n",
      "[87, 188]\n",
      "[18967, 748]\n",
      "[106, 179]\n",
      "[19117, 598]\n",
      "[72, 213]\n",
      "[19088, 337]\n",
      "[124, 451]\n",
      "[19077, 348]\n",
      "[127, 448]\n",
      "[19138, 255]\n",
      "[65, 542]\n",
      "[19101, 292]\n",
      "[69, 538]\n",
      "[19286, 480]\n",
      "[100, 134]\n",
      "[19163, 603]\n",
      "[78, 156]\n",
      "[19637, 133]\n",
      "[75, 155]\n",
      "[19094, 676]\n",
      "[82, 148]\n",
      "[19461, 318]\n",
      "[89, 132]\n",
      "[19142, 637]\n",
      "[83, 138]\n",
      "[19471, 297]\n",
      "[80, 152]\n",
      "[19141, 627]\n",
      "[59, 173]\n",
      "[19463, 281]\n",
      "[114, 142]\n",
      "[19099, 645]\n",
      "[113, 143]\n",
      "[18995, 479]\n",
      "[254, 272]\n",
      "[19025, 449]\n",
      "[140, 386]\n",
      "[17303, 1894]\n",
      "[474, 329]\n",
      "[19039, 158]\n",
      "[143, 660]\n",
      "[19076, 272]\n",
      "[54, 598]\n",
      "[19021, 327]\n",
      "[68, 584]\n",
      "[18011, 1418]\n",
      "[292, 279]\n",
      "[19121, 308]\n",
      "[55, 516]\n",
      "[19110, 296]\n",
      "[57, 537]\n",
      "[19082, 324]\n",
      "[66, 528]\n",
      "[17807, 1599]\n",
      "[317, 277]\n",
      "[19058, 348]\n",
      "[79, 515]\n",
      "[19161, 263]\n",
      "[24, 552]\n",
      "[19108, 316]\n",
      "[36, 540]\n",
      "[19065, 429]\n",
      "[230, 276]\n",
      "[19045, 449]\n",
      "[167, 339]\n",
      "[18994, 715]\n",
      "[153, 138]\n",
      "[19081, 628]\n",
      "[108, 183]\n",
      "[18817, 874]\n",
      "[148, 161]\n",
      "[19099, 592]\n",
      "[104, 205]\n",
      "[19184, 537]\n",
      "[108, 171]\n",
      "[19175, 546]\n",
      "[87, 192]\n",
      "[18903, 805]\n",
      "[129, 163]\n",
      "[19111, 597]\n",
      "[106, 186]\n",
      "[18916, 761]\n",
      "[151, 172]\n",
      "[19089, 588]\n",
      "[134, 189]\n",
      "[18781, 919]\n",
      "[130, 170]\n",
      "[19107, 593]\n",
      "[110, 190]\n",
      "[19461, 267]\n",
      "[102, 170]\n",
      "[19142, 586]\n",
      "[85, 187]\n",
      "[19380, 349]\n",
      "[121, 150]\n",
      "[19066, 663]\n",
      "[124, 147]\n",
      "[19278, 441]\n",
      "[101, 180]\n",
      "[19095, 624]\n",
      "[104, 177]\n",
      "[19027, 706]\n",
      "[128, 139]\n",
      "[19099, 634]\n",
      "[140, 127]\n",
      "[18998, 721]\n",
      "[136, 145]\n",
      "[19082, 637]\n",
      "[65, 216]\n",
      "[19091, 591]\n",
      "[154, 164]\n",
      "[19147, 535]\n",
      "[68, 250]\n",
      "[19329, 399]\n",
      "[126, 146]\n",
      "[19175, 553]\n",
      "[77, 195]\n",
      "[19331, 420]\n",
      "[122, 127]\n",
      "[19179, 572]\n",
      "[66, 183]\n",
      "[19303, 475]\n",
      "[112, 110]\n",
      "[19159, 619]\n",
      "[74, 148]\n",
      "[19231, 497]\n",
      "[99, 173]\n",
      "[19147, 581]\n",
      "[57, 215]\n",
      "[19288, 409]\n",
      "[112, 191]\n",
      "[19088, 609]\n",
      "[119, 184]\n",
      "[19287, 441]\n",
      "[96, 176]\n",
      "[19104, 624]\n",
      "[85, 187]\n",
      "[19201, 498]\n",
      "[136, 165]\n",
      "[19080, 619]\n",
      "[93, 208]\n",
      "[19208, 510]\n",
      "[127, 155]\n",
      "[19100, 618]\n",
      "[88, 194]\n",
      "[19532, 212]\n",
      "[104, 152]\n",
      "[19125, 619]\n",
      "[61, 195]\n",
      "[19367, 411]\n",
      "[102, 120]\n",
      "[19162, 616]\n",
      "[59, 163]\n",
      "[19243, 459]\n",
      "[132, 166]\n",
      "[19167, 535]\n",
      "[93, 205]\n",
      "[19116, 608]\n",
      "[127, 149]\n",
      "[19103, 621]\n",
      "[93, 183]\n",
      "[19073, 666]\n",
      "[119, 142]\n",
      "[19146, 593]\n",
      "[74, 187]\n",
      "[19229, 503]\n",
      "[98, 170]\n",
      "[19114, 618]\n",
      "[88, 180]\n",
      "[19257, 470]\n",
      "[120, 153]\n",
      "[19138, 589]\n",
      "[83, 190]\n",
      "[19483, 259]\n",
      "[110, 148]\n",
      "[19167, 575]\n",
      "[86, 172]\n",
      "[18980, 795]\n",
      "[129, 96]\n",
      "[19148, 627]\n",
      "[87, 138]\n",
      "[19295, 414]\n",
      "[89, 202]\n",
      "[19131, 578]\n",
      "[81, 210]\n",
      "[18940, 769]\n",
      "[128, 163]\n",
      "[19132, 577]\n",
      "[102, 189]\n",
      "[19168, 545]\n",
      "[114, 173]\n",
      "[19174, 539]\n",
      "[119, 168]\n",
      "[18904, 783]\n",
      "[131, 182]\n",
      "[19072, 615]\n",
      "[123, 190]\n",
      "[19154, 519]\n",
      "[121, 206]\n",
      "[19096, 577]\n",
      "[98, 229]\n",
      "[19286, 443]\n",
      "[96, 175]\n",
      "[19139, 590]\n",
      "[119, 152]\n",
      "[18527, 999]\n",
      "[267, 207]\n",
      "[19109, 417]\n",
      "[123, 351]\n",
      "[18052, 1404]\n",
      "[283, 261]\n",
      "[19116, 340]\n",
      "[64, 480]\n",
      "[19135, 314]\n",
      "[37, 514]\n",
      "[19119, 330]\n",
      "[43, 508]\n",
      "[18009, 1437]\n",
      "[286, 268]\n",
      "[19133, 313]\n",
      "[57, 497]\n",
      "[19163, 260]\n",
      "[26, 551]\n",
      "[19127, 296]\n",
      "[35, 542]\n",
      "[17896, 1492]\n",
      "[335, 277]\n",
      "[19096, 292]\n",
      "[90, 522]\n",
      "[19132, 267]\n",
      "[69, 532]\n",
      "[19092, 307]\n",
      "[75, 526]\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds of MWPM:\n",
      "> Accuracy: 0.9570700336699954 (+- 5.129406134054286e-05)\n",
      "> F1: 0.5570431326659525(+- 0.0005011229435730007)\n",
      "> Time: 5708.04626292499 (+- 2127.064047847968)\n",
      "Average scores for all folds of PLUT:\n",
      "> Accuracy: 0.9602933184997448 (+- 1.1895090832780539e-05)\n",
      "> F1: 0.07382960967829029(+- 0.000480254070692271)\n",
      "> Time: 16.221522433333334 (+- 8.993279156590631)\n",
      "Average scores for all folds of NN:\n",
      "> Accuracy: 0.9817699917462478 (+- 5.5601021464884325e-06)\n",
      "> F1: 0.7454087193138745(+- 0.0007184395330878576)\n",
      "> Time: 12.618017 (+- 0.7230543954345114)\n",
      "> AUC for class : 0.9833169021151996 (+- 0.0)\n",
      "X^2 for MWPM and NN: 0\n",
      "X^2 for PLUT and NN: 0\n",
      "> AUC for class X00: 0.8214824191454625 (+- 0.0025965188951278424)\n",
      "X^2 for MWPM and NN: 154.88618346545866\n",
      "X^2 for PLUT and NN: 97.6878612716763\n",
      "> AUC for class X01: 0.9659140492205993 (+- 0.0013856368529444657)\n",
      "X^2 for MWPM and NN: 187.09106984969054\n",
      "X^2 for PLUT and NN: 129.29753521126761\n",
      "> AUC for class X02: 0.9941481185545963 (+- 0.00018517768896231514)\n",
      "X^2 for MWPM and NN: 220.9848229342327\n",
      "X^2 for PLUT and NN: 388.5355113636364\n",
      "> AUC for class X03: 0.9948369987791448 (+- 0.00016248593694092892)\n",
      "X^2 for MWPM and NN: 109.44010416666667\n",
      "X^2 for PLUT and NN: 477.37553956834535\n",
      "> AUC for class X04: 0.9950563100344874 (+- 0.00021123204941837263)\n",
      "X^2 for MWPM and NN: 255.57849829351537\n",
      "X^2 for PLUT and NN: 450.7811671087533\n",
      "> AUC for class X05: 0.9937200300930737 (+- 0.0005736280249339026)\n",
      "X^2 for MWPM and NN: 440.8333333333333\n",
      "X^2 for PLUT and NN: 396.442645074224\n",
      "> AUC for class X06: 0.9643083059751663 (+- 0.0007666845909616321)\n",
      "X^2 for MWPM and NN: 1034.4429203539823\n",
      "X^2 for PLUT and NN: 116.25053995680345\n",
      "> AUC for class X10: 0.9638944665277996 (+- 0.0004798839319670582)\n",
      "X^2 for MWPM and NN: 691.7278592375367\n",
      "X^2 for PLUT and NN: 147.53151260504202\n",
      "> AUC for class X11: 0.9893589221952863 (+- 0.00015059111072014743)\n",
      "X^2 for MWPM and NN: 311.73664122137404\n",
      "X^2 for PLUT and NN: 323.4260614934114\n",
      "> AUC for class X12: 0.9913337108417408 (+- 0.0003338436690197651)\n",
      "X^2 for MWPM and NN: 209.9596899224806\n",
      "X^2 for PLUT and NN: 316.8895104895105\n",
      "> AUC for class X13: 0.992870749227103 (+- 0.0004650173267408303)\n",
      "X^2 for MWPM and NN: 225.64285714285714\n",
      "X^2 for PLUT and NN: 315.75386597938143\n",
      "> AUC for class X14: 0.9924938456512202 (+- 0.00044251441583538563)\n",
      "X^2 for MWPM and NN: 144.0\n",
      "X^2 for PLUT and NN: 360.61984536082474\n",
      "> AUC for class X15: 0.9915292718041612 (+- 0.000519549173662067)\n",
      "X^2 for MWPM and NN: 439.741610738255\n",
      "X^2 for PLUT and NN: 312.93561103810777\n",
      "> AUC for class X16: 0.9639277073858591 (+- 0.0010890794911275143)\n",
      "X^2 for MWPM and NN: 119.025\n",
      "X^2 for PLUT and NN: 140.5558312655087\n",
      "> AUC for class X20: 0.9645450711977941 (+- 0.001298706383829854)\n",
      "X^2 for MWPM and NN: 147.88967136150234\n",
      "X^2 for PLUT and NN: 191.48466257668713\n",
      "> AUC for class X21: 0.9911660070676287 (+- 0.000498133071855436)\n",
      "X^2 for MWPM and NN: 633.0406811731315\n",
      "X^2 for PLUT and NN: 372.8933143669986\n",
      "> AUC for class X22: 0.9919101005304631 (+- 7.08320407296451e-05)\n",
      "X^2 for MWPM and NN: 250.17301587301588\n",
      "X^2 for PLUT and NN: 306.10705289672546\n",
      "> AUC for class X23: 0.9924075854809054 (+- 0.0003694914622968242)\n",
      "X^2 for MWPM and NN: 292.8890577507599\n",
      "X^2 for PLUT and NN: 421.95205479452056\n",
      "> AUC for class X24: 0.9917942665664415 (+- 0.0005538642562364193)\n",
      "X^2 for MWPM and NN: 348.8890306122449\n",
      "X^2 for PLUT and NN: 379.15558912386706\n",
      "> AUC for class X25: 0.9912222878230179 (+- 0.0002069275692700141)\n",
      "X^2 for MWPM and NN: 252.7\n",
      "X^2 for PLUT and NN: 359.83472222222224\n",
      "> AUC for class X26: 0.9644859507253847 (+- 0.0014554333050149255)\n",
      "X^2 for MWPM and NN: 708.8459285295841\n",
      "X^2 for PLUT and NN: 172.2146017699115\n",
      "> AUC for class X30: 0.9642839176375231 (+- 0.001296156299046868)\n",
      "X^2 for MWPM and NN: 740.9420378279439\n",
      "X^2 for PLUT and NN: 122.24231464737794\n",
      "> AUC for class X31: 0.991024583720112 (+- 0.00011754990612471821)\n",
      "X^2 for MWPM and NN: 431.4876126126126\n",
      "X^2 for PLUT and NN: 308.14561855670104\n",
      "> AUC for class X32: 0.9920813941482659 (+- 0.0003993664306928)\n",
      "X^2 for MWPM and NN: 366.5306406685237\n",
      "X^2 for PLUT and NN: 383.47180192572216\n",
      "> AUC for class X33: 0.9926187925020055 (+- 0.00014827110898040324)\n",
      "X^2 for MWPM and NN: 231.17368421052632\n",
      "X^2 for PLUT and NN: 373.0761772853186\n",
      "> AUC for class X34: 0.9922919215270747 (+- 0.0004187504634700006)\n",
      "X^2 for MWPM and NN: 254.11237785016286\n",
      "X^2 for PLUT and NN: 374.94813829787233\n",
      "> AUC for class X35: 0.9911107604076475 (+- 5.7442476497794174e-05)\n",
      "X^2 for MWPM and NN: 492.58864426419467\n",
      "X^2 for PLUT and NN: 406.8921568627451\n",
      "> AUC for class X36: 0.9648943008127626 (+- 0.0007933734673146436)\n",
      "X^2 for MWPM and NN: 117.57287449392713\n",
      "X^2 for PLUT and NN: 142.45920303605314\n",
      "> AUC for class X40: 0.9644342142983016 (+- 0.0003615609895865136)\n",
      "X^2 for MWPM and NN: 122.25051334702259\n",
      "X^2 for PLUT and NN: 147.27272727272728\n",
      "> AUC for class X41: 0.9910831063493444 (+- 0.00012056652331653613)\n",
      "X^2 for MWPM and NN: 636.0440647482014\n",
      "X^2 for PLUT and NN: 288.4872180451128\n",
      "> AUC for class X42: 0.9926111666446996 (+- 0.00022953180136432139)\n",
      "X^2 for MWPM and NN: 214.54059040590406\n",
      "X^2 for PLUT and NN: 386.41153846153844\n",
      "> AUC for class X43: 0.9922875857964295 (+- 0.00017198395271088976)\n",
      "X^2 for MWPM and NN: 271.3837037037037\n",
      "X^2 for PLUT and NN: 391.1253602305475\n",
      "> AUC for class X44: 0.9921383209433783 (+- 0.00020143016542978364)\n",
      "X^2 for MWPM and NN: 378.88085676037485\n",
      "X^2 for PLUT and NN: 344.7815934065934\n",
      "> AUC for class X45: 0.9910246183197766 (+- 0.0004849259165691765)\n",
      "X^2 for MWPM and NN: 278.7056074766355\n",
      "X^2 for PLUT and NN: 316.96875\n",
      "> AUC for class X46: 0.9641168101332597 (+- 0.0007289162318493675)\n",
      "X^2 for MWPM and NN: 861.9783813747229\n",
      "X^2 for PLUT and NN: 109.34631147540983\n",
      "> AUC for class X50: 0.9637312314765388 (+- 0.00044174594401776035)\n",
      "X^2 for MWPM and NN: 702.1361985472155\n",
      "X^2 for PLUT and NN: 66.3479674796748\n",
      "> AUC for class X51: 0.9913077295803272 (+- 0.00037321008188926356)\n",
      "X^2 for MWPM and NN: 342.03434065934067\n",
      "X^2 for PLUT and NN: 382.54683195592287\n",
      "> AUC for class X52: 0.9925652901435948 (+- 0.0002513101341999641)\n",
      "X^2 for MWPM and NN: 280.2926829268293\n",
      "X^2 for PLUT and NN: 287.5300230946882\n",
      "> AUC for class X53: 0.9929022147422848 (+- 0.00044414417042450534)\n",
      "X^2 for MWPM and NN: 245.86116322701687\n",
      "X^2 for PLUT and NN: 370.9809384164223\n",
      "> AUC for class X54: 0.9923540377658493 (+- 0.00016355575164228069)\n",
      "X^2 for MWPM and NN: 187.43562610229276\n",
      "X^2 for PLUT and NN: 399.3781869688385\n",
      "> AUC for class X55: 0.9915173078629916 (+- 0.0003779368707950591)\n",
      "X^2 for MWPM and NN: 481.12529274004686\n",
      "X^2 for PLUT and NN: 411.3805970149254\n",
      "> AUC for class X56: 0.9649818907199452 (+- 0.0002708534335919717)\n",
      "X^2 for MWPM and NN: 97.49240780911063\n",
      "X^2 for PLUT and NN: 101.89473684210526\n",
      "> AUC for class X60: 0.9633828630913024 (+- 0.0003393581193685094)\n",
      "X^2 for MWPM and NN: 111.628125\n",
      "X^2 for PLUT and NN: 136.5207756232687\n",
      "> AUC for class X61: 0.9941973983247008 (+- 0.00019569542226404162)\n",
      "X^2 for MWPM and NN: 247.65689655172415\n",
      "X^2 for PLUT and NN: 403.19530102790014\n",
      "> AUC for class X62: 0.9948532187163599 (+- 0.000103727036994222)\n",
      "X^2 for MWPM and NN: 15.620192307692308\n",
      "X^2 for PLUT and NN: 463.9168865435356\n",
      "> AUC for class X63: 0.9951388459250474 (+- 0.00024226241520952104)\n",
      "X^2 for MWPM and NN: 127.72481572481573\n",
      "X^2 for PLUT and NN: 424.7347222222222\n",
      "> AUC for class X64: 0.9945299182888703 (+- 0.0004554492761440269)\n",
      "X^2 for MWPM and NN: 123.75596816976127\n",
      "X^2 for PLUT and NN: 468.64285714285717\n",
      "> AUC for class X65: 0.9930255945711417 (+- 3.475856758863264e-05)\n",
      "X^2 for MWPM and NN: 69.76202531645569\n",
      "X^2 for PLUT and NN: 371.9802110817942\n",
      "> AUC for class X66: 0.9795916915648133 (+- 0.0005834965535613788)\n",
      "X^2 for MWPM and NN: 68.45293315143248\n",
      "X^2 for PLUT and NN: 161.05942275042446\n",
      "> AUC for class Z00: 0.9525997267249513 (+- 0.000903718971728793)\n",
      "X^2 for MWPM and NN: 850.3213682432432\n",
      "X^2 for PLUT and NN: 0.6511627906976745\n",
      "> AUC for class Z01: 0.956403202844173 (+- 0.0005298346532048797)\n",
      "X^2 for MWPM and NN: 144.44478527607362\n",
      "X^2 for PLUT and NN: 168.51645569620254\n",
      "> AUC for class Z02: 0.9620305594641221 (+- 0.0014570896471886752)\n",
      "X^2 for MWPM and NN: 740.1315789473684\n",
      "X^2 for PLUT and NN: 174.94214876033058\n",
      "> AUC for class Z03: 0.9635397548661386 (+- 0.0012350624435508825)\n",
      "X^2 for MWPM and NN: 160.46458923512748\n",
      "X^2 for PLUT and NN: 169.35641025641024\n",
      "> AUC for class Z04: 0.9619354708543594 (+- 0.0004948386532119759)\n",
      "X^2 for MWPM and NN: 856.4514613778706\n",
      "X^2 for PLUT and NN: 168.20608899297423\n",
      "> AUC for class Z05: 0.9621777388185793 (+- 0.0008868640261445937)\n",
      "X^2 for MWPM and NN: 197.3658536585366\n",
      "X^2 for PLUT and NN: 221.13920454545453\n",
      "> AUC for class Z06: 0.9786469150540269 (+- 0.0002576214459584225)\n",
      "X^2 for MWPM and NN: 59.490136570561454\n",
      "X^2 for PLUT and NN: 128.18344155844156\n",
      "> AUC for class Z10: 0.9928751423816233 (+- 0.0001440901638348285)\n",
      "X^2 for MWPM and NN: 362.58179723502303\n",
      "X^2 for PLUT and NN: 365.9796195652174\n",
      "> AUC for class Z11: 0.9888575792003811 (+- 0.0004764121043467036)\n",
      "X^2 for MWPM and NN: 514.3101761252447\n",
      "X^2 for PLUT and NN: 340.76005747126436\n",
      "> AUC for class Z12: 0.9895734260006195 (+- 0.00042675160571411776)\n",
      "X^2 for MWPM and NN: 284.0062015503876\n",
      "X^2 for PLUT and NN: 331.38072669826227\n",
      "> AUC for class Z13: 0.9894767908168498 (+- 0.00028942438407495775)\n",
      "X^2 for MWPM and NN: 487.82119914346896\n",
      "X^2 for PLUT and NN: 341.53627311522047\n",
      "> AUC for class Z14: 0.9904000169593574 (+- 0.00028628047399610254)\n",
      "X^2 for MWPM and NN: 406.66776315789474\n",
      "X^2 for PLUT and NN: 284.2229916897507\n",
      "> AUC for class Z15: 0.9903049887661759 (+- 0.0004323795689815059)\n",
      "X^2 for MWPM and NN: 591.9389895138227\n",
      "X^2 for PLUT and NN: 330.475106685633\n",
      "> AUC for class Z16: 0.9920589977489737 (+- 0.0003041163455265835)\n",
      "X^2 for MWPM and NN: 72.88888888888889\n",
      "X^2 for PLUT and NN: 372.5782414307005\n",
      "> AUC for class Z20: 0.9941852880641522 (+- 0.00023656706676816776)\n",
      "X^2 for MWPM and NN: 109.63617021276596\n",
      "X^2 for PLUT and NN: 367.7814485387548\n",
      "> AUC for class Z21: 0.9908421238490683 (+- 0.000503875017711224)\n",
      "X^2 for MWPM and NN: 212.03136531365314\n",
      "X^2 for PLUT and NN: 370.0013736263736\n",
      "> AUC for class Z22: 0.9910383153979971 (+- 0.00023166122082677476)\n",
      "X^2 for MWPM and NN: 399.1954436450839\n",
      "X^2 for PLUT and NN: 314.01679586563307\n",
      "> AUC for class Z23: 0.991459254885439 (+- 9.209537945980369e-05)\n",
      "X^2 for MWPM and NN: 397.9649941656943\n",
      "X^2 for PLUT and NN: 464.44586894586894\n",
      "> AUC for class Z24: 0.990827911332598 (+- 0.0003819356729801369)\n",
      "X^2 for MWPM and NN: 255.16241610738254\n",
      "X^2 for PLUT and NN: 360.12603648424545\n",
      "> AUC for class Z25: 0.9913976282848337 (+- 0.00011421206981863637)\n",
      "X^2 for MWPM and NN: 140.92190476190476\n",
      "X^2 for PLUT and NN: 358.13492063492066\n",
      "> AUC for class Z26: 0.9945302620164747 (+- 0.0004047449679020229)\n",
      "X^2 for MWPM and NN: 162.74723247232473\n",
      "X^2 for PLUT and NN: 399.7257053291536\n",
      "> AUC for class Z30: 0.9939488716844647 (+- 0.00029041340961524515)\n",
      "X^2 for MWPM and NN: 223.24361158432708\n",
      "X^2 for PLUT and NN: 427.03607503607503\n",
      "> AUC for class Z31: 0.9913240224507143 (+- 0.00022417852749659968)\n",
      "X^2 for MWPM and NN: 264.44463087248323\n",
      "X^2 for PLUT and NN: 428.72884012539186\n",
      "> AUC for class Z32: 0.990387614987274 (+- 0.0003458087386458517)\n",
      "X^2 for MWPM and NN: 168.16890595009596\n",
      "X^2 for PLUT and NN: 328.4629120879121\n",
      "> AUC for class Z33: 0.9912942526752065 (+- 0.0002397136462101745)\n",
      "X^2 for MWPM and NN: 220.36499068901304\n",
      "X^2 for PLUT and NN: 408.2425952045134\n",
      "> AUC for class Z34: 0.9904966246503596 (+- 0.00030556131396860484)\n",
      "X^2 for MWPM and NN: 205.55362776025237\n",
      "X^2 for PLUT and NN: 387.1137640449438\n",
      "> AUC for class Z35: 0.991373401155569 (+- 0.0003576302524544807)\n",
      "X^2 for MWPM and NN: 229.08006279434852\n",
      "X^2 for PLUT and NN: 396.3753541076487\n",
      "> AUC for class Z36: 0.9943409833859709 (+- 0.00015665576020928654)\n",
      "X^2 for MWPM and NN: 36.23101265822785\n",
      "X^2 for PLUT and NN: 456.2485294117647\n",
      "> AUC for class Z40: 0.9940398301263239 (+- 0.0004966705021906446)\n",
      "X^2 for MWPM and NN: 184.92007797270955\n",
      "X^2 for PLUT and NN: 457.97925925925927\n",
      "> AUC for class Z41: 0.9916740134567952 (+- 0.00046429972591283065)\n",
      "X^2 for MWPM and NN: 179.82402707275804\n",
      "X^2 for PLUT and NN: 309.6831210191083\n",
      "> AUC for class Z42: 0.9907306656804362 (+- 0.0002591884919940091)\n",
      "X^2 for MWPM and NN: 313.46938775510205\n",
      "X^2 for PLUT and NN: 388.9761904761905\n",
      "> AUC for class Z43: 0.9905733192182476 (+- 0.00010025085602284877)\n",
      "X^2 for MWPM and NN: 379.7656050955414\n",
      "X^2 for PLUT and NN: 402.2848575712144\n",
      "> AUC for class Z44: 0.9910515260340833 (+- 0.0003781693750810755)\n",
      "X^2 for MWPM and NN: 271.5740432612313\n",
      "X^2 for PLUT and NN: 396.3753541076487\n",
      "> AUC for class Z45: 0.991547320065576 (+- 0.0002589608433178719)\n",
      "X^2 for MWPM and NN: 206.44237288135594\n",
      "X^2 for PLUT and NN: 379.5014880952381\n",
      "> AUC for class Z46: 0.9943715269781732 (+- 0.0004337105057427746)\n",
      "X^2 for MWPM and NN: 59.360433604336045\n",
      "X^2 for PLUT and NN: 360.2783661119516\n",
      "> AUC for class Z50: 0.9926937080869497 (+- 0.00018113683624329586)\n",
      "X^2 for MWPM and NN: 478.5984848484849\n",
      "X^2 for PLUT and NN: 406.8921568627451\n",
      "> AUC for class Z51: 0.990678025536443 (+- 0.0004979642221350934)\n",
      "X^2 for MWPM and NN: 208.69980119284295\n",
      "X^2 for PLUT and NN: 373.3171471927162\n",
      "> AUC for class Z52: 0.9897448878944639 (+- 0.00014976993629415403)\n",
      "X^2 for MWPM and NN: 456.63322185061315\n",
      "X^2 for PLUT and NN: 330.8924889543446\n",
      "> AUC for class Z53: 0.9901327559016765 (+- 0.00010894475268285256)\n",
      "X^2 for MWPM and NN: 280.5766312594841\n",
      "X^2 for PLUT and NN: 266.8100303951368\n",
      "> AUC for class Z54: 0.9897299766603224 (+- 0.00013647425169653762)\n",
      "X^2 for MWPM and NN: 463.67724288840265\n",
      "X^2 for PLUT and NN: 326.6680216802168\n",
      "> AUC for class Z55: 0.9896182650747791 (+- 0.0007809797041923034)\n",
      "X^2 for MWPM and NN: 246.2640625\n",
      "X^2 for PLUT and NN: 338.4948148148148\n",
      "> AUC for class Z56: 0.9934724287486076 (+- 0.00018431747489311935)\n",
      "X^2 for MWPM and NN: 222.10760667903526\n",
      "X^2 for PLUT and NN: 311.5655853314527\n",
      "> AUC for class Z60: 0.9792915582055787 (+- 0.0006432404233993493)\n",
      "X^2 for MWPM and NN: 422.0860979462875\n",
      "X^2 for PLUT and NN: 158.97962962962964\n",
      "> AUC for class Z61: 0.9610838010132154 (+- 0.0005107878129249448)\n",
      "X^2 for MWPM and NN: 743.5684647302904\n",
      "X^2 for PLUT and NN: 187.19059405940595\n",
      "> AUC for class Z62: 0.9629733508930871 (+- 0.0015571763237176124)\n",
      "X^2 for MWPM and NN: 217.02564102564102\n",
      "X^2 for PLUT and NN: 219.2922252010724\n",
      "> AUC for class Z63: 0.9620784499590056 (+- 0.0007602525456524797)\n",
      "X^2 for MWPM and NN: 767.5565873476495\n",
      "X^2 for PLUT and NN: 175.74324324324326\n",
      "> AUC for class Z64: 0.9626508879631023 (+- 0.00018957995743445154)\n",
      "X^2 for MWPM and NN: 189.82167832167832\n",
      "X^2 for PLUT and NN: 204.2296072507553\n",
      "> AUC for class Z65: 0.9617796131345026 (+- 0.00013811026312843358)\n",
      "X^2 for MWPM and NN: 731.4373289545704\n",
      "X^2 for PLUT and NN: 105.76178010471205\n",
      "> AUC for class Z66: 0.9616068316649268 (+- 0.000671276853393005)\n",
      "X^2 for MWPM and NN: 115.50297619047619\n",
      "X^2 for PLUT and NN: 139.68848167539267\n",
      "###################################################################################\n",
      "TOTAL F1 NN: [0.7466026170895966, 0.7447298695420905, 0.7449999416902822, 0.7453024489335289]\n",
      "TOTAL F1 PLUT: [0.07436437291975014, 0.07319961646740877, 0.07392483964771193]\n",
      "TOTAL F1 MWPM: [0.5570304203885315, 0.5576631378129446, 0.5564358397963814]\n",
      "TOTAL ACC NN: [0.9817760586738586, 0.9817712903022766, 0.9817626262626084]\n",
      "TOTAL ACC PLUT: [0.960282959944449, 0.960287018882497, 0.9603099766722879]\n",
      "TOTAL ACC MWPM: [0.9570212121211669, 0.9571409090908701, 0.9570479797979491]\n",
      "TOTAL TIME NN: [13.6240815, 12.273374, 11.9565955]\n",
      "TOTAL TIME PLUT: [27.279464, 16.1340635, 5.2510398]\n",
      "TOTAL TIME MWPM: [4881.778657700013, 9217.311648799974, 3500.318302099989, 5232.7764430999805]\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test MWPM decoder for this fold\n",
    "#labels = targets[train], features = inputs[train]\n",
    "# x_test_d7 = translate_to_graph(testData_d7_MWPM, targs, mlb_d7)\n",
    "\"\"\"\n",
    "decoding_d7, time_mwpm = do_new_decoding(x_test_d7, 7, 0)\n",
    "decoding_d7['combine'] = decoding_d7[[0, 1]].values.tolist()\n",
    "decoding_d7['combine'].apply(lambda x: x[0].extend(x[1]))\n",
    "decoding_d7 = np.array(decoding_d7[0])\n",
    "\n",
    "time_per_fold_mwpm.append(time_mwpm)\n",
    "\n",
    "pred_mwpm = mlb_d7.transform(decoding_d7)\n",
    "\n",
    "if fold_no < 3:\n",
    "    acc = partial_accuracy(targets_test_2, pred_mwpm)\n",
    "else:\n",
    "    acc, contingency_mwpm = partial_accuracy_and_contingency(targets_test_2, pred_mwpm, mlb_d7)\"\"\"\n",
    "\n",
    "#acc_per_fold_mwpm.append(acc)\n",
    "#f1_per_fold_mwpm.append(f1_score(targets_test_2, pred_mwpm, average='micro'))\n",
    "\n",
    "#####################################################################################################\n",
    "#test the plut decoder for this fold\n",
    "\n",
    "#lookup_d7 = lookup_decoder(7)\n",
    "\n",
    "#lookup_d7 = train_plut(lookup_d7, inputs_train, targets[train])\n",
    "\n",
    "#start = time.time_ns()\n",
    "#pred_plut_d7 = test_plut(lookup_d7, inputs_test)\n",
    "#end = time.time_ns() \n",
    "#time_per_fold_plut.append((end - start)/ (10 ** 9))\n",
    "\n",
    "if fold_no < 3:\n",
    "    acc = partial_accuracy(targets[test], pred_plut_d7)\n",
    "    f1 = f1_score(targets[test], pred_plut_d7, average='micro')\n",
    "else:\n",
    "    pred_plut_d7 = test_plut(lookup_d7, inputs_test_2)\n",
    "    #f1 = f1_score(targets_test_2, pred_plut_d7, average='micro')\n",
    "    acc, contingency_plut = partial_accuracy_and_contingency(targets_test_2, pred_plut_d7, mlb_d7)\n",
    "\n",
    "#acc_per_fold_plut.append(acc)\n",
    "#f1_per_fold_plut.append(f1)\n",
    "\n",
    "#####################################################################################################\n",
    "#Test the NN decoder for this fold\n",
    "\"\"\"\n",
    "model_d7 = compile_FFNN_model_DepthSeven(7)\n",
    "\n",
    "# Generate a print\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "# Fit data to model\n",
    "history = model_d7.fit(\n",
    "    x=inputs_train ,\n",
    "    y=targets[train],\n",
    "    validation_split=.25,\n",
    "    epochs= 150)\"\"\"\n",
    "\n",
    "pred = model_d7.predict(inputs_test_2)\n",
    "pred[pred>=.5]=1 \n",
    "pred[pred<.5]=0\n",
    "acc, contingency_nn = partial_accuracy_and_contingency(targets_test_2, pred, mlb_d7)\n",
    "f1 = f1_score(targets_test_2, pred, average='micro')\n",
    "\n",
    "#acc_per_fold.append(acc)\n",
    "f1_per_fold.append(f1)\n",
    "\n",
    "# Increase fold number\n",
    "fold_no = fold_no + 1\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(targets[test].ravel(), predictions_d7.ravel())\n",
    "tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "tprs[-1][0] = 0.0\n",
    "roc_auc = auc(fpr, tpr)\n",
    "aucs.append(roc_auc)\n",
    "plt.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "#get the AUCs of each class, used to get average AUC of each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(targets[test][:, i], predictions_d7[:, i]) \n",
    "    aucs_classes[mlb_d7.classes_[i]].append(auc(fpr[i], tpr[i]))\n",
    "\n",
    "#########################################################################################################\n",
    "#compute McNemar's statistic on results of last fold\n",
    "\n",
    "mcnemar_results_mwpm = {}\n",
    "mcnemar_results_plut = {}\n",
    "\n",
    "for class_ in mlb_d7.classes_:\n",
    "    \n",
    "    #compute the x^2 for NN and MWPM\n",
    "    mcnemar_results_mwpm[class_]=contingency_table_and_t(contingency_nn[class_], contingency_mwpm[class_])[1]    \n",
    "    #comput the x^2 for NN and PLUT\n",
    "    mcnemar_results_plut[class_] = contingency_table_and_t(contingency_nn[class_], contingency_plut[class_])[1]\n",
    "        \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds of MWPM:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_mwpm)} (+- {np.std(acc_per_fold_mwpm)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_mwpm)}(+- {np.std(f1_per_fold_mwpm)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_mwpm)} (+- {np.std(time_per_fold_mwpm)})')\n",
    "print('Average scores for all folds of PLUT:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold_plut)} (+- {np.std(acc_per_fold_plut)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold_plut)}(+- {np.std(f1_per_fold_plut)})')\n",
    "print(f'> Time: {np.mean(time_per_fold_plut)} (+- {np.std(time_per_fold_plut)})')\n",
    "print('Average scores for all folds of NN:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}(+- {np.std(f1_per_fold)})')\n",
    "print(f'> Time: {np.mean(time_per_fold)} (+- {np.std(time_per_fold)})')\n",
    "for key in aucs_classes:\n",
    "    cleanedList = [x for x in aucs_classes[key] if str(x) != 'nan']\n",
    "    print(f'> AUC for class {key}: {np.mean(cleanedList)} (+- {np.std(cleanedList)})') #this has to be a for loop\n",
    "    print(\"X^2 for MWPM and NN: \" + str(mcnemar_results_mwpm[key]))  \n",
    "    print(\"X^2 for PLUT and NN: \" + str(mcnemar_results_plut[key]))\n",
    "print(\"###################################################################################\")\n",
    "print(\"TOTAL F1 NN: \" + str(f1_per_fold))\n",
    "print(\"TOTAL F1 PLUT: \" + str(f1_per_fold_plut))\n",
    "print(\"TOTAL F1 MWPM: \" + str(f1_per_fold_mwpm))\n",
    "print(\"TOTAL ACC NN: \" + str(acc_per_fold))\n",
    "print(\"TOTAL ACC PLUT: \" + str(acc_per_fold_plut))\n",
    "print(\"TOTAL ACC MWPM: \" + str(acc_per_fold_mwpm))\n",
    "print(\"TOTAL TIME NN: \" + str(time_per_fold))\n",
    "print(\"TOTAL TIME PLUT: \" + str(time_per_fold_plut))\n",
    "print(\"TOTAL TIME MWPM: \" + str(time_per_fold_mwpm))\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of Depth 7 NN',fontsize=18)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model_d5 = compile_FFNN_model_DepthFive(5)\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "history = model_d5.fit(\n",
    "    x=x_train_d5.values,\n",
    "    y=Y_train_d5,\n",
    "    validation_split=.25,\n",
    "    epochs = 500\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Make a quick epoch vs. loss plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Depth 5 Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Make a quick epoch vs. accuracy plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Depth 5 Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# predict\n",
    "from sklearn.metrics import precision_score,accuracy_score, f1_score, recall_score, hamming_loss\n",
    "\n",
    "start = time.time()\n",
    "predictions_d5 = model_d5.predict(x_test_d5.values)\n",
    "end = time.time()\n",
    "print(\"Time: \" + str(end - start))\n",
    "\n",
    "pred=predictions_d5.copy()\n",
    "\n",
    "thresholds=[0.1, 0.2, 0.3, .4, .5, .6, .7, .8, .9]\n",
    "for val in thresholds:\n",
    "    pred=predictions_d5.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "    \n",
    "  \n",
    "    precision = precision_score(Y_test_d5, pred, average='micro')\n",
    "    recall = recall_score(Y_test_d5, pred, average='micro')\n",
    "    f1 = f1_score(Y_test_d5, pred, average='micro')\n",
    "   \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "    print(\"Accuracy = \",accuracy_score(Y_test_d5, pred))\n",
    "    print(\"Accuracy = \",partial_accuracy(Y_test_d5, pred))\n",
    "    print(\"\\n\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pred=predictions_d5.copy()\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "#look at confusion matrix to see what got misclassified    \n",
    "pred[pred>=.5]=1\n",
    "pred[pred<.5]=0\n",
    "multilabel_confusion_matrix(Y_test_d5, pred)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#look at classifcation report to see what got mislabeled\n",
    "print(classification_report(Y_test_d5, pred))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Train on 304908 samples, validate on 101636 samples\n",
      "Epoch 1/150\n",
      "304908/304908 [==============================] - 61s 200us/step - loss: 0.1685 - accuracy: 0.9585 - val_loss: 0.1573 - val_accuracy: 0.9599\n",
      "Epoch 2/150\n",
      "304908/304908 [==============================] - 62s 202us/step - loss: 0.1335 - accuracy: 0.9607 - val_loss: 0.1117 - val_accuracy: 0.9631\n",
      "Epoch 3/150\n",
      "304908/304908 [==============================] - 64s 210us/step - loss: 0.0985 - accuracy: 0.9665 - val_loss: 0.0879 - val_accuracy: 0.9699\n",
      "Epoch 4/150\n",
      "304908/304908 [==============================] - 68s 224us/step - loss: 0.0809 - accuracy: 0.9721 - val_loss: 0.0749 - val_accuracy: 0.9742\n",
      "Epoch 5/150\n",
      "304908/304908 [==============================] - 73s 238us/step - loss: 0.0704 - accuracy: 0.9757 - val_loss: 0.0666 - val_accuracy: 0.9771\n",
      "Epoch 6/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0630 - accuracy: 0.9783 - val_loss: 0.0602 - val_accuracy: 0.9793\n",
      "Epoch 7/150\n",
      "304908/304908 [==============================] - 57s 189us/step - loss: 0.0575 - accuracy: 0.9803 - val_loss: 0.0552 - val_accuracy: 0.9810\n",
      "Epoch 8/150\n",
      "304908/304908 [==============================] - 60s 197us/step - loss: 0.0532 - accuracy: 0.9817 - val_loss: 0.0519 - val_accuracy: 0.9821\n",
      "Epoch 9/150\n",
      "304908/304908 [==============================] - 60s 198us/step - loss: 0.0499 - accuracy: 0.9828 - val_loss: 0.0490 - val_accuracy: 0.9831\n",
      "Epoch 10/150\n",
      "304908/304908 [==============================] - 61s 199us/step - loss: 0.0473 - accuracy: 0.9837 - val_loss: 0.0463 - val_accuracy: 0.9840\n",
      "Epoch 11/150\n",
      "304908/304908 [==============================] - 59s 195us/step - loss: 0.0452 - accuracy: 0.9843 - val_loss: 0.0449 - val_accuracy: 0.9844\n",
      "Epoch 12/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0434 - accuracy: 0.9849 - val_loss: 0.0430 - val_accuracy: 0.9850\n",
      "Epoch 13/150\n",
      "304908/304908 [==============================] - 63s 207us/step - loss: 0.0419 - accuracy: 0.9853 - val_loss: 0.0414 - val_accuracy: 0.9855\n",
      "Epoch 14/150\n",
      "304908/304908 [==============================] - 56s 184us/step - loss: 0.0406 - accuracy: 0.9857 - val_loss: 0.0403 - val_accuracy: 0.9858\n",
      "Epoch 15/150\n",
      "304908/304908 [==============================] - 66s 215us/step - loss: 0.0395 - accuracy: 0.9860 - val_loss: 0.0392 - val_accuracy: 0.9861\n",
      "Epoch 16/150\n",
      "304908/304908 [==============================] - 57s 186us/step - loss: 0.0385 - accuracy: 0.9863 - val_loss: 0.0384 - val_accuracy: 0.9863\n",
      "Epoch 17/150\n",
      "304908/304908 [==============================] - 60s 196us/step - loss: 0.0376 - accuracy: 0.9865 - val_loss: 0.0374 - val_accuracy: 0.9866\n",
      "Epoch 18/150\n",
      "304908/304908 [==============================] - 62s 205us/step - loss: 0.0367 - accuracy: 0.9867 - val_loss: 0.0367 - val_accuracy: 0.9867\n",
      "Epoch 19/150\n",
      "304908/304908 [==============================] - 60s 196us/step - loss: 0.0360 - accuracy: 0.9869 - val_loss: 0.0362 - val_accuracy: 0.9868\n",
      "Epoch 20/150\n",
      "304908/304908 [==============================] - 62s 205us/step - loss: 0.0353 - accuracy: 0.9871 - val_loss: 0.0358 - val_accuracy: 0.9870\n",
      "Epoch 21/150\n",
      "304908/304908 [==============================] - 59s 194us/step - loss: 0.0346 - accuracy: 0.9873 - val_loss: 0.0348 - val_accuracy: 0.9872\n",
      "Epoch 22/150\n",
      "304908/304908 [==============================] - 56s 185us/step - loss: 0.0340 - accuracy: 0.9874 - val_loss: 0.0342 - val_accuracy: 0.9873\n",
      "Epoch 23/150\n",
      "304908/304908 [==============================] - 56s 184us/step - loss: 0.0334 - accuracy: 0.9876 - val_loss: 0.0334 - val_accuracy: 0.9876\n",
      "Epoch 24/150\n",
      "304908/304908 [==============================] - 60s 197us/step - loss: 0.0329 - accuracy: 0.9877 - val_loss: 0.0330 - val_accuracy: 0.9877\n",
      "Epoch 25/150\n",
      "304908/304908 [==============================] - 60s 197us/step - loss: 0.0323 - accuracy: 0.9878 - val_loss: 0.0325 - val_accuracy: 0.9878\n",
      "Epoch 26/150\n",
      "304908/304908 [==============================] - 57s 186us/step - loss: 0.0318 - accuracy: 0.9880 - val_loss: 0.0320 - val_accuracy: 0.9879\n",
      "Epoch 27/150\n",
      "304908/304908 [==============================] - 62s 203us/step - loss: 0.0314 - accuracy: 0.9881 - val_loss: 0.0313 - val_accuracy: 0.9881\n",
      "Epoch 28/150\n",
      "304908/304908 [==============================] - 58s 191us/step - loss: 0.0309 - accuracy: 0.9882 - val_loss: 0.0310 - val_accuracy: 0.9881\n",
      "Epoch 29/150\n",
      "304908/304908 [==============================] - 55s 181us/step - loss: 0.0305 - accuracy: 0.9883 - val_loss: 0.0307 - val_accuracy: 0.9882\n",
      "Epoch 30/150\n",
      "304908/304908 [==============================] - 55s 181us/step - loss: 0.0300 - accuracy: 0.9884 - val_loss: 0.0305 - val_accuracy: 0.9882\n",
      "Epoch 31/150\n",
      "304908/304908 [==============================] - 56s 184us/step - loss: 0.0296 - accuracy: 0.9885 - val_loss: 0.0302 - val_accuracy: 0.9883\n",
      "Epoch 32/150\n",
      "304908/304908 [==============================] - 56s 185us/step - loss: 0.0292 - accuracy: 0.9886 - val_loss: 0.0297 - val_accuracy: 0.9885\n",
      "Epoch 33/150\n",
      "304908/304908 [==============================] - 69s 227us/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 0.0298 - val_accuracy: 0.9884\n",
      "Epoch 34/150\n",
      "304908/304908 [==============================] - 67s 218us/step - loss: 0.0285 - accuracy: 0.9888 - val_loss: 0.0292 - val_accuracy: 0.9886\n",
      "Epoch 35/150\n",
      "304908/304908 [==============================] - 61s 200us/step - loss: 0.0282 - accuracy: 0.9889 - val_loss: 0.0286 - val_accuracy: 0.9887\n",
      "Epoch 36/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0279 - accuracy: 0.9890 - val_loss: 0.0286 - val_accuracy: 0.9887\n",
      "Epoch 37/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0276 - accuracy: 0.9891 - val_loss: 0.0281 - val_accuracy: 0.9888\n",
      "Epoch 38/150\n",
      "304908/304908 [==============================] - 61s 199us/step - loss: 0.0273 - accuracy: 0.9892 - val_loss: 0.0278 - val_accuracy: 0.9889\n",
      "Epoch 39/150\n",
      "304908/304908 [==============================] - 58s 191us/step - loss: 0.0270 - accuracy: 0.9892 - val_loss: 0.0274 - val_accuracy: 0.9891\n",
      "Epoch 40/150\n",
      "304908/304908 [==============================] - 63s 207us/step - loss: 0.0267 - accuracy: 0.9893 - val_loss: 0.0273 - val_accuracy: 0.9890\n",
      "Epoch 41/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0264 - accuracy: 0.9894 - val_loss: 0.0271 - val_accuracy: 0.9891\n",
      "Epoch 42/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0262 - accuracy: 0.9895 - val_loss: 0.0267 - val_accuracy: 0.9893\n",
      "Epoch 43/150\n",
      "304908/304908 [==============================] - 58s 191us/step - loss: 0.0259 - accuracy: 0.9895 - val_loss: 0.0265 - val_accuracy: 0.9892\n",
      "Epoch 44/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0257 - accuracy: 0.9896 - val_loss: 0.0262 - val_accuracy: 0.9893\n",
      "Epoch 45/150\n",
      "304908/304908 [==============================] - 60s 196us/step - loss: 0.0255 - accuracy: 0.9897 - val_loss: 0.0263 - val_accuracy: 0.9893\n",
      "Epoch 46/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0252 - accuracy: 0.9897 - val_loss: 0.0259 - val_accuracy: 0.9894\n",
      "Epoch 47/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0250 - accuracy: 0.9898 - val_loss: 0.0257 - val_accuracy: 0.9895\n",
      "Epoch 48/150\n",
      "304908/304908 [==============================] - 61s 199us/step - loss: 0.0248 - accuracy: 0.9898 - val_loss: 0.0257 - val_accuracy: 0.9894\n",
      "Epoch 49/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0246 - accuracy: 0.9899 - val_loss: 0.0253 - val_accuracy: 0.9895\n",
      "Epoch 50/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0244 - accuracy: 0.9899 - val_loss: 0.0252 - val_accuracy: 0.9896\n",
      "Epoch 51/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0242 - accuracy: 0.9900 - val_loss: 0.0251 - val_accuracy: 0.9896\n",
      "Epoch 52/150\n",
      "304908/304908 [==============================] - 58s 191us/step - loss: 0.0241 - accuracy: 0.9900 - val_loss: 0.0250 - val_accuracy: 0.9896\n",
      "Epoch 53/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0239 - accuracy: 0.9901 - val_loss: 0.0245 - val_accuracy: 0.9898\n",
      "Epoch 54/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0237 - accuracy: 0.9901 - val_loss: 0.0244 - val_accuracy: 0.9898\n",
      "Epoch 55/150\n",
      "304908/304908 [==============================] - 58s 191us/step - loss: 0.0235 - accuracy: 0.9902 - val_loss: 0.0241 - val_accuracy: 0.9898\n",
      "Epoch 56/150\n",
      "304908/304908 [==============================] - 59s 193us/step - loss: 0.0234 - accuracy: 0.9902 - val_loss: 0.0241 - val_accuracy: 0.9898\n",
      "Epoch 57/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0232 - accuracy: 0.9902 - val_loss: 0.0240 - val_accuracy: 0.9899\n",
      "Epoch 58/150\n",
      "304908/304908 [==============================] - 59s 193us/step - loss: 0.0231 - accuracy: 0.9903 - val_loss: 0.0240 - val_accuracy: 0.9899\n",
      "Epoch 59/150\n",
      "304908/304908 [==============================] - 58s 191us/step - loss: 0.0229 - accuracy: 0.9903 - val_loss: 0.0238 - val_accuracy: 0.9899\n",
      "Epoch 60/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0228 - accuracy: 0.9904 - val_loss: 0.0236 - val_accuracy: 0.9899\n",
      "Epoch 61/150\n",
      "304908/304908 [==============================] - 59s 192us/step - loss: 0.0226 - accuracy: 0.9904 - val_loss: 0.0238 - val_accuracy: 0.9899\n",
      "Epoch 62/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0225 - accuracy: 0.9904 - val_loss: 0.0235 - val_accuracy: 0.9900\n",
      "Epoch 63/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0224 - accuracy: 0.9905 - val_loss: 0.0245 - val_accuracy: 0.9896\n",
      "Epoch 64/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0222 - accuracy: 0.9905 - val_loss: 0.0232 - val_accuracy: 0.9901\n",
      "Epoch 65/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0221 - accuracy: 0.9905 - val_loss: 0.0230 - val_accuracy: 0.9901\n",
      "Epoch 66/150\n",
      "304908/304908 [==============================] - 59s 193us/step - loss: 0.0220 - accuracy: 0.9906 - val_loss: 0.0229 - val_accuracy: 0.9902\n",
      "Epoch 67/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0219 - accuracy: 0.9906 - val_loss: 0.0228 - val_accuracy: 0.9902\n",
      "Epoch 68/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0217 - accuracy: 0.9906 - val_loss: 0.0228 - val_accuracy: 0.9902\n",
      "Epoch 69/150\n",
      "304908/304908 [==============================] - 60s 196us/step - loss: 0.0216 - accuracy: 0.9907 - val_loss: 0.0227 - val_accuracy: 0.9903\n",
      "Epoch 70/150\n",
      "304908/304908 [==============================] - 57s 187us/step - loss: 0.0215 - accuracy: 0.9907 - val_loss: 0.0225 - val_accuracy: 0.9903\n",
      "Epoch 71/150\n",
      "304908/304908 [==============================] - 58s 191us/step - loss: 0.0214 - accuracy: 0.9907 - val_loss: 0.0224 - val_accuracy: 0.9903\n",
      "Epoch 72/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0213 - accuracy: 0.9908 - val_loss: 0.0223 - val_accuracy: 0.9904\n",
      "Epoch 73/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0212 - accuracy: 0.9908 - val_loss: 0.0224 - val_accuracy: 0.9903\n",
      "Epoch 74/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0211 - accuracy: 0.9908 - val_loss: 0.0221 - val_accuracy: 0.9904\n",
      "Epoch 75/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0210 - accuracy: 0.9908 - val_loss: 0.0220 - val_accuracy: 0.9904\n",
      "Epoch 76/150\n",
      "304908/304908 [==============================] - 59s 194us/step - loss: 0.0209 - accuracy: 0.9909 - val_loss: 0.0219 - val_accuracy: 0.9904\n",
      "Epoch 77/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0208 - accuracy: 0.9909 - val_loss: 0.0216 - val_accuracy: 0.9905\n",
      "Epoch 78/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0207 - accuracy: 0.9909 - val_loss: 0.0221 - val_accuracy: 0.9903\n",
      "Epoch 79/150\n",
      "304908/304908 [==============================] - 61s 199us/step - loss: 0.0206 - accuracy: 0.9909 - val_loss: 0.0218 - val_accuracy: 0.9904\n",
      "Epoch 80/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0205 - accuracy: 0.9910 - val_loss: 0.0215 - val_accuracy: 0.9905\n",
      "Epoch 81/150\n",
      "304908/304908 [==============================] - 58s 191us/step - loss: 0.0204 - accuracy: 0.9910 - val_loss: 0.0216 - val_accuracy: 0.9905\n",
      "Epoch 82/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0203 - accuracy: 0.9910 - val_loss: 0.0214 - val_accuracy: 0.9905\n",
      "Epoch 83/150\n",
      "304908/304908 [==============================] - 57s 187us/step - loss: 0.0202 - accuracy: 0.9910 - val_loss: 0.0218 - val_accuracy: 0.9903\n",
      "Epoch 84/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0201 - accuracy: 0.9911 - val_loss: 0.0211 - val_accuracy: 0.9906\n",
      "Epoch 85/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0201 - accuracy: 0.9911 - val_loss: 0.0212 - val_accuracy: 0.9906\n",
      "Epoch 86/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0200 - accuracy: 0.9911 - val_loss: 0.0211 - val_accuracy: 0.9906\n",
      "Epoch 87/150\n",
      "304908/304908 [==============================] - 60s 195us/step - loss: 0.0199 - accuracy: 0.9911 - val_loss: 0.0210 - val_accuracy: 0.9907\n",
      "Epoch 88/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0198 - accuracy: 0.9912 - val_loss: 0.0208 - val_accuracy: 0.9906\n",
      "Epoch 89/150\n",
      "304908/304908 [==============================] - 59s 193us/step - loss: 0.0197 - accuracy: 0.9912 - val_loss: 0.0210 - val_accuracy: 0.9907\n",
      "Epoch 90/150\n",
      "304908/304908 [==============================] - 58s 192us/step - loss: 0.0197 - accuracy: 0.9912 - val_loss: 0.0207 - val_accuracy: 0.9907\n",
      "Epoch 91/150\n",
      "304908/304908 [==============================] - 57s 187us/step - loss: 0.0196 - accuracy: 0.9912 - val_loss: 0.0207 - val_accuracy: 0.9907\n",
      "Epoch 92/150\n",
      "304908/304908 [==============================] - 59s 195us/step - loss: 0.0195 - accuracy: 0.9912 - val_loss: 0.0208 - val_accuracy: 0.9907\n",
      "Epoch 93/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0194 - accuracy: 0.9913 - val_loss: 0.0207 - val_accuracy: 0.9906\n",
      "Epoch 94/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0194 - accuracy: 0.9913 - val_loss: 0.0208 - val_accuracy: 0.9907\n",
      "Epoch 95/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0193 - accuracy: 0.9913 - val_loss: 0.0206 - val_accuracy: 0.9908\n",
      "Epoch 96/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0192 - accuracy: 0.9913 - val_loss: 0.0206 - val_accuracy: 0.9906\n",
      "Epoch 97/150\n",
      "304908/304908 [==============================] - 59s 193us/step - loss: 0.0191 - accuracy: 0.9913 - val_loss: 0.0204 - val_accuracy: 0.9908\n",
      "Epoch 98/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0191 - accuracy: 0.9914 - val_loss: 0.0205 - val_accuracy: 0.9907\n",
      "Epoch 99/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0190 - accuracy: 0.9914 - val_loss: 0.0204 - val_accuracy: 0.9908\n",
      "Epoch 100/150\n",
      "304908/304908 [==============================] - 60s 196us/step - loss: 0.0189 - accuracy: 0.9914 - val_loss: 0.0200 - val_accuracy: 0.9908\n",
      "Epoch 101/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0189 - accuracy: 0.9914 - val_loss: 0.0200 - val_accuracy: 0.9908\n",
      "Epoch 102/150\n",
      "304908/304908 [==============================] - 59s 193us/step - loss: 0.0188 - accuracy: 0.9914 - val_loss: 0.0200 - val_accuracy: 0.9908\n",
      "Epoch 103/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0187 - accuracy: 0.9914 - val_loss: 0.0202 - val_accuracy: 0.9908\n",
      "Epoch 104/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0187 - accuracy: 0.9915 - val_loss: 0.0199 - val_accuracy: 0.9908\n",
      "Epoch 105/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0186 - accuracy: 0.9915 - val_loss: 0.0200 - val_accuracy: 0.9909\n",
      "Epoch 106/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0186 - accuracy: 0.9915 - val_loss: 0.0200 - val_accuracy: 0.9908\n",
      "Epoch 107/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304908/304908 [==============================] - 59s 194us/step - loss: 0.0185 - accuracy: 0.9915 - val_loss: 0.0202 - val_accuracy: 0.9908\n",
      "Epoch 108/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0184 - accuracy: 0.9915 - val_loss: 0.0204 - val_accuracy: 0.9908\n",
      "Epoch 109/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0184 - accuracy: 0.9915 - val_loss: 0.0197 - val_accuracy: 0.9909\n",
      "Epoch 110/150\n",
      "304908/304908 [==============================] - 60s 198us/step - loss: 0.0183 - accuracy: 0.9916 - val_loss: 0.0196 - val_accuracy: 0.9909\n",
      "Epoch 111/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0183 - accuracy: 0.9915 - val_loss: 0.0197 - val_accuracy: 0.9909\n",
      "Epoch 112/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0182 - accuracy: 0.9916 - val_loss: 0.0197 - val_accuracy: 0.9909\n",
      "Epoch 113/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0182 - accuracy: 0.9916 - val_loss: 0.0194 - val_accuracy: 0.9910\n",
      "Epoch 114/150\n",
      "304908/304908 [==============================] - 57s 189us/step - loss: 0.0181 - accuracy: 0.9916 - val_loss: 0.0195 - val_accuracy: 0.9909\n",
      "Epoch 115/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0181 - accuracy: 0.9916 - val_loss: 0.0195 - val_accuracy: 0.9909\n",
      "Epoch 116/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0180 - accuracy: 0.9916 - val_loss: 0.0193 - val_accuracy: 0.9910\n",
      "Epoch 117/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0179 - accuracy: 0.9917 - val_loss: 0.0196 - val_accuracy: 0.9909\n",
      "Epoch 118/150\n",
      "304908/304908 [==============================] - 59s 195us/step - loss: 0.0179 - accuracy: 0.9917 - val_loss: 0.0195 - val_accuracy: 0.9910\n",
      "Epoch 119/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0179 - accuracy: 0.9917 - val_loss: 0.0193 - val_accuracy: 0.9910\n",
      "Epoch 120/150\n",
      "304908/304908 [==============================] - 59s 193us/step - loss: 0.0178 - accuracy: 0.9917 - val_loss: 0.0197 - val_accuracy: 0.9908\n",
      "Epoch 121/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0178 - accuracy: 0.9917 - val_loss: 0.0192 - val_accuracy: 0.9910\n",
      "Epoch 122/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0177 - accuracy: 0.9917 - val_loss: 0.0192 - val_accuracy: 0.9910\n",
      "Epoch 123/150\n",
      "304908/304908 [==============================] - 58s 192us/step - loss: 0.0177 - accuracy: 0.9917 - val_loss: 0.0192 - val_accuracy: 0.9910\n",
      "Epoch 124/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0176 - accuracy: 0.9917 - val_loss: 0.0191 - val_accuracy: 0.9911\n",
      "Epoch 125/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0176 - accuracy: 0.9918 - val_loss: 0.0191 - val_accuracy: 0.9910\n",
      "Epoch 126/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0175 - accuracy: 0.9918 - val_loss: 0.0189 - val_accuracy: 0.9911\n",
      "Epoch 127/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0175 - accuracy: 0.9918 - val_loss: 0.0190 - val_accuracy: 0.9910\n",
      "Epoch 128/150\n",
      "304908/304908 [==============================] - 59s 193us/step - loss: 0.0174 - accuracy: 0.9918 - val_loss: 0.0189 - val_accuracy: 0.9911\n",
      "Epoch 129/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0174 - accuracy: 0.9918 - val_loss: 0.0189 - val_accuracy: 0.9911\n",
      "Epoch 130/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0174 - accuracy: 0.9918 - val_loss: 0.0188 - val_accuracy: 0.9911\n",
      "Epoch 131/150\n",
      "304908/304908 [==============================] - 60s 196us/step - loss: 0.0173 - accuracy: 0.9918 - val_loss: 0.0192 - val_accuracy: 0.9909\n",
      "Epoch 132/150\n",
      "304908/304908 [==============================] - 57s 189us/step - loss: 0.0173 - accuracy: 0.9918 - val_loss: 0.0188 - val_accuracy: 0.9910\n",
      "Epoch 133/150\n",
      "304908/304908 [==============================] - 59s 193us/step - loss: 0.0172 - accuracy: 0.9918 - val_loss: 0.0186 - val_accuracy: 0.9911\n",
      "Epoch 134/150\n",
      "304908/304908 [==============================] - 57s 187us/step - loss: 0.0172 - accuracy: 0.9919 - val_loss: 0.0188 - val_accuracy: 0.9911\n",
      "Epoch 135/150\n",
      "304908/304908 [==============================] - 59s 193us/step - loss: 0.0171 - accuracy: 0.9919 - val_loss: 0.0187 - val_accuracy: 0.9911\n",
      "Epoch 136/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0171 - accuracy: 0.9919 - val_loss: 0.0187 - val_accuracy: 0.9911\n",
      "Epoch 137/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0171 - accuracy: 0.9919 - val_loss: 0.0187 - val_accuracy: 0.9911\n",
      "Epoch 138/150\n",
      "304908/304908 [==============================] - 59s 193us/step - loss: 0.0170 - accuracy: 0.9919 - val_loss: 0.0185 - val_accuracy: 0.9911\n",
      "Epoch 139/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0170 - accuracy: 0.9919 - val_loss: 0.0185 - val_accuracy: 0.9911\n",
      "Epoch 140/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0169 - accuracy: 0.9919 - val_loss: 0.0185 - val_accuracy: 0.9911\n",
      "Epoch 141/150\n",
      "304908/304908 [==============================] - 60s 197us/step - loss: 0.0169 - accuracy: 0.9919 - val_loss: 0.0186 - val_accuracy: 0.9911\n",
      "Epoch 142/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0169 - accuracy: 0.9919 - val_loss: 0.0184 - val_accuracy: 0.9912\n",
      "Epoch 143/150\n",
      "304908/304908 [==============================] - 58s 192us/step - loss: 0.0168 - accuracy: 0.9920 - val_loss: 0.0183 - val_accuracy: 0.9912\n",
      "Epoch 144/150\n",
      "304908/304908 [==============================] - 58s 189us/step - loss: 0.0168 - accuracy: 0.9920 - val_loss: 0.0189 - val_accuracy: 0.9910\n",
      "Epoch 145/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0168 - accuracy: 0.9920 - val_loss: 0.0184 - val_accuracy: 0.9911\n",
      "Epoch 146/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0167 - accuracy: 0.9920 - val_loss: 0.0185 - val_accuracy: 0.9912\n",
      "Epoch 147/150\n",
      "304908/304908 [==============================] - 57s 188us/step - loss: 0.0167 - accuracy: 0.9920 - val_loss: 0.0185 - val_accuracy: 0.9912\n",
      "Epoch 148/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0166 - accuracy: 0.9920 - val_loss: 0.0183 - val_accuracy: 0.9912\n",
      "Epoch 149/150\n",
      "304908/304908 [==============================] - 59s 194us/step - loss: 0.0166 - accuracy: 0.9920 - val_loss: 0.0183 - val_accuracy: 0.9912\n",
      "Epoch 150/150\n",
      "304908/304908 [==============================] - 58s 190us/step - loss: 0.0166 - accuracy: 0.9920 - val_loss: 0.0184 - val_accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "model_d7 = compile_FFNN_model_DepthSeven(7)\n",
    "print(\"Fit model on training data\")\n",
    "history = model_d7.fit(\n",
    "    x=x_train_d7.values,\n",
    "    y=Y_train_d7,\n",
    "    validation_split=.25,\n",
    "    epochs= 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss (MSE)')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a quick epoch vs. loss plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Depth 7 Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a quick epoch vs. accuracy plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Depth 7 Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 4.547666311264038\n",
      "Micro-average quality numbers\n",
      "Precision: 0.7567, Recall: 0.9810, F1-measure: 0.8544\n",
      "Accuracy =  0.36361131882403874\n",
      "Accuracy =  0.9866029137051278\n",
      "\n",
      "\n",
      "Micro-average quality numbers\n",
      "Precision: 0.8088, Recall: 0.9604, F1-measure: 0.8781\n",
      "Accuracy =  0.43610531701365657\n",
      "Accuracy =  0.9893198783056936\n",
      "\n",
      "\n",
      "Micro-average quality numbers\n",
      "Precision: 0.8427, Recall: 0.9340, F1-measure: 0.8860\n",
      "Accuracy =  0.4861171238537526\n",
      "Accuracy =  0.9903745431803124\n",
      "\n",
      "\n",
      "Micro-average quality numbers\n",
      "Precision: 0.8738, Recall: 0.9030, F1-measure: 0.8882\n",
      "Accuracy =  0.5202782478649297\n",
      "Accuracy =  0.9908926328892962\n",
      "\n",
      "\n",
      "Micro-average quality numbers\n",
      "Precision: 0.9049, Recall: 0.8706, F1-measure: 0.8874\n",
      "Accuracy =  0.527687040025188\n",
      "Accuracy =  0.9911501372890424\n",
      "\n",
      "\n",
      "Micro-average quality numbers\n",
      "Precision: 0.9356, Recall: 0.8387, F1-measure: 0.8845\n",
      "Accuracy =  0.5064839230194026\n",
      "Accuracy =  0.9912244766525676\n",
      "\n",
      "\n",
      "Micro-average quality numbers\n",
      "Precision: 0.9620, Recall: 0.8108, F1-measure: 0.8799\n",
      "Accuracy =  0.4698532016214727\n",
      "Accuracy =  0.9911376148827753\n",
      "\n",
      "\n",
      "Micro-average quality numbers\n",
      "Precision: 0.9807, Recall: 0.7842, F1-measure: 0.8715\n",
      "Accuracy =  0.42834231965051756\n",
      "Accuracy =  0.9907367985013541\n",
      "\n",
      "\n",
      "Micro-average quality numbers\n",
      "Precision: 0.9918, Recall: 0.7462, F1-measure: 0.8516\n",
      "Accuracy =  0.3733322838364359\n",
      "Accuracy =  0.9895851346711012\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\n",
    "# predict\n",
    "from sklearn.metrics import precision_score,accuracy_score, f1_score, recall_score, hamming_loss\n",
    "\n",
    "start = time.time()\n",
    "predictions_d7 = model_d7.predict(x_test_d7.values)\n",
    "end = time.time()\n",
    "print(\"Time: \" + str(end - start))\n",
    "\n",
    "pred=predictions_d7.copy()\n",
    "\n",
    "\n",
    "thresholds=[0.1, 0.2, 0.3, .4, .5, .6, .7, .8, .9]\n",
    "for val in thresholds:\n",
    "    pred=predictions_d7.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "    \n",
    "  \n",
    "    precision = precision_score(Y_test_d7, pred, average='micro')\n",
    "    recall = recall_score(Y_test_d7, pred, average='micro')\n",
    "    f1 = f1_score(Y_test_d7, pred, average='micro')\n",
    "   \n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "    print(\"Accuracy = \",accuracy_score(Y_test_d7, pred))\n",
    "    print(\"Accuracy = \",partial_accuracy(Y_test_d7, pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "predictions_d7 = model_d7.predict(x_test_d7.values)\n",
    "pred=predictions_d7.copy()\n",
    "\n",
    "n_classes = 99\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test_d7[:, i], pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test_d7.ravel(), pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x_train_d3.to_csv(\"x_train_d3_01.csv\")\n",
    "x_test_d3.to_csv(\"x_test_d3_01.csv\")\n",
    "pd.DataFrame(Y_train_d3).to_csv(\"Y_train_d3_01.csv\")\n",
    "pd.DataFrame(Y_test_d3).to_csv(\"Y_test_d3_01.csv\")\n",
    "\n",
    "x_train_d5.to_csv(\"x_train_d5_01.csv\")\n",
    "x_test_d5.to_csv(\"x_test_d5_01.csv\")\n",
    "pd.DataFrame(Y_train_d5).to_csv(\"Y_train_d5_01.csv\")\n",
    "pd.DataFrame(Y_test_d5).to_csv(\"Y_test_d5_01.csv\")\n",
    "\n",
    "x_train_d7.to_csv(\"x_train_d7_01.csv\")\n",
    "x_test_d7.to_csv(\"x_test_d7_01.csv\")\n",
    "pd.DataFrame(Y_train_d7).to_csv(\"Y_train_d7_01.csv\")\n",
    "pd.DataFrame(Y_test_d7).to_csv(\"Y_test_d7_01.csv\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model_d7.save(\"model_d7_01.h5\")\n",
    "#model_d5.save(\"model_d5_01.h5\")\n",
    "model.save(\"model_d3_01.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
